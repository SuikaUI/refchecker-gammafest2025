This item was submitted to Loughborough's Research Repository by the author.
Items in Figshare are protected by copyright, with all rights reserved, unless otherwise indicated.
Transfer learning and meta learning-based fast downlink beamforming
adaptation
PLEASE CITE THE PUBLISHED VERSION
 
AM (Accepted Manuscript)
PUBLISHER STATEMENT
© 2020 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other
uses, in any current or future media, including reprinting/republishing this material for advertising or
promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of
any copyrighted component of this work in other works.
All Rights Reserved
REPOSITORY RECORD
Yuan, Yi, Gan Zheng, Kai-Kit Wong, Björn Ottersten, and Zhi-Quan Luo. 2020. “Transfer Learning and Meta
Learning-based Fast Downlink Beamforming Adaptation”. Loughborough University.
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
Transfer Learning and Meta Learning Based
Fast Downlink Beamforming Adaptation
Yi Yuan, Gan Zheng, Senior Member, IEEE, Kai-Kit Wong, Fellow, IEEE,
Bj¨orn Ottersten, Fellow, IEEE, Zhi-Quan Luo, Fellow, IEEE
This paper studies fast adaptive beamforming optimization for the signal-to-interference-plus-noise
ratio balancing problem in a multiuser multiple-input single-output downlink system. Existing deep
learning based approaches to predict beamforming rely on the assumption that the training and testing
channels follow the same distribution which may not hold in practice. As a result, a trained model
may lead to performance deterioration when the testing network environment changes. To deal with
this task mismatch issue, we propose two ofﬂine adaptive algorithms based on deep transfer learning
and meta-learning, which are able to achieve fast adaptation with the limited new labelled data when
the testing wireless environment changes. Furthermore, we propose an online algorithm to enhance the
adaptation capability of the ofﬂine meta algorithm in realistic non-stationary environments. Simulation
results demonstrate that the proposed adaptive algorithms achieve much better performance than the
direct deep learning algorithm without adaptation in new environments. The meta-learning algorithm
outperforms the deep transfer learning algorithm and achieves near optimal performance. In addition,
compared to the ofﬂine meta-learning algorithm, the proposed online meta-learning algorithm shows
superior adaption performance in changing environments.
Index Terms
Deep transfer learning, meta-learning, online learning, beamforming, MISO, SINR balancing.
Y. Yuan and G. Zheng are with the Wolfson School of Mechanical, Electrical and Manufacturing Engineering, Loughborough
University, Loughborough, LE11 3TU, UK (E-mail: {y.yuan, g.zheng}@lboro.ac.uk).
K.-K. Wong is with the Department of Electronic and Electrical Engineering, University College London, London, WC1E
6BT, UK (Email: ).
B. Ottersten is with Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, L-1359
Luxembourg (Email: ).
Z.-Q. Luo is with Shenzhen Research Institute of Big Data, and the Chinese University of Hong Kong, Shenzhen, China
(Email: ).
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
I. INTRODUCTION
Multi-antenna techniques have been widely used to improve the spectral efﬁciency of modern
wireless communications systems due to their ability to exploit spatial characteristics of the
propagation channel , . Beamforming is recognized as one of the most promising multiantenna techniques since it can efﬁciently improve the antenna diversity gain and mitigate
multiuser interference. In the last two decades, beamforming optimization has been well studied
for some speciﬁcal problems, such as signal-to-interference-plus-noise ratio (SINR) balancing
problem , , power minimization problem , and sum rate maximization problem
 , – . Most beamforming design problems are solved using either tailor-made iterative
algorithms or general iterative algorithms using convex optimization tools. However, iterative
algorithms may have slow convergence. This fact causes severe computational latency and makes
the optimized beamforming solutions outdated. Hence, existing beamforming techniques have
difﬁculty meeting the demands for real-time applications in the ﬁfth generation (5G) systems.
Although heuristic methods such as zero-forcing (ZF) beamforming are faster to implement,
they often show far from optimal system performance. Hence, designing efﬁcient solutions that
balance computational complexity and performance has attracted much attention.
Recently, deep learning (DL) has been recognized as an efﬁcient technique to solve difﬁcult
design problems in wireless communications due to its ability of modeling highly non-linear
functions at considerably lower complexity – . Accordingly, DL techniques have been
widely used in many applications of wireless networks to address speciﬁc physical layer issues,
such as channel estimation and decoding – , hybrid precoding – and resource
allocation – . The successful application of the DL techniques on the problems of resource
allocation – is based on the learning to optimize framework, which aims to learn a simple
mapping through the deep neural network (DNN) instead of optimizing the complex mathematic
problems. Motivated by the above successful applications of DL techniques, it is possible to
address the tradeoff issue between complexity and performance in the beamforming design.
This is the result of the mapping from the input channel state to output beamforming that is
obtained by training the neural networks in an ofﬂine manner. The beamforming solution can
be directly predicted using the trained network in real time. The advantage of the learning
to optimize framework is to transfer the complex real-time optimization procedures to ofﬂine
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
training showing great potential to solve the beamforming design problems in multi-antenna
systems – . In , a DL model was proposed to predict the beamforming matrix with a
restricted codebook and a ﬁnite solution space which cause performance loss. In order to improve
the performance, the works in , directly predicted the beamforming matrix using the
trained network. However, the direct prediction method may cause high training complexity and
low learning accuracy of the neural networks since the number of variables to predict increases
signiﬁcantly as the number of transmit antennas and users increases. To overcome this drawback,
the authors in exploited the problem structure and proposed a model-based DL framework
to optimize the beamforming matrix. The proposed model-based framework includes two parts:
the DL part used to learn the optimal mapping from the channel to the uplink power allocation
as key features with much reduced dimension than the original beamforming matrix, and the
signal processing part used to recover beamforming from the predicted uplink power allocation.
By utilizing the speciﬁc problem structure, a DL enabled approach was proposed to optimize
beamforming of the SINR balancing problem under per-antenna power constraints . The
proposed DL algorithms in – are based on a common assumption that the training and
testing channel data are drawn from the same distribution in a ﬁxed stationary environment.
However, this assumption may be violated in real-world systems due to the dynamic nature of
wireless networks. As a result, existing DL based optimization algorithms may cause a task
mismatch issue when the network environment changes. A straightforward way is to re-train the
model from scratch using newly collected data for each new network environment. However,
this method results in huge overhead of data collection and training time. Hence, overcoming
the task mismatch issue in deep learning to optimize beamforming becomes a major challenge
in dynamic communications environments.
Transfer learning is a promising technique to deal with the task mismatch issue experienced
in the practical wireless communication systems due to its ability to transfer the useful prior
knowledge to a new scenario . The basic idea of transfer learning is to extract the key features
of the source domain and reﬁne the pre-trained model in the target domain. The efﬁciency of
the transfer learning technique on solving the task mismatch issue has been investigated in
the resource allocation of wireless communications , . Another efﬁcient way to deal
with the task mismatch issue is meta-learning, which aims to improve the learning ability by
leveraging the different but related training and testing data . Most existing meta-learning
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
algorithms are problem-speciﬁc. In order to eliminate the model architecture restriction on the
applications of meta-learning, the authors in proposed the model-agnostic meta-learning
(MAML) algorithm. The MAML algorithm aims to learn a parameter initialization of the
model for fast adaptation by alternating between inner-task procedure and cross-task procedure.
Speciﬁcally, the task-speciﬁc parameters are updated by performing the gradient descent on
the loss function of the corresponding task in the inner-task procedure, and the global network
parameter is updated by performing the gradient descent on the sum of the loss function of the
associated tasks in the cross-task procedure. Based on the advantages of the MAML algorithm
on solving mismatch issues, it has been used to deal with the channel estimation problems in
wireless communication systems – . For instance, MAML-based meta-learning algorithm
was proposed to solve the decoding problem over fading channels , to estimate the end-to-end
channel with insufﬁcient pilots , and to predict channel state information (CSI) of frequency
division duplexing systems . The simulation results in – indicate that meta-learning
is able to achieve better adaptation performance compared to the joint training method since the
joint training method uses the overall available data in the source domain and target domain to
train the model without the adaptation process.
Although transfer learning and meta learning techniques have been used to solve the channel
estimation and decoding problems – , they are still in the early stage for wireless communications applications. Different from channel estimation and decoding problems, beamforming
design is a well-known challenging problem and there is no known solution to the optimal
adaptive beamforming in a dynamic wireless environment. Hence, it is important to design
adaptive beamforming algorithms to solve the mismatch issue. In addition, directly applying
adaptive learning techniques to solve the high dimensional beamforming solution will cause
high training complexity and inaccurate results. In order to improve the accuracy and reduce the
complexity of neural network training, we choose the uplink power allocation vector as the low
dimensional feature to predict. To be speciﬁc, we propose the ofﬂine and online fast adaptive
algorithms using transfer learning and meta learning techniques to solve the mismatch issue of
beamforming design in dynamic wireless environments. Our main contributions are summarized
as follows:
• We propose an ofﬂine adaptive learning algorithm based on deep transfer learning (DTL)
by combining DL techniques and transfer learning to achieve the adaption to a new envi-
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
ronment. This algorithm ﬁrst trains a model in the source domain which includes channel
data different from those in the testing environment. It then reﬁnes the pre-trained model by
ﬁxing common feature layers and re-training the fully connected layer in the target domain
which includes few labelled data from the testing environment.
• We proposed an ofﬂine adaptive learning algorithm based on meta-learning by utilizing the
idea of MAML. This algorithm includes two parts: the meta-training part and the ﬁne-tuning
part. The meta-training aims to optimize the global parameter initialization via alternating
between the inner-task procedure and the cross-task procedure using data in the source
domain. The ﬁne-tuning part reﬁnes the initialized parameter using the global parameter
and limited data in the new environment. The advantages of the proposed meta-learning
include fast adaptation and near optimal performance.
• We propose an online adaptation algorithm to further improve the adaptation capability
of the ofﬂine meta-learning algorithm in the real-world non-stationary communications
scenarios where the environment constantly changes such that new labelled data only arrive
sequentially. This algorithm is designed based on meta-learning and the ‘follow the leader
(FTL)’ method. The FTL method is used to deal with the sequential data in real-time
systems and the meta-learning method is used for fast adaptation.
• Extensive simulations are carried out to evaluate the adaption capability of the proposed
algorithms in realistic communications scenarios using WINNER II and 3GPP channel
models. The results verify the adaption performance of the proposed ofﬂine algorithms and
indicate that the ofﬂine meta-learning algorithm can achieve near optimal performance by
avoiding the huge data collection and training time in new communications scenarios. In
addition, the proposed online algorithm can signiﬁcantly improve the adaption of the ofﬂine
meta-learning algorithm in non-stationary scenarios.
The remainder of this paper is organized as follows. Section II introduces the system model
and the beamforming neural network (BNN) learning framework. In section III, the ofﬂine
DTL algorithm and meta-learning algorithm are proposed. Section IV develops the online metalearning based adaptation algorithm. Simulation results and conclusions are presented in Section
V and Section VI, respectively.
Notions: The boldface lower case letters and capital letters are used to represent column
vectors and matrices, respectively. The notation aH and ∥a∥2 denote the Hermitian conjugate
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
transpose and the l2-norm of a vector a, respectively. The operator CN(0, Θ) represents a
complex Gaussian vector with zero-mean and covariance matrix Θ. IM denotes an identity
matrix of size M × M. Finally, ←denotes the assignment operation.
II. SYSTEM MODEL
A multi-input single-output (MISO) downlink transmission system is considered, in which K
single antenna users are served by a base station (BS) with M antennas. The received signal at
user k can be expressed as
k wksk + nk, ∀k
where hk ∈CM×1 denotes the channel coefﬁcient between the BS and user k, wk and sk ∼
CN(0, 1) denote the transmit beamforming and the information signal for user k, respectively,
and the additive Gaussian white noise (AWGN) is given by nk ∼CN(0, σ2
k). Consequently, the
signal-to-interference-plus-noise ratio (SINR) balancing problem can be formulated as:
wk,k=1,...,K
k wj|2 + σ2
where P is power budget. Many existing algorithms can be used to generate the optimal solution
of problem (2). Although the existing DL-based algorithms can solve the issue of outdated
beamforming caused by the conventional optimization algorithms, they will cause the task
mismatch issue when the network environment changes. Hence, we focus on the design of
fast adaptive learning algorithms to overcome the task mismatch issue in beamforming design
in dynamic network environments.
The DL-based BNN for uplink power prediction and beamforming recovery .
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
Directly predicting beamforming causes high training complexity and inaccurate results due
to the high dimensional beamforming matrix, so instead we predict the low dimensional uplink
power allocation vector. According to the uplink-downlink duality in and , using the
uplink power allocation vector to replace beamforming as the output of the neural network is
possible because the same SINR region of the uplink and downlink problems can be achieved.
Based on uplink-downlink duality and normalized beamforming wk = ˜wk√pk, the downlink
problem (2) can be converted into the following uplink problem
j̸=k qj|hH
j ˜wk|2 + σ2
s.t. ∥q∥1 ≤P, ∥˜wk∥2 = 1, ∀k,
where q = [q1, . . . , qK]T and qk is the uplink power allocation for user k, ˜wk and pk are
the normalized beamforming and downlink power allocation of user k, respectively. Sufﬁcient
labelled data can be generated by solving problem (3). The model-based BNN approach proposed
in is chosen for our algorithms design since it can efﬁciently extract features and can
recover the high dimensional beamforming matrix from the low dimensional feature vector. The
BNN framework shown in Fig. 1 includes two modules: the neural network module and the
beamforming recovery module. First, we introduce how to recover beamforming matrices by
using the recovery module. With the predicted uplink power allocation vector, the normalized
beamforming vector can be obtained as ˜wk =
k=1 qkhkhH
k=1 qkhkhH
k )−1hk∥2, ∀k. Then, the optimal
downlink power allocation vector p = [p1, . . . , pK]T can be obtained by ﬁnding the ﬁrst K
components of the eigenvector of the following matrix
where 1 = [1, 1, . . . , 1]T, D = diag{1/| ˜wH
1 h1|2, . . . , 1/| ˜wH
KhK|2}, σ = [σ2
2, . . . , σ2
[U]kk′ = | ˜wH
k′hk|2, if k
′ = k, otherwise [U]kk′ = 0. Finally, the downlink beamforming matrix
W = [w1, . . . , wk] is derived as W = ˜
P, where ˜
W = [ ˜w1, . . . , ˜wK] and P = diag(p).
Second, we brieﬂy describe the neural network framework used in the paper according to
the neural network module of BNN. The convolutional neural network (CNN) architecture is
chosen as the base of the learning framework in this paper due to its ability of extracting
features and reducing learned parameters. Speciﬁcally, the CNN framework includes the input
layer, convolutional layer (CL), batch normalization (BN) layer, activation (AC) layer, and fully
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
connected layer (FC). Channel realization is split into two real value inputs. One is the in-phase
component R(h) of channel realization and the other one is the quadrature component I(h) of
channel realization.
As a regression problem is considered in this paper, we use supervised learning and the
standard mean squared error (MSE) as the loss function to calculate the loss of the neural
network. The loss function is deﬁned as follows:
LossD(θ) = 1
∥ˆq(i)(θ) −q(i)∥2
where D = {(h(i), q(i))}N
i=1 is the training dataset, q(i) and ˆq(i)(θ) denote the optimal uplink
power allocation vector generated by solving (3) and the predicted uplink power allocation vector
of the neural network for the i-th sample in each batch, respectively, θ is the network parameter
and N is the batch size. In the following sections, we will design our fast adaptive learning
algorithms.
III. OFFLINE LEARNING ALGORITHMS
In this section, we design two ofﬂine adaptive learning methods to optimize beamforming:
1) DTL algorithm and 2) meta-learning algorithm. These two algorithms aim to achieve fast
adaptation in the new test wireless environment with limited channel data whose distribution is
different from that in the training environment. In the following subsections, we describe the
details of these two algorithms.
A. Joint Training
In this subsection, we introduce the joint training method, which is considered as a benchmark
for evaluating the adaptation ability of the proposed ofﬂine algorithms. The joint training method
aims to learn a single model on a joint dataset. Hence, the objective of the joint training method
can be expressed by the following optimization problem
ϕ = arg min
ϕ LossDjoint(ϕ),
where Djoint denotes the joint training dataset, which is generated by merging the training data
and adaptation data, and ϕ is the parameter vector of the single model. The parameter vector ϕ
can be iteratively updated based on the following gradient-based learning rule
ϕ ←ϕ −α∇ϕLossDjoint(ϕ),
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
where α is the learning rate.
B. Deep Transfer Learning
Transfer learning has been recognized as an efﬁcient method for model prediction as it not
only reduces the dependence on a large amount of labelled data but also avoids training the
model from scratch. Different transfer learning methods and corresponding applications have
been introduced in . Since the same SINR balancing optimization problem are used to
guide beamforming design over different wireless environments, it indicates that some common
features inherent in the optimization problem can be extracted and transferred. Therefore, a DTL
algorithm via ﬁne-tuning, which combines the DL and transfer learning techniques, is proposed
to generalize the beamforming prediction in different channel distributions.
1) Deﬁnition of Datasets: The fundamental idea of transfer learning is to train the neural
network in a given source domain and then adapt the model to a target domain. To apply DTL,
we ﬁrst deﬁne datasets for the network model. We use the algorithm in [3, Table 1] to generate
NTr sample pairs for each user to compose the training dataset DTr(·), which will be used to
create the pre-trained model. Then, we use the same process to generate the adaptation dataset
DAd(·) with NAd sample pairs using the test channel fading distribution different from that used
in generating DTr(·). We assume that any sample pair in the testing dataset DTe(·) does not
appear in the adaptation dataset DTe(·).
2) Transfer Learning: The proposed DTL includes two stages: 1) building the pre-trained
neural network model in the source domain 2) reﬁning the pre-trained model in the target domain.
In the ﬁrst stage, we minimize the loss function LossDTr(θ) on the training dataset {DTr(k)}NT r
which includes sufﬁcient sample pairs, to optimize the network model. The network parameter
can be updated by using the following equation
θ ←θ −α∇θLossDTr(θ),
where α is the network learning rate, ∇θLossDTr(θ) is the gradient of the loss function over
θ. Alternatively, the network parameter θ also can be updated by using the existing adaptive
moment estimation (ADAM) algorithm .
Next, we move to the ﬁne-tuning stage when the pre-training stage is ﬁnished. Fine-tuning
aims to reﬁne all or partial parameters of the pre-trained neural network on the target task. To fast
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
Algorithm 1: The proposed ofﬂine adaptation algorithm based on DTL.
Input: Learning rate α and β, batch size Nb, training dataset {DTr(k)}NT r
k=1 , adaptation dataset {DAd(k)}NAd
Output: Learned network parameter θ
Pre −training
1) Randomly initialize the network parameter θ
2) Initialize the step: t = 0
3) while not done do
Randomly select Nb sample pairs form {DTr(k)}NT r
k=1 to compose a batch task
Update the network parameter by θt ←θt−1 −α∇θt−1LossDTr(θt−1) or by ADAM optimizer
7) end while
Fine −tuning
1) Initialize ˜θ ←θ
2) for j = 1, . . . , GAd do
Update the parameter of the FC layer in ˜θ by using ADAM
adapt to the new environment, there are only limited labelled data of the target task available.
In , it is reported that given a small dataset overﬁtting may happen if all parameters are
re-trained, hence we only re-train partial parameters by freezing the remaining parameters to
implement the ﬁne-tuning. To be speciﬁc, we assume the number of neural network layers is L
and divide the pre-trained model into two parts. We set the ﬁrst L −1 layers as the extractor,
which is used to extract features of the problem and the last FC layer as the learner which is used
to reﬁne the network in the target domain. We assume that the extractor part is non-trainable and
only the learner part is trainable when the network is trained using the adaption dataset. Then, the
parameter of FC layer of the pre-trained network can be updated by using either (8) or ADAM
on the adaption dataset DAd(·). After ﬁnishing the training and ﬁne-tuning steps, we obtain the
adapted network model which can be used to predict the uplink power allocation coefﬁcient on
DTe(·). The proposed DTL algorithm is summarized in Algorithm 1 which includes pre-training
and ﬁne-tuning stages.
C. Meta Learning Algorithm
Different from transfer learning, meta learning aims to learn the best learning strategy, which
is used to acquire an inductive bias for the entire class of tasks of interest for fast adaptation
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
 . We will design an ofﬂine meta learning algorithm to achieve faster and better adaptation
than DTL in dynamic environments based on the MAML algorithm proposed in .
1) Deﬁnition of Task: Since the goal of the MAML algorithm is to train an efﬁcient parameter
initialization based on the multiple tasks, we deﬁne and form tasks before using MAML to
design our algorithm. In our algorithm, a task is deﬁned as a prediction process of uplink power
allocation from channel realizations in a chosen dataset. Each such dataset is composed of
training data and validation data for a particular task. We deﬁne a task set {Tmt(k)}Kmt
k=1 , which
includes Kmt tasks. Each task in the task set is formed by randomly selecting training data and
validation data from the meta training dataset DTr(·).
2) Deﬁnition of Dataset: Channel realizations and the associated optimal uplink power allocation vectors are involved in both training data and validation data of each task. The set of
training data is deﬁned as the support set Dmts(·) and the set of validation data is deﬁned as the
query set Dmtq(·). The support set and query set include Ns and Nq labelled data, respectively.
We deﬁne the set used for adaption as the adaption dataset DAp(·), which includes NAd sample
pairs. Note that the distribution of channel realizations in DAp(·) is different from the distribution
in DTr(·).
The workﬂow of the meta learning.
3) Meta-training Stage: The MAML algorithm uses two iterative processes, inner-task update
and cross-task update, to generate the parameter initialization with the good generalization ability.
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
Inner-task update is used to optimize the neural network parameter of each task, and cross-task
update is used to optimize the global neural network based on the sum of the loss functions of all
tasks. In order to efﬁciently solve the mismatch issue of beamforming design, these two iterative
processes are adopted to design our meta learning based adaptive beamforming algorithm. In Fig.
2, the workﬂow of two iterative training processes is provided to explain the training process of
our meta algorithm. In the following, we use a batch of tasks (include Nb tasks) as an example to
introduce the two processes in Fig. 2. The same neural network architecture is used in inner-task
update and cross-task update.
Inner-task update is a process of training the neural network parameters of each task in the
related batch. The goal of each task is to optimize its own neural network parameter on its support
set via the global network parameter. The objective of each task is achieved by minimizing the
loss function based on supervised learning. Although the objective function of each task is the
same, the dataset used to achieve the goal of each task is different. The objective function of
each task can be expressed as
φk = arg min
φk LossDmts(k)(φk),
k = 1, . . . , Nb,
where φk is the neural network parameter of task k and it is initialized by the global network
parameter θ, Dmts(k) is the support set of task k. Since the loss function LossDmts(k) in (9)
is represented by the MSE between the predicted value and the true value shown in (5), such
loss function is differentiable. Hence, the gradient descent technique can be used to solve the
optimization problem in (9). Multiple gradient updates are considered to update the parameter
of each task rather than one gradient update originally proposed in . Notice that the neural
network parameter of each task is independently updated. As we can see from Fig. 2, the updating
process of the neural network parameter for each task on its support set is parallel. Since the
objective function of each task is the same and the updating processes of the parameters for
all tasks are parallel, we use task k as an example to explain the updating process of its own
neural network parameter on the related support set Dmts(k). The neural network parameter of
all tasks is initialized by the global parameter θ. By using the gradient descent technique, the
neural network parameter φk of task k can be estimated by
= θ −β∇θLossDmts(k)(θ),
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
where β is the learning rate of the inner-task update, the superscript 0 of φk denotes the ﬁrst
iteration of gradient update. When the number of iterative steps is greater than one, the parameter
φk of task k is updated by calculating the gradient of the loss function over its own parameter
obtained at the previous iterative step, where is given by
k = φ(i−1)
LossDmts(k)(φ(i−1)
where the superscript i of φk is the index of the iteration step and i = 1, . . . , Gin, Gin is the
number of inner iterative steps. The ‘compute gradient’ function in Fig. 2 is used to compute the
gradient of the loss function in (10) and (11). The repeated updating processes are represented
by φk, k = 1, . . . , Nb, which is fed back to ‘compute gradient’ in Fig. 2. The neural network
parameter of task k can be updated as φk = φGin
when the number of iterations arrives at the ﬁnal
step Gin. Notice that the loss function LossDmts(k)(φk), ∀k of each task is unknown and needs to
be estimated on its support set Dmts(k) at each iterative step. When all tasks in the batch ﬁnish
their iterations, the loss function can be considered as a metric to evaluate the trained parameter
of each task on the related query set Dmtq(·). These loss functions can be used to optimize the
global network parameter θ in cross-task update, which is described in the following part.
Cross-task update is a process of optimizing the global network parameter θ based on the sum
of the loss functions of all tasks in the batch. As mentioned in the inner-task update process, the
loss functions of all tasks in the batch can be estimated based on the neural network parameter
of the related tasks and their query sets when the maximum iteration step is achieved. Such loss
functions can be added together to form the loss function used to optimize the global network
parameter θ. This process is implemented by the sum function in Fig. 2. The objective function
of optimizing the global network parameter θ on a batch of tasks can be expressed as
θ = arg min
LossDmtq(k)(φk),
where Dmtq(k) is the query set of task k. Similar to inner-task update, the gradient descent
technique can be used to update θ in (12), which is given by
LossDmtq(k)(φk),
where α is the learning rate of cross-task update. Notice that there exists the chain rule when
calculating the gradient of the loss function of each task in (13) since the neural network
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
parameter of each task is updated at each iteration based on the updated parameter of this task
at the previous iteration. Hence, the update of the neural network parameter in each iterative
step needs to compute the gradient with respect to the parameter of the previous iterative step
when computing the gradient of the loss function with respect to θ, which can be expressed as
∂LossDmtq(k)(φk)
∂LossDmtq(k)(φGin
) · . . . ·
∂θ . It indicates that the MAML
algorithm needs an additional backward pass since it involves a gradient through a gradient
process. As shown in Fig. 2, the updated global network parameter θ is considered as the
initialized parameter of the tasks in the next batch and will be continuously updated. The
algorithm will move to the next training step when the global network parameter in all batches
completes the updating process by alternating inner-task update and across-task update in Fig.
2. An efﬁcient parameter initialization θ will be obtained when the training is completed.
Different from the joint training method, which optimizes the neural network parameter based
on the loss function of the single model shown in (7), the proposed meta learning algorithm
optimizes the model parameter via the loss functions of multiple tasks on their own model
shown in (13). Using multiple models will improve the generalization ability. Compared to the
joint training method, the proposed MAML-based learning algorithm can generate the parameter
initialization, which has better generalization ability and can help any task from the same
distribution to achieve their optimal parameter more efﬁciently.
4) Meta-adaption Stage: Based on the initial global network parameter θ obtained from the
above meta-training stage, the network parameter will be updated using the adaptation dataset
DAp(·) to achieve fast adaptation to the new task. We set the number of adaptation steps as GAd.
Before implementing the adaptation, we initialize the adaptation parameter φAp as θ, which is
obtained through the meta training stage. In the jth adaptation step, the network parameter φAp
can be updated as
Ap −β∇φ(j)
ApLossDAp(φ(j)
The iteration will ﬁnish when the stoping criterion is achieved. Full details for implementing
meta-learning and meta-adaptation are summarized in Algorithm 2.
Comparison of transfer learning and meta leaning: Transfer learning and meta learning both
have the training and adaption stages. Although they have the same objective of achieving fast
adaption, the strategies used in the training and adaption stages are different. Hence, transfer
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
Algorithm 2: The proposed ofﬂine adaptation algorithm based on meta-learning.
Input: Learning rate α and β, batch size Nb, meta-training task set {Tmt(k)}Kmt
k=1 , support set Dmts(k)Kmt
k=1 with Ns labelled
data, query set Dmtq(k)Kmt
k=1 with Nq labelled data, the number of inner-task update steps Gin, adaptation dataset DAp,
and the number of adaptation steps GAp
Output: Learned initial network parameter θ
Meta −training
1) Randomly initialize the network parameter θ
2) while not done do
Randomly sample batch of task Tk from {Tmt(k)}Kmt
for Tk, k = 1, . . . , Nb do
Randomly sample support set Dmts(k) with Ns sample pair and query set Dmtq(k) with Nq sample pair from Tk
for i = 1, . . . , Gin do
Evaluate the gradient of the loss function of task k on Dmts(k)
Update the task parameter based on (10) and (11)
Update the global network parameter θ by (13) or by using ADAM optimizer
12) end while
Meta −adaptation
1) Initialize φAp ←θ
2) for j = 1, . . . , GAd do
Update all parameters in φAp by using ADAM
learning is not a special case of meta learning. Meta learning uses two iterative procedures to
train the model, which means that it needs two backward passes in the training stage. However,
transfer learning uses one backward pass to train the model in the training stage. In the adaption
stage, meta learning re-trains all parameters on the new task whereas transfer learning only
re-trains the parameter of the last layer while retaining the rest parameters.
IV. ONLINE META-LEARNING ALGORITHM
Although the proposed ofﬂine learning algorithms offer effective strategies to achieve fast
adaptation to a new task, the design of the adaptation stage is based on the assumption that the
dataset used for adaptation is available in advance and comes from a stationary distribution. Under
this assumption, the ofﬂine adaptation algorithms may not perform well in real-world wireless
communication applications, such as vehicular communications in which the communications
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
environment may keep changing. This is because of two reasons: 1) the channel is likely to
become available sequentially since channel estimation methods normally need time to ﬁrst obtain
the channel statistics and then estimate the channel; 2) the channel may follow a non-stationary
distribution as the environment continues to change. In order to enhance the adaptation capability
of the proposed ofﬂine meta-learning algorithm in real-world applications, we propose an online
adaptation algorithm in this section based on the online meta-learning framework introduced in
A. Online learning
Online learning is a learning paradigm which uses the idea of continual learning on a nonstationary distribution of tasks over time . The learner aims to sequentially learn the model
parameter θt over all time slots. In order to measure the learning ability of a learner, the notion
of regret is introduced, which is deﬁned as difference between the cumulative loss of the learner
t=1 LossDt(θt) and the cumulative loss of best single model PT
t=1 LossDt(θ). The parameter θt
is determined by the online learner, while and the parameter θ is obtained by training the model
based on the hindsight data . The aim of online learning is to design an algorithm which
can make the corresponding regret grow as slowly as possible.
FTL is a standard online learning algorithm which aims to update the parameter θt at
slot t based on the sum of the loss functions of the previous data Dt−1. It can be expressed as
θt = arg min
LossDk(θ).
B. Online Meta-learning
FTL may not learn an effective online model because it trains a single model on a single dataset
from all prior time slots. In order to learn effective models to adapt to the non-stationary scenario,
we consider to incorporate the meta-learning technique into FTL to design the online adaptation
algorithm. Note that we cannot directly apply the ofﬂine meta-training learning introduced in
section III-B to design the online algorithm for the following reason. In the ofﬂine scenario, the
data used for adaptation are available in advance and come from a stationary distribution, which
means all data in the adaptation set can be used to adapt the learning model. In the online scenario,
however, the data used for adaptation arrive sequentially and may come from a non-stationary
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
distribution, which means we cannot use the whole data in the adaptive set to implement the
adaptation like the ofﬂine scenario. We need to use the cumulative data to implement adaptation
in an online manner. Based on the aforementioned difference, in the following we will provide
details for the design of our online meta adaptive algorithm.
Similar to the ofﬂine meta learning algorithm in section III-C, the proposed online meta
algorithm involves two processes of calculating the gradient in the meta training phase. The
ﬁrst gradient is used to update the task-speciﬁc parameter based on the network parameter. The
second gradient is used to update the network parameter based on the updated task-speciﬁc
parameters. To implement online learning, we assume that data received at each time slot is a
task for adaptation in subsequent time slots, and each task includes N input/output pairs for
each user. We use Tt to denote the task of the time slot t. Then, we deﬁne an empty task set Bt
to store the data of the task Tt at the time slot t. Notice that there is no training process at the
beginning t = 0. In the following, we use time slot t > 1 as the example to describe the online
learning process of the proposed algorithm. At the beginning of the time slot t, the algorithm
uses the task set Bt to store the sample pairs of Tt as the data of the task Tt arrives. The algorithm
samples a minibatch of tasks with size Ntask from previous task sets {Bk, k = 0, . . . , t−1}. For
each task in the minibatch, we sample its training set Dtr
k with Ntr sample pairs and validation
with Nval sample pairs from the corresponding task set Bk, k = 0, . . . , t −1. In the
following, we will describe two iterative processes, one is the process to update the task-speciﬁc
parameter and the other one is to update the network parameter at the time slot t. First, we use
task Tk as an example to describe the updating process of the task-speciﬁc parameter. Based on
the training set Dtr
k , the task-speciﬁc parameter φk for task Tk can be updated by the stochastic
gradient descent method as follows:
φk ←θt −β∇θtLossDtr
where β is the learning rate, Loss is the MSE loss function provided in (5). θt is the network
parameter at the time slot t, which is used to initialize the task-speciﬁc parameter φk of the task
k at the beginning of the updating process. The equation in (16) is used for the ﬁrst gradient
descent update on the task parameter φk. If multiple gradient descent updates are used, the
updating equation after the ﬁrst update is given by
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
where superscript j of φk is the index of the iterative step and j = 2, . . . , Nin. Second, we move
to estimate the network parameter once the updating process of the task-speciﬁc parameter for
each task in the minibatch is ﬁnished. Note that the same task may appear several times in a
minibatch. Hence, we use index Zk ∈[0, Ntask] to record the number of appearance times of
task Tk in the corresponding minibatch. Based on the updated task-speciﬁc parameter φNin
each task in the minibatch, the shared network parameter θt at the time slot t can be updated
using the validation set of the corresponding tasks as follows:
θt ←θt −α∇θ
ZkLossDval
where α is the learning rate. Once the iterative procedure of updating the network parameter θt
of time slot t is ﬁnished, we adapt the trained model using the current received the data in Bt.
The process is repeated in the next time slot t + 1. Full details of the online meta adaptation are
summarized in Algorithm 3. We use the network parameter obtained from ofﬂine meta learning
as the initialized network parameter for the learning algorithm.
V. SIMULATION RESULTS
In this section, numerical simulations are carried out to evaluate the advantages of the proposed
adaptive beamforming optimization algorithms for different wireless communications scenarios.
A MISO downlink system with one BS and multiple users is considered. The main simulation
parameters are set as follows: carrier frequency is 2.9 GHz, bandwidth is 20 MHz, noise power
spectral density is -174 dBm/Hz, the learning rates are α = 0.001, β = 0.01, the iterative steps
are Gin = Gad = Nin = Nad = 20, and the batch size is Nb = 20. Other speciﬁc parameters
including the number of antennas at the BS M, the number of users K and the transmit power
P are provided in each ﬁgure. All input data and corresponding labels are generated by using
MATLAB. Tensorﬂow 2.0.0 and Keras 2.3.1 are used to implement the proposed DTL algorithm.
PyTorch 1.4.0 is used to implement the proposed meta-learning algorithms. All simulation results
are generated by using a computer with Intel i7-7700HQ CPU and 8 GB RAM.
In our simulation, we assume that the BS can obtain perfect CSI based on channel estimation
or feedback. Each sample pair in all datasets is composed of channel realization and the uplink
power allocation vector. For each channel realization, we can generate its associated uplink power
allocation vector by solving the uplink problem (3). Channel realizations of the testing dataset
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
Algorithm 3: The proposed online meta-learning algorithm.
Input: Learning rate α and β, ofﬂine trained network parameter θmeta, empty task sets Bt, ∀t, the number of inner update
steps Nin, the number of adaptation steps Nad, the number of minibatch size Ntask, the received sample pairs N, the
sample pairs of training set and validation set Ntr and Nval
Output: Learned network parameter θt for each slot t
1) initialize the network parameter θ1 ←θmeta
2) for t = 0, . . . do
B0 ←{h0, q0} of task T0
Bt ←{ht, qt} of task Tt
while not done do
random sample a minibatch of tasks and the corresponding set Dtr
k and Dval
from Bk, k = 0, . . . , t −1,
for all sampled task do
for j = 1, . . . , Nin do
update the parameter of each task by (16) and (17)
update the shared network parameter θt by using (18)
−−−−−−−−−−−−−−−−−−−−Adaptation −−−−−−−−−−−−−−−−−−−
initialize θad ←θt
for n = 1, . . . , Nad do
update θad on current task set Bt: θad ←θadβ∇θadLossBt(θad)
23) end for
and the adaption dataset come from the same distribution. The distribution of channel realizations
in the testing dataset is different from that of the training dataset. The channel realizations in
training dataset used for transfer learning and meta-learning algorithms are generated by using
three small-scale fading channel models: Rayleigh model with distribution CN(0, IM), Rician
model with rician factor 3, and Nakagami model with fading parameter 5 and the average power
gain 2. We generate 5000 channel samples for each of the three small fading models. Hence,
the training dataset includes 15000 sample pairs. For meta-learning algorithm, we randomly
sample labelled data from 15000 sample pairs to construct 1500 tasks, Kmt = 1500. Each task
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
includes Ns = 50 training sample pairs and Nq = 50 validation sample pairs. In addition, 5000
testing sample pairs are generated for each testing channel model, which uses different channel
distribution from the training data. The DL network shown in Fig. 1 includes eleven layers, one
input layer, two CL layers, two BN layers, three AC layers, one ﬂatten layer, one FC layer, and
one output layer. The input size of the input layer is 2 × MK. For the two CL layers, each CL
layer applies 8 kernels of size 3 × 3, one stride, and one padding. The input size of the ﬁrst CL
layer equals to the size of the input data. The input size of the second CL layer and the output
size of both CL layers equal to 2×MK ×8. Besides, ReLU and Sigmoid functions are adopted
at the ﬁrst two activation layers and the last activation layer, respectively. Adam optimizer is
adopted . The exponential decay rates for the ﬁrst moment estimates and the second moment
estimates are set to 0.9 and 0.999, respectively. The epsilon of Adam is set to 10−8.
We consider the following four typical fading scenarios for testing the adaptation capability
of the proposed learning algorithms:
• Large-scale fading case: this model is a typically fading model used in communications
• WINNER II indoor case: the WINNER II indoor ofﬁce scenario speciﬁed in .
• WINNER II outdoor case: a typical WINNER II urban scenario speciﬁed in .
• Vehicular case: we adopt an urban vehicle-to-infrastructure (V2I) scenario deﬁned in Annex
A of 3GPP TR 36.885 .
For comparison, we introduce other three benchmarks, namely, the optimal solution, the BNN
solution, and the joint learning solution. The deﬁnitions of all solutions for comparison are listed
• The optimal solution: this solution shows the optimal result of the problem in (2) obtained
by using the iterative algorithm proposed in . It serves as a performance upper bound
for all other schemes.
• The BNN solution: this solution shows the predicted result, which is obtained based
on the assumption that wireless channels in the training dataset follow the same fading
distribution as those in the testing dataset. It provides a performance upper bound for our
proposed adaptive algorithms.
• The transfer learning solution: this solution shows the adaptation result of the proposed
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
DTL algorithm in Section III-A.
• The meta-learning solution: this solution shows the fast adaptation result of the proposed
meta-learning algorithm in Section III-B.
• The joint training solution: this solution shows the result obtained by training the neural
network using all available data without adaptation.
For fair comparison, we set the same convergence criteria for the iterative procedures of all
schemes. In addition, we set the same size of training set of ﬁne-tuning for transfer learning and
meta-learning algorithms. The results and analysis are provided for each case below.
A. Large-scale fading case
The number of fine-tuning samples
Meta learning
Transfer learning
The comparison of ﬁne-tuning samples for meta and transfer learning when M = 8, K = 8.
In this case, the pathloss model is given by PL = 128.1 + 37.6 log10(d [km]), where d is the
distance between a user and BS. The shadow fading follows the log-normal distribution with
zero mean and 8 dB standard deviation. The Rayleigh fading channel with zero mean and unit
variance is adopted as the small-scale fading for this case. All users are randomly distributed
within a disc with a radius of 500 m. In order to choose the proper size of ﬁne-tuning samples
for the proposed two adaptation algorithms, we ﬁrst investigate the effect of the number of
ﬁne-tuning samples used in the transfer learning and the meta-learning algorithms in Fig. 3.
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
Transmit power (dBm)
Optimal solution
Meta learning
Transfer leanring
Joint training
The number of users
Optimal solution
Meta learning
Transfer leanring
Joint training
The SINR performance comparison on large-scale case for different metrics: (a) transmit power when M = 4, K = 4
and (b) the number of users when M = 8, P = 25 dBm.
As the ﬁgure shows, the SINR increases when the number of ﬁne-tuning samples increases for
both algorithms under different transmit power settings. The SINR generated by the proposed
meta-learning algorithm almost converges by using only 20 ﬁne-tuning samples. However, there
is still an obviously gap (almost 1 dB for 25 dBm and 0.5 dB for 20 dBm of transmit power)
between the meta-learning and transfer learning algorithms when the number of ﬁne-tuning
samples increases to 100. By considering the adaptation overhead and the SINR performance,
we choose 20 samples for ﬁne-tuning of the transfer-learning and the meta-learning algorithms
in all testing channel models.
Based on the 20 ﬁne-tuning samples, we demonstrate the adaptation capability of the proposed
algorithms via the SINR performance using two different metrics in Fig. 4. Fig. 4(a) shows the
effects of the transmit power on the SINR performance. As can be seen, the SINR increases as
the transmit power increases for all schemes. The SINR result generated by the proposed metalearning algorithm is very close to that of the BNN scheme which validates its effectiveness.
It is observed that the performance gap between the transfer learning and the meta-learning is
signiﬁcantly enlarged as the transmit power increases. The joint training scheme without adaptation achieves the worst SINR compared to other schemes. In Fig. 4(b), the SINR performance
becomes worse as the number of users increases. The proposed meta-learning algorithm still
produces better result which is close to the BNN scheme, compared to the transfer learning
and the joint training scheme. It is interesting that there is an obviously reduction of the SINR
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
Transmit power (dBm)
Optimal solution
Meta learning
Transfer leanring
Joint training
The number of walls
Optimal solution
Meta learning
Transfer leanring
Joint training
The SINR performance comparison in the WINNER II indoor case when M = 4, K = 4: (a) transmit power when
nw = 2 and (b) the number of walls when P = 25 dBm.
performance gap between the meta-learning algorithm and the transfer learning algorithm when
the number of users is greater than 6. This is because more channel features can be extracted
and transferred by using the transfer learning algorithm as more users are involved. Overall,
the results plotted in Fig. 4 demonstrates that the proposed meta-learning algorithm provides an
efﬁcient beamforming adaptation solution.
B. WINNER II indoor case
In the WINNER II indoor case, we assume that the access point (AP) and users are located on
the same ﬂoor. Users are randomly located between 10 m to 100 m away from the AP. We adopt
the corridor-to-room scenario, in which only non line-of-sight (NLOS) path is considered due to
the blocked light-of-sight (LOS) path. The pathloss is given by PL = 43.8+36.8 log10(d [m])+
20 log10(fc/5) + 5(nw −1), where fc is carrier frequency and nw is the number of walls. The
standard deviation of shadow fading is 4 dB. The adaptation capability of the proposed learning
algorithms in the WINNER indoor case is investigated in Fig. 5 based on two factors: the transmit
power at the AP and the number of walls. Fig. 5(a) shows that the adaptation capability of the
proposed meta-learning algorithm in the indoor fading case is similar to that demonstrated in
the large-scale case. Different from the results shown in Fig. 4(a), the SINR performance of
the transfer learning algorithm is close to that of the meta-learning algorithm when the transmit
power is smaller than 15 dBm in Fig. 5(a). This fact may indicate that the system needs to spend
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
Transmit power (dBm)
Optimal solution
Meta learning
Transfer leanring
Joint training
The number of users
Optimal solution
Meta learning
Transfer leanring
Joint training
The SINR performance comparison in the WINNER II outdoor case: (a) transmit power when M = 4, K = 4 and (b)
the number of users when M = 8, P = 25 dBm.
more power on overcoming the fading caused by the walls. Hence, the effects of the number
of walls on the adaptation capability for the proposed algorithms are provided in Fig. 5(b). As
can be seen from Fig. 5(b), the SINR performance decreases for all schemes when the number
of walls between the user and AP increases. In addition, the performance gap between the meta
learning and the transfer learning algorithm rapidly reduces as the number of walls increases.
C. WINNER II outdoor case
In the WINNER II outdoor case, we assume that the BS is located in the cell center and covers
a disc with a radius of 1000 m. Users are randomly distributed between 100 m to 1000 m away
from the BS. The pathloss and shadowing of LOS in WINNER B1 are adopted to generate the
large-scale fading for this case. Fig. 6 demonstrates the adaptation capability of the proposed
learning algorithms in the WINNER II outdoor case through the SINR performance. As can be
seen from Fig. 6, the proposed meta-learning algorithm achieves the highest SINR performance
compared to the proposed transfer learning algorithm and the joint training algorithm as the
transmit power and the number of users change. Compare with the SINR performance in Fig.
4(a) and Fig. 5(a), the performance gap between the proposed transfer learning algorithm and
the joint training algorithm is signiﬁcantly increased when the transmit power is greater than 15
dBm in Fig. 6(a).
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
D. Vehicular case
Manhattan road grid 750 m × 1299 m .
In the vehicular case, we use the Manhattan grid layout with the region size of 750 m×1299 m
to set up a realistic V2I communication scenario as shown in Fig. 7. The size of each grid is
250 m × 433 m. There are two lanes in each direction for vehicles with 3.5 m lane width. The
BS is located in the center of the layout. The vehicles are uniformly placed on each direction of
the road. The probability of each vehicle to change its direction at the intersection is set to be
0.4. Each vehicle will change its direction when it arrives at the edge of the layout. We assume
that the velocity of each vehicle is 60 km/h. The pathloss and shadowing adopted in this case
are the same to those in the large-scale case. Besides, the antenna gains of the BS and each
vehicle user are set to be 8 dBi and 3 dBi, respectively. The decorrelation distance is set to 50
m. We use Clarke’s model introduced in to generate the small-scale fading of the moving
The effects of the transmit power and the number of vehicles on the SINR performance
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
Transmit power (dBm)
Optimal solution
Meta learning
Transfer leanring
Joint training
The number of vehicles
Optimal solution
Meta learning
Transfer leanring
Joint training
The number of vehicles
Execution time per channel (s)
Proposed NN
Optimal solution
The performance and complexity comparison of the proposed algorithms in the vehicular case: (a) SINR versus transmit
power when M = 4, K = 4, (b) SINR versus the number of vehicles when M = 8, P = 25 dBm and (c) execution time per
channel versus the number of vehicles when M = 8, P = 25 dBm.
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
are presented in Fig. 8(a) and Fig. 8(b), respectively. For both factors, the SINR performance
of the proposed meta-leaning algorithm is close to that of the BNN scheme. Fig. 8(a) shows
that the proposed meta-learning and transfer learning algorithms signiﬁcantly outperform the
joint training scheme when the transmit power is greater than 14 dBm. There exists an obvious
performance gap between the two learning algorithms when the transmit power is greater than
25 dBm. Fig. 8(b) shows that the meta-learning algorithm signiﬁcantly outperforms the transfer
learning algorithm and the joint training method. The SINR performance gap between the transfer
learning algorithm and joint training method becomes large as the number of vehicles increases.
Similar to the above three fading cases, the proposed meta-learning algorithm provides superior
performance thanks to its fast adaptation even in the moving scenario. Fig. 8(c) shows the
comparison of the execution time between the proposed algorithms (same for the transfer learning
and the meta-learning algorithms) and the optimal solution. From the ﬁgure, we can see that
the proposed learning algorithms requires much less time compared to the optimal solution.
This is because no iterative process is used in the proposed learning algorithms to predict the
beamforming solution.
In addition, we compare the ﬁne-tuning execution time of the meta-learning algorithm and
transfer learning algorithm in Table I. The results are obtained by using 20 ﬁne-tuning samples
and 20 iterative steps. In order to make the fair comparison between the proposed two algorithms,
the adaption of the transfer learning algorithm is also implemented by using PyTorch. From Table
I, we can see that the execution time of the transfer learning algorithm to achieve adaption is
less than that of the meta learning algorithm and this is because only part of the neural network
needs to be re-trained in transfer learning.
COMPARISON OF FINE-TUNING EXECUTION TIME BETWEEN META LEARNING AND TRANSFER LEARNING.
Meta-learning (ms)
Transfer learning (ms)
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
90 100 110 120 130 140 150
Index of time slots (t)
Average SINR (dB)
Online meta adaptation
Online joint adaptation
Offline upper bound
Offline meta adaptation
Performance comparison between online and ofﬂine adaptation algorithm M = 4, K = 4, P = 25 dBm
E. Online learning
In this case, we evaluate the performance of the proposed online meta-learning algorithm in
real-world non-stationary scenarios. We consider mobile users travelling from outdoor to urban
and then highway environments in the simulation to investigate the adaptation capability of the
proposed online algorithm in the changing environments. The WINNER II outdoor and vehicular
case are used to generate channel data for the outdoor and urban scenarios, respectively. The
freeway case introduced in 3GPP TR 36.885 is used to generate channel data for the
highway scenario. The number of lanes in each direction and the velocity of each vehicle are
set as 3 and 120 km/h, respectively. The antenna gains of the BS and vehicle in the urban and
highway scenario are set as 8 dBi and 3 dBi, respectively. We set the minibatch Ntask = 20,
the same sample pairs for training set and validation set Ntr = Nval = 4. The results of
the online joint adaptation algorithm is obtained by using the FTL method. Fig. 9 shows the
adaptation performance comparison between the proposed ofﬂine and online learning algorithm
over the whole communications period as the users move across different environments. Each
simulation point in the ﬁgure is obtained by averaging all of the actual experimental points
at the individual time slots over the previous time slots in the corresponding communications
scenario. To implement simulation, we assume that ﬁve adaptation channels N = 5 and ten
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
testing channels of each user are received at each time slot. Each communications scenario lasts
50 time slots. For the ofﬂine meta adaptation case, the neural network model will be updated
periodically at every 60 time slots based on the collected channel information during that period.
For the ofﬂine upper bound case, we assume that the system knows the exact environment for all
communications scenarios in advance and also knows when to update the model, so it provides
a performance upper bound. The online joint adaptation uses all data until slots t −1 to train
the model and then use the data at slot t to ﬁne tune the model. As we can see from the
ﬁgure, there is an obvious drop on the average SINR for all cases when the communications
scenario changes, which indicates that the changing communications scenario can signiﬁcantly
affect the system performance. There exists an obvious gap between the online algorithm and the
ofﬂine upper bound, and the performance gap is obviously enlarged when the communication
scenario changes from outdoor to urban, whereas the performance gap is slightly increased
when the scenario changes from urban to highway. The reason is that urban and highway are
both scenarios with high mobility and they share more similar channel statistics features. It is
interesting to point out that the ofﬂine meta adaptation algorithm performs worse than the online
joint method from the beginning of the urban scenario to the beginning of the highway scenario.
The reason is that the ofﬂine meta adaptation algorithm still uses the trained model based on
the previous scenario (outdoor/urban) to the new scenarios (urban/highway). The difference in
mobility between different environments causes the task mismatch issue for the ofﬂine meta
learning algorithm before its periodic update. Whereas the ofﬂine meta adaptation algorithm
outperforms the online joint method after updating its model in the highway case. This fact
indicates that the ofﬂine algorithm heavily relies on the stationary environment. The proposed
online meta adaptation algorithm has the best performance compared to the online joint method
and the ofﬂine meta adaptation, and it can fast adapt to the new communications scenario by
effectively making use of sequential data.
VI. CONCLUSION
In this paper, we have proposed two ofﬂine learning algorithms to achieve fast adaptation
on the beamforming design when the distribution of testing wireless environments changes. For
the DTL algorithm, it utilizes the pre-trained model to re-train part of the parameter in order
to achieve the adaption on the new environment. Different from the DTL algorithm, the meta
November 2, 2020
A REVISION SUBMITTED TO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
learning algorithm aims to learn the parameter initialization, which can be used to achieve fast
adaption to the new environment by re-training the whole neural network. In order to enhance the
adaption capability of the proposed ofﬂine meta-learning algorithm in the real-world scenarios,
an online adaptive learning algorithm was proposed based on the meta-learning algorithm and
the FTL approach. Simulation results demonstrated that both ofﬂine algorithms can achieve fast
adaption when testing data come from a different distribution, and the proposed meta learning
algorithm provides better generalization ability by using slightly more adaptation time compared
to the DTL algorithm. The online adaptive algorithm can signiﬁcantly enhance the adaption
capability of the proposed ofﬂine meta-learning algorithm in non-stationary scenarios. In this
paper we only consider a single task distribution which is to optimize beamforming. In the
future, we plan to use the lifelong learning technique to solve more complex problems in
self-organizing networks, in which tasks may come from different distributions, so bidirectional
learning, knowledge retention and accumulation are necessary.