Anomaly Detection for Discrete Sequences: A Survey
Technical Report
Department of Computer Science
and Engineering
University of Minnesota
4-192 EECS Building
200 Union Street SE
Minneapolis, MN 55455-0159 USA
Anomaly Detection for Discrete Sequences: A Survey
Varun Chandola, Arindam Banerjee, and Vipin Kumar
May 22, 2009
Anomaly Detection for Discrete Sequences:
Varun Chandola, Arindam Banerjee and Vipin Kumar
Abstract—This survey attempts to provide a comprehensive and structured overview of the existing research for the problem of detecting
anomalies in discrete sequences. The aim is to provide a global understanding of the sequence anomaly detection problem and how techniques proposed for different domains relate to each other. Our speciﬁc
contributions are as follows: We identify three distinct formulations of the
anomaly detection problem, and review techniques from many disparate
and disconnected domains that address each of these formulations.
Within each problem formulation, we group techniques into categories
based on the nature of the underlying algorithm. For each category, we
provide a basic anomaly detection technique, and show how the existing
techniques are variants of the basic technique. This approach shows
how different techniques within a category are related or different from
each other. Our categorization reveals new variants and combinations
that have not been investigated before for anomaly detection. We also
provide a discussion of relative strengths and weaknesses of different
techniques. We show how techniques developed for one problem formulation can be adapted to solve a different formulation; thereby providing
several novel adaptations to solve the different problem formulations.
We highlight the applicability of the techniques that handle discrete
sequences to other related areas such as online anomaly detection and
time series anomaly detection.
INTRODUCTION
Sequence data is found in a wide variety of application
domains such as intrusion detection, bio-informatics,
weather prediction, system health management, etc.
Hence anomaly detection for sequence data is an important topic of research. There is extensive work on
anomaly detection techniques – that look for individual objects that are different from normal objects.
These techniques do not take the sequence structure of
the data into consideration. For example, consider the
set of user command sequences shown in Table 1. While
sequences S1–S4 represent normal daily proﬁles of a
user, the sequence S5 is possibly an attempt to break
into a computer by trying different passwords. Though
the sequence S5 is anomalous, each command in the
sequence by itself is normal.
A sequence is an ordered series of events. Sequences
can be of different types, such as binary, discrete, and
continuous, depending on the type of events that form
the sequences. Discrete and continuous sequences (or
time series) are two most important form of sequences
encountered in real life. In this survey we will focus on
discrete sequences. Discrete or symbolic sequences are
ordered sets of events such that the events are symbols
login, passwd, mail, ssh, . . . , mail, web, logout
login, passwd, mail, web, . . . , web, web, web, logout
login, passwd, mail, ssh, . . . , mail, web, web, logout
login, passwd, web, mail, ssh, . . . , web, mail, logout
login, passwd, login, passwd, login, passwd, . . . , logout
Sequences of User Commands
belonging to a ﬁnite unordered alphabet. For example,
a text document is a sequence of words, a computer
program is executed as a sequence of system calls, a gene
is a sequence of nucleic acids.
Often, one is interested in detecting anomalies in
discrete sequences to ﬁnd possible intrusions, frauds,
faults, contaminations. For example, the sequences of
commands issued by computer users (as shown in Table
1) are collected to detect possible intrusive activities.
Anomaly detection for discrete sequences is a challenging task, since it involves exploiting the sequential
nature of data to detect anomalies. Some of the speciﬁc
challenges are as follows:
• Multiple deﬁnitions of anomalies exist for sequences;
an event within a sequence maybe anomalous, a subsequence within a sequence maybe anomalous, or the entire sequence maybe anomalous. Each deﬁnition needs
to be handled differently. For example, given a data
base of protein sequences, one might be interested
in sequences that are anomalous. On the other hand,
given a long sequence of system calls executed in a
computer system, one might be interested in detecting
subsequences when the computer system was under a
virus attack. A technique that detects anomalous events
within a sequence might not be directly applicable to
detecting anomalies that are caused by a subsequence
of events occurring together.
• The length of the anomaly within a sequence is usually
not known and varies signiﬁcantly across different application domains. Techniques typically have to rely on
user-deﬁned lengths, which may or may not be optimal.
• Computational complexity is a signiﬁcant issue for
sequence data, especially since sequences can be very
long and the alphabet size can be large.
Anomaly detection for discrete sequences has been a
focus of many research papers. But most of the anomaly
detection techniques have been developed within speciﬁc application domains. In particular, several techniques have been developed to detect anomalies in
operating system call data – . Budalakoti et al ,
 present a study of anomaly detection techniques
to detect anomalies in ﬂight safety domain. Sun et al
 present a probabilistic sufﬁx tree based technique
and evaluate it on biological sequences. While each
technique has been evaluated within a speciﬁc domain,
there has not been an attempt to analyze the problem in
its entirety. The reason such analysis is essential is that
the nature of the sequence data as well as the nature of
anomalies can differ fundamentally across domains, and
hence while a technique is shown to be effective within
one domain, it does not guarantee its effectiveness in a
different domain.
Even though the existing techniques appear to have
the same objective, i.e., to detect anomalies in discrete sequences, a deeper analysis reveals that different
techniques actually address different problem formulations. For example, Forrest et al proposed several
techniques that detect an anomalous sequence from a
database of unlabeled sequences. On the other hand,
Chakrabarti et al detect an anomalous subsequence
within a long sequence of events. Gwadera et al 
address the problem of determining if the frequency
of occurrence of a short subsequence in a given long
test sequence is anomalous with respect to its expected
frequency of occurrence in normal sequences. All of
these formulations are fundamentally distinct, and hence
require exclusive techniques to solve them. It is not
only important to identify which problem formulation is
addressed by a given technique, but also to understand
how techniques that address one formulation can be
adapted to solve a different formulation.
The literature on anomaly detection for sequences is
scattered across varied application domains, but there
has not been any study that provides a global overview
of the literature. A comparison of four different anomaly
detection techniques for discrete sequences was presented by Forest et al , but all of the techniques focussed on system call intrusion detection. Chandola et al
 provided a comparative evaluation of eight anomaly
detection techniques on sequence data collected from
different domains, but only focussed on the problem
of detecting anomalous sequences from a database of
sequences.
Our Contributions
In this survey we attempt to provide a comprehensive
and structured overview of the existing research in
this context. We aim to provide a global understanding
of the sequence anomaly detection problem and how
techniques proposed for different domains relate to each
other. We also study the different problem formulations
and show how techniques developed for a particular
problem formulation can be adapted and applied in a
different context.
Our speciﬁc contributions are:
formulations
anomaly detection problem, and review techniques
from many disparate and disconnected domains
that address each of these formulations.
• Within each problem formulation, we group techniques into categories based on the nature of the
underlying algorithm. For each category, we provide
a basic anomaly detection technique, and show how
the existing techniques are variants of the basic
technique. This approach shows how different techniques within a category are related or different
from each other. Our categorization reveals new
variants and combinations that have not been investigated before for anomaly detection. We also
provide a discussion of relative strengths and weaknesses of different techniques.
• We show how techniques developed for one problem formulation can be adapted to solve a different
formulation; thereby providing several novel adaptations to solve the different problem formulations.
• We highlight the applicability of the techniques that
handle discrete sequences to other related areas
such as online anomaly detection and time series
anomaly detection.
Organization
The rest of this survey article is organized as follows.Section 2 describes different application domains
where anomaly detection techniques for discrete sequences have been developed. Section 3 deﬁnes three
different ways in which the anomaly detection problem can be formulated. Sections 4, 5, and 6 provide
an overview of techniques that have been proposed
to solve each of one of these problem formulations.
Section 7 discusses how the different anomaly detection
techniques discussed in the survey are applicable in the
context of online anomaly detection. Conclusions and
future directions of research are presented in Section 8.
APPLICATIONS
OF ANOMALY DETECTION
FOR DISCRETE SEQUENCES
A few application domains where anomaly detection
techniques have been developed to handle discrete sequences are as follows:
• Sequence of operating system calls/user commands ,
 – . The sequences are deﬁned using an alphabet
of all possible system calls (∼160 for Sun Solaris operating system) or user commands (∼2500 for a typical
UNIX user). Anomalies in such data sets correspond
to anomalous program behavior, often caused due to
“break-ins” in the computer system by a virus or a
malicious user, or unauthorized access of a computer
• Biological sequences such as DNA sequences, protein sequences , . The sequences are deﬁned using an
alphabet that corresponds to nucleic acid bases (4), or
amino acid bases (∼20). Anomalies in such data sets
correspond to either mutations, or a “disease” condition
in the biological organism .
• Sensor data from operational systems (such as aircrafts or
space shuttles) , , . The sequences are collected
during the operation of the system through multiple
discrete sensors. The alphabet size for such discrete
sequences is typically large (∼1000 for aircraft data
 ). Anomalies in such data sets corresponds to faults
scenarios in the operation of the system or accidents.
• Sequences of transactions from online banking, customer
purchases, and other retail commerce domains . The
“symbols” in such sequences are “actions” by customers and the alphabet size for such sequences can
also be large. Anomalies in such data sets correspond
to irregular or abnormal behavior by customers.
• Navigational click sequences from web sites , .
The “symbols” in such sequences correspond to clicked
links (web-sites), or categories to which the links belong
to. The anomalies in such data correspond to irregular
or unauthorized user behavior.
PROBLEM DEFINITIONS
Here we will discuss three different formulations of the
sequence anomaly detection problem that are considered important in many application domains. Each of
these formulations are unique in terms of the how the
anomalies are deﬁned. For the ﬁrst formulation, an entire
sequence is anomalous if it is signiﬁcantly different
from normal sequences. For the second formulation, a
subsequence within a long sequence is anomalous if it
is signiﬁcantly different from other subsequences in the
same sequence. For the third formulation, a given test
pattern is anomalous if its frequency of occurrence in a
test sequence is signiﬁcantly different from its expected
frequency in a normal sequence.
From the application perspective, the choice of the
formulation
anomalies to the requirement of the application domain.
For example, consider the following three scenarios that
can arise in the domain of operating system intrusion
detection:
• Scenario 1: A security analyst is interested in detecting
“illegal” user sessions on a computer belonging to a
corporate network. An illegal user session is caused
when an unauthorized person uses the computer with
malicious intent. To detect such intrusions, the analyst
can use the ﬁrst formulation, in which the past normal
user sessions (sequence of system calls/commands) are
used as the training data, and a new user session is
tested against this training data.
• Scenario 2: A security analyst is interested in detecting
if a user’s account was misused (hacked) in the past
few months. To detect this misuse, the analyst can use
the second formulation, in which the user’s activity for
the past few months is considered as a long sequence,
and is tested for any anomalous subsequence.
• Scenario 3: A security analyst is interested in determining if the frequency with which a user executed a particular sequence of commands is higher (or lower) than
an expected frequency. Going back to the example given
in Table 1, the sequence login,passwd,login,passwd
corresponds to a failed login attempt followed by a
successful login attempt. Occurrence of this sequence in
a user’s daily proﬁle is normal if it occurs occasionally,
but is anomalous if it occurs very frequently, since
it could correspond to an unauthorized user surreptitiously attempting an entry into the user’s computer
by trying multiple passwords. To detect such intrusions,
the analyst can use the third formulation, in which the
sequence of commands is the query pattern, and the
frequency of the query pattern in the user sequence
for the given day is compared against the expected
frequency of the query pattern in the daily sequences
for the user in the past, to detect anomalous behavior.
The ﬁrst problem formulation has been addressed in
the majority of papers, but the other two formulations
have also been addressed in certain domains. The next
three sections discuss techniques that address these three
problem formulations.
DETERMINING IF A SEQUENCE IS ANOMA-
LOUS W.R.T. A SEQUENCE DATABASE
The most common formulation of anomaly detection
problem for sequences is to determine if a given test sequence is anomalous with respect to a reference database
of sequences. One application of this formulation was
provided as Scenario 1 in Section 3. Most techniques
that solve this formulation, assign an anomaly score to
the test sequence. If a set of test sequences is given, the
anomaly score is used to rank them, to determine the
most anomalous test sequences.
Two variants of this problem formulation exist. In
the ﬁrst variant, the reference (or training) database is
assumed to contain only normal sequences and each
test sequence is tested against the normal reference
database (semi-supervised anomaly detection). In the
second variant, the task is to detect anomalous sequences
from an unlabeled database of sequences (unsupervised
anomaly detection). For the second variant, it is assumed
that majority of sequences in the unlabeled database are
The semi-supervised variant of problem formulation
1 can be stated as following:
Deﬁnition 1: Given a set of n sequences, S = {S1, S2,
. . ., Sn}, and a sequence Sq belonging to a test data set
Sq, compute an anomaly score for Sq with respect to a
training data set S.
The length of sequences in S and the length of Sq might
not be equal. After assigning an anomaly score to the
test sequence, an additional test is required to determine
if the anomaly score is signiﬁcantly large for the test
sequence to be considered anomalous.
The semi-supervised variant of problem formulation
1 can be stated as following:
Deﬁnition 1a: Given a set of n sequences, S = {S1, S2,
. . ., Sn}, ﬁnd all sequences in S that are anomalous
w.r.t. rest of S.
techniques that handle the semi-supervised variant. A semisupervised technique can be adapted to solve the unsupervised problem by treating the entire data set as a
training set, and then scoring each sequence with respect
to this training set. Such adaptations assume that the
given set contains few anomalous sequences, and hence
semi-supervised technique does not get affected by the
presence of anomalies in the “training” set.
Techniques that solve problem formulation 1 typically
operate in two steps. In the ﬁrst step, a “model” representing the normal behavior is learnt from sequences
in S. In the second step, the “likelihood” of the test sequence Sq to be generated by model M is estimated. The
likelihood is used to assign an anomalous label/score to
the test sequence.
We use the term model in a loose fashion and it
may refer to a generative model, a non-parametric density
estimate, or a similarity kernel. Examples of generative
models are ﬁnite state automata (FSA), hidden markov
models (HMM), and mixture of HMMs. Several techniques use a similarity kernel between the test sequences
in Sq and the normal sequences in S. Additionally,
there is a class of techniques in which the likelihood
of a test sequence is estimated using the likelihood of
short windows contained in the test sequence. Thus the
model M for such techniques is the density estimate of
the different short windows that occur in the test and
training sequences.
Anomaly detection techniques can also be classiﬁed
based on the unit element of a test sequence that is
analyzed by the technique, as follows:
• Kernel Based Techniques: These techniques treat the
entire test sequence as a unit element in the analysis, and hence are analogous to point based anomaly
detection techniques. They typically apply a proximity
based point anomaly detection technique by deﬁning
an appropriate similarity kernel for the sequences.
• Window Based Techniques: These techniques analyze
a short window of symbols—a short subsequence—
within the test sequence at a time. Thus such techniques
treat a subsequence within the test sequence as a unit
element for analysis. These techniques require an additional step in which the anomalous nature of the entire
test sequence is determined, based on the analysis on
the subsequences within the entire sequence.
• Markovian Techniques: These techniques predict the
probability of observing each symbol of the test sequence, using a probabilistic model, and use the persymbol probabilities to obtain an anomaly score for the
test sequence. These techniques analyze each symbol
with respect to previous few symbols.
• Hidden Markov Model Based Techniques: These techniques transform the input sequences into sequences
of hidden states, and then detect anomalies in the
transformed sequences.
A detailed discussion of the above four categories of
techniques is given in the next four subsections.
Kernel Based Techniques
These techniques compute pairwise similarity between
sequences using a speciﬁc similarity measure and then
make use of a traditional point (or instance) based
anomaly detection algorithm (which utilizes the similarities) , , .
A basic kernel based technique operates as follows.
First, a pairwise similarity matrix is computed for the
training sequences in S. Next, the test sequence Sq is
compared against the similarity matrix to obtain the
anomaly score for Sq, using a point based anomaly
detection algorithm.
Several variants of the basic technique have been
proposed which use different point based algorithms
and different similarity measures to compare a pair of
sequences.
Using Different Point Based Anomaly Detection Algorithms
Two point based anomaly detection algorithms that have
been used for discrete sequences are k-nearest neighbor
(kNN) based and clustering based . Chandola et
al proposed a kNN based technique in which the
anomaly score of a test sequence is equal to the inverse
of its similarity to its kth nearest neighbor in the training
data set S.
Budalakoti et al , proposed a clustering based
technique in which the training sequences are ﬁrst clustered into a ﬁxed number of clusters using the k-medoid
algorithm . The anomaly score for a test sequence is
then computed as equal to the inverse of its similarity
to its closest medoid. Probabilistic clustering techniques,
which do not require an explicit similarity matrix to
ﬁnd clusters in the training set, have also been used for
anomaly detection. For example, Yang et al propose
a technique that uses a mixture of Probabilistic Suffux
Trees as cluster representations. Other probabilistic
techniques such as mixture of HMMs , or mixture of Maximum Entropy (maxent) models can also
be employed in the same manner for clustering based
anomaly detection.
Using Different Similarity Measures
The simplest similarity measure for comparing a pair
of discrete sequences is the Simple Matching Coefﬁcient
(SMC) which counts the number of positions in
which the two sequences match as its similarity. While
computing the similarity is fast (linear in the length
of the sequences), this measure has a drawback that it
requires the sequences to be of equal lengths.
Several anomaly detection techniques use the length of
the longest common subsequence as a similarity measure
since it can compute similarity between two sequences
of unequal lengths , , . This similarity (nLCS)
between two sequences Si and Sj, is computed as:
nLCS(Si, Sj) = |LCS(Si, Sj)|
where LCS(Si, Sj) is the longest common subsequence
shared by Si and Sj.
The disadvantage of using nLCS is the computational
complexity involved, which is an order of magnitude
more than that of SMC, though faster algorithms to
compute the LCS have been proposed . A disadvantage of both SMC and nLCS is that they do not
incorporate the relation between different pairs of symbols when computing the similarity, i.e., all matches and
mismatches are treated equally.
Other similarity measures that do not require the
sequences to be of equal length can also be used instead
of nLCS. One such measure was proposed by Kumar
et al by converting the sequences into bitmaps and
comparing the bitmaps to determine the similarity.
Advantages
Disadvantages
Techniques. The advantage of kernel based techniques
is that after obtaining a similarity kernel, any similarity
applied to detect anomalies. Techniques that involve
computing similarity can leverage the existing research
on sequence similarity , , , and then apply
known nearest neighbor or clustering based anomaly
detection techniques , .
A disadvantage of kernel based techniques is that their
performance is highly dependent on the choice of the
similarity measure. Similarity measures such as nLCS
are able to distinguish between normal and anomalous
test sequences only when anomalous sequences are signiﬁcantly different from the training sequences. If the
anomalies are localized in the test sequence, similarity
measures such as nLCS fail to pick up such minor difference. Another disadvantage of kernel based techniques
is the O(n2) complexity involved in computing pairwise
similarity between sequences in S.
Window Based Techniques
Window based techniques extract ﬁxed length overlapping windows from a test sequence. Each window is
assigned an anomaly score. The anomaly scores of all
windows within a test sequence are aggregated to obtain
an anomaly score for the entire test sequence.
The motivation behind window based techniques can
be understood by ﬁrst understanding the limitation of
kernel based techniques. Probabilistically speaking, kernel based techniques indirectly estimate P(Sq|M), which
is the conditional probability of occurrence of an entire
test sequence Sq, given the model M learnt from the
training data set. Researchers have argued that often,
the cause of anomaly can be localized to one or more
shorter subsequences within the actual sequence . If
the entire sequence is analyzed as a whole, the anomaly
signal might not be distinguishable from the inherent
variation that exists across sequences. By analyzing a
short window at a time, window based techniques try
to localize the cause of anomaly within one or a few
The standard technique to obtain short windows from
a sequence is to slide a ﬁxed length window, one symbol
at a time, along the sequence. Let us assume that for a
given sequence S, the extracted windows are denoted
by ω1, ω2 . . . ωt and each window ωi can also be denoted
as ωi ωi . . . ωi[k].
Another way to understand the motivation behind the
window based techniques. Let us assume that an anomalous test sequence Sq contains a subsequence aq (of a
certain length), which is the actual cause of anomaly.
In a sliding window based technique, if the length of
the window is k, the anomalous subsequence aq will
occur (partly or whole) in |aq| + k −1 windows. Thus
the anomalous sequence can be potentially detected by
detecting at least one of such windows.
A basic window based technique operates as follows.
In the training phase, k length sliding windows are
extracted from all training sequences and the frequency
of occurrence of each unique window in the training data
set is maintained (as a normal dictionary). In the test step,
sliding windows of length k are extracted from the test
sequence, Sq. A window ωi is assigned a likelihood score
L(ωi) which is equal to the frequency associated with
the window ωi in the normal dictionary. A threshold
λ is used to determine if a particular window, ωi is
anomalous (L(ωi) < λ) or not (L(ωi) ≥λ). The anomaly
score of the test sequence is proportional to the number
of anomalous windows in the test sequence. The exact
expression for the anomaly score of a test sequence, Sq
is given by:
A(Sq) = |i : L(ωi) < λ, 1 ≤i ≤t|
The above mentioned basic window based technique
has been proposed for operating system call intrusion
detection and is termed as t-STIDE (threshold based
sequence time delay embedding) , .
Several variants of the t-STIDE technique have been
proposed, especially for system call intrusion detection
 , , , – . These variants differ from t-
STIDE in terms of how they assign an anomaly score to
a window, and how they combine the scores to obtain a
global anomaly score for the test sequence.
Assigning Anomaly Scores to Windows
In the t-STIDE technique, the anomaly score for each
window ωi (denoted as A(ωi)) is equal to the inverse
of frequency of occurrence of the window in the normal dictionary. Other techniques have been proposed to
assign a different anomaly score to a window. We will
discuss three types of such techniques here.
1. Using lookahead pairs. Techniques under this category make use of lookahead pairs to assign score to a
window, ωi . The normal dictionary is constructed as
follows. For each symbol that occurs in S, the symbols
that occur j positions after that symbol (∀j ∈[1, k]) are
recorded. To assign anomaly score to ωi, the number
of symbol pairs of the form ⟨ωi , ωi[j]⟩, ∀j ∈(1, k] are
counted, such that ωi is not followed by ωi[j] after
j positions in the normal dictionary. The total number
of mismatching lookahead pairs divided by k is the
anomaly score for the window.
2. Comparing against a normal dictionary. Techniques
under this category construct a normal dictionary (of
ﬁxed length windows) from training sequences and compare each window from the test sequence to the normal
dictionary to obtain an anomaly score.
Hofmeyr et al use Hamming Distance (or number
of mismatches) between the test window ωi and the
closest window in the normal dictionary as anomaly
score A(ωi). In the same paper, another technique to
compute A(ωi) is presented. A(ωi) is 1 if the window
ωi is not present in the normal dictionary, and 0 if the
window is present in the normal dictionary. Hamming
Distance has also been used in , . The latter
approach has been adopted by , , , .
Lane and Brodley , , use the following
similarity measure to compute similarity Sim(ωi, ϑj)
between a test window, ωi and a window in the normal
dictionary, ϑj:
w(ωi, ϑj, l) =
if i = 0 or ωi[l] ̸= ϑj[l]
1 + w(ωi, ϑj, l −1)
if ωi[l] = ϑj[l]
Sim(ωi, ϑj) =
w(ωi, ϑj, l)
Note that in above similarity measure, a series of consecutive matching symbols can accumulate a large similarity, while even a single mismatch in the middle can
greatly reduce the similarity.
The anomaly score assigned to ωi is equal to the
inverse of maximum similarity between ωi and windows
in the normal dictionary. Lane’s PhD. thesis discusses other variants of the above described similarity
measure in the context of anomaly detection.
As mentioned earlier, the dictionaries are typically
built for normal behavior. Certain techniques construct
dictionaries for only the anomalous behavior , –
 . For example, Dasgupta et al ﬁrst build a normal
dictionary of windows. They then generate random windows from the given alphabet. Any window that does
not match a normal window is treated as anomalous
window and added to the anomaly dictionary. A comparative study of using normal and anomaly dictionaries
is presented in .
3. Using a classiﬁer. Instead of using the frequency of
occurrence of a window to compute its anomaly score,
some techniques use a classiﬁer to assign an anomaly
label to each window. The training involves learning
a classiﬁer from the set of k length windows obtained
from the training data set S. If S contains both normal
and anomalous sequences, one way to obtain labeled
windows was proposed by :
• Windows extracted from normal sequences of S are
assigned a normal label.
• If a window extracted from an anomalous sequence
of S occurs in any normal sequence also, it is assigned a normal label, else it is assigned anomalous
If S contains only normal sequences, a random anomaly
generation approach is used , , . All windows
extracted from sequences in S are assigned a normal
label. To obtain anomalous windows, random windows
are generated. If the window occurs in S, it is ignored,
or else it is assigned an anomalous label and added to
the training data set.
After constructing a training data set, a classiﬁer is
learnt. Different type of classiﬁcation models have been
learnt, such as HMM based , neural networks ,
 , , , SVM , , and rule based classiﬁers
 . During testing, the anomaly score for each window
ωi obtained from test sequence Sq, A(ωi) = 0 if the
classiﬁer labels it as normal, and A(ωi) = 1 if the
classiﬁer labels it as anomalous.
Obtaining Anomaly Score for Test Sequence
Once all windows in a given test sequence, Sq, are assigned an anomaly score, the next step is to combine the
anomaly scores (a vector of length |Sq| −k + 1) to obtain
an overall anomaly score A(Sq). One such technique was
discussed earlier for the t-STIDE technique. Here we will
describe some other combination techniques that have
been proposed in the literature.
Hofmeyr et al propose two methods to compute the
overall anomaly score. The ﬁrst method computes this
as the average of the strength of anomaly signal over all
windows in Sq.
The second method checks if any window in Sq has a
if ∃i : A(ωi) ≥1
Forrest et al proposed a technique to obtain A(Sq),
known as locality frame count (LFC). For every mismatching window A(ωi) = 1, the technique counts the number
of mismatching windows in the previous n windows
of Sq (n is a user deﬁned parameter). If this number
is greater than a threshold, A(Sq) is incremented. The
LFC technique considers a sequence highly anomalous
only when a signiﬁcant number of anomalous windows
occur close to each other. If the anomalous windows
are located far apart across Sq, the LFC method gives
a lower anomaly score to Sq. A similar technique has
been proposed by Gao et al .
The intuition behind the LFC approach is that anomalies in actual anomalous sequences typically occur as
temporally clustered anomalous symbols, hence aggregating the anomaly scores across the entire sequence Sq
might “wash out” the anomaly signal; the local combination techniques on the other hand would capture such
combination
proposed by called the leaky bucket. They use the
vector obtained of anomaly scores for the windows in
the test sequence. For each anomalous window, 1 is
added to the global anomaly score and for each normal
window 1 is subtracted (the score is never allowed
to fall below 0). Thus consecutive anomalies result in
the global score to increase. If at any time the global
score goes above a threshold, the entire test sequence is
declared to be anomalous. This technique provides the
same beneﬁt as LFC technique.
Advantages and Disadvantages of Window Based
Techniques.
techniques over kernel based techniques is that they are
better suited to detect anomalies which are localized in
a short region in the test sequence. Constructing normal
dictionaries is simple to implement and can be done
efﬁciently using appropriate data structures.
One disadvantage of window based techniques is that
they are highly reliant on the value of k (length of the
window). If k is chosen to be very small, most k length
windows will have a high probability of occurrence in
the training sequences, while if k is chosen to be very
large, most k length windows will have a low probability
of occurrence in the training sequences. Thus, in either
case, the discriminatory power of the k length windows to differentiate between normal and anomalous
sequences will be low. Setting an optimal value for k
is challenging. Another disadvantage is that storing all
unique windows that occur in training sequences and
their frequencies can require large amount of memory.
Markovian Techniques
The third category of techniques that solve problem
formulation 1 learn a model from the training sequences.
The model is used as an approximation of the “true”
distribution that generated the normal data. Typically
the probability of a given sequence S (= ⟨s1, s2, . . . sl⟩)
is factorized using the chain rule:
P(si|s1s2 . . . si−1)
where l is the length of the sequence and si is the symbol
occurring at position i in S.
Markovian techniques utilize the short memory property of sequences, which is observed across different
domains . The short memory property is essentially
a higher-order Markov condition which states that the
conditional probability of occurrence of a symbol si,
given the sequence observed so far can be approximated
P(si|s1s2 . . . si−1) = P(si|si−ksi−k−1 . . . si−1)
Markovian techniques operate in two phases, training
and testing. Training involves learning a probabilistic
model using training sequences in S. Testing involves
calculating the conditional probabilities for each symbol of the test sequence, using the model, and then
combining them to obtain an overall probability for the
test sequence using (7). Finally, an anomaly score A(Sq)
for the test sequence is calculated as the inverse of the
probability of Sq.
Fixed Markovian Techniques
Such techniques use a ﬁxed history (of length k) to
estimate the conditional probability of a symbol in the
test sequence.
A basic ﬁxed Markovian technique “learns” the conditional probability of occurrence of a given symbol sqi
P(sqi|sq(i−k) . . . sq(i−1)) = f(sq(i−k) . . . sq(i−1)sqi)
f(sq(i−k) . . . sq(i−1))
where f(sq(i−k) . . . sq(i−1)sqi) is the frequency of occurrence of the subsequence sq(i−k) . . . sq(i−1)sqi in the sequences in S and f(sq(i−k) . . . sq(i−1)) is the frequency
of occurrence of the subsequence sq(i−k) . . . sq(i−1) in the
sequences in S.
Different variants of the basic technique have been
proposed. Ye proposed one such technique for k = 1.
An issue with the basic ﬁxed Markovian technique
is that storing all transition frequencies (See (9)) can
potentially require a huge amount of space. Let the
alphabet set size for a given sequence data set by σ. The
the total number of frequencies required by the basic
technique will be ≈σk+1.
Michael and Ghosh address this issue by storing
the frequencies in an Extended Finite State Automata
(EFSA) . The EFSA is like a traditional FSA but with
frequencies associated with the nodes and the transitions
from one node to another. Each node denotes a k length
subsequence. A node has a transition to another node
only if the subsequence for the second node can be
obtained from the subsequence for the ﬁrst node by
removing the ﬁrst symbol of the ﬁrst node and appending any symbol at the end of the subsequence. The
number of times the subsequence for a node occurs in
the sequences in S is stored at the node. The number of
times a transition from one node to another is observed
in the sequences in S are stored at the transitions. Only
those nodes and transitions that are observed in the
training sequences are stored in the EFSA. Thus the size
of EFSA is typically smaller than the total possible size.
During testing, k+1 sized windows are extracted from
the test sequence Sq. The ﬁrst k symbols determine the
current state in the EFSA while the last k symbols denote
the next state in the EFSA. If a transition between the two
states is deﬁned, the conditional probability for the last
symbol of the window by substituting the frequencies
stored in the current node and the transition in (9). If the
transition is not deﬁned the symbol is ignored. Chandola
et al proposed a variant of the EFSA technique in
which if the transition is not deﬁned, the conditional
probability of the last symbol of the window is set to
The EFSA based technique was also extended by
Michael and Ghosh to the case in the conditional
probability for 2 or more symbols, given the previous
k symbols is used to obtain the ﬁnal anomaly score for
Another variant of the basic technique was proposed
by Marceau which uses sufﬁx trees. In this technique the sufﬁx tree only maintains the k + 1 length
subsequences and their k length sufﬁxes that exist in the
sequences in S. Thus this technique learns a traditional
FSA. During testing, all k + 1 length subsequences are
extracted from Sq and fed into the FSA. An anomaly is
detected if the FSA reaches a state from where there is
no outgoing edge corresponding to the last symbol of
the current subsequence.
Variable Markovian Techniques
An issue with ﬁxed Markovian techniques is that they
force each symbol of a test sequence to be conditioned
on the previous k symbols (See (9)). Often, the frequency
of a k length subsequence, i.e., (sq(i−k) . . . sq(i−1)), may
not be sufﬁciently large to provide a reliable estimate
of the conditional probability of a symbol that follows
this subsequence. For example, let us assume that the
subsequence aabbb occurs once across all training sequences and is followed by symbol b’ in that solitary
occurrence. A ﬁxed Markovian technique (k = 5) will assign a conditional probability of 1 to P(b|aabbb). But this
conditional probability is not reliable, and hence might
give undesirable results. Variable Markovian techniques
try to address this issue by allowing symbols to be
conditioned on a variable length history. For the above
example, P(b|aabbb) might be substituted with P(b|abbb)
if the subsequence abbb occurs signiﬁcant number of
times in the training sequences.
One such technique was proposed by Sun et al 
using Probabilistic Sufﬁx Trees (PST) . A PST is a
compact tree representation of a variable Markov chain,
which uses classical sufﬁx trees as its index structure. In
a PST, each edge is labeled using a symbol, and each
node represents the subsequence obtained by traversing
the path from root to the node, as well as the number
of times the subsequence is observed in the training
sequences. Each node also stores the conditional probability of observing each symbol in the alphabet, given the
subsequence represented by the node. The PST is grown
(training phase) by scanning the training sequences. The
maximum depth of the tree is ﬁxed at k, which is a user
deﬁned parameter. Several pruning criterion are applied
to the PST to ensure that the PST contains only those
paths that occur signiﬁcantly enough number of times
in the training sequences. The pruning can be done by
applying thresholds to the frequency of a node label,
or to the conditional probability of a symbol emanating
from a given node. If no pruning is applied, the PST is
equivalent to the EFSA technique discussed in Section
During the testing phase for the PST based technique
the test sequence is scanned and the PST is traversed
simultaneously. For a symbol sqi in the test sequence
Sq, its conditional probability is estimated by ﬁnding the
longest sufﬁx of the k length subsequence that precedes
sqi (in Sq) and occurs as a path in the PST. Thus, different
symbols are conditioned on a different sized history. To
obtain the likelihood score, L(Sq) (inverse of anomaly
score), of the test sequence, two combination techniques
have been proposed:
log P(sqi|sq(i−j+1)...sq(i−1)))
i=1 P(sqi)
i=1 p(sqi|sq(i−j+1)...sq(i−1))
where p(sqi) is the empirical probability of symbol si in
S and j ≤k. Sun et al show that the combination
technique in (10) performs better than the combination
technique in (11) for anomaly detection using protein
sequences.
Sparse Markovian Techniques
Variable Markovian techniques described above allow a
symbol sqi to be analyzed with respect to a history that
could be of different lengths for different symbols; but
they still choose contiguous and immediately preceding
symbols to sqi in Sq. Sparse Markovian techniques are
more ﬂexible in the sense that they estimate the conditional probability of sqi based on symbols within the
previous k symbols, which are not necessarily contiguous or immediately preceding to sqi. In other words
the symbols are conditioned on a sparse history. Using
the example from Section 4.3.2, if the sequence “aabbb”
occurs rarely in the training sequence, the conditional
probability P(b|aabbb) can be potentially replaced with
P(b|aXbXb) where X can be replaced with any symbol
of the alphabet.
One such sparse technique has been proposed by
Eskin et al , using Sparse Markov Transducers (SMT)
 . SMTs, similar to probabilistic sufﬁx trees, estimate
a probability distribution conditioned on an input sequence. SMTs generalize probabilistic sufﬁx trees by
allowing for wild-cards in the conditioning sequences.
The proposed technique estimates the probability distribution of an output symbol, conditioned on an input
sequence. SMTs are sparse in the sense that they allow
some positions in the conditioning input sequence to be
ignored by introducing wild cards. In the training phase,
a forest of SMTs is learnt from the training sequences to
account for wild cards at different positions in the paths
from the root. The depth of the SMTs is ﬁxed at a user
deﬁned depth k. The testing phase is exactly like the
testing phase for the PST technique described earlier.
Lee et al proposed a different sparse Markovian
technique that uses a classiﬁcation algorithm (RIPPER
 ) to build sparse models for sequences. In this
technique, k length windows are extracted from the
training sequences in S. The ﬁrst k −1 positions of these
windows are treated as k −1 categorical attributes, and
the kth position is treated as the target class. RIPPER
is used to learn rules from this categorical data set to
predict the kth symbol given the ﬁrst k −1 symbols.
During testing, for each symbol sqi, the ﬁrst rule that
ﬁres for the vector sq(i−k+1) . . . sq(i−1) is chosen. If the
target of the selected rule is sqi, then the probability
P(sqi|sq(i−k+1) . . . sq(i−1))
1. If the target of the
selected rule is not sqi, then P(sqi|sq(i−k+1) . . . sq(i−1))
is the inverse of the conﬁdence associated with the
selected rule. Since the precedent of a RIPPER rule is
an instance of the subset of the k −1 attributes, hence
the RIPPER based technique learns a sparse model from
the training data.
Advantages
Disadvantages
Techniques.
techniques is that they analyze each event with respect
to it immediate context. Thus such techniques are able
to detect anomalous sequences even if the anomalies
localized.
techniques provide ﬂexibility in terms of the size of
history to observe for every symbol. Thus if in a normal
test sequence, the probability of observing a symbol is
low with respect to its k length history, the variable
and sparse techniques will estimate the probability with
respect to a shorter history, and hence the symbol will
have a higher probability. Thus such techniques help
reduce the false positive rate.
The above mentioned strength of variable and sparse
Markovian techniques can also become a disadvantage.
For these techniques, the probability of a “truly” anomalous symbol will be boosted since it will be conditioned on a shorter history, whereas the ﬁxed Markovian
technique will still assign a low probability to such a
symbol. Thus the variable and sparse techniques might
suffer with higher false negative rate. Chandola et al 
compare a ﬁxed Markovian technique with a variable
and a sparse Markovian technique on data from different
application domains and show that the ﬁxed Markovian
technique (using EFSA) outperforms the variable (using
PST) and the sparse (using RIPPER) techniques on many
data sets. The same paper also provides scenarios in
which the variable and sparse Markovian techniques can
be better than the ﬁxed Markovian techniques. Another
disadvantage of the Markovian techniques is that they
are sensitive to the choice of the length of the history.
Hidden Markov Models Based Techniques
Hidden Markov Models (HMM) are powerful ﬁnite state
machines that are widely used for sequence modeling
 . HMMs have also been applied to sequence anomaly
detection , – . Such techniques use HMM to
transform the input sequences from the symbol space
to the hidden state space. The underlying assumption
for such techniques is that the nature of the sequences
is captured effectively by the hidden space.
The general approach is to construct an HMM with σ
hidden states, from the normal sequences in S using the
Baum Welch algorithm . For each normal sequence
in S, as well as the test sequence Sq, the optimal state
transition sequence is obtained using the Viterbi algorithm . At this point any sequence anomaly detection
technique that has been discussed in previous sections
can be applied to estimate the anomaly score for the test
One such technique is proposed in , where 1-order
ﬁnite Markovian technique is applied on the sequences
of hidden states for anomaly detection. Qiao et al
 apply a window based technique in the hidden
state space. An extension to the latter technique was
proposed by Zhang et al , in which the state
transition sequences from the HMM are used to train
another HMM. The state transition sequences from the
second HMM are then used as input to a window based
anomaly detection technique.
Advantages
Disadvantages
Techniques. HMM based techniques transform the
input sequences into sequences of hidden states. Thus,
if the assumption that the training sequences in S
are generated by a particular HMM hold true, the
transformed data (hidden state sequences) will result in
better anomaly detection.
If the above assumption regarding sequences in S
to be generated by the HMM does not hold true, the
performance of the HMM based technique can be worse
than the performance of an anomaly detection technique
on the original data. Another disadvantage of HMM
based techniques is that initializing the HMM (number
of hidden states, initial transition matrix) is often not
intuitive, and poor choice for these can often result in
sub-optimal performance of the technique.
SUBSEQUENCES
WITHIN A LONG SEQUENCE
Techniques under this category solve the following
anomaly detection problem:
Deﬁnition 2: Detect short subsequences in a long sequence T, that are anomalous with respect to rest of T.
Such anomalous subsequences can also be considered as
discords, as deﬁned by Keogh et al : “subsequences of
a longer time series that are maximally different to rest of the
time series subsequences”. We will refer to such anomalous
subsequences as discords in this section.
This problem deﬁnition is natural for several application domains, where an activity is being monitored over
a long period of time. For example, in credit card fraud
detection, an individual’s credit card transactions are
continuously monitored, and a discord, i.e, an anomalous sequence of actions (purchases), may indicate a case
of identify theft/misuse.
A basic anomaly detection technique can be described
as follows: First, all k-length windows are extracted
from the given sequence T and stored as a database of
ﬁxed length windows, denoted as Tk. Each window is
assigned an anomaly score by comparing it with rest of
the windows in Tk. The windows with anomaly scores
above a user deﬁned threshold are chosen as the top
discords. Since the length of the “true” discord is not
known a priori, the techniques that solve this problem
generally assume that the discords are contained within
a subsequence (or a window) of ﬁxed length k.
This basic technique is at the heart of a number of
techniques investigated by Keogh et al – . Note
that these techniques were originally presented in the
context of time series data, but can be extended to
discrete sequences by discretizing the time series using
techniques such as Symbolic ApproXimation (SAX) .
An issue with the basic technique is that when any
window is compared with the other windows in Tk, the
windows which overlap with the given window in T,
will be highly “similar” to the given window. For example, any window will differ in at most 1 position with the
immediately next window in the given sequence. This
property will be exhibited by both normal windows as
well as windows that contain discords, and can bias the
computation of anomaly score for a window. Keogh et
al propose a simple solution (referred to as non-self
match in the paper) to this issue by comparing a window
with only the windows in Tk that do not overlap with
the given window.
Several variants of the basic techniques have been proposed, and can be broadly grouped into two categories.
The ﬁrst category of techniques score the windows differently, while the second category of techniques address
the time complexity of the basic technique.
Window Scoring Techniques
One possible technique for scoring the windows is to
count the number of times a window occurs in the
database of all windows, Tk (this is similar to the window based techniques such as t-STIDE, discussed in
Section 4.2). The anomaly score of the window will be
the inverse of this count. While for smaller values of k
this is a reasonable technique, it might be not be possible
to ﬁnd exact matches of the window in Tk when the
value of k is large.
Another possible technique for scoring the windows
would be that the anomaly score of any window is
calculated as equal to its distance to its mth nearest
neighbor in Tk. One such variant, called HOTSAX ,
was proposed by Keogh et al, in which the m = 1, i.e.,
the anomaly score of a window is equal to its distance
to its nearest neighbor in Tk (only the non-self matches
are considered). One drawback of the nearest neighbor based technique is that they involve an additional
parameter, m, which needs to be set carefully, though
approaches such as using the weighted sum of distance
to the m nearest neighbors to compute the anomaly score
can be used to reduce the sensitivity on m.
Another variation of the basic anomaly detection technique, known as Window Comparison Anomaly Detection
(WCAD), was proposed by Keogh et al . To assign
anomaly score to each window in the sequence T, the
window is compared against rest of the sequence (say T ′)
using an information theoretic measure called Compression Based Dissimilarity (CDM). For a window ωi ∈Tk,
the CDM is deﬁned as:
CDM(ωi, T ′) =
C(ωi) + C(T ′)
where C(x) is the compression attained by any standard
compression algorithm on a given string x. The intuition
behind using the measure deﬁned in (12) is that if the
window ωi is normal, it will match the rest of the
sequence very well and hence will not require extra
space when both ωi and T ′ are compressed together. On
the other hand, if ωi is a discord, it will not match the
rest of the sequence and hence the value of C(ωiT ′), and
hence the anomaly score, will be high.
Wei et al proposed a variation of the basic
technique by sliding two adjacent windows along the
sequence. The anomaly score of each window is computed by comparing its bitmap with the bitmap of the
previously adjacent window. The length of the preceding window is not required to be same as the current
window. The underlying assumption for this technique
is that a normal window will be similar to the previously
adjacent window, while a window containing a discord
will be signiﬁcantly different.
Several of the above mentioned variants measure similarity/distance between a pair of windows. A number
of similarity/distance measures such as Simple Matching
Coefﬁcient (SMC), edit distance, length of longest common
subsequence, and weighted SMC can be used. Wei et al
 use a visualization technique called time series or
chaos bitmaps to compute similarity between windows.
The authors assume that the sequences consist of four
symbols. Each window is represented as a l × l bitmap
(l ≤k), which is a matrix that contains the number
of times any l length subsequence occurs in the given
window. The matrix is normalized by dividing each
value by the maximum value exists in the matrix.
Optimizing the Complexity of the Basic Technique
An issue with the basic technique that solves problem
formulation 2 is that it requires O(l2) comparisons of
window pairs, where l is the length of the sequence T.
Several faster variations have been proposed that can run
in approximately linear time in the context of continuous
time series , , – , and can be extended to
discrete sequences.
One general technique for reducing complexity of the
basic technique makes use of the following fact. Instead
of scoring all windows, they score as many windows
as required to get the top p anomalous windows. Thus
a window can be pruned if at anytime its distance
to its current mth nearest neighbor is lower than the
anomaly score of the current window with pth largest
anomaly score. Since the distance of the window to its
actual mth nearest neighbor is upper bounded by the
current distance, this window will never ﬁgure in the
top p anomalous windows, and hence can be pruned.
Such pruning has been successfully used for traditional
anomaly detection , and has been applied to discord
detection , , . It should be noted that this
pruning method guarantees the same result as the basic
technique, but can result in lower execution time.
Segmentation Techniques
Choosing an optimal value of k is challenging. If k is
set to be very small, all k length windows might appear
highly probable, resulting in high false negative rates.
If k is set to be very large, all k length windows might
have a low occurrence probabilities, resulting high false
positive rates. This challenge becomes more signiﬁcant
if the sequence contains multiple discords, of varying
length. In this case, a single value of k might not be
enough to detect all discords.
One approach to address this challenge is to extract
unequal length segments from the given sequence T, as
proposed by Chakrabarti et al . Originally, this segmentation based technique was proposed for a sequence
of market baskets, but this can be easily generalized
to a discrete sequence, by encoding the alphabets as
bit vectors, and hence treating them as market baskets.
In this approach, T is segmented into unequal length
segments, such that the sum of the number of bits
required to encode each segment (using Shannon’s Source
Coding Theorem) is minimized. The segments which require highest number of bits for encoding are treated as
discords. It is shown that an optimal O(|T|2) solution
exists to ﬁnd such segmentation when number of items
is 1, i.e., for a binary sequence. Approximate algorithms
are proposed to handle the case when number of items
is more than 1, though the technique is limited to small
item set sizes, or small alphabets.
Relationship Between Techniques Solving Problem Formulation 1 and Problem Formulation 2
Techniques that handle problem formulation 1 and the
techniques that handle problem formulation 2 have been
developed independently since they solve distinct problems. Here, we will discuss how techniques belonging
to the ﬁrst category can be used to solve the second
problem, and vice versa.
Using Techniques for Problem Formulation 1 to Solve
Problem Formulation 2:
The basic anomaly detection
technique described earlier in this section assigns an
anomaly score to a given window ωi with respect to
a data base of windows Tk (a majority of which are
assumed to be normal). Any anomaly detection technique that solves problem formulation 1, as described in
Section 4, can be applied here by considering Tk −ωi as
the training data set S and the given window ωi as a test
sequence Sq. For Markovian techniques, such as EFSA
and PST, extracting windows from T is not explicitly
required, since a model can be constructed using the
single long sequence T, and then a window can be tested
against the model to obtain an anomaly score.
The key issue with using techniques, such as EFSA
and PST, is that a model has to be constructed for every
window ωi, using the data set Tk −ωi. A simple solution
to this issue is to construct a single model using the
entire sequence Tk, and then score each window against
this model, but the model will get biased from the
discords that exist in the original sequence T. However,
this bias will be small as long as the size of the discord
is small compared to the entire sequence. Unsupervised
techniques such as clustering and k-nearest neighbor
can also be applied to assign an anomaly score to each
window, though the self match issue, discussed earlier,
needs to be explicitly handled.
Using Techniques for Problem Formulation 2 to solve
Problem Formulation 1: If all training sequences in S
and the given test sequence Sq in problem formulation
1 are arranged linearly, in no particular order, a long
sequence can be constructed. An anomaly detection
technique discussed to handle problem formulation 2
can be applied to detect all anomalous ﬁxed length
windows. The anomaly score of the test sequence Sq can
be assigned as equal to the number of windows of Sq
that are detected as discords. The key issue with this
adaptation is that the entire test sequence will be compared (as a window) with other the training sequences,
and hence will face same challenges as the kernel based
techniques discussed in Section 4.1. Another issue with
this approach is that the windows which span across two
sequences are an artifact of the concatenation and might
affect the performance of the technique.
DETERMINING
ANOMALOUS W.R.T ITS EXPECTED FREQUENCY
Techniques under this category solve the following
anomaly detection problem:
Deﬁnition 3: Given a short query pattern s, a long
test sequence S and a training set of long sequences S,
determine if the frequency of occurrence of s in S is
anomalous with respect to frequency of occurrence of s
This problem has also been referred to as surprise detection in the context of time series data , . Keogh et
al deﬁne a pattern to be surprising “if the frequency of
the pattern differs substantially from that expected by chance,
given some previously seen data”. Note that patterns with
both greater or smaller frequencies are of interest.
The above formulation is motivated from Scenario 3
discussed in Section 3 where a pattern is anomalous if
its frequency in the given sequence is signiﬁcantly different from its expected frequency in normal sequences.
Another possible motivation for this formulation could
be in the case vs control analysis , popular in epidemiological studies. The idea is to detect patterns whose
occurrence in a given test data set (case) is different
from its occurrence in a normal data set (control). Such
techniques aim to prioritize the patterns (s) existing in a
known anomalous sequence (S) based on their frequency
A Basic Technique to Solve Problem Formulation 1
A basic technique to solve the above problem assigns
an anomaly score to the query pattern s, as follows:
Count the number of occurrences of the query pattern
in the sequence S and all sequences in S, and compute
the anomaly score for s as the difference between the
number of times s occurs in S and the expected number
of times s occurs in any sequence in S.
More formally, the following two quantities may be
deﬁned, ¯fS(s) and ¯fS(s):
¯fS(s) is the frequency with which the query pattern
occurs in the test sequence S, normalized by the length
of S, and can be directly computed as:
¯fS(s) = fS(s)
¯fS(s) is the expected frequency of the query pattern
to occur in a sequence in S normalized by the length of
the sequence. ¯fS(s) can be estimated as:
¯fS(s) = 1
The anomaly score of the query pattern s is computed
A(s) = | ¯fS(s) −¯fS(s)|
Variations of the Basic Technique
In the basic technique a query pattern s is considered to
“occur” in a sequence if s is a substring of the sequence.
An issue with considering substrings is that it forces
the query pattern to occur exactly. If s is long, it is
unlikely for entire s to occur in a training sequence.
Another issue is that in several domains, it might be
reasonable to assume that the symbols of the query
pattern can occur interspersed with other symbols, and
hence only considering substring matches will miss such
occurrences. To address these issues, following three
variations of the basic technique have been proposed:
• Counting the number of times a substring of the query
pattern s occurs in a sequence. Keogh et al ﬁnd
the largest l in the interval [1, |s|), such that every
l length substring of s occurs at least once in the
training sequences. The frequency fS(s) from (14) is
then replaced with the following quantity:
j=1 fS(s[j, j + l])
j=2 fS(s[j, j + l −1])
where s[j, k] denotes the substring of s starting at jth
location of s and ending at the kth location. The idea is
to estimate the occurrence of the query pattern s using a
set of substrings of s. By searching for a set in which all
substrings occur at least once, the frequency estimation
is more reliable.
• Counting the number of times the query pattern s occurs
as a subsequence in a sequence. An issue with the basic
technique is that counting the number of times s occurs
as a subsequence in a long sequence is expensive. To
make the formulation more tractable, Gwadera et al 
extract all windows of a ﬁxed length (greater than the
length of s), from the sequence and then determine
all those windows that contain s as a subsequence.
Thus a query pattern s is considered to “occur” in
a sequence if there exists a window such that s is a
subsequence of the given window. The number of ﬁxedlength windows which contain s as a subsequence are
counted. These counts are used as fS(s) and fSi(s) in
(13) and (14), respectively.
• Counting the number of times any permutation of the
query pattern s occurs in a sequence. This alternative was
proposed by Gwadera et al as an extension to the
subsequence based technique . For the permutation
approach, the number of ﬁxed-length windows which
contain any permutation of s are counted. The motivation behind considering all permutations is that in
certain scenarios, the ordering of events (or symbols)
within the query pattern s do not matter.
Issues with the Basic Technique
The basic technique and its variations have following
two key issues:
Computational Complexity
For each query pattern, the time required to compute its
anomaly score is linear in the length of S and the length
and number of sequences in S. If there are multiple
query patterns, e.g., all short subsequences that occur
in S, the total time required to score all query patterns
adds up to a high value. To address this issue, Keogh et
al proposed a technique called TARZAN , which
uses sufﬁx trees to efﬁciently compute the frequency of
occurrence of a query pattern in a given sequence. Sufﬁx
trees are created for S and for each sequence in S1. Only
two sufﬁx trees are required, one for the sequences in
S and for the sequence S, and can be constructed with
complexity linear in the length of the sequences. The
counts for a query pattern s, can be obtained with complexity linear in the length of s. Gwadera et al 
use Interpolated Markov Models (IMM) to efﬁciently
ﬁnd the number of windows extracted from a sequence
that contain the query pattern or its permutations, as a
subsequence.
Scoring of Anomalies
The basic technique assigns an anomaly score to the
query pattern (14) but does not declare if the query
pattern is anomalous or not. For the TARZAN technique,
since there are multiple query patterns to be scored,
a relative ordering can be obtained using the anomaly
scores, and top few patterns with highest scores could
be declared as anomalous. But if there is only one query
pattern, a method is needed for declaring the query
pattern to be anomalous or normal, based on its anomaly
score. Gwadera et al address this issue by assuming
a statistical distribution for ¯fS(s). Instead of computing
the anomaly score for a query pattern as shown in
(15), a statistical test is applied to determine if ¯fS(s) is
generated by the same distribution.
Relationship Between Techniques Solving Problem Formulation 1 and Problem Formulation 3
The techniques that solve problem formulation 3 assign
an anomaly score to a short pattern s. The basic window
based technique discussed in Section 4.2, that handles
problem formulation 1, assigns an anomaly score to
each short window belonging to the test sequence. Both
techniques appear to be similar in this step, but they
are actually quite distinct. While the basic technique
discussed in this section assigns an anomaly score to a
pattern based on its frequency in the test sequence and
its expected frequency in normal sequences, the basic
window based technique assigns an anomaly score to a
window based on only its expected frequency in normal
sequences. To be more precise, the basic window based
technique that solves problem formulation 1 essentially
uses ¯fS(s) as the anomaly score of each window, while
1. TARZAN was originally proposed to handle the case when S
contains only one sequence.
the basic technique that solves problem formulation
3 compares this value with the normalized frequency
of occurrence of the window in the test sequence to
compute its anomaly score (See (15)).
Nevertheless, techniques for problem formulation 3
can also be used to ﬁnd certain types of anomalies
in the context of problem formulation 1. An alternate
cause of anomaly could be that a test sequence is
anomalous because it contains one or more patterns
whose frequency of occurrence in the test sequence is
signiﬁcantly different from their frequency of occurrence
in the training sequences. Such anomalous sequences
can be detected as follows: For the given test sequence,
ﬁxed length windows are extracted. Each window is
assigned an anomaly score using the basic technique that
solves problem formulation 3. The anomaly scores of all
windows are aggregated to obtain an overall anomaly
score for the test sequence.
ONLINE ANOMALY DETECTION
Several application domains collect sequence data in a
streaming fashion , e.g., system call data collected by
a computer system, data generated by an aircraft during
its ﬂight, etc. Such domains, often require the anomalies
to be detected in such sequences in an online fashion,
i.e., as soon as they occur , . Online anomaly
detection has the advantage that it can allow analysts
to undertake preventive or corrective measures as soon
as the anomaly is manifested in the sequence data.
For example, in aircraft health monitoring, the current
ﬂight sequence for an aircraft is tested if it is anomalous
or not, with respect to a database of historical normal
ﬂight sequences of the aircraft. Determining that the
current ﬂight sequence has an anomaly, as soon as it
occurs (even before the entire ﬂight sequence is collected)
might help the health monitoring system to raise an early
Among the different categories of techniques that
handle the problem formulation 1, some can be easily
adapted to operate in an online fashion. The window
based and Markovian techniques assign anomaly score
to windows (or symbols) as they are collected. By applying a threshold on the anomaly score, the sequence
can be declared to be anomalous even before observing
the entire sequence. Hence such techniques can be easily
adapted to operate in an online fashion. In contrast,
kernel based techniques measure the similarity of entire
test sequence with training sequences, and hence are not
suitable for online detection problem.
Techniques that handle the problem formulation 2 can
be easily adapted to detect anomalies in an online fashion. In the online setting each successive subsequence of
symbols is assigned an anomaly score with respect to the
sequence observed so far. A threshold on the score computed for each window can be used to declare it to be
normal or anomalous, as soon as it is observed. To obtain
reliable anomaly scores, such techniques might require
to observe a signiﬁcantly long portion of the sequence
initially before scoring the incoming subsequences.
Problem formulation 3 is more difﬁcult to handle in
an online setting, in which the test sequence S is being
collected in an online fashion. This setting poses a challenge to techniques discussed in Section 6, because the
frequency of occurrence of the query pattern in the test
sequence will have to be estimated without observing
the entire test sequence.
CONCLUDING REMARKS
This survey has attempted to provide a structured and
comprehensive overview of the research on the problem of anomaly detection for discrete sequences. The
survey covers techniques developed independently for
different domains and thus opens up the possibility of
applying techniques developed within one domain to
a completely different setting. In addition, this broad
survey makes it possible to envision a rich set of possibilities for extension of the current state of art along
different dimensions. Besides serving as a structured
and comprehensive review of the existing research, the
survey provides a rich set of possible techniques that
can be developed by extending the current state of art
in different directions. Such possibilities are not obvious
without conducting such global study of the problem.
One of the most interesting aspect of the problem of
anomaly detection for sequences is the rich diversity of
problem formulations. In this survey we have discussed
three different problem formulations that are relevant in
varied application domains.
For each problem formulation we have identiﬁed distinct groups of techniques that use a speciﬁc approach to
detect anomalies. Within each of these groups we have
provided a basic technique and shown how different
existing techniques are variations of the corresponding basic technique. We also provide the motivation
behind the different variations and the strengths and
weaknesses associated with the different categories of
techniques. This results in a better understanding of
the current state of research as well as allows future
researchers to develop novel variations. For example, in
the kernel based techniques for problem formulation 1
(Section 4.1), we observe that by using a different combination of a point based anomaly detection algorithm
and a similarity measure, a different anomaly detection
technique can be developed. Similarly, by using different
techniques to compare a pair of windows, one can
develop novel variations of the basic window based
technique discussed in Section 5.1. In addition, we have
also discussed how techniques from one problem formulation can be adapted to solve a different formulation,
thereby enriching the set of techniques to choose from,
for a given formulation.
Although the focus of this survey article has been on
discrete sequences, many of the techniques discussed
here are also applicable to continuous sequences (or time
series). For example, kernel based techniques can be
adapted for continuous sequences by using an appropriate similarity/distance kernel, such as Euclidean Distance
 , and Cross Correlation , . Window based
techniques can be adapted by using the Euclidean distance to kth closest window from the training sequence
set to assign anomaly score to the window . Markovian techniques can be adapted by substituting the
Markovian model with a time series prediction model,
which can determine the likelihood of observing a real
valued event, given a ﬁnite history of events . HMM
based techniques can be adapted by using a continuous
version of HMM . While some of these adaptations
have already been proposed, others are subject of future
This article has focused on techniques that deal with
univariate discrete sequences. Many real world applications deal with sequences of multivariate events, where
the events might contain discrete, continuous, or a mixed
set of observations . Some of the techniques discussed in this article are relevant to such settings, though
additional thought still needs to be given to how to
handle such complex sequences. For example, kernel and
window based techniques for problem formulation 1, as
well as the basic technique for problem formulation 2 can
be easily extended to multivariate sequences as long as
a similarity measure can be developed to compare two
multivariate discrete sequences. Such techniques have
not been tried yet, but need to be investigated in future.
ACKNOWLEDGEMENT
NNX08AC36A, NSF Grant CNS-0551551 and NSF Grant
IIS-0713227. Access to computing facilities was provided by
the Digital Technology Consortium.