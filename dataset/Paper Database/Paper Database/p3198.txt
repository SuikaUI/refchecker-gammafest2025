Speech Translation and the End-to-End Promise:
Taking Stock of Where We Are
Matthias Sperber
 
Matthias Paulik
 
Over its three decade history, speech translation has experienced several shifts in its primary research themes; moving from loosely
coupled cascades of speech recognition and
machine translation, to exploring questions
of tight coupling, and ﬁnally to end-to-end
models that have recently attracted much attention.
This paper provides a brief survey
of these developments, along with a discussion of the main challenges of traditional approaches which stem from committing to intermediate representations from the speech recognizer, and from training cascaded models separately towards different objectives.
end-to-end
techniques
promise a principled way of overcoming
these issues by allowing joint training of
all model components and removing the
need for explicit intermediate representations.
However, a closer look reveals that many
end-to-end models fall short of solving these
issues, due to compromises made to address
data scarcity. This paper provides a unifying
categorization and nomenclature that covers
both traditional and recent approaches and
that may help researchers by highlighting both
trade-offs and open research questions.
Introduction
Speech translation (ST), the task of translating
acoustic speech signals into text in a foreign language, is a complex and multi-faceted task that
builds upon work in automatic speech recognition
(ASR) and machine translation (MT). ST applications are diverse and include travel assistants
 , simultaneous lecture translation , movie dubbing/subtitling , language documentation and crisis response , and developmental efforts .
Until recently, the only feasible approach has
been the cascaded approach that applies an ASR
to the speech inputs, and then passes the results
on to an MT system. Progress in ST has come
from two fronts: general improvements in ASR and
MT models, and moving from the loosely-coupled
cascade in its most basic form toward a tighter
coupling. However, despite considerable efforts
toward tight coupling, a large share of the progress
has arguably been owed simply to general ASR and
MT improvements.1
Recently, new modeling techniques and in particular end-to-end trainable encoder-decoder models
have fueled hope for addressing challenges of ST
in a more principled manner. Despite these hopes,
the empirical evidence indicates that the success
of such efforts has so far been mixed .
In this paper, we will attempt to uncover potential reasons for this. We start by surveying models
proposed throughout the three-decade history of ST.
By contrasting the extreme points of loosely coupled cascades vs. purely end-to-end trained direct
models, we identify foundational challenges: erroneous early decisions, mismatch between spokenstyle ASR outputs and written-style MT inputs, and
loss of speech information (e.g. prosody) on the
one hand, and data scarcity on the other hand. We
then show that to improve data efﬁciency, most endto-end models employ techniques that re-introduce
issues generally attributed to cascaded ST.
Furthermore, this paper proposes a categorization of ST research into well-deﬁned terms for
the particular challenges, requirements, and techniques that are being addressed or used. This multidimensional categorization suggests a modeling
1For instance, Pham et al. ’s winning system in the
IWSLT 2019 shared ST task makes
heavy use of recent ASR and MT modeling techniques, but is
otherwise a relatively simple cascaded approach.
 
space with many intermediate points, rather than
a dichotomy of cascaded vs. end-to-end models,
and reveals a number of trade-offs between different modeling choices. This implies that additional
work to more explicitly analyze the interactions
between these trade-offs, along with further model
explorations, can help to determine more favorable
points in the modeling space, and ultimately the
most favorable model for a speciﬁc ST application.
Chronological Survey
This chapter surveys the historical development
of ST and introduces key concepts that will be
expanded upon later.2
Loosely Coupled Cascades
Early efforts to realize ST introduced what we
will refer to as the loosely coupled cascade in
which separately built ASR and MT systems are
employed and the best hypothesis of the former
is used as input to the latter. The possibility of
speech-to-speech translation, which extends the
cascade by appending a text-to-speech component,
was also considered early on .
These early systems were especially susceptible to errors propagated from the ASR, given the
widespread use of interlingua-based MT which relied on parsers unable to handle mal-formed inputs
 . Subsequent systems Wang and Waibel
 ; Takezawa et al. ; Black et al. ;
Sumita et al. , relying on data driven, statistical MT, somewhat alleviated the issue, and also
in part opened the path towards tighter integration.
Toward Tight Integration
Researchers soon turned to the question of how
to avoid early decisions and the problem of error
propagation. While the desirable solution of full integration over transcripts is intractable ,
approximations are possible. Vidal ; Bangalore and Riccardi ; Casacuberta et al. ;
P´erez et al. compute a composition of FSTbased ASR and MT models, which approximates
the full integration up to search heuristics, but suffers from limited reordering capabilities. A much
2For a good comparison of empirical results, which are not
the focus of this paper, we refer to concurrent work . Moreover, for conciseness we do not cover the
sub-topic of simultaneous translation .
simpler, though computationally expensive, solution is the n-best translation approach which replaces the sum over all possible transcripts by a
sum over only the n-best ASR outputs . Follow-up work
suggested lattices and confusion nets as more effective and efﬁcient alternatives to n-best lists. Lattices proved ﬂexible
enough for integration into various translation models, from word-based translation models to phrasebased ST Matusov et al. to neural
lattice-to-sequence models .
Another promising idea was to limit the detrimental effects of early decisions, rather than attempting to avoid early decisions. One way of
achieving this is to train robust translation models
by introducing synthetic ASR errors into the source
side of MT corpora . A different route is
taken by Dixon et al. ; He et al. who
directly optimize ASR outputs towards translation
Beyond early decisions, research moved towards
tighter coupling by addressing issues arising from
ASR and MT models being trained separately and
on different types of corpora. Domain adaptation
techniques were used by Liu et al. ; F¨ugen
 to adapt models to the spoken language domain. Matusov et al. ; F¨ugen propose
re-segmenting the ASR output and inserting punctuation, so as to provide the translation model with
well-formed text inputs. In addition, disﬂuency removal was proposed to
avoid translation errors caused by disﬂuencies that
are often found in spoken language.
Aguero et al. ; Anumanchipalli et al.
 ; Do et al. ; Kano et al. propose
prosody transfer for speech-to-speech translation
by determining source-side prosody and applying
transformed prosody characteristics to the aligned
target words.
Speech Translation Corpora
It is important to realize that all efforts to this point
had used separate ASR and MT corpora for training. This often led to a mismatch between ASR
trained on data from the spoken domain, and MT
trained on data from the written domain. End-toend ST data (translated speech utterances) was
only available in small quantities for test purposes.
Paulik proposes the use of audio recordings of interpreter-mediated communication scenarios, which is not only potentially easier to obtain,
but also does not exhibit such domain mismatches.
Post et al. manually translate an ASR corpus to obtain an end-to-end ST corpus, and show
that training both ASR and MT on the same corpus
considerably improves results compared to using
out-of-domain MT data. Unfortunately, high annotation costs prevent scaling of the latter approach,
so follow-up work concentrates on compiling ST
corpora from available web sources . Note that despite
these efforts, publicly available ST corpora are currently strongly limited in terms of both size and
language coverage. For practical purposes, the use
of separate ASR and MT corpora is therefore currently unavoidable.
End-to-End Models
The availability of end-to-end ST corpora, along
with the success of end-to-end models for MT and
ASR, led researchers to explore ST models trained
in an end-to-end fashion. This was fueled by a hope
to solve the issues addressed by prior research in
a principled and more effective way. Duong et al.
 ; Berard et al. ; Bansal et al. explore direct ST models that translate speech without using explicitly generated intermediate ASR
output. In contrast, Kano et al. ; Anastasopoulos and Chiang ; Wang et al. 
explore end-to-end trainable cascades and triangle models, i.e. models that do rely on transcripts,
but are optimized in part through end-to-end training. Multi-task training and pre-training were
proposed as a way to incorporate additional ASR
and MT data and reduce dependency on scarce
end-to-end data . As these techniques were not able
to exploit ASR and MT data as effectively as the
loosely coupled cascade, other approaches like subtask training for end-to-end-trainable cascades
 , data augmentation , knowledge distillation , and meta-learning were proposed. Salesky et al.
Figure 1: Illustration of inference strategies (§4.2):
Committed/marginalizing
(Di), committed/marginalizing triangle (CT/MT), joint
(Jt). Double lines differentiate the observed variable
(speech input X) from random variables (intermediate
representations IR and translations T). Shaded circles
marginalize over random variables.
 propose pre-segmenting speech frames,
 explore
speech-to-speech translation. Sung et al. ;
di Gangi et al. ; Di Gangi et al. ; Bahar et al. ; Inaguma et al. ; di Gangi
et al. transfer ideas from MT and ASR
ﬁelds to ST.
Central Challenges
Given the abundance of prior work, a clear picture on where we currently stand is needed. For
purposes of identifying the key challenges in ST research, this section will contrast the extreme cases
of the loosely coupled cascade (CC in Fig. 1)3
against the vanilla direct model (Di in Fig. 1).4
We emphasize that these models are only extreme
points in a modeling space with many intermediate
points, as we will see in §4. We assume appropriate speech features X as inputs. T, ˆT ∈T denote
candidate/best translations, respectively, from the
MT hypothesis space. S∈H denotes a graphemic
transcript from the ASR hypothesis space.
Challenges of Loosely Coupled Cascades
The loosely coupled cascade justiﬁes its decomposition into MT model PMT (T∣S) and ASR model
PASR (S∣X) as follows:
3ASR and MT models trained separately on different corpora; intermediate representation is ASR 1-best output.
4Encoder-decoder model trained on speech utterances
paired with translations; no intermediate representations used.
ˆT = argmax
P (T∣S,X)P (S∣X)
PMT (T∣S)PASR (S∣X)
S∈H′ PMT (T∣S)PASR (S∣X)
Note that here the set H′ contains only a single
entry, the 1-best ASR output. The approximations
in these derivations directly result in the following
three foundational challenges:
Erroneous early decisions:
Committing to a potentially erroneous S during inference. This leads
to the well-known problem of error propagation
 and is caused by avoiding the intractable full integration over transcripts
(Eq. 3) and using only the 1-best ASR output instead (Eq. 4). Typical countermeasures include
increasing H′ to cover a larger space using lattices
or confusion nets, or improving the robustness of
MT models.
Mismatched source-language:
ASR and MT
components model the source-language (transcript)
priors PMT(S) and PASR(S) differently.5 Causes
include both modeling assumptions, e.g. ASR
modeling only unpunctuated transcripts; and mismatched training data, leading to stylistic and topical divergence. Typical countermeasures are domain adaptation techniques, disﬂuency removal,
text normalization, and segmentation/punctuation
insertion.
Information loss:
Assumed conditional independence between inputs and outputs, given the transcript: (T á X) ∣S. This can be seen in Eq. 3 and
results in any information not represented in S to
be lost for the translation step. In particular, the MT
model is unaware of prosody which structures and
disambiguates the utterances, thus playing a role
similar to punctuation in written texts; and provides
ways to emphasize words or parts of the messages
that the speaker think are important. Prosody also
conveys information on the speaker’s attitude and
emotional state .
5Note that our deﬁnition does not entail covariance shift
and other forms of domain mismatch 
which, though relevant, are not unique to cascaded ST and are
widely covered by general ASR and MT literature .
Challenges of the Vanilla Direct Model
Consider instead the other extreme case:
encoder-decoder model trained to directly produce
translations from speech (Eq. 1). Because this
model avoids the decomposition in Eq. 2-4, it is not
subject to the three issues outlined in §3.1. Unfortunately, this second extreme case is often impractical due to its dependency on scarce end-to-end
ST training corpora (§2.3), rendering this model
unable to compete with cascaded models that are
trained on abundant ASR and MT training data.
Most recent works therefore depart from this
purely end-to-end trained direct model, and incorporate ASR and MT back into training, e.g. through
weakly supervised training, or by exploring end-toend trainable cascades or triangle models (CT/MT in
Fig. 1). This departure raises two questions: (1) To
what extent does the re-introduction of ASR and
MT data cause challenges similar to those found in
loosely coupled cascades? (2) Are techniques such
as weakly supervised training effective enough to
allow competing with the loosely coupled cascade?
To address the second question, we propose the
notion of data efﬁciency as a fourth key challenge.
Data efﬁciency:
The increase in accuracy
achievable through the addition of a certain
amount of training data. To assess data efﬁciency,
data ablations that contrast models over at least
two data conditions are required. We argue that
empirical evidence along these lines will help considerably in making generalizable claims about the
relative performance between two ST models. Generalizable ﬁndings across data conditions are critical given that ST models are trained on at least
three types of corpora (ASR, MT, and end-to-end
corpora), whose availability vastly differs across
languages.
Data Efﬁciency vs. Modeling Power – A
Trade-Off?
Consider how the incorporation of MT and ASR
data into ST models of any kind may inherently
cause the problems as outlined in §3.1: Training on MT data may weaken the model’s sensitivity to prosody; the effectiveness of training on
ASR+MT data may be impacted by mismatched
source-language issues; even some types of endto-end-trainable models make (non-discrete) early
decisions that are potentially erroneous.
This suggests a potential trade-off between data
efﬁciency and modeling power. In order to ﬁnd
kochira wa suekko no lucy desu
this is my niece , lucy
こちら　は　姪っ子　の　ルーシー　です　。
lucy, kono ko ga watashi no suekko desu
this is my niece , lucy
ルーシー　、　この　子　が　私　の　姪っ子　です　。
chiizu toka jamu toka, dore ni shimasu ka
will you have Ĺ£cheese or Ĺ£jam
チーズ　とか　ジャム　とか、　どれ　に　します　か　？
chiizu ka jamu, docchi ni shimasu ka
will you have Ĺ£cheese or Ď£jam
チーズ　か　ジャム、　どっち　に　します　か　？
Table 1: Motivating examples for prosody-aware translation from English to Japanese. In the ﬁrst example, prosody
disambiguates whether the speaker is talking about Lucy as a third person or directly addressing Lucy. In the second
example, prosody disambiguates whether cheese or jam is an open set or a closed set. In both cases, the surface
form of the Japanese translation requires considerable changes depending on the prosody.
models that trade off advantages and disadvantages
in the most favorable way, it is therefore necessary to thoroughly analyze models across the dimensions of early decisions, mismatched sourcelanguage, information loss, and data efﬁciency.
Analyzing early decisions:
Problems due to erroneous early decisions are inference-time phenomena in which upstream ASR errors are responsible
for errors in the ﬁnal translation outputs. It follows
that the problem disappears for hypothetical utterances for which the ASR can generate error-free
intermediate representations. Thus, models that
do not suffer from erroneous early decisions will
expectedly exhibit an advantage over other models especially for acoustically challenging inputs,
and less so for inputs with clean acoustics. This
angle can provide us with strategies for isolating
errors related to this particular phenomenon. Prior
work in this spirit has demonstrated that lattice-tosequence translation is in fact beneﬁcial especially
for acoustically challenging inputs , and that cascaded models with non-discrete
intermediate representations are less sensitive to
artiﬁcially perturbed intermediate representations
than if using discrete transcripts as an intermediate
representation .
Analyzing mismatched source-language:
Endto-end ST corpora allow for controlled experiments
in which one can switch between matched vs. mismatched (out-of-domain) MT corpora. Post et al.
 demonstrated that using a matched corpus
can strongly improve translation quality for loosely
coupled cascades. We are not aware of such analyses in more recent work.
information
 has addressed
prosody transfer in speech-to-speech translation,
but to our knowledge the question of how such
information should inform textual translation
decisions is still unexplored.
Table 1 shows
examples that may motivate future work in this
direction.
Analyzing data efﬁciency:
While several prior
works aim at addressing this problem, often only a
single data condition is tested, limiting the generalizability of ﬁndings. We are aware of three recent
works that do analyze data efﬁciency across several
data conditions . Findings indicate that
both pretraining and data synthesizing outperform
multi-task training in terms of data efﬁciency, and
that end-to-end trainable cascades are on par with
loosely coupled cascades, while strongly outperforming multi-task training.
Modeling Techniques
Let us now break apart modeling techniques from
prior literature into four overarching categories,
with the aim of exposing the ST modeling space
between the extreme points of vanilla direct models
and loosely coupled cascades.
Intermediate Representations
Almost all models use intermediate representations
(IRs) in some form: non-direct models to support
both training and inference, and direct models to
overcome data limitations. IRs are often speech
transcripts, but not necessarily so. A number of
factors must be considered for choosing an appropriate IR, such as availability of supervised data,
inference accuracy, expected impact of erroneous
early decisions, and the feasibility of backpropagation through the IR for end-to-end training. We list
several possibilities below:
Transcripts:
Generally used in the loosely coupled cascade.
Being a discrete representation,
this option prevents end-to-end training via backpropagation, although future work may experiment
with work-arounds such as the straight-through
gradient estimator . Besides
graphemic transcripts, phonetic transcripts are another option .
Hidden representations:
Kano et al. ;
Anastasopoulos and Chiang ; Sperber et al.
 propose the use of hidden representations
that are the by-product of a neural decoder generating an auxiliary IR such as a transcript. Advantages
of this representation are differentiability, prevention of information loss, and weakened impact of
erroneous early decisions. A downside is that endto-end ST data is required for training.
Lattices compactly represent the space
over multiple sequences, and therefore weaken the
impact of erroneous early decisions. Future work
may explore lattices over continuous, hidden representations, and end-to-end training for ST models
with lattices as intermediate representation.
presegmented speech frames or
unsupervised speech-unit clusters as intermediate representation.
possibilities may be explored in future work.
Inference Strategies
The conditioning graph (Fig. 1) reveals independence assumptions and use of IRs at inference time.
Some strategies avoid the problem of early decisions (MC, Di, MT, Jt), while others remove the
conditional independence assumption between inputs and outputs (Di, CT, MT, Jt).
Committed cascade (CC):
Compute one IR, rely
on it to generate outputs (Eq. 4). Includes both the
loosely coupled cascade, and recent end-to-end
trainable cascaded models such as by Kano et al.
 ; Sperber et al. .
Marginalizing cascade (MC):
Compute outputs
by relying on IRs, but marginalize over them instead of committing to one (Eq. 3). As marginalization is intractable, approximations such as n-best
translation or lattice translation are generally used.
Direct (Di):
Compute outputs without relying on
IRs (Eq. 1). To address data limitations, techniques
such as multi-task training or data augmentation
can be used, but may reintroduce certain biases.
Committed triangle (CTr):
Commit to an IR,
then produce outputs by conditioning on both inputs and intermediate representation.
Anastasopoulos and Chiang , who introduce the
triangle model, use it in its marginalizing form (see
below). Unexplored variations include the use of
discrete transcripts as IR, which interestingly could
be seen as a strict generalization of the loosely coupled cascade and should therefore never perform
worse than it if trained properly.
Marginalizing triangle (MTr):
Produce output
by conditioning on both input and IR, while
marginalizing over the latter (Eq. 2). Anastasopoulos and Chiang marginalize by taking an
n-best list, with n set to only 4 for computational
reasons. This raises the question of whether the
more computationally efﬁcient lattices could be
employed instead. Similar considerations apply to
the end-to-end trainable marginalizing cascade.
Joint (Jt):
Changes the problem formulation to
ˆS, ˆT = argmaxS∈H,T∈T Pr (S,T ∣X). This is a
useful optimization for many applications which
display both transcripts and translations to the user,
yet to our knowledge has never been explicitly addressed by researchers.
Training Strategies
This group of techniques describes the types of
supervision signals applied during training.
Subtask training:
Training of sub-components
by pairing IRs with either the speech inputs or the
output translations. Loosely coupled cascades rely
on this training technique while recently proposed
cascaded and triangle models often combine subtask training and end-to-end training.
Auxiliary task training:
Training by pairing either model inputs or outputs with data from an
arbitrary auxiliary task through multi-task training.6 This technique has been used in two ways
in literature: (1) To incorporate ASR and MT data
into direct models by using auxiliary models that
share parts of the parameters with the main model
 . Auxiliary models are introduced for training purposes only, and discarded
during inference. This approach has been found
6This deﬁnition subsumes pretraining, which is simply
using a speciﬁc multitask training schedule.
inferior at exploiting ASR and MT data when compared to subtask training .
(2) To incorporate various types of less closely
related training data, such as the use of multitask
training to exploit ASR data from an unrelated third
language .
End-to-end:
Supervision signal that directly
pairs speech inputs and output translations. This
technique is appealing because it jointly optimizes
all involved parameters and may lead to better optima. The main limitation is lack of appropriate
data, which can be addressed by combined training
with one of the alternative supervision types, or by
training on augmented data, as discussed next.
End-to-End Training Data
Speech utterances for training are
translated (and possibly transcribed) by humans.
This is the most desirable case, but such data is
currently scarce. While we have seen growth in
data sources in the past two years (§2.3), collecting
more data is an extremely important direction for
future work.
Augmented:
Data obtained by either augmenting an ASR corpus with automatic translations, or
augmenting an MT corpus with synthesized speech.
This has been shown more data efﬁcient than multitask training in the context of adding large MT and
ASR corpora . Pino et al. 
ﬁnd that augmented ASR corpora are more effective than augmented MT corpora. This approach allows training direct models and end-to-end models
even when no end-to-end data is available. Knowledge distillation can be seen as an extension . An important problem that needs analysis is to what extent mismatched source-language
and information loss degrade the augmented data.
Zero-Shot:
Using no end-to-end data during
training. While augmented data can be used in
most situations in which no manual data is available, it suffers from certain biases that may harm
the ST model. Similarly to how zero-shot translation enables translating between unseen combinations of source and target languages, it may be
worth exploring whether some recent models, such
as direct models or cascades with non-discrete IRs,
can be trained without resorting to any end-to-end
data for the particular language pair of interest.
Applications and Requirements
While we previously described the task of ST simply as the task of generating accurate text translations from speech inputs, the reality is in fact
much more complicated. Future work may exploit
new modeling techniques to explicitly address the
aspects drawn out below.
Mode of Delivery
Batch mode:
A (potentially large) piece of
recorded speech is translated as a whole. Segmentation into utterances may or may not be given.
This mode allows access to future context, and
imposes no strict computational restrictions. Typical applications include movie subtitling and dubbing .
Consecutive:
Real-time situation where inputs
are provided as complete utterances or other translatable units, and outputs must be produced with
low latency. A typical example is a two-way translation system on a mobile device . This is the only mode of delivery that allows
interaction between speaker and translator .
Simultaneous:
Real-time situation where latency is crucial and outputs are produced incrementally based on incoming audio stream. Simultaneous translation is faced with an inherent delay
vs. accuracy trade-off, such as in a typical lecture
translation application . In addition
to computational latency, which is relevant also
with consecutive translation, simultaneous translation suffers from inherent modeling latency caused
by factors including reordering.
Output Medium
This is a standard setting, but is nevertheless worth discussing in more detail for at least two
reasons: (1) as is well-known in the subtitling industry, reading speeds can be slower than speaking
and listening speeds , implying that a recipient may not be able to follow verbatim text translations in case of fast speakers, and
that summarization may be warranted. (2) Text display makes repair strategies possible that are quite
distinct from spoken outputs: One can alter, highlight, or remove past outputs. One possible way of
exploiting this is Niehues et al. ’s strategy of
simultaneous translation through re-translation.
tambi´en tengo um eh estoy tomando una clase ..
i also have um eh i’m taking a marketing class ..
porque qu´e va, mja ya te acuerda que ..
because what is, mhm do you recall now that ..
Table 2: Examples for faithful Spanish to English translations, taken from .
Speech outputs have been used since the
early days , but whether to apply
text-to-speech on top of translated text has often
been seen as a question to leave to user interface designers. Here, we argue that ST researchers should
examine in what ways speech outputs should differ
from text outputs. For example, is disﬂuency removal beneﬁcial for speech
outputs, given that human listeners are naturally
able to repair disﬂuencies ? Further
examples that need more exploration are prosody
transfer and models that directly translate speech-to-speech .
The Role of Transcripts
Mandatory transcripts:
User interface displays
both transcripts and translations to the user. This
scenario has been implemented in many applications , but has
received little attention in the context of end-to-end
ST research. It ties together with the joint inference
model (§4.3). Note that with loosely coupled cascades, there is little need to consider this scenario
explicitly because the application can simply display the by-product transcripts to the user. But this
is not easily possible with direct models or with
models using IRs other than transcripts.
Auxiliary transcripts:
Transcriptions are not
needed as user-facing model outputs, but may be
exploited as IRs during training and possibly inference. This is the most typical formal framing of the
ST task, assuming that transcribed training data is
useful mainly for purposes of improving the ﬁnal
translation.
Transcript-free:
No transcribed training data
exists, so the model cannot rely on supervised transcripts as IR. The main scenario is endangered
language preservation for languages without written script, where it is often easier to collect translated speech than transcribed speech for
a more nuanced categorization.
Keeps the contextual meaning of the
original as precisely as possible within the grammatical constraints of the target language. With
text as output medium, faithful translation may result in poor readability, e.g. due to the translation
of disﬂuencies (Table 2). Arguably the most appropriate output medium for faithful ST would be
speech, although user studies are needed to conﬁrm
this. Another application are high-stake political
meetings in which translations must stay as close
to the original sentence as possible. As we move
toward more distant language pairs, the practicability of faithful translation of spoken language with
disﬂuencies becomes increasingly questionable.
Communicative:
Renders the contextual meaning of the original such that both content and style
are acceptable and comprehensible by the target
audience. An important example for improving
communicativeness is disﬂuency removal . Given that human translators and
interpreters adapt their translation method depending on factors that include input and output medium
 , more research is needed beyond
disﬂuency removal. Communicative translations
are especially relevant in casual contexts where convenience and low cognitive effort are mandative.
Arguably the closest neighbor of spoken language
style in the text realm is social media, it would
be interesting to attempt speech-to-text translation
with social-media style outputs.
Discussion
Recent works on end-to-end modeling techniques
are motivated by the prospect of overcoming the
loosely coupled cascade’s inherent issues, yet of the
issues outlined in §2.1, often only the goal of avoiding early decisions is mentioned motivationally.
While early decisions and data efﬁciency have been
recognized as central issues, empirical insights are
still limited and further analysis is needed. Mismatched source-language and information loss are
often not explicitly analyzed.
We conjecture that the apparent trade-off between data efﬁciency and modeling power may
explain the mixed success in outperforming the
loosely coupled cascade. In order to make progress
in this regard, the involved issues (early decisions, mismatched source-language, information
loss, data efﬁciency) need to be precisely analyzed
(§3), and more model variants (§4) should be explored. As a possible starting point one may aim
to extend, rather than alter, traditional models, e.g.
applying end-to-end training as a ﬁne-tuning step,
employing a direct model for rescoring, or adding
a triangle connection to a loosely coupled cascade.
We further suggest that more principled solutions to
the different application-speciﬁc requirements (§5)
should be attempted. Perhaps it is possible to get
rid of segmentation as a separate step in batch delivery mode, or perhaps text as output medium can be
used to visualize repairs more effectively. Several
of the application-speciﬁc requirements demand
user studies and will not be sufﬁciently solved by
relying on automatic metrics only.
Conclusion
We started this paper with a chronological survey of
three decades of ST research, focusing on carving
out the key concepts. We then provided deﬁnitions
of the central challenges, techniques, and requirements, motivated by the observation that recent
work does not sufﬁciently analyze these challenges.
We exposed a signiﬁcant space of both modeling
ideas and application-speciﬁc requirements left to
be addressed in future research.
Our hope is to encourage meaningful and generalizable comparisons on our quest toward overcoming the long-standing issues found in ST models.