This is the author’s final, peer-reviewed manuscript as accepted for publication. The
publisher-formatted version may be available through the publisher’s web site or your
institution’s library.
This item was retrieved from the K-State Research Exchange (K-REx), the institutional
repository of Kansas State University. K-REx is available at 
ADABOOST+: an ensemble learning approach for estimating
weather-related outages in distribution systems
Padmavathy Kankanala, Sanjoy Das, and Anil Pahwa
How to cite this manuscript
If you make reference to this version of the manuscript, use the following information:
Kankanala, P., Das, S., & Pahwa, A. . ADABOOST+: An ensemble learning
approach for estimating weather-related outages in distribution systems. Retrieved from
 
Published Version Information
Citation: Kankanala, P., Das, S., & Pahwa, A. . ADABOOST+: An ensemble
learning approach for estimating weather-related outages in distribution systems. IEEE
Transactions on Power Systems, 29(1), 359-367.
Copyright: © 2013 IEEE
Digital Object Identifier (DOI): doi:10.1109/TPWRS.2013.2281137
Publisher’s Link: 
> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) <
Abstract— Environmental factors, such as weather, trees and
animals are major causes of power outages in electric utility
distribution systems. Of these factors, wind and lightning have
the most significant impacts. The objective of this paper is to
investigate models to estimate wind and lighting related outages.
Such estimation models hold the potential for lowering
operational costs and reducing customer downtime. This paper
proposes an ensemble learning approach based on a boosting
algorithm, ADABOOST+, for estimation of weather caused power
outages. Effectiveness of the model is evaluated using actual data,
which comprised of weather data and recorded outages for four
cities of different sizes in Kansas. The proposed ensemble model
is compared with previously presented regression, neural
network, and mixture of experts models. The results clearly show
that ADABOOST+ estimates outages with greater accuracy than
the other models for all four data sets.
Index Terms— Artificial intelligence, ensemble learning,
environmental factors, power distribution systems, power system
reliability.
I. INTRODUCTION
T is a well recognized fact that weather conditions,
specifically wind and lightning, have a great effect on
outages in power distribution systems . Literature on
outage analysis shows that especially overhead lines are
highly susceptible to environmental factors such as weather,
trees, and animals . Proper design and maintenance can
help in reducing weather related outages, but it is hard to
prevent them completely. Although outages are more likely
during severe weather, their occurrences are highly irregular
rendering them very difficult to predict. A model which can
accurately estimate outages based on weather data can help
utilities in outage management, system design and upgrades.
Weather is typically categorized into normal weather,
severe weather and extreme weather. The National Weather
meteorological phenomena with the potential to cause
damage, serious social disruption, or loss of human life.
Extreme weather conditions include hurricanes, tornadoes,
This work was supported by the National Science Foundation under Award
ECCS-0926020.
Padmavathy Kankanala (e-mail: ), Anil Pahwa (e-mail:
 ), and Sanjoy Das (e-mail: ) are with
Department of Electrical and Computer Engineering, Kansas State University,
Manhattan, KS 66506 USA.
severe thunderstorms, snowstorms, and ice storms. Severe
weather conditions are characterized by lightning, high wind,
extreme temperature, and heavy rainfall. Utilities usually
separate outages caused by extreme weather conditions from
those caused by severe weather conditions while evaluating
the system performance. Since the outages occur randomly
with higher probabilities during adverse conditions and outage
recordings can have significant human errors, obtaining high
correlation between estimated outages and observed outages is
a very challenging task. Various models have been proposed
in the literature to study effects of different weather
phenomenon on outages with different levels of success.
An exponential model as a function of time for forecasting
cumulative outages during different extreme weather events
has been proposed in . In this paper, the authors have
classified storms by the intensity of temperature and wind
speeds. Also, flash data has been considered for analysis of
outages caused by storm with lightning activity. Similarly,
statistical models to predict the number of outages due to
hurricanes and ice storms have been developed in . In
these papers, the authors have developed the hurricane and ice
storm models as a function of explanatory variables such as
number of protective devices, maximum wind gust and
duration, ice thickness, hurricane rainfall, storm indicator
covariate, land cover type, soil drainage level and soil depth.
These methods have limitation such as evolving power system
inventory with time and presence of huge matrix of spatial
correlation makes it computationally challenging. Poisson
regression and Bayesian hierarchical network for risk
management of power outages caused by extreme weather
conditions is investigated in . In this study, surface wind
speed, gust speed, gust frequency, daily rainfall, daily
minimum pressure and daily maximum and minimum
temperature have been considered, while other weather factors
such as lightning are excluded. A Poisson regression model
and a Bayesian network model to predict the yearly weatherrelated failure events on overhead lines are presented in .
Similarly, in Poisson regression is used to study the
significance of weather variables on outages using outage data
from substations within 10 miles of National Weather Service
sites under severe weather conditions.
Prior work of authors of this paper to study effects of wind
and lightning includes investigation of linear, quadratic and
exponential regression models , multilayered neural
ADABOOST+: An Ensemble Learning Approach
for Estimating Weather-Related Outages in
Distribution Systems
Padmavathy Kankanala, Student Member, IEEE, Sanjoy Das, Non-Member, IEEE, and Anil Pahwa,
Fellow, IEEE
> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) <
networks , and mixture of experts (ME) . Although
these prior methods show acceptable performance, there
remains enough scope for further improvement using state-ofthe-art machine learning algorithms.
The main focus of this paper is build upon the prior work of
the authors and the existing literature to explore techniques
using ensemble learning to estimate with greater accuracy
outages in power distribution systems caused by weather.
Specifically, demonstrate that ensemble-based methods can do
a better job than a single learner approach. In addition to a
standard ADABOOST, an approach based on a new boosting
algorithm, ADABOOST+, which is a modification proposed by
the authors of this paper, is presented. Ensemble learning is a
technique that embodies one of the main directions of current
machine learning research. Although in this paper the
ensemble’s constituent units are referred to as neural
networks, an ensemble could equally well comprise of other
learning models, such as support vector machines ,
kernel-based models , radial basis function networks , decision trees , fuzzy logic or ARMA models
 in addition to neural networks . Random
forests are another good method for classification and
regression. However, during preliminary investigation for the
problem, we found the random forests algorithm for
classification but not for regression. We also tried some kernel
based approaches before settling down with backprop-trained
neural networks which seemed to perform best. Furthermore,
since the motivation behind ADABOOST is to obtain a strong
learner using an ensemble of weak learners, the specific
choice of weak learner is not a significant issue.
The rest of the paper is organized as follows. Section II is
an exposition to ensemble learning along with a survey of the
applications in power and energy systems that have only
recently begun to appear. In Section III, the specific ensemble
algorithm used in this research is presented in greater detail.
Section IV outlines how available historical weather
observations and outage data are processed in this
investigation. Section V provides results obtained from this
comparisons
approaches. Finally, section VI concludes this research.
II. ENSEMBLE LEARNING
Aggregating models into ensembles is performed due to a
variety of reasons. For example, when the input data is both
extensive and spatially distributed, instead of transporting
large volumes of data into a single location, it is preferable to
train neural networks at different nodes, and communicate
only their outputs into a central facility for collective decision
making. Motivated by these considerations, an ensemble
learning algorithm whose inputs range from historical records
of grid failures to distributed real-time sensor measurements
of the grid, is suggested. The task is to estimate the mean
times between failures of various power equipment of the
electricity grid of New York city .
Elsewhere, data heterogeneity has led to schemes where
neural networks are trained to only process a subset of input
fields, with a separate dedicated unit used for decision fusion.
Multiple neural networks are trained with different inputs, and
an ensemble is used to forecast load conditions .
Ensembles are also used for classification and regression
tasks, to increase prediction accuracies beyond what can be
accomplished with a single neural network. The expected error
of a trained neural network for test data consists of three
components: (i) random noise, (ii) bias, and (iii) variance.
Random noise pertains to anomalies present in the test data
that cannot be alleviated through computational means. The
second component – bias, refers to the neural networks own
topological inadequateness when modeling the data. It can be
reduced by increasing the network’s complexity – such as
adding more hidden neurons. Unfortunately, increased
network size also leads to higher variance, i.e. the sensitivity
of the network’s parameters to the training samples, which is
the third source of error. In other words, increasing the neural
network size to improve its performance with respect to the
training samples has the undesirable effect of degrading the
network’s overall performance. This is the well-known biasvariance dilemma in machine learning theory; decreasing the
bias increases the variance and vice versa.
Fig.1. Schematic of an ensemble of neural networks.
Ensemble learning offers an alternative route to lower the
variance without compromising the bias term . This is
done by aggregating the output over multiple, separately
trained neural networks (Fig. 1). Although individual neural
networks in the ensemble can exhibit high sensitivities to the
training data, the variance of the collective output remains
quite low. Even simple aggregation techniques, such as
averaging the outputs of all neural networks, have shown great
promise. A recent study reports that averaging the individual
1-9 day ahead weather predictions of several radial basis
function networks is significantly more accurate than each
network’s output .
More advanced theoretical considerations have led to even
better ensemble methods to lower the variance. In bagging,
bootstrapped subsets of the training data are used to train each
network in the ensemble . This approach has been used for
short-term
forecasting
meteorological
information .
On the other hand, in boosting weighted training of the
neural networks is applied . ADABOOST is the most
> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) <
widely used algorithm for boosting ensemble outputs . The New York power grid study uses a realization of
this basic method called RANKBOOST .
Each phase of ADABOOST involves the complete training of
a separate neural network in the ensemble. In the initial phase,
a neural network is trained with equal weights assigned to all
samples in the test data. In each subsequent phase, a new
neural network is trained with samples associated with high
output errors from earlier networks receiving exponentially
increasing weights. This scheme was originally used in
classification tasks in the ADABOOST.M1 and ADABOOST.M2
algorithms . ADABOOST.R is an adaptation of
ADABOOST.M2 for regression problems . The algorithm
that is considered for comparison in this paper is
ADABOOST.RT, which is also meant for regression .
III. PROPOSED APPROACH
Each of the ܶ models used in the ensemble is a standard
multilayered neural network with a single hidden layer. The
output ݕ of such a network is ,
In the above equation, ܯ is the number of hidden neurons, and
ܦ, the size of the input ܠ whose ݅௧௛ component is ݔ௜. The
quantities ࢃ௜௝
ை are the synaptic strengths of the
neurons in the hidden and output layers, while ܊௜
௛ and ܾ௢ are
their corresponding biases, with subscripts denoting the
neurons they are associated with. The function ߪ: Ը஽→ሾ0, 1ሿ
is the usual sigmoid function.
During training, the synaptic strengths and biases are
updated iteratively using stochastic gradient descent. With
ሼ࢞ሺ݊ሻ, ݋ሺ݊ሻሽ representing the ݊௧௛ input-output training sample
out of a total of ܰ (i.e. 1 ൑݊൑ܰ), the updating rule is,
2 ߟൈ݀ሺ݊ሻൈ׏గሾݕሺ݊ሻെ݋ሺ݊ሻሿଶ. ሺ2ሻ
In the above equation, ߟ is the learning rate while ߨ may be
any of the network’s parameters (i.e. ࢃ௜௝
When the training sample input is ܠሺ݊ሻ, the corresponding
output ݕሺ݊ሻ of the neural network is determined in accordance
with (1). The parameter ݀ሺ݊ሻ is the weight assigned to the ݊௧௛
sample by ADABOOST.
As multiple neural networks are present in the ensemble,
subscripts are applied to distinguish between the quantities
pertaining to them. Thus ݀௧ሺ݊ሻ denotes the ݊୲୦ sample’s
weight when training the ݐ୲୦ neural network (1 ൑ݐ൑ܶ),
while ݕ௧ሺ݊ሻ is its corresponding output.
The sample weights begin with equal initial assignments,
ܰ, ሺ1 ൑݊൑ܰሻ. ሺ3ሻ
Hence the first neural network receives an equal amount of
training for each sample.
In each subsequent network with index ݐ൅1, each sample
weight ݀௧ାଵሺ݊ሻ is determined based on the fraction error
produced by the preceding (ݐ௧௛) neural network with sample
ሼ࢞ሺ݊ሻ, ݋ሺ݊ሻሽ. In order to do so, the algorithm maintains a
threshold value ߠ. The neural network output for this sample
is considered to be error-free when the absolute relative error
lies within ߠ,
|ݕ௧ሺ݊ሻെ݋ሺ݊ሻ|
The new weights ݀௧ାଵሺ݊ሻ are determined from the prior ݀௧ሺ݊ሻ
in accordance with (5) below,
ۖۓ݀௧ሺ݊ሻߝ௧,
|ݕ௧ሺ݊ሻെ݋ሺ݊ሻ|
݀௧ሺ݊ሻ, |ݕ௧ሺ݊ሻെ݋ሺ݊ሻ|
The quantity ߝ௧ in (5) is the error rate produced by the ݐ௧௛
network at the end of its training with ሼ࢞ሺ݊ሻ, ݋ሺ݊ሻሽ~݀௧ሺ݊ሻ.
Using (4) as the criterion for a sample to be error-free, the set
of erroneous samples is,
࣢௧ൌቊ݊ቤ|ݕ௧ሺ݊ሻെ݋ሺ݊ሻ|
Hence the network’s error rate is given by,
In order to ensure that the new weights constitute a
probability distribution, they are normalized as follows,
Following normalization, the weights add up to unity,
The overall training algorithm used by both ADABOOST.RT
as well as ADABOOST+ is outlined below.
1. Initialize ݀ଵ using ሺ3ሻ.
For each neural network ݐൌ1 to ܶ do
2. Train network ݐ using ሺ1ሻ and ሺ2ሻ.
3. Compute error rate ߝ௧ using ሺ6ሻ and ሺ7ሻ.
4. Compute distribution ݀௧ାଵ using ሺ5ሻ.
5. Normalize distribution ݀௧ାଵ using ሺ8ሻ.
6. Add network ݐ to ensemble.
The algorithms ADABOOST.RT and ADABOOST+ differ in
how the ensemble output is determined. In ADABOOST.RT, the
ensemble output ݋ොሺ݊ሻ is the weighted sum of all ܶ neural
networks, with the neural networks receiving weights
proportional to the logarithm of their inverse error rates. Thus
the weight ߜ௧ applied the output of the ݐ୲୦ neural network
(1 ൑ݐ൑ܶ) is,
Accordingly, the ensemble output by ADABOOST.RT is,
݋ොሺ݊ሻൌ෍ߜ௧ݕ௧ሺ݊ሻ
However, in the proposed ADABOOST+, the weights are
determined to explicitly minimize the sum of the squared
errors of all samples. Arranging the sample outputs and the
> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) <
ensemble outputs as ܰൈ1 column vectors ܗ and ܗෝ
respectively, the sum squared error can be expressed as,
ܧൌ෍൫݋ሺ݊ሻെ݋ොሺ݊ሻ൯
ൌሺܗെܗෝሻ୘ሺܗെܗෝሻ. ሺ12ሻ
Likewise, the outputs of each network can be organized as an
ܰൈ1 vector ܡ௧. In a similar manner the network weights can
be arranged as a ܶൈ1 vector ઼. Defining the ܰൈܶ output
matrix ܇ൌሾܡଵ… ܡ்ሿ, the output vector ܗෝ can be expressed
ܗෝൌ܇઼. ሺ13ሻ
Note that (13) is only a vector-matrix reformulation of (11).
It can be shown that the choice of ઼ that minimizes the sum
squared error ܧ is given by,
઼ൌሺ܇୘܇ሻିଵ܇୘ܗ. ሺ14ሻ
The above equation is the pseudo-inverse rule with the ܶൈܰ
matrix ܇ାൌሺ܇୘܇ሻିଵ܇୘ being the pseudo-inverse of ܇.
Regularization can be incorporated for numerical stability of
the matrix inversion, in which case ઼ can be obtained as
follows with ߪ being a small constant,
઼ൌሺ܇୘܇൅ߪ۷ሻିଵ܇୘ܗ. ሺ15ሻ
In ADABOOST+, (14) or (15) is applied to determine the
network weights. The ensemble output is determined in
accordance with (13).
IV. OUTAGE AND WEATHER DATA PREPARATION
Typical outage management systems in utilities record
necessary information related to circuit outages including
service area, circuit reference number, outage cause, outage
weather, outage duration, number of customers affected,
tripped equipment’s, outage date and time, etc. The weather
during outage is a set of weather conditions that utilities define
based on their priorities and local weather characteristics. The
most reliable weather information can always be obtained
from the local weather stations, which record weather data
including date, temperature, weather phenomenon, snow/ice,
precipitation, pressure and wind on daily basis.
Existing literature suggests that either gust or sustained
wind can be used to study effects of outages with neither
having any specific advantage over the other. Gust is recorded
for days with high wind speeds and significant variation
between peak and average speeds. In other words gust is an
indicator of high wind speed as well as large fluctuations in
wind speed or conditions which are likely to cause outages. In
this paper, maximum daily wind gust measured on 5-second
basis is used as the variable to study the wind effects because
in our previous research we had found it to provide the best
correlation to outages compared to other variables. However,
for days with low wind speeds, which don’t have gust
recorded, 1-minute sustained speed is used. Additional
investigation to identify other suitable wind related variables
from the available data to include in the analysis will be
pursued as part of future research.
Daily aggregate lightning stroke currents are calculated by
summing the magnitudes of all the lightning strokes in
kiloAmps (kA) including the first stroke and the flashes 
within 500m around the feeders for each day of the study.
Since our intent was to study combined effects of wind and
lightning as well as that of wind alone, all the days including
those that didn’t have any recorded lightning were included.
Also, the days of extreme weather conditions were excluded.
Three such days for Lawrence, six days for Topeka, and eight
days for Wichita were in this category, which were considered
outliers and were removed from the data for analysis, which
spanned a period of seven years from 2005 to 2011.
Fig.2. Outages caused by wind and lightning
Fig.3. Outages in the higher range caused by wind and lightning (each bar
graph represents outages with a bin size of five)
The daily maximum wind gust or 1-minute maximum
sustained wind and aggregate lightning strokes were used as
inputs for the model. In addition to these variables, trees
around the feeders and vegetation management are important
issues to consider because trees interact in a complex manner
with wind to cause outages. However, since we aggregated
all the feeders in the entire city in our analysis and each city
was analyzed separately, tree density is not an important
variable because it remains constant throughout the analysis
for the specific city. Some spatial aggregation of feeders is
necessary for smoothing of data to obtain meaningful
statistical patterns . If the tree density changes over time
and utilities keep a good record of this change, this
information could be included in the analysis. The utility that
Histogram of Weather-related Outages, 2005-2011
Number of Outages/Day
Number of Days
Histogram of Weather-related Outages, 2005-2011
Number of Outages/Day
Number of Days
> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) <
provided the data for analysis does vegetation management on
a rolling basis over a period of four years. Specifically, trees
in one-fourth of the city are trimmed each year, which allows
completion of the entire city in four years. After that the cycle
starts again. Therefore, if one looks at the entire city at any
time, it remains roughly in the same state with respect to
exposure to trees. If the feeders that had trees trimmed in a
particular year were aggregated together to form four groups,
it would be possible to include vegetation information as an
input to the model. This approach might work for larger cities
but might not work for smaller cities. This is an important
issue, which requires additional data from the utility and
further investigation.
The four cities included in this study are Manhattan (7
distribution substations with 176 miles of distribution feeders
at 12.47 kV), Lawrence (7 distribution substations with 193
miles of distribution feeders at 12.47 kV), Topeka (22
distribution substations with 560 miles of distribution feeders
mostly at 12.47 kV and a very small portion at 4 kV), and
Wichita (42 distribution substations with 1165 miles of
distribution feeders mostly at 12.47 kV and a very small
portion at 4 kV).
Outages recorded in the database with lightning, trees, wind
as cause, and equipment and unknown outages possibly
caused by lightning and wind were included in the outage
counts for the study. The weather at the time of all recorded
lightning, equipment failure and unknown outages was
manually examined to ensure that the lightning actually
occurred on the feeder experiencing outage. Outages that were
recorded as caused by lightning with no recorded lightning on
the specific feeder were removed. On the other hand,
equipment and unknown outages coinciding with recorded
lightning on the specific feeders were included. In our
previous studies such detailed screening was not done.
Therefore, the results shown in this paper based on these
methods are different from those papers.
Fig. 2 and 3 shows histogram of outages (per day) in the
study period for the four districts. Note that the scales of Fig 3
are different from that of Fig. 2. Also, in Fig. 3, each bar
represents outages in a range covering five different values.
For example, 11 on the x-axis represents outages from 11 to
15 and so on. The figure doesn’t show a few additional days
that had outages higher than 50. These figures show that there
are a large number of days with zero or low number of
recorded outages. Manhattan has the largest number of days
with zero outages and Wichita has the smallest number of
days with zero outages with Lawrence and Topeka falling in
between in order. The trend reverses for one or higher number
of outages. This is an outcome of the spatial aggregation of
outages. Since Wichita has the largest service area, the
probability of outages at each level greater than zero is higher
for it than the cities with smaller service areas.
V. EXPERIMENTAL RESULTS
The data of the four cities were divided into training and test sets to evaluate performance of
the ADABOOST models. The results obtained from these
models were compared with prior research results . In
the previous research, linear, quadratic and exponential
regression models have been considered . The model
shown in (16) is considered for comparison because it showed
the best performance out of them,
݋ොൌߚଵܮ݅൅ߚଶܹ݀൅ߚଷܹ݀ൈܮ݅൅ߚସܹ݀ଶ൅ ߚହܮ݅ଶ ሺ16ሻ
Here, ݋ො is the estimated number of outages, ܮ݅ is the
accumulated lightning strokes in kA per day, and ܹ݀ is the
maximum wind gust speed in miles per hour for the day.
Another model included for comparison is a neural network,
which was applied to perform regression . The output of
this network is determined in accordance with (1), with ݋ොൌݕ.
The training is performed as in (2) with ݀ሺ݊ሻൌ1 for each
sample ݊. In addition, a model based on mixture of experts
(ME) was considered for comparison.
To evaluate performance of the models, different criteria for
comparison are used which are presented below:
(i) Mean Absolute Error (MAE) gives the average deviation of
the estimated values from the observed values. This is given
ܰ൭෍|݋ොሺ݅ሻെ݋ሺ݅ሻ|
(ii) Mean Square Error (MSE) between the observed and
estimated outages defines the goodness of fit of the models.
For N observations MSE is given by,
ܰ൭෍൫݋ොሺ݅ሻെ݋ሺ݅ሻ൯
(iii) Correlation Coefficient, R
ሺ݋ሺ݅ሻെ݋̅ሻ൫݋ොሺ݆ሻെ݋ො̅൯
ሺ݋ሺ݅ሻെ݋̅ሻଶ
൫݋ොሺ݆ሻെ݋ො̅൯
where, ݋̅ is the average of observed outages and ݋ො̅ is the
average of estimated outages.
Fig. 4 and 5 show the percentage MSE of ADABOOST.RT
and ADABOOST+ against the number of networks for the
training data set of the four cities. The performance of
ADABOOST+ with Wichita data improved with regularization
with ߪ = 0.01 in (15). In all other cases regularization was not
used since it didn’t change the results. The percentage MSE
drops as the number of networks increase and it stabilizes after
a certain number of networks. For example, for Wichita, the
percentage MSE drops to 65% for ADABOOST.RT with four
neural networks whereas for ADABOOST+ the percentage MSE
drops to 43% for the same number of neural networks; clearly
illustrating the better performance of ADABOOST +. Increasing
the number of neural networks beyond that didn’t change the
results significantly. We believe that this is because even with
only one neural network the results are reasonable and thus
only some additional neural networks are required to improve
the results and reach a stable point. This could also be
> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) <
dependent on the nature of the problem and initial selection of
the neural network. Some problems could require a large
number of neural networks to stabilize the error. For
comparison results obtained with five neural networks are
Performance measures of the models based on average
absolute error (MAE) and mean squared error (MSE) are
given in Tables from I to IV for the four cities. The R-square
for regression between the estimated and the observed values
of outages are not very large, but they are within a range
similar to those presented previously in the literature for
outage analysis. The nature of the data, which has significant
natural randomness as well as errors introduced by people
while collecting and recording observations make it very
difficult to get very high correlation.
SUMMARY RESULTS FOR MANHATTAN
Training Data
Regression
Neural Network
ADABOOST.RT
SUMMARY RESULTS FOR LAWRENCE
Training Data
Regression
Neural Network
ADABOOST.RT
SUMMARY RESULTS FOR TOPEKA
Training Data
Regression
Neural Network
ADABOOST.RT
SUMMARY RESULTS FOR WICHITA
Training Data
Regression
Neural Network
ADABOOST.RT
ADABOOST.RT
Number of Networks
Number of Networks
Fig.4. Performance of the ADABOOST.RT model
Fig.5. Performance of the ADABOOST+ model
> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) <
From the comparison of results from different methods for
train and test data, it is found that ADABOOST+ performs
relatively better over others followed by ADABOOST.RT. The
only case where ADABOOST+ showed a slight reduction in
performance compared to ADABOOST.RT based on these
parameters is for the test data of Wichita. Although it appears
to be a reduction is performance, it will be shown later that in
fact ADABOOST+ performed better than ADABOOST.RT.
Fig. 6 and 7 show scatter plots with regression line of
observed vs. estimated outages for training and test data of
best regression model, neural network, ME, ADABOOST.RT,
and ADABOOST+. In addition to the previously considered
parameters, slope of the regression line between the observed
and the estimated outages in an indicator of performance of
the models. Higher slope would mean better performance
with a slope of one giving the ideal performance. These
graphs show clear improvement in performance of the
ADABOOST+ model, which provides better slope than other
models for all the training as well as test cases. ADABOOST+
performs distinctly better than the other models for outages in
the lower range. However, all the models under predict
outages in the higher range. This can be expected because the
data in the higher range is sparse and thus the models are not
able to fully learn the characteristics in the data in this range.
VI. CONCLUSIONS
In this paper, a new boosting algorithm ADABOOST+ is
proposed to determine the effects of wind and lightning on
outages in overhead distribution systems The models were
trained and tested using the available historical data from
2005-2011 to verify their robustness. Comparison of the
results show that the ADABOOST+ performs better than
ADABOOST.RT and both the boosting models provide better
estimates of the outages than the models based on standard
regression, neural network, and mixture of experts.
The results are useful for utilities for system design and
upgrades. Further research to improve ADABOOST+ will be
focused on automating the choice of optimal value of
threshold depending on the characteristics of the data set.
Other machine learning models will be investigated to further
improve the results, specifically for outages in the higher
range. Other variables to represent wind in addition to gust
speed and inclusion of vegetation related information into the
models will be explored. The current research is suitable for
end of the year evaluation based on past data. Ongoing
research will focus on outage prediction in the future based on
weather scenarios for the future.
Observed Outages
Estimated Outages
Manhattan Training Data
Neural Network
ADABOOST.RT
Observed Outages
Estimated Outages
Lawrence Training Data
Neural Network
ADABOOST.RT
Observed Outages
Estimated Outages
Topeka Training Data
Neural Network
ADABOOST.RT
Observed Outages
Estimated Outages
Wichita Training Data
Neural Network
ADABOOST.RT
Fig.6. Scatter plot along with regression line of observed vs. estimated outages for 2005-2009 training data for different models
(red-regression, cyan-neural network, green-mixture of experts, magenta-ADABOOST.RT and blue-ADABOOST+).
> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) <
ACKNOWLEDGMENT
We would like to thank David Rose and Rodney Robinson
of Westar Energy, Topeka, KS for providing the outage and
lightning data, Mary Knapp of State Climate Office at Kansas
State University for providing the weather data. We would
also like to thank NSF for providing financial support for the
project. The views expressed in this paper are of the authors.