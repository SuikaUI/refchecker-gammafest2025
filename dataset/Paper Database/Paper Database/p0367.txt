Hybrid Task Cascade for Instance Segmentation
Jiangmiao Pang2,3
Jiaqi Wang1
Xiaoxiao Li1
Shuyang Sun4
Wansen Feng2
Ziwei Liu1
Jianping Shi2
Wanli Ouyang4
Chen Change Loy5
Dahua Lin1
1The Chinese University of Hong Kong
2SenseTime Research
3Zhejiang University
4The University of Sydney
5Nanyang Technological University
Cascade is a classic yet powerful architecture that has
boosted performance on various tasks. However, how to introduce cascade to instance segmentation remains an open
question. A simple combination of Cascade R-CNN and
Mask R-CNN only brings limited gain. In exploring a more
effective approach, we ﬁnd that the key to a successful instance segmentation cascade is to fully leverage the reciprocal relationship between detection and segmentation. In
this work, we propose a new framework, Hybrid Task Cascade (HTC), which differs in two important aspects: (1) instead of performing cascaded reﬁnement on these two tasks
separately, it interweaves them for a joint multi-stage processing; (2) it adopts a fully convolutional branch to provide spatial context, which can help distinguishing hard
foreground from cluttered background. Overall, this framework can learn more discriminative features progressively
while integrating complementary features together in each
stage. Without bells and whistles, a single HTC obtains
38.4% and 1.5% improvement over a strong Cascade Mask
R-CNN baseline on MSCOCO dataset. Moreover, our overall system achieves 48.6 mask AP on the test-challenge split,
ranking 1st in the COCO 2018 Challenge Object Detection
Task. Code is available at: 
open-mmlab/mmdetection.
1. Introduction
Instance segmentation is a fundamental computer vision
task that performs per-pixel labeling of objects at instance
level. Achieving accurate and robust instance segmentation in real-world scenarios such as autonomous driving and
video surveillance is challenging. Firstly, visual objects are
often subject to deformation, occlusion and scale changes.
Secondly, background clutters make object instances hard
to be isolated. To tackle these issues, we need a robust representation that is resilient to appearance variations. At the
same time, it needs to capture rich contextual information
for discriminating objects from cluttered background.
Cascade is a classic yet powerful architecture that has
boosted performance on various tasks by multi-stage reﬁnement. Cascade R-CNN presented a multi-stage architecture for object detection and achieved promising results.
The success of Cascade R-CNN can be ascribed to two key
aspects: (1) progressive reﬁnement of predictions and (2)
adaptive handling of training distributions.
Though being effective on detection tasks, integrating
the idea of cascade into instance segmentation is nontrivial. A direct combination of Cascade R-CNN and Mask
R-CNN only brings limited gain in terms of mask AP
compared to bbox AP. Speciﬁcally, it improves bbox AP by
3.5% but mask AP by 1.2%, as shown in Table 1. An important reason for this large gap is the suboptimal information ﬂow among mask branches of different stages. Mask
branches in later stages only beneﬁt from better localized
bounding boxes, without direct connections.
To bridge this gap, we propose Hybrid Task Cascade
(HTC), a new cascade architecture for instance segmentation. The key idea is to improve the information ﬂow
by incorporating cascade and multi-tasking at each stage
and leverage spatial context to further boost the accuracy.
Speciﬁcally, we design a cascaded pipeline for progressive
reﬁnement. At each stage, both bounding box regression
and mask prediction are combined in a multi-tasking manner. Moreover, direct connections are introduced between
the mask branches at different stages – the mask features
of each stage will be embedded and fed to the next one,
as demonstrated in Figure 2. The overall design strengthens the information ﬂow between tasks and across stages,
leading to better reﬁnement at each stage and more accurate
predictions on all tasks.
For object detection, the scene context also provides useful clues, e.g. for inferring the categories, scales, etc. To
leverage this context, we incorporate a fully convolutional
branch that performs pixel-level stuff segmentation. This
branch encodes contextual information, not only from foreground instances but also from background regions, thus
complementing the bounding boxes and instance masks.
Our study shows that the use of the spatial contexts helps
 
to learn more discriminative features.
HTC is easy to implement and can be trained end-toend. Without bells and whistles, it achieves 2.6% and 1.4%
higher mask AP than Mask R-CNN and Cascade Mask
R-CNN baselines respectively on the challenging COCO
dataset. Together with better backbones and other common
components, e.g. deformable convolution, multi-scale training and testing, model ensembling, we achieve 49.0 mask
AP on test-dev dataset, which is 2.3% higher than the winning approach of COCO Challenge 2017.
Our main contributions are summarized as follows: (1)
We propose Hybrid Task Cascade (HTC), which effectively
integrates cascade into instance segmentation by interweaving detection and segmentation features together for a joint
multi-stage processing. It achieves the state-of-the-art performance on COCO test-dev and test-challenge.
demonstrate that spatial contexts beneﬁt instance segmentation by discriminating foreground objects from background
clutters. (3) We perform extensive study on various components and designs, which provides a reference and is helpful
for futher research on object detection and instance segmentation.
2. Related Work
Instance Segmentation.
Instance segmentation is a task
to localize objects of interest in an image at the pixellevel, where segmented objects are generally represented by
masks. This task is closely related to both object detection
and semantic segmentation . Hence, existing methods for this task roughly fall into two categories, namely
detection-based and segmentation-based.
Detection-based methods resort to a conventional detector to generate bounding boxes or region proposals,
and then predict the object masks within the bounding
Many of these methods are based on CNN, including DeepMask , SharpMask , and Instance-
MNC formulates instance segmentation
as a pipeline that consists of three sub-tasks: instance localization, mask prediction and object categorization, and
trains the whole network end-to-end in a cascaded manner. In a recent work, FCIS extends InstanceFCN and
presents a fully convolutional approach for instance segmentation. Mask-RCNN adds an extra branch based
on Faster R-CNN to obtain pixel-level mask predictions, which shows that a simple pipeline can yield promising results. PANet adds a bottom-up path besides the
top-down path in FPN to facilitate the information ﬂow.
MaskLab produces instance-aware masks by combining
semantic and direction predictions.
Segmentation-based methods, on the contrary, ﬁrst obtains a pixel-level segmentation map over the image, and
then identiﬁes object instances therefrom. Along this line,
Zhang et al. propose to predict instance labels
based on local patches and integrate the local results with
an MRF. Arnab and Torr also use CRF to identify instances. Bai and Urtasun propose an alternative way,
which combines watershed transform and deep learning to
produce an energy map, and then derive the instances by
dividing the output of the watershed transform. Other approaches include bridging category-leval and instance-level
segmentation , learning a boundary-aware mask representation , and employing a sequence of neural networks to deal with different sub-grouping problems .
Multi-stage Object Detection.
The past several years
have seen remarkable progress in object detection. Mainstream object detection frameworks are often categorized
into two types, single-stage detectors and twostage detectors . Recently, detection frameworks with multiple stages emerge as an increasingly popular paradigm for object detection. Multi-region CNN 
incorporates an iterative localization mechanism that alternates between box scoring and location reﬁnement. AttractioNet introduces an Attend & Reﬁne module to update bounding box locations iteratively. CRAFT incorporates a cascade structure into RPN and Fast R-
CNN to improve the quality of the proposal and detection results. IoU-Net performs progressive bounding
box reﬁnement (even though not presenting a cascade structure explicitly). Cascade structures are also used to exclude
easy negative samples. For example, CC-Net rejects
easy RoIs at shallow layers. Li et al. propose to operate
at multiple resolutions to reject simple samples. Among all
the works that use cascade structures, Cascade R-CNN 
is perhaps the most relevant to ours. Cascade R-CNN comprises multiple stages, where the output of each stage is fed
into the next one for higher quality reﬁnement. Moreover,
the training data of each stage is sampled with increasing
IoU thresholds, which inherently handles different training
distributions.
While the proposed framework also adopts a cascade
structure, it differs in several important aspects. First, multiple tasks, including detection, mask prediction, and semantic segmentation, are combined at each stage, thus forming a joint multi-stage processing pipeline. In this way, the
reﬁnement at each stage beneﬁts from the reciprocal relations among these tasks. Moreover, contextual information
is leveraged through an additional branch for stuff segmentation and a direction path is added to allow direct information ﬂow across stages.
3. Hybrid Task Cascade
Cascade demonstrated its effectiveness on various tasks
such as object detection . However, it is non-trivial to
design a successful architecture for instance segmentation.
In this work, we ﬁnd that the key to a successful instance
(a) Cascade Mask R-CNN
(b) Interleaved execution
(c) Mask information ﬂow
(d) Hybrid Task Cascade (semantic feature fusion with box
branches is not shown on the ﬁgure for neat presentation.)
Figure 1: The architecture evolution from Cascade Mask R-CNN to Hybrid Task Cascade.
Figure 2: Architecture of multi-stage mask branches.
segmentation cascade is to fully leverage the reciprocal relationship between detection and segmentation.
Overview. In this work, we propose Hybrid Task Cascade
(HTC), a new framework of instance segmentation. Compared to existing frameworks, it is distinctive in several aspects: (1) It interleaves bounding box regression and mask
prediction instead of executing them in parallel. (2) It incorporates a direct path to reinforce the information ﬂow
between mask branches by feeding the mask features of
the preceding stage to the current one. (3) It aims to explore more contextual information by adding an additional
semantic segmentation branch and fusing it with box and
mask branches. Overall, these changes to the framework
architecture effectively improve the information ﬂow, not
only across stages but also between tasks.
3.1. Multi-task Cascade
Cascade Mask R-CNN.
We begin with a direct combination of Mask R-CNN and Cascade R-CNN, denoted as
Cascade Mask R-CNN. Speciﬁcally, a mask branch following the architecture of Mask R-CNN is added to each stage
of Cascade R-CNN, as shown in Figure 1a. The pipeline is
formulated as:
= P(x, rt−1),
rt = Bt(xbox
= P(x, rt−1),
mt = Mt(xmask
Here, x indicates the CNN features of backbone network,
indicates box and mask features derived
from x and the input RoIs. P(·) is a pooling operator, e.g.,
RoI Align or ROI pooling, Bt and Mt denote the box and
mask head at the t-th stage, rt and mt represent the corresponding box predictions and mask predictions. By combining the advantages of cascaded reﬁnement and the mutual beneﬁts between bounding box and mask predictions,
this design improves the box AP, compared to Mask R-CNN
and Cascade R-CNN alone. However, the mask prediction
performance remains unsatisfying.
Interleaved Execution.
One drawback of the above design is that the two branches at each stage are executed in
parallel during training, both taking the bounding box predictions from the preceding stage as input. Consequently,
the two branches are not directly interacted within a stage.
In response to this issue, we explore an improved design,
which interleaves the box and mask branches, as illustrated
in Figure 1b. The interleaved execution is expressed as:
= P(x, rt−1),
rt = Bt(xbox
= P(x, rt),
mt = Mt(xmask
In this way, the mask branch can take advantage of the updated bounding box predictions. We found that this yields
improved performance.
Mask Information Flow.
In the design above, the mask
prediction at each stage is based purely on the ROI features
x and the box prediction rt. There is no direct information
ﬂow between mask branches at different stages, which prevents further improvements on mask prediction accuracy.
Towards a good design of mask information ﬂow, we ﬁrst
recall the design of the cascaded box branches in Cascade
R-CNN . An important point is the input feature of box
branch is jointly determined by the output of the preceding stage and backbone. Following similar principles, we
introduce an information ﬂow between mask branches by
feeding the mask features of the preceding stage to the current stage, as illustrated in Figure 1c. With the direct path
between mask branches, the pipeline can be written as:
= P(x, rt−1),
rt = Bt(xbox
= P(x, rt),
mt = Mt(F(xmask
t−1 denotes the intermediate feature of Mt−1 and
we use it as the mask representation of stage t −1. F is
a function to combine the features of the current stage and
the preceding one. This information ﬂow makes it possible
for progressive reﬁnement of masks, instead of predicting
masks on progressively reﬁned bounding boxes.
Implementation.
Following the discussion above, we
propose a simple implementation as below.
, mt−1) = xmask
In this implementation, we adopt the RoI feature before
the deconvolutional layer as the mask representation m−
whose spatial size is 14×14. At stage t, we need to forward
all preceding mask heads with RoIs of the current stage to
compute m−
2 (F(xmask
t (F(xmask
denotes the feature transformation component
of the mask head Mt, which is comprised of 4 consecutive
3 × 3 convolutional layers, as shown in Figure 2. The transformed features m−
t−1 are then embedded with a 1 × 1 convolutional layer Gt in order to be aligned with the pooled
backbone features xmask
. Finally, Gt(m−
t−1) is added to
through element-wise sum.
With this introduced
bridge, adjacent mask branches are brought into direct interaction. Mask features in different stages are no longer
isolated and all get supervised through backpropagation.
semantic feature
segmentation prediction
Figure 3: We introduce complementary contextual information by adding semantic segmentation branch.
3.2. Spatial Contexts from Segmentation
To further help distinguishing the foreground from the
cluttered background, we use the spatial contexts as an effective cue. We add an additional branch to predict per-pixel
semantic segmentation for the whole image, which adopts
the fully convolutional architecture and is jointly trained
with other branches, as shown in Figure 1d. The semantic segmentation feature is a strong complement to existing
box and mask features, thus we combine them together for
better predictions:
= P(x, rt−1) + P(S(x), rt−1),
rt = Bt(xbox
= P(x, rt) + P(S(x), rt),
mt = Mt(F(xmask
where S indicates the semantic segmentation head. In the
above formulation, the box and mask heads of each stage
take not only the RoI features extracted from the backbone
as input, but also exploit semantic features, which can be
more discriminative on cluttered background.
Semantic Segmentation Branch.
Speciﬁcally, the semantic segmentation branch S is constructed based on the
output of the Feature Pyramid . Note that for semantic
segmentation, the features at a single level may not be able
to provide enough discriminative power. Hence, our design
incorporates the features at multiple levels. In addition to
the mid-level features, we also incorporate higher-level features with global information and lower-level features with
local information for better feature representation.
Figure 3 shows the architecture of this branch. Each level
of the feature pyramid is ﬁrst aligned to a common representation space via a 1 × 1 convolutional layer. Then low level
feature maps are upsampled, and high level feature maps are
downsampled to the same spatial scale, where the stride is
set to 8. We found empirically that this setting is sufﬁcient
for ﬁne pixel-level predictions on the whole image. These
transformed feature maps from different levels are subsequently fused by element-wise sum. Moreover, we add four
convolutional layers thereon to further bridge the semantic
gap. At the end, we simply adopt a convolutional layer to
predict the pixel-wise segmentation map. Overall, we try
to keep the design of semantic segmentation branch simple
and straightforward. Though a more delicate structure can
further improve the performance, It goes beyond our scope
and we leave it for future work.
Fusing Contexts Feature into Main Framework. It is
well known that joint training of closely related tasks can
improve feature representation and bring performance gains
to original tasks. Here, we propose to fuse the semantic features with box/mask features to allow more interaction between different branches. In this way, the semantic branch
directly contributes to the prediction of bounding boxes and
masks with the encoded spatial contexts.
Following the
standard practice, given a RoI, we use RoIAlign to extract a
small (e.g., 7 × 7 or 14 × 14) feature patch from the corresponding level of feature pyramid outputs as the representation. At the same time, we also apply RoIAlign on the feature map of the semantic branch and obtain a feature patch
of the same shape, and then combine the features from both
branches by element-wise sum.
3.3. Learning
Since all the modules described above are differentiable,
Hybrid Task Cascade (HTC) can be trained in an end-to-end
manner. At each stage t, the box head predicts the classiﬁcation score ct and regression offset rt for all sampled RoIs.
The mask head predicts pixel-wise masks mt for positive
RoIs. The semantic branch predicts a full image semantic segmentation map s. The overall loss function takes the
form of a multi-task learning:
mask) + βLseg,
bbox(ci, rt, ˆct, ˆrt) = Lcls(ct, ˆct) + Lreg(rt, ˆrt),
mask(mt, ˆmt) = BCE(mt, ˆmt),
Lseg = CE(s,ˆs).
bbox is the loss of the bounding box predictions at
stage t, which follows the same deﬁnition as in Cascade
R-CNN and combines two terms Lcls and Lreg, respectively for classiﬁcation and bounding box regression.
mask is the loss of mask prediction at stage t, which adopts
the binary cross entropy form as in Mask R-CNN . Lseg
is the semantic segmentation loss in the form of cross entropy. The coefﬁcients αt and β are used to balance the contributions of different stages and tasks. We follow the hyperparameter settings in Cascade R-CNN . Unless otherwise noted, we set α = [1, 0.5, 0.25], T = 3 and β = 1 by
4. Experiments
4.1. Datasets and Evaluation Metrics
We perform experiments on the challenging
COCO dataset . We train our models on the split of
2017train (115k images) and report results on 2017val and
2017test-dev. Typical instance annotations are used to supervise box and mask branches, and the semantic branch is
supervised by COCO-stuff annotations.
Evaluation Metrics. We report the standard COCO-style
Average Precision (AP) metric which averages APs across
IoU thresholds from 0.5 to 0.95 with an interval of 0.05.
Both box AP and mask AP are evaluated. For mask AP,
we also report AP50, AP75 (AP at different IoU thresholds)
and APS, APM, APL (AP at different scales). Runtime is
measured on a single TITAN Xp GPU.
4.2. Implementation Details
In all experiments, we adopt a 3-stage cascade. FPN is
used in all backbones. For fair comparison, Mask R-CNN
and Cascade R-CNN are reimplemented with PyTorch 
and mmdetection , which are slightly higher than the reported performance in the original papers. We train detectors with 16 GPUs (one image per GPU) for 20 epoches
with an initial learning rate of 0.02, and decrease it by 0.1
after 16 and 19 epoches, respectively. The long edge and
short edge of images are resized to 1333 and 800 respectively without changing the aspect ratio.
During inference, object proposals are reﬁned progressively by box heads of different stages. Classiﬁcation scores
of multiple stages are ensembled as in Cascade R-CNN.
Mask branches are only applied to detection boxes with
higher scores than a threshold (0.001 by default).
4.3. Benchmarking Results
We compare HTC with the state-of-the-art instance segmentation approaches on the COCO dataset in Table 1. We
also evaluate Cascade Mask R-CNN, which is described
in Section 1, as a strong baseline of our method. Compared to Mask R-CNN, the naive cascaded baseline brings
3.5% and 1.2% gains in terms of box AP and mask AP respectively. It is noted that this baseline is already higher
than PANet , the state-of-the-art instance segmentation
method. Our HTC achieves consistent improvements on
different backbones, proving its effectiveness. It achieves
a gain of 1.5%, 1.3% and 1.1% for ResNet-50, ResNet-101
and ResNeXt-101, respectively.
4.4. Ablation Study
Component-wise Analysis.
Firstly, we investigate the
effects of main components in our framework.
“Interleaved” denotes the interleaved execution of bbox and mask
Table 1: Comparison with state-of-the-art methods on COCO test-dev dataset.
runtime (fps)
Mask R-CNN 
ResNet-50-FPN
ResNet-50-FPN
Cascade Mask R-CNN
ResNet-50-FPN
Cascade Mask R-CNN
ResNet-101-FPN
Cascade Mask R-CNN
ResNeXt-101-FPN
HTC (ours)
ResNet-50-FPN
HTC (ours)
ResNet-101-FPN
HTC (ours)
ResNeXt-101-FPN
branches, “Mask Info” indicates the mask branch information ﬂow and “Semantic” means introducing the semantic segmentation branch. From Table 2, we can learn that
the interleaved execution slightly improves the mask AP by
0.2%. The mask information ﬂow contributes to a further
0.6% improvement, and the semantic segmentation branch
leads to a gain of 0.6%.
Effectiveness of Interleaved Branch Execution. In Section 3.1, we design the interleaved branch execution to beneﬁt the mask branch from updated bounding boxes during training. To investigate the effeciveness of this strategy, we compare it with the conventional parallel execution
pipeline on both Mask R-CNN and Cascade Mask R-CNN.
As shown in Table 3, interleaved execution outperforms parallel execution on both methods, with an improvement of
0.5% and 0.2% respectively.
Effectiveness of Mask Information Flow. We study how
the introduced mask information ﬂow helps mask prediction
by comparing stage-wise performance. Semantic segmentation branch is not involved to exclude possible distraction.
From Table 4, we ﬁnd that introducing the mask information ﬂow greatly improves the the mask AP in the second
stage. Without direct connections between mask branches,
the second stage only beneﬁts from better localized bounding boxes, so the improvement is limited (0.8%). With the
mask information ﬂow, the gain is more signiﬁcant (1.5%),
because it makes each stage aware of the preceding stage’s
features. Similar to Cascade R-CNN, stage 3 does not outperform stage 2, but it contributes to the ensembled results.
Effectiveness of Semantic Feature Fusion.
We exploit
contextual features by introducing a semantic segmentation
branch and fuse the features of different branches. Multitask learning is known to be beneﬁcial, here we study the
necessity of semantic feature fusion.
We train different
models that fuse semantic features with the box or mask
or both branches, and the results are shown in Table 5. Simply adding a full image segmentation task achieves 0.6%
improvement, mainly resulting from additional supervision.
Feature fusion also contributes to further gains,e.g., fusing
the semantic features with both the box and mask branches
brings an extra 0.4% gain, which indicates that complementary information increases feature discrimination for box
and mask branches.
Inﬂuence of Loss Weight. The new hyper-parameter β is
introduced, since we involve one more task for joint training. We tested different loss weight for the semantic branch,
as shown in Table 6. Results show that our method is insensitive to the loss weight.
4.5. Extensions on HTC
With the proposed HTC, we achieve 49.0 mask AP and
2.3% absolute improvement compared to the winning entry
last year. Here we list all the steps and additional modules used to obtain the performance. The step-by-step gains
brought by each component are illustrated in Table 7.
HTC Baseline.
The ResNet-50 baseline achieves 38.2
DCN. We adopt deformable convolution in the last
stage (res5) of the backbone.
SyncBN. Synchronized Batch Normalization is
used in the backbone and heads.
Multi-scale Training. We adopt multi-scale training. In
each iteration, the scale of short edge is randomly sampled
from , and the scale of long edge is ﬁxed as 1600.
SENet-154. We tried different backbones besides ResNet-
50, and SENet-154 achieves best single model performance among them.
GA-RPN. We ﬁnetune trained detectors with the proposals generated by GA-RPN , which achieves near 10%
higher recall than RPN.
Multi-scale Testing. We use 5 scales as well as horizontal
ﬂip at test time and ensemble the results. Testing scales are
(600, 900), (800, 1200), (1000, 1500), (1200, 1800), .
test stage
stage 1 ∼3
stage 1 ∼3
Ablation study of semantic feature fusion on
COCO 2017 val.
4.6. Extensive Study on Common Modules
We also perform extensive study on some components
designed for detection and segmentation. Components are
often compared under different conditions such as backbones, codebase, etc. Here we provide a uniﬁed environment with state-of-the-art object detection and instance segmentation framework to investigate the functionality of extensive components. We integrate several common modules
Table 6: Ablation study of semantic branch loss weight β
on COCO 2017 val.
Table 7: Results (mask AP) with better backbones and bells
and whistles on COCO test-dev dataset.
2017 winner 
HTC baseline
+ ms train
+ SENet-154
+ ensemble
designed for detection and segmentation and evaluate them
under the same settings, and the results are shown in Table 8. Limited by our experience and resources, some implementations and the integration methods may not be optimal and worth further study. Code will be released as a
benchmark to test more components.
ASPP. We adopt the Atrous Spatial Pyramid Pooling
(ASPP) module from the semantic segmentation community to capture more image context at multiple scales.
Figure 4: Examples of segmentation results on COCO dataset.
We append an ASPP module after FPN.
PAFPN. We test the PAFPN module from PANet . The
difference from the original implementation is that we do
not use Synchronized BatchNorm.
GCN. We adopt Global Convolutional Network (GCN) 
in the semantic segmentation branch.
PreciseRoIPooling.
We replace the RoI align layers in
HTC with Precise RoI Pooling .
SoftNMS. We apply SoftNMS to box results.
Table 8: Extensive study on related modules on COCO
HTC+PrRoIPool
HTC+SoftNMS
5. Conclusion
We propose Hybrid Task Cascade (HTC), a new cascade architecture for instance segmentation. It interweaves
box and mask branches for a joint multi-stage processing,
and adopts a semantic segmentation branch to provide spatial context.
This framework progressively reﬁnes mask
predictions and integrates complementary features together
in each stage.
Without bells and whistles, the proposed
method obtains 1.5% improvement over a strong Cascade
Mask R-CNN baseline on MSCOCO dataset. Notably, our
overall system achieves 48.6 mask AP on the test-challenge
dataset and 49.0 mask AP on test-dev.
Acknowledgments.
This work is partially supported by
the Collaborative Research grant from SenseTime Group
(CUHK Agreement No. TS1610626 & No. TS1712093),
the General Research Fund (GRF) of Hong Kong (No.
14236516, No. 14203518 & No. 14224316), and Singapore MOE AcRF Tier 1 (M4012082.020).