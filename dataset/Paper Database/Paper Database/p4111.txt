Construction
of Gauss-Christ
Quadrature
By Walter Gautschi*
1. Introduction.
Let w(x) be a given function ("weight function")
defined on a
finite or infinite interval (a, b). Consider a sequence of quadrature
/ f(x)w(x)dx = ¿ Xr(n)/fe(n)) , n = 1, 2, 3, • • • .
Each of these rules will be called a Gauss-Christoffel quadrature formula if it has
maximum degree of exactness, i.e. if (1.1) is an exact equality whenever / is a polynomial of degree 2n — 1. It is a well-known fact, due to Christoffel , that such
quadrature
formulas exist uniquely, provided the weight function w(x) is nonnegative, integrable with /* w(x)dx > 0, and such that all its moments
ßk= xkw(x)dx, k = 0,1,2,
exist. Then, moreover, £r(n) £ (a, b), and Xr(n) > 0. If w(x) is not of constant
Gauss-Christoffel
formulas still exist if certain Hankel determinants
in the moments
are different from zero . In this case, however, some of the abscissas £rM may
fall outside the interval (a, b) ; in particular,
they may become complex. We shall
call £r(n) the Christoffel abscissas, and Xr(n) the Christoffel weights associated
the weight function w(x).
Gauss originally considered the case w(x) = 1 on [— 1,1]. Other classical cases
are associated with the names of Jacobi, Laguerre, and Hermite. In more recent
times, the subject has experienced a considerable resurgence, as is evidenced by the
appearance of numerous numerical tables , , both relative to classical and
nonclassical weight functions. The emergence of powerful high-speed computers,
undoubtedly,
has been a major force in this development.
Curiously enough, the
constructive (algorithmic) aspect of the subject, until very recently, has remained at
the state of development in which it was left by Christoffel, and Stieltjes . The
generally recommended
procedure still consists in constructing
the system {xr}
of orthogonal polynomials associated with the weight function w(x), and to obtain
£r(n) as the zeros of ir„, and Xr(n), in a number
of possible ways, in terms of these
orthogonal polynomials. An alternative
procedure, suggested by Rutishauser
makes use of the quotient-difference
algorithm, while Golub and Welsch use
QÄ-transformations
to compute £r(n) as eigenvalues
of a Jacobi matrix
and Xr(n) as the first component of the corresponding
eigenvectors.
These methods,
as interesting
as they are, appear to be computationally
feasible, for large n, only
if the orthogonal polynomials xr, or the associated Stieltjes continued fraction, are
explicitly
Otherwise,
they are subject
to severe numerical
instability,
Received September 11, 1967.
* This work was performed
in part at the Argonne National
Laboratory,
Argonne, Illinois,
under the auspices of the U. S. Atomic Energy Commission.
WALTER GAUTSCHI
making it virtually impossible to obtain meaningful answers, unless one resorts to
multiple-precision
The reason for this is the ill-conditioned
of the problem which these
methods attempt
to solve. The problem, basically, is the purely algebraic one of
deriving £r(n>, Xr(?l) from the first 2n moments
of w(x), i.e. of solving the algebraic
system of equations
Èx,wK,wf-/i» (fc = 0, 1,2, ...,2n-l).
It will be shown (Section 2) that for a finite interval (0, 1) the (asymptotic,
condition number k„ for this problem can be estimated from below by
Kn > min U, — ) max {(1 + {«) fl L l)+ **'t> ) Í "
Considering that the abscissas £r(n), for large n, tend to cluster near the endpoints
of the interval (0, 1), many of the differences £r(n) — &(n) will be quite small in absolute value. Consequently,
some of the products in (1.4), and thus the lower bound
for Kn, are likely to be very large when n is large.
To give a more concrete idea of just how large k„ may become, we note [22, p.
309] that for a wide class of weight functions
the abscissas £r(n) ultimately
—> =o ) assume an arc cos-distribution,
£r(n) = i(l
+ cos e/n)) , e/n) = (2r - l)x/2n
the £rCn) in (1.4) by their approximate
values in (1.5), one finds that
^ . ( 1 \ (17 + 6V8)" . . / 1 \ (33.97)"
Kn > mm I /to, — J-—:—-
> min I /t0, ■— ) nÁ / .
\ /to/ 64w
Numerical values of the lower bound in (1.6), for /t0 = 1 and a few selected values
of n, are shown in Table 1.
Lower bound for condition number k„
(33.97)n/64n2
6.4 X 1018
1.6 X 1026
It is thus seen that in the presence of rounding
errors the above-mentioned
methods, if they rely on the moments, must be expected to suffer a loss of at least
11 decimal digits, if n = 10, and a loss of 26 digits, when n = 20. This is well above
the attrition
level one is normally
willing to accept!
The lesson to be learned from this analysis is evident:
the moments
as data, for constructing
Gauss-Christoffel
quadrature
formulas of large
order n. Apart
from the fact that they are not always easy to compute,
changes in the moments
(due to rounding,
for example) may result in very large
changes in the Christoffel
GAUSS-CHRISTOFFEL QUADRATURE FORMULAS
In Section 3 we propose an alternative procedure for generating Gauss-Christoffel
formulas, which is based on a suitable discretization of the inner product (/, g) =
¡lf(x)g(x)w(x)dx,
and thus bypasses the moments altogether. As the discretization
is made infinitely fine, the process converges to the desired Christoffel numbers provided the singularities of w(x), if any, are located at the endpoints of the interval
and are monotonie. Extensive tests have shown that the method is reasonably
accurate, relatively
"inexpensive,"
and requiring only single-precision
arithmetic.
A computer algorithm (in ALGOL) is to appear in .
Cases may arise in which our method converges very slowly. While approximate
Christoffel
are still obtained,
it may be desirable to further
their accuracy. This can be done by applying Newton's method to a system of equations, equivalent to (1.3), using as initial approximations
the approximate
Christoffel
numbers already obtained. An appropriate
procedure for this will be described in
Section 4. Unfortunately,
this iterative
refinement calls for the moments of the
weight function, and therefore is of limited practical value, unless one is prepared
to use higher-precision
work in some preliminary
parts of the computation.
The ability to generate Gauss-Christoffel
quadrature
formulas, as needed, is of
considerable practical interest, not only for integrating
singular functions, but also
for the numerical solution of integral equations and boundary value problems. We
also remark that this new capability may well be useful in future systems of "automated numerical analysis," such as the NAPSS system currently under development
at Purdue University .
In the appendix are collected a few general properties, more or less known, of
orthogonal polynomials which are relevant to our discussion in Sections 3, 4.
Extensions of our work seem possible to quadrature
formulas of maximum degree of exactness, where some of the abscissas are prescribed,
or the quadrature
sum involves derivative
values as well as function values. Such generalizations,
however, will not be considered here.
2. Condition of the Classical Approach. In this section we discuss the condition of the problem of solving the system of algebraic equations (1.3). In particular
we derive the estimates
(1.4) and (1.6) for the asymptotic
condition number, and
compare them with the condition of inverting Hilbert matrices.
It will be useful, first, to consider the condition of a mapping M, say, from one
normed space X into another,
Following Rice , we define the (relative) 5-condition number k(8) of M at xo £ X
«Wtfm^ll^' + ^-^'ll/A.
Thus, k(ô) represents
the maximum
amount by which a (relative)
perturbation
the space X, as given by 5/1 Wl,
is magnified under the mapping M. Since the
perturbations
to be considered are small (rounding errors!) it is natural to consider
the (relative) asymptotic
condition number k of M at xo, as defined by
WALTER GAUTSCHI
K = lim k(S) ,
where the existence of the limit, of course, is assumed.
In solving the system of equations
(1.3) we are dealing with the mapping M:
X —» F of a 2n-dimensional
Euclidean space into itself, if we identify X with the
"moment space," and Y with the space of Christoffel numbers. This mapping is
one-to-one in the neighborhood
of the exact solution of (1.3). We may write (1.3)
in the compact form
-, /t2n-i),
(Xl, • • -, X„, £l,
•, £,), F* - (Fh Ft,
Fk(y) = Z X^*"1 (k = 1, 2,
The (relative) asymptotic
condition number k = kk for solving the nonlinear
system of equations (2.3) at x<¡ is well known to be (cf. )
\yo\\ It^ö/o)]"1!!,
where y0 is the solution of F(y) = x0, and ^(2/) denotes the Jacobian matrix of F.
The matrix norm in (2.5) is assumed to be subordinate
to the vector norm chosen
in X and Y. From (2.4) we obtain by a simple computation that
Ft(y0) = HA,
(2n — l)?i
(2n - l)?„2i
GAUSS-CHRISTOFFEL QUADRATURE FORMULAS
(For simplicity,
we have written
|r for £r(n), and Xr for \rM.)
Hence, by (2.5),
k = JJ^îli IIa^w-1!!
Kn ||2/o|| ||A „ || .
We now choose our norms. We take as vector norm ||a;|| = maxs \xk\, and correspondingly
as matrix norm ||.4|| = max* ^r
|<z&rJ. We further
assume the basic
to be (0, 1), and w(x) ^ 0. Clearly,
||a;o|| i5 /to- Since Xr > 0, and ^r=i
/to, we have Xr < /t0. Also, 0 < £r < 1. Therefore,
\\y0\\ = max:(Xr,
£r) < max (1, /t0) .
Moreover, with the matrix norm as defined,
llA-ig-ièminCl, l/^IIS-1».
It thus follows from (2.8), that
/to min (1, l//to) ||,-^i||
Kn> max (1,/to) l|A "'
or, equivalently,
K„>min(/t0, l/^IIS-1!!.
Further discussion now hinges on obtaining a lower bound for || E_1||, where S is
the matrix in (2.7), a confluent Vandermonde
matrix .
2.1. Let £i, £2, • • -, £n be mutually distinct positive numbers, and S the
matrix defined in (2.7). Then
Mi g || S"1!! á max (uh u2),
where || • || denotes the maximum row sum norm, and
(2.11 u,- = max 6rl"
(2.12) brm = 1 + £r, b/2) = 1 + 2£r ¿ r-i—
Çr ~ Kk + 2
b—l;*|rfr £r — £*
Proof. It was shown in that
where A = (ara), B = (brs) are (n X 2n)-matrices
satisfying
(2.13) z ia„i ^ t,« n (t^Y
, ë i6«i = &r(i)
A:?*)- \ Çr — Kk /
*7är \ Kr — «
a = max Z la^l > ß — max 2 l&™| ,
we have by (2.11) and (2.13), a ^ u2, ß = u\. Now, either a g /3, or a > ß. In the
WALTER GAUTSCHI
first case, ||S_1|| = ß = Mi, in the second case, Mi < ||E-1¡| = a ^ u2. Hence, (2.10)
holds in either case, and Theorem 2.1 is proved.
We remark that in the case ui ^ w2 we have || H-1|| = U\.
Applying Theorem 2.1 to (2.9), we obtain
Kn > min (/t0, — ) max {(1 + £r) Ü ( \ + \ ) !,
the result already stated in (1.4).
Using the approximations
(cf. (1.5))
kr = Kl + Xr) ,
Xr = COS 0r ,
0r = (2f - 1)tt/2« ,
where xr are the zeros of the Chebyshev
polynomial
Tn(x), we may estimate
(2.15) (i + « n (f^)2 - i (3 +.,,) n (f^)2
r.(3) ]2 j_ [ r.(3) I2
Tn'(xr) = 7Y(cos0r)
= n v" ry = (-1)'
Now the maximum
in (2.14) is obviously
larger than the respective
expression
evaluated for any fixed r = r0. Choosing r0 = [n/2] + 1, we obtain in view of (2.15),
1 . ( 1 \ [cnTn(3)~
- mm I /to, — ) -—
\ mo / L n
c„ = 1 (n odd) ,
c„ = cos (ir/2n) (n even) .*
Since cos (ir/2n) ^ 1/ V 2 (n ^ 2), it follows that cn 5; 1/ V 2, and so
k„ > (l/16n2) min (Mo, l//io)[T„(3)]2 .
As is well known, zn = THi/¿) satisfies
Zn+l — &Zn + Zn-1 = 0 ,
Hence, using standard
results from the theory of linear difference equations,
zn = r,(3) = §(ii" + Í2») , ii = 3+V8,
i2 = 3 - V8 .
It follows that r„(3) > 5Í1", and we finally obtain
k„ > min. ( 1 \ (17 + 6V8)"
111 I Mo, -
the result already stated in (1.6).
We note from (2.17) that
k„ grows at least at a rate essentially
exp [n In (17 + 6 V 8)] = exp (3.5255 • • • n). Surprisingly, this coincides with
the rate of growth of the (Turing)
for the nth order segment
* We use the symbol
> to remind the reader that we are now dealing with an approximate
lower bound.
GAUSS-CHRISTOFFEL QUADRATURE FORMULAS
the Hubert matrix, as estimated by Todd . Computing Christoffel numbers on
the interval (0, 1) from given moments is therefore about as ill-conditioned
inversion of Hubert matrices!
3. Computation of Christoffel Numbers by Orthogonal Polynomials of a Discrete
Variable. We begin with the classical construction due to Christoffel. We introduce
the inner product
(f,g) = / f(x)g(x)w(x)dx ,
and let J7rr}r=o denote the associated
orthonormal
polynomials
(cf. Example
the appendix),
(xr, xs) = 5rs, degree
(irr) = r .
Let %,M be the zeros of tu(x) in (say) increasing order. Then çV(n) are precisely the
Christoffel abscissas corresponding
to the weight function w(x). The Christoffel
weights can be found, e.g., from
Xr" 'Züb^f'
This representation
is particularly
suitable for computation
since it involves the
summation of positive terms.
It seems appropriate,
at this point, to distinguish two cases :
(a) The polynomials
¡xr} are known explicitly,
i.e. either the coefficients of
Trr(x), or the coefficients in the three-term
recurrence
[cf. (A.7)], * are
known in closed form. We may refer to this as the classical case, and call the corresponding weight functions "classical." In this case the approach just outlined is
entirely satisfactory
for computational
(b) The polynomials
{t?} are not explicitly known. We refer to this as the nonclassical case, and call the corresponding
weight functions "nonclassical."
case it is necessary to progressively
generate either the coefficients of tt(x), or the
coefficients in the three-term
recurrence
relation for the irr. This amounts
orthogonalization
of the successive powers, and hence requires knowledge of the
moments of the given weight function. We are therefore in essence solving the illconditioned problem discussed in Section 2, and must thus be prepared to encounter
severe numerical instability.
The following approach is specifically designed to handle the case of nonclassical
weight functions.
denote a sequence of auxiliary quadrature
formulas with positive weights,
QA4>) = E Wkm<t>(xkm) , Wk(N) > 0 , N>n,
îence of auxiliary quadrature
Qn(<p) = J <j>(x)dx
* (A.7) refers to formula (7) of the appendix.
WALTER GAUTSCHI
We assume first (a, b) a finite interval, say (—1, 1) for definiteness. We define a
new inner product,
[/, g]s = QN(fgw),
that is, more explicitly,
(3.5') If, 9h = E Wkmf(xkm)g(Xkm) , Wkm = Wkmw(xkm) .
Since Wk(N) > 0 (we assume here that w(xkiN)) ^ 0 for k = 1, 2, • • -, N), the inner
product (3.5') gives rise to a set {irr.jv}^1 of orthonormal
polynomials of a discrete
variable (cf. Example 2 of the appendix),
[wr.N, TTs,n]n = Sts ,
T, 8 = 0, 1, 2, • • -, N - 1 .
These polynomials may be generated as described in the appendix. The process requires the computation
of inner products of the form (3.5'), which in turn requires
only a finite summation and the evaluation of w(x) at the points Xk(JV) (no moments !).
In analogy with the classical approach we now define £("at to be the zeros of
■ïïn,N(x) (known to be real), and let
[TTk.NKÇr.NJi
The Q"N, \^lf, suitably
are taken to approximate
£r(n), Xr<n), respectively.
These approximations
depend on the parameter
N, and hopefully converge to the
desired Christoffel numbers as N —> °o.
We may now rephrase Theorem 4 of the appendix, and its Corollary, as follows :
3.1. Suppose that limAf-,,» [/, g]N = (/, g), whenever f and g are polynomials. Then
lim 7rr,jv(a;) = irT(x) ,
lim {g, = ç-r(n) , lim \%
Under the assumption of Theorem 3.1, our construction
thus yields a convergent
process. The stated assumption, in essence, requires that the quadrature
rule Qn in
(3.4) be convergent for integrands
of the form <p(x) = p(x)w(x), where p(x) is a
polynomial,
and w(x) is the given weight function. Since w(x) might be singular,
we require, in other words, convergence of the quadrature rule in the presence of singularities. Fortunately,
most of the common quadrature
formulas do converge, even
in the presence of singularities, particularly
if the singularities occur at the endpoints
of the interval
and are monotonie
 , .
From the computational
point of view, convergence
alone, while desirable,
far from sufficient. Practical
considerations
lead us to impose the following additional requirements
on the quadrature
rules Qn ■
(i) Convergence
should be reasonably
fast, even in the presence of singularities ;
(ii) The quadrature
rule Qn should be easy to generate
for arbitrary,
especially large, values of N;
GAUSS-CHRISTOFFEL QUADRATURE FORMULAS
(iii) The interval [xi<-N), x2(JV), • • -, xn(N)] spanned by xi*-N), ■ ■ -, xnÍN) should
contain the desired Christoffel abscissas £i(k), • • -, £>»(n)-
The first requirement
assures that the value of JV, necessary for given accuracy,
is not excessively large. This is important,
since the work involved in generating
the discrete polynomials
ttt,n is proportional
to N. The second requirement
provides flexibility of the process, and also eliminates
the need for storing a large
of high-order
quadrature
formulas in the computer
requirement
is necessary because of the known fact that the zeros of irn¡N(x) are
all located in the interval [xi(N), • • -, xn(n)]- Since these zeros are supposed to approximate
the abscissas £r<n), these latter had better be contained in that interval!
These, of course, are hard criteria to accommodate.
In view of the tendency of
the £r(n) to crowd near the endpoints of ( — 1, 1), requirements
(i) and (iii) suggest
that we choose the abscissas Xk^m to have the same property. This rules out the
most common quadrature
rules, such as trapezoidal,
midpoint, and Simpson rules.
The classical Gaussian quadrature
formula, on the other hand, is in conflict with
requirement
(ii). A quadrature
rule which comes close to satisfying all the requirements is the Newton-Cotes
formula for the abscissas
xkm = cos dkm , 6km = (2k - l)r/22V ,
the zeros of the Chebyshev polynomial
Tn(x). The corresponding
weight factors
Wk(tf) can be written down explicitly, as was already pointed out by Fejér . In fact,
lN/2] cos (2mekm)
»"-ffl-íl-
This takes care of the requirements
(ii) and (iii), although it may be argued that
(3.10), (3.11) require the evaluation of a large number of cosines. Actually, only one
value of the cosine, viz. cos (ir/2N), is needed, since all the others, both in (3.10) and
(3.11), can be generated by well-known recurrence formulas! For best accuracy,
however, it is recommended that only the cosines in (3.11) be computed recursively,
especially if N is very large (say, exceeding 200).
As to requirement
(i) we have recently shown that the Fejér quadrature
formula does indeed converge, not only for continuous
functions,
but also for
singular functions, provided the singularities
occur at the endpoints and are monotonic. The exact nature of the singularity
is otherwise irrelevant.
The rate of convergence, of course, depends on the type of singularity,
though in a manner which
is not well understood
at the present time. Numerical
experience indicates
convergence can be rather fast for some singularities (e.g. logarithmic singularities),
but discouragingly slow for others (e.g. square-root singularities).
Another quadrature
formula, which might be suitable, is the Gauss-Chebyshev
L^$f2dx^fÈiHxkm)'
P <b(x)dx = -— £ (sin ekm)<t>(xkm) .
(1if it is rewritten
in the form
WALTER GAUTSCHI
Here we have exact equality if <p(x) = p2N-i(x)(l
— x2)~112, where p2N-i(x) is a polynomial of degree 2N — 1. The formula (3.12) is therefore particularly
suitable in
cases where the weight function w(x) has square-root
singularities
at the endpoints
±1, which is one of the cases where the Fejér formula converges very slowly.
It is interesting to point out the close kinship between the Fejér formula (3.10),
(3.11) and the Gauss-Chebyshev
formula (3.12), noting that the right-hand
(3.11) is nothing else but the truncated
Fourier expansion of (t/N)
sin 0it('v), the
weight factor in (3.12)!
We may also remark, at this point, that in the process of generating the polynomials iTr.N (r = 0, 1, • • -, n), one needs to evaluate inner products [/, g]x only for
polynomials /, g of degree ¿n.
Using the Fejér quadrature
formula, which is of
interpolatory
type, it thus follows from (3.1), (3.5) that for such/
and g, [f, g]N =
(/, g) whenever w(x) is a polynomial of degree m, and N > 2n + m. As a result, our
process of constructing Christoffel numbers, based on the Fejér formula (3.10), (3.11),
is exact if w(x) is a polynomial of degree m and N > 2n + m. The process, in this
case, converges trivially.
Similarly, our process of constructing Christoffel numbers,
based on the Gauss-Chebyshev formula (3.12), is exact if w(x) — (1 — x2)~l!2 and N
Our development
so far assumed [—1, 1] as the basic interval.
This is no restriction of generality. In fact, the case of an arbitrary
finite interval [a, b] is readily
reduced to the case considered by a linear transformation
of the independent
variable. In the case of a half-infinite interval, say (0, go), let <p(t) be any continuously
differentiable
monotonically
increasing function mapping the interval ( — 1, 1) onto
(0, » ). Then
(f,g) = J f(x)g(x)w(x)dx = J /(*(¿))ff(*(i))w(*(0)*'(0d<,
and we can proceed as before if we define
[f,gh = iwkmf(cp(xkm))g(<p(xkm)),
= w^N)w((b(xkm))<p'(xkm)
An analogous device applies for a doubly infinite interval
(— eo, °o), in which case
<p(t) is to map (—1, 1) onto (—=°,
go). Simple transformation
functions,
proved satisfactory,
are <p(t) = (1 + t)/(l
— t) for (0, «), and <p(t) = t/(l — t2) for
We conclude
this section with a few comments
on the computation
of irn,N(x). We assume that
the coefficients
ar, br+i in the recurrence
relation (cf. (A.7*))
irr+l,N(x)
= ((X — ar)irr,N(x)
— br1Tr-l,N(x))/br+l
(r = 0, 1, ...,n-l),
ito,n(x) = aTx 2, t-i,n(x)
have already been obtained
by the methods described in the appendix.
We propose
two different procedures to find the Christoffel abscissas, depending on whether the
GAUSS-CHRISTOFFEL QUADRATURE FORMULAS
|rw) are desired for ail k = 1, 2, • • -, n, r = 1, 2, • ■ -, k, or £r(,l), r = 1, 2, • • -, n,
are desired for only one, or a few selected values of n.
In the first case we apply Newton's
method to each of the equations
= 0 (fc = 2, 3, • • -, n), using (£^7°
+ £r0c~1'')/2 as initial approximation
for £rlk).
(Here, £o(Ä:-1) is equal to a, if a is finite, or a lower bound for £i(n), if a = — °o. Similarly i;^*-1' is equal to b, if b is finite, or an upper bound for £n<n), if b = 00.) The
choice of the initial approximation
is motivated
by the interlacing
zeros of irr,N and is normally sufficiently accurate to assure rapid convergence of
Newton's iteration. Occasionally, however, because of the highly oscillatory character of the polynomials
7rr,jv, it may happen that some of the Newton iterates fall
astray. For this reason it is recommended
that each Newton approximation
checked upon whether or not it satisfies the interlacing property.
If not, the appropriate
subinterval
should be examined more carefully for possible zeros, and
Newton's iteration repeated with a suitably revised initial approximation.
In the second case, the zeros £r(n) may be computed in their natural order, using
Newton's method in combination
with successive deflation. Thus suppose ¿1 = £i(n)
is already
We then construct
the deflated polynomial
(we drop the
second subscripts N for notational
simplicity)
«■„«(*) = (*»(*) - «■.(&))/(*
and compute its smallest zero by Newton's method, using £1 as initial approximation.
Thereafter,
we deflate again, and compute the smallest zero of the twice deflated
polynomial. The process is repeated until all zeros are obtained. We note, that x„ui
can be obtained by a recurrence relation very similar to (3.13), namely
ar)irrll](x)
- brirl^1(x))/br+1
1,2, ...,n-
*i[11(aO =xo/&i,
This follows readily from (3.13), and the definition (3.14), where n is to be replaced
by r. (This technique of deflation, in the context of matrices, was already described
by Wilkinson [24, p. 468ff.]. He also analyzes its numerical stability.)
Similarly, the
m-times deflated polynomial
irnlm](x) can be generated
= (7rr[m-1](U)
ar)rrlm](x)
brwlZ\(x))/br+1
(r = m,wi+
Tm (X) = 1Tm-l /bm ,
To avoid undesirable
accumulation
of error, it is recommended
that each deflation
(except the first) be preceded by a "refinement"
of the respective zero using Newton's iteration
applied to the original (undeflated)
polynomial irn(x).
It should be noted that the initial approximations
to the zeros, if successive
deflations are used, are not as accurate as those used in the first procedure (without
deflation).
4. Iterative Refinement of Christoffel Numbers. We assume now that we have
approximations
£r°, Xr° to the desired Christoffel
¿r<n), X/n), which
WALTER GAUTSCHI
are sufficiently accurate to attempt solving the basic system of algebraic equations
by Newton's method. The approximations
£r°, Xr°, for example, may have been obtained by the procedure discussed in Section 3.
Let {pi-}2!!^1 be a system of 2n linearly independent
polynomials, and define the
"modified moments" by
mk = j pk(x)w(x)dx .
The basic system of equations (1.3) is obviously equivalent to
£ KMPk(ïrM) =mk (k = 0, 1, 2, • • •, 2n - 1) .
We wish to choose the polynomials
pr in such a way that the system (4.2), unlike (1.3), is well-conditioned.
this would be achieved if the Jacobian
matrix «7(Xi, • • -, X„; £i, • • -, £„) of (4.2) evaluated
at the exact solution Xr = Xr(n),
£r = £,>>, is orthogonal. We shall settle for the next best, which is orthogonality
/(À!0, •■•, X„°;£i°, • ■•,£»"). Since
(4.3) J(Xr;£r)
-P2n-l(?l) • • • P2n-l(£„) Xip'2n_i(£i) • " ■ X„p2„_1(£„)J
the required orthogonality
means that the rows in the matrix (4.3) be mutually
orthonormal.
In terms of the inner product
{/, g\ = ¿
[/(ír°)ptt,°)
+ (Xr°)2/'(£rV(¿;r0)]
this in turn implies that
{pr, p*) = 8rs, r, s = 0, 1, • • -, 2n - 1 .
We are led to the discrete analogue of Gröbner polynomials, considered in Example
3 of the appendix.
In choosing the polynomials pT as described, we not only are achieving a wellconditioned system of algebraic equations,
(4.2), but also assure that the linear
systems of equations
which need to be solved in Newton's
method are all wellconditioned. This is so because the first of these is exactly orthogonal,
remaining ones are nearly orthogonal.
Unfortunately,
the modified moments (4.1) are not known in advance, and must
be generated,
along with the polynomials
pr. As is shown in the first section of
the appendix, we have for {pr} the recurrence relation
= ((X — aT,r)Pr(x)
— ar,r-\Pr-l(x)
• • — ar,oPo(x))/br+i
•••,2np0(x) = {1,1}""
where the coefficients ars and 6r+i can be computed
as described in the appendix.
Let us define, then,
GAUSS-CHRISTOFFEL QUADRATURE FORMULAS
mrk = / xkpr(x)w(x)dx
We have, in particular,
m0* = poßk , mro = mr,
where m* are the moments (1.2) of w(x). From (4.6) and (4.7) we obtain
mT+1,k = ( mr,k+i
arsmSkj/br+i.
We may consider mr,k as entries at grid points of the triangular
region r ^ 0,
k ^ 0, r + k ;£ 2n — 1 in the first quadrant of the (r, fc)-plane. The entries along
the vertical boundary of the triangle, by (4.8), are poM*, which we assume to be
known. The relation (4.9) then permits to progressively fill in the triangle, proceeding from left to right. When completed, the entries along the horizontal boundary
will be found, which by (4.8) are precisely the modified moments mr.
Our process of iterative refinement thus consists of two parts. First, the generation of the orthonormal
polynomials pr and, along with this, the generation of the
modified moments mr. Second, the solution of the system of equations (4.2) by
Newton's method. Since the whole process (starting, as it does, with the moments
Mi) is unstable, and the second part is stable, we conclude that the first part must
be unstable. In practice, therefore, unless n is small, this part should be carried
out with high precision.
5. Examples. We select at random some of the possible applications of our procedure to numerical integration,
and also point out some of its limitations.
examples, of course, could easily be multiplied. For additional numerical examples
we refer to .
(a) In the theory of radiative equilibrium of stellar atmospheres one encounters
integrals of the form
mE^it-Tïïdt,
F(r) = 2 /" f(t)E2(t - r)dt - 2 f f(t)E2(r - t)dt ,
to evaluate mean intensities and fluxes. Here, f(t) is a known function, and Em(x)
= J"™ e~xt trmdt, the exponential
integral. After a suitable change of variables, one
is thus faced with integrals of the form
/ f(x)Em(x)dx , / f(x)Em(r - x)dx .
Since Em(x) has a logarithmic
singularity
at x = 0, and an essential singularity
x = co, it is natural
to treat Em(x) and Em(r — x) as weight functions,
and to apply
the corresponding
Gauss-Christoffel
quadrature
formulas [2, p. 65ff]. These may be
constructed
by our procedure
of Section 3, both singularities
being monotonie.
20-point formula for w(x) = E\(x), 0 < x < co, so obtained,
may be found in .
(b) For the evaluation of Fourier coefficients it may be useful to compute
WALTER GAUTSCHI
— / f(x)[ 1 — . ax )dx
by Gaussian quadrature
treating the trigonometric
factor as a weight function .
(c) Fourier integrals, such as J"o°° f(x) cos ax dx, may be treated by Gaussian
quadrature,
in a manner described in . This calls for n-point Gauss-Christoffel
formulas with weight function w(x) = (1 + cos x)/(l
+ x)2n+s on (0, go), where
s > 0 is a suitable number, depending on the behavior of f(x) at x = go .
We have here a case of a nonmonotonic
singularity
(at x = go) and thus no
theoretical justification for the process of Section 3. The process, accordingly, seems
to converge very slowly, if at all. To illustrate, we display below the minimum and
relative errors in the abscissas £r(n) and weights Xr(n) for the case s = 1,
n = 5, and values of N as shown.
min. err. £r (5)
max. err. £r(.->)
min. err. Xr(5)
max. err. Xr(5)
(d) In an attempt
to integrate
numerically
the remainder
term in the Euler-
sum formula , one might use Gauss-Christoffel
formulas with weight
function w(x) = 1/x — [1/x] on (0, 1). This function has an infinite number of discontinuities,
accumulating
at x = 0, and is all but monotonie there. Not surprisingly, our procedure of Section 3 does not seem to converge, not even for n as small
as 5, as may be seen from the following results.
Appendix. Orthogonal
polynomials
We collect here, for easy reference, some elementary properties, computational
aspects, and examples of orthogonal polynomials which are useful in the context
of Sections 3 and 4.
containing
r = 0, 1, 2, • • •, N, where N may be finite or infinite. Designate by (
) an inner
product in S. The set of orthogonal
polynomials,
relative to this inner product, will
be denoted by {pr}f_o. Thus,
(pr, p») = 0 for r ?¿ s , degree (pr) = r .
GAUSS-CHRISTOFFEL quadrature
These polynomials are uniquely determined if we require that each pr has leading
coefficient one. The orthonormal
polynomials will be denoted by p*. We have
= CrPr(x) ,
Cr = (pr, Pr)~112 .
1. Recurrence relations.
1. The orthogonal polynomials in (1), having leading coefficients one,
satisfy the recurrence relation
= (x — ar,r)Pr(x)
— ar,r-iPr-\(x)
— ■ ■ ■ — ar,oPo(x)
(r = 0, 1,2, ...,2V-1),
ar,s = (xpr, Ps)/(ps, Ps) (s = 0,1,2,
Proof. It is clear that the polynomials defined by (3), and p<¡(x) = 1, have
leading coefficients one and correct degrees. A simple computation
shows that
orthogonality
of p0, pi, ■ ■ •, pr implies orthogonality
of p0, pi, • • -, pr+i. Since
p0 and p\ are orthogonal, Theorem 1 follows by induction.
A recurrence relation for the orthonormal
polynomials p* could be obtained in
the obvious manner by substituting
(2) into (3). Computationally,
it is slightly
more convenient to introduce
Pr(x) = Cr-lPr(x)
= Cr-lP*(x)/cr
and to transform
(3), (4) into
(o*\ Pt+i(x)
= (x — a*T,r)pr*(x)
— a*r,r-\P%-\(x)
— • • • — a^,0po*(x)
P*+l(x) = pr+l(x)/(pr+l,
a* s = (xpr*, p*) (s = 0, 1, • • •, r) .
2. // the inner product satisfies
(xf, g) = (/, xg) ,
then (3) is a three-term recurrence relation, i.e.
Pr+i(x) = (x — ar)pr(x)
— brpr-i(x) (r = 0, 1, • • •, N — 1) ,
ar = (xpr, Pr)/(Pr,
Pr) (r = 0, 1, • • •, N - 1) ,
bT = (Xpr, pr~l)/(Pr-l,
Pr-l) = (pr, pr)/(Pr-l,
(r = 1, 2, ■ ■ ■, N - 1) .
(We adopt the convention, in (7), that p~i(x) = 0.)
Proof. By (6) we have (xpr, ps) = (pr, xps) = 0 if s < r — 1, since xps is a
polynomial
of degree £r — 1, and p, is orthogonal
to every polynomial
<r. Consequently,
by (4), ars = 0 if s < r — 1, and Theorem
2 is a corollary
1. The second expression
for br is obtained
by noting that (xpr, Pr-i)
(pr, xpr-i)
= (pr, Pr), since xpr-i
differs from pr by a polynomial
WALTER GAUTSCHI
We may interpret
pr(x) of Theorem
2 as the characteristic
polynomial
det (xlr — Jr) of the symmetric tridiagonal
y/br-i ar-i J
Since, by the second relation in (9), br > 0, we have that Jr is a Jacobi matrix.
Consequently,
as is well known, the polynomials
have the Sturm sequence property (cf. [24, p. 300]). In particular, the zeros of pr separate those of
Using (5), we obtain for the orthonormal
polynomials pT* of Theorem 2 the
(7*) Pr+iG*0 = (x - ar*)pr*(x)
- br*p*-i(x) , p*+i(x) = pr+i(x)/b*+1
Or* = (xpr*, P*)
br* = (Pr, Pr)1'2 .
This form of the recurrence relation is particularly
convenient
for computation
[4, p. 234].
Noting that ar
■Jbr, the Gershgorin
circle theorem
applied to
the Jacobi matrix Jn permits one to find upper and lower bounds for the zeros of
pn(x) in terms of the coefficients ar* and br*.
2. Examples.
Example 1. Let S = C[— 1, 1], the class of continuous functions on [—1, 1]
(hence N = go), and let the inner product be defined by
(/:; g) = f f(x)g(x)w(x)dx,
Here, w(x) is a weight function assumed to be positive for —1 < x < 1, and such
that all its moments Jli xrw(x)dx,
r = 0, 1, 2, • • -, exist. The inner product
clearly satisfies (6).
The recursion (7) can be used, in principle, to generate the orthogonal
polynomials pr(x) successively for r = 1, 2, 3, • • -, starting with p-i(x) = 0, pa(x) = 1.
In practice, this requires the computation
of the inner products in (8), (9), which
in view of (10) may be problematic,
especially if w(x) is a singular function not of
the standard
type w(x) = (1 — x)"(l + x)ß, a > —1, ß > —1. In the latter
case, pr are the Jacobi polynomials,
and the coefficients ar, br in (7) are known
explicitly .
Example 2. Let N = n — 1 be a fixed positive integer, and S the set of polynomials of degree ^ N. Define
GAUSS-CHRISTOFFEL QUADRATURE FORMULAS
(f,g)=T,Wrf(Xr)g(Xr),
where wr, xr are fixed real numbers
with wT > 0, xr 9e xs for r ¿¿ s. We note that
S is an inner product space, since (f, f) =0
implies f(xT) = 0 (r = 1, 2, • • •, n),
which in turn implies/
= 0, / being a polynomial of degree <n.
In contrast to Example 1, we now have a finite set of orthogonal polynomials
depending on a parameter, n. To different values of n correspond different sets of
orthogonal
polynomials. As (6) is satisfied, these polynomials again obey the relations in (7)-(9).
The successive computation
of the coefficients ar, br is now
straightforward,
since the inner product
(11) requires only the evaluation
finite sum.
Example 3. Let N = 2n — 1 be fixed, and S the set of polynomials of degree
g N. Define
(/, g) = E [urf(xr)g(xT)
+ vrf (xT)g'(xr)] ,
where uT, vr, xr are fixed real numbers,
with ur > 0, vr > 0. As in Example 2 one
shows that S is an inner-product
space. Unlike the previous example, however,
the inner product now fails to satisfy (6). As a result, the associated orthogonal
polynomials
pT obey the "long" recurrence
(3). The coefficients ar,s appearing in this relation are different from zero, in general, although
in special
circumstances
some of them may vanish (cf. Theorem 3 below).
While it is true that the recurrence relation is now more complicated,
still be used, as in Example 2, to successively build up the coefficients ar,,. The
inner products
required in (4) are readily computed by the finite summation
(12), using for the derivatives the recursion
Or — ar.r)Pr'(x)
— ar,r-ip'r-i(x)
— ar,ipi'(x)
We remark that the continuous
analogues of the polynomials
considered in
Example 3 were recently studied by Gröbner .
3. Symmetry Properties. If w(x) is an even function on (—a, a), where 0 < a
^ go , then the associated orthogonal polynomials satisfy
PAX) = (-l)rPr(-x)
In particular,
the zeros of pr are located symmetrically
with respect to the origin,
and x = 0 is a zero of pT if r is odd.
This property
may be used to essentially cut in half the amount of work required to construct the Christoffel numbers for an even weight function. Indeed,
the polynomials
pn,e(x) — p2n(^x)
form a set of orthogonal
polynomials
to the inner product
(f,g)e = f
f(x)g(x)^^-dx
It follows that the Christoffel
£T% \Tn?, of p„,e are related to those of p2n by
«ft = [|?T,
XÄi = 2Xr(2n>
(r = 1,2, • • •, n) ,
where £r(2"> are the positive zeros of p2n and \<2n) the corresponding
weight factors.
WALTER GAUTSCHI
Similarly,
the polynomials
pn,o(x) = (1/ V x)p2n+\( V x) are orthogonal
with respect to the inner product
(f,g)o= f(x)g(x)Vxw(Vx)dx,
and their zeros and weight factors are given by
i> (2n+l)-i2
Cr,0 = [Kr
Xr,0 = 2?r,0Ar
(f = 1,2, • • -, W) .
Here again £r(2n+1) denotes the positive zeros of p2K+i and Xr(2"+1) the corresponding
weight factors. Moreover,
/" u>(a;)dz -
= X0<2"+1)
is the weight factor corresponding
to the zero £o(2n+1) = 0 of p2n+i.
The inner product (12) may be called equilibrated if
X\ ~T" *£»
(r = l,2, ...,n).
Vn+i—r — Vr
3. // the inner product (12) is equilibrated, in the sense of (14), then the
associated orthogonal polynomials pr satisfy
Pr(Xx + Xn — X) = (-l)rPr(x)
Moreover, every other coefficient in the recursion (3) is zero, i.e.
ar,r-2* = 0 (s = 1, 2, 3, •••).
The proof of Theorem 3 is elementary,
and is omitted here.
4. Discrete vs. Continuous Orthogonal Polynomials.
The orthogonal
polynomials of Example 2 may be considered discrete analogues of those in Example 1.
It is reasonable to expect that the former approach
the latter, as n —> oo, if the
inner product in (11) converges to the inner product in (10).
4. Let (/, g) denote the inner product in (10), and let
[f,g]n= J2wrMf(XrM)g(XrM),
where wrM are positive numbers and xrM, for each n, are n distinct numbers in
[ — 1, 1]. Let {pr}r=o denote the set of orthogonal polynomials associated with (10), and
\pr.n]"=o the set of orthogonal polynomials associated with (17). Suppose that
lim [/, g]n = (f, g) ,
whenever f and g are polynomials.
Then for each r = 0, 1, 2, • • • we have the limit
lim Pr,n(x) = VAX)
for any fixed x, and thus uniformly for x in any finite interval.
GAUSS-CHRISTOFFEL QUADRATURE FORMULAS
Proof. We begin with the observation that
\U,g]n\ ú Y,™™
max \f(x)\
■ max \g(x)\
for any continuous functions /, g, and therefore
\\f,g]n\ ^||/|| IMI «.
The polynomials pr, by Theorem 2, satisfy (7)-(9), while the polynomials p,,»,
by the same theorem, satisfy
= (x — ar,„)pr,„(x)
— &r,npr-i,n(a:)
Suppose now that (19) is true for r = s and r = s — 1. We want to show that
(19) holds for r = s + 1. For this it suffices to show that
&«,„—>&„ (n—>co),
since by (21), this implies
—» (x — as)ps(x)
— bsps-i(x)
= pg+i(x).
The first term on the right, by (18), has the limit (ps, pe) as n —> oo. To the second
term we apply (20), with the result that
|[P«, Ps.n - Ps]n\ á ||PS|| \\Ps.n ~ Ps\\[l,
Since [1, l]n —> (1, 1), and ps.n —* ps (by assumption),
we see that the bound on
the right tends to zero as n —> go . By the same reasoning, one shows that the last
term in (24) also tends to zero. Consequently,
[p5,n, ps,n]n
In the same manner, analogous limit relations
can be established
for all the
other inner products appearing in (22), thus proving (23).
Since, trivially,
po,„ —» po, P-i,n —■*
p-i, the assertion
(19) now follows by induction.
Theorem 4 may also be obtained from a general theorem of B. Ft. Kripke 
on best approximation
with respect to nearby norms, if one observes that xT —
pr,n(x) and xr — pT(x) are the best approximations
to xr, from polynomials
degree r — 1, in the norms of (17) and (10), respectively.
The author is indebted
to Professor J. R. Rice for this remark.
Corollary.
the zeros of pr(x),
increasing
be denoted
•ri(r>, x2M, • • -, Xrir), and the zeros ofpT,n(x),
in the same order, by x^n, x^n, • • -, xrT)n.
Under the assumptions
of Theorem 4, we have
(25) lim xst = x,M , lim pt,n(x%)
= pt(xsM) (s = 1, 2, • • •, r; t < r) .
WALTER GAUTSCHI
Proof. The first relation in (25) follows from the continuity of the zeros of an
algebraic equation. The second relation follows from
PtAxi'l) - Pt(XsM)
= [pt.n(Xst) - P<Wl)] + ÍPtUt) - Pt(x,M)]
by observing
\ptin(x(¡i)
á max_is*si \pt,n(x) - pt(x)\ -» 0
(n —> oo ) , and pt(xlt%) —» Pt(x,M)
Computer Sciences Department
Purdue University
Lafayette, Indiana 47907
1. D. G. Anderson,
quadrature
formulae for Jo1 — \i\{x)f{x)dx," Math. Comp.
v. 19, 1965, pp. 477-481. MR 31 #2826.
2. S. Chandrasekhar,
Radiative Transfer, Oxford Univ. Press, 1950, Chapter II. MR 13,
3. E. B. Christoffel,
"Sur une classe particulière
de fonctions entières et de fractions
continues," Ann. Mat. Pura Appl., (2), v. 8, 1877, pp. 1-10.
4. P. J. Davis, Interpolation and Approximation, Blaisdell, New York, 1963. MR 28 #393.
5. P. J. Davis
& P. Rabinowitz,
the singularity
in approximate
integration,"
SI AM J. Numer. Anal, v. 2, 1965, pp. 367-383. MR 33 #3459.
6. L. Fejér,
"Mechanische
Quadraturen
mit positiven
Cotesschen
Math. Z., v.
37, 1933, pp. 287-309.
7. C. F. Gauss,
nova integralium
valores per approximationem
inveniendi,"
Comment. Soc. Regiae Sei. Gottingensis Recentiores, v. 3, 1816; Werke, Vol. 3, pp. 163-196.
8. W. Gautschi,
"On inverses of Vandermonde
and confluent Vandermonde
matrices. II,"
Numer. Math., v. 5, 1963, pp. 425-430. MR 29 #1734.
9. W. Gautschi,
"Numerical
quadrature
in the presence of a singularity,"
SI AM J. Numer.
Anal, v. 4, 1967, pp. 357-362.
10. W. Gautschi,
"Algorithm,
quadrature
formulas,"
Comm. ACM. (To appear.)
11. G. H. Golub
& J. H. Welsch,
Calculation of Gauss Quadrature Rules, Comput. Sei. Dept.
Tech. Rep. No. CS 81, Stanford University, Calif., 1967.
12. W. Gröbner,
"Orthogonale
Polynomsysteme
die gleichzeitig
mit f{x) auch deren Ableitung/'(x)
approximieren,"
Funktionalanalysis,
Approximationstheorie,
Numerische Mathematik,
edited by L. Collatz, G. Meinardus, and H. Unger, Birkhäuser, Basel, 1967, pp. 24-32.
13. B. R. Kripke,
"Best approximation
with respect to nearby
Numer. Math., v.
6, 1964, pp. 103-105. MR 29 #1483.
14. L. G. Kruglikova
& V. I. Krylov,
"Numerical
Fourier transform,"
Dokl. Akad. Nauk
BSSR, v. 5, 1961, pp. 279-283v(Russian) MR 26 #886.
15. V. I. Krylov
& L. T. Sul'gina,
Handbook on Numerical Integration, "Nauka,"
1966. (Russian)
16. P. Rabinowitz,
integration
in the presence of a singularity,"
SI AM J. Numer.
Anal, v. 4, 1967, pp. 191-201.
17. J. R. Rice, "A theory of condition," SIAM J. Numer. Anal, v. 3, 1966, pp. 287-310.
18. J. R. Rice & S. Rosen,
numerical analysis problem solving system,"
ACM 21st Nati. Conf., Los Angeles, Calif. , Thompson, Washington, D. C, 1966,
pp. 51-56.
19. H. Rutishauser,
"On a modification
of the QD-algorithm
with Graeffe-type
convergence," Proc. IFIP Congress 62, pp. 93-96, North-Holland, Amsterdam, 1963.
20. T. J. Stieltjes,
"Quelques recherches sur la théorie des quadratures
dites mécaniques,"
Ann. Sei. Ecole Norm. Sup., (3), v. 1, 1884, pp. 409-426; Oevres Complètes, Vol. I, pp. 377-394.
21. A. H. Stroud
& Don Secrest,
Gaussian Quadrature Formulas, Prentice-Hall,
Cliffs, N. J., 1966. MR 34 #2185.
22. G. Szegö, Orthogonal Polynomials, Amer. Math. Soc. Colloq. Publ., Vol. 23, Amer. Math.
Soc, Providence, R. I., 1959. MR 21 #5029.
23. J. Todd, "The condition of the finite segments of the Hubert matrix," Nat. Bur. Standards
Appl. Math. Ser., No. 39, U. S. Government Printing Office, Washington, D. C, 1954, pp. 109-116.
MR 16, 861.
24. J. H. Wilkinson,
The Algebraic Eigenvalue Problem, Clarendon Press, Oxford, 1965.
MR 32 #1894.
25. I. Zamfirescu,
"An extension of Gauss' method for the calculation of improper integrals,"
Acad. R. P. Romîne Stud. Cere. Mat., v. 14, 1963, pp. 615-631. (Romanian) MR 32 #1906.