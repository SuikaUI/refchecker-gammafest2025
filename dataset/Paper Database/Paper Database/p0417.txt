IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. XX, XX XXXX
Output Reachable Set Estimation and Veriﬁcation
for Multi-Layer Neural Networks
Weiming Xiang, Senior Member, IEEE, Hoang-Dung Tran Member, IEEE, and Taylor T. Johnson Member, IEEE
Abstract—In this paper, the output reachable estimation and
safety veriﬁcation problems for multi-layer perceptron neural
networks are addressed. First, a conception called maximum
sensitivity in introduced and, for a class of multi-layer perceptrons whose activation functions are monotonic functions,
the maximum sensitivity can be computed via solving convex
optimization problems. Then, using a simulation-based method,
the output reachable set estimation problem for neural networks
is formulated into a chain of optimization problems. Finally, an
automated safety veriﬁcation is developed based on the output
reachable set estimation result. An application to the safety
veriﬁcation for a robotic arm model with two joints is presented
to show the effectiveness of proposed approaches.
Index Terms—Multi-layer perceptron, reachable set estimation,
simulation, veriﬁcation.
I. INTRODUCTION
Artiﬁcial neural networks have been widely used in machine
learning systems. Applications include adaptive control –
 , pattern recognition , , game playing , autonomous
vehicles , and many others. Though neural networks have
been showing the effectiveness and powerful ability in dealing
with complex problems, they are conﬁned to systems which
comply only to the lowest safety integrity levels since, in
most of the time, a neural network is viewed as a black box
without effective methods to assure safety speciﬁcations for
its outputs. Verifying neural networks is a hard problem, even
simple properties about them have been proven NP-complete
problems . The difﬁculties mainly come from the presence
of activation functions and the complex structures, making
neural networks large-scale, nonlinear, non-convex and thus
incomprehensible to humans. Until now, only few results have
been reported for verifying neural networks. The veriﬁcation
for feed-forward multi-layer neural networks is investigated
based on Satisﬁability Modulo Theory (SMT) in , . In
 an Abstraction-Reﬁnement approach is proposed. In ,
 , a speciﬁc kind of activation functions called Rectiﬁed
Linear Unit is considered for veriﬁcation of neural networks.
The material presented in this paper is based upon work supported by the
National Science Foundation (NSF) under grant numbers CNS 1464311 and
1713253, and SHF 1527398 and 1736323, and the Air Force Ofﬁce of Scientiﬁc Research (AFOSR) under contract numbers FA9550-15-1-0258, FA9550-
16-1-0246, and FA9550-18-1-0122. The U.S. government is authorized to
reproduce and distribute reprints for Governmental purposes notwithstanding
any copyright notation thereon. Any opinions, ﬁndings, and conclusions or
recommendations expressed in this publication are those of the authors and
do not necessarily reﬂect the views of AFOSR or NSF.
Authors are with the Department of Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN 37212 USA. Email:
Weiming Xiang ( ), Hoang-Dung Tran ( ), Taylor T. Johnson ( ).
Additionally, some recent reachable set estimation results are
reported for neural networks – , these results that are
based on Lyapunov functions analogous to stability – 
and reachability analysis of dynamical systems , , have
potentials to be further extended to safety veriﬁcation.
In this work, we shall focus on a class of neural networks
called Multi-Layer Perceptron (MLP). Due to the complex
structure, manual reasoning for an MLP is impossible. Inspired
by some simulation-based ideas for veriﬁcation – ,
the information collected from a ﬁnitely many simulations
will be exploited to estimate the output reachable set of an
MLP and, furthermore, to do safety veriﬁcation. To bridge the
gap between the ﬁnitely many simulations and the output set
generated from a bounded input set which essentially includes
inﬁnite number of inputs, a conception called maximum sensitivity is introduced to characterize the maximum deviation of
the output subject to a bounded disturbance around a nominal
input. By formulating a chain of optimizations, the maximum
sensitivity for an MLP can be computed in a layer-by-layer
manner. Then, an exhaustive search of the input set is enabled
by a discretization of input space to achieve an estimation of
output reachable set which consists of a union of reachtubes.
Finally, by the merit of reachable set estimation, the safety
veriﬁcation for an MLP can be done via checking the existence
of intersections between the estimated reachable set and unsafe
regions. The main beneﬁts of our approach are that there are
very few restrictions on the activation functions except for
the monotonicity which is satisﬁed by a variety of activation
functions, and also no requirement on the bounded input sets.
All these advantages are coming from the simulation-based
nature of our approach.
The remainder of this paper is organized as follows. Preliminaries and problem formulation are given in Section II. The
maximum sensitivity analysis for an MLP is studied in Section
III. Output reachable set estimation and safety veriﬁcation
results are given in Section IV. An application to robotic arms
is provided in Section V and Conclusions are presented in
Section VI.
II. PRELIMINARIES AND PROBLEM FORMULATION
A. Multi-Layer Neural Networks
A neural network consists of a number of interconnected
neurons. Each neuron is a simple processing element that
responds to the weighted inputs it received from other neurons.
In this paper, we consider the most popular and general feedforward neural networks called the Multi-Layer Perceptron
(MLP). Generally, an MLP consists of three typical classes
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. XX, XX XXXX
of layers: An input layer, that serves to pass the input vector
to the network, hidden layers of computation neurons, and an
output layer composed of at least a computation neuron to
produce the output vector. The action of a neuron depends on
its activation function, which is described as
j=1 ωijxj + θi
where xj is the jth input of the ith neuron, ωij is the weight
from the jth input to the ith neuron, θi is called the bias
of the ith neuron, yi is the output of the ith neuron, f(·) is
the activation function. The activation function is a nonlinear
function describing the reaction of ith neuron with inputs
xj(t), j = 1, · · · , n. Typical activation functions include
rectiﬁed linear unit, logistic, tanh, exponential linear unit,
linear functions, for instance. In this work, our approach aims
at dealing with the most of activation functions regardless of
their speciﬁc forms, only the following monotonic assumption
needs to be satisﬁed.
Assumption 1: For any x1 ≤x2, the activation function
satisﬁes f(x1) ≤f(x2).
Remark 1: Assumption 1 is a common property that can be
satisﬁed by a variety of activation functions. For example, it is
easy to verify that the most commonly used logistic function
f(x) = 1/(1 + e−x) satisﬁes Assumption 1.
An MLP has multiple layers, each layer ℓ, 1 ≤ℓ≤L, has
n[ℓ] neurons. In particular, layer ℓ= 0 is used to denote the
input layer and n stands for the number of inputs in the
rest of this paper, and n[L] stands for the last layer, that is
the output layer. For a neuron i, 1 ≤i ≤n[ℓ] in layer ℓ, the
corresponding input vector is denoted by x[ℓ] and the weight
matrix is W[ℓ] = [ω[ℓ]
1 , . . . , ω[ℓ]
n[ℓ]]⊤, where ω[ℓ]
is the weight
vector. The bias vector for layer ℓis θ[ℓ] = [θ[ℓ]
1 , . . . , θ[ℓ]
The output vector of layer ℓcan be expressed as
y[ℓ] = fℓ(W[ℓ]x[ℓ] + θ[ℓ])
where fℓ(·) is the activation function for layer ℓ.
For an MLP, the output of ℓ−1 layer is the input of ℓlayer.
The mapping from the input x of input layer to the output
y[L] of output layer stands for the input-output relation of the
MLP, denoted by
y[L] = F(x )
where F(·) ≜fL ◦fL−1 ◦· · · ◦f1(·).
According to the Universal Approximation Theorem ,
it guarantees that, in principle, such an MLP in the form
of (2), namely the function F(·), is able to approximate any
nonlinear real-valued function. Despite the impressive ability
of approximating functions, much complexities represent in
predicting the output behaviors of an MLP. In most of real
applications, an MLP is usually viewed as a black box to
generate a desirable output with respect to a given input.
However, regarding property veriﬁcations such as safety veri-
ﬁcation, it has been observed that even a well-trained neural
network can react in unexpected and incorrect ways to even
slight perturbations of their inputs, which could result in
unsafe systems. Thus, the output reachable set estimation of
an MLP, which is able to cover all possible values of outputs,
is necessary for the safety veriﬁcation of an MLP and draw a
safe or unsafe conclusion for an MLP.
B. Problem Formulation
Given an input set X, the output reachable set of neural
network (2) is stated by the following deﬁnition.
Deﬁnition 1: Given an MLP in the form of (2) and an input
set X, the output reachable set of (2) is deﬁned as
Y ≜{y[L] | y[L] = F(x ), x ∈X}.
Since MLPs are often large, nonlinear, and non-convex, it
is extremely difﬁcult to compute the exact output reachable
set Y for an MLP. Rather than directly computing the exact
output reachable set for an MLP, a more practical and feasible
way is to derive an over-approximation of Y, which is called
output reachable set estimation.
Deﬁnition 2: A set ˜Y is called an output reachable set
estimation of MLP (2), if Y ⊆˜Y holds, where Y is the output
reachable set of MLP (2).
Based on Deﬁnition 2, the problem of output reachable set
estimation for an MLP is given as below.
Problem 1: Given a bounded input set X and an MLP
described by (2), how to ﬁnd a set ˜Y such that Y ⊆˜Y, and
make the estimation set ˜Y as small as possible1?
In this work, we will focus on the safety veriﬁcation
for neural networks. The safety speciﬁcation for outputs is
expressed by a set deﬁned in the output space, describing the
safety requirement.
Deﬁnition 3: Safety speciﬁcation S of an MLP formalizes
the safety requirements for output y[L] of MLP y[L]
F(x ), and is a predicate over output y[L] of MLP. The MLP
is safe if and only if the following condition is satisﬁed:
where ¬ is the symbol for logical negation.
Therefore, the safety veriﬁcation problem for an MLP is
stated as follows.
Problem 2: Given a bounded input set X, an MLP in the
form of (2) and a safety speciﬁcation S, how to check if
condition (4) is satisﬁed?
Before ending this section, a lemma is presented to show
that the safety veriﬁcation of an MLP can be relaxed by
checking with the over-approximation of the output reachable
Lemma 1: Consider an MLP in the form of (2), an output
reachable set estimation Y ⊆˜Y and a safety speciﬁcation S,
the MLP is safe if the following condition is satisﬁed
˜Y ∩¬S = ∅.
Proof: Since Y ⊆˜Y, (5) directly leads to Y ∩¬S = ∅.
The proof is complete.
Lemma 1 implies that it is sufﬁcient to use the estimated
output reachable set for the safety veriﬁcation of an MLP, thus
the solution of Problem 1 is also the key to solve Problem 2.
1 For a set Y, its over-approximation ˜Y1 is smaller than another overapproximation ˜Y2 if dH( ˜Y1, Y) < dH( ˜Y2, Y) holds, where dH stands for
the Hausdorff distance.
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. XX, XX XXXX
III. MAXIMUM SENSITIVITY FOR NEURAL NETWORKS
Due to the complex structure and nonlinearities in activation functions, estimating the output reachable sets of MLPs
represents much difﬁculties if only using analytical methods.
One possible way to circumvent those difﬁculties is to employ
the information produced by a ﬁnite number of simulations.
As well known, the ﬁnitely many simulations generated from
input set X are incomplete to characterize output set Y,
a conception called maximum sensitivity is introduced to
bridge the gap between simulations and output reachable set
estimations of MLPs.
Deﬁnition 4: Given an MLP y[L] = F(x ), an input x 
and disturbances ∆x satisfying
≤δ, the maximum
sensitivity of the MLP with input error δ at x is deﬁned by
ǫF (x , δ) ≜inf{ǫ :
where y[L] = F(x ) and
Remark 2: In some previous articles as , , the
sensitivity for neural networks is deﬁned as the mathematical
expectation of output deviations due to input and weight
deviations with respect to overall input and weight values
in a given continuous interval. The sensitivity in the average
point of view works well for learning algorithm improvement
 , weight selection , architecture construction , for
instance. However, it cannot be used for safety veriﬁcation
due to the concern of soundness. In this paper, the maximum
sensitivity is introduced to measure the maximum deviation of
outputs, which is caused by the bounded disturbances around
the nominal input x .
Due to the multiple layer structure, we are going to develop
a layer-by-layer method to compute the maximum sensitivity
deﬁned by (6). First, we consider a single layer ℓ. According
to Deﬁnition 4, the maximum sensitivity for layer ℓ, which is
denoted by ǫ(x[ℓ], δ[ℓ]) at x[ℓ], can be computed by
max ǫ(x[ℓ], δ[ℓ])
s.t. ǫ(x[ℓ], δ[ℓ]) =
fℓ(W[ℓ](x[ℓ] + ∆x[ℓ]) + θ[ℓ]) −y[ℓ]
y[ℓ] = fℓ(W[ℓ]x[ℓ] + θ[ℓ])
In the rest of paper, the norm ∥·∥is considered the inﬁnity
norm, that is ∥·∥∞. By the deﬁnition of ∥·∥∞and monotonicity
assumption in Assumption 1, the optimal solution ∆x[ℓ]
(7) can be found by running the following set of optimization
To ﬁnd the optimal solution of (7) for layer ℓ, we start from
the neuron i in layer ℓ, the following two convex optimizations
can be set up
i )⊤(x[ℓ] + ∆x[ℓ]) + θ[ℓ]
i )⊤(x[ℓ] + ∆x[ℓ]) + θ[ℓ]
Then, due to the monotonicity, the following optimization
problem deﬁned over a ﬁnite set consisting of β[ℓ]
i,min obtained in (8) and (9) is formulated to compute the
maximum absolute value of output of neuron i in layer ℓ
i ) −fℓ((ω[ℓ]
i )⊤(x[ℓ]) + θ[ℓ])
i,min, β[ℓ]
Finally, based on the maximum absolute value of the output
of neuron i and because of the deﬁnition of inﬁnity norm, we
are ready to compute the maximum sensitivity of layer ℓby
picking out the largest value of γ[ℓ]
in layer ℓ, that is
max ǫ(x[ℓ], δ[ℓ])
s.t. ǫ(x[ℓ], δ[ℓ]) ∈{γ[ℓ]
1 , . . . , γ[ℓ]
In summary, the maximum sensitivity of a single layer
ℓcan be computed through solving optimizations (8)–(11)
sequentially.
Proposition 1: Given a single layer ℓ, the maximum sensitivity ǫ(x[ℓ], δ[ℓ]) is the solution of (11) in which γ[ℓ]
1 , . . . , γ[ℓ]
are solutions of (10) with β[ℓ]
i,min, β[ℓ]
i,max being solutions of (8)
The above optimizations (8)–(11) provide a way to compute
the maximum sensitivity for one layer. Then, for an MLP,
we have x[ℓ] = y[ℓ−1], ℓ= 1, . . . , L, so the output of
each layer can be computed by iterating above optimizations
with updated input x[ℓ] = y[ℓ−1], δ[ℓ] = ǫ(x[ℓ−1], δ[ℓ−1]),
ℓ= 1, . . . , L. The maximum sensitivity of neural network
y[L] = F(x ) is the outcome of optimization (11) for output
layer L, namely, ǫF (x , δ) = ǫ(x[L], δ[L]). The layer-by-layer
idea is illustrated in Fig. 1, which shows the general idea of
the computation process for multiple layer neural networks.
In conclusion, the computation for the maximal sensitivity
of an MLP is converted to a chain of optimization problems.
Furthermore, the optimization problems (8), (9) are convex
optimization problems which can be efﬁciently solved by
existing tools such as cvx, linprog in Matlab. To be
more efﬁcient in computation without evaluating the objective
function repeatedly, we can even pre-generate the expression
of optimal solutions given the weight and bias of the neural
network. Optimizations (10), (11) only have ﬁnite elements
to search for the optimum, which can be also computed efﬁciently. The algorithm for computing the maximum sensitivity
of an MLP is given in Algorithm 1.
IV. REACHABLE SET ESTIMATION AND VERIFICATION
In previous section, the maximum sensitivity for an MLP
can be computed via a chain of optimizations. The computation result actually can be viewed as a reachtube for the inputs
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. XX, XX XXXX
Illustration for computing maximum sensitivity for an MLP.
Algorithm 1 Maximum Sensitivity Computation Function for
Require: MLP F, input x and disturbance error δ.
Ensure: Maximum Sensitivity ǫF(x , δ).
1: function MAXSENSITIVITY(F, x , δ)
x ←x ; δ ←δ
for ℓ= 1 : 1 : L −1 do
Solve (8), (9) to obtain β[ℓ]
i,min, β[ℓ]
i,min, β[ℓ]
i,max, solve (10) to obtain γ[ℓ]
i , solve (11) to obtain ǫ(x[ℓ], δ[ℓ])
x[ℓ+1] ←fℓ(W[ℓ]x[ℓ] +θ[ℓ]); δ[ℓ+1] ←ǫ(x[ℓ], δ[ℓ])
With x[L], δ[L], solve (8)–(11) to obtain ǫ(x[L], δ[L])
ǫF (x , δ) ←ǫ(x[L], δ[L])
return ǫF(x , δ)
12: end function
around nominal input x , that are the inputs bounded in the
∞≤δ. This allows us to relate the individual
simulation outputs to the output reachable set of an MLP.
First, the input space is discretized into lattices, which are
described by
Li ≜{x |
x −x 
where x 
and δ are called the center and the radius of
Li, respectively. The sets Li satisfy Li ∩Lj = {x |
x −x 
x −x 
∞= δ} and S∞
Rn×n. Obviously, for any bounded set X, we can ﬁnd a ﬁnite
number of Li such that Li
T X ̸= ∅. The index set for all Li
satisfying Li ∩X ̸= ∅is denoted by I, so it can be obtained
i∈I Li. Explicitly, the lattices with a smaller radius
δ are able to achieve a preciser approximation of bounded set
X and, moreover, S
i∈I Li will exactly be X if radius δ →0.
The number of lattices is closely related to the dimension of
the input space and radius chosen for discretization. Taking a
unit box {x ∈Rn | ∥x∥≤1} for example, the number of
lattices with radius δ is ⌈1/2δ⌉n.
The ﬁrst step is to derive all the lattices Li, i ∈I for the
input set X such that Li ∩X ̸= ∅, ∀i ∈I. Then, based on the
maximum sensitivity computation result, the output reachtube
for each lattice Li can be obtained by using Algorithm 1.
Since X ⊆S
i∈I Li, the union of output reachtubes of Li,
i ∈I includes all the possible outputs generated by the neural
network with input set X. The following proposition is the
main result in this work.
Proposition 2: Given an MLP y[L] = F(x ), input set X
and lattices Li, i ∈I with centers x 
and radius δ, and all
the lattices satisfy Li ∩X ̸= ∅, ∀i ∈I, the output reachable
set Y satisﬁes Y ⊆˜Y ≜S
i∈I ˜Yi, where
˜Yi ≜{y[L] |
y[L] −y[L]
∞≤ǫF (x 
i , δ), y[L]
where ǫF (x 
i , δ) is computed by Algorithm 1.
Proof: Using Algorithm 1 for inputs within lattice Li, ˜Yi
is the reachtube for Li via the given MLP. Thus, the union
of ˜Yi, that is S
i∈I ˜Yi, is the output reachable set of S
Moreover, due to X ⊆S
i∈I Li, it directly implies that the
output reachable set of X is a subset of S
i∈I ˜Yi, that is Y ⊆
i∈I ˜Yi. The proof is complete.
Based on Proposition 2, the output reachable set estimation
involves the following two key steps:
(1) Execute a ﬁnite number of simulations for MLP to
get individual outputs y[L]
with respect to individual
inputs x 
i . This can be done by simply generating the
outputs with a ﬁnite number of inputs through the MLP
i ). That is the main reason that our
approach is called simulation-based.
(2) Compute the maximum sensitivity for a ﬁnite number
of lattices centered at x 
i , which can be solved by the
MaxSensitivity function proposed in Algorithm 1.
This step is to produce the reachtubes based on the
simulation results, and combine them for the reachable
set estimation of outputs.
The complete algorithm to perform the output reachable set
estimation for an MLP is summarized in Algorithm 2, and
Example 1 is provided to validate our approach.
Algorithm 2 Output Reachable Set Estimation for MLP
Require: MLF F, input set X.
Ensure: Estimated output set ˜Y.
1: function OUTPUTREACH(F, X)
Initialize Li, i ∈I, x 
i , δ; ˜Y ←∅
for ℓ= 1 : 1 : |I| do
i , δ) ←MAXSENSITIVITY(F, x 
˜Yi ←{y[L] |
y[L] −y[L]
∞≤ǫF (x 
˜Y ←˜Y ∪˜Yi
10: end function
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. XX, XX XXXX
Input sets X1 and 25 lattices with radius of δ = 0.1.
Example 1: A neural network with 2 inputs, 2 outputs and
1 hidden layer consisting of 5 neurons is considered. The
activation function for the hidden layer is choosen as tanh
function and purelin function is for the output layer. The
weight matrices and bias vectors are randomly generated as
The input set is considered as X1
|x1 −0.5| ≤0.5 ∧|x2 −0.5| ≤0.5}. In order to execute
function OutputReach described in Algorithm 2, the ﬁrst
step is to initialize the lattices Li with centers x 
and radius
δ. In this example, the radius is chosen to be 0.1 and 25 lattices
are generated as in Fig. 2 shown in gray, which means there are
in total 25 simulations to be executed for the output reachable
set estimation.
Executing function OutputReach for X1, the estimated
output reachable set is given in Fig. 3, in which 25 reachtubes
are obtained and the union of them is an over-approximation of
reachable set Y. To validate the result, 10000 random outputs
are generated, it is clear to see that all the outputs are included
in the estimated reachable set, showing the effectiveness of the
proposed approach.
Moreover, we choose different radius for discretizing state
space to show how the choice of radius affects the estimation outcome. As mentioned before, a smaller radius implies
a tighter approximation of input sets and is supposed to
achieve a preciser estimation. Here, we select the radius as
δ ∈{0.1, 0.05, 0.025, 0.0125}. With ﬁner discretizations, more
simulations are required for running function OutputReach,
but tighter estimations for the output reachable set can be
obtained. The output reachable set estimations are shown in
Fig. 4. Comparing those results, it can be observed that a
smaller radius can lead to a better estimation result at the
Output reachable set estimation with input set X1 and δ = 0.1. 25
reachtubes are computed and 10000 random outputs are all included in the
estimated reachable set.
Output reachable set estimations with input set X1 and δ =
0.1(blue), 0.05(green), 0.025(yellow), 0.0125(cyan). Tighter estimations
are obtained with smaller radius.
COMPARISON OF OUTPUT REACHABLE SET ESTIMATIONS WITH
DIFFERENT RADIUS
Computation time
Simulations
expense of more simulations and computation time, as shown
in Table I.
Algorithm 2 is sufﬁcient to solve the output reachable set
estimation problem for an MLP, that is Problem 1. Then,
we can move forward to Problem 2, the safety veriﬁcation
problem for an MLP with a given safety speciﬁcation S.
Proposition 3: Consider an MLP in the form of (2), an
output reachable set estimation and a safety speciﬁcation S,
the MLP is safe if ˜Y ∩¬S = ∅, where ˜Y is the estimated
output reachable set obtained by Algorithm 2.
Proof: By Algorithm 2, we have Y ⊆˜Y, where Y is the
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. XX, XX XXXX
actual output reachable set of the MLP. Using Lemma 1, the
safety can be guaranteed. The proof is complete.
The simulation-based safety veriﬁcation algorithm is presented in Algorithm 3.
Algorithm 3 Safety Veriﬁcation for MLP
Require: MLP F, input set X, safety requirement S.
Ensure: Safe or unsafe property.
1: function SAFETYVERI(F, X, S)
Initialize Li, i ∈I, x 
for ℓ= 1 : 1 : |I| do
∩¬S ̸= ∅and x 
return UNSAFE
˜Y ←OUTPUTREACH(F, X)
if ˜Y ∩¬S = ∅then
return SAFE
return UNCERTAIN
15: end function
Remark 3: The Algorithm 3 is sound for the cases of SAFE
and UNSAFE, that is, if it returns SAFE then the system is
safe; when it returns UNSAFE there exists at least one output
from input set is unsafe since the existence of one simulation
that is unsafe is sufﬁcient to claim unsafeness. Additionally, if
it returns UNCERTAIN, caused by the fact ˜Y ∩¬S ̸= ∅, that
means the safety property is unclear for this case.
Example 2: The same MLP as in Example 1 is considered,
and the input set is considered to be X2 = {[x1 x2]⊤|
|x1 −0.5| ≤1.5 ∧|x2 −0.5| ≤0.1}. Furthermore, the safe
speciﬁcation S is assumed as S = {[x1 x2]⊤| −3.7 ≤x1 ≤
−1.5}. To do safety veriﬁcation, the ﬁrst step of using function
SafetyVeri in Algorithm 3 is to initialize the lattices Li
with two radius δ1 = 0.1 and δ2 = 0.05. Since two radius are
used, the veriﬁcation results could be different due to different
precisions selected. The veriﬁcation results are shown in Figs.
5 and 6, and compared in Table II.
COMPARISON OF SAFETY VERIFICATIONS WITH DIFFERENT RADIUS
Simulations
The safety property is uncertain when the radius is chosen
as 0.1. However, we can conclude the safeness of the MLP
when a smaller radius δ = 0.05 is chosen at the expense of
increasing the number of simulations from 15 to 60.
V. APPLICATION IN SAFETY VERIFICATION FOR ROBOTIC
ARM MODELS
In this section, our study focuses on learning forward
kinematics of a robotic arm model with two joints, see Fig.
7. The learning task of the MLP is to predict the position
Safe Region
Safety veriﬁcation for input belonging to X2. With radius δ = 0.1,
the MLP cannot be concluded to be safe or not, since there exist intersections
between the estimated reachable set and the unsafe region.
Safe Region
Safety veriﬁcation for input belonging to X2. With δ = 0.05, the
safety can be conﬁrmed, since the estimated reachable set is in the safe region.
(x, y) of the end with knowing the joint angles (θ1, θ2). For
the robotic arm, the input space [0, 2π] × [0, 2π] for (θ1, θ2)
is classiﬁed into three zones for its operations:
(1) Normal working zone: The normal working zone is the
working region that the robotic arm works most of the
time in, and the input-output training data is all collected
from this region to train the MLP model. This zone is
assumed to be θ1, θ2 ∈[ 5π
(2) Forbidden zone: The forbidden zone speciﬁes the region
that the robotic arm will never operate in due to physical
constraints or safety considerations in design. This zone
is assumed as θ1, θ2 ∈[0, π
(3) Buffering zone: The buffering zone is between the normal working zone and the forbidden zone. Some occasional operations may occur out of normal working zone,
but it remains in the buffering zone, not reaching the
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. XX, XX XXXX
Robotic arm with two joints. The normal working zone of (θ1, θ2)
is colored in green and the buffering zone is in yellow.
forbidden zone. This zone is θ1, θ2 ∈[ π
12 ] ∪[ 7π
The safety speciﬁcation for the position (x, y) is considered
as S = {(x, y) | −14 ≤x ≤3 ∧1 ≤y ≤17}. In the
safety point of view, the MLP needs to be veriﬁed that all the
outputs produced by the inputs in the normal working zone and
buffering zone will satisfy safety speciﬁcation S. One point
needs to emphasize is that the MLP is trained by the data in
normal working zone, but the safety speciﬁcation is deﬁned
on both normal working zone and buffering zone.
Using the data from normal working zone, the learning
process is standard by using train function in the neural
network toolbox in Matlab. The MLP considered for this
example is with 2 inputs, 2 outputs and 1 hidden layer
consisting of 5 neurons. The activation functions tanh and
purelin are for hidden layer and output layer, respectively.
However, for the trained MLP, there is no safety assurance
for any manipulations, especially for the ones in the buffering
zone where no input-output data is used to train the MLP.
To verify the safety speciﬁcation of the trained MLP, our
function SafetyVeri presented in Algorithm 3 is used for
this example.
First, we train the MLP with inputs (θ1, θ2) ∈[ 5π
12 ] along with their corresponding outputs. Then, to
use function SafetyVeri for the inputs in both normal
working zone and buffering zone, we discretize input space
3 ] with radius δ = 0.05. The safety veriﬁcation
result is shown in Fig. 8. It can be observed that the safety
property of the MLP is uncertain since the estimated reachable
set reaches out of the safe region S. Then, 5000 random
simulations are executed, and it shows that no output is unsafe.
However, 5000 simulations or any ﬁnite number of simulations
are not sufﬁcient to say the MLP is safe. Therefore, to soundly
claim that the MLP trained with the data collected in normal
working zone is safe with regard to both normal working and
buffering zones, a smaller radius δ = 0.02 has to be adopted.
The veriﬁcation result with δ = 0.02 is shown in Fig. 9. It
can be seen that the reachable set of the MLP is contained in
the safe region, which is sufﬁcient to claim the safety of the
robotic arm MLP model.
VI. RELATED WORK
In , an SMT solver named Reluplex is proposed for a
special class of neural networks with ReLU activation func-
Safe region for (x,y)
Safety veriﬁcation for MLP model of robotic arm with two joints.
With radius δ = 0.05, the safety cannot be determined.
Safe region for (x,y)
Safety veriﬁcation for MLP model of robotic arm with two joints.
With radius δ = 0.02, the MLP model can be claimed to be safe.
tions. The Reluplex extends the well-known Simplex algorithm
from linear functions to ReLU functions by making use of
the piecewise linear feature of ReLU functions. In contrast to
Reluplex solver in the context of SMT, the approach developed
in our paper aims at the reachability problem of neural
networks. In , A layer-by-layer approach is developed
for the output reachable set computation of ReLU neural
networks. The computation is formulated in the form of a set
of manipulations for a union of polytopes. It should be noted
that our approach is general in the sense that it is not tailored
for a speciﬁc activation function.
The authors of and propose an approach for
verifying properties of neural networks with sigmoid activation
functions. They replace the activation functions with piecewise
linear approximations thereof, and then invoke black-box SMT
solvers. Our approach does not use any approximations of
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. XX, XX XXXX
activation functions. Instead, the approximation of our approach comes from the over-approximation of output set of
each neuron, by lower and upper bounds.
In a recent paper , the authors propose a method for
proving the local adversarial robustness of neural networks.
The purpose of paper is to check the robustness around
one ﬁxed point. Instead, our approach is focusing on a set
deﬁned on a continuous domain, rather than one single point.
Finally, Lyapunov function approach plays a key role in
stability and reachability analysis for dynamical systems such
as uncertain systems , positive systems , hybrid systems – . The neural networks involved in papers –
 are recurrent neural networks modeled by a family of
differential equations so that Lyapunov function approach
works. For the MLP considered in this paper which is described by a set of nonlinear algebraic equations, Lyapunov
function approach is not a suitable tool. Thus, we introduce
another conception called maximal sensitivity to characterize
the reachability property of neural networks.
VII. CONCLUSIONS
This paper represents a simulation-based method to compute
the output reachable sets for MLPs by solving a chain of
optimization problems. Based on the monotonic assumption
which can be satisﬁed by a variety of activation functions of
neural networks, the computation for the so-called maximum
sensitivity is formulated as a set of optimization problems
essentially described as convex optimizations. Then, utilizing
the results for maximum sensitivity, the reachable set estimation of an MLP can be performed by checking the maximum
sensitivity property of ﬁnite number of sampled inputs to the
MLP. Finally, the safety property of an MLP can be veriﬁed
based on the estimation of output reachable set. Numerical
examples are provided to validate the proposed algorithms.
Finally, an application of safety veriﬁcation for a robotic arm
model with two joints is presented.