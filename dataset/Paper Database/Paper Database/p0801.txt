Graph Neural Networks in Recommender Systems: A Survey
SHIWEN WU, Peking University, China
FEI SUNâˆ—, Alibaba Group, China
WENTAO ZHANG, XU XIE, BIN CUIâ€ , Peking University, China
With the explosive growth of online information, recommender systems play a key role to alleviate such
information overload. Due to the important application value of recommender systems, there have always been
emerging works in this field. In recommender systems, the main challenge is to learn the effective user/item
representations from their interactions and side information (if any). Recently, graph neural network (GNN)
techniques have been widely utilized in recommender systems since most of the information in recommender
systems essentially has graph structure and GNN has superiority in graph representation learning. This
article aims to provide a comprehensive review of recent research efforts on GNN-based recommender
systems. Specifically, we provide a taxonomy of GNN-based recommendation models according to the types
of information used and recommendation tasks. Moreover, we systematically analyze the challenges of
applying GNN on different types of data and discuss how existing works in this field address these challenges.
Furthermore, we state new perspectives pertaining to the development of this field. We collect the representative
papers along with their open-source implementations in 
CCS Concepts: â€¢ Information Systems â†’Recommender systems.
Additional Key Words and Phrases: Recommender System; Graph Neural Network; Survey
ACM Reference Format:
Shiwen Wu, Fei Sun, and Wentao Zhang, Xu Xie, Bin Cui. 2022. Graph Neural Networks in Recommender
Systems: A Survey. ACM Comput. Surv. 37, 4, Article 111 , 37 pages. 
INTRODUCTION
With the rapid development of e-commerce and social media platforms, recommender systems have
become indispensable tools for many businesses . They can be recognized
as various forms depending on industries, like product suggestions on online e-commerce websites
(e.g., Amazon and Taobao) or playlist generators for video and music services (e.g., YouTube, Netflix,
and Spotify). Users rely on recommender systems to alleviate the information overload problem
and explore what they are interested in from the vast sea of items (e.g., products, movies, news, or
restaurants). Therefore, accurately modeling usersâ€™ preferences from their historical interactions
(e.g., click, watch, read, and purchase) lives at the heart of an effective recommender system.
âˆ—Shiwen Wu and Fei Sun contributed equally to this research.
â€ Wentao Zhang and Bin Cui are the corresponding authors.
Authorsâ€™ addresses: Shiwen Wu, School of CS and Key Lab of High Confidence Software Technologies (MOE), Peking
University, Beijing, 100871, China, ; Fei Sun, , Alibaba Group, Beijing, 100102,
China; Wentao Zhang, Xu Xie, Bin Cui, {wentao_zhang,xu.xie,bin.cui}@pku.edu.cn, School of CS and Key Lab of High
Confidence Software Technologies (MOE), Institute of Computational Social Science, Peking University (Qingdao), Peking
University, Beijing, 100871, China.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and
the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires
prior specific permission and/or a fee. Request permissions from .
Â© 2022 Association for Computing Machinery.
0360-0300/2022/4-ART111 $15.00
 
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
 
Wu, et al.
Broadly speaking, in the past decades, the mainstream modeling paradigm in recommender
systems has evolved from neighborhood methods to representation learning based
frameworks . Item-based neighborhood methods directly recommend
items to users that are similar to the historical items they have interacted with. In a sense, they
represent usesâ€™ preferences by directly using their historical interacted items. Early item-based
neighborhood approaches have achieved great success in real-world applications because of their
simplicity, efficiency, and effectiveness.
An alternative approach is representation learning based methods that try to encode both
users and items as continuous vectors (i.e., embeddings) in a shared space, thus making them
directly comparable. Representation based models have sparked a surge of interest since the
Netflix Prize competition demonstrates matrix factorization models are superior to classic
neighborhood methods for recommendations. After that, various methods have been proposed to
learn the representations of users and items from matrix factorization to deep learning
models . Nowadays, deep learning models have been a dominant methodology for
recommender systems in both academic research and industrial applications due to the ability in
effectively capturing the non-linear and non-trivial user-item relationships and easily incorporating
abundant data sources, e.g., contextual, textual, and visual information.
Among all those deep learning algorithms, one line is graph learning-based methods, which
consider the information in recommender systems from the perspective of graphs . Most of the
data in recommender systems have a graph structure essentially . For example, the interaction
data in a recommendation application can be represented by a bipartite graph between user and
item nodes, with observed interactions represented by links. Even the item transitions in usersâ€™
behavior sequences can also be constructed as graphs. The benefit of formulating recommendation
as a task on graphs becomes especially evident when incorporating structured external information,
e.g., the social relationship among users and knowledge graph related to items .
In this way, graph learning provides a unified perspective to model the abundant heterogeneous
data in recommender systems. Early efforts in graph learning-based recommender systems utilize
graph embedding techniques to model the relations between nodes, which can be further divided
into factorization-based methods, distributed representation-based methods, and neural embeddingbased methods . Inspired by the superior ability of GNN in learning on graph-structured data,
a great number of GNN-based recommendation models have emerged recently.
Nevertheless, providing a unified framework to model the abundant data in recommendation
applications is only part of the reason for the widespread adoption of GNN in recommender
systems. Another reason is that, different from traditional methods that only implicitly capture the
collaborative signals (i.e., using user-item interactions as the supervised signals), GNN can naturally
and explicitly encode the crucial collaborative signal (i.e., topological structure) to improve the user
and item representations. In fact, using collaborative signals to improve representation learning
in recommender systems is not a new idea that originated from GNN . Early
efforts, such as SVD++ and FISM , have already demonstrated the effectiveness of the
interacted items in user representation learning. In view of the user-item interaction graph, these
previous works can be seen as using one-hop neighbors to improve user representation learning.
The advantage of GNN is that it provides powerful and systematic tools to explore multi-hop
relationships which have been proven to be beneficial to the recommender systems .
With these advantages, GNN has achieved remarkable success in recommender systems in
the past few years. In academic research, a lot of works demonstrate that GNN-based models
outperform previous methods and achieve new state-of-the-art results on the public benchmark
datasets . Meanwhile, plenty of their variants are proposed and applied to various
recommendation tasks, e.g., session-based recommendation , Points-of-interest (POI)
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Graph Neural Networks in Recommender Systems: A Survey
recommendation , group recommendation , multimedia recommendation and bundle recommendation . In industry, GNN has also been deployed in web-scale
recommender systems to produce high-quality recommendation results . For example,
Pinterest developed and deployed a random-walk-based Graph Convolutional Network (GCN)
algorithm model named PinSage on a graph with 3 billion nodes and 18 billion edges, and gained
substantial improvements in user engagement in online A/B test.
Differences between this survey and existing ones. There exist surveys focusing on different
perspectives of recommender systems . However, there are very few
comprehensive reviews that position existing works and current progress of applying GNN in
recommender systems. For example, Zhang et al. and Batmaz et al. focus on most of the
deep-learning techniques in recommender systems while ignoring GNN. Chen et al. summarizes
the studies on the bias issue in recommender systems. Guo et al. review knowledge graphbased recommendations, and Wang et al. propose a comprehensive survey in the sessionbased recommendations. These two works only include some of the GNN methods applied in the
corresponding sub-fields and examine a limited number of works. To the extent of our knowledge,
the most relevant survey published formally is a short paper , which presents a review of
graph learning-based systems and briefly discusses the application of GNN in recommendation. One
recent survey under review classifies the existing works in GNN-based recommender systems
from four perspectives of recommender systems, i.e., stage, scenario, objective, and application.
Such taxonomy emphasizes recommender systems but pays insufficient attention to applying GNN
techniques in recommender systems. Besides, this survey provides few discussions on the
advantages and limitations of existing methods. There are some comprehensive surveys on the
GNN techniques , but they only roughly discuss recommender systems as one of the
applications.
Given the impressive pace at which the GNN-based recommendation models are growing, we
believe it is important to summarize and describe all the representative methods in one unified and
comprehensible framework. This survey summarizes the literature on the advances of GNN-based
recommendation and discusses open issues or future directions in this field To this end, more than
100 studies were shortlisted and classified in this survey.
Contribution of this survey. The goal of this survey is to thoroughly review the literature on
the advances of GNN-based recommender systems and discuss further directions. The researchers
and practitioners who are interested in recommender systems could have a general understanding
of the latest developments in the field of GNN-based recommendation. The key contributions of
this survey are summarized as follows:
â€¢ New taxonomy. We propose a systematic classification schema to organize the existing GNNbased recommendation models. Specifically, we categorize the existing works based on the type of
information used and recommendation tasks into five categories: user-item collaborative filtering,
sequential recommendation, social recommendation, knowledge graph-based recommendation,
and other tasks (including POI recommendation, multimedia recommendation, etc.).
â€¢ Comprehensive review. For each category, we demonstrate the main issues to deal with.
Moreover, we introduce the representative models and illustrate how they address these issues.
â€¢ Future research. We discuss the limitations of current methods and propose nine potential
future directions.
The remaining of this article is organized as follows: Section 2 introduces the preliminaries for
recommender systems and graph neural networks. Then, it discusses the motivations of applying
GNN in recommender systems and categorizes the existing GNN-based recommendation models.
Section 3-7 summarizes the main issues of models in each category and how existing works tackle
these challenges, and analyze their advantages and limitations. Section 8 gives a summary of the
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Wu, et al.
Table 1. Key notations used in this paper
Descriptions
The set of users/items
R = {ğ‘Ÿğ‘¢,ğ‘–}
Interaction between users and items
Social relationship between users
Knowledge graph
EKG = {ğ‘’ğ‘–}
The set of entities in Knowledge graph
RKG = {ğ‘Ÿğ‘’ğ‘–,ğ‘’ğ‘—}
The set of relations in Knowledge graph
Adjacency matrix of graph
In & out adjacency matrix of directed graph
Neighborhood set of node ğ‘£
Hidden state of node embedding at layer ğ‘™
Aggregated representation of node ğ‘£â€™s neighbors at layer ğ‘™
Final representation of user ğ‘¢
Final representation of item ğ‘–
Final representation of user ğ‘¢in the social space
Final representation of user ğ‘¢in the item space
Transformation matrix at layer ğ‘™
Transformation matrix of relation ğ‘Ÿat layer ğ‘™
Bias term at layer ğ‘™
Vector concatenation
Element-wise multiplication operation
mainstream benchmark datasets, widely-adopted evaluation metrics and real-world applications.
Section 9 discusses the challenges and points out nine future directions in this field. Finally, we
conclude the survey in Section 10.
BACKGROUNDS AND CATEGORIZATION
Before diving into the details of this survey, we give a brief introduction to recommender systems
and GNN techniques. We also discuss the motivation of utilizing GNN techniques in recommender
systems. Furthermore, we propose a new taxonomy to classify the existing GNN-based models.
Throughout this paper, we use bold uppercase characters to denote matrices, bold lowercase
characters to denote vectors, italic bold uppercase characters to denote sets, and calligraphic fonts
to denote graphs. For easy reading, we summarize the notations that will be used throughout the
paper in Table 1.
Recommender Systems
Recommender systems infer usersâ€™ preferences from user-item interactions or static features, and
further recommend items that users might be interested in . It has been a popular research area
for decades because it has great application value and the challenges in this field are still not well
addressed. Formally, the task is to estimate her/his preference for any item ğ‘–âˆˆI by the learnt user
representation â„âˆ—
ğ‘¢and item representation â„âˆ—
ğ‘¦ğ‘¢,ğ‘–= ğ‘“(â„âˆ—
where score function ğ‘“(Â·) can be dot product, cosine, multi-layer perceptions, etc., and ğ‘¦ğ‘¢,ğ‘–denotes
the preference score for user ğ‘¢on item ğ‘–, which is usually presented in probability.
According to the types of information used to learn user/item representations, the research
of recommender systems can usually be classified into specific types of tasks. The user-item
collaborative filtering recommendation aims to capture the collaborative signal by leveraging only
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Graph Neural Networks in Recommender Systems: A Survey
the user-item interactions, i.e., the user/item representations are jointly learned from pairwise
data . When the timestamps of the userâ€™s historical behavior are known
or the historical behavior is organized in chronological order, the user representations can be
enhanced via exploring the sequential patterns in her/his historical interactions . According to whether the users are anonymous or not and whether the
behaviors are segmented into sessions, works in this field can be further divided into sequential
recommendation and session-based recommendation. The session-based recommendation can be
viewed as a sub-type of sequential recommendation with anonymous and session assumptions .
In this survey, we do not distinguish them and refer to them collectively as the much broader
term sequential recommendation for simplicity since our main focus is the contribution of GNN
to recommendation, and the differences between them are negligible for the application of GNN.
In addition to sequential information, another line of research exploits the social relationship to
enhance the user representations, which is classified as social recommendation .
The social recommendation assumes that the users with social relationships tend to have similar
user representations based on the social influence theory that connected people would influence
each other. Besides the user representation enhancement, a lot of efforts try to enhance the item
representations by leveraging knowledge graph, which expresses relationships between items
through attributes. These works are always categorized as knowledge graph-based recommender
systems, which incorporates the semantic relations among items into collaborative signals.
Graph Neural Network Techniques
Recently, systems based on variants of GNN have demonstrated ground-breaking performances
on many tasks related to graph data, such as physical systems , protein structure , and
knowledge graph . In this part, we firstly introduce the definition of graphs, and then give a
brief summary of the existing GNN techniques.
A graph is represented as G = (V, E), where V is the set of nodes and E is the set of edges. Let
ğ‘£ğ‘–âˆˆV be a node and ğ‘’ğ‘–ğ‘—= (ğ‘£ğ‘–, ğ‘£ğ‘—) âˆˆE be an edge pointing from ğ‘£ğ‘—to ğ‘£ğ‘–. The neighborhood of a
node ğ‘£is denoted as N (ğ‘£) = {ğ‘¢âˆˆV|(ğ‘£,ğ‘¢) âˆˆE}. Generally, graphs can be categorized as:
â€¢ Directed/Undirected Graph. A directed graph is a graph with all edges directed from one
node to another. An undirected graph is considered as a special case of directed graphs where there
is a pair of edges with inverse directions if two nodes are connected.
â€¢ Homogeneous/Heterogeneous Graph. Homogeneous graph consists of one type of nodes
and edges, and heterogeneous graph has multiple types of nodes or edges.
â€¢ Hypergraph. A hypergraph is a generalization of a graph in which an edge can join any
number of vertices.
Given the graph data, the main idea of GNN is to iteratively aggregate feature information from
neighbors and integrate the aggregated information with the current central node representation
during the propagation process . From the perspective of network architecture, GNN
stacks multiple propagation layers, which consist of the aggregation and update operations. The
formulation of propagation is
Aggregation:
= Aggregatorğ‘™
= Updaterğ‘™(h(ğ‘™)
where h(ğ‘™)
denotes the representation of node ğ‘¢at ğ‘™ğ‘¡â„layer, and Aggregatorğ‘™and Updaterğ‘™represent the function of aggregation operation and update operation at ğ‘™ğ‘¡â„layer, respectively. In
the aggregation step, existing works either treat each neighbor equally with the mean-pooling
operation , or differentiate the importance of neighbors with the attention mechanism .
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Wu, et al.
In the update step, the representation of the central node and the aggregated neighborhood will
be integrated into the updated representation of the central node. In order to adapt to different
scenarios, various strategies are proposed to better integrate the two representations, such as GRU
mechanism , concatenation with nonlinear transformation and sum operation . To
learn more about GNN techniques, we refer the readers to the surveys .
Here, we briefly summarize the aggregation and update operations of five typical GNN frameworks which are widely adopted in the field of recommendation.
â€¢ GCN approximates the first-order eigendecomposition of the graph Laplacian to iteratively
aggregate information from neighbors. Concretely, it updates the embedding by
Aggregation:
where ğ›¿(Â·) is the nonlinear activation function, like ReLU, W(ğ‘™) is the learnable transformation
matrix for layer ğ‘™, Ëœğ‘ğ‘£ğ‘—is the adjacency weight ( Ëœ
ğ‘ğ‘£ğ‘£= 1) and ğ‘‘ğ‘—ğ‘—= Î£ğ‘˜Ëœ
â€¢ GraphSAGE samples a fixed size of neighborhood for each node, proposes mean/sum/maxpooling aggregator and adopts concatenation operation for update,
Aggregation:
= Aggregatorğ‘™
where Aggregatorğ‘™denotes the aggregation function at ğ‘™ğ‘¡â„layer, ğ›¿(Â·) is the nonlinear activation
function, and W(ğ‘™) is the learnable transformation matrix.
â€¢ GAT assumes that the influence of neighbors is neither identical nor pre-determined by
the graph structure, thus it differentiates the contributions of neighbors by leveraging attention
mechanism and updates the vector of each node by attending over its neighbors,
Aggregation:
where Att(Â·) is a attention function and a typical Att(Â·) is LeakyReLU
W(ğ‘™) is responsible for transforming the node representations at ğ‘™ğ‘¡â„propagation and a is the
learnable parameter.
â€¢ GGNN adopts a gated recurrent unit (GRU) in the update step,
Aggregation:
= GRU(h(ğ‘™)
GGNN executes the recurrent function several times over all nodes , which might face the
scalability issue when it is applied in large graphs.
â€¢ HGNN is a typical hypergraph neural network, which encodes high-order data correlation
in a hypergraph structure. The hyperedge convolutional layer is in the following formulation:
Aggregation:
H(ğ‘™+1) = ğ›¿
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Graph Neural Networks in Recommender Systems: A Survey
ğ‘–1 ğ‘–2 ğ‘–3 ğ‘–4 ğ‘–5
(a) User-item bipartite graph.
user behavior sequence
(b) Sequence graph.
(c) Social relationship between users.
John Lasseter
Buzz Lightyear
Walt Disney
(d) Knowledge graph
Fig. 1. Representative graph structures in recommender systems.
where ğ›¿(Â·) is the nonlinear activation function, like ReLU, W(ğ‘™) is the learnable transformation
matrix for layer ğ‘™, E is the hypergraph adjacent matrix, and Dğ‘’and Dğ‘£denote the diagonal matrices
of the edge degrees and the vertex degrees, respectively.
Why Graph Neural Network for Recommendation
In the past few years, many works on GNN-based recommendation have been proposed. Before
diving into the details of the latest developments, it is beneficial to understand the motivations of
applying GNN to recommender systems.
The most intuitive reason is that GNN techniques have been demonstrated to be powerful
in representation learning for graph data in various domains , and most of the data in
recommendation has essentially a graph structure as shown in Figure 1. For instance, the user-item
interaction data can be represented by a bipartite graph (as shown in Figure 1a) between the user
and item nodes, where the link represents the interaction between the corresponding user and
item. Besides, a sequence of items can be transformed into the sequence graph, where each item
can be connected with one or more subsequent items. Figure 1b shows an example of sequence
graph where there is an edge between consecutive items. Compared to the original sequence
data, sequence graph allows more flexibility to item-to-item relationships. Beyond that, some side
information also has naturally a graph structure, such as social relationship and knowledge graph,
as shown in Figure 1c and 1d.
Due to the specific characteristic of different types of data in recommendation, a variety of models
have been proposed to effectively learn their pattern for better recommendation results, which is
a big challenge for the model design. Considering the information in recommendation from the
perspective of the graph, a unified GNN framework can be utilized to address all these tasks. For
example, the task of non-sequential recommendation is to learn the effective node representations,
i.e., user/item representations, and to further predict user preferences. The task of sequential
recommendation is to learn the informative graph representation, i.e., sequence representation.
Both node representation and graph representation can be learned through GNN. Besides, it is
more convenient and flexible to incorporate additional information (if available), compared to nongraph perspective. For instance, the social network can be integrated into the user-item bipartite
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Wu, et al.
relationship as a unified graph. Both the social influence and collaborative signal can be captured
during the iterative propagation.
Moreover, GNN can explicitly encode the crucial collaborative signal of user-item interactions to
enhance the user/item representations through the propagation process. Utilizing collaborative
signals for better representation learning is not a completely new idea. For instance, SVD++ incorporates the representations of interacted items to enrich the user representations. ItemRank 
constructs the item-item graph from interactions, and adopts the random-walk algorithm to rank
items according to user preferences. Note that SVD++ can be seen as using one-hop neighbors (i.e.,
items) to improve user representations, while ItemRank utilizes two-hop neighbors to improve
item representations. Compared with non-graph model, GNN is more flexible and convenient to
model multi-hop connectivity from user-item interactions, and the captured CF signals in high-hop
neighbors have been demonstrated to be effective for recommendation.
Categories of Graph Neural Network-Based Recommendation
In this survey, we propose a new taxonomy to classify the existing GNN-based models. Based on
the types of information used and recommendation tasks, the existing works are categorized into
user-item collaborative filtering, sequential recommendation, social recommendation, knowledge
graph-based recommendation, and other tasks. In addition to the former four types of tasks, there
are other recommendation tasks, such as POI recommendation, multimedia recommendation, and
bundle recommendation. Since the studies utilizing GNN in these tasks are not that abundant, we
group them into one category and discuss their current developments, respectively.
The rationale of classification is as follows: The graph structure depends to a large extent on
the type of information. For example, a social network is naturally a homogeneous graph, and
user-item interaction can be considered either a bipartite graph or two homogeneous graphs (i.e.,
user-user and item-item graphs). Besides, the information type also plays a key role in designing
an efficient GNN architecture, such as aggregation and update operations and network depth. For
instance, a knowledge graph has multi-type entities and relations, which requires considering such
heterogeneity during propagation. Moreover, recommendation tasks are highly related to the type
of information used. For example, the social recommendation is to make a recommendation by
utilizing the social network information, and the knowledge graph-based recommendation is to
enhance the item representation by leveraging semantic relations among items in the knowledge
graph. This survey is mainly for the readers interested in the development of GNN in recommender
systems. Thus our taxonomy is primarily from the perspective of recommender systems but also
takes the GNN into account.
USER-ITEM COLLABORATIVE FILTERING
Given the user-item interaction data, the basic idea of user-item collaborative filtering is essentially
using the items interacted by users to enhance user representations and using the users once
interacted with items to enrich item representations. Inspired by the advantage of GNN techniques
in simulating the information diffusion process, recent efforts have studied the design of GNN
methods, in order to exploit high-order connectivity from user-item interactions more efficiently.
Figure 2 illustrates the pipeline of applying GNN to user-item interaction information.
To take full advantage of GNN methods on capturing collaborative signals from user-item
interactions, there are four main issues to deal with:
â€¢ Graph Construction. Graph structure is essential for the scope and type of information to
propagate. The original bipartite graph consists of a set of user/item nodes and the interactions
between them. Whether to apply GNN over the heterogeneous bipartite graph or construct the
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Graph Neural Networks in Recommender Systems: A Survey
(ğ‘¢1,ğ‘–2), (ğ‘¢1,ğ‘–3)
(ğ‘¢2,ğ‘–3), (ğ‘¢2,ğ‘–5)
(ğ‘¢3,ğ‘–1), (ğ‘¢3,ğ‘–4)
(ğ‘¢4,ğ‘–1), (ğ‘¢4,ğ‘–3)
(ğ‘¢4,ğ‘–4), (ğ‘¢4,ğ‘–5)
user-item interaction
Aggregation â†’n(ğ‘™)
Update â†’h(ğ‘™+1)
Final Node Rep.
Prediction
Fig. 2. The overall framework of GNN in user-item collaborative filtering.
homogeneous graph based on two-hop neighbors? Considering computational efficiency, how to
sample representative neighbors for graph propagation instead of operating on the full graph?
â€¢ Neighbor Aggregation. How to aggregate the information from neighbor nodes? Specifically,
whether to differentiate the importance of neighbors, model the affinity between the central node
and neighbors, or the interactions among neighbors?
â€¢ Information Update. How to integrate the central node representation and the aggregated
representation of its neighbors?
â€¢ Final Node Representation. Predicting the userâ€™s preference for the items requires the
overall user/item representation. Whether to use the node representation in the last layer or the
combination of the node representations in all layers as the final node representation?
Graph construction
Most of works apply the GNN on the original useritem bipartite graph directly. There are two issues in directly applying GNN on the original graph:
one is effectiveness that the original graph structure might not be sufficient enough for learning
user/item representations; another one is efficiency that aggregating the information of the full
neighborhoods of nodes requires high computation cost especially for the large-scale graph .
One strategy to address the first issue is to enrich the original graph structure by adding edges,
such as links between two-hop neighbors and hyperedges. For instance, Multi-GCCF and
DGCF add edges between two-hop neighbors on the original graph to obtain the user-user
and item-item graph. In this way, the proximity information among users and items can be explicitly
incorporated into user-item interactions. DHCF introduces the hyperedges and constructs the
user/item hypergraphs, in order to capture explicit hybrid high-order correlations. Another strategy
is to introduce virtual nodes for enriching the user-item interactions. For example, DGCF 
introduces virtual intent nodes and decomposes the original graph into a corresponding subgraph
for each intent, which represents the node from different aspects and has better expressive power.
HiGNN creates new coarsened user-item graphs by clustering similar users/items and taking
the clustered centers as new nodes, in order to explicitly capture hierarchical relationships among
users and items.
In terms of the second issue, sampling strategies are proposed to make GNN efficient and scalable
to large-scale graph-based recommendation tasks. PinSage designs a random-walk based
sampling method to obtain the fixed size of neighborhoods with the highest visit counts. In this way,
those nodes that are not directly adjacent to the central node may also become its neighbors. Multi-
GCCF and NIA-GCN randomly sample a fixed size of neighbors. Sampling is a trade-off
between the original graph information and computational efficiency. The performance of the
model depends on the sampling strategy and the more efficient sampling strategy for neighborhood
construction deserves further studying.
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Wu, et al.
Neighbor aggregation
The aggregation step is of the vital importance of information propagation for the graph structure,
which decides how much neighborsâ€™ information should be propagated. Mean-pooling is one of the
most straightforward aggregation operations , which treats neighbors equally,
|Nğ‘¢| W(ğ‘™)h(ğ‘™)
Mean-pooling is easy for implementation but might be inappropriate when the importance of
neighbors is significantly different. Following the traditional GCN, some works employ â€œdegree
normalizationâ€ , which assigns weights to nodes based on the graph structure,
Owing to the random-walk sampling strategy, PinSage adopts the normalized visit counts as
the importance of neighbors when aggregating the vector representations of neighbors. However,
these aggregation functions determine the importance of neighbors according to the graph structure
but ignore the relationships between the connected nodes.
Motivated by common sense that the embeddings of items in line with the userâ€™s interests
should be passed more to the user (analogously for the items), MCCF and DisenHAN 
leverage attention mechanism to learn the weights of neighbors . NGCF employs
element-wise product to augment the itemsâ€™ features the user cares about or the usersâ€™ preferences
for features the item has. Take the user node as an example, the aggregated neighbor representation
is calculated as follows:
NIA-GCN argues that existing aggregation functions fail to preserve the relational information
within the neighborhood, thus proposes the pairwise neighborhood aggregation approach to explicitly capture the interactions among neighbors. Concretely, it applies element-wise multiplication
between every two neighbors to model the user-user/item-item relationships.
Information update
Given the information aggregated from its neighbors, how to update the representation of the node
is essential for iterative information propagation. According to whether to retain the information
of the node itself, the existing methods can be divided into two directions. One is to discard the
original information of the user or item node completely and use the aggregated representation
of neighbors as the new central node representation , which might overlook the
intrinsic user preference or the intrinsic item property.
Another is to take both the node itself (h(ğ‘™)
ğ‘¢) and its neighborhood message (n(ğ‘™)
ğ‘¢) into consideration to update node representations. The most straightforward way is to combine these two
representations linearly with sum-pooling or mean-pooling operation . Inspired
by the GraphSAGE , some works adopt concatenation function with nonlinear
transformation to integrate these two representations as follows:
W(ğ‘™) Â· (h(ğ‘™)
ğ‘¢) + b(ğ‘™)
where ğœdenotes the activation function, e.g., ReLU, LeakyReLU, and sigmoid. Compared to linear
combination, concatenation operation with feature transformation allows more complex feature
interaction. LightGCN and LR-GCCF observe that nonlinear activation contributes little
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Graph Neural Networks in Recommender Systems: A Survey
to the overall performance, and they simplify the update operation by removing the non-linearities,
thereby retaining or even improving performance and increasing computational efficiency.
Final node representation
Applying the aggregation and update operations layer by layer generates the representations of
nodes for each depth of GNN. The overall representations of users and items are required for the
final prediction task.
A mainstream approach is to use the node vector in the last layer as the final representation,
 . However, the representations obtained in different layers
emphasize the messages passed over different connections . Specifically, the representations
in the lower layer reflect the individual feature more while those in the higher layer reflect the
neighbor feature more. To take advantage of the connections expressed by the output of different
layers, recent studies employ different methods to integrate the messages from different layers.
Mean-pooling:
Sum-pooling:
Weighted-pooling:
Concatenation:
âŠ•Â· Â· Â· âŠ•h(ğ¿)
where ğ›¼(ğ‘™) is a learnable parameter. Note that mean-pooling and sum-pooling can be seen as
two special cases of weighted pooling. Compared to mean-pooling and sum-pooling, weighted
pooling allows more flexibility to differentiate the contribution of different layers. Among these
four methods, the former three all belong to linear operation, and only concatenation operation
preserves information from all layers.
Corresponding to the discussion at the beginning of this section, we briefly summarize the existing
works from four issues:
â€¢ Graph Construction. The most straightforward way is to directly use the original user-item
bipartite graph. If some nodes have few neighbors in the original graph, it would be beneficial to
enrich the graph structure by either adding edges or nodes. When dealing with large-scale graphs,
it is necessary to sample the neighborhood for computational efficiency. Sampling is a trade-off
between effectiveness and efficiency, and a more effective sampling strategy deserves further study.
â€¢ Neighbor Aggregation. When neighbors are more heterogeneous, aggregating neighbors with
attentive weights would be preferable to equal weights and degree normalization; otherwise, the
latter two are preferable for easier calculation. Explicitly modeling the influence among neighbors
or the affinity between the central node and neighbors might bring additional benefits, but needs
to be verified on more datasets.
â€¢ Information Update. Compared to discarding the original node, updating the node with its
original representation and the aggregated neighbor representation would be preferable. Recent
works show that simplifying the traditional GCN by removing the transformation and non-linearity
operation can achieve better performance than the original ones.
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Wu, et al.
User-item CF
Graph Construction
Neighbor Aggregation
Information Update
Final Node Representation
Original Bipartite Graph
Enriching the Original Graph
Sampling the Neighborhood
GC-MC , SpectralCF , STAR-GCN , NGCF ,
Bi-HGNN , LR-GCCF , LightGCN , AGCN ,
HashGNN , DGCN-BinCF 
Adding Edges:
Multi-GCCF , DGCF , DHCF 
Adding Nodes: DGCF , HiGNN 
Random-walk Sampling: PinSage 
Random Sampling: NIA-GCN , Multi-GCCF 
Equal Weights:
GC-MC , STAR-GCN , Multi-GCCF , IC-MC ,
HashGNN , Bi-HGNN , HiGNN , GraphSAIL 
â€œDegree Normalizationâ€:
LR-GCCF , AGCN , LightGCN , DGCF 
Attentive Weights: MCCF ,DisenHAN 
Central Node Augmentation: NGCF 
Neighbor Interaction: NIA-GCN 
= ğ›¿(W(ğ‘™)n(ğ‘™)
GC-MC , STAR-GCN , DGCF 
Sum/Average of h(ğ‘™)
NGCF , IC-MC , HashGNN ,
NIA-GCN , AGCN 
W(ğ‘™) Â· (h(ğ‘™)
ğ‘¢) + b(ğ‘™)
PinSage , Bi-HGNN , GraphSAIL ,
Multi-GCCF , HiGNN 
LightGCN : h(ğ‘™+1)
LR-GCCF : h(ğ‘™+1)
= W(ğ‘™)n(ğ‘™)
Last Layer Representation hâˆ—
Integration of All Layers
GC-MC , PinSage ,
STAR-GCN , Bi-HGNN ,
HashGNN , DisenHAN 
âŠ•Â· Â· Â· âŠ•h(ğ¿)
SpectralCF , NGCF , IC-MC ,
LR-GCCF , MBGCN 
DGCF 
DGCF 
ğ‘™=0 ğ›¼(ğ‘™)h(ğ‘™)
LightGCN , GCM 
Fig. 3. Summary of representative works in user-item collaborative filtering.
â€¢ Final Node Representation. To obtain overall user/item representation, utilizing the representations from all layers is preferable to directly using the last layer representation. In terms
of the function of integrating the representations from all layers, weighted-pooling allows more
flexibility, and concatenation preserves information from all layers.
Figure 3 summarizes the typical strategies for each of the main issues, and lists the representative
works accordingly.
SEQUENTIAL RECOMMENDATION
Sequential recommendation predicts usersâ€™ next preferences based on their most recent activities,
which seeks to model sequential patterns among successive items, and generate accurate recommendations for users . From the perspective of adjacency between items, sequences of items
can be modeled as graph-structured data. Inspired by the advantage of GNN, it is becoming popular
to utilize GNN to capture the transition pattern from usersâ€™ sequential behaviors by transforming
them into the sequence graph.
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Graph Neural Networks in Recommender Systems: A Survey
user behavior sequence
Sequence model
Next prediction task
Fig. 4. The overall framework of GNN in sequential recommendation.
user behavior sequence
Adding Edges between Two Consecutive Items
MA-GNN 
Adjusting the Graph of Current Sequence
SGNN-HN 
Hypergrpah
Incorporating Other Sequences
Fig. 5. Representative graph construction methods in the sequential recommendation, where the original
nodes and edges are in green, and the additional ones are in red.
Figure 4 illustrates the overall framework of GNN in sequential recommendation. To fully utilize
GNN in the sequential recommendation, there are three main issues to deal with:
â€¢ Graph Construction. To apply GNN in the sequential recommendation, the sequence data
should be transformed into a sequence graph. Is it sufficient to construct a subgraph for each
sequence independently? Would it be better to add edges among several consecutive items than
only between the two consecutive items?
â€¢ Information Propagation. To capture the transition patterns, which propagation mechanism
is more appropriate? Is it necessary to distinguish the sequential order of the linked items?
â€¢ Sequential Preference. To get the userâ€™s temporal preference, the item representations in
a sequence should be integrated. Whether to simply apply attentive pooling or leverage RNN
structure to enhance consecutive time patterns?
Graph construction
Unlike the user-item interactions which have essentially bipartite graph structure, the sequential
behaviors are naturally expressed in the order of time, i.e., sequences, instead of sequence graphs.
Constructing graph based on the original bipartite graph is optional and mainly driven by the
scalability or heterogeneity issue, whereas the construction of sequence graph based on usersâ€™
sequential behaviors is a necessity for applying GNN in sequential recommendation. Figure 5 shows
the representative graph construction strategies for sequential behaviors.
Constructing the directed graph for each sequence by treating each item in the sequence as
a node and adding edges between two consecutively clicked items is the most straightforward
way . However, in most scenarios, the length of the user sequence is short,
e.g., the average length on the preprocessed Yoochoose1/41 dataset is 5.71 . A sequence graph
constructed from a single and short sequence consists of a small number of nodes and connections,
and some nodes might even have only one neighbor, which contains too limited knowledge to
1The dataset is available at html. Note that this work preprocesses the dataset by
filtering out the sequences of length 1 and items appearing less than 5 times.
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Wu, et al.
reflect usersâ€™ dynamic preferences and cannot take full advantage of GNN in graph learning. To
tackle this challenge, recent works propose several strategies to enrich the original sequence graph
structure, which can be divided into two mainstreams.
One mainstream is to utilize additional sequences to enrich the item-item transitions. The
additional sequences can be other types of behavior sequences , the historical sequences of the
same user , or part/all of the sequences in the whole dataset . For instance,
HetGNN utilizes all behavior sequences, and constructs edges between two consecutive items
in the same sequence with their behavior types as the edge types. A-PGNN deals with the
occasion when users are known, thus incorporating the userâ€™s historical sequences with the current
sequence to enrich the item-item connections. GCE-GNN and DAT-MDI exploit the item
transitions in all sessions to assist the transition patterns in the current sequence, which leverage
the local context and global context. Different from GCE-GNN and DAT-MDI that treats
all the transitions equally, TASRec attaches more importance to the recent transitions to
augment the more recent transitions. Instead of incorporating all the sessions, DGTN only
adds similar sessions to the current session, based on the assumption that similar sequences are
more likely to reflect similar transition patterns. All these methods introduce more information
into the original graph, and improve the performance compared to a single sequence graph.
Another mainstream approach is to adjust the graph structure of the current sequence. For
example, assuming the current node has a direct influence on more than one consecutive item,
MA-GNN extracts three subsequent items and adds edges between them. Considering that
only adding edges between consecutive items might neglect the relationships between distant items,
SGNN-HN introduces a virtual â€œstarâ€ node as the center of the sequence, which is linked with
all the items in the current sequence. The vector-wise representation of the â€œstarâ€ node reflects
the overall characteristics of the whole sequence. Hence, each item can gain some knowledge
of the items without direct connections through the â€œstarâ€ node. Chen and Wong point out
that existing graph construction methods ignore the sequential information of neighbors, and
bring about the ineffective long-term capturing problem. Therefore, they propose LESSR, which
constructs two graphs from one sequence: one distinguishes the order of neighbors, another allows
the short-cut path from the item to all the items after it.
In addition to the above two mainstreams, other graph construction methods have emerged
recently. Inspired by the advantage of hypergraph in modeling beyond-pairwise relations, hypergraph has been leveraged to capture the high-order relations among items and the cross-session
information. SHARE constructs a hypergraph for each session, of which the hyperedges are
defined by various sizes of sliding windows. DHCN takes each session as one hyperedge and
integrates all the sessions in one hypergraph. To explicitly incorporate cross-session relationships,
DHCN and COTREC construct the session-to-session graph, which takes each session
as a node and assigns the weights based on the shared items.
Information propagation
Given a built sequence graph, it is essential to design an efficient propagation mechanism to capture
transition patterns among items. The GGNN framework is widely adopted to propagate information
on the directed graph. Specifically, it employs mean-pooling to aggregate the information of the
previous items and the next items respectively, combines the two aggregated representations, and
utilizes GRU component to integrate the information of neighbors and the central node. The
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Graph Neural Networks in Recommender Systems: A Survey
propagation functions are given as follows:
ğ‘–ğ‘ ,ğ‘¡| Î£ğ‘—âˆˆNin
ğ‘–ğ‘ ,ğ‘¡| Î£ğ‘—âˆˆNout
ğ‘–ğ‘ ,ğ‘¡= nin(ğ‘™)
= GRU(h(ğ‘™)
ğ‘–ğ‘ ,ğ‘¡, n(ğ‘™)
ğ‘–ğ‘ ,ğ‘¡, Nout
ğ‘–ğ‘ ,ğ‘¡denotes the neighborhood set of previous items and next items, GRU(Â·) represents
the GRU component. Different from the pooling operation, the gate mechanism in GRU decides
what information to be preserved and discarded. Unlike GGNN which treats the neighbors equally,
attention mechanism is also utilized to differentiate the importance of neighbors .
All the above methods adopt the permutation-invariant aggregation function during the message
passing, ignoring the order of items within the neighborhood, which may lead to the loss of
information . To address this issue, LESSR preserves the order of items in the graph
construction, and leverages the GRU component to aggregate the neighbors sequentially, as
the following equation:
ğ‘–ğ‘ ,ğ‘¡,ğ‘˜= GRU(ğ‘™) (n(ğ‘™)
ğ‘–ğ‘ ,ğ‘¡,ğ‘˜âˆ’1, h(ğ‘™)
where h(ğ‘™)
ğ‘–ğ‘ ,ğ‘¡,ğ‘˜represents the ğ‘˜ğ‘¡â„item in the neighborhood of ğ‘–ğ‘ ,ğ‘¡ordered by time, and n(ğ‘™)
ğ‘–ğ‘ ,ğ‘¡,ğ‘˜denotes
the neighborhood representation after aggregating ğ‘˜items.
For the sequence graph with hypergraph structure, DHCN adopts the typical hypergraph
neural network HGNN , which treats the nodes equally during propagation. To differentiate the
importance of items within the same hyperedge, SHARE designs two attention mechanisms
to propagate the information of item nodes. One is the hyperedges, and the other is the information of the hyperedges to the connected item nodes. For user-aware sequential recommendation,
A-PGNN and GAGA implicitly incorporate the user information, and augment the
representations of items in the neighborhood with user representation.
Sequential preference
Due to the limited iteration of propagation, GNN cannot effectively capture long-range dependency
among items . Therefore, the representation of the last item (or any item) in the sequence is not
sufficient enough to reflect the userâ€™s sequential preference. Besides, most of the graph construction
methods of transforming sequences into graphs lose part of the sequential information . In
order to obtain the effective sequence representation, existing works propose several strategies to
integrate the item representations in the sequence.
Considering that the items in a sequence have different levels of priority, the attention mechanism
is widely adopted for integration. Some works calculate the attentive weights
between the last item and all the items in the sequence and aggregate the item representations as
the global preference, and incorporate it with local preference (i.e., the last item representation)
as the overall preference. In this way, the overall preference relies heavily on the relevance of the
last item to the user preference. Inspired by the superiority of multi-layer self-attention strategy
in sequence modeling, GC-SAN stacks multiple self-attention layers on the top of the item
representations generated by GNN to capture long-range dependencies.
In addition to leveraging attention mechanism for sequence integration, sequential signals are
explicitly incorporated into the integration process. For instance, NISER and GCE-GNN 
add the positional embeddings, which reflect the relative order of the items, to effectively obtain
position-aware item representations. To balance the consecutive time and flexible transition pattern,
FGNN employs the GRU with attention mechanism to iteratively update the user preference
with item representations in the sequence.
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Wu, et al.
Sequential Recommendation
Graph Construction
Information Propagation
Sequential Preference
Adding Edges between Two Consecutive Items:
SR-GNN , GC-SAN , NISER , FGNN , GAG 
Incorporating Other Sequences:
HetGNN , A-PGNN , DGTN , GCE-GNN ,
DAT-MDI , TASRec , COTREC 
Adjusting the Graph of Current Sequence:
MA-GNN , SGNN-HN , LESSR , SURGE 
Hypergraph: SHARE , DHCN 
Variants of GGNN:
SR-GNN , GC-SAN , NISER , SGNN-HN , DAT-MDI 
Attention Mechanism:
FGNN , GCE-GNN , SURGE 
GCN Framework: TASRec , COTREC 
GRU for Aggregation: LESSR 
Attention Mechanism:
SR-GNN , GAG , SGNN-HN , DGTN , GC-SAN 
Adding Positional Embedding:
NISER , GCE-GNN 
GRU with Attention: FGNN 
Fig. 6. Summary of representative works in sequential recommendation.
All the above works integrate the item representations within the userâ€™s behavior sequence to
generate the representation of sequential preference. Apart from these methods, DHCN and
COTREC enrich the sequence graph by the session-to-session graph in the graph construction
step. Therefore, they combine the sequential representation learned from the session-to-session
graph and the one aggregated from items at this step.
This part briefly summarizes the reviewed works in terms of the three main issues.
â€¢ Graph Construction. The most straightforward construction is to add edges between the two
consecutive items. When the sequence length is short, utilizing additional sequences can enrich
the sequence graph, and it would be preferable if the additional sequence are more similar to the
original sequence. Another line is to adjust the graph structure of the behavior sequence. There is
no accepted statement on which method is better. Moreover, incorporating the session-to-session
graph into the sequence graph is also used to gain further improvements.
â€¢ Information Propagation. Most of the propagation methods are variants of the propagation
methods in traditional GNN frameworks, and there is no consensus on which method is better.
Some complex propagation methods, such as LESSR , achieve performance gain at the cost of
more computation. Whether to adopt complex propagation methods in practice depends on the
trade-off between computation costs and performance gains.
â€¢ Sequential Preference. To obtain the sequential preference, an attention mechanism is widely
adopted to integrate the representations of items in the sequence. Beyond that, adding positional
embeddings can enhance the relative order of the items and can bring a few improvements. Whether
leveraging RNN structure can boost performance for all the sequential recommendation tasks
requires further investigation.
Figure 6 summarizes the typical strategies for each of the main issues and lists the representative
works accordingly.
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Graph Neural Networks in Recommender Systems: A Survey
Social GNN block
U-I GNN block
(a) The framework of GNN on the bipartite graph
and social network graph separately.
(b) The framework of GNN on the unified graph
of user-item interactions and social network.
Fig. 7. Two strategies for social enhanced general recommendation.
SOCIAL RECOMMENDATION
With the emergence of online social networks, social recommender systems have been proposed to
utilize each userâ€™s local neighborsâ€™ preferences to enhance user modeling . All
these works assume users with social relationships should have similar representations based on
the social influence theory that connected people would influence each other. Some of them directly
use such relationship as regularizer to constraint the final user representations ,
while others leverage such relationship as input to enhance the original user embeddings .
From the perspective of graph learning, the early works mentioned above can be seen as modeling
the first-order neighbors of each user. However, in practice, a user might be influenced by her/his
friendsâ€™ friends. Overlooking the high-order influence diffusion in previous works might lead to the
suboptimal recommendation performance . Thanks to the ability of simulating how users are
influenced by the recursive social diffusion process, GNN has become a popular choice to model
the social information in recommendation.
To incorporate relationships among users into interaction behaviors by leveraging GNN, there
are two main issues to deal with:
â€¢ Influence of Friends. Do friends have equal influence? If not, how to distinguish the influence
of different friends?
â€¢ Preference Integration. Users are involved in two types of relationships, i.e., social relationships with their friends and interactions with items. How to integrate the user representations
from the social influence perspective and interaction behavior?
Influence of friends
Generally, a social graph only contains information about whether the users are friends, but the
strengths of social ties are usually unknown. To propagate the information of friends, it is essential
to decide the influence of friends. DiffNet treats the influence of friends equally by leveraging
mean-pooling operation. However, the assumption of equal influence is not in accordance with the
actual situation, and the influence of a user is unsuitable to be simply determined by the number
of her/his friends. Indeed, users are more likely to be influenced by friends with strong social ties
or similar preferences. Therefore, attention mechanism is widely leveraged to differentiate the
influence of neighbors . For example, Song et al. propose DGRec,
which dynamically infers the influence of neighbors based on their current interests. It first models
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Wu, et al.
dynamic usersâ€™ behaviors with a recurrent neural network, and then acquires the social influence
with a graph-attention neural network. Compared to the mean-pooling operation, the attention
mechanism boosts the overall performance, which further verifies the assumption that different
friends have different influence power.
Moreover, a recent work, named ESRF , argues that social relations are not always reliable.
The unreliability of social information lies in two aspects: on the one hand, the users with explicit
social connections might have no influence power; on the other hand, the obtained social relationships might be incomplete. Considering that indiscriminately incorporating unreliable social
relationships into recommendation may lead to poor performance, ESRP leverages the autoencoder
mechanism to modify the observed social relationships by filtering irrelevant relationships and
investigating the new neighbors. Similarly, DiffNetLG involves implicit local influence to
predict the unobserved social relationship and then utilizes both explicit and implicit social relations
to make recommendations.
Preference Integration
Users in social recommendatioin are involved in two types of relationships, one is the user-item
interactions and the other is the social graph. To enhance the user preference representation by
leveraging social information, there are two strategies for combining the information from these
two networks,
â€¢ to learn the user representation from these two networks respectively and then
integrate them into the final preference vector, as illustrated in Figure 7a;
â€¢ to combine the two networks into one unified network and apply GNN to propagate
information, as illustrated in Figure 7b.
The advantage of the first strategy lies in two aspects: on the one hand, we can differentiate the
depth of diffusion process of two networks since they are treated separately; on the other hand,
any advanced method for user-item bipartite graph can be directly applied, and for social network,
a homogeneous graph, GNN techniques are extremely suitable for simulating the influence process
since they are originally proposed for homogeneous graphs. As for the integration of the user
representations learned from two relationships, there are two main mechanisms, i.e., linearity
combination and non-linearity combination. Among the linearity combination, DiffNet treats
the user representations from two spaces equally, and combines them with a sum-pooling operation.
Instead of an equal-weight combination, DANSER dynamically allocates weights according
to the user-item paired features. Among the non-linearity combination, multi-layer perceptrons
over the concatenated vector are widely adopted to enhance the feature interactions .
The advantage of integrating the two graphs into one unified network is that both the higherorder social influence diffusion in the social network and interest diffusion in the user-item bipartite
graph can be simulated in a unified model, and these two kinds of information simultaneously
reflect usersâ€™ preferences. DiffNet++ designs a two-level attention network to update user
nodes at each layer. Specifically, it firstly aggregates the information of neighbors in the bipartite
graph (i.e., interacted items) and social network (i.e., friends) by utilizing the GAT mechanism
respectively. Considering that different users may have different preferences in balancing these
two relationships, it further leverages another attention network to fuse the two hidden states of
neighbors. Similarly, SEFrame utilizes a heterogeneous graph network to fuse the knowledge
from social relationships, user-item interactions and item transitions from the heterogeneous graph,
and employs a two-level attention network for propagation. Up till now, there is no evidence to
show which strategy always achieves better performance.
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Graph Neural Networks in Recommender Systems: A Survey
Social Recommendation
Influence of Friends
Preference Integration
Equal Influence: DiffNet 
Differentiating Influence by Attention:
GraphRec , DiffNet++ , DANSER ,
GAT-NSR , DGRec , TGRec 
Modifying the Relations:
ESRF , DiffNetLG 
Separate Graphs
A Unified Graph
Linearity Combination:
Equal weights: DiffNet 
Different weights: DANSER 
Non-linearity Combination:
GraphRec , GNN-SoR , SR-HGNN 
A Hierarchical Aggregation Schema:
DiffNet++ , SEFrame 
Fig. 8. Summary of representative works in social recommendation.
Corresponding to the discussion at the beginning of this section, we briefly summarize the current
works in terms of the two issues:
â€¢ Influence of Friends. Compared to assigning equal weights to friends, differentiating the
influence of different friends is more appropriate. An emerging direction is to automatically modify
the social relationship, which can benefit from the presence of noise in social networks.
â€¢ Preference Integration. The strategies for combining the two sources of information depends
on whether to consider the two graphs separately or unify them into one graph. For the separate
graphs, user preference is an integration of the overall representations learned from these two
graphs. For the unified graph, a commonly adopted strategy is the hierarchical aggregation schema.
Figure 8 summarizes the typical strategies for each of the main issues, and lists the representative
works accordingly.
KNOWLEDGE GRAPH BASED RECOMMENDATION
Social network that reflects relationships between users, is utilized to enhance user representation,
while knowledge graph that expresses relationships between items through attributes, is leveraged
to enhance the item representation. Incorporating knowledge graph into recommendation can bring
two-facet benefits : (1) the rich semantic relations among items in a knowledge graph can
help explore their connections and improve the item representation; (2) knowledge graph connects
a userâ€™s historically interacted items and recommended items, which enhances the interpretability
of the results .
Despite the above benefits, utilizing knowledge graph in recommendation is rather challenging
due to its complex graph structure, i.e., multi-type entities and multi-type relations. Previous
works preprocess knowledge graph by knowledge graph embedding (KGE) methods to learn the
embeddings of entities and relations, such as The limitation of commonly-used
KGE methods is that they focus on modeling rigorous semantic relatedness with the transition
constraint, which are more suitable for the tasks related to graph, such as link prediction rather
than recommendation . Meta-path based methods manually define meta-paths that carry
the high-order information and feed them into a predictive model, and thus they require domain
knowledge and are rather labor-intensive for complicated knowledge graph .
Given the user-item interaction information as well as the knowledge graph, the knowledge
graph based recommendation seeks to take full advantage of the rich information in the knowledge
graph, which can help to estimate the usersâ€™ preferences for items by explicitly capturing relatedness
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Wu, et al.
between items. For the effectiveness of knowledge graph based recommendation, there are two
main issues to deal with:
â€¢ Graph Construction. How to effectively integrate the collaborative signals from user-item
interactions and the semantic information from the knowledge graph? Whether to explicitly
incorporate the user nodes into knowledge graph or implicitly use the user nodes to distinguish
the importance of different relations?
â€¢ Relation-aware Aggregation. One characteristic of knowledge graph is that it has multiple types of relations between entities. How to design a relation-aware aggregation function to
aggregate information from linked entities?
Graph Construction
For the stage of graph construction, one main concern is how to effectively integrate the collaborative signals and knowledge information.
One direction is to incorporate the user nodes into the knowledge graph. For instance, KGAT ,
MKGAT and CKAN combine the user-item bipartite graph and knowledge graph into
one unified graph by taking the user nodes as one type of entity and the relation between users and
items as â€œinteraction". Recent efforts focus on the entities and relations relevant to the user-item
pair. Therefore, they construct the subgraph that links the user-item pair with the userâ€™s historical
interacted items and the related semantics in knowledge graph . Based on the assumption
that a shorter path between two nodes reflects more reliable connections, AKGE constructs
the subgraph by the following steps: pre-train the embeddings of entities in the knowledge graph
by TransR ; calculate the pairwise Euclidean distance between two linked entities; keep the ğ¾
paths with the shortest distance between the target user and item node. The potential limitation is
that the subgraph structure depends on the pre-trained entity embeddings and the definition of
distance measurement. ATBRG exhaustively searches the multi-layer entity neighbors for the
target item and the items from the userâ€™s historical behaviors and restores the paths connecting
the user behaviors and the target item by multiple overlapped entities. In order to emphasize the
information-intensive entities, ATBRG further prunes the entities with a single link, which can also
help control the scale of the graph. Although these methods can obtain subgraphs more relevant
to the user-item pair, it is quite time-consuming to pre-train the entity embedding or search and
prune paths exhaustively. An effective and efficient subgraph construction strategy is worthy of
further investigation.
Another direction is to implicitly use the user nodes to distinguish the importance of different
relations. For instance, KGCN and KGNN-LS take the user nodes as queries to assign
weights to different relations. In terms of graph construction, this line of research emphasizes the
usersâ€™ preferences towards relations instead of the collaborative signal in user-item interactions.
Relation-aware Aggregation
To fully capture the semantic information in knowledge graph, both the linked entities (i.e., ğ‘’ğ‘–,ğ‘’ğ‘—)
and the relations in between (i.e., ğ‘Ÿğ‘’ğ‘–,ğ‘’ğ‘—) should be taken into consideration during the propagation
process. Besides, from the perspective of recommender systems, the role of users might also have an
influence. Owing to the advantage of GAT in adaptively assigning weights based on the connected
nodes, most of the existing works apply the variants of the traditional GAT over the knowledge
graph, i.e., the central node is updated by the weighted average of the linked entities, and the
weights are assigned according to the score function, denoted as ğ‘(ğ‘’ğ‘–,ğ‘’ğ‘—,ğ‘Ÿğ‘’ğ‘–,ğ‘’ğ‘—,ğ‘¢). The key challenge
is to design a reasonable and effective score function.
For the works that regard the user nodes as one type of entities, the usersâ€™ preferences are expected to be spilled over to the entities in the knowledge graph during the propagation
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Graph Neural Networks in Recommender Systems: A Survey
Knowledge Graph Based
Recommendation
Graph Construction
Relation-aware Aggregation
User Node as Entity
Only Knowledge Graph: KGCN , KGNN-LS 
A Unified Graph:
KGAT , MKGAT , CKAN 
User-item Subgraph:
AKGE , ATBRG 
Only Relation: KGAT , MKGAT , CKAN 
User-aware: KGCN , KGNN-LS , KGPolicy 
Fig. 9. Summary of representative works in knowledge graph based recommendation.
process since the item nodes would be updated with the information of interacted users and related
attributes, then the other entities would contain usersâ€™ preferences with iterative diffusion. Therefore, these works do not explicitly model usersâ€™ interests in relations but differentiate the influence
of entities by the connected nodes and their relations. For instance, inspired by the transition
relationship in knowledge graph, KGAT assigns the weight according to the distance between
the linked entities in the relation space,
ğ‘(ğ‘’ğ‘–,ğ‘’ğ‘—,ğ‘Ÿğ‘’ğ‘–,ğ‘’ğ‘—,ğ‘¢) =  Wğ‘Ÿeğ‘—
 Wğ‘Ÿeğ‘–+ eğ‘Ÿğ‘’ğ‘–,ğ‘’ğ‘—
where Wğ‘Ÿis the transformation matrix for the relation, which maps the entity into relation space.
In this way, the closer entities would pass more information to the central node. These methods
are more appropriate for the constructed subgraph containing user nodes, since it is difficult for
the usersâ€™ interests to extend to all the related entities by stacking a limited number of GNN layers.
For the works that do not combine the two sources of graphs, these studies explicitly
characterize usersâ€™ interests in relations by assigning weights according to the connecting relation
and specific user. For example, the score function adopted by KGCN is the dot product of the
user embedding and the relation embedding, i.e.,
ğ‘(ğ‘’ğ‘–,ğ‘’ğ‘—,ğ‘Ÿğ‘’ğ‘–,ğ‘’ğ‘—,ğ‘¢) = uâŠ¤rei,ej.
In this way, the entities whose relations are more consistent with usersâ€™ interests will spread more
information to the central node.
Corresponding to the discussion at the beginning of this section, we briefly summarize the current
works in terms of the two issues:
â€¢ Graph Construction. Existing works either consider the user nodes as one type of entities
or implicitly use the user nodes to differentiate the relations. The first direction can be further
divided into the overall unified graph or the specific subgraph for the user-item pair. Compared to
the overall unified graph, the user-item subgraph has the advantage of focusing on more related
entities and relations, but it requires more computation time and the performance depends on the
construction of the subgraph, which still requires further investigation.
â€¢ Relation-aware Aggregation. The variants of GAT are widely leveraged to aggregate information from linked entities, taking into account the relations. For the graphs that do not explicitly
incorporate user nodes, user representations are utilized to assign weights to the relations.
Figure 9 summarizes the typical strategies for each of the main issues, and lists the representative
works accordingly.
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Wu, et al.
OTHER TASKS
In addition to these four types of tasks, the researchers have started to utilize GNN for improving
the performance of other recommendation tasks, such as POI recommendation and multimedia recommendation. In this section, we will summarize the recent developments for each task
respectively.
Points-of-interest (POI) recommendation plays a key role in location-based service, which
utilizes the geographical information to capture geographical influence among POIs and usersâ€™
historical check-ins to model the transition patterns. In the field of POI recommendation, there
are several kinds of graph data, such as the user-POI bipartite graph, the sequence graph based
on check-ins and geographical graph, i.e., the POIs within a certain distance are connected and
the edge weights depend on the distance between POIs . SGRec enriches the check-in
sequence with the correlated POIs belonging to other check-ins, which allows collaborative signals
to be propagated across sequences. Chang et al. believe that the more often users consecutively
visited the two POIs, the greater the geographical influence between these two POIs. Hence, the
check-ins not only reflect usersâ€™ dynamic preferences but also indicate the geographical influence
among POIs. To explicitly incorporate the information of geographical distribution among POIs,
the edge weights in the sequence graph depend on the distance between POIs .
Group recommendation aims to suggest items to a group of users instead of an individual
one based on their historical behaviors. There exist three types of relationships: user-item, each
user interacts with several items; user-group, a group consists of several users; and group-item,
a group of users all choose the same item. â€œGroupâ€ can be regarded as a bridge connecting the
users and the items in the group recommendation, which can be either treated as a part of the
graph or not. Here are two representative works corresponding to these two strategies respectively.
GAME introduces the â€œgroup nodeâ€ in the graph, and applies the GAT to assign appropriate
weights to each interacted neighbor. With the propagation diffusion, group representation can be
iteratively updated with interacted items and users. However, this approach can not be directly
applied to the task where groups are changed dynamically and new groups are constantly formed.
Different from the former transductive method, GLS-GRL learns the group representative in
an inductive way, which constructs the corresponding graph for each group specifically. The group
representation is generated by integrating the user representations involved in the group, which
can address the new group problem.
Bundle recommendation aims to recommend a set of items as a whole for a user. There are
three types of relationships: user-item, each user interacts with several items; user-bundle, users
choose the bundles; and bundle-item, a bundle consists of several items. For group recommendation,
â€œgroupâ€ is made up of users; for bundle recommendation, â€œgroupâ€ means a set of items. Analogously,
the key challenge is to obtain the bundle representation. BGCN unifies the three relationships
into one graph and designs the item level and bundle level propagation from the usersâ€™ perspective.
HFGN considers the bundle as the bridge that users interact with the items through bundles.
Correspondingly, it constructs a hierarchical structure upon user-bundle interactions and bundleitem mappings and further captures the item-item interactions within a bundle.
Click-through rate (CTR) prediction is an essential task for recommender systems in largescale industrial applications, which predicts the click rate based on the multi-type features. The
key challenges of CTR are to model feature interactions and capture user interests. Inspired by the
information diffusion process of GNN, a recent work, Fi-GNN , employs GNN to capture the
high-order interactions among features. Specifically, it constructs a feature graph, where each node
corresponds to a feature field and different fields are connected with each other through edges.
Hence, the task of feature interactions is converted to propagate node information across the graph.
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Graph Neural Networks in Recommender Systems: A Survey
Despite its considerable performance, Fi-GNN ignores the collaborative signals implicit in user
behaviors. DG-ENN designs both the attribute graph and user-item collaborative graph, and
utilizes GNN techniques to capture the high-order feature interactions and collaborative signals.
To further alleviate the sparsity issue of the user-item interactions, DG-ENN enriches the original
user-item interaction relationships with user-user similarity relationships and item-item transitions.
Multimedia Recommendation has been a core service to help users identify multimedia
contents of interest. The main characteristic is the contents are in multi-modality, e.g., text, images,
and videos. Recently, researchers start to adopt GNN to capture the collaborative signals from
usersâ€™ interactions with multi-modal contents. For instance, MMGCN constructs a user-item
bipartite graph for each modality and applies GNN to propagate information for each graph,
respectively. The overall user/item representations are the sum of the user/item representations
of different modalities. GRCN utilizes the multi-modal contents to refine the connectivity
of user-item interactions. For each propagation layer, GRCN takes the maximum value of the
user-item similarities in different modalities as the weight of the user-item interaction edges and
uses the corresponding weights to aggregate neighbors. MKGAT unifies the user nodes
and multi-modal knowledge graph into one graph and employs a relation-aware graph attention
network to propagate information. Considering the multi-modal characteristic of entities, MKGAT
designs the entity encoder to map each specific data type into a condensed vector.
DATASETS, EVALUATION METRICS AND APPLICATIONS
In this section, we introduce the commonly-adopted datasets and evaluation metrics for different
recommendation tasks, and summarize the real-world applications of GNN-based recommendation.
This section can help researchers find suitable datasets and evaluation metrics to test their methods,
and get an overview of the practical applications of GNN-based recommendation.
This part introduces the public commonly-adopted datasets for GNN-based recommendation
systems, as summarized in Table 2. Due to the page limit, we do not list the datasets used by other
recommender tasks, and we refer readers to the published works.
MovieLens2 datasets are collected from MovieLens website, among which three stable benchmark datasets with different scales of rating pairs, i.e., MovieLens-100K, MovieLens-1M, and
MovieLens-20M, are most commonly used . Each dataset contains user-item rating pairs with
timestamps, the movieâ€™s attributes and tags, and user demographic features. The ratings range from
1 to 5, with a minimum interval of 1. The MovieLens datasets are widely adopted as benchmark
datasets in user-item collaborative filtering tasks and knowledge graph based recommendation.
Amazon3 dataset includes reviews (ratings, text, helpfulness votes), product metadata (descriptions, category information, price, brand, and image features), and links (also viewed/also bought
graphs) . The full dataset is split into sub-datasets by categories, e.g., Amazon-Books, Amazon-
Instant Video, and Amazon-Electronics. The sub-datasets in Amazon are usually adopted to test
the performance in user-item collaborative filtering and sequential recommendation.
Yelp 4 dataset contains the user check-ins and is still being updated. Yelp dataset is widely
adopted in user-item collaborative filtering and POI recommendation tasks. Existing works usually
select one-year data for experiments, e.g., NGCF uses the 2018 edition of the Yelp dataset.
2 
3 
4 
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Wu, et al.
Table 2. Datasets of GNN-based recommendation tasks.
User-Item CF
MovieLens-100K
GC-MC , STAR-GCN , DHCF 
MovieLens-1M
GC-MC , SpectralCF , STAR-GCN , Bi-HGNN , DGCN-BinCF 
MovieLens-10M
GC-MC , STAR-GCN , DGCN-BinCF 
SpectralCF , NGCF , LR-GCCF , LightGCN , DGCF , AGCN , NIA-GCN , Multi-GCCF 
NGCF , LR-GCCF , LightGCN , HashGNN , DGCF , NIA-GCN , Multi-GCCF 
NGCF , LightGCN , DGCN-BinCF , DGCF , Multi-GCCF 
Sequential
Recommendation
SR-GNN , NISER , FGNN , HetGNN , DGTN , DAT-MDI , SGNN-HN , SHARE , DHCN ,
Diginetica
SR-GNN , GC-SAN , NISER , FGNN , DGTN , GCE-GNN , DAT-MDI ,
TASRec , COTREC , SGNN-HN , LESSR , SHARE , DHCN 
Retailrocket
GC-SAN , NISER , TASRec , COTREC 
MA-GNN , TGSRec 
GAG , LESSR 
GAG , LESSR , SERec , DGSR 
Recommendation
DiffNet , DiffNet++ , DGRec , GNN-SoR , KCGN 
DiffNet , DiffNet++ , MHCN 
GraphRec , GNN-SoR , SR-HGNN 
GraphRec , DANSER , KCGN , SR-HGNN 
ESRF , GNN-SoR , MHCN 
ESRF , DGRec , SR-HGNN , MHCN 
Recommendation
MovieLens-1M
AKGE , TGCN , KHGT 
MovieLens-10M
MKGAT 
MovieLens-20M
KGCN , KGNN-LS , CKAN 
Book-Crossing
KGCN , KGNN-LS , CKAN 
KGCN , KGNN-LS , KGAT , AKGE , TGCN , CKAN 
KGNN-LS , MKGAT , CKAN 
KGAT , AKGE , KHGT 
KGAT , IntentGC , ATBRG 
IntentGC , ATBRG 
Gowalla5 dataset is the check-in dataset obtained from Gowalla, where users share their locations
by checking-in . In addition to the check-in information, Gowalla dataset also contains the
social relationship among users. Gowalla is a classical dataset for POI recommendation and adopted
in user-item collaborative filtering and sequential recommendation as well.
Yoochoose6 dataset is obtained from the RecSys Challenge 2015, which contains a stream of
user clicks on an e-commerce website within 6 months. Instead of the entire dataset, most of the
recent studies use the most recent fractions 1/64 and 1/4 of the sequences as the experimental
datasets, named Yoochoose1/64 and Yoochoose1/4, respectively.
Diginetica7 is provided by CIKM Cup 2016, which contains the transactional data in chronological order. Diginetica is commonly used in session-based recommendation.
RetailRocket8 dataset has been collected from a real-world ecommerce website, which contains
six months of user browsing activities.
LastFM9 dataset contains musician listening information from a set of 2 thousand users and
the attributes of artists from Last.fm10 online music system . This dataset is widely adopted by
sequential recommendation, social recommendation and knowledge graph based recommendation.
Epinions dataset and Ciao dataset are shared by Tang et al. . Each dataset contains the
usersâ€™ ratings (from 1 to 5), reviews towards items, and the directed trust relationships between
users. These two datasets have been widely used as benchmarks for social recommendation.
5 
6 
7 
8 
9 
10 
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Graph Neural Networks in Recommender Systems: A Survey
Table 3. Evaluation metrics of GNN-based recommendation tasks.
User-Item CF
SpectralCF , NGCF , LightGCN , DGCN-BinCF , DHCF , DGCF , NIA-GCN , Multi-GCCF 
SpectralCF , DGCN-BinCF 
NGCF , LR-GCCF , LightGCN , AGCN , HashGNN , DGCN-BinCF , DHCF , DGCF , NIA-GCN , Multi-GCCF 
LR-GCCF , AGCN , HashGNN , DHCF , PinSage 
Sequential
Recommendation
SR-GNN , FGNN , GCE-GNN , COTREC , SGNN-HN , DHCN 
SR-GNN , GC-SAN , NISER , FGNN , GAG , HetGNN , A-PGNN , DGTN , GCE-GNN ,
COTREC , SGNN-HN , LESSR , SURGE , SHARE , DHCN , SERec , TGSRec 
GC-SAN , HetGNN , LESSR , SHARE , SERec , DGSR 
NISER , GAG , A-PGNN , DGTN , DAT-MDI , TASRec , MA-GNN , TGSRec 
HetGNN , DAT-MDI , TASRec , MA-GNN , SURGE , DGSR 
Recommendation
DiffNet , DiffNet++ , KCGN 
DiffNet , DiffNet++ , ESRF , DGRec , GNN-SoR , KCGN , MHCN 
DANSER , HGP 
DANSER , ESRF , MHCN 
ESRF , DGRec , MHCN 
Recommendation
KGCN , IntentGC , ATBRG , CKAN 
KGCN , CKAN 
KGNN-LS , KGAT , MKGAT 
KGAT , AKGE , MKGAT , TGCN , KHGT 
AKGE , TGCN , KHGT 
Book-Crossing11 dataset contains 1 million ratings (ranging from 0 to 10) of books and the
attributes of books (e.g., title, author) in the Book-Crossing community. This dataset is widely used
as a benchmark for knowledge graph based recommendation.
Evaluation Metrics
It is essential to select adequate metrics to evaluate the performance of compared methods. Table 3
summarizes the evaluation metrics adopted by different recommendation tasks.
HR measures the proportion of users who have at least one click on the recommended items, i.e.,
|U| Î£ğ‘¢âˆˆUğ¼(|ğ‘…ğ¾(ğ‘¢) âˆ©ğ‘‡(ğ‘¢)| > 0),
where ğ‘‡(ğ‘¢) denotes the ground truth item set, ğ‘…ğ¾(ğ‘¢) denotes the top-K recommended item set,
and ğ¼(Â·) is the indicator function.
Precision, Recall and F1 are widely adopted to evaluate the accuracy of top-K recommendation.
Precision@K measures the fraction of the items the user will click among the recommended K
items. Recall@K measures the proportion of the number of user clicks in the recommended K items
to the entire click set. F1@K is the combination of Precision@K and Recall@K.
Precision@ğ¾(ğ‘¢) = |ğ‘…ğ¾(ğ‘¢) âˆ©ğ‘‡(ğ‘¢)|
Recall@ğ¾(ğ‘¢) = |ğ‘…ğ¾(ğ‘¢) âˆ©ğ‘‡(ğ‘¢)|
F1@ğ¾(ğ‘¢) =2 Ã— Precision@ğ¾(ğ‘¢) Ã— Recall@ğ¾(ğ‘¢)
Precision@ğ¾(ğ‘¢) + Recall@ğ¾(ğ‘¢)
The overall metric is the average over all the usersâ€™, e.g., Precision@ğ¾=
|U | Î£ğ‘¢âˆˆUPrecision@ğ¾(ğ‘¢).
NDCG differentiates the contributions of the accurately recommended items based on their
ranking positions.
ğ‘˜(ğ‘¢) âˆˆğ‘‡(ğ‘¢))
ğ‘˜(ğ‘¢) denotes the ğ‘˜ğ‘¡â„item in the recommended list ğ‘…ğ¾(ğ‘¢).
11 cziegler/BX/
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Wu, et al.
MAP is a widely adopted ranking metric, which measures the average precision over users,
|U| Î£ğ‘¢âˆˆUÎ£ğ¾
ğ‘˜(ğ‘¢) âˆˆğ‘‡(ğ‘¢))Precision@ğ‘˜(ğ‘¢)
AUC is the probability that the model ranks a clicked item more highly than a non-clicked item.
When the implicit feedback estimation is considered a binary classification problem, AUC is widely
adopted to evaluate the performance.
AUC(ğ‘¢) = Î£ğ‘–âˆˆğ‘‡(ğ‘¢)Î£ğ‘—âˆˆI\ğ‘‡(ğ‘¢)ğ¼(Ë†ğ‘Ÿğ‘–> Ë†ğ‘Ÿğ‘—)
|ğ‘‡(ğ‘¢)||I \ğ‘‡(ğ‘¢)|
The overall AUC is the average over all the usersâ€™.
Applications
In this part, we summarize the real-world applications of GNN-based recommendation models
according to the existing works published by the industry.
Product(Advertisement) recommendation on E-commerce platform is one of the most common
application scenarios . For instance, IntentGC leverages both explicit
preferences in user-item interactions and heterogeneous relationships in knowledge graph by graph
convolutional networks, and is deployed at Alibaba platform for recommending products to users.
Another application is the content recommendation, which recommends news, articles to users. For
example, Wu et al. deploy DANSER on a real-world article recommender system, WeChat Top
Story by exploiting the user-article interactions and social relationships. App recommendation has
also attempted to utilize GNN-based models, e.g., GraphSAIL is deployed in the recommender system
of a mainstream App Store, which selects several hundred apps from the universal set for each
user . Besides, Ying et al. deploy PinSage at Pinterest, which can generate higher-quality
recommendations of images than comparable deep learning and graph-based alternatives.
FUTURE RESEARCH DIRECTIONS AND OPEN ISSUES
Whilst GNN has achieved great success in recommender systems, this section outlines several
promising prospective research directions.
Diverse and Uncertain Representation
In addition to heterogeneity in data types (e.g., node types like user and item, and edge types like
different behavior types), users in the graph usually also have diverse and uncertain interests .
Representing each user as a onefold vector (a point in the low-dimensional vector space) as in
previous works is hard to capture such characteristics in usersâ€™ interests. Thus, how to represent
usersâ€™ multiple and uncertain interests is a direction worth exploring.
A natural choice is to extend such onefold vector to multiple vectors with various methods , e.g., disentangled representation learning or capsule networks . Some works
on GNN-based recommendation also have begun to represent users with multiple vectors. For
instance, DGCF explicitly adds orthogonal constraints for multi-aspect representations and
iteratively updates the adjacent relationships between the linked nodes for each aspect respectively.
The research of multiple vector representation for recommendation, especially for GNN-based
recommendation model, is still in the preliminary stage, and many issues need to be studied in
the future, e.g., how to disentangle the embedding pertinent to usersâ€™ intents; how to set the
different interest number for each user in an adaptive way; how to design an efficient and effective
propagation schema for multiple vector representations.
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Graph Neural Networks in Recommender Systems: A Survey
Another feasible solution is to represent each user as a density instead of a vector. Representing
data as a density (usually a multi-dimensional Gaussian distribution) provides many advantages, e.g.,
better encoding uncertainty for a representation and its relationships, and expressing asymmetries
more naturally than dot product, cosine similarity, or euclidean distance. Specifically, Gaussian
embedding has been widely used to model the data uncertainty in various domains, e.g., word
embedding , document embedding , and network/graph embedding . For
recommendation, Dos Santos et al. and Jiang et al. also deploy Gaussian embedding to
capture usersâ€™ uncertain preferences for improving user representations and recommendation
performance. Density-based representation, e.g., Gaussian embedding, is an interesting direction
that is worth exploring but has not been well studied in the GNN-based recommendation models.
Scalability of GNN in Recommendation
In industrial recommendation scenarios where the datasets include billions of nodes and edges while
each node contains millions of features, it is challenging to directly apply the traditional GNN due
to the large memory usage and long training time. To deal with the large-scale graphs, there are two
mainstreams: one is to reduce the size of the graph by sampling to make existing GNN applicable;
another is to design a scalable and efficient GNN by changing the model architecture. Sampling
is a natural and widely adopted strategy for training large graphs. For example, GraphSAGE 
randomly samples a fixed number of neighbors, and PinSage employs the random walk
strategy for sampling. Besides, some works reconstruct the small-scale subgraph from
the original graph for each user-item pair. However, sampling will lose more or less part of the
information, and few studies focus on how to design an effective sampling strategy to balance the
effectiveness and scalability.
Another mainstream to solve this problem is to decouple the operations of nonlinearities and
collapsing weight matrices between consecutive layers . As the neighbor-averaged
features need to be precomputed only once, they are more scalable without the communication
cost in the model training. However, these models are limited by their choice of aggregators and
updaters, as compared to traditional GNN with higher flexibility in learning . Therefore, more
future works should be studied in face of the large-scale graphs.
Dynamic Graphs in Recommendation
In real-world recommender systems, not only the objects such as users and items, but also the
relationships between them are changing over time. To maintain the up-to-date recommendation,
the systems should be iteratively updated with the new coming information. From the perspective
of graphs, the constantly updated information brings about dynamic graphs instead of static ones.
Static graphs are stable so they can be modeled feasibly, while dynamic graphs introduce changing
structures. An interesting prospective research problem is how to design the corresponding GNN
framework in response to the dynamic graphs in practice. Existing studies in recommendation pay
little attention to the dynamic graphs. As far as we know, GraphSAIL is the first attempt to
address the incremental learning on GNN for recommender systems, which deals with the changing
of interactions, i.e., the edges between nodes. To balance the update and preservation, it constraints
the embedding similarity between the central node and its neighborhood in successively learned
models and controls the incrementally learned embedding close to its previous version. Dynamic
graphs in recommendation is a largely under-explored area, which deserves further studying.
Reception Field of GNN in Recommendation
The reception field of a node refers to a set of nodes including the node itself and its neighbors
reachable within ğ¾-hops , where ğ¾is the number of propagation iterations. Generally, the
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Wu, et al.
aggregation step ğ¾is the same as the number of GNN layers in coupled GNNs (e.g., GCN and
GraphSAGE). In addition, some recent graph diffusion-based works decouple the
operations of aggregation and update and embrace a larger reception field with a larger aggregation
step. For nodes with low degree, they need deep GNN architecture to enlarge their reception
field for sufficient neighborhood information. However, by increasing the propagation steps, the
reception field of nodes with high degree will expand too big and may introduce noise, which could
lead to the over-smoothing problem and a consequent drop in performance.
For the graph data in recommendation, the degree of nodes exhibits a long tail distribution, i.e.,
active users have lots of interactions with items while cold users have few interactions, and similar
to the popular items and cold items. Therefore, applying the same propagation step on all the nodes
may be suboptimal. There are only a few emerging works to adaptively decide the propagation
step for each node in order to obtain a reasonable reception field . As a result, how to
adaptively select a suitable reception field for each user or item in GNN-based recommendation is
still an issue worth of research.
Self-supervised Learning
Self-supervised learning (SSL) is an emerging paradigm for improving the utilization of data, which
can help alleviate the sparsity issue. Inspired by the success of SSL in other areas, recent efforts
have leveraged SSL to recommender systems, and made remarkable achievements . In
the field of GNN-based recommender systems, there exist few attempts to employ SSL as well.
For instance, COTREC designs a contrastive learning task by maximizing the agreement
between the representations of the last-clicked item and the predicted items samples, accompanied
with the given session representation. DHCN maximizes the mutual information between
the session representations learned via the session-to-session graph and item-session hypergraph.
The key challenge is how to design an effective supervised signal corresponding to the main task.
Considering the prevalence of sparsity issue in recommender systems, we believe self-supervised
learning in GNN-based recommender systems is a promising direction.
Robustness in GNN-based Recommendation
Recent studies show that GNN can be easily fooled by small perturbation on the input , i.e.,
the performance of GNN will be greatly reduced if the graph structure contains noise. In realworld recommendation scenarios, it is a common phenomenon that the relationships between
nodes are not always reliable. For instance, users may accidentally click the items, and part of
social relationships cannot be captured. In addition, the attacker may also inject fake data into
the recommender systems. Therefore, it is of great practical significance to construct a robust
recommender system that is able to generate stable recommendations even in the presence of
shilling attacks. Due to the vulnerability of GNN to noisy data, it is of great practical significance to
construct a robust recommender system that is able to generate stable recommendations even in the
presence of shilling attacks . In the field of GNN, there are emerging efforts on graph adversarial
learning to enhance the robustness . Few attempts in GNN-based recommendation have
started to pay attention to robustness. For instance, GraphRf jointly learn the rating prediction
and fraudster detection, where the probability of being a fraudster determines the reliability of the
userâ€™s rating in the rating prediction component. How to build a more robust recommender system
is worth exploring but has not been well studied in the GNN-based recommender systems.
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Graph Neural Networks in Recommender Systems: A Survey
Privacy Preserving
Due to the strict privacy protection under General Data Protection Regulation 12, the privacy
preservation in recommender systems has aroused lots of concern in academia and industry
since most of the data may be deemed confidential/private, e.g., social network and historical
behavior . An emerging paradigm is to use federated learning to train recommender systems
without uploading usersâ€™ data to the central server . However, the local user data only
contains first-order user-item interactions, which is challenging to capture high-order connectivity
without privacy linkage . Another line is to employ differential privacy to guarantee the user
privacy in the procedure of recommender systems . One limitation of differential privacy
is that it usually brings a decrease in performances .
Some efforts have focused on privacy-preserving in GNN-based recommendation. For instance,
FedGNN trains the GNN model locally based on the local user-item graph. The pseudo
interacted items, and a user-item graph expansion method are proposed to protect the items and
exploit the high-order interactions, respectively. Based on local differential privacy (LDP) ,
FedGNN may add noise to the local gradient of each model and thus decrease the model accuracy.
To reduce the amount of noise while maintaining privacy protection, PPGRec converts the
LDP model into the central differential privacy model and only adds noise to the aggregated global
gradient. With the increasing societyâ€™s emphasis on privacy protection, privacy preservation in
GNN-based recommendations should be an attractive direction due to its practical value.
Fairness in GNN-based Recommender System
Recent years have seen a surge of research effort on recommendation biases to achieve fairness .
For instance, the recommendation performance for users of different demographic groups should
be close, and each item should have an equal probability of overall exposure. With the widespread
of GNN, there is an increasing societal concern that GNN could make discriminatory decisions .
Some explorations have been made towards alleviating biases in GNN-based recommender systems.
For instance, NISER applies normalization operation over the representations to handle popularity bias. FairGNN employs an adversarial learning paradigm to eliminate the bias of GNN
by leveraging graph structures and limited sensitive information. Due to the prevalence of biases in
recommender systems and societyâ€™s growing focus on fairness, ensuring fairness whilst maintaining
comparable performance in GNN-based recommender systems deserves further studying.
Explainability
Explainability is beneficial for recommender systems: on the one hand, explainable recommendations to users allow them to know why the items are recommended and could be persuasive; on the
other hand, the practitioners can know why the model works, which could help further improvements . Due to the significance of explainability, many interests have focused on designing
explainable recommendation models or conducting post-hoc interpretations .
With the proliferation of GNN, recent efforts have investigated GNN explainability methods .
The methods can be divided into two categories: the instance-level methods provide example-specific
explanations by identifying important input features for its prediction ; the model-level
methods provide high-level interpretations and a generic understanding of how deep graph models
work . There are also some attempts on explainability on GNN-based recommendation . Most of them utilize semantic information in knowledge graph and conduct post-hoc
interpretations. Up till now, the explainable GNN-based recommender systems are still not fully
explored, which should be an interesting and beneficial direction.
12 
ACM Comput. Surv., Vol. 37, No. 4, Article 111. Publication date: April 2022.
Wu, et al.
CONCLUSION
Owing to the superiority of GNN in learning on graph data, utilizing GNN techniques in recommender systems has gained increasing interests in academia and industry. In this survey, we
provided a comprehensive review of the most recent works on GNN-based recommender systems.
We proposed a classification scheme for organizing existing works. For each category, we briefly
clarified the main issues, detailed the corresponding strategies adopted by the representative models,
and discussed their advantages and limitations. Furthermore, we suggested several promising directions for future researches. We hope this survey can provide readers with a general understanding
of the recent progress in this field, and shed some light on future developments.
ACKNOWLEDGEMENT
This work is supported by NSFC (No. 61832001), Beijing Academy of Artificial Intelligence (BAAI),
and PKU-Tencent Joint Research Lab.