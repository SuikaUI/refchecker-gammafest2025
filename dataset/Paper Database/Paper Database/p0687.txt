Multi-view Stereo via Volumetric Graph-cuts
and Occlusion Robust Photo-Consistency
George Vogiatzis, Carlos Hern´andez Esteban,
Philip H. S. Torr, Roberto Cipolla
May 30, 2007
This paper presents a volumetric formulation for the multi-view stereo problem which is
amenable to a computationally tractable global optimisation using Graph-cuts. Our approach is
to seek the optimal partitioning of 3D space into two regions labelled as ‘object’ and ‘empty’ under
a cost functional consisting of the following two terms: (1) A term that forces the boundary between
the two regions to pass through photo-consistent locations and (2) a ballooning term that inﬂates
the ‘object’ region. To take account of the effect of occlusion on the ﬁrst term we use an occlusion
robust photo-consistency metric based on Normalised Cross Correlation, which does not assume
any geometric knowledge about the reconstructed object. The globally optimal 3D partitioning can
be obtained as the minimum cut solution of a weighted graph.
I. INTRODUCTION
This paper considers the problem of reconstructing the dense geometry of a 3D object from
a number of images in which the camera pose and intrinsic parameters have been previously
obtained. This is a classic computer vision problem that has been extensively studied and
a number of solutions have been published. Work in the ﬁeld can be categorised according
to the geometrical representation of the 3D object with the majority of papers falling under
one of the following two categories: (1) algorithms that recover depth-maps with respect to
an image plane and (2) volumetric methods that represent the volume directly, without any
reference to an image plane.
In the ﬁrst class of methods, a reference image is selected and a disparity or depth value
is assigned to each of its pixels using a combination of image correlation and regularisation.
An excellent review for image based methods can be found in Scharstein and Szeliski .
These problems are often formulated as minimisations of Markov Random Field (MRF)
energy functions providing a clean and computationally-tractable formulation, for which good
approximate solutions exist using Graph-cuts , , or Loopy Belief Propagation .
They can also be formulated as continuous PDE evolutions on the depth maps . However,
a key limitation of these solutions is that they can only represent depth maps with a unique
disparity per pixel, i.e. depth is a function of image point. Capturing complete objects in
this manner requires further processing to merge multiple depth maps. This was recently
attempted in but resulted in only partially reconstructed object surfaces, leaving holes
in areas of uncertainty. A second limitation is that the smoothness term imposed by the MRF
is deﬁned on image disparities or depths and hence is viewpoint dependent i.e. if a different
May 30, 2007
Toy House. This is an example of a 3D model of a real object, obtained using the technique described
in this paper. In the top row are four images of a toy house while in the bottom row, renderings of the 3D model
from similar viewpoints are shown . The ﬁrst three images were part of the input sequence used while the fourth
was not shown to the algorithm. The model of this small toy house (approximately 10cm in diameter) contains
accurately reconstructed sub-millimetre details such as the fence and the relief of the roof.
view is chosen as the reference image the results may be different.
The second class comprises of methods that use a volumetric representation of shape. For
a recent, very thorough review of related techniques see . Under this framework multiple
viewpoints can be easily integrated and surface smoothness can be enforced independent of
viewpoint. This class consists of techniques using implicit representations such as voxel occupancy grids , or level-sets of 3D scalar ﬁelds , , and explicit representations such as
polygonal meshes , . While some of these methods are known to produce high quality
reconstructions their convergence properties in the presence of noise are not well understood.
Due to lack of regularisation, methods based on Space Carving produce surfaces that
tend to bulge out in regions of low surface texture (see the discussion about shape priors in
 ). In variational schemes such as level-sets and mesh based stereo, the optimal surface
is usually obtained via gradient descent optimisation. As a result, these techniques typically
employ multi-resolution coarse-to-ﬁne strategies to decrease the probability of getting trapped
in local minima (e.g. , , , ). Furthermore, explicit representations such as meshes
are known to suffer from topological and sampling problems .
The approach described in this paper combines the advantages of both classes described
above. We adopt an implicit volumetric representation based on voxel occupancy, but we
pose the reconstruction problem as ﬁnding the minimum cut of a weighted graph. This
computation is exact and can be performed in polynomial time. The beneﬁts of our approach
May 30, 2007
are the following:
1) Objects of arbitrary topology can be fully represented and computed as a single surface
with no self-intersections.
2) The representation and geometric regularisation is image and viewpoint independent.
3) Global optimisation is computationally tractable, using existing max-ﬂow algorithms.
A. Background and previous work
The inspiration for the approach presented in this paper is the work of Boykov and
Kolmogorov which establishes a theoretical link between maximum ﬂow problems in
discrete graphs and minimal surfaces in an arbitrary Riemannian metric. In particular the
authors show how a continuous Riemannian metric can be approximated by a discrete
weighted graph so that the max-ﬂow/min-cut solution for the graph corresponds to a local
geodesic or minimal surface in the continuous case. The application described in that paper
is interactive 2D or 3D segmentation. A probabilistic formulation of interactive segmentation
with a more elaborate foreground/background model was given in Blake et al .
In we showed how the basic idea of can be applied to the volumetric, multiview stereo problem by computing a photo-consistency based Riemannian metric in which
a minimal surface is computed. In that method two basic assumptions are made: Firstly, it
is assumed that the object surface lies between two parallel boundary surfaces. The outer
boundary is usually obtained from the visual hull while the inner boundary lies at a constant
distance inside the outer boundary. This effectively limits the depth of concavities that can
be represented in the reconstructed object. The second assumption is that the visibility of
each point on the object’s surface can be determined from the visibility of the closest point
on the outer surface. Even though both of these assumptions are satisﬁed for a large class
of objects and acquisition set-ups, they restrict the applicability of the method considerably.
Nevertheless, by demonstrating promising results and highlighting the feasibility of solving
multi-view stereo using volumetric graph cuts, inspired a number of techniques , ,
 , , , , that built on our formulation and attempted to address some of its
shortcomings.
In Furukawa et al. and Sinha et al. two different ways were proposed for incorporating the powerful silhouette cue into the graph-cut framework while Starck et al.
 and Tran et al. showed how to enforce sparse feature matches as hard constraints.
Hornung and Kobbelt improved the construction of the voxel grid and cast the method
May 30, 2007
in a hierarchical framework that allows for a signiﬁcant speedup at the expense of no longer
obtaining a global optimum. Finally, Boykov and Lempitsky offer an alternative approach
for visibility reasoning, while in this is expanded to incorporate the idea of photo-ﬂux
as a data-driven ballooning force that helps reconstruct thin protrusions and concavities.
Additionally, and were the ﬁrst papers to propose a global optimisation scheme for
volumetric multi-view stereo that did not require any initialisation (e.g. visual hull). However
the reconstructions shown were less detailed than those obtained with other state-of-the-art
techniques and no comparison or quantitative analysis was provided.
In this paper we improve the original formulation of the method of by relaxing the
two assumptions described above. Hence, in the present formulation (a) the object surface
is not geometrically constrained to lie between an inner and an outer surface and (b) no
explicit reasoning about visibility is required. This is achieved through the use of a robust
shape-independent photo-consistency cost ﬁrst used in . The key idea behind that scheme
is that occluded pixels are treated as outliers in the matching process. Furthermore, the
formulation presented here achieves reconstruction results of far superior accuracy than ,
as demonstrated by results from a scene where ground truth is available (Fig. 5 and Table I).
The rest of the paper is laid out as follows: Section II describes how multi-view stereo can
be formulated as a graph-cut optimisation. In section III we describe the photo-consistency
functional associated with any candidate surface while section IV explains how this functional
is approximated with a discrete ﬂow graph. Section V presents our 3D reconstruction results
on real objects and section VI concludes with a discussion of the paper’s main contributions.
II. GRAPH-CUTS FOR VOLUMETRIC STEREO
In and subsequently in it was shown how graph-cuts can optimally partition 2D or
3D space into ‘foreground’ and ‘background’ regions under any cost functional consisting
of the following two terms:
• Foreground/background cost: for every point in space there is a cost for it being
‘foreground’ or ‘background’.
• Discontinuity cost: for every point in space, there is a cost for it lying on the boundary
between the two partitions.
Mathematically, the cost functional described above can be seen as the sum of a weighted
surface area of the boundary surface and a weighted volume of the ‘foreground’ region as
May 30, 2007
where S is the boundary between ‘foreground’ and ‘background’, V (S) denotes the ‘foreground’ volume enclosed by S and ρ and σ are two scalar density ﬁelds.
The application described in was the problem of 2D/3D segmentation. In that domain
ρ(x) is deﬁned as a function of the image intensity gradient and σ(x) as a function of the
image intensity itself or local image statistics. In this paper we show how multi-view stereo
can also be described under the same framework with the ‘foreground’ and ‘background’
partitions of 3D space corresponding to the reconstructed object and the surrounding empty
space respectively.
Our model balances two competing terms: The ﬁrst one minimises a surface integral of
photo-consistency while the second one maximises volume. The following two subsections
describe the two terms of our multi-view stereo cost functional in more detail.
A. Foreground/background cost
A challenge speciﬁc to the multi-view stereo problem, is that there is no straightforward
way to deﬁne the foreground/background model σ(x). This is because in this problem our
primary source of geometric information is the correspondence cue which is based on the
following observation: A 3D point located on the object surface projects to image regions
of similar appearance in all images where it is not occluded. Using this cue one can label
3D points as being on or off the object surface but cannot directly distinguish between
points inside or outside it. In contrast, the silhouette cue is based on the requirement that all
points inside the object volume must project inside the silhouettes of the object that can be
extracted from the images. Hence the silhouette cue can provide some foreground/background
information by giving a very high likelihood of being outside the object to 3D points that
project outside the silhouettes. In a data driven, foreground/background model based on
the concept of photo-ﬂux has been introduced. To compute photo-ﬂux, surface orientation
must be either estimated (in the case of global optimisation) or the current surface orientation
is used (in the case of gradient-descent surface evolution).
In this work we adopt a very simple, data-independent model where σ(x) is deﬁned as a
negative constant λ that produces an inﬂationary (ballooning) tendency. The motivation for
this type of term in the active contour domain is given in , but intuitively, it can be thought
May 30, 2007
of as a shape prior that favours objects that ﬁll the bounding volume in the absence of any
other information. If the value of λ is too large then the solution tends to over-inﬂate, ﬁlling
the entire bounding volume while if λ is too small then the solution collapses into an empty
surface. For values of λ in between these two cases the algorithm converges to the desired
surface. In practice it is quite easy to ﬁnd a value of λ which will work by performing a few
trial runs. As there is a large range of suitable λ values, all of which give nearly identical
results, no detailed search for the optimal λ value is necessary.
Additionally we can encode any silhouette information that may be available by setting
σ(x) to be inﬁnitely large when x is outside the visual hull. Furthermore if we can also
assume, as in , that the concavities of the object are of a maximum depth D from the
visual hull then we can set σ(x) to be inﬁnitely small when x is inside the visual hull at a
distance, at least D from it. In many cases such as the experiments of Figure 1 and 4 where
the objects have relatively simple topology, a bounding box guaranteed to contain the object
is sufﬁcient to obtain a good reconstruction. To encode this knowledge we just need to set
σ(x) to be inﬁnitely large when x is outside that bounding box.
B. Discontinuity cost
The second challenge of multi-view stereo is that the surface area density ρ, which
corresponds to the discontinuity cost, is a function of the photo-consistency of the point
in space, which in turn depends on which cameras are visible from that point. Consequently
in multi-view stereo the discontinuity cost has the form ρ(x, S) since the surface S itself
determines camera visibility. The graph-cut formulation of cannot easily be adapted to
cope with this type of cost functional. In , the problem is solved by assuming the
existence of an approximate surface Sapprox, provided by the visual hull or otherwise, which
provides visibility information. However, as self-occlusions not captured by the approximate
surface will be ignored, the accuracy of the results may suffer. Also, such approximate object
surface may not be readily available. Our approach is to use a photo-consistency metric that
accounts for occlusions using robust Normalised Cross-Correlation (NCC) voting without any
dependence on approximate object geometry. The surface cost functional that we optimise is
The next section will describe the photo-consistency metric ρ(x) in more detail.
May 30, 2007
III. PHOTO-CONSISTENCY METRIC
The input to our method is a sequence of images I1, ..., IN calibrated for camera pose and
intrinsic parameters. The photo-consistency of a potential scene point x can be evaluated by
comparing its projections in the images where it is visible. We propose the use of a robust
photo-consistency metric similar to the one described in that does not need any visibility
computation. This choice is motivated by the excellent results obtained by this type of photoconsistency metric in the recent comparison of 3D modelling techniques carried out by .
The basic idea is that all potential causes of mismatches like occlusion, image noise, lack of
texture or highlights are uniformly treated as outliers in the matching process. Matching is
then seen as a process of robust model ﬁtting to data containing outliers. Speciﬁcally, for a
given 3D point x, its photo-consistency value ρ(x) is computed by asking every image i to
give a vote for that location. Speciﬁcally, we deﬁne
ρ(x) = exp{−µ
VOTEi(x)}.
where µ is very stable rate-of-decay parameter which in all our experiments was set to 0.05.
The value of VOTEi(x) is computed as follows:
• Compute the corresponding optic ray
oi(d) = x + (ci −x)d
that goes through the camera’s optic centre ci and the 3D point x,
• As a function of the depth along the optic ray d, project the 3D point oi(d) into the M
closest cameras N (i) and compute M correlation scores Sj(d) between image Ij∈N (i) and
the reference image Ii. Each score Sj(d) is obtained using normalised cross correlation
between two square windows centred on the projections of oi(d) into Ii and Ij∈N (i). For
the experiments presented here we used 11 × 11 pixel windows.
• combine the M correlation scores Sj(d) into a single score C(d), and give a vote to the
3D location x, i.e., oi(0), only if C(0) is the global maximum of C as follows:
C(0) ≥C(d) ∀d
One of the simplest ways of combining the M correlation scores for every depth d is to
simply average them, i.e.,
May 30, 2007
depth along optic ray
correlation score
proposed method CW
Robust voting vs averaging. Our algorithm robustly estimates the depth of a pixel in an input image
(left) by computing NCC scores between a patch centred on that pixel and patches along points on corresponding
epipolar lines in the M closest images, two of which are shown in the middle column. In this way M correlation
curves are obtained (in our example M = 6). These curves are plotted here in red across depth along the optic
ray. Curves corresponding to un-occluded viewpoints (such as the top-middle image) share a local optimum in
the same location which corresponds to the correct surface depth. Curves from occluded viewpoints (such as the
bottom-middle image) do not have an optimum in that location and hence a simple averaging of the curves (dashed
line) does not work. By computing a sliding Parzen ﬁlter on the local maxima of the correlation curves (here we
have used a Gaussian kernel) the correct depth can be recovered at the point of maximum response.
However, averaging does not allow the robust handling of occlusions, highlights or lack of
texture. In order to obtain a better score C(d), we make an important observation: because of
different types of noise in the image, the global maximum of a single correlation curve does
not always correspond to the correct depth. However, if the surface is seen by the camera
without occlusion or sensor saturation, the correlation score does show a local maximum
near the correct depth, though it may not be the global one. In order to take into account this
observation, we build a new C by detecting all the local maxima dk of Sj, i.e., ∂Sj
∂d2 (dk) > 0, and using a Parzen window with a kernel W as follows:
Sj(dk)W(d −dk).
The Parzen window technique provides an effective way of taking into account the actual
scores of the local maxima and reinforcing those local maxima that are close to each other.
It provides very good robustness against occlusion and image noise, which in practice makes
it the core of a photo-consistency measure that does not need explicit visibility computation.
Figure 2 demonstrates the beneﬁts of the Parzen ﬁltering technique as opposed to simple
averaging of correlation scores. For the example of ﬁgure 2 a Gaussian kernel has been
used. In practice we discretise the 3D volume into voxels and we count the number of local
May 30, 2007
Surface geometry and ﬂow graph construction. On the left: a 2D slice of space showing the bounding
volume and the optimal surface inside it that is obtained by computing the minimum cut of a weighted graph. Note
that complicated topologies such as holes or disjoint volumes can be represented by our model and recovered after
optimisation. On the right: the correspondence of voxels with nodes in the graph. Each voxel is connected to its
neighbours as well as to the source.
maxima that fall inside a voxel. This corresponds to using a rectangular kernel with width
equal to the size of the voxel grid.
IV. GRAPH STRUCTURE
To obtain a discrete solution to Equation (2) 3D space is quantised into voxels of size
h×h×h. The graph nodes consist of all voxels whose centres are within a certain bounding
box that is guaranteed to contain the object. For the results presented in this paper these
nodes were connected with a regular 6-neighbourhood grid. Bigger neighbourhood systems
can be used which provide a better approximation to the continuous functional (2), at the
expense of using more memory to store the graph. Now assume two voxels centred at xi and
xj are neighbours. Then the weight of the edge joining the two corresponding nodes on the
graph will be 
wij = 4πh2
where ρ(x) is the matching cost function deﬁned in Equation (3). In addition to these weights
between neighbouring voxels there is also the ballooning force edge connecting every voxel
to the source node with a constant weight of wb = λh3. Finally, the outer voxels that are part
of the bounding box (or the voxels outside the visual hull if that is available) are connected
with the sink with edges of inﬁnite weight. The conﬁguration of the graph is shown in ﬁgure
3 (right).
It is worth pointing out that the graph structure described above can be thought of as a
simple binary MRF. Variables correspond to voxels and can be labelled as being inside or
outside the scene. The unitary clique potential is just 0 if the voxel is outside and wb if it is
May 30, 2007
inside the scene while the pairwise potential between two neighbour voxels i and j is equal to
wij if the voxels have opposite labels and 0 otherwise. As a binary MRF with a sub-modular
energy function it can be solved exactly in polynomial time using Graph-cuts.
V. RESULTS
In this section we present some 3D reconstruction results obtained by our technique. The
system used for all the models shown was a Linux-based Intel Pentium IV with 2GB RAM
and running at 3.0 GHz. The spatial resolution for the voxel grids was 3003 voxels for the
toy house sequence (Figure 1), 2003 voxels for the Hygeia sequence (Figure 4) and 2563 v
voxels for the Temple sequence (Figure 5). The ballooning parameter λ was set to values
between 0.1 and 1.0. Computation time is strongly dominated by the photo-consistency cost
calculation which takes between 30 minutes and 1.5 hours depending on number of images
and their resolution. Generally the computational complexity of this part of the algorithm
grows linearly with the total number of pixels in the sequence. The computation time required
by the graph-cut computation for a 3003 grid is approximately 45 minutes. We used the graphcut algorithm proposed in and in particular the implementation available at the authors’
The ﬁrst experiment was performed on a plaster bust of the Greek goddess Hygeia (36
images) photographed with a 5M pixel digital camera. The object was mounted on a turntable
and camera pose was obtained automatically using the object’s silhouettes . Note however
that these silhouettes were not used for any other computation such as visual hull construction.
The reconstruction results are shown in ﬁgure 4.
Our second experiment (Figure 5) used images of a replica of the Castor and Pollux
(Dioscuri) temple in Agrigento, Sicily with a resolution of 640 × 480 pixels. Four of these
images are shown in the ﬁrst row of Figure 5. This sequence was used as part of a multi-view
stereo evaluation effort which was presented in . Camera motion is known and ground
truth is available through the use of a laser scanner device (see for details). Three
different subsets of the sequence each with a different number of images are provided: the
full set of 312 images (Full), a medium sized sequence with 47 images (Ring) and a sparse
sequence with only 16 images (SparseRing). As the object is photographed against a black
background, silhouettes can be computed by simple thresholding. The visual hull obtained
from those silhouettes is shown in the second row of Figure 5. We have encoded this in
our foreground/background term as described in section II-A. Figure 5 shows the results of
May 30, 2007
Reconstruction results. Reconstruction of plaster bust of Greek goddess Hygeia. The input sequence
consists of 36 images. Four of these are shown in the ﬁrst row while the second row shows similar views of the
reconstructed model.
our reconstruction for the Full subsequence (fourth row) compared to the results obtained
using the original formulation of Volumetric Graph-cuts (third row). The improvement
in geometric accuracy is especially evident in the rear view of the temple where, due to selfocclusions the visibility assumptions of were severely violated. Our present formulation
makes no such visibility approximations and hence is able to fully extract the geometry
information contained in the images.
Figure 6 provides a qualitative demonstration of the difference in discriminative power
between the photo-consistency metric of (left) and our current method (right). The
ﬁgure shows slices of the two photo-consistency ﬁelds corresponding to the upper part of
the temple above the columns. It demonstrates a signiﬁcant reduction in photo-consistency
noise brought about by the robust voting scheme of section III.
A quantitative analysis of our results and comparison with state-of-the-art techniques across
all three subsequences is presented in Table I. The accuracy metric shown is the distance d
(in millimetres) that brings 90% of the reconstructed surface within d from some point on
the ground truth surface. The completeness ﬁgure measures the percentage of points in the
ground truth model that are within 1.25mm of the reconstructed model. Under both metrics
our method currently ranks among the top performers. In the SparseRing sequence with only
16 images our method performs best in terms of both accuracy and completeness.
The ﬁnal example, shown in Figure 1 is from a high-resolution sequence of 140 images
(3456 × 2304 pixels) of a toy house of about 10cm diameter. Camera calibration has been
May 30, 2007
Castor and Pollux (Dioscuri) temple sequence. First row: Four of the input images. Second row: Visual
hull obtained from silhouettes. Third row: Results obtained with the original Volumetric Graph-cuts formulation
of . Fourth row: Results obtained with the method presented here. The occlusion robust photo-consistency
metric greatly enhances the detail of the reconstruction.
Noise reduction in photo-consistency. Left: a slice of the photo-consistency volume taken through
the entablature of the temple. Centre: the metric of contains falsely photo-consistent regions (e.g. near the
corners). Right: the occlusion robust metric proposed here signiﬁcantly suppresses noise and the correct surface
can be accurately localised.
May 30, 2007
Accuracy / Completeness
Full (312 images)
Ring (47 images)
SparseRing (16 images)
Hernandez 
0.36mm / 99.7%
0.52mm / 99.5%
0.75mm / 95.3%
Goesele 
0.42mm / 98.0%
0.61mm / 86.2%
0.87mm / 56.6%
Hornung 
0.58mm / 98.7%
0.60mm / 99.5%
0.90mm / 95.4%
Furukawa 
0.65mm / 98.7%
0.58mm / 98.5%
0.82mm / 94.3%
Vogiatzis 
1.07mm / 90.7%
0.76mm / 96.2%
2.77mm / 79.4%
Present method
0.50mm / 98.4%
0.64mm / 99.2%
0.69mm / 96.9%
COMPARISON OF OUR METHOD WITH STATE-OF-THE-ART TECHNIQUES AGAINST GROUND TRUTH DATA (FROM ).
obtained automatically using silhouettes . As in the ﬁrst experiment however, we did not
include these silhouettes in our foreground/background term. The mesh obtained from the
3003 voxel grid contains accurately reconstructed sub-millimetre details.
VI. DISCUSSION
This paper introduces the use of graph-cut optimisation to the volumetric multi-view
stereo problem. We begin by deﬁning an occlusion-robust photo-consistency metric which is
then approximated by a discrete ﬂow graph. This metric uses a robust voting scheme that
treats pixels from occluded cameras as outliers. We then show how graph-cut optimisation
can exactly compute the minimal surface that encloses the largest possible volume, where
surface area is just a surface integral in this photo-consistency ﬁeld. The experimental results
presented, demonstrate the beneﬁts of combining a volumetric surface representation with a
powerful discrete optimisation algorithm such as Graph-cuts.