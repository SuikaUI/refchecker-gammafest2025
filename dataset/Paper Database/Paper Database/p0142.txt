Population Set Based Global Optimization Algorithms: Some
Modiﬁcations and Numerical Studies∗
School of Computational and Applied Mathematics,
Witwatersrand University, Wits - 2050, Johannesburg
Department of Computer Science, ˚Abo Akademi University,
Turku, Finland
This paper studies the eﬃciency and robustness of some recent and well known population set based direct search global optimization methods such as Controlled Random
Search, Diﬀerential Evolution, and the Genetic Algorithm. Some modiﬁcations are made
to Diﬀerential Evolution and to the Genetic Algorithm to improve their eﬃciency and
robustness. All methods are tested on two sets of test problems, one composed of easy
but commonly used problems and the other of a number of relatively diﬃcult problems.
Global Optimization, Direct Search Method, Controlled Random Search,
Diﬀerential Evolution, Genetic Algorithm, Continuous Variable.
Introduction
Direct search methods are widely used in applied science and in engineering. They are
a class of optimization methods which are easy to program, do not require any properties
of the function f(x), x ∈Ω⊂Rn (Ωis assumed to be deﬁned by specifying upper and
lower limits of the domain of each variable), being optimized and are often claimed to be
robust for problems with noisy function values. Hence, when the optimizing function is
nonlinear, non-diﬀerentiable and non-smooth direct search methods are the methods of
choice. Over the years several direct search methods for solving the global optimization
problems for continuous variables x have been proposed.
These are based on global
exploration (search of Ω) and localization of search.
Some well known direct search
methods are the Downhill Simplex (DS) method of Nelder and Mead , the method
of Hooke and Jeeves . These methods are really local optimization methods and are
usually used in a repeated fashion from random starting points when used on multi-modal
problems. These methods have been used in many industrial and scientiﬁc applications,
particularly by the engineering community.
A diﬀerent strategy to solve multi-modal problems is used by population set based
methods. Here a set S of initial samples in Ωis successively transformed into samples
concentrated on the global minimum. The basic population set based methods can be
described as follows:
• Generate the initial set S randomly in Ω
• Iteratively replace points in S with better points
∗The paper was revised when the ﬁrst author was spending his sabbatical leave at IMA, University of
Minnesota, USA. Financial support from IMA is acknowledged.
• Stop when some stopping condition is met
One of the population set based direct search methods is the Controlled Random
Search (CRS) Algorithm of Price . Although this method proved very robust in
many applications it is somewhat less known to the engineering community. Another popular population set based algorithm is the Genetic Algorithm (GA) . Most
recently Storn and Price proposed a new population set based direct search method,
the Diﬀerential Evolution (DE) Method.
The objective of this paper is to describe the three population set based methods
using the same general algorithm and in this way show the similarity of them and how
they diﬀer from each other. Further we will investigate the improvement in eﬃciency and
robustness of modiﬁcations to DE and to GA.
To this end, ﬁrst the robustness and eﬃciency of these direct search techniques, their
strengths and weaknesses, are thoroughly investigated by their implementation on classes
of test problems, classiﬁed as easy, moderately diﬃcult and hard problems . Second,
we propose modiﬁcations to DE and to GA to improve their robustness.
In Section 2 we brieﬂy describe all CRS, GA and DE algorithms.
Following the
descriptions we introduce our proposed modiﬁcations to GA and DE in the respective
subsections of Section 2. The test problems considered for comparison purpose are brieﬂy
discussed in Section 3. Numerical results and comparisons are made in Section 4. Section
5 contains a discussion and conclusions based on the results obtained by diﬀerent algorithms. Similarities and dis-similarities of all population set based methods are presented
in Appendix I. A set B of test problems are given in Appendix II.
Three Classes of Population Set Based Algorithms
All population set based direct search methods use a population set S. The initial S
consists of N points with corresponding function values. A contraction process is then
used to drive these points to the vicinity of the global minimizer. Diﬀerent population
set based method uses diﬀerent strategies in the contraction process, per generation. For
instance, the CRS algorithm makes use of simplexes for generating alternatives to replace
a single sample (worst point) in the set S. In GA a subset of S is successively selected
for which mutations and crossovers are used to generate m1 new samples to replace m1
old samples (bad points) of S. Unlike CRS which attempts to replace a single point in S
per generation, and GA which replaces m1 points (parents) of S by the new m1 points
(children) per generation, DE attempts to replace all points in S by new points at each
generation. Here, mutation and crossover are used to generate trial points. A point to
point comparison is then made and better trial points are accepted.
CRS Algorithms
Several versions of the CRS algorithm can be found in the literature; these are various
modiﬁcations made to the original Controlled Random Search (CRS1) algorithm. The
ﬁrst two improvements (CRS2 and CRS3) was proposed by Price himself. Subsequently, Ali and Storey presented CRS4 and CRS5, Mohan and Shanker CRSI
and Ali et al proposed CRS6. In the original version, CRS1, the search region Ωis
sampled and then a simplex is formed from a subset of this sample. One of the points
of the simplex is reﬂected in the centroid of the remaining points (as in the Nelder and
Mead) to obtain a new trial point. If the new trial point is better than the current worst
point in S then it replaces the worst point. The process of forming a new simplex and
generating the trial point is then repeated until some stopping condition is met. In the
second version, CRS2, a more sophisticated use is made of the simplexes in obtaining
new trial points. In the third version, CRS3, a Nelder-Mead-type local search (DS) is
incorporated. In versions CRS4 and CRS5 further local techniques are introduced. The
version CRS6 incorporates a local technique with a quadratic interpolation. The use of
the quadratic interpolation replacing the simplexes within the framework of CRS (CRSI)
is also proposed in . It is easy to describe all CRS algorithms based on the description
Algorithm-1 : The CRS1 Algorithm
Step 1 Determine the initial set S
S = {x1, x2, · · · , xN}
where the points xi, i = 1, 2, · · · , N are sampled randomly in Ω; evaluate f(x) at
each xi, i = 1, 2, · · · , N. Take N >> n, n being the dimension of the function f(x).
Set generation counter k = 0.
Step 2 Determine best, worst point in S. Determine the points xmax, xmin and their
function values fmax, fmin such that
fmax = max
fmin = min
If the stopping condition (eg. fmax −fmin < ϵ) is satisﬁed, then stop.
Step 3 Generate point to replace point in S. Choose randomly n+1 distinct points
xp(1), xp(2), · · · , xp(n+1) from S (selection) and compute (by, say mutation)
˜x = 2G −xp(n+1)
where the centroid G is given by
If ˜x ̸∈Ωgo to Step 3; otherwise compute f(˜x). If f(˜x) ≥fmax then go to Step 3.
Step 4 Update S. Update S by
S = S ∪{˜x} −{xmax} ,
set k := k + 1 and go to Step 2.
Notice that the core operation, i.e., the operation through which the trial points are
generated in the CRS1 algorithm is in Step 3. Therefore, all other CRS algorithms are
derived by modifying this step.
The CRS algorithms, CRS2-5, use simplexes but they diﬀer from CRS1 in that they
make a random selection of n points in S and include the current best point bringing the
number of points up to n + 1. Therefore, the modiﬁcation of Step 3 is that n distinct
points xp(2), xp(3), · · · , xp(n+1) are sampled from S and that G is calculated by
The CRS2-5 algorithms then calculate a trial point using (1). CRS1 becomes CRS2 by
simply replacing (2) with (3). Each of CRS3-5 has an extra local feature added to the
global feature of CRS2. For instance, CRS3 replaces (2) with (3) but each time (1) in
Step 3 ﬁnds a new xmin, CRS3 incorporates a Nelder-Mead type local search from the
best n + 1 points of the set S. CRS4 and CRS5 also implements (3) but instead of using
a Nelder-Mead type local search whenever a new xmin is found, CRS5 uses a gradient
based local search from xmin, and CRS4 evaluates f in r points (eg. r = 4) from the βdistribution using the current xmin as its mean and the distance between xmin and xmax as
standard deviation. CRSI simply uses a quadratic interpolation in Step 3 to generate the
trial point ˜x. The quadratic interpolation uses a = xmin and two other randomly selected
points {b, c} from S to determine the coordinates of the trial point ˜x = (˜x1, ..., ˜xn), where
(bi2 −ci2)f(a) + (ci2 −ai2)f(b) + (ai2 −bi2)f(c)
(bi −ci)f(a) + (ci −ai)f(b) + (ai −bi)f(c)
CRS6 also uses the quadratic interpolation but as soon as the trial point ˜x becomes the
best point in S it uses β-distribution as in CRS4.
To summarise, CRS1 uses (1) together with (2) to generate trial points away from
xp(n+1) in the direction of the centre of gravity of the remaining n point whereas CRS2
uses (1) with (3) to generate points in the direction of the centre of gravity of n points
including the best point, xmin.
CRS3-5 includes localization features added onto the
point generation feature of CRS2, i.e., each time rule (1) and (3) produces a best point a
local exploration feature is applied. This local feature is diﬀerent for diﬀerent algorithm.
CRS6 and CRSI uses the quadratic interpolation method to generate trial points. This
interpolation method uses the best point in the set S. A localization feature is added
to CRS6 but not in CRSI. We use the following table to distinguish between the CRS
algorithms.
Table 1: Local and global features of CRS
Local and global features
Global feature only : use (1) and (2)
Global feature only : use (1) and (3)
Global feature : use (1) and (3); Local feature DS
Global feature : use (1) and (3); Local feature : β-distribution
Global feature : use (1) and (3); Local feature : Gradient based search
Global feature only : use (4)
Global feature : use (4); Local feature : β-distribution
Remark 1 : The three main features of CRS are (i) selection, (ii) reproduction and
(iii) acceptance. The selection of n points for CRS2-5, n + 1 for CRS1 and 2 points
for CRS6/CRSI is random. Reproduction consists of mutation only, e.g., the operation
deﬁned by (1), for CRS1-5, a single interpolation for CRSI and the interpolation and beta
distribution for CRS6. Acceptance of the trial point is not compulsory.
Genetic Algorithms (GA)
The genetic algorithm is a global optimization technique based on natural selection and
the genetic reproduction mechanism.
Like CRS, GA maintains a set S of candidate
solutions, where each solution is coded as a binary string known as chromosome. Central
to GA is the natural evolution of the set S. At each generation of GA a new S evolves
from the old S, i.e., each generation updates the set S. As the generation proceeds the
set of solutions in S converges to the global minimum. In the basic GA, three steps are
involved in the evolution from one generation to the next. These are:
- evaluation of f at each new member of the current set S,
- stochastic selection of points (parents) from the current set S with a bias in the
selection towards better points,
- reproduction of new points (children) from the selected points (parents) using the
two genetic operations: crossover and mutation. The crossover operation is achieved
by taking two selected points, cutting the strings at random index and exchanging
parts. Mutation is achieved by simply ﬂipping the bit at some random index.
This cycle of evaluation, selection and reproduction terminates when a convergence criterion is met.
Genetic Algorithm (GA1) for Function Optimization
The binary coded GA can be modiﬁed for function optimization . Recent applications of GA on function optimization, however, have shown that the real coded GA
is superior to its conventional binary coded counterpart . A real-coded GA
treats chromosomes as vectors (points) of real valued numbers and it adapts the genetic
operators accordingly. Several versions of real coded GA have been proposed. Yen and
Lee proposed a real coded GA which combines GA with a stochastic variant of the
DS method. Recently, a hybrid algorithm comprising of GA and DS was proposed by
Yang and Douglas . One main problem with these methods is that at each generation
the whole population needs rank ordering in accordance with the function values, which is
expensive in terms of cpu time even for a moderate population size. Moreover, numerical
investigations with a wide range of problems were not carried out. Most recently, Hu et
al has proposed a new version of real coded GA. Numerical studies were carried
out on a relatively large set of test problems with the conclusion that the convergence of
the algorithm is rapid.
In this implementation the crossover is done arithmetically, i.e., given the parents
x = (x1, x2, · · · , xn) and y = (y1, y2, · · · , yn) one calculates:
˜xi = αixi + (1 −αi)yi,
˜yi = αiyi + (1 −αi)xi,
i = 1, 2, · · ·, n,
where αi are uniform random numbers in [−0.5, 1.5]. The crossover rule deﬁned by (5)
does not maintain the convexity property, but it is exploratory. For instance, points will
be generated not only on the lines joining x and y but around the line as well as further
sides of both the points. Mutation for a string is carried out by setting
˜xi = ˜xi + γ × (U i −Li),
for a randomly selected index i and γ = 0.1. Here, U i and Li are the upper and lower
bound of the element xi. An important factor in GA is the selection scheme used. A
tournament selection scheme with three players was found robust . Therefore, rank
ordering is no longer needed in this implementation of GA. Here we restrict ourselves to
the real coded GA and in particular to the algorithm of Hu et al .
Although the real coded genetic algorithm (GA1) proposed by Hu et al is
noise tolerant and claimed to be robust some aspects of this GA need to be addressed.
For instance, the ﬁrst drawback is that the selection procedure used was the so called
tournament selection where each time the best of three randomly chosen parents was
selected, and the process continued until m1 parents were selected; m1 children were
then produced from these m1 parents using crossover and mutation. We believe that this
selection criterion is too biased towards the better points and therefore it is too greedy
and may only work for extremely easy problems. Indeed, GA1 was tested on a large class
of test problems, and all these problems are easy to solve as shown in a recent study
 . The second drawback is that the mutation operator is rather randomly chosen, in
particular, the choice of γ. If the diﬀerence between U i and Li is high then this will
create a point far away from the point generated by crossover operation. This point will
be accepted by the mandatory acceptance rule and it has a particular disadvantage of
slowing down the convergence at the later stage of the algorithm when the N points are
scattered around the global minimizer. Moreover, comparison of GA was made with the
CRS6 algorithm only. Since the results of their paper were given only for the parallel
implementations of GA and CRS, comparisons made by the authors were not
systematic. For instance, the population sizes used in the algorithms were not equal. We
address these issues in the next section and propose a modiﬁcation to GA1. We will also
compare GA1 with other algorithms in a systematic manner using both easy and diﬃcult
problems. We now describe a generic real coded GA.
Algorithm-2 : The Genetic Algorithm (GA1)
Step 1 Determine the initial set S. Same as in Algorithm-1.
Step 2 Determine best, worst point in S. Same as in Algorithm-1.
Step 3 Generate points to replace points in S.
• Selection : select m1 ≤N points from S as parents.
• Crossover : pair the points (parents) and generate m1 new points (oﬀsprings),
which replaces the m1 worst points (least ﬁttest strings) in S.
• Mutation : mutate an element of each point (string) with probability pµ, say
pµ = 0.001. Mutation is repeated if the mutated solution is infeasible.
Step 4 Update S. Update S, set k := k + 1 and go to Step 2.
The number of children, m1, to be created per generation will aﬀect the performance
of the GA. For the sequential GA a smaller m1, e.g., the nearest even integer to 0.1N, is
suggested .
Remark 2 : Selection of m1 points is biased towards the better points. Reproduction
consists of crossover and mutation. Acceptance is compulsory as the m1 children replaces
the m1 parents in each generation.
The Modiﬁed Genetic Algorithm (GA2) for Function Optimization
To address the ﬁrst drawback we replace the tournament selection with a random selection. In addition to the crossover rule (5), a learning component is introduced in the
crossover phase to make GA more exploratory. As in GA1, children are created two at
a time in GA2. However, unlike GA1 where two children are created using two parents
obtained by using tournament selection GA2 creates two children from randomly selected
n+2 parents, xp(1), xp(2), · · · , xp(n+1), xp(n+2), from S. The selected n+2 points are used
to calculate the centroid G of the n points remaining after excluding the two worst points,
say xp(n+1) and xp(n+2). The ﬁrst child is then taken as the best point of {ˆx1, ˆx2}, where
ˆx1 = 2 × G −xp(n+1)
ˆx2 = 2 × G −xp(n+2) .
If the j-th point (j = 1, 2) ˆxj is not in Ωthen it is calculated as ˆxj = 1
 G + xp(n+j)
second child is found from the best of {ˆx3, ˆx4}, where ˆx3 and ˆx4 are obtained using the
crossover rule (5). This crossover is carried out between two parents selected randomly
from the n + 2 points, again excluding two worst points, say xp(n+1) and xp(n+2). If the
trial points fall outside Ω, random selection of αi ∈[−0.5, 1.5] continues until ˆx3, ˆx4 ∈Ω.
For the next pair of children n+2 points are again selected randomly from S and the above
process continued. The m1 children are therefore generated two at a time. Although the
above mentioned rules take two extra function evaluations for each pair generated, this
rule has proved robust and exploratory and therefore a good alternative to the tournament
selection. The mutation rate was set to pµ = 0.001 for both GA1 and GA2. For each
child xj generated the mutation is carried out with probability pµ from a randomly chosen
component xi
j of xj. We ran into trouble when using (6), especially for problems with
large Ω. For such problems, points determined by (6) frequently fell outside Ωor move far
away from the points in S, delaying the convergence. Therefore, we carried out numerical
studies to empirically obtain the value of γ in (6). A good value of γ is found to lie
randomly on an interval. In particular, we modify the mutation operator (6) to
xi = xi + γ × (U i −Li),
where γ is a random number in [−0.01, 0.01]. This mutation rule was used for both GA1
Diﬀerential Evolution (DE)
Diﬀerential Evolution (DE) is a population set based algorithm designed for minimizing
a function of real variables. It is extremely robust in locating the global minimum. The
overall structure of DE resembles that of CRS and GA. Like the other population set based
direct search methods DE also attempts to guide an initial set S = {x1, x2, · · · , xN} of
points in Ωto the vicinity of the global minimum through repeated cycles of selection,
reproduction (mutation and crossover) and acceptance, see Algorithm-3. However, unlike
CRS which attempts to replace a single point in S per generation, and GA which replaces
m1 points (parents) of S by the new m1 points (children) per generation, DE attempts
to replace all points in S by new points at each generation. We now describe how this
is done. In each generation, N competitions are held to determine the members of S for
the next generation. The i-th (i = 1, 2, · · · , N) competition is held to replace xi in S.
Considering xi as the target point a trial point yi is found from two points (parents), the
point xi, i.e., the target point and the point ˆxi determined by the mutation operation. In
its mutation phase DE randomly selects three distinct points xp(1), xp(2) and xp(3) from
the current set S. None of these points should coincide with the current target point xi.
The weighted diﬀerence of any two points is then added to the third point which can be
mathematically described as :
ˆxi = xp(1) + F × (xp(2) −xp(3)) ,
where F ≤1 is a scaling factor. The trial point yi is found from its parents xi and ˆxi
using the following crossover rule :
if Rj ≤CR or j = Ii
if Rj > CR and j ̸= Ii ,
where Ii is a randomly chosen integer in the set I, i.e., Ii ∈I = {1, 2, · · · , n}; the
superscript j represents the j-th component of respective vectors; Rj ∈(0, 1), drawn
randomly for each j.
The entity CR is a constant (eg.
The ultimate aim of
the crossover rule (10) is to obtain the trial vector yi with components coming from the
components of target vector xi and mutated vector ˆxi. And this is ensured by introducing
CR. Notice that for CR = 1 the trial vector yi is the replica of the mutated vector ˆxi, i.e.,
only the mutation operation is used in reproduction. The eﬀect of this will be studied
later. The acceptance mechanism follows the crossover. In the acceptance phase the
function value at the trial point, f(yi), is compared to f(xi), the value at the target
point. If f(yi) < f(xi) then yi replaces xi in S, otherwise, S retains the original xi. The
process continues until all members of S are targeted. The stopping condition in Step 2,
can for all algorithms be deﬁned as :
fmax −fmin ≤ϵ,
where ϵ is a small number, say ϵ = 10−6.
Algorithm-3 : The Diﬀerential Evolution Algorithm (DE)
Step 1 Determine the initial set S. Same as in Algorithm-1.
Step 2 Determine best, worst point in S. Same as in Algorithm-1.
Step 3 Generate points to replace points in S. For each xi ∈S, determine yi by the
following two reproduction operations:
• Mutation : Randomly select three points from S except xi, the running target
and ﬁnd the second parent ˆxi by the mutation rule (9).
• Crossover : Calculate the trial vector yi corresponding to the target xi from xi
and ˆxi using the crossover rule (10).
Step 4 Replace points in S. Select each trial vector yi for the (k +1)-th generation using
the acceptance criterion : replace xi ∈S with yi if f(yi) < f(xi) otherwise retain
xi. Set k := k + 1 and go to Step 2.
Design of DE certainly brought a new dimension to the direct search techniques in the
ﬁeld of global optimization. However, we believe that some aspects of DE need addressing.
First, the sensitivity of the parameters F and CR was not studied, authors just chose their
values randomly with F mainly between 0.5 and 0.9 and CR between 0.1 and 0.9. Second,
the implementation of DE required some estimate of the global minimum to be provided;
which is not possible for an arbitrary function. Third, although the authors claim the
robustness of DE, comparisons of DE with other credible direct search methods of similar
kind, such as CRS and GA were not made. And ﬁnally, the main diﬃculty with the DE
algorithm appears to lie in the slowing down of the convergence as the region of global
minimum is approached. We try to address these problems in the next section.
Remark 3 : Selection of 3 points used in mutation is random. Reproduction consists
of crossover and mutation. Point to point comparisons are made for acceptance and thus
the acceptance is not compulsory. Notice that the trial point corresponding to the best
point in S will be rejected if the corresponding function value at the trial point is not
better than fmin, but even if it is better than the function value at second best point in
S. The point to point comparison makes the re-search procedure exploratory.
The Modiﬁed DE Algorithms : DEPD, DE1-3
To overcome some of the above mentioned drawbacks of DE and to make DE more
eﬃcient we propose some modiﬁcations to the original DE. In particular, we introduce an
auxiliary set Sa of N points alongside S, propose a rule for calculating the scaling factor
F automatically and use the pre-calculated diﬀerential vectors xp(2) −xp(3) in (9). We
also empirically obtain an optimal value for the CR. These will now be discussed.
Population Sets : Instead of working with one population set S, we use two sets, S and
Sa. The reason for this is to make use of potential trial points which are normally rejected
in DE. It has been shown in our earlier work that the introduction of Sa increases
the exploration of the search in the case of a very practical large scale global optimization
problem. Initially, two sets each containing N points are generated in the following way;
iteratively sample two points from Ω, the best point xi going to S and the other x′
At each generation, if the trial point yi, corresponding to the target xi, does not satisfy
the greedy criterion f(yi) < f(xi) then the point yi is not abandoned altogether, rather
it competes with its corresponding target in the set Sa. If f(yi) < f(x′
i) then yi replaces
i in the auxiliary set Sa. Some good points from Sa can then be used to replace some
bad points in S periodically.
The Scaling Factor : The calculation of F is based on the demand that the search be
diversiﬁed at early stages and intensiﬁed at latter stages. Therefore, the following scheme
is proposed :
fmin | < 1 ,
otherwise ,
ensuring that F ∈[lmin, 1). fmax and fmin are respectively the maximum and minimum
values in S and lmin is a lower bound for F.
The Pre-calculated Diﬀerentials (PD) : DE proposed by Storn and Price generates
diﬀerential vectors (one for each targeted point) in the mutation phase at each generation
of the algorithm.
Therefore, N diﬀerential vectors will be calculated by (9) in each
generation. Although mean of the distribution of such diﬀerentials is always zero (since
xp(2) −xp(3) and xp(3) −xp(2) occur with equal frequency) these diﬀerentials vectors will
gradually be shorter and shorter as the points in S become closer and closer. And this
has two eﬀects : (i) calculation of N diﬀerentials at each generation makes DE time
consuming and (ii) it (calculation of the diﬀerential vectors at each generation) limits the
exploratory feature of DE. The motivation of PD is to make DE faster and exploratory,
and one way this could be achieved is to use pre-calculated diﬀerentials in the mutation
We now explain how the pre-calculated diﬀerentials are used in DE. At the very ﬁrst
iteration of the algorithm all the diﬀerential vectors generated are kept in an array A.
In the consecutive generations (say, the next R generations) when the point xi ∈S are
targeted, the intermediate point ˆxi is calculated using (9) by choosing a random point
xp(1) from S and a random diﬀerential from A. This process continues in the mutation
phase for R generations of the algorithm before A is updated again with new diﬀerentials.
Therefore, in this version of DE the mutation operation has two diﬀerent modes : mode 1
where new diﬀerentials are used in (9) (mutation use three distinct vectors from S) and
mode 2 where pre-calculated diﬀerentials stored in A are used in (9). Mode 1 of the
mutation is switched on after every R generations i.e., after every R generations the
array A is updated with new diﬀerentials.
By simply making this change in DE the
algorithm can be made substantially faster and exploratory. This change is implemented
in the mutation phase. We call this implementation of DE the diﬀerential evolution using
pre-calculated diﬀerential (DEPD) which replace the Step 3 of Algorithm-3 with :
Step 3 For each xi ∈S, determine yi by the following two operations.
• Mutation : If (k = 0) or k ≡0 (mod R) execute mode 1 else mode 2.
Mode 1 : Randomly select three points xp(1), xp(2) and xp(3) from S except xi,
the running target and ﬁnd the point ˆxi by the mutation rule (9) using the
diﬀerential vector (xp(2) −xp(3)). If a component ˆxj
i falls outside Ωthen it is
found randomly in-between the j-th lower and upper limits. Update the i-th
element of the array A with this diﬀerential.
Mode 2 : Randomly select a point xp(1) from S and a diﬀerential vector from A
and ﬁnd the point ˆxi by the mutation rule (9). If a component ˆxj
i falls outside
Ωthen it is found randomly in-between the j-th lower and upper limits.
• Crossover : Calculate the trial vector yi corresponding to the target xi from xi
and ˆxi using the crossover rule (10).
Although we will justify the use of PD in the DE algorithm, it is not our intention to
present DEPD as a stand-alone algorithm for our current piece of work. We use PD as an
embedded component of some modiﬁed DE algorithms whose features are given below.
Features of the Modiﬁed DE : The modiﬁed DE utilizes the potential points of Sa;
after each M number of generations (R is not necessarily equal to M) we replace the
m2 worst points in S with the m2 best points from Sa. The value of M can be chosen
as constant or variable. In the case of variable M, the initial value is set to an integer
and it is gradually decreased so that the convergence becomes quicker as the the points
in S converges to the region of the global minimum. In this version of the modiﬁed DE
the stopping condition remains the same, namely (11), the one which was used for all
the methods (CRS, GA and DE) described so far. We call this DE, the DE1 algorithm.
We also incorporate a local search in the modiﬁed DE which operates from the worst
(DE2) or best (DE3) n + 1 points of S, immediate before the worst (DE2) or the best
(DE3) n + 1 points of S is replaced with the best n + 1 of Sa. As indicated above we
call these modiﬁed versions, DE2 and DE3 respectively. Notice that for DE3 even if S
contains the best points it gets replaced. The DE2/DE3 algorithm stops when the same
minimum is found t times or when (11) is met. We have implemented the Nelder-Mead’s
Down-hill simplex (DS) algorithm as a local search algorithm in DE2 and DE3. The DS
algorithm was stopped when fhi −flo < 10−4, flo and fhi respectively being the best and
the worst values within n + 1 function values of DS. With this stopping condition for DS
we found that suﬃciently good accuracies were obtained for all the problems considered.
We also considered two minima as the same when their diﬀerence fell within the tolerance
of 0.005. We now present the modiﬁed DE algorithms.
Algorithm DEn : The DE1, DE2 and DE3 algorithms now can be described by the
following pseudo Pascal procedure.
initialize S and Sa;
initialize M, M1, M2 and R;
ﬁnd fmin and fmax;
calculate F;
k := k + 1;
call procedure mutation (for k = 0 initialize A and update A if (k mod R)=0) ;
call procedure crossover;
call procedure acceptance;
ﬁnd fmin and fmax;
calculate F;
if ((k mod M)=0) then
(For DE2 (DE3) activate local search and keep record of local minima found);
Replace the worst (best) m2 points of S with the best m2 points of Sa;
M := M −n;
if M <= M1 then M:=M1;
ﬁnd fmin and fmax;
calculate F;
until stopping condition;
Problems Used for Comparisons
Performance of all the population set based direct search algorithms described thus far
were judged using two classes of test problems. They are the classes of easy and diﬃcult
problems . We consider a set A of 9 easy test problems for our study. These are
the two dimensional Goldstein and Price (GP) problem, the 4 dimensional Shekel family
(S5,S7 and S10), the Hartmann family (the 3 and 6 dimensional Hartmann problems;
H3 and H6), the Schubert family (the 3 and 5 dimensional Schubert problems; P8 and
P16) and the 10 dimensional problem of Levy (L10). Although some of these problems
have a multitude of local minima, in particular the Schubert family (53 and 155 minima
respectively) and the problem of Levy (1010 minima), a recent study have shown that all
these problems are easy to solve and that one should rely not only on these test problems
when testing a particular algorithm. Details of some properties of these test problems
are given in , and will not be repeated here. Besides these, we also consider another
set, B, of 6 relatively diﬃcult test problems. These are the 10 dimensional Extended
Rosenbrock (ER10), Schewefel (SF10), Griewank (GW10), the 5 dimensional Shekel’s
Foxholes (FX5), Rastrigin (RG5), and the modiﬁed Langerman (ML5). Of these FX5 is
a diﬃcult problem and the rest are moderately diﬃcult problems (according to the study
done by T¨orn et al ). The problems of set B are given in Appendix I.
Numerical Results
In this section the computational results are summarized. Each of the algorithms was
run 100 times on each of the test problems to determine the percentages of success. Let
TS be the number of runs out of 100 runs that succeeded in locating the global minimum
by the respective algorithm. A solution to the problem will of course not be the global
minimum f ∗exactly, but for instance a value less than f ∗
ε , where f ∗
ε = f ∗+ ε, where
ε = 10−4. To even out the stochastic ﬂuctuations in the number of function evaluations
and cpu times by computing averages FE and cpu for those runs for which the global
minima were obtained. The performance is measured by criteria based on FE, cpu and
TS. All algorithms were run on a SGI-Indy Irix-5.3. Random numbers were generated
using the well tested procedure given in . A common parameter of all population set
based direct search methods is the size N of the population used. Diﬀerent values for N
are suggested for diﬀerent methods. For example, CRS uses N = 10(n + 1); for DE a
value between 5n to 10n is suggested; for GA no ﬁxed and ﬁrst rule of choice is given.
Therefore, as a compromise we use two values for N, namely 7n and 12n. In an earlier
investigation of the robustness of some stochastic global optimization algorithms
 using test problems and some diﬃcult practical problems, CRS4 was found
to be the best and CRS2 the runner up amongst all of a set of stochastic algorithms.
Therefore, in our present investigation of the population set based direct search methods
we consider CRS2, CRS4, CRS6 and CRSI where CRS6 and CRSI are two recent versions
Comparison : GA1 vs GA2
Choice of Parameter values : Parameters involved in GA’s are the mutation probability pµ, the number of children m1 and the model parameters αi and γ respectively
in the crossover and mutation rule. Common values of these are used for both GA1 and
Comparison : In this section we compare GA1 and GA2 using the test sets A and B. We
ﬁrst ﬁnd the percentage of success (TS) in locating the global minima. Table 2 represents
the success rate (%) for 100 runs. Table 2 shows that the reliability of GA2 is superior to
Table 2: Comparison of GA1 and GA2 using percentage of success(TS)
that of GA1 for both values of N. It is clear from the total ﬁgures that for the test set A,
the total number of successes of GA2 is about the double of that of GA1 on the average.
Since the performance of GA1 is considerably better for N = 12n we compare the total
FE and cpu for this value. The total (FE,cpu) is (13776, 2.06) corresponding to the total
of 522 successes for GA1, and is (24108, 4.11) corresponding to the total of 806 successes
for GA2. However, although GA2 is superior to GA1 in locating the global minimum
it needs double (FE,cpu) as compared with that needed by GA1. We, therefore, study
further to see if GA1 outperforms GA2 on set A in ﬁnding the global minimum given
(FE,cpu) nearly the same. For this reason, we ran GA1 on the test set A with increasing
values of N. For instance, N = 12n, 15n, 18n, 21n and 24n and so on. We found that for
N = 24n the (FE,cpu) was (23972, 5.75) for a total of 701 successes on A. Comparing
this with the result of GA2 for N = 12n we see that even though both used more or less
the same (FE,cpu) GA2 is still superior in TS. In a similar manner, we ran GA2 on the
test set A with decreasing values of N. We found that for N = 8n the (FE,cpu) was
(13885, 2.86) for a total of 754 successes on A. This result, (13885, 2.86), is the nearest
(FE,cpu) needed by GA1 for N = 12n but with less successes (TS=522) in obtaining the
global minimum. It is now clear that for the same (FE,cpu) GA2 is much superior to
GA1 on A in locating the global minimum.
For the test set B the results are (25174, 9.98), TS=46 for GA1 and (23904, 6.91),
TS=84 for GA2. For set B we must exclude ER10 from the comparison as GA1 has a
0% success rate on ER10. Moreover, GA2 needed on average (FE,cpu) = (494470, 58.87)
per run for ER10. From this we can confer that GA2 is superior on both sets. Therefore,
in comparing the direct search methods later we will only consider GA2.
Comparison : DE vs DEPD and DE1-3
Choice of Parameter Values : The original DE has two parameters : F and CR.
We begin here by studying the eﬀect of CR in DE. Although the eﬀect of calculating F
using (12) is shown next, we study the correlation between F and CR using some sample
values. In particular, we take F = 0.45, 0.65 0.85 and 1 and each of these values we
conducted a series of DE runs using various values for CR. For instance we ran DE for
CR = 0.25, 0.5, 0.75 and 1 using N = 7n. The results on both sets were in agreement
and we present only the results for set A. There were 900 runs on set A and the total
number of successes on these runs are presented in Table 3. The last column in Table 3
Table 3: Successful runs out of 900 runs for DE using CR and F
shows that the higher number of failures has occurred when using CR = 1, i.e., when
the trial points are obtained using the mutation rule (9) only. The performance of DE is
signiﬁcantly worse in this case. A comparison of the results under this column with that
of columns 2-4 establishes the fact that both the crossover and mutation are necessary in
obtaining trial points in DE. For columns 2-4, TS increases, on average, with the increase
of F. From the results in the last row it can be seen that total number of successes for the
second and third columns are the same but it (total of TS) is much less for column four.
We now compare the number of function evaluations required for the results in Table 3.
Except the Levy function, the FE decreases with the increase of CR, for all F and for
all test functions, in all runs. Since the total FE is dominated by FE for L10 we exclude
the FE required for Levy. The results of 8 test functions are presented in Table 4. Here,
FE is the average number of function evaluation per successful run and the total FE in
Table 4 represents total of 8 such FE in set A.
We now compare Table 3 with Table 4. We ﬁrst compare columns 3 and 4 on both
the tables. Comparing average FE in the last row on Table 4, it can be seen that FE for
column 3 is about 7% more than that of column 4. However, in term of success column
Table 4: Comparison of total FE using CR and F
3 on Table 3 is superior to column 4 (3557 vs 3529). Comparing columns 2 and 3, we
see that average FE of column 3 on Table 4 is about 59% superior to that of column
2, given the same number of total successes for these two columns in Table 3. Even if
we include FE for L10, still it (average FE for column 3 on Table 4) remains about 43%
superior to that of column 2. This motivates us to use CR = 0.5, halfway between the two
parents, throughout our numerical investigation. This policy ensures that each parent’s
components has 50% chance of being selected to produce a new point.
Next we motivate the choice of F. We propose a good strategy for F : the value
of F should be large at the early stages and small at the later stages. To this end, we
ran DE with CR = 0.5 and F being calculated using (12). For this, at the beginning
of each generation new fmin and fmax are found prior to the calculation of F. In this
implementation of DE on set A the TS was 892, three more than average TS of column 3
of Table 3, and the total result (excluding L10) on FE was 29596 which is about 15% less
than average FE of column 3 of Table 4. Similarly, the cpu=1.39 is about 7% less than the
corresponding cpu in Table 4. The results motivated us to use F from (12) throughout
the rest the paper. A good value of lmin was empirically found to be in [0.4, 0.5]. However,
in all implementations we have used lmin = 0.4.
So far we have obtained the empirical choice of F, CR and lmin in (12) for the DE
algorithm. Next we introduce the pre-calculated diﬀerentials (PD) in the DE algorithm
to make it faster. We begin our numerical studies by comparing DE with DEPD. DEPD
is DE using PD. We compare these two using a number of values for the parameter
R. Notice that for R = 0 DE and DEPD are identical. We again use the test set A
with N = 7n. About the same level of TS and the same stopping condition conveniently
allowed us to compare the eﬃciency of the algorithms in terms of cpu and FE. We present
the results for DEPD using R = 1, 2, · · ·, 5. Hence for a set of results for DE there are
ﬁve sets for DEPD. We summarize these results in Table 5. We present the percentage
of improvement by which DEPD outperforms DE. Improvements are recorded on total
results. Total is the total of average cpu and FE for each function. Averages are taken on
successful runs over over 100 runs. As predictable, Table 5 clearly shows the superiority of
Table 5: Improvements of DEPD over DE
DEPD over DE in cpu. However, it is inferior to DE in FE for some cases. This superiority
of DE over DEPD is by a very small margin and except for R=5 this superiority can be
ignored. Clearly the overall best results are obtained at R=4 and for the rest of our
numerical studies we use this value for R.
With the introduction of PD we have shown that DE can be made signiﬁcantly faster.
Therefore, together with the other good choice of F, CR and lmin we use R = 4 in all of
our modiﬁed algorithms.
For our ﬁrst modiﬁed algorithm, the DE1 algorithm, the other parameters involved
are : M and m2. The value of M is selected to lie in [M1, M2]. Initially, M is set to
M2, its highest value, and then gradually decreased to its lowest value M1. To clarify
further, after M(= M2) generations, m2 best points from Sa replaces m2 worst points in
S and then M is reduced to, say M −n, before the next replacement takes place. The
process continues until M reaches M1. For M = M1 the replacement process continues
after every M1 generations. The eﬀect of m2 in DE1 was also studied by considering
m2 = n + 1 and 2(n + 1).
A numerical investigation has shown that M1 = 5n and
M2 = 7n work well for DE1.
The modiﬁed DE2 and DE3 algorithm also replaces m2 points of S inasmuch as the
same way as in DE1, but they explore the m2 points using a local search from them
just before their (m2 points) replacement. For instance, in DE3 the local search starts
from m2 best points of S and as soon as the local search is completed they are replaced
with the best m2 points in Sa. Therefore, m2 is ﬁxed and for DE2/DE3 the value of
m2 is always set to n + 1. The values of M1 and M2 are the same as in DE1. However,
if the local search produces more than 5 local minima then these values were doubled,
i.e., M1 = 10n and M2 = 14n to prevent ﬁnding multiple local minima. The value of t
determines one’s conﬁdence in that points in S have converged to a minimum, and we
have investigated this by choosing diﬀerent values for t.
Comparison : We now compare DE and its modiﬁed versions, DE1, DE2 and DE3,
using total FE, cpu and the total number of successes out of 900 runs for set A and 600
runs for set B. The results are summarized in Table 6. It is important to note that DE2
and DE3 were the only algorithms to locate the minimum value for ER10 with success
rates about 20% on the average. Since neither DE nor DE1 succeeded in ﬁnding the
minimum for this problem even once, and the fact that around 40% of the total FE is
determined by the FE required for ER10 by DE2 and DE3, a fair comparison is also made
excluding the results obtained for ER10, we call this test set B′. The best results were
obtained by DE3 on set A and by DE1 on the sets B and B′. Table 6 also shows that
comparatively less success occurred for DE2 with t = 3 on both sets and therefore in our
next comparison results using t = 4 are considered.
For a further comparison we also ran DE(CR = 0.5, F = 1) and DE(CR = 0.5, F
from (12)) on both A and B′. The total number of successes of DE (CR = 0.5, F = 1)
on A is (899, 897) and on B′ (394, 407) for the pair of population sizes (7n, 12n). These
results for DE(CR = 0.5, F from (12)) are (892, 900) and (396, 406) respectively on A
From these results and the results presented in Table 6 it is clear that TS
attained by DE and by all the modiﬁed DE methods both on A and B′ are very much
the same. Therefore, it will be interesting to see how much improvement (say, on FE)
has been achieved by the proposed modiﬁcations, given the same level of success. This is
summarized in terms of percentage of improvement on FE in Table 7. Table 7 shows that
a substantial improvement has been achieved by the proposed modiﬁcations. In Table 7
the ﬁgures in a row for DE(CR = 0.5, F from (12)) are less than in the corresponding
row for DE(F = 1, CR = 0.5), meaning that a good percentage of reduction has been
achieved by using (12). However, the majority of the improvements have occurred due to
other features of the modiﬁed algorithms, i.e., other changes made to the DE. Although
DE2 and DE3 are close, DE3 gave slightly better results on the average.
Comparison : CRS vs GA vs DE
In this section we compare all population set based direct search methods to single out
a general purpose and robust global optimization method.
For this purpose a rankordering (from superior to inferior) based on some measure is needed. For the test set
A all DE algorithms, except very few cases, were able to locate the global minimum for
all problems. Performance of other direct search methods is also better for set A than
for B. Therefore the ranking based on TS, total FE and cpu can be made. All results
are presented for N = 12n, and for the modiﬁed DE, m2 = n + 1 is used. The rankordering is shown in Table 8. Table 8 shows that in terms of FE and cpu the CRS and
GA are superior but this ranking is reversed in favor of DEs in term of TS. Moreover,
in terms of TS the worst performing DE-type method, DE1, is about 5% superior to
Table 6: Comparison of DE1 and DE2 using FE, TS and cpu
Table 7: Percentage of improvement made by DE1-3 over DE on FE
the best performing CRS-type method, CRS4. On the other hand, in terms of FE the
best performing DE-type, DE3, is about 39% worse-oﬀthen the worst performing CRS2
within CRS. However, in terms of cpu CRS2 is about 18% superior to DE3. For set A,
DE and the modiﬁed DE are robust in ﬁnding the global minima but CRS are faster in
cpu and use less FE. However, the problem with CRS was that CRSI failed 7 times to
converge, twice for S10 and ﬁve times for S5. By convergence, here, we mean convergence
either to a local or to the global minimum. Since in the above table the ranking is almost
reversed on eﬃciency and reliability we try to measure the reliability by keeping the total
FE roughly constant. To this end, we ran CRS4 the neighbor of DE1 in the third row of
Table 8 with a increased value of N = 17n to achieve roughly the same level of total FE.
Although the total success TS of CRS4 is now increased from 856 to 871 but it is still
far short of 893 the TS for DE1. If we now run DE1 with a smaller N (e.g., N = 6n)
for which the FE is more or less the same with CRS4, it still retains superiority over
CRS4 in TS. This clearly demonstrates that the DE-type algorithms are always superiors
on A. Next we consider the test set B to rank-order the algorithms, and the ranking is
presented in Table 9. Table 9 shows that the DE-type algorithms are the best in terms
of cpu and TS. In terms of TS the worst performing DE-type, DE(CR = 0.5, F = 1), is
55% superior to its close competitor GA2 and 59% superior to CRS2, the best performer
of CRS. In terms of FE the worst DE-type, DE3, is worse-oﬀto both CRS6 & CRSI
by about 8% but if we compare DE3, CRSI and CRS6 in terms of TS the superiority
of DE3 becomes apparent from the third row. Above all, DE2 and DE3 become the
best overall performers if we exclude ER10, the minimum of which was only located by
Table 8: Rank-ordering based on set A
Table 9: Rank-ordering based on set B
GA2, DE2 and DE3. Therefore, the overall comparisons in Table 9 shows that for the
moderate to diﬃcult test problems in set B, DE and the modiﬁed DE algorithms always
perform better. Moreover, except for GR10, CRSI failed to converge on the rest of the
test problems of set B 9 times in all. The CRS2 algorithm also failed to converge 71
times for GR10, 3 times for RG5 and 62 times for SF10 respective. The other algorithms
did not have any such problems of convergence.
Discussion and Conclusion
The optimization of non-diﬀerentiable functions (including noisy or not exactly known
functions) is a common problem occurring in various applications. Therefore, using direct
search methods which have shown to be robust and eﬃcient could be rewarding. We
have developed several versions of the Diﬀerential Evolution method (DE). From the
comparison in the previous section it is quite clear that the new algorithms are superior
not only to the original DE but also to many other recent direct search global optimization
algorithms. What makes the DE-type algorithms more robust than the CRS & GAtype algorithms is the feature that all points in the set S are possibly updated for each
generation.
In this way DE has the potential to explore Ωwidely with the help of
the existing points of the the current generation. The CRS-type algorithms lack this
features in that they repeatedly replace the xmax whenever a better points is found. This
ignores the potential of the points xmax in driving the search and thus making it less
exploratory. Unlike DE, where a replacement is done after a point to point comparison,
in GA the replacement of m1 worst points with m1 better points is mandatory. This
repeated replacement in CRS and mandatory replacement in GA makes the re-search
procedure of the respective algorithm more intensiﬁed rather than diversiﬁed. Whereas
the DE-type algorithms have the capacity to maintain a balance between this two features
: intensiﬁcation and diversiﬁcation. The modiﬁed DEs have incorporated the features to
make the search diversiﬁed at early stages and intensiﬁed at later stages. Moreover, even
if DE2 and DE3 stop at a local minimum using the stopping rule (11) (and not using
t = 4) it was noticed in many occasions that at least one local search was able to ﬁnd the
global minimum. The incorporation of local search, therefore, enhanced the robustness
of the DE-type methods. Further research is underway in developing a hybrid DE global
optimization method to ﬁnd even more robust and eﬃcient DE algorithms.
1DE(CR = 0.5, F = 1)
2DE(CR = 0.5, F from (12))