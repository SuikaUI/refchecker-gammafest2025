Curriculum Manager for Source Selection
in Multi-Source Domain Adaptation
Luyu Yang1, Yogesh Balaji1, Ser-Nam Lim2, Abhinav Shrivastava1
1University of Maryland
2Facebook AI
Abstract. The performance of Multi-Source Unsupervised Domain Adaptation depends signiﬁcantly on the eﬀectiveness of transfer from labeled
source domain samples. In this paper, we proposed an adversarial agent
that learns a dynamic curriculum for source samples, called Curriculum
Manager for Source Selection (CMSS). The Curriculum Manager, an independent network module, constantly updates the curriculum during
training, and iteratively learns which domains or samples are best suited
for aligning to the target. The intuition behind this is to force the Curriculum Manager to constantly re-measure the transferability of latent
domains over time to adversarially raise the error rate of the domain
discriminator. CMSS does not require any knowledge of the domain labels, yet it outperforms other methods on four well-known benchmarks
by signiﬁcant margins. We also provide interpretable results that shed
light on the proposed method.
Keywords: unsupervised domain adaptation, multi-source, curriculum
learning, adversarial training
Introduction
Training deep neural networks requires datasets with rich annotations that are
often time-consuming to obtain. Previous proposals to mitigate this issue have
ranged from unsupervised , self-supervised , to
low shot learning . Unsupervised Domain Adaptation (UDA), when
ﬁrst introduced in , sheds precious insights on how adversarial training can
be utilized to get around the problem of expensive manual annotations. UDA
aims to preserve the performance on an unlabeled dataset (target) using a model
trained on a label-rich dataset (source) by making optimal use of the learned
representations from the source.
Intuitively, one would expect that having more labeled samples in the source
domain will be beneﬁcial. However, having more labeled samples does not equal
better transfer, since the source will inadvertently encompass a larger variety
of domains. While the goal is to learn a common representation for both source
and target in such a Multi-Source Unsupervised Domain Adaptation (MS-UDA)
setting, enforcing each source domain distribution to exactly match the target
may increase the training diﬃculty, and generate ambiguous representations near
the decision boundary potentially resulting in negative transfer. Moreover, for
 
Yang et. al
practical purposes, we would expect the data source to be largely unconstrained,
whereby neither the number of domains or domain labels are known. A good
example here would be datasets collected from the Internet where images come
from unknown but potentially a massive set of users.
To address the MS-UDA problem, we propose an adversarial agent that learns
a dynamic curriculum for multiple source domains, named Curriculum Manager for Source Selection (CMSS). More speciﬁcally, a constantly updated curriculum during training learns which domains or samples are best suited for
aligning to the target distribution. The CMSS is an independent module from
the feature network and is trained by maximizing the error of discriminator in
order to weigh the gradient reversal back to the feature network. In our proposed adversarial interplay with the discriminator, the Curriculum Manager is
forced to constantly re-measure the transferability of latent domains across time
to achieve a higher error of the discriminator. Such a procedure of weighing the
source data is modulated over the entire training. In eﬀect, the latent domains
with diﬀerent transferability to the target distribution will gradually converge
to diﬀerent levels of importance without any need for additional domain partitioning prior or clustering.
We attribute the following contributions to this work:
– We propose a novel adversarial method during training towards the MS-
UDA problem. Our method does not assume any knowledge of the domain
labels or the number of domains.
– Our method achieves state-of-the-art in extensive experiments conducted on
four well-known benchmarks, including the large-scale DomainNet (∼0.6
million images).
– We obtain interpretable results that show how CMSS is in eﬀect a form
of curriculum learning that has great eﬀect on MS-UDA when compared
to the prior art. This positively diﬀerentiates our approach from previous
state-of-the-art.
Related Work
UDA is an actively studied area of research in machine learning and computer
vision. Since the seminal contribution of Ben-David et al. , several techniques
have been proposed for learning representations invariant to domain shift . In this section, we review some recent methods that are most related
to our work.
Multi-Source Unsupervised Domain Adaptation (MS-UDA) assumes
that the source training examples are inherently multi-modal. The source domains contain labeled samples while the target domain contains unlabeled samples . In , adaptation was performed by aligning the moments
of feature distributions between each source-target pair. Deep Cocktail Network
(DCTN) considered the more realistic case of existence of category shift in
Curriculum Manager for Source Selection
Fig. 1: Illustration of CMSS during training. All training samples are passed through
the feature network F. CMSS prefers samples with better transferability to match
the target, and re-measure the transferability at each iteration to keep up with the
discriminator. At the end of training after the majority of samples are aligned, the
CMSS weights tend to be similar among source samples.
addition to the domain shift, and proposes a k-way domain adversarial classiﬁer
and category classiﬁer to generate a combined representation for the target.
Because domain labels are hard to obtain in the real world datasets, latent
domain discovery – a technique for alleviating the need for explicit domain
label annotation has many practical applications. Xiong et al. proposed to
use square-loss mutual information based clustering with category distribution
prior to infer the domain assignment for images. Mancini et al. used a domain
prediction branch to guide domain discovery using multiple batch-norm layers.
Domain-Adversarial Training has been widely used since Domain-
Adversarial Neural Network (DANN) was proposed. The core idea is to train
a discriminator network to discriminate source features from target, and train the
feature network to fool the discriminator. Zhao et al. ﬁrst proposed to generalize DANN to the multi-source setting, and provides theoretical insights on the
multi-domain adversarial bounds. Maximum Classiﬁer Discrepancy (MCD) 
is another powerful technique for performing adaptation in an adversarial manner using two classiﬁers. The method ﬁrst updates the classiﬁers to
maximize the discrepancy between the classiﬁers’ prediction on target samples,
followed by minimizing the discrepancy while updating the feature generator.
Domain Selection and Weighting: Some previous methods that employed
sample selection and sample weighing techniques for domain adaptation include
 . Duan et al. proposed using a domain selection machine by leveraging
a large number of loosely labeled web images from diﬀerent sources. The authors
of adopted a set of base classiﬁers to predict labels for the target domain as
well as a domain-dependent regularizer based on smoothness assumption. Bhatt
Yang et. al
Fig. 2: Architecture comparison of left: DANN , middle: IWAN , and right:
proposed method. Red dotted lines indicate backward passes. (F: feature extractor,
Cls: classiﬁer, D: domain discriminator, GRL: gradient reversal layer, CM: Curriculum
Manager, Ldom: Eq.1 domain loss, Lwdom: Eq.3 weighted domain loss)
et al. proposed to adapt iteratively by selecting the best sources that learn
shared representations faster. Chen et al. used a hand-crafted re-weighting
vector so that the source domain label distribution is similar to the unknown
target label distribution. Mancini et al. modeled the domain dependency
using a graph and utilizes auxiliary metadata for predictive domain adaptation.
Zhang et al. employed an extra domain classiﬁer that gives the probability
of a sample coming from the source domain. The higher the conﬁdence is from
such an extra classiﬁer, the more likely it can be discriminated from the target
domain, in which case the importance of the said sample is reduced accordingly.
Curriculum for Domain Adaptation aims at an adaptive strategy over
time in order to improve the eﬀectiveness of domain transfer. The curriculum can
be hand-crafted or learned. Shu et. al designed the curriculum by combining
the classiﬁcation loss and discriminator’s loss as a weighting strategy to eliminate the corrupted samples in the source domain. Another work with similar
motivation is , in which Chen et. al proposed to use per-category prototype
to measure the prediction conﬁdence of target samples. A manually designed
threshold τ is utilized to make a binary decision in selecting partial target samples for further alignment. Kurmi et. al used a curriculum-based dropout
discriminator to simulate the gradual increase of sample variance.
Preliminaries
Task Formulation: In multi-source unsupervised domain adaptation (MS-
UDA), we are given an input dataset Dsrc = {(xs
i=1 that contains samples
from multiple domains. In this paper, we focus on classiﬁcation problems, with
the set of labels ys
i ∈{1, 2, . . . , nc}, where nc is the number of classes. Each
i has an associated domain label, ds
i ∈{1, 2, . . . , S}, where S is the
number of source domains. In this work, we assume source domain label information is not known a priori, i.e., number of source domains or source domain
label per sample is not known. In addition, given an unlabeled target dataset
Dtgt = {xt
i=1, the goal of MS-UDA is to train models using multiple source
domains (Dsrc) and the target domain (Dtgt), and improve performance on the
target test set.
Curriculum Manager for Source Selection
Domain-Adversarial training: First, we discuss the domain-adversarial training formulation from that is the basis from which we extend to MS-UDA.
The core idea of domain-adversarial training is to minimize the distributional
distance between source and target feature distributions posed as an adversarial
game. The model has a feature extractor, a classiﬁer, and a domain discriminator. The classiﬁer takes in feature from the feature extractor and classiﬁes it in nc
classes. The discriminator is optimized to discriminate source features from target. The feature network, on the other hand, is trained to fool the discriminator
while at the same time achieve good classiﬁcation accuracy.
More formally, let Fθ : R3×w×h →Rd denote the feature extraction network,
Cφ : Rd →Rnc denote the classiﬁer, and Dψ : Rd →R1 denote the domain
discriminator. Here, θ, φ and ψ are the parameters associated with the feature
extractor, classiﬁer, and domain discriminator respectively. The model is trained
using the following objective function:
Lcls −λLdom
˜yi log(C(F(xs
Ldom = −Ex∼Dsrc log(D(F(x))) −Ex∼Dtgt log(1 −D(F(x)))
log(D(F(xs
log(1 −D(F(xt
Lcls is is the cross-entropy loss in source domain (with ˜yi being the one-hot
encoding of the label yi), and Ldom is the discriminator loss that discriminates
source samples from the target. Note that both these loss functions use samples
from all source domains.
In principle, if domain labels are available, there are two possible choices for
the domain discriminator: (1) k domain discriminators can be trained, each one
discriminating one of the source domains from the target , or (2) a domain
discriminator can be trained as a (k + 1)-way classiﬁer to classify input samples
as either one of the source domains or target . However, in our setup, domain
labels are unknown and, therefore, these formulations can not be used.
CMSS: Curriculum Manager for Source Selection
For the source domain that is inherently multi-modal, our goal is to learn a dynamic curriculum for selecting the best-suited samples for aligning to the target
feature distribution. At the beginning of training, the Curriculum Manager is expected to prefer samples with higher transferability for aligning with the target,
i.e., source samples which have similar feature distributions to the target sample. Once the feature distributions of these samples are aligned, our Curriculum
Manager is expected to prioritize the next round of source samples for alignment. As the training progresses, the Curriculum Manager can learn to focus on
Yang et. al
diﬀerent aspects of the feature distribution as a proxy for better transferability.
Since our approach learns a curriculum to prefer samples from diﬀerent source
domains, we refer to it is Curriculum Manager for Source Selection (CMSS).
Our approach builds on the domain-adversarial training framework (described
in §3). In this framework, our hypothesis is that source samples that are hard
for the domain discriminator to separate from the target samples are likely the
ones that have similar feature distributions. Our CMSS leverages this and uses
the discriminator loss to ﬁnd source samples that should be aligned ﬁrst. The
preference for source samples is represented as per-sample weights predicted by
CMSS. Since our approach is based on domain-adversarial training, weighing
Ldom using these weights will lead to the discriminator encouraging the feature
network to bring the distributions of higher weighted source samples closer to
the target samples. This signal between the discriminator and feature extractor
is achieved using the gradient reversal layer (see for details).
Therefore, our proposed CMSS is trained to predict weights for source samples at each iteration, which maximizes the error of the domain discriminator.
Due to this adversarial interplay with the discriminator, the CMSS is forced to
re-estimate the preference of source samples across training to keep up with the
improving domain discriminator. The feature extractor, F, is optimized to learn
features that are both good for classiﬁcation and confuse the discriminator. To
avoid any inﬂuence from the classiﬁcation task in the curriculum design, our
CMSS also has an independent feature extractor module that learns to predict
weights per-sample given the source images and domain discriminator loss.
Training CMSS: The CMSS weight for every sample in the source domain,
i, is given by ws
i . We represent this weighted distribution as ˜Dsrc. The CMSS
network is represented by Gρ : Rc×w×h →R1 with parameters ρ. Given a batch
of samples, xs
2, . . . xs
b, we ﬁrst pass these samples to Gρ to obtain an array of
scores that are normalized using softmax function to obtain the resulting weight
vector. During training, the CMSS optimization objective can be written as
i) log(D(F(xs
With the source sample weights generated by CMSS, the loss function for
domain discriminator can be written as
Lwdom = −1
i) log(D(F(xs
log(1 −D(F(xt
The overall optimization objective can be written as
Lcls −λLwdom
Curriculum Manager for Source Selection
where Lcls is the Cross-Entropy loss for source classiﬁcation and Lwdom is the
weighted domain discriminator loss from Eq. (3), with weights obtained by optimizing Eq. (2). λ is the hyperparameter in the gradient reversal layer. We follow and set λ based on the following annealing schedule: λp =
1+exp(−γ·p)−1,
where p is the current number of iterations divided by the total. γ is set to 10
in all experiments as in . Details of training are provided in Algorithm 1.
CMSS: Theoretical Insights
We ﬁrst state the classic generalization bound for domain adaptation . Let
H be a hypothesis space of V C-dimension d. For a given hypothsis class H,
deﬁne the symmetric diﬀerence operator as H∆H = {h(x) ⊕h′(x)|h, h′ ∈H}.
Let Dsrc, Dtgt denote the source and target distributions respectively, and ˆDsrc,
ˆDtgt denote the empirical distribution induced by sample of size m drawn from
Dsrc, Dtgt respectively. Let ϵs (ϵt) denote the true risk on source (target) domain,
and ˆϵs (ˆϵt) denote the empirical risk on source (target) domain. Then, following
Theorem 1 of , with probability of at least 1 −δ, ∀h ∈H ,
ϵt(h) ≤ˆϵs(h) + 1
2dH∆H( ˆDsrc, ˆDtgt) + C
where C is a constant
d log(m/d) + log(1/δ)
Here, λ is the optimal combined risk (source + target risk) that can be achieved
by hypothesis in H. Let {xs
i=1 be the samples in the empirical distributions ˆDsrc and ˆDtgt respectively. Then, P(xs
i) = 1/m and P(xt
i) = 1/m. The
empirical source risk can be written as ˆϵs(h) = 1/m P
Now consider a CMSS re-weighted source distribution ˆDwsrc, with P(xs
wi. For ˆDwsrc to be a valid probability mass function, P
i = 1 and ws
Algorithm 1 Training CMSS (Curriculum Manager for Source Selection)
Require: Niter: Total number of training iterations
Require: γ: For computing λp for Lwdom
Require: N s
b: Batch size for source and target domains
1: Shuﬄe the source domain samples
2: for t in (1 : Niter) do
Compute λ according to 2/(1 + exp(−γ · (t/Niter))) −1
Sample a training batch from source domains {(xs
i=1 ∼Dsrc and from
target domain {xt
Update ρ by minρ −λLwdom
Update ψ by minψ λLdom
Update θ, φ by minθ,φ Lcls −λLwdom
8: end for
Yang et. al
Note that ˆDsrc and ˆDwsrc share the same samples, and only diﬀer in weights.
The generalization bound for this re-weighted distribution can be written as
2dH∆H( ˆDwsrc, ˆDtgt) + C
Since the bound holds for all weight arrays w = [ws
2 . . . ws
m] in a simplex, we
can minimize the objective over w to get a tighter bound.
ϵt(h) ≤min
2dH∆H( ˆDwsrc, ˆDtgt) + C
The ﬁrst term is the weighted risk, and the second term dH∆H( ˆDwsrc, ˆDtgt) is
the weighted symmetric divergence which can be realized using our weighted
adversarial loss. Note that when w = [1/m, 1/m, . . . 1/m], we get the original
bound (5). Hence, the original bound is in the feasible set of this optimization.
Relaxations. In practice, deep neural networks are used to optimize the bounds
presented above. Since the bound (6) is minimized over the weight vector w, one
trivial solution is to assign non-zero weights to only a few source samples. In this
case, a neural network can overﬁt to these source samples, which could result
in low training risk and low domain divergence. To avoid this trivial case, we
present two relaxations:
– We use the unweighted loss for the source risk (ﬁrst term in the bound (6)).
– For the divergence term, instead of minimizing w over all the samples, we
optimize only over mini-batches. Hence, for every mini-batch, there is at
least one wi which is non-zero. Additionally, we make weights a function
of input, i.e., wi = Gρ(xs
i), which is realized using a neural network. This
will smooth the predictions of wi, and make the weight network produce a
soft-selection over source samples based on correlation with the target.
Note that the Gρ network discussed in the previous section satisﬁes these criteria.
Experimental Results
In this section, we perform an extensive evaluation of the proposed method
on the following tasks: digit classiﬁcation(MNIST, MNIST-M, SVHN, Synthetic
Digits, USPS), image recognition on the large-scale DomainNet dataset (clipart,
infograph, paiting, quickdraw, real, sketch), PACS (art, cartoon, photo and
sketch) and Oﬃce-Caltech10 (Amazon, Caltech, Dslr, Webcam). We compare
our method with the following contemporary approaches: Domain Adversarial Neural Network (DANN) , Multi-Domain Adversarial Neural Network
(MDAN) and two state-of-the-art discrepancy-based approaches: Maximum Classiﬁer Discrepancy (MCD) and Moment Matching for Multi-
Source (M 3SDA) . We follow the protocol used in other multi-source domain
Curriculum Manager for Source Selection
Table 1: Results on Digits classiﬁcation. The proposed CMSS achieves 90.8%
accuracy. Comparisons with MCD and M 3SDA are reprinted from . All experiments are based on a 3-conv-layer backbone trained from scratch. (mt, mm, sv, sy, up:
MNIST, MNIST-M, SVHN, Synthetic Digits, UPSP)
mm, sv, sy, up
mt, sv, sy, up
mt, mm, sy, up
mt, mm, sv, up
mt, mm, sv, sy
Source Only
92.3 ± 0.91
63.7 ± 0.83
71.5 ± 0.75
83.4 ± 0.79
90.7 ± 0.54
80.3 ± 0.76
97.9 ± 0.83
70.8 ± 0.94
68.5 ± 0.85
87.3 ± 0.68
93.4 ± 0.79
83.6 ± 0.82
97.2 ± 0.98
75.7 ± 0.83
82.2 ± 0.82
85.2 ± 0.58
93.3 ± 0.48
86.7 ± 0.74
96.2 ± 0.81
72.5 ± 0.67
78.8 ± 0.78
87.4 ± 0.65
95.3 ± 0.74
86.1 ± 0.64
M 3SDA 
98.4 ± 0.68
72.8 ± 1.13
81.3 ± 0.86
89.5 ± 0.56
96.1 ± 0.81
87.6 ± 0.75
99.0 ± 0.08
75.3 ± 0.57
88.4 ± 0.54
93.7 ± 0.21
97.7 ± 0.13
90.8 ± 0.31
adaptation works , where each domain is selected as the target domain
while the rest of domains are used as source domains. For Source Only and
DANN experiments, all source domains are shuﬄed and treated as one domain.
To guarantee fairness of comparison, we used the same model architectures,
batch size and data pre-processing routines for all compared approaches. All our
experiments are implemented in PyTorch.
Experiments on Digit Recognition
Following DCTN and M 3SDA , we sample 25000 images from training
subset and 9000 from testing subset of MNIST, MNIST-M, SVHN and Synthetic
Digits. The entire USPS is used since it contains only 9298 images in total.
In all the experiments, the feature extractor is composed of three conv layers
and two fc layers. The entire network is trained from scratch with batch size
equals 16. For each experiment, we run the same setting ﬁve times and report
the mean and standard deviation. (See Appendix for more experiment details
and analyses.) The results are shown in Table 1. The proposed method achieves
an 90.8% average accuracy, outperforming other baselines by a large margin
(∼3% improvement on the previous state-of-the-art approach).
Experiments on DomainNet
Next, we evaluate our method on DomainNet – a large-scale benchmark
dataset used for multi-domain adaptation. The DomainNet dataset contains
samples from 6 domains: Clipart, Infograph, Painting, Quickdraw, Real and
Sketch. Each domain has 345 categories, and the dataset has ∼0.6 million
images in total, which is the largest existing domain adaptation dataset. We use
ResNet-101 pretrained on ImageNet as the feature extractor for in all our experiments. For CMSS, we use a ResNet-18 pretrained on ImageNet. The batch size
is ﬁxed to 128. We conduct experiments over 5 random runs, and report mean
and standard deviation over the 5 runs.
Yang et. al
Table 2: Results on the DomainNet dataset. CMSS achieves 46.5% average accuracy. When the target domain is quickdraw q, CMSS is the only one that outperforms
Source Only which indicates negative transfer has been alleviated. Source Only * is reprinted from , Source Only is our implemented results. All experiments are based on
ResNet-101 pre-trained on ImageNet. (c: clipart, i: infograph, p: painting, q: quickdraw,
r: real, s: sketch)
Source Only*
Source Only
M 3SDA 
The results are shown in Table 2. CMSS achieves 46.5% average accuracy,
outperforming other baselines by a large margin. We also note that our approach
achieves the best performance in each experimental setting. It is also worth
mentioning that in the experiment when the target domain is Quickdraw (q),
our approach is the only one that outperforms Source Only baseline, while all
other compared approaches result in negative transfer (lower performance than
the source-only model). This is since quickdraw has a signiﬁcant domain shift
compared to all other domains. This shows that our approach can eﬀectively
alleviate negative transfer even in such challenging set-up.
Experiments on PACS
PACS is another popular benchmark for multi-source domain adaptation.
It contains 4 domains: art, cartoon, photo and sketch. Images of 7 categories are
collected for each domain. There are 9991 images in total. For all experiments,
we used ResNet-18 pretrained on ImageNet as the feature extractor following
 . For the Curriculum Manager, we use the same architecture as the feature
extractor. Batch size of 32 is used. We conduct experiments over 5 random runs,
and report mean and standard deviation over the runs. The results are shown
in Table 3 (a: art, c: cartoon, p: painting, s: sketch.). CMSS achieves the state-ofthe-art average accuracy of 89.5%. On the most challenging sketch (s) domain,
we obtain 82.0%, outperforming other baselines by a large margin.
Experiments on Oﬃce-Caltech10
The oﬃce-Caltech10 dataset has 10 object categories from 4 diﬀerent domains: Amazon, Caltech, DSLR, and Webcam. For all the experiments, we use
the same architecture (ResNet-101 pretrained on ImageNet) used in . The
Curriculum Manager for Source Selection
Table 3: Results on PACS
c, p, s →a
a, p, s →c
a, c, s →p
a, c, p →s
Source Only
M 3SDA 
Table 4: Results on Oﬃce-Caltech10
Source Only
M 3SDA 
Table 5: Comparing re-weighting methods
r, s →c r, s →i r, s →p r, s →q q, s →r q, r →s
w variance by ours
w variance by IWAN
Fig. 3: Mean/var of weights over time.
experimental results are shown in Table 4 (A: Amazon, C: Caltech, D: Dslr, W:
Webcam). CMSS achieves state-of-the-art average accuracy of 97.2%.
Comparison with other re-weighting methods
In this experiment, we compare CMSS with other weighing schemes proposed in
the literature. We use IWAN for this purpose. IWAN, originally proposed
for partial domain adaption, reweights the samples in adversarial training using
outputs of discriminator as sample weights (Refer to Figure 2). CMSS, however,
computes sample weights using a separate network Gρ updated using an adversarial game. We adapt IWAN for multi-source setup and compare it against our
approach. The results are shown in Table 5 (abbreviations of domains same as
Table 2). IWAN obtained 43.1% average accuracy which is close to performance
obtained using DANN with combined source domains. For further analysis, we
plot how sample weights estimated by both approaches (plotted as mean ± variance) change as training progresses in Figure 3. We observe that CMSS selects
weights with larger variance which demonstrates its sample selection ability,
while IWAN has weights all close to 1 (in which case, it becomes similar to
DANN). This illustrates the superiority of our sample selection method. More
discussions on sample selection can be found in Section 6.2. CMSS also achieves
a faster and more stable convergence in test accuracy compared to DANN 
where we assume a single source domain (Figure 6), which further supports the
eﬀectiveness of the learnt curriculum.
Yang et. al
Target = Clipart
Clipart Infograph Painting Quickdraw Real
Number of Samples above threshold
Thresh =2.0
Thresh =2.2
Clipart Infograph Painting Quickdraw Real
Thresh =0.8
Thresh =0.9
Thresh =0.4
Thresh =0.5
Clipart Infograph Painting Quickdraw Real
Thresh =0.2
Thresh =0.3
Clipart Infograph Painting Quickdraw Real Sketch
Thresh =0.9
Thresh =1.0
Clipart Infograph Painting Quickdraw Real
Thresh =1.2
Thresh =1.4
Clipart Infograph Painting Quickdraw Real
Number of Samples above threshold
Fig. 4: Interpretation results of the sample selection on DomainNet dataset using
the proposed method. In each plot, one domain is selected as the target. In each setting,
predictions of CMSS are computed for each sample of the source domains. The bars
indicate how many of these samples have weight prediction larger than a manually
chosen threshold, with each bar denoting a single source domain. Maximum number of
samples are highlighted in red. Best viewed in color
Interpretations
In this section, we are interested in understanding and visualizing the source
selection ability of our approach. We conduct two sets of experiments: (i) visualizations of the source selection curriculum over time, and (ii) comparison of our
selection mechanism with other sample re-weighting methods.
Visualizations of source selection
Domain Preference We ﬁrst investigate if CMSS indeed exhibits domain preference over the course of training as claimed. For this experiment, we randomly
select m = 34000 training samples from each source domain in DomainNet and
obtain the raw weights (before softmax) generated by CMSS. Then, we calculate
the number of samples in each domain passing a manually selected threshold τ.
We use the number of samples passing this threshold in each domain to indicate
the domain preference level. The larger the fraction, more weights are given to
samples from the domains, hence, higher the domain preference. Figure 4 shows
the visualization of domain preference for each target domain. We picked 3 different τ in each experiment for more precise observation. We observe that CMSS
does display domain preference (Clipart - Painting, Infograph - Sketch, Real -
Clipart) that is in fact correlated with the visual similarity of the domains. An
exception is Quickdraw, where no domain preference is observed. We argue that
this is because Quickdraw has signiﬁcant domain shift compared to all other
domains, hence no speciﬁc domain is preferred. However, CMSS still produces
Curriculum Manager for Source Selection
Top Ranked
Bottom Ranked
Bottom Ranked
Fig. 5: Ranked source samples according to learnt weights (class “Clock” of Domain-
Net dataset). LHS: Examples of unlabeled target domain Clipart and the Top/Bottom
Ranked ∼50 samples of the source domain composed of Infograph, Painting, Quickdraw, Real and Sketch. RHS: Examples of unlabeled target domain Quickdraw and the
Ranked samples of source domain composed of Clipart, Infograph, Painting, Real and
Sketch. Weights are obtained at inference time using CMSS trained after 5 epochs.
Proposed Method
DANN source combined
Fig. 6: Test accuracy after the model is trained for t epochs. Comparison between CMSS
and DANN using source domains combined as one.
better performance on Quickdraw. While there is no domain preference for Quickdraw, there is within-domain sample preference as illustrated in Figure 5. That
is, our approach chooses samples within a domain that are structurally more similar to the target domain of interest. Hence, just visualizing aggregate domain
preference does not depict the complete picture. We will present sample-wise
visualization in the next section.
Beyond Domain Preference In addition to domain preference, we are interested in taking a closer look at sample-wise source selection. To do this, we ﬁrst
obtain the weights generated by CMSS for all source samples and rank the source
images according to their weights. An example is shown in Figure 5. For better
understanding, we visualize samples belonging to a ﬁxed category (“Clock” in
Figure 5). See Appendix for more visualizations.
In Figure 5, we ﬁnd that notion of similarity discovered by CMSS is diﬀerent
for diﬀerent domains. When the target domain is Clipart (left panel of Figure 5),
source samples with colors and cartoonish shapes are ranked at the top, while
samples with white background and simplistic shapes are ranked at the bottom.
When the target is Quickdraw (right panel of Figure 5), one would think that
Yang et. al
Target range
Fig. 7: t-SNE visualization of features at six diﬀerent epochs during training. The
shaded region is the migrated range of target features. Dateset used is PACS with
sketch as the target domain.
CMSS will simply be selecting images with similar white background. Instead, it
prefers samples which are structurally similar to the regular rounded clock shape
(as most samples in Quickdraw are similar to these). It thus appears that structural similarity is favored in Quickdraw, whereas color information is preferred
in Clipart. This provides support that CMSS selects samples according to ease of
alignment to the target distribution, which is automatically discovered per domain. We argue that this property of CMSS has an advantage over approaches
such as MDAN which simply weighs manually partitioned domains.
Selection Over Time
In this section, we discuss how source selection varies as training progresses. In
Figure 3, we plot mean and variance of weights (output of Curriculum Manager)
over training iterations. We observe that the variance is high initially, which
indicates many samples have weights away from the mean value of 1. Samples
with higher weights are preferred, while those with low weights contribute less to
the alignment. In the later stages, the variance is very low which indicates most of
the weights are close to 1. Hence, our approach gradually adapts to increasingly
many source samples over time, naturally learning a curriculum for adaptation.
In Figure 7, we plot a t-SNE visualization of features at diﬀerent epochs. We
observe that the target domain sketch (red) ﬁrst adapts to Art (yellow), and
then gradually aligns with Cartoon (green) and Photo (blue).
Conclusion
In this paper, we proposed Curriculum Manager for Source Selection (CMSS)
that learns a curriculum for Multi-Source Unsupervised Domain Adaptation.
A curriculum is learnt that iteratively favors source samples that align better
with the target distribution over the entire training. The curriculum learning is
achieved by an adversarial interplay with the discriminator, and achieves stateof-the-art on four benchmark datasets. We also shed light on the inner workings
of CMSS, and we hope that will pave the way for further advances to be made
in this research area.
Curriculum Manager for Source Selection
Acknowledgement
This work was supported by Facebook AI Research and DARPA via ARO contract number W911NF2020009.