Real-Time Dynamics from Imaginary-Time Quantum Monte Carlo Simulations:
Tests on Oscillator Chains
J. Bonˇca∗and J.E. Gubernatis
Theoretical Division, Los Alamos National Laboratory, Los Alamos, NM 87545
 
We used methods of Bayesian statistical inference and the principle of maximum entropy to analytically continue imaginary-time Green’s function generated in quantum Monte Carlo simulations
to obtain the real-time Green’s functions. For test problems, we considered chains of harmonic and
anharmonic oscillators whose properties we simulated by a hybrid path-integral quantum Monte
Carlo method. From the imaginary-time displacement-displacement Green’s function, we ﬁrst obtained its spectral density. For harmonic oscillators, we demonstrated the peaks of this function were
in the correct position and their area satisﬁed a sum rule. Additionally, as a function of wavenumber, the peak positions followed the correct dispersion relation. For a double-well oscillator, we
demonstrated the peak location correctly predicted the tunnel splitting. Transforming the spectral
densities to real-time Green’s functions, we conclude that we can predict the real-time dynamics
for length of times corresponding to 5 to 10 times the natural period of the model. The length of
time was limited by an overbroadening of the peaks in the spectral density caused by the simulation
algorithm.
02.70.Lq, 05.30.-d, 02.50.Wp
I. INTRODUCTION
One of the goals for doing computer simulations is the production of information useful in the interpretation and
design of experiments. Notwithstanding important issues regarding Hamiltonian selection and parameterization, the
interface of simulations with experiment is particularly challenging for quantum systems. The current Monte Carlo
algorithms, whether they impose quantum particle statistics constraints or not, are performed either in real-time t
or in imaginary-time (Euclidean time) τ = −it. In real-time, the propagator exp(itH) for a system, described by a
Hamiltonian H, oscillates wildly at long-times. Analytically, these rapid oscillations self-cancel, but a Monte Carlo
process, as it is typically used, has diﬃculty achieving this cancellation. As a consequence, modiﬁcations of the basic
algorithms have been proposed to extend the simulations as long as possible in the real-time domain . With these
new algorithms, simulations typically produce dynamics extending to 2 to 3 times the natural periods of the systems.
In imaginary-time, the propagator exp(−τH) is diﬀusive and the rapid oscillations are avoided. Correlations functions
G(τ), however, are now a function of imaginary-time, and such functions do not easily convey the actual dynamics
of the system. In principle, real-time correlation (Green’s) functions ˆG(t) can be obtained from the imaginary-time
ones by the process of analytic continuation. In practice, this process is diﬃcult because it is ill-posed and because
the Monte Carlo data is incomplete and noisy.
Recently, procedures were proposed to perform this analytic continuation .
These procedures draw heavily
upon methods of Bayesian statistical inference and the principle of maximum entropy to infer from imaginary-time
correlation functions their associated spectral densities A(ω). Through linear-response theory, the spectral densities
represent the spectra associated with numerous real-time measurements of current-current, spin-spin, etc. correlations
functions. What apparently has not yet been tried is performing the Hilbert transform of these spectral densities to
obtain the frequency-dependent retarded correlation function and then Fourier transforming this quantity to obtain
the real-time correlation function. In this paper, we will carry out these additional steps. By doing this, we hope to
gain a greater understanding of the physical content present in the spectral density returned by the Bayesian methods.
We expected that the resultant real-time information would be limited by the approximate and probabilistic nature
of the analytic continuation methods. We found, however, that the distance in real-time over which our results are
valid is limited primarily by the ability of the simulation algorithm to produce good data. To interface proﬁtably with
the numerical analytic continuation, the simulation algorithm has to produce high quality data consistent with the
assumptions of procedures. The algorithm we used had problems doing this, and we will describe the measures taken
to reduce this diﬃculty. Even so, in most cases we were able to extend in real-time up to factor of 10 natural periods
of the physical systems. Longer extensions are possible and require longer Monte Carlo runs. For present purposes,
we had no physical motivation to do so.
In Section II, we will discuss the various models studied. We simulated a particle moving in single harmonic and
double-well anharmonic potential and a collection of particles moving in chains of these potentials. For these models
we know the exact solutions. By calculating their properties numerically, we can benchmark our methods. Certain
properties of a single double-well potential, like the tunnel splitting, are easily obtained numerically.
diagram for a chain of such oscillators is also known . This type of chain can exist in a symmetric or displacive
state. In Section III, we summarize the numerical analytic continuation procedure we used and discuss our simulation
technique. Modifying the simulation technique to be more naturally ergodic and to produce data with short statistical
auto-correlation times was the most diﬃcult and restrictive part of our study. We present our results and conclusions
in Sections IV and V.
II. MODELS
We simulated ﬁve Hamiltonians. One was that for a single harmonic oscillator
which has the natural frequency ω0 =
γ/m. Another was that for a chain of N such oscillators
2 (xi −xi−1)2
Fourier transforming the displacements xi and momenta pi, we can of course rewrite this second Hamiltonian as
where k = −π, −(N −1)π/N, . . . , π and ω2
0(1 −cos k). In this form, the Hamiltonian is explicitly expressed as
a collection on N independent simple oscillators. The natural frequency of an oscillator is ωk. The third Hamiltonian
was a variant of the harmonic chain
2 (xi −xi−1)2 + 1
which after Fourier transforming the displacements becomes
k = 1 + 2ω2
0(1 −cos k). In this form, the Hamiltonian is again explicitly expressed as a collection on N
independent simple oscillators but with a dispersion relation that has a non-zero frequency at k = 0. The two other
Hamiltonians were a single, symmetric, double-well potential
which has well bottoms at x = ±1 and a barrier height of unity at x = 0, and a chain of such potentials
2 (xi −xi−1)2 + 1
In the chain, ǫ sets the barrier height of every double-well. In both chains we assumed periodic boundary conditions
and disallowed particle exchange.
For these Hamiltonians, our simulations obtained estimates of the imaginary-time displacement-displacement
Green’s function
Gij(τ) = Gi−j(τ) = ⟨Tτxi(τ)xj(0)⟩
Here, the angular brackets denote thermal averaging. It is more convenient and illuminating to work with the spatial
Fourier transform Gk(τ) of Gij and it is known that
dω e−τωAk(ω)
where Ak(ω) is the spectral density. This function has the properties that
Ak(ω) = −Ak(−ω)
The odd symmetry of Ak(ω) allows us to re-express (9) as
dω ω[e−τω + e−(β−τ)ω]
and it is straightforward to show that Ak(ω) obeys the sum rule
1 −e−βω = ⟨x2
The spectral density Ak(ω) is also related to the frequency Fourier transform ˆGR(ω) of the real-time, retarded
Green’s function 
k (t) = −iθ(t)⟨[x−k(t), xk(0)]⟩
ω −ω′ + iη
where 0 < η ≪1, from which it follows that
k (t) = −iθ(t) 1
dω Ak(ω)e−iωte−ηt
For an individual harmonic oscillator of frequency ωk, the eigenstates and energies are exactly known, and all the
quantities in the above paragraph are known analytically:
sinh(βωk/2) cosh
Ak(ω) = π[δ(ω −ωk) −δ(ω + ωk)]/mωk
ω −ωk + iη −
ω + ωk + iη
k (t) = θ(t) 1
mω sin(ωkt)e−ηt
coth (βωk/2)
The eigenstates and energies of a single harmonic oscillator have deﬁnite, well-known characteristics: Because the
potential is symmetric about x = 0, the eigenfunctions have alternating parity. The ground state has even parity and
an energy 1
2ωk. The energies of the excited states are regularly spaced at intervals of ωk. The double-well potential
is also symmetric about x = 0, and its eigenstates also alternate in parity with the ground state again having even
parity. The precise details about the energy spectrum, however, are only available numerically. When these states
lie below the barrier, and particularly for deep wells, they group into widely-separated, nearly degenerate pairs. The
separation in energies within and between pairs is called the tunnel spitting.
The spectral density is dominated
by terms with matrix elements involving states 0 and 1. Contributions from matrix elements of x involving (0,3),
(3,4), (0,5), (3,5), (5,6), etc. have smaller contribution to the spectral density because of smaller overlap between
the eigenstates. Additionally, most can be “frozen-out” by making the temperature at least comparable to E3 −E0.
This temperature range is the one in which we generally worked. The nature of the energy levels and eigenstates is
schematically represented in Fig. 1.
The spatial Fourier transformation of the Hamiltonian of the double-well chain does not produce as system of independent oscillators. This is the essence of its non-linearity. The model, however, has an interesting zero-temperature
phase diagram as a function of the parameters ǫ and γ . Roughly, ǫ is a measure of the barrier height relative to the
frequency of inter-site oscillation and the frequency of oscillation associated with the well-bottom. When the barrier
height is large, the particles collectively are displaced to the left or the right of their classical equilibrium positions in
a broken symmetry state characterized by a non-zero value of the mean-squared displacement. As the barrier height
is lowered, a critical value is reached where because of zero-point motion and tunneling, the particles collectively
make a transition to a state where the mean-squared displacement of each is zero. Accordingly, a simulation of the
chain, done in one of these two thermodynamic phases, is expected to exhibit diﬀerent quantum characteristics in the
spectral density.
III. METHODS
A. Hybrid Path-Integral Monte Carlo Method
Our Monte Carlo simulations will be based on the Feynman path integral formulation of quantum mechanics. In
imaginary-time, this formulation represents the partition function Z as
Dxe−S[x(t)]
dτ H[x(τ)]
is the action corresponding to the path x(τ) and H[x(τ)] represents the path dependence of the Hamiltonian. The
Monte Carlo method is used to perform the integration over the paths in (21). It is applied after the integral in (22)
is approximated by a sum over L steps in imaginary-time each of length ∆τ and the momenta are approximated by
a forward-diﬀerence approximation between successive displacements in imaginary-time:
pi(τ) = m∂xi(τ)
≈mxi(τ + ∆τ) −xi(τ)
For a one-dimensional system of N particles, the action becomes
2 (xi,j −xi,j+1
)2 + V (xi,j, xi+1,j)
This form is similar in appearance to a classical two-body potential energy deﬁned on a N × L lattice where at a
given τ the particles interact through the potential energy function of the original problem (scaled by ∆τ), and at a
given position they interact by a harmonic potential with a spring constant equal to m/∆τ. For a single particle, the
summation over the spatial coordinate i is dropped and the discretized action has the interpretation of a chain where
the particles at imaginary-time move in a potential ∆τV (xj) while interacting with particles at neighboring times by
a harmonic potential with spring constant 1/∆τ. For the models we are considering, the discretized actions are:
1. Single Harmonic Oscillator:
2. Harmonic Chain:
xi,j+1 −xi,j
2 (xi+1,j −xi,j)2 ,
3. Harmonic Chain plus on-site oscillator:
xi,j+1 −xi,j
2 (xi+1,j −xi,j)2 + 1
4. Single Double-Well Potential:
5. Double-Well Chain:
xi+1,j −xi,j
2 (xi,j −xi,j+1)2 + 1
The simplest way to apply the Monte Carlo method is to move repeatedly from point to point on the space-time
lattice, at each point propose a change in the coordinate, xi,j →x′
i,j, and accept the change via the Metropolis
algorithm with probability min[1, exp(−∆S)] where ∆S is the change in the value of the action proposed by the
proposed change . This method is often called path-integral Monte Carlo (PIMC).
An alternative to the Monte Carlo evaluation of the path-integral is a molecular dynamics evaluation . Here, a
ﬁctitious momentum πi,j is associated with each point to deﬁne a pseudo Hamiltonian
and standard molecular dynamics techniques are used to sample phase space. The approach takes advantage of the
classical nature of the ﬁelds in the path-integral formulation and produces the correct statistical mechanics because
in classical statistical mechanics the momentum degrees of freedom can be integrated out of the partition function.
The method is often called path-integral molecular dynamics.
At the core of the method we used is the hybrid Monte Carlo approach suggested by Duane et al. which
combines the molecular dynamics approach with the Monte Carlo procedure to obtain the best features of both
methods. The general expectation is faster equilibration of the simulation and shorter auto-correlation times between
measured quantities. With this method, the following steps are cycled: For a given set of xi,j the corresponding
pseudo momenta are assigned values randomly from a Maxwell-Boltzmann distribution for the velocities. The energy
is computed. Next, both the momenta and displacements are evolved by molecular dynamics for some pseudo time tp.
The energy is recomputed. Then the evolved displacements are accepted with probability min[1, exp(−∆E)], where
∆E is the diﬀerence in energy between the initial and ﬁnal conﬁguration. Normally, molecular dynamics is energy
conserving so the evolved displacements would always be accepted. A guiding idea behind the hybrid method is to
use for the molecular dynamics with emphasis on fast integration, as opposed to accurate integration, and to adjust
the size of these steps ∆t and tp so the Monte Carlo decision accepts 90 −95% of the conﬁguration. The molecular
dynamics method globally updates all the displacements and is a computationally eﬃcient procedure. The Monte
Carlo procedure maintains detailed balance to ensure proper equilibrium averages and ﬁlters out the results of “bad”
integrations.
We found, however, that this simple form of the hybrid method was inadequate for present purposes. The output
of our simulation is to be used as input to maximum entropy procedures to execute the analytic continuation. As
we will discuss below, the analytic continuation problem is an ill-posed problem and hence is very sensitive to the
size of the errors associated with the input data. For a ﬁxed amount of computer time, reducing the size of the error
eﬃciently by a Monte Carlo method requires shortening the auto-correlation times between measurements. In our
computed Green’s function, in spite of small estimates for the error bars, we would often see small (within the error
bars) unphysical sawtooth-like structure in regions about τ = β/2. Following a simple procedure suggested by Neal
 , we could generally remove this structure and also be more ergodic. His suggestion was after each Monte Carlo
decision to reverse the direction of the molecular time integration, i.e., ∆t →−∆t, with probability 1/2. A smaller
improvement is achieved by not using a ﬁxed length for the time integration in the molecular dynamics simulation but
rather to choose the length randomly from the interval (tp −δ, tp + δ) where tp and δ are chosen so the Monte Carlo
acceptance rate is in the 90 to 95 per cent range. We will refer to the combined method as the hybrid path-integral
Monte Carlo method (HPIMC). Adjusting the Monte Carlo acceptance rate is not the entire story. First, it seems
best to insure tp is several times larger than the natural period associated with the slowest signiﬁcant modes in the
systems and then choose δ to ﬁx the acceptance ratio.
We remark that Fahy and Hamann observed for the standard hybrid method the existence of a critical time tc
(dependent of model parameters) demarking non-ergodic and chaotic behavior in the results of the time integration.
For a harmonic system, tc is inﬁnite which suggests the inapplicability of the method to a harmonic system. We
observed the behavior they found but whether tp was larger or smaller than tc had only small consequences on our
measured results. As we illustrate below, we achieved very accurate results for the harmonic models.
We also remark that the results of the simulations depend on the size of ∆τ. By performing simulations for several
diﬀerent values of ∆τ, we could in principle extrapolate the results to the ∆τ = 0 limit. We did not do this but
instead observed that simulations performed with diﬀerent values of ∆τ gave very similar results.
B. Maximum Entropy Method
The maximum entropy method is used to regularize the solution of (11). Dropping the subscript k for convenience,
we rewrite this equations as
dω K(τ, ω)[A(ω)/ω]
where the kernel
e−τβ + e−(β−τ)
Because both the kernel and A(ω)/ω are regular at ω = 0, we solve for A(ω)/ω and then trivially ﬁnd A(ω). For
discrete values of τ and ω we approximate (31) as
where Gi = G(τi), Ki,j = K(τi, ωj), and Aj = A(ωj)∆ωj/ωj.
The Monte Carlo method will return estimates ¯Gi of Gi and estimates of the sample variance σ2
j on the Gi. With
this information, a natural solution path to Aj would be to ﬁnd the values of Aj that minimize
( ¯Gi −Gi)2/σ2
This approach, however, almost always fails. One reason is that it ignores the strong correlations that normally exist
between the measured values of Gi, i.e., values of the Green’s function at diﬀerent imaginary-times. At the very least,
we must modify (35) to be
( ¯Gi −Gi)[C−1]i,j( ¯Gj −Gj)
where Ci,j is the measured covariance among the values of ¯Gi. The i-th diagonal element of C is simply σ2
modiﬁcation of the deﬁnition of χ2 while necessary is insuﬃcient. The diﬃculty is the inverse problem, that is, solving
(31) for A(ω), is ill-posed. This condition is caused by the exponential character of the kernel at large values of ω.
At large ω, large variations in A(ω) make little change in G(τ). The simulation, on other other hand, gives noisy
and incomplete information about G(τ), and hence for a given set of ¯Gi, an inﬁnite number of Aj will satisfy the
least-squared estimate (36).
The next level of solution seeks to regularize the minimization of χ2 by constraining it, i.e., minimizing
where the αi are Lagrange multipliers and the fi(A) are functions of Aj representing possible constraints on the
solution. Typical constraints include smoothness, non-negativity, sum rules, moments, etc. The diﬃculty with this
approach is choosing the Lagrange multipliers. Ad hoc choices are commonplace. Often small changes in the values
of these parameters produce massive changes in the results.
The maximum entropy approach follows from the observation that the spectral density is interpretable as a probability density function. The principle of maximum entropy states the probabilities should be assigned in such a way
as to maximize
Aj −mj −Aj ln(Aj/mj)
Here, the mj, called the default model, set the location of the maximum of S and the value of S at this point to
be zero. The default model is solution for Aj in the absence of other constraints on Aj. The method of maximum
entropy maximizes
Q(A) = αS −1
To ﬁx α, an ad hoc procedure called historic maximum entropy is often used . An more modern alternative
is the Bayesian-based classic maximum entropy which uniquely determines α provided certain conditions are meet
 . Under these conditions solution for Aj is the most probable one. Unfortunately, these conditions seem often
violated in the analytic condition problem. Accordingly, to estimate the Aj, we adopted a procedure suggested by
In Bryan’s method , for a given value of α, we ﬁnd the A(α) that maximizes Q(A). For the solution to (33), we
dα A(α) Pr[α| ¯G]
where Pr[α| ¯G] is the probability of α given the data ¯G. Bayesian analysis shows that
Pr[α| ¯G] = Pr[α]
where ZL is the normalization factor for e−1
2 χ2, ZS(α) is the normalization factor for eαS, and Pr[α] is Jeﬀreys’ prior.
Details on the computation of this joint probability are discussed elsewhere . With this function, the integral (40)
is performed numerically.
The most diﬃcult part of the problem is not evaluating the maximum entropy equations but satisfying the statistical
assumptions on which they are based. The principal assumption is
Pr[ ¯G|A] = e−1
The meaning of this assumption is the measured values of Gi are statistically independent and distributed according
to a multi-variable Gaussian distribution function deﬁned by the covariance matrix C. Proper estimation of C is
paramount. Under normal circumstance the data produced by the simulations do not satisfy these assumptions. The
procedures we use to have the data approximate these assumptions are discussed elsewhere . When we have proper
data, our solution (40) usually shows good insensitivity to the choice of the default model. Additionally, the historic
and classic maximum entropy solutions usually agree well with it.
IV. RESULTS
To determine spectral properties of models listed in Section II, we performed HPIMC simulations with up to 800
bins of data (Nbin) , each with up to 4000 measurements (Nsweep). Simulations with large bin-sizes were necessary
to avoid nonergodic behavior of the HPIMC method when used for chains with double well potentials close to the
zero-temperature phase transition point. Furthermore, we set the value for the imaginary time step to ∆τ = 0.25.
This choice on the one hand was small enough to avoid errors associated by the discretization of otherwise continuous
imaginary time scale τ, and on the other hand was large enough to avoid unphysical correlations between successive
imaginary-time measurements of the Green’s function G(τ). Since our calculations were performed at the inverse
temperatures β between 1 and 10, the corresponding number of imaginary time steps L = β∆τ was between 40 and
For a successful application of the HPIMC it is crucial to choose the proper value of the pseudo-time tp and the
size of its step ∆t in the molecular dynamic part of the simulation. Following Fahy and Hamman, we determined the
value of the critical value tc for each case under consideration and then took tp > tc to avoid running the simulation
in a non-ergodic regime. Typical values for tp were between 5 and 15 for double-well cases listed below. We stress
that there was not much diﬀerence in the quality of the HPIMC data if we chose tp > tc or chose tp = tc/2. In
addition, we obtained good data for the harmonic wells by choosing tp ∼1/ω0 even though for this particular case
tc = ∞. If we deﬁne ω0 as the smallest nonzero frequency of the system, optimal values of the step size ∆t are
between 0.05/ω0 and 0.1/ω0. Larger values of ∆t lead to larger errors in the pseudo-time propagation which then
lead to small acceptance ratios. Smaller values of ∆t lead to longer compution times. Unless speciﬁed otherwise, we
always chose m = mπ = γ = 1. We emphasize that the HPIMC method is insensitive of the choice of the mass mπ
associated with the ﬁctitious momentum πi,j.
In Fig. 2, we show the displacement-displacement Green’s function G(τ), for a single harmonic oscillator, obtained
by evaluating (16) for various values of ω0β, as a function of the imaginary-time variable τ. These curves look similar
to the Green’s functions that we obtained numerically for this and the other models: For some parameters and
temperatures, the G(τ) varies little as a function of τ; for others, it varies rapidly at the ends of the interval [0, β)
and is ﬂat in the middle with values nearly equal to zero; and for still other parameters, it has a featureless, parabolic
looking shape.
The common features of these curves have several signiﬁcant implications for the analytic continuation problem.
First, we remark that from the quantum Monte Carlo simulations we obtain estimates of G(τ) only at a relatively
small number of discrete values τi. The smoothness of the curves implies that the G(τi) at neighboring values of τi
are correlated. The computation of the covariance matrix in (36) is thus an important part of the of the analysis
of the data. While the correlations among the diﬀerent τ values of G(τ) make the interpretation of the assignment
of an “error-bar” to a given τ value delicate, such an assignment illustrates several diﬃculties inherent in the data
that help to make the analytic continuation of the data often very diﬃcult. In the case where G(τ) is nearly ﬂat, the
errors bars mean that a number of values of G(τ) are “within the error-bars” of each other. This situation, along
with the correlations implied by sizable oﬀ-diagonal elements of the covariance matrix, means that only a subset, and
often a small subset, of the measured values of G(τ) represent independent data useful for the analytic continuation
procedure. The analytic continuation near the classical limit can be very diﬃcult.
The situation with the rapid end-point variation and the ﬂat nearly zero values is another diﬃcult case. Again the
ﬂat region generates a lose of useful values of G(τ) and the smallness of G(τ) in this region can engender situations
where the error bars would imply that during the simulation estimates of G(τ), which must be non-negative, were
derived from ensemble values that included negative ones. The Monte Carlo algorithms in fact do not produce negative
values but do produce highly skewed ﬂuctuations about the mean. The Gaussian assumption for the likelihood function
in (42) thus can only be approached in the limits of a large number of independent measurements when the central
limit controls the data distribution. The ratio of the mean value to the estimated variance (signal to noise ratio) also
indicates that the most eﬀective data comes from those in the rapidly decreasing region. At low temperatures, the
analytic continuation problem can become very diﬃcult.
The details of the simulation algorithm can also impact the quality of the results and data. In Fig. 3, we show
G(τ)/G(0) as a function of τ obtained by two closely related simulation techniques for a single harmonic oscillator.
We remark that the scale of abscissa is 1/100 of that of Fig. 2 and the ordinate shows τ only in a narrow region at the
symmetry point β/2. The dashed curve is the analytic result obtained from (16). The data is represented by square
markers were obtained by the HPIMC method without the time-reversed step; the data represented by the circles
were obtained with the HPIMC method with the time-reversed step. In each case, the same number of Monte Carlo
steps were made. One sees that the ﬂuctuations with the HPIMC method without the time-reversed step are larger
and that the error bars associated with the results suggest a dip into non-negative values of G(τ). More signiﬁcantly,
the results deviate from the exact curve by more than one standard deviation in the immediate vicinity of τ = β/2.
The analytic continuation result for A(ω) from the data partially shown in Fig. 3 is shown in Fig. 4. From (17), the
spectral density should be 0.5δ(ω−1). The solid curve is obtained from the HPIMC algorithm and shows a broadened
delta-function at the right location with nearly the correct weight. The fraction of a per-cent diﬀerence from the
correct weight is most likely a consequence of the small error caused by discretizing the imaginary-time derivatives.
On the other hand, the dashed curve, which is obtained from the data obtained from the HIPMC algorithm without
the time-reversed step, is broader, located incorrectly, and has a larger discrepancy in its weight. The increased
breadth is a consequence of the larger variance in the measured data. The incorrect location and poorer weight is a
consequence of the small deviation from the exact value near τ = β/2, which in turn is a consequence of the Monte
Carlo algorithm performing badly.
In Fig. 5, with the data obtained from the HPIMC algorithm, we show the full analytic continuation form G(τ) to
GR(t). In Fig. 5a, the data (open circle) is compared with the exact results for G(τ) (solid line) obtained from (16).
In Fig. 5b, the dashed curve is the A(ω) obtained by the analytic continuation procedure, while the solid line is a
Lorentzian at the same location. The real part of G(ω) is shown in Fig. 5c, where the dashed line is the quantum
Monte Carlo results and the solid line is an analytic result obtained from the Lorentzian from Fig. 5c. The width η
of the Lorentzian shown in Fig. 5b was adjusted so the ω = 0 values of the two curves agreed. The single adjustment
produced remarkably good agreement at high frequencies. The principal diﬀerences between the two curves are at
ω = ±1 where divergences should exist as indicated by (18). Finally, GR(t) is shown in Fig. 5d. The solid line was
obtained analytically and used the Lorentzian of Fig. 5b, while the dashed line is the quantum Monte Carlo result.
The agreement between the results is satisfying and comparable in quality to that possible by real-time quantum
Monte Carlo methods. The width of the Lorentzian was 7/ω0, i.e., about 7 times the natural period of the harmonic
oscillator. This width is still controlled by the size of the variance in the measured values of G(τ).
For the case of the harmonic chain, we computed the Green’s function Gk(τ) for each independent wave number
and from it found the corresponding spectral density Ak(ω). As with the single oscillator, this function should be
a delta-function located at ωk and have a weight equal to Gk(0) = ⟨x2
k⟩. As in the single oscillator case, instead of
ﬁnding a delta-function, we found a Lorentzian-like peak at the correct location with the correct weight. The peaks
for diﬀerent values of k, however, had diﬀerent widths. In general, the peak widths increased with increasing k,
correlating with the increased variance associated with the Gk(τ). The spectral densities for the three lowest values of
k are shown in Fig. 6. The peak positions as a function of ω give the phonon dispersion relation. Our determination
of this relation is compared to the exact result in Fig. 7. The agreement is excellent. There is a diﬃculty that must
be mentioned. At k = 0 and ωk = 0, Gk(τ) is ﬂat and the weight of the peak approaches inﬁnity. For k = 0, not
surprisingly, we were unable to do the analytic continuation. This situation is why we considered the model deﬁned
by (4). Here, ωk at k = 0 is not zero and the determination of Ak(ω), and subsequently ωk, is possible for all values
of k. The dispersion relation found from the analytic continuation agrees very well with exact result.
For a single, double-well potential, the spectral density can give direct information about tunneling processes.
This situation is illustrated in Fig. 8 where the spectral densities for the Hamiltonian, described by (6), are shown
for several diﬀerent values of the parameter γ. It is straightforward to discretize Schroedinger’s time-independent
diﬀerential equation for this potential and ﬁnd the eigenvalues of the resulting eigenvalue equation. We adjusted the
model parameters so only a very few (usually one) of the lowest eigenstate lied below the barrier height, similar to the
situation depicted in Fig. 1a. (For deeper wells, our simulation methods would get stuck in one well or the other for
large numbers of Monte Carlo steps, and hence the algorithm eﬀectively lost ergodicity.) In the cases reported, the
temperatures of the simulations were also less than the separation between the two lowest lying pairs of eigenstates.
Thus, our spectral densities only exhibited the transition between these two states, and the position of the peak
gives a direct measure of the lowest frequency tunnel splitting. This position agreed very well with the exact value
calculated from Schroedinger’s equation. Additionally, the weight of the peak also agreed well with the sum rule (12).
For a chain of double-well potentials (7), still a diﬀerent situation presents itself. At zero temperature, depending on
the values of ǫ and γ, the system exists in either a broken symmetry phase, in which the mean-squared displacement is
non-zero, or in a symmetric phase, in which the mean-squared displacement is zero. The model has a quantum phase
transition. We found that simulation, if performed in the broken symmetry phase, stuck in one well or the other for
large numbers of Monte Carlo steps, making it diﬃcult to collect the amount of statistically independent information
to do the analytic continuation. In Fig. 9, we report the Ak(ω) for two simulations done in the symmetric phase. The
one in Fig. 9b is close to the zero-temperature phase boundary. As one moves closer to the T = 0 phase boundary by
increasing ǫ, the k = 0 peak moves towards ω = 0. This movement is a consequence of the decreasing probability for
tunneling between the two minima of the double-well potential as the barrier height is increased.
V. CONCLUDING REMARKS
We used methods of Bayesian statistical inference and the principle of maximum entropy to analytically continue
imaginary-time Green’s function generated in quantum Monte Carlo simulations to obtain the real-time displacementdisplacement Green’s functions. For test problems, we considered chains of harmonic and anharmonic oscillators whose
properties we simulated by a hybrid path-integral quantum Monte Carlo method (HPIMC). From the imaginarytime, displacement-displacement Green’s function, we ﬁrst obtained its spectral density. For harmonic oscillators,
we demonstrated that the peaks of this function were in the correct position and their area satisﬁed a sum rule.
Additionally, as a function of wavenumber, the peak positions followed the correct dispersion relation. For a doublewell oscillator, we demonstrated the peak location correctly predicted the tunnel splitting. Transforming the spectral
densities to real-time Green’s functions, we conclude that we can predict the real-time dynamics for length of times
corresponding to 5 to 10 times the natural period of the model. The length of time was limited by the simulation
algorithm and not directly by the analytic continuation procedure.
The simulation algorithm inﬂuences the results in at least two ways. One way is the ease with which statistically
independent, Gaussian-distributed data is obtained. In our experience, of the various quantum Monte Carlo methods
we have used, path-integral Monte Carlo methods (PIMC) tend to produce data with long-ranged correlations, thus
making statistical independence sometimes diﬃcult to achieve. Achieving statistical independence is important for
proper error estimation because of the sensitivity of ill-posed problems to errors in the data. With out statistical
indepence these error are usually underestimated. That the data is Gaussian-distributed is necessary to satisfy the
assumptions of the analytic continuation procedure. Currently, large amounts of data are used to force the simulation
data to have proper statistical properties. The method of binned averages , with many measurements in a bin, is
used to achieve statistical independence. The central limit theorem is used to obtain a Gaussian distribution of the
binned averages. Because of the low computational intensity necessary for the test cases considers, producing the
necessary large amounts of data was not problematic.
A second way the algorithm can inﬂuence the results is through broken ergodicity and unphysical results. Here, we
are referring to the ragged structure we saw in G(τ) with the hybrid method and to the small systematic diﬀerence
between the exact and computed results. We have not previously seen similar problems. Small modiﬁcations in
the simulation algorithm removed the problems but it was at ﬁrst diﬃcult to determine the source of the diﬃculty.
Because the purpose of the research was not algorithmic development, we did not do any comparisons of HPIMC
and other possible methods to determine relative eﬃciency and other merits. Again, the computation times for these
simulations is small (a few hours on a modest workstation) and so we were unmotivated to make such comparisons.
Other recently suggested approaches, e.g., , should be considered as part of further studies.
In general, we believe we have demonstrated that analytically continuing imaginary-time correlation functions,
obtained from a quantum Monte Carlo simulation, to obtain real-time correlation functions is a feasible alternative to
obtaining such real-time functions directly from a quantum Monte Carlo simulation done in real-time. One advantage
in choosing this approach appears to be the longer length of time over which the real-time information is faithful to
the correct result. Of course, this conclusion is based on one study of simple models; however, this study does strongly
indicate the direction for further and more extensive work.
ACKNOWLEDGMENTS
This work was supported by the U.S. Department of Energy. We thank J. Doll and G. Berman for helpful conversations.
Present Address: Joˇzef Stefan Institute, University of Ljubljana, 61111 Ljubljana, Slovenia.
 A brief review is given by B.J. Berne and D. Thirumalai, Ann. Rev. Chem. Phys. 47, 401 . More recent works
include: J.D. Doll, R.D. Coalson, and D.L. Freeman, J. Chem. Phys. 87, 1641 : J.D. Doll, D.L. Freeman, and T.L.
Beck, Adv. Chem. Phys. 78, 61 ; C.H. Mak and R. Egger, Phys. Rev. A, to appear; and references therein.
 J.E. Gubernatis, M. Jarrell, R.N. Silver, and D.S. Sivia, Phys. Rev. B 44, 6011 ; M. Jarrell and J.E. Gubernatis,
Phys. Reprt., to appear.
 Xidi Wang, D.K. Campbell, and J.E. Gubernatis, Phys. Rev. B 49, 15485 .
 G.D. Mahan, Many-Particle Physics .
 See for example, M. Creutz and B. Freedman, Ann. Phys. (N.Y.) 132, 427 .
 B.J. Berne and D. Thirumalai, Ann. Rev. Phys. Chem. 37, 401 .
 S. Duane, A.D. Kennedy, B.J. Pendleton, and D. Roweth, Phys. Lett. B 195, 216 .
 R.N. Neal, unpublished.
 S. Fahy and D.R. Hamann, Phys. Rev. Lett. 69, 761 .
 J. Skilling, in Maximum Entropy and Bayesian Methods edited by J. Skilling , p. 45.
 S.F. Gull, in Maximum Entropy and Bayesian Methods edited by J. Skilling , p. 53.
 R.K. Bryan, Eur. Biophys. J. 18, 165 .
 D.D. Frantz, D.L. Freeman, and J.D. Doll, J. Chem. Phys. 97, 5713 .
 Jianshu Cao and B.J. Berne, J. Chem. Phys. 92, 1980 .
Schematic representation of the energy levels in a harmonic and double-well potential.
FIG. 2. Green’s function G(τ) for a particle in a harmonic-well, obtained from the analytical form (21) potential, as a
function of imaginary-time τ and at diﬀerent values of βω0.
FIG. 3. Comparison of analytical results for the Green’s functions for a particle in an harmonic well (dashed curve) with
numerical results (open circles and squares) obtained using HPIMC method (a) with and (b) without the time-reversal step in
the molecular dynamic part of the algorithm.
FIG. 4. Comparison of the spectral functions obtained from the data shown in Fig. 3. As in Fig. 3, in we present spectral
functions extracted from HPIMC data (a) with and (b) without the time-reversal step. We also present G(0), the computed
area under the curves.
FIG. 5. Comparison of the Green’s function (a) and its spectral fruntions for a particle in a harmonic well obtained by
randomly changing the direction of the molecular dynamics time integration (open circles in (a) and full line in (b)) and by
not randomly changing he integration time direction (open circles in (a) and full line in (b)). Presented is only a small portion
of G(τ) around τ = β/2 where deviations from the analytic solution (dashed line in (a)) are enhanced. Also presented are the
sum rules. Analytically, G(τ = 0) = ⟨x2⟩= 0.500.
FIG. 6. Spectral functions for the harmonic chain at diﬀerent values of k. Arrows above spectral functions denote exact
positions of peaks. We also compare the numerically calculated sum-rules f with analytical values.
FIG. 7. Dispersion relation ωk for harmonic chain with m = 1 and γ = 1. Open circles correspond to discrete values of ωk
for a 10-site system.
FIG. 8. Spectral functions for a single double-well potential at diﬀerent values of γ and diﬀerent temperatures 1/β. Arrows
above spectral functions denote exact positions ω0 of peaks as obtained by numerical solution of the double-well potential.
We also compare sum-rules, calculated by integrating the spectral functions A(ω) over ω, with G(τ = 0) =< x2 >, obtained
directly from the QMC calculation. ν is the ratio 1/ηt0 where η was obtained by ﬁtting A(ω) to the analytical form G(ω), see
FIG. 9. Spectral functions A(ω) for a chain of 20 sites at two diﬀerent values of ǫ: (a) ǫ = 0.5 and (b) ǫ = 0.75. We present
the spectral functions for diﬀerent wavevectors k in units of 2π/20.
analytical
Nsweep=2000
Harmonic well
a) G(0)=0.496
b) G(0)=0.482
Harmonic well
Nsweep=2000
Harmonic well
Nsweep=2000
k=1, Gk(0)=0.0806, <x
k=2, Gk(0)=0.0420, <x
k=3, Gk(0)=0.0302, <x
Nsweep=2000
k=0, Gk(0)=0.0487, <x
k=1, Gk(0)=0.0423 ,<x
k=2, Gk(0)=0.0319, <x
k=3, Gk(0)=0.0256, <x
k=4, Gk(0)=0.0225, <x
Nsweep=2000
Double well, Ns=1
Nsweep=4000, Nbin=400-1000
m=4.0, ω0=0.20, G(0)=0.566, <x
2>=0.588, β=20
m=2.0, ω0=0.39, G(0)=0.602, <x
2>=0.606, β=15
m=1.0, ω0=0.72, G(0)=0.669, <x
2>=0.670, β=10
Double well
Nsweep=4000
Nbin =400-1000
k=0, Gk(0)=0.067, <xk
k=1, Gk(0)=0.051, <xk
k=2, Gk(0)=0.034, <xk
k=3, Gk(0)=0.025, <xk
k=4, Gk(0)=0.020, <xk
ε=0.5, m=1, γ=2
Nb=600, Nsweep=1000
k=0, Gk(0)=0.107, <xk
k=1, Gk(0)=0.0448, <xk
k=2, Gk(0)=0.0247, <xk
k=3, Gk(0)=0.0168, <xk
ε=0.75, m=γ=1
Nb=600, Nsweep=2000