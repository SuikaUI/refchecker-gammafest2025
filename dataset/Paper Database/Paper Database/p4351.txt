HAL Id: inria-00548511
 
Submitted on 20 Dec 2010
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of scientific research documents, whether they are published or not.
The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
Creating Eﬀicient Codebooks for Visual Recognition
Frédéric Jurie, Bill Triggs
To cite this version:
Frédéric Jurie, Bill Triggs.
Creating Eﬀicient Codebooks for Visual Recognition.
10th International Conference on Computer Vision (ICCV ’05), Oct 2005, Beijing, China.
pp.604 – 610,
￿10.1109/ICCV.2005.66￿. ￿inria-00548511￿
Creating Efﬁcient Codebooks for Visual Recognition
Frederic Jurie and Bill Triggs
GRAVIR-INRIA-CNRS, 655 Avenue de l’Europe, Montbonnot 38330, France
{Frederic.Jurie,Bill.Triggs}@inrialpes.fr, 
Visual codebook based quantization of robust appearance descriptors extracted from local image patches is an
effective means of capturing image statistics for texture
analysis and scene classiﬁcation. Codebooks are usually
constructed by using a method such as k-means to cluster
the descriptor vectors of patches sampled either densely
(‘textons’) or sparsely (‘bags of features’ based on keypoints or salience measures) from a set of training images.
This works well for texture analysis in homogeneous images, but the images that arise in natural object recognition tasks have far less uniform statistics. We show that
for dense sampling, k-means over-adapts to this, clustering
centres almost exclusively around the densest few regions
in descriptor space and thus failing to code other informative regions. This gives suboptimal codes that are no better
than using randomly selected centres. We describe a scalable acceptance-radius based clusterer that generates better codebooks and study its performance on several image
classiﬁcation tasks. We also show that dense representations outperform equivalent keypoint based ones on these
tasks and that SVM or Mutual Information based feature
selection starting from a dense codebook further improves
the performance.
1. Introduction
Representations based on loose collections of invariant appearance descriptors extracted from local image patches
have become very popular for texture analysis and visual
recognition . They
are ﬂexible and relatively easy to construct, they capture a
signiﬁcant proportion of the complex statistics of real images and visual classes in a convenient local form, and they
have good resistance to occlusions, geometric deformations
and illumination variations. In particular, the statistics of
This work was partially supported by the EU network PASCAL and the
French ACI grant MOVISTAR. It beneﬁted from discussions with several
members of our team including A. Agarwal, G. Dork´o, D. Larlus, B. Ninassi, E. Nowak and J. Zhang.
Figure 1: Top: sample images from four categories of the
‘Xerox 7’ dataset. Bottom: the image regions assigned to
the 100 codewords with maximal inter-category discrimination in this dataset. The codewords represent meaningful
object parts, even though they were learned without using
the category labels.
natural image classes can be encoded by vector quantizing
the appearance space and accumulating histograms or signatures of patch appearances based on this coding. Traditionally one codes a dense set of patches (‘texton’ representation) , but sparser sets based on keypoints or ‘points
of interest’ detected by invariant local feature detectors have
generated a lot of interest recently . Keypoints potentially provide greater invariance and more compact coding, but they were not designed to select the most
informative regions for classiﬁcation and, as we will show
below, dense sampling followed by explicit discriminative
feature selection gives signiﬁcantly better results.
Both sparse and dense codebooks are typically created
from a set of training images using a standard clustering
algorithm such as k-means. This works well for texture
analysis on images containing only a few homogeneous regions, and adequately for keypoint based representations in
general, but we will show that it is suboptimal for recognition using dense patches from natural scenes. The wide
range of region sizes in such scenes leads to a highly nonuniform, power-law-like sample distribution in descriptor
This leads k-means to choose suboptimal codebooks in which most of the centers cluster near high density regions , thus under-representing equally discriminant low-to-medium density ones. §3 describes our
method for allocating centers more uniformly, inspired by
mean shift and on-line facility location .
Finally, most current methods for learning codebooks are
generative – they capture overall image statistics but not
necessarily the ﬁne distinctions needed to discriminate between classes. This can be palliated by generating a large
codebook and selecting a discriminant subset of ‘parts’ (informative classes of patches) from it – see ﬁg. 1 and §4.4.
The selected parts tend to have intermediate probabilities,
allowing many rare parts to be discarded while still preserving a fairly sparse and hence compact representation.
A codebook algorithm contains three components: the
patch selector, the appearance descriptor, and the quantization algorithm. This paper focuses on the ﬁrst and last.
Appearance is represented simply as vectors of raw pixel intensities compared using ZNCC, but other vector valued appearance descriptors can be used and informal experiments
with SIFT descriptors gave similar results.
There are indications that despite their good matching
performance, existing keypoint detectors (F¨orstner, Harrisafﬁne, etc.) often fail to detect the most informative patches
for image classiﬁcation . Another strategy is to select
patches by testing many potential templates and selecting
the ones that maximize an informativeness score such as
mutual information . We will do this, densely sampling patches at all image scales, quantizing, then selecting
the most informative centres using a separate feature selection algorithm.
1.1. Previous Work
By ‘textons’ (c.f. ) we mean a set of representative
classes of image patches that sufﬁce to characterize an image object or texture. Such textons are typically extracted
densely, representing small and relatively generic image
micro-structures – blobs, bars, corners, etc.
When larger, more semantically meaningful structures are
wanted, sparse sampling is typically used. For example,
Weber et al. learn a generative model for face recognition from a set of training images by detecting F¨orstner keypoints at a single scale and quantizing the selected (small)
raw image patches using k-means.
Similarly, Leung et
al. use Gabor texture features for texture classiﬁcation.
Recently, several groups (e.g. ) have proposed
‘bag of features’ methods based on normalized patches or
SIFT descriptors over Difference of Gaussian, Harrisscale or Harris-afﬁne keypoints , vector quantized using k-means. Leibe et al. proposed a similar method
based on a codebook learned by agglomeratively clustering
raw pixel intensity vectors of Harris keypoints. Agarwal et
al. adopted a similar approach incorporating spatial relations between parts.
2. Local Appearance Statistics
To avoid the suboptimal choices made by keypoint detectors, we base our representation on densely sampled
The inter-class discrimination provided by kmeans codebooks is highly dependent on the sample distribution in descriptor space, degrading as this becomes more
nonuniform. K-means works well for images containing
only uniform texture patches, and tolerably well for keypoint based descriptors in more general images, although
the distribution is already quite nonuniform in this case. But
with densely sampled descriptor sets in general images, the
distribution becomes so nonuniform that k-means devotes
most of its centres to the immediate neighborhood of the
central peak, and the coding suffers. The nonuniformity
is essentially due to two effects: (i) certain patches (uniform regions, step edges, etc.) occur far more frequently
than others (faces, stop signs); and (ii) the amount of any
given texture that appears is extremely variable owing to
the multiscale region structure of natural scenes (the statistics of this is captured quite well by “dead leaves” –
sets of opaque, homogeneous patches occurring randomly
at all positions and scales – and similar fractal models). Kmeans centres drift towards high density regions owing to
the ‘mean shift like’ k-means update rule. Asymptotically,
they are distributed according to the underlying density, i.e.
in the same way as random samples.
This point is critical because the patches that are most
informative for classiﬁcation tend to have intermediate frequencies. Over-frequent patches typically contain generic
image structures like edges that occur often in all classes,
giving little discriminant information.
Conversely, rare
patches may be highly discriminant when they occur, but
they occur so seldom that they have little inﬂuence on overall performance. These effects are probably even greater in
man-made environments, where large uniform uninformative regions are common.
To illustrate the non-uniformity, we use our (below)
clustering algorithm to analyze the probability density of
variance-normalized patches from natural images. These
are 11×11 gray level patches, sampled densely from multiscale pyramids with 10 layers spaced by 2
4 in scale. Other
patch sizes from 6×6 to 20×20 give very similar results.
For now, the only important properties of our clusterer are
that it chooses the densest regions ﬁrst and ﬁlls them with
uniformly-sized balls. Hence, any nonuniformity in the resulting texton counts is direct evidence of nonuniformity at
the scale of the balls in the underlying distribution.
We have run several experiments using different image
collections: one containing 500 natural images of width
300–800 pixels, and several others that include more speciﬁc objects (see §4 for details).
Fig. 2 (left) shows the
statistics for two of these image sets.
The bin densities
roughly follow a power law (exponent ≈−1.6) – c.f. Zipf’s
Bin Probability
Bin Probability
Figure 2: Log-log plots of the local density of image features for the most probable 800 bins, for densely sampled
patches (left) and for keypoint based patches (right). The
distribution is markedly more peaked for dense patches than
for keypoints.
law from textual word frequency analysis . The law
persists over a wide range of natural image types and bin
probabilities, ﬂattening out to equiprobability only for very
rare centers. In contrast, as shown in ﬁg. 2 (right), the corresponding distribution for patches selected using a keypoint
detector (here, Lowe’s ) is much more uniform, with
most of the bins having comparatively similar probabilities
and only a few being rare.
3. Clustering Algorithm
Existing Methods:
Before describing our clustering algorithm, we give a brief review of vector quantization methods for large sets of vectors in high dimensional spaces. In
our case the feature dimension is in the hundreds (121 for
11×11 patches) so quantization based on a uniform grid of
centers is infeasible and clustering is the preferred method
for ﬁnding the centers. With densely sampled patches the
number of samples to be clustered can be more than 108 for
medium-sized datasets.
Feature spaces are typically designed to capture perceptually meaningful distinctions while providing good resistance to extraneous details such as changes in illumination.
In a well-chosen representation, distances in feature space
thus tend to coincide roughly with distinguishability with
respect to such perceptual “noise”. This implies that a perceptually efﬁcient coding should have roughly uniform cell
sizes, or at least enforce a lower bound on the cell size: it is
wasteful to code dense regions more ﬁnely than the underlying “noise” level.
Owing to its simplicity, k-means is a popular algorithm
for perceptual coding. Unfortunately it has the defect that
cluster centers are drawn irresistibly towards denser regions
of the sample distribution by the ‘mean shift’ like process
that is used to update them, with the result that they tend to
be tightly clustered near dense regions and sparsely spread
in sparse ones. This effect is especially pronounced in high
dimensions where it is infeasible to tile the region of the
peak densely with cells. The typical result is a cluster of
centers surrounding the peak, with Voronoi cells that extend
radially outwards for a signiﬁcant distance, each including
a few more distant points. This gives a perceptually very
nonuniform coding. K-means has other drawbacks. It is
non-robust – points lying far from any of the centers can
signiﬁcantly distort the position of the centre that they are
assigned to – and the number of centers must be known in
advance, whereas the overall goal is to code an unknown
number of “distinguishable parts”.
Several authors have used agglomerative clustering for
the centre allocation problem . The proposed methods are rather inefﬁcient but there are interesting alternatives such as the on-line facility location algorithm .
These approaches handle the unbalanced density problem
well, but they can not be applied to large datasets owing to
their high algorithmic complexity. Mean shift has been used
in a similar context , but it can not be used directly with
natural images because informative parts seldom coincide
with well-separated density modes.
Several studies of clustering for large data sets have appeared in the data mining literature. Such methods typically
use some form of subsampling for speed . In practice,
subsampling based methods have trouble with unbalanced
densities, especially if uniform subsampling is used .
Like k-means, they tend to allocate most of their centres to
a few dense regions thus ‘starving’ lower density ones. Proposed solutions include different forms of resampling such
as random oversampling, random undersampling, and importance weighting methods that adjust the cost of the various regions to counter the imbalance .
Our algorithm: Our proposed strategy combines the advantages of on-line clustering and mean-shift in
an undersampling framework . The algorithm produces
an ordered list of centers, with the quantization rule that
patches are assigned to the ﬁrst centre in the list that lies
within a ﬁxed radius r of them, or left unlabeled if there is
no such centre.
The parameters of the algorithm are the number of subsamples N, the cell radius r and the mean shift radius h
(which we always set to r). Centers are created one by
one in list order. For each entry, the centre is set when it
is added to the list and never changed after that. At each
step, we draw N patches uniformly and randomly from the
currently unlabeled part of the data set, compute their maximal density region by running a mean-shift estimator 
with a Gaussian kernel of width h on them, allocate a new
centre at the maximal density position, and (notionally – in
practice this is done lazily) sweep the dataset, labeling and
eliminating all of the patches that are assigned to this centre. Eliminating the labeled patches prevents the algorithm
from repeatedly assigning centers to the same high density
region. As we are mainly interested in coding regions of intermediate probability, the algorithm can either be stopped
Figure 3: The 100 most frequent codewords produced by
quantizing the Agarwal et al. dataset. The parameters
of the algorithm were N=1000 and h=r=0.8 (which gives
clusters with a fairly loose set of appearances).
by monitoring the informativeness of the clusters created
(see §4), or simply run until a “sufﬁciently large” number
of clusters has been found.
The computational complexity is governed mainly by the
cost of the mean shift iterations, which in practice (given
the high dimension) need to be initialized at each of the N
sample centers in turn to ensure reliable mode-ﬁnding. This
quadratic cost is acceptable because it is applied to only to
a small (N element) subset of the available patches. Finding and eliminating the labeled patches is at worst linear in
the number of training samples, times the average number
of centers that need to be tested before elimination. In practice, the centers are found in roughly decreasing order of
frequency, so the average number of centres tested is effectively independent of the total number of centres in the list
(although it does depend strongly on r). In the experiments
below, the average number of centers tested per vector is
generally less than 9 for codebooks of several thousand centers. As an illustration, ﬁg. 3 shows the ﬁrst 100 codewords
for the Agarwal-Roth set of side views of cars.
4. Categorization and Object Detection
We demonstrate the performance of our codebooks with experiments on object recognition and image categorization.
For simplicity we formulate categorization as supervised
learning over a ‘bag of features’ representation .
Despite the fact that they capture only local statistics and ignore geometric relationships, bags of features perform surprisingly well. Here they provide a convenient baseline for
comparing the performance of different codebooks, without
the complexities inherent in strategies that incorporate more
We compared two linear classiﬁers: simple Naive Bayes
and linear Support Vector Machines. SVM’s are known to
produce reliable results in high-dimensional problems, and
here they easily outperform Naive Bayes in all of the tests
performed – see ﬁg 6.
We tested two ways of producing feature vectors from
codebook based labelings: binary indicator vectors and his-
Figure 4: Three images from each class of the ‘Xerox 7’
dataset : faces, buildings, trees, cars, phones, bikes and
books. Intra-class variability makes the categorization problem quite challenging.
tograms. In the histogram representation, the feature vector
is just the normalized (scaled to total sum 1) histogram of
occurrence counts for the different codewords. For indicator vectors, each codeword’s feature is 1 if a patch with the
codeword occurs in the image and 0 otherwise . In fact,
rather than using simple presence/absence, we threshold the
number of occurrences of the codeword in the image to produce the binary vector. The thresholds are selected automatically to maximize the mutual information (MI) between the
thresholded codeword frequency and the class.
The size of the codebooks is potentially very large so
there may be overﬁtting (too many “noise” features for good
classiﬁcation). To show how the approach behaves when
only a restricted subset of the vocabulary is used, we report on three different feature selection methods: maximization of mutual information (MI) , and of odds
ratio (OR) , and training an initial linear SVM classiﬁer
on the full feature set and retaining only the features that
have the highest weights (SVM) . Information Gain
was also tested but performed less well than MI.
The number of possible combinations of descriptor
types, codebooks, feature selectors and classiﬁers is quite
large, so only the most relevant combinations were tested.
4.1. Data sets
We tested on three data sets. The ﬁrst, side views of cars
from Agarwal & Roth , was designed to evaluate object
detection algorithms. Performance is measured by precision/recall as suggested in .
The second, ‘Xerox 7’ , contains 1776 images from
seven categories. Fig. 4 shows some examples. The object
poses are highly variable and there is a signiﬁcant amount
of background clutter, some of which belongs to the other
categories (notably buildings, trees and cars), making the
classiﬁcation task fairly challenging. We report the confusion matrix and the overall error rate under 10-fold crossvalidation with a standardized set of folds.
The last dataset contains 4 classes from the ETH80
database : models of cars, horses, dogs and cows. At
the individual patch level, the horses, dogs and cows have
1−precision
Dense sampling, Our Clustering method
Dense sampling, k−means Clustering
Keypoints sampling, k−means clustering
Figure 5: MI based feature selection on the Agarwal-Roth
car data set. Top: the 100 best codewords for dense codebooks based on our clusterer (left) and k-means (middle),
and a keypoint codebook based on k-means (right). Note
the relative lack of diversity in the dense k-means codebook.
Bottom: the Precision-Recall curves for these codebooks,
using a linear SVM classiﬁer over 600 features selected using MI. Our dense approach performs best.
rather similar appearances. There is no background, and
hence neither visual context to help, nor clutter to hinder,
the classiﬁcation. We report overall classiﬁcation error rates
under 10-fold cross-validation.
4.2. Dense versus Sparse Codebooks
The ﬁrst experiment uses the Agarwal & Roth test set .
The problem is to detect the objects (car sides) and return
their image locations. There are 500 positive and 500 negative 100×400 pixel training images at 10 scale levels from
100×400 to 17×70. Some positive images are shown in
ﬁg. 3 (left). We report results for three 2500-centre codebooks based on both positive and negative images from the
training set: one built by densely sampling patches and using our clustering method; one built using dense patches
and k-means; and one built with k-means using keypoints
detected by Lowe’s DoG detector . In each case we select the 600 best codewords by maximizing the mutual information between optimally thresholded codeword occurrence counts and categories, and use a linear SVM classiﬁer
with 10-fold cross validation. Fig. 5 shows the Precision-
Recall curves. The proposed method clearly outperforms
the k-means based dense one, which in turn outperforms
the keypoint based one. Further experiments with different classiﬁers and codebook sizes conﬁrmed these relative
performances. Comparisons of our method with agglomerative, k-means and on-line k-means clusterers on several
other datasets in the sparse case gave similar results.
We also ran similar experiments on the ETH80 dataset.
Fig. 6 (top left) shows the overall error for various numbers of centers, selection methods and classiﬁers. For every combination of feature selector and classiﬁer tested, our
clustering method produced the best codebook.
One major determinant of classiﬁer performance is the
number of image patches used to compute the test image
histogram. Fig. 6 (top centre) shows the overall misclassiﬁcation rate for the ‘Xerox 7’ dataset as a function of
this number, for randomly sampled and keypoint based test
patches and using a ﬁxed codebook built using our dense
approach. Randomly selected patches perform at least as
well as keypoint based ones and in both cases performance
increases substantially as more patches are sampled, asymptotically reaching that of the dense method (the last ‘random’ point). Similar results appear to hold for keypoint
based codebooks.
There are two main conclusions: (i) adopting a sparse,
keypoint based image representation instead of a densely
sampled one often leads to a signiﬁcant loss of discriminative power; (ii) with dense sampling, k-means produces
poor codebooks – it is better to use more evenly distributed
coding centres, e.g. based on an algorithm that enforces
ﬁxed-radius clusters.
4.3. Histogram Encoding
We evaluated two methods of converting raw codeword occurrence counts to classiﬁcation features: normalized histograms (normalizing the sum of the counts to one) and binary feature vectors (thresholding each count at the value
that optimizes the MI w.r.t. the class labels on the training set, and coding the result as a binary vector). In each
case the dimension of the descriptor vector is the number of
codewords after feature selection. Histograms performed
better for the Agarwal-Roth and Xerox 7 datasets – see
ﬁg. 6 (top right, bottom left & centre) – but the differences
are small.
Hoping to reduce the effects of the very non-uniform distribution of occurrence counts, we also tested feature vectors produced by ranking the codeword counts and using
1/(1 + rank) as a codeword feature, but the results were
similar to or worse than those of standard histograms. Histogram features thus seem to be a reasonable choice for
codebook based visual detection and categorization.
4.4. Feature Selection and Informativeness
When constructing codebooks for visual learning, it is important to include codewords in regions with intermediate occurrence probabilities. These codewords are not the
ﬁrst ones to be produced by our algorithm, so the initial
codebook will generally be larger than the ﬁnal number of
useful features, and subsequent feature selection is advis-
Number of centers
Overall Error Rate
Dense Codebook/ MI F.S. / Naive Bayes Classifier
Dense Codebook/ MI F.S. / Linear SVM Classifier
Dense Codebook / Linear SVM F.S. / Naive Bayes Classifier
Dense Codebook / Linear SVM F.S. / Linear SVM Classifier
Keypoints Codebook/ MI F.S. / Naive Bayes Classifier
Keypoints Codebook/ MI F. S. / Linear SVM Classifier
Keypoints Codebook / Linear SVM F.S. / Naive Bayes Classifier
Keypoints Codebook / Linear SVM F.S. / Linear SVM Classifier
Average number of points per image
Overall misclassification Rate
Random detection
Key−point detection
Number of centers
Overall Error Rate
Histogram Features: MI F.S. / Naive Bayes Classifier
Histogram Features: MI F.S. / Linear SVM Classifier
Histogram Features: Linear SVM F.S. / Naive Bayes Classifier
Histogram Features: Linear SVM F.S. / Linear SVM Classifier
Binary Features: MI F.S. / Naive Bayes Classifier
Binary Features: MI F.S. / Linear SVM Classifier
Binary Features: Linear SVM F.S. / Naive Bayes Classifier
Binary Features: Linear SVM F.S. / Linear SVM Classifier
Number of centers
Recall at Equal Error Rate
Features: histograms / Feature Selection: MI
Features: binary / Feature Selection: MI
Features: histograms / Feature Selection: LSVM
Features: binary / Feature Selection : LSVM
Features: histograms / Feature Selection : OR
Features: binary / Feature Selection : OR
Number of centers
Recall at Equal Error Rate
Features: histograms / F.S.: MI
Features: binary / F.S.: MI
Features: histograms / F.S.: LSVM
Features: binary / F.S.: LSVM
Features: histograms / F.S.: OR
Features: binary / F.S.: OR
1−precision
50 centers,Dense Online Clustering, LSVM F.S., LSVM Classiﬁer
100 centers,Dense Online Clustering, LSVM F.S., LSVM Classiﬁer
270 centers,Dense Online Clustering, LSVM F.S., LSVM Classiﬁer
3000 centers,Dense Online Clustering, LSVM F.S., LSVM Classiﬁer
Best results obtained by Agarwal et al. (270 centers +rel. features)
Figure 6: Top left: ETH80 dataset. For all feature selectors and classiﬁers tested, our dense codebook outperforms keypointbased k-means. Top centre: Classiﬁcation performance depends critically on the number of patches sampled from the test
image. Keypoint based patches do no better than random or sparse grid sampling. This is with our dense codebook on the
Xerox 7 dataset, but similar results appear to hold for keypoint based codebooks. Top right: Our dense method on the Xerox
7 dataset. The linear SVM classiﬁer over histogram features has the lowest error rate, with either MI (for many centres) or
LSVM (for few centres) feature selection. Bottom left & centre: Car detection on the Agarwal-Roth data set using our dense
codebooks. Naive Bayes (left) and linear SVM (centre) classiﬁers. LSVM feature selection with either histogram or binary
based coding performs best. Bottom right: Our approach outperforms that of Agarwal et al., even though it does not code
spatial relations between features.
able. We studied three feature selection methods: mutual
information (MI), odds ratio (OR) and linear SVM weights
(LSVM). When there were more than two classes, the OR
and LSVM criteria were calculated by averaging the corresponding two-class criteria over the possible one-against-all
subproblems. Using the maximum value over the subproblems instead gave similar or slightly worse results.
LSVM selection topped most of our experiments (see
ﬁg. 6 top left, bottom left & centre), but on Xerox 7 MI was
preferred (ﬁg. 6 top right). However, note that the full codebooks generally outperformed any of the reduced ones, so
feature selection should only be used if the computational
cost of the algorithm needs to be reduced. Fig. 1 shows the
parts corresponding to the top 100 MI codewords for a few
images of the Xerox 7 dataset.
4.5. Comparing absolute performances
The high quality of our codebooks allows simple recognition schemes to outperform more complex ones based on
other codebooks. Fig. 6 (bottom right) compares our system’s precision/recall to that of Agarwal et al. .
Label \ True Faces Bldgs Trees Cars Phones Bikes Books
Figure 7: The confusion matrix for our method on Xerox7.
use (we believe) the same experimental and precision/recall
protocol as . Our precision at equal rate error is more
than 10% higher than the best results of , despite the fact
that we rely on a simple linear SVM classiﬁer and incorporate no inter-patch geometry (whereas uses spatial relations between pairs of features).
On the Xerox 7 dataset, the best results were obtained
with our codebooks and a linear SVM. Fig. 7 shows the confusion matrix for this conﬁguration, using 600 codewords.
Our overall error rate is 4.8% with standard deviation 1.2%,
whereas the (k-means and sparse feature based, but otherwise comparable) method of has an error rate of 15%.
5. Summary and Conclusions
We have presented a simple but effective algorithm for
building codebooks for visual recognition.
The method
is based on two key observations: (i) restricting attention
to patches based at sparse keypoints often loses a signiﬁcant amount of discriminant information, so densely sampled patches should be coded; and (ii) for densely sampled patches, descriptors are distributed very nonuniformly
in descriptor space, which leads k-means-like clusterers to
concentrate most of their centers in high density regions,
thus ‘starving’ medium density ones and leading to poor
codebooks. As an alternative, we described a simple ﬁxedradius clusterer based on mean shift, that scales well to large
datasets and whose codebooks signiﬁcantly outperform kmeans based ones. The approach was validated on several
‘bag-of-features’ based object detection and image classi-
ﬁcation tasks, showing results that are clearly superior to
other state-of-the-art approaches.
Future work: We are currently consolidating our results
on dense versus keypoint methods and evaluating our approach on SIFT descriptors rather than normalized patches.
We also hope to integrate discriminative information into
the centre selection process so that it directly selects discriminant features.