Relation-Shape Convolutional Neural Network for Point Cloud Analysis
Yongcheng Liu†‡
Shiming Xiang†‡
Chunhong Pan†
†National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences
‡School of Artiﬁcial Intelligence, University of Chinese Academy of Sciences
Email: {yongcheng.liu, bfan, smxiang, chpan}@nlpr.ia.ac.cn
Point cloud analysis is very challenging, as the shape
implied in irregular points is difﬁcult to capture.
this paper, we propose RS-CNN, namely, Relation-Shape
Convolutional Neural Network, which extends regular grid
CNN to irregular conﬁguration for point cloud analysis.
The key to RS-CNN is learning from relation, i.e., the geometric topology constraint among points. Speciﬁcally, the
convolutional weight for local point set is forced to learn
a high-level relation expression from predeﬁned geometric
priors, between a sampled point from this point set and the
others. In this way, an inductive local representation with
explicit reasoning about the spatial layout of points can be
obtained, which leads to much shape awareness and robustness. With this convolution as a basic operator, RS-CNN,
a hierarchical architecture can be developed to achieve
contextual shape-aware learning for point cloud analysis.
Extensive experiments on challenging benchmarks across
three tasks verify RS-CNN achieves the state of the arts.
1. Introduction
Recently, the analysis of 3D point cloud has drawn a lot
of attention, as it has many applications such as autonomous
driving and robot manipulation. However, this task is very
challenging, since it is difﬁcult to infer the underlying shape
formed by these irregular points (see Fig. 1 for detail).
For this issue, much effort is focused on replicating the
remarkable success of convolutional neural network (CNN)
on regular grid data (e.g., image) analysis , to irregular point cloud processing . Some
works transform point cloud to regular voxels or
multi-view images for easy application of classic grid CNN. These transformations, however, usually lead
to much loss of inherent geometric information in 3D point
cloud, as well as high complexity.
To directly process point cloud, PointNet independently learns on each point and gathers the ﬁnal features
∗Corresponding author: Bin Fan
Figure 1. Left part: Point cloud. Right part: Underlying shape
formed by this point cloud.
for a global representation. Though impressive, this design ignores local structures that have been proven to be
important for abstracting high-level visual concepts in image CNN . To solve this problem, some works partition point cloud into several subsets by sampling or
superpoint . Then a hierarchy is built to learn contextual representation from local to global. Nevertheless, this
extremely relies on effective inductive learning of local subsets, which is quite intractable to achieve.
Generally, there are mainly three challenges for learning
from point set P ⊂R3: (1) P is unordered, thus requiring the learned representation being permutation invariant;
(2) P distributes in 3D geometric space, thus demanding
the learned representation being robust to rigid transformation (e.g., rotation and translation); (3) P forms an underlying shape, therefore, the learned representation should be of
discriminative shape awareness. The issue (1) has been well
resolved by symmetric function , while (2) and
(3) still demand for a full exploration. The goal of this work
is to extend regular grid CNN to irregular conﬁguration for
handling these issues together.
To this end, we propose a relation-shape convolutional
neural network (aliased as RS-CNN). The key to RS-CNN
is learning from relation, i.e., the geometric topology constraint among points, which in our view can encode meaningful shape information in 3D point cloud.
Speciﬁcally, each local convolutional neighborhood is
constructed by taking a sampled point x as the centroid and
 
the surrounding points as its neighbors N(x). Then, the
convolutional weight is forced to learn a high-level relation
expression from predeﬁned geometric priors, i.e., intuitive
low-level relation between x and N(x). By convoluting in
this way, an inductive representation with explicit reasoning about the spatial layout of points can be obtained. It
discriminatively reﬂects the underlying shape that irregular
points form thus is shape-aware. Furthermore, it can bene-
ﬁt from geometric priors, including the invariance to points
permutation and the robustness to rigid transformation (e.g.,
translation and rotation). With this convolution as a basic operator, a hierarchical CNN-like architecture, i.e., RS-
CNN, can be developed to achieve contextual shape-aware
learning for point cloud analysis.
The key contributions are highlighted as follows:
• A novel learn-from-relation convolution operator
called relation-shape convolution is proposed. It can
explicitly encode geometric relation of points, thus resulting in much shape awareness and robustness;
• A deep hierarchy equipped with the relation-shape
convolution, i.e., RS-CNN, is proposed. It can extend
regular grid CNN to irregular conﬁguration for achieving contextual shape-aware learning of point cloud;
• Extensive experiments on challenging benchmarks
across three tasks, as well as thorough empirical and
theoretical analysis, demonstrate RS-CNN achieves
the state of the arts.
2. Related Work
View-based and volumetric methods. View-based methods represent a 3D shape as a group of 2D views from different angles. Recently, many works 
have been proposed to recognize these view images with
deep neural networks. They often ﬁnetune a pre-trained
image-based architecture for accurate recognition. However, 2D projections could cause loss of shape information
due to self-occlusions, and it often demands a huge number
of views for decent performance.
Volumetric methods convert the input 3D shape into
a regular 3D grid, over which classic CNN can be employed . The main limitation is the quantization
loss of the shape due to the low resolution enforced by 3D
grid. Recent space partition methods like K-d trees or
octrees rescue some resolution issues but still
rely on the subdivision of a bounding volume rather than
a local geometric shape. In contrast to these methods, our
work aims to process 3D point cloud directly.
Deep learning on point cloud. PointNet pioneers this
route by independently learning on each point and gathering
the ﬁnal features with max pooling. Yet this design neglects
local structures, which have been proven important for the
success of CNN. To remedy this, PointNet++ suggests
a hierarchical application of PointNet to multiple subsets of
point cloud. Local structure exploitation with PointNet is
also investigated in . In addition, Superpoint is
proposed to partition point cloud into geometric elements.
Graph convolution network is applied on a local graph created by neighboring points . However, these
methods do not explicitly model the local spatial layout of
points, thus acquiring less shape awareness. By contrast,
our work captures the spatial layout of points by learning a
high-level relation expression among points.
Some works map point cloud to a high-dimensional
space to facilitate the application of classic CNN. SPLAT-
Net maps the input points onto a sparse lattice, then
processing with bilateral convolution . PCNN extends the function over point cloud to a continuous volumetric function over ambient space. These methods could
cause loss of geometric information, while our method directly operates on point cloud without introducing such loss.
Another key issue is the irregularity of points. Some
works focus on analyzing symmetric functions that are
equivariant to point sets learning . Some
other works develop alignment network for the
robustness to rigid transformation in 3D space. However,
the alignment learning is a suboptimal solution for this issue. Some traditional descriptors like Fast Point Feature
Histograms can be invariant to translation and rotation, yet
they are often less effective for high-level shape understanding. Our method that learns on geometric relation among
points is naturally robust to rigid transformation, whilst being highly effective due to the powerfulness of deep nets.
Relation learning. To learn a data-dependent weight from
relation has been explored in the ﬁeld of image and video
analysis. Spatial transformer learns a transition matrix
to align 2D images. Non-local network learns longterm relation across video frames. Relation networks 
learn position relation across objects. DFN proposes
general dynamic ﬁlters that inspire many subsequent works.
There are also some works focusing on the relation learning in 3D point cloud. DGCNN captures similar local shapes by learning point relation in a high-dimensional
feature space, yet this relation could be unreliable in some
cases. Wang et al. propose a parametric continuous
convolution that is based on computable relation among
points, but they do not explicitly learn from local to global
like classic CNN. By contrast, our method learns a highlevel relation expression from geometric priors in 3D space,
and performs contextual local-to-global shape learning.
3. Shape-Aware Representation Learning
The core of point cloud analysis is to discriminatively
represent the underlying shape with robustness. Here we
learn contextual shape-aware representation for this goal,
by extending regular grid CNN to irregular conﬁguration
with a novel relation-shape convolution (RS-Conv).
learn from relation
shared MLP
Relation-Shape Convolution
shape-aware
representation
shared MLP
shared MLP
equal channels
shared MLP
channel-raising mapping
Figure 2. Overview of relation-shape convolution (RS-Conv). The key is to learn from relation. Speciﬁcally, the convolutional weight for
xj is converted to wij, which learns a mapping M (Eq. (2)) on predeﬁned geometric relation vector hij. In this way, the inductive convolutional representation σ
 A({wij · f xj, ∀xj})
(Eq. (3)) can expressively reason the spatial layout of points, resulting in discriminative
shape awareness. As in image CNN , further channel-raising mapping is conducted for a more powerful shape-aware representation.
3.1. Relation-Shape Convolution
Local-to-global learning, which has gained remarkable
success in image CNN , is a promising solution for
contextual shape representation. However, it extremely relies on shape-aware inductive learning from irregular point
subsets, which remains a quite intractable problem.
Modeling. To overcome this issue, we model local point
subset Psub ⊂R3 to be a spherical neighborhood, with a
sampled point xi as the centroid and surrounding points as
its neighbors xj ∈N(xi). The left-most part of Fig. 2 illustrates this modeling. Then, our goal is to learn an inductive
representation f Psub of this neighborhood, which should discriminatively encode the underlying shape information. To
this end, we formulate a general convolutional operation as
f Psub = σ
 A({T (f xj), ∀xj})
1, dij < r ∀xj ∈N(xi),
where x is a 3D point and f is a feature vector. dij is the
Euclidean distance between xi and xj, and r is the sphere
radius. Here f Psub is obtained by ﬁrst transforming the features of all the points in N(xi) with function T , and then
aggregating them with function A followed by a nonlinear
activator σ. In this formulation, the two functions A and T
are the key to f Psub. That is, the permutation invariance of
point set can be achieved only when A is symmetric (e.g.,
summation) and T is shared over each point in N(xi).
Limitations of classic CNN. In classic CNN, T is implemented as T (f xj) = wj · f xj, where wj is learnable
weight and “·” denotes element-wise multiplication. There
are mainly two limitations of this convolution when applied on point cloud: 1) wj is not shared over each point
in N(xi), resulting in variance to point permutation and incapability to process irregular Psub (e.g., different number);
2) the gradient of wj in backpropagation is only relevant to
the isolated point xj, leading to an implicit learning strategy, which could not bring much shape awareness and ro-
1In this paper, the bias term is omitted for clarity.
bustness to f Psub. This issue can be partly alleviated by some
techniques like performing various data augmentations or
using lots of convolutional ﬁlters, yet they are suboptimal.
Conversion: Learn from relation.
We argue that the
above limitations can be mitigated by learning from relation. In the neighborhood of 3D space, the geometric relation between xi and all its neighbors N(xi) is an explicit
expression about the spatial layout of points, which further
discriminatively reﬂects the underlying shape. To capture
this relation, we replace wj in classical CNN with wij,
which learns a mapping M of a relation vector hij, i.e.,
the predeﬁned geometric priors between xi and xj. We call
hij as low-level relation. This process can be described as
T (f xj) = wij · f xj = M(hij) · f xj.
The goal of mapping M is to abstract high-level relation
expression between two points, which can encode their spatial layout. Here we implement M with a shared multi-layer
perceptron (MLP) due to its powerful mapping ability. This
process is illustrated in the middle part of Fig. 2. In this
way, wj is neatly converted to wij, whose gradient (determined by hij) is relevant to both xi and xj. Meanwhile, M
is exactly shared over all the points in N(xi), making it independent to the irregularity of points. It can also be robust
to rigid transformation that will be clariﬁed in Sec 3.2.
As a consequence, f Psub in Eq. (1) becomes
f Psub = σ
 A({M(hij) · f xj, ∀xj})
This convolutional representation, with all the relation between xi and N(xi) aggregated, can achieve explicit reasoning about the spatial layout of points, thus resulting in
discriminative shape awareness. For geometric priors, one
can use 3D Euclidean distance as an intuitive description of
low-level relation hij. Moreover, hij can also be deﬁned
ﬂexibly since M can map it to a high-dimensional relation
vector for channel alignment with f xj for easy multiplication. We will discuss hij in detail in the experiment section.
Channel-raising mapping. In Eq. (3), the channel number of f Psub is the same as the input feature f xj. This is
inconsistent with classic image CNN that increases channel
number while decreasing image resolution for a more abstract representation. For example, the channel number of
64-128-256-512 is set in VGG network . Accordingly,
we add a shared MLP on f Psub for further channel-raising
mapping. It is illustrated in the middle part of Fig. 2.
3.2. Properties
RS-Conv in Eq. (3) can maintain four decent properties:
Permutation invariance. In the inner mapping function
M(h), both the low-level relation h and the shared MLP
M are invariant to the input order of points. Therefore,
with the outer aggregation function A being symmetric, the
permutation invariance can be satisﬁed.
Robustness to rigid transformation. This property is well
held in the high-level relation encoding M(h). It can be
robust to rigid transformation, e.g., translation and rotation,
when a suitable h (e.g., 3D Euclidean distance) is deﬁned.
Points interaction.
Points are not isolated and nearby
points form a meaningful shape in geometric space. Thus
their inherent interaction is critical for discriminative shape
awareness. Our solution of relation learning explicitly encode the geometric relation among points, naturally capturing the interaction of points.
Weight sharing. This is the key property that allows applying the same learning function over different irregular point
subsets for robustness, as well as low complexity. In Eq. (3),
the symmetric A, the shared MLP M and the predeﬁned
geometric priors h are all independent to the irregularity of
points. Hence, this property is also satisﬁed.
3.3. Revisiting 2D Grid Convolution
The proposed RS-Conv is a generic formulation of 2D
grid convolution for relation reasoning. We clarify this with
a neighborhood (convolution kernel) of 3 × 3 on a 2D-grid
feature map, as illustrated in Fig. 3. Speciﬁcally, the summation function P is a speciﬁc instance of the aggregation
function A. Moreover, note that wj always implies a ﬁxed
positional relation between xi and its neighbor xj in the regular grid. For example, w1 always implies the top-left relation with xi, and w2 implies the right-above relation with
xi. In other words, wj is actually constrained to encode one
kind of regular grid relation in the learning process. Therefore, our RS-Conv with relation learning is more general
and can be applied to model 2D grid spatial relationship.
3.4. RS-CNN for Point Cloud Analysis
Using RS-Conv (Fig. 2) as a basic operator and adopting a uniform sampling strategy, a hierarchical shape-aware
: top left
: right above
: top right
feature map
convolution kernel
grid relation
Figure 3. Illustration of 2D grid convolution with a kernel of 3×3.
fully connected layers
long-range connections
feature propagation layers
per-point predictions
Figure 4. The architectures of RS-CNN applied in the classiﬁcation (a) and segmentation (b) of point cloud. N is the number of
points and C is the channel number.
learning architecture like classic CNN, namely, RS-CNN,
can be developed for point cloud analysis as
PNℓ= RS-CONV(Fℓ−1
PNℓ, features in layer ℓof the sampled point set PNℓ
with number Nℓ, are obtained by applying RS-Conv on the
features in the previous layer ℓ−1.
Our RS-CNN applied in the classiﬁcation and segmentation of point cloud is illustrated in Fig. 4. In both tasks,
RS-CNN is used for learning a group of hierarchical shapeaware representation. The ﬁnal global representation followed by three fully connected (FC) layers is conﬁgured
for classiﬁcation. For segmentation, the learned multi-level
representation is successively upsampled by feature propagation to generate per-point predictions. Both of them
can be trained in an end-to-end manner.
3.5. Implementation Details
RS-Conv in Eq. (3). Symmetric function max pooling is
applied as aggregation function A. ReLU is used as
nonlinear activator σ. For mapping function M, a threelayer shared MLP is deployed since theoretically it can ﬁt
arbitrary continuous mappings . Low-level relation hij
is deﬁned as a compact vector with 10 channels, i.e., (3D
Euclidean distance, xi −xj, xi, xj). The channel-raising
mapping is achieved by a single-layer shared MLP. Batch
normalization is applied in each MLP.
RS-CNN for points analysis.
The farthest points are
picked from point cloud for sampling local subsets to perform RS-Conv. In each neighborhood, a ﬁxed number of
neighbors are randomly sampled for batch processing, and
they are normalized to take the centroid as the origin. To
capture more sufﬁcient geometric relation, we force RS-
CNN to learn over three-scale neighborhoods centered on
a sampled point with a shared weight.
This is different
from multi-scale grouping (MSG) that learns multiscale features using multiple groups of weight. RS-CNN
with 3 layers and 4 layers is deployed for classiﬁcation and
segmentation, respectively. Note that only 3D coordinates
xyz are used as the input features to RS-CNN.
Our RS-CNN is implemented using Pytorch2. The Adam
optimization algorithm is employed for training, with a
mini-batch size of 32. The momentum for BN starts with
0.9 and decays with a rate of 0.5 every 20 epochs. The
learning rate begins with 0.001 and decays with a rate of
0.7 every 20 epochs. The weight of RS-CNN is initialized
using the techniques introduced by He et al. .
4. Experiment
In this section, we arrange comprehensive experiments
to validate the proposed RS-CNN. First, we evaluate RS-
CNN for point cloud analysis on three tasks (Sec 4.1). We
then provide detailed experiments to carefully study RS-
CNN (Sec 4.2). Finally, we visualize the shape features that
RS-CNN captures and analyze the complexity (Sec 4.3).
4.1. Point Cloud Analysis
Shape classiﬁcation.
We evaluate RS-CNN on Model-
Net40 classiﬁcation benchmark .
It is composed of
9843 train models and 2468 test models in 40 classes. The
point cloud data is sampled from these models by . We
uniformly sample 1024 points and normalize them to a unit
sphere. During training, we augment the input data with
random anisotropic scaling in the range [-0.66, 1.5] and
translation in the range [-0.2, 0.2], as in . Meanwhile,
dropout technique with 50% ratio is applied in FC layers. During testing, similar to , we perform ten voting tests with random scaling and average the predictions.
The quantitative comparisons with the state-of-the-art
point-based methods are summarized in Table 1, where
RS-CNN outperforms all the xyz-input methods. Speciﬁcally, RS-CNN reduces the error rate of PointNet++ by
31.2%, and surpasses its advanced version that uses additional normal data as well as very dense points (5k). Moreover, even using only xyz as the input, RS-CNN can also
achieve a superior result (93.6%) compared with the best
additional-input method SO-Net (93.4%). This convincingly veriﬁes the effectiveness of our RS-CNN.
We test the robustness of RS-CNN on sampling density, by using sparser points of number 1024, 512, 256, 128
and 64 as the input to a model trained with 1024 points.
As in , random input dropout technique is applied for
a fair comparison.
Fig. 5 shows the test results, where
2 
Figure 5. Left part: Point cloud with random point dropout. Right
part: Test results of using sparser points as the input to a model
trained with 1024 points.
Table 1. Shape classiﬁcation results (%) on ModelNet40 benchmark (nor: normal, “-”: unknown).
Pointwise-CNN 
Deep Sets 
PointNet 
Flex-Conv 
Kd-Net(depth=10) 
PointNet++ 
KCNet 
MRTNet 
Spec-GCN 
PointCNN 
DGCNN 
SO-Net 
Kd-Net(depth=15) 
O-CNN 
Spec-GCN 
PointNet++ 
SpiderCNN 
SO-Net 
the compared methods are PointNet , PointNet++ ,
PCNN and DGCNN . As can be seen, it is more dif-
ﬁcult for shape recognition when points get sparser. Even
so, RS-CNN is still considerably robust. It achieves nearly
consistent robustness as PointNet++, whilst showing superior performance on each density.
Shape part segmentation. Part segmentation is a challenging task for ﬁne-grained shape analysis. We evaluate
RS-CNN for this task on ShapeNet part benchmark and
follow the data split in . This dataset contains 16881
shapes with 16 categories, and is labeled in 50 parts in total.
As in , we randomly pick 2048 points as the input and
concatenate the one-hot encoding of the object label to the
last feature layer. During testing, we also apply ten voting
tests using random scaling. Except for standard IoU (Interover-Union) on each category, we also report two types of
mean IoU (mIoU) that are averaged across all classes and
all instances, respectively.
Table 2. Shape part segmentation results (%) on ShapeNet part benchmark (nor: normal, “-”: unknown).
guitar knife lamp laptopmotor
pistol rocketskate
Kd-Net 
PointNet 
RS-Net 
SPLATNet 
KCNet 
DGCNN 
PointNet++ 
SyncCNN 
SO-Net 
SpiderCNN 
Figure 6. Segmentation examples on ShapeNet part benchmark.
Table 2 summarizes the quantitative comparisons with
the state-of-the-art methods, where RS-CNN achieves the
best performance with class mIoU of 84.0% and instance
mIoU of 86.2%. This considerably surpasses the second
best xyz-based methods, i.e., DGCNN with 82.3%
(1.7↑) in class mIoU and PCNN with 85.1% (1.1↑) in
instance mIoU, respectively. Noticeably, RS-CNN sets new
state of the arts in the xyz-based methods over ten categories. These improvements demonstrate the robustness of
RS-CNN to diverse shape structures. Fig. 6 shows some
segmentation examples. One can see that although the part
shapes implied in irregular points are varied and they may
be very confusing to recognize, RS-CNN can also segment
them out with decent accuracy.
Normal estimation. Normal estimation in point cloud is
a crucial step for numerous applications, such as surface
reconstruction and rendering. This task is very challenging since it requires a higher level of reasoning, which goes
beyond the underlying shape recognition. We take normal
estimation as a supervised regression task, and achieve it using the segmentation network. The cosine-loss between the
normalized output and ground truth normal is applied for
regression training. ModelNet40 dataset is used for evaluation, with uniformly sampled 1024 points as the input.
The quantitative results are summarized in Table 3. RS-
CNN outperforms other advanced methods on this task with
Table 3. Normal estimation error on ModelNet40 dataset.
ModelNet40
PointNet 
PointNet++ 
ground truth
pointnet++
ground truth
< 30° normal
> 90° normal
Figure 7. Normal estimation on ModelNet40 dataset. For clearness, we only show predictions with angle less than 30◦in blue,
and angle greater than 90◦in red between ground truth normals.
a lower error of 0.15.
This signiﬁcantly reduces the error of PointNet++ (0.29) by 48.3%.
Fig. 7 shows some
normal estimation examples, where our RS-CNN with geometric relation learning can obtain more decent predictions.
However, RS-CNN could also be less effective for some intractable shapes, such as spiral stairs and intricate plants.
Table 4. Ablation study of RS-CNN (%).
“DP” indicates the
dropout technique in FC layers of the classiﬁcation network.
4.2. RS-CNN Design Analysis
In this section, we ﬁrst perform a detailed ablation study
on RS-CNN. Then, we discuss the choices of aggregation
function A, mapping function M and low-level relation h
in Eq. (3). Finally, we validate the robustness of RS-CNN
on point permutation and rigid transformation. All experiments are conducted on ModelNet40 classiﬁcation dataset.
Ablation study. The results are summarized in Table 4.
The baseline (model A) is set to learn without geometric relation encoding, but with a shared three-layer MLP as feature transformation function T in Eq. (1).
The baseline only gets an accuracy of 87.2%. Yet with
geometric relation learning, it is signiﬁcantly improved to
89.9% (model B). This convincingly veriﬁes the effectiveness of our RS-CNN. Then, a great improvement of 2%
is gained after using BN (model C), maybe because it can
greatly ease the network training. Moreover, dropout technique improves the result by 0.3% (model D). As mentioned in Sec 3.5, RS-CNN should be able to beneﬁt from
sufﬁcient geometric relation. This is veriﬁed by model E
(92.5%) and model F (92.9%) that perform two-scale and
three-scale relation learning, respectively. Eventually, with
ten voting tests, an impressive accuracy of 93.6% (model
G) can be obtained with only xyz features.
To investigate the impact of the number of input points
on RS-CNN, we also train the network with 2048 points but
ﬁnd no improvement (model H). In addition, to compare
with the baseline (model A) more fairly, we set a new baseline (model I) that works with all the techniques but relation learning. It gets an accuracy of 90.1%, which RS-CNN
can also surpass by 3.5%. We speculate that RS-CNN with
geometric relation reasoning can acquire more discriminative shape awareness, and this awareness can be greatly enhanced by multi-scale relation learning.
Aggregation function A. Three symmetric functions: max
pooling (max), average pooling (avg.)
and summation
(sum), are employed to study the effect of A on RS-CNN.
Table 5 summarizes the results. As can be seen, with M
using three layers, max pooling achieves the best performance while average pooling and summation get the same
Table 5. The results (%) of different designs on aggregation function A and mapping function M (Eq. (3)) (M(k): k-layer MLP).
Table 6. The results (%) of ﬁve intuitive low-level relations h (Ed:
Euclidean distance, cosd: cosine distance, xnor: normal of x, x′:
2D projection of x). Model A applies only 3D Euclidean distance
as h; Model B adds the coordinates difference to model A; Model
C adds the coordinates of two points to model B; Model D utilizes
the normals of two points and their cosine distance as h; Model E
projects 3D points onto a 2D plane of XY, XZ and YZ.
low-level relation h
(3D-Ed, xi −xj)
(3D-Ed, xi −xj, xi, xj)
(3D-cosd, xnor
(2D-Ed, x′
accuracy. The reason may be that max pooling can select
the biggest feature response, thus keeping the most expressive representation and removing redundant information.
Mapping function M. The results of M deployed with
different layers are summarized in the ﬁrst three rows of
Table 5. One can see that the best accuracy of 93.6% is
obtained by a shared three-layer MLP, and it decreases by
0.9% when increasing the number of layers. The reason
might be that M with four layers brings some difﬁculty for
network training. Noticeably, RS-CNN can also get a decent accuracy of 92.4% with M using only two layers. This
veriﬁes the powerfulness of relation learning for underlying
shape capturing from point cloud.
Low-level relation h. The key to RS-CNN is learning from
relation, thus how to deﬁne h is an issue worth exploring.
Actually, h can be deﬁned ﬂexibly, as long as it could discriminatively reﬂect the underlying shape. To validate this
claim and facilitate the understanding, we experiment with
ﬁve intuitive relation deﬁnitions as examples, whose results
are summarized in Table 6.
As can be seen, using only 3D Euclidean distance as
h, the accuracy can also reach 92.5% (model A). This
demonstrates the effectiveness of our RS-CNN for highlevel geometric relation learning.
Moreover, the performance is gradually improved with additional relation, including coordinates difference (model B) and coordinates
themselves (model C). We also utilize the normal vectors of
two points and their cosine distance as h, the result (model
Table 7. Robustness to point permutation and rigid transformation
(%). During testing, we perform random permutation (perm.) of
points, add a small translation of ±0.2 and counterclockwise rotate
the input point cloud by 90◦and 180◦around Y axis.
PointNet 
PointNet++ 
† The accuracy drops a lot mainly because the forcible normalization
of each local point subset could bring difﬁculty for shape recognition.
D) is 92.8%. This indicates RS-CNN is also able to abstract
shape information from the relation in normals.
Intuitively, the relation among points in the 2D view of
point cloud can also reﬂect the underlying shape. Therefore, to validate our RS-CNN for shape abstraction on 2D
relation, we forcibly set the value of one dimension in 3D
coordinates to be zero, i.e., projecting 3D points onto a 2D
plane of XY, XZ and YZ. The results are all around 92.2%
(model E), which is quite impressive. This further veriﬁes
the effectiveness of the proposed relation learning method.
Robustness to point permutation and rigid transformation.
We compare the robustness of our RS-CNN with
PointNet and PointNet++ . Note that all the models
are trained without related data augmentations, e.g., translation or rotation, to avoid confusion in this test. In addition,
although relation learning in RS-CNN is robust to rotation,
the initial input features of 3D coordinates are affected. We
address this issue by normalizing each sampled point subset to corresponding local coordinate system, which is determined by each sampled point and its normal. For a fair
comparison, we also perform this normalization for Point-
Net++, as it learns over local subsets as well. The 3D Euclidean distance is applied as geometric relation h in RS-
CNN for this test. Table 7 summarizes the test results.
As can be seen, all the methods are invariant to permutation. However, PointNet is vulnerable to both translation
and rotation while PointNet++ is sensitive to rotation. By
contrast, our RS-CNN with geometric relation learning is
invariant to these perturbations, making it powerful for robust shape recognition.
4.3. Visualization and Complexity Analysis
Visualization. Fig. 8 visualizes the shape features learned
by the ﬁrst two layers of RS-CNN on ModelNet40 dataset.
As it shows, the features learned by the ﬁrst layer mostly
respond to edges, corners and arcs, while the ones in the
second layer capture more semantical shape parts like airfoils and heads. This veriﬁes RS-CNN can learn progressive
shape-aware representation for point cloud analysis.
Complexity Analysis.
Table 8 summarizes the space
Figure 8. Visualization of the shape features learned by the ﬁrst
two layers of RS-CNN on ModelNet40 dataset.
The features
learned by the ﬁrst layer mostly respond to edges, corners and arcs,
while the ones in the second layer capture more semantical shape
parts like airfoils and heads.
Table 8. Complexity of RS-CNN in point cloud classiﬁcation.
#FLOPs/sample
PointNet 
PointNet++ 
(number of params) and the time (ﬂoating point operations/sample) complexity of RS-CNN in classiﬁcation with
1024 points as the input. Compared with PointNet ,
RS-CNN reduces the params by 59.7% and the FLOPs by
32.9%, which shows its great potential for real-time applications, e.g., scene parsing in autonomous driving.
5. Conclusion
In this work, RS-CNN, namely, Relation-Shape Convolutional Neural Network, which extends regular grid CNN
to irregular conﬁguration for point cloud analysis, has been
proposed. The core to RS-CNN is a novel convolution operator, which learns from relation, i.e., the geometric topology constraint among points. In this way, explicit reasoning
about the spatial layout of points can be made to obtain discriminative shape awareness. Moreover, the decent properties of geometric relation can also be acquired, such as
robustness to rigid transformation. As a consequence, RS-
CNN equipped with this operator can achieve contextual
shape-aware learning, making it highly effective. Extensive
experiments on challenging benchmarks across three tasks,
as well as thorough empirical and theoretical analysis, have
demonstrated RS-CNN achieves the state of the arts.