Nonlinear ®ltering and measure-valued processes
Dan Crisan1,w Terry Lyons2,ww
1Department of Mathematics, University of Edinburgh, JCMB, KB, May®eld Road, Edinburgh,
EH9 3JZ, UK
2Department of Mathematics, Huxley Building, Imperial College, 180 Queen's Gate, London
SW7 2BZ, UK
Received: 12 April 1995 / In revised form: 1 April 1997
Summary. We construct a sequence of branching particle systems with time
and space dependent branching mechanisms whose expectation converges to
the solution of the Zakai equation. This gives an alternative numerical
method to solve the Filtering Problem.
AMS Subject Classi®cation : 93E11, 60G57, 65U05
1 Introduction
1.1 A brief of the basic framework
X; F; Ft0; P be a ®ltered probability space where we have a
d  mdimensional standard Brownian motion f
Wt; Vt; Ft; t  0g and n a d-dimensional, F0-measurable, square integrable random vector, independent of
W ; V . Let also f : 0; 1  Rd ! Rd, r: 0; 1  Rd ! L
Rd2; h: 0; 1  Rm ! Rm be continuous functions which satisfy sucient
conditions to have existence and uniqueness of the solution for the following
system of stochastic dierential equations (cf or ):
dXt  f t; Xt
 dt  r t; Xt
dYt  h t; Xt
 dt  dVt
with the initial conditions X0  n and Y0  0. The process X is usually called
observation
Ys; 0  s  t and Y 
Ys; s  0, the observation r-®elds. The ®l-
Probab. Theory Relat. Fields 109, 217±244 
w Supported by an Edinburgh University grant and the British Council.
ww Supported by EPSRC Fellowship No. B/93/SF/445 and EEC Grant SC1-CT92-0784.
tering problem consists in determining the conditional law of the signal given
the observation process, i.e., in computing
def E u Xt
where u is a Borel bounded function on Rd. To do this, one changes the
underlying measure so that Yt becomes a Brownian motion under the new
probability measure ~P, independent of X and
P ÿ a:s: ;
s; Xs dYs ÿ 1
s; Xsj2dsjYt and ~E is the
expectation with respect to ~P. By imposing stronger conditions on the coecients and the initial conditions of (1) and (2) one proves that qt uniquely
satis®es the following evolution equation, called the Zakai equation
su ds 
Rd is the in®nitesimal generator associated with the signal X and u 2 D
For a detailed account of the ®ltering problem, see for instance, or .
1.2 A brief outline of the paper
In the next section we construct a sequence of branching particle systems
with wildly varying space and time dependent distributional branching
generating function. This sequence is proven to be tight in the third section
and it is used to prove the existence of a measure-valued branching process
denoted by X (calligraphic X), de®ned on
X; F; ~P, with the property that,
for every u 2 D
A, the process
is a square integrable martingale with respect to the ®ltration Ft _ Y. From
the particular construction we use, the quadratic variation of the martingale
t will have the form
where vs is a bounded, positive function, continuous in time and vt  1
8t 2 0; 1. The last condition insures the existence of the branching mechanism presented in the next section. In section 4 we present the connection
between this process and the ®ltering problem. We prove that the conditional
expectation of X given Y satis®es (3) and that the particle systems approximation can be used to solve numerically the ®ltering problem.
D. Crisan, T. Lyons
We feel this result is of interest for a number of reasons, some are technical
and relate to the extension of the Dawson Watanabe construction ( , ) of
a measure valued process to a case where the expected number of ospring
varies so rapidly with time that it is not a function at all but in reality is only a
distribution. However, we are more excited by the potential this construction
has for the numerical solution of stochastic pde's over high dimensional state
spaces. We illustrate our idea in this paper by concentrating on the important
example of the Zakai equation of non-linear ®ltering.
1.3 Problems with high-dimensional ®ltering
As we have set out above, the essential problem of non-linear stochastic
®ltering is to ®nd the conditional distribution of Xt given the information
obtained by measuring Ys for s in some time window t ÿ R; t
. The problem
has a considerable importance, but its usefulness is limited to those cases
where numerical solution is feasible.
In the special case where the evolution of Xt is given by a linear equation and
h is also linear, one has the very nice property that if one assumes a Gaussian
distribution for X0 then the conditional distribution of Xt is always Gaussian,
and in consequence can be described by a ®nite number of parameters (its mean
and covariance). This remark has enormous computational signi®cance: the
conditional distribution can be obtained by solving an ordinary dierential
equation for the covariance and a stochastic dierential equation for the mean.
This approach is the well known Kalman ®lter ( , ).
However, it took a considerable time for the Kalman ®lter to be used in a
routine way. The major reason for its acceptance has to be that with modern
computing power it is almost a trivial exercise to solve an ODE and only
slightly more dicult to solve an SDE numerically. On the negative side,
there are many situations where the linear/Gaussian assumptions of this
model are inappropriate and in this case it would seem attractive to apply the
Zakai equation which gives a stochastic PDE for the measure (or its density)
describing the conditional distribution of Xt.
This might seem like a wonderful panacea; unfortunately, in real applications Xt is often a multidimensional variable, even in four dimensions it can
be a serious problem to solve a PDE and more dicult to accurately solve an
SPDE, in ®fty dimensions it is utterly hopeless. This has lead to attempts to
®nd wider classes of models where the posterior distribution lies in a ®nite
dimensional manifold (the so-called BenesÏ and Ocone ®lters, , ) but
these represent a very small class.
More practical have been the approaches where linearisation can be applied recursively using the extended Kalman ®lter ( ). But clearly approaches via linearisation have strong limitations if there is signi®cant
uncertainty in the observations. It has remained a serious problem to ®nd
good ways to approximate the posterior measure in the general case. It is this
problem we try to address in this paper. We start with a few general remarks.
Nonlinear ®ltering and measure-valued processes
In high dimensions one of the most convenient ways to describe a measure is to generate a sample of it, in other words a sequence of points randomly chosen according to its distribution. This fact has been realised by
statisticians for many years and explains the popularity of Gibbs Sampling
(cf , , ). The reason is that often one is interested in some low
dimensional marginal distribution and not the measure itself. Obtaining this
directly from a density function in high dimensions is not computationally
feasible, as it involves a numerical integration over the whole space. On the
other hand the projection of a sample can quickly be computed, and nonparametric approaches can be used eectively to construct approximate
marginal distributions.
Our idea is that it might be possible to approach the Zakai equation by
creating a sample from the posterior measure. We do not quite succeed, but
we are able to produce arbitrarily good approximations.
1.4 Constructing particle approximations
Recall ( ) that the Dawson Watanabe measure valued process is easily
constructed as a limit of branching particle systems, each particle of which
moves according to the same law and branches independently of the others.
Such processes are easy to simulate (particularly on parallel machines) and so
the Dawson Watanabe process can be approximated numerically.
In our case, we construct a measure valued process whose expectation at
any time is the conditional distribution of Xt . This also has a branching
particle system approximation; moreover the particles evolve independently
moving with the same law as X and branch according to a mechanism that
depends on the trajectory of the particle and Y , but is independent of the
events elsewhere in the system. It is also easy to simulate. It follows that one
may approximate the measure valued process, and by taking independent
copies of this approximation, estimate its expectation. The result is a cloud of
paths, with those surviving to the current time providing an estimate for the
conditional distribution of Xt.
Because we can look back along the paths that have survived and observe
the historical process, we see that we are also able to update our estimate of
the past behaviour of our process without serious computational diculty.
Our approach is feasible in the sense that one can carry it out and get a
return directly related to the amount of computational eort invested.
However, it has to be said that the convergence could still be quite slow. We
are currently investigating rates of convergence and hope to report on this at
a later date. However, if we contrast this approach with the one where
particles are weighted with exponentials (the classical Monte Carlo method,
see for instance , , ), we would point out two apparent advantages
over this (largely disastrous) method. Firstly, all computations done are
associated with particles that carry the same weighting ± one never ®nds
oneself computing a trajectory that will obviously have a smaller weight than
D. Crisan, T. Lyons
another. A second related point is that paths exploring unfruitful directions
of exploration are rapidly killed suggesting a model akin to lemmings ¯owing
along and reproducing heavily, but being killed if they drift away from the
plausible values of the variables. This again suggests a sifting out of potentially unhelpful computation.
2 Assumptions and notations
Rd be the space of continuous bounded functions on Rd, C0
the space of continuous functions which vanish at in®nity, CK
Rd be the
space of continuous functions with compact support, C2
Rd be the space on
continuous functions with compact support with continuous ®rst and second
partial derivatives and C2
Rd be the space on continuous bounded functions with continuous ®rst and second partial derivatives.
Rd be the space of ®nite measures over Rd endowed with the
topology of weak convergence, i.e., the topology in which, ln ! l i
l; f  for all f 2 Cb
Rd and M0
Rd be the space of ®nite measures over Rd endowed with the topology of vague convergence, i.e., the
topology in which, ln ! l i
l; f  for all f 2 C0
We assume that the coecients of the system (1)+(2) satisfy the necessary Lipschitz and linear growth conditions for the solution of the Zakai
equation (see or ) to exist and be unique and that h is a continuous
Rd of the in®nitesimal generator A
s has the following
properties:
 For every f 2 D
A, there exists a sequence fn 2 D
A such that
A and fn converges boundedly and pointwise to f and, respectively,
Afn converges boundedly and pointwise to Af (a sequence xn of bounded
functions converges boundedly and pointwise to x if it converges pointwise
and supn kxnk < 1).
 There exists a sequence fukgk>0; uk : Rd ! 0; 1 of continuous bounded
functions such that uk; u2
A, for all s 2 0; 1, x 2 Rd; jA
and there exists Rk and rk such that 0 < k < rk < Rk; and uk CB
Remark 2.1 If the coecients of the stochastic dierential equation (1) are
continuous, then for any f 2 C2
A, we have f 2 2 C2
Moreover, for any f 2 C2
A one can choose fn 2 C2
such that fn converges boundedly and pointwise to f and, respectively, Afn
converges boundedly and pointwise to Af . Under reasonable extra conditions (e.g. that the space-time process is Feller), if f 2 D
A and limt!0 Ptf  f , and limt!0 APtf  Af boundedly
and pointwise, so condition
 is satis®ed (Pt is the semigroup associated to
the process X).
Nonlinear ®ltering and measure-valued processes
Remarks 2.2 If the coecients of the stochastic dierential equation (1)
satisfy the condition
then one can prove that if
for kxk  rk
for rk < kxk < Rk
for kxk  Rk
then uk satisfy
 for large enough rk and Rk.
From now on, we work under the new probability measure ~P and all
the expectations and conditional expectations will be considered with respect
3 The construction of the particle systems
t; Ft; 0  t  1g be a sequence of branching particle systems on
X; F; ~P with values in MF
Rd de®ned as follows:
(a) Initial condition
0 is the occupation measure of n particles (we will denote the number
of particles alive at time t by Nn
t) of mass 1
i 2 Rd, for every i; n 2 N.
2. The occupation measure of the particles tends weakly to the initial distribution of the signal, i.e.
(b) Evolution in time
We describe the evolution of the processes in the interval
i  0; 1; . . . ; n ÿ 1.
1. At the time i
n, the process consists of the occupation measure of Nn
particles of mass 1
2. During the interval the particles move independently with the same law as
the signal (1). Let V
s, s 2 i
n  be the trajectory of a generic particle in
this interval.
3. At the end of the interval, each particle branches into a random number of
particles with a mechanism depending on its trajectory in the interval. The
mechanism is chosen so that it has ®nite second moment and the mean
D. Crisan, T. Lyons
number of osprings for a particle given the r-®eld Fi1
Fs; s < i1
of events up to time i1
t dYt ÿ 1
and the variance is equal to vi1
n . The particles branch independently of each
In the description above vs is an arbitrary bounded, positive function,
continuous in time and vt  1
4 ; 8t 2 0; 1. The last condition insures the existence of the required branching mechanism. We denote by kvk the supremum of v over the interval 0; 1, i.e.,
Just before the
i  1-th branching, we will have Nn
n particles. Let us
denote by Xn
n ÿ the state of the process just before the
branching and by V j
s, s 2 i
n  the trajectory of the j-th particle alive
during the interval
1  j  Nn
n. Let also qj
n  be the number of osprings of the j-th particle at time i1
and, since we assumed that h is a
continuous bounded functions, let khk be the quantity
t;x20;1Rd kh
t; xk < 1 :
Remarks 3.1 We have the following relations:
0  n, 8n  0, t 2 0; 1.
ii. ~EN 2
t  ekhk2nt
nekhk2ntÿk
n , 8n  0, t 2 0; 1
x is the largest
integer smaller that x).
Proof. i. Nn does not change during the intervals
n , k  0; . . . ; n ÿ 1 so
n . Therefore it suces to prove that ~ENn
n  ~ENn
0  i < n ÿ 1. Using (6), we have
hh t; V j
hh t; V j
Nonlinear ®ltering and measure-valued processes
hh t; V j
since s ! exp
t dYt ÿ 1
is an Fs-adapted
martingale.
ii. From the construction of the branching mechanism of the particles we
hh t; V j
2h t; V j
2h2h t; V j
This inequality and the independence of the particles implies (as in i.)
It follows that
 ekhk2nt
nekhk2ntÿk
D. Crisan, T. Lyons
where the second inequality was obtained from (8). This completes the proof
of the Remark.
Let u be a continuous bounded function. Using the Remark 3.1 we get
t; u is square integrable and
hh t; V j
In between two branches the particles move according to the prescribed SDE
(1), hence for t in the interval i
n  and u 2 D
 ds  Su;i
t; Ft; t 2 i
n g is a square integrable local martingale (we
use again the Remark 3.1) with the quadratic variation
rj1;krj2;k
s; Tr DurrDu
It follows that
t; Ft; t 2 0; 1g is a square integrable local martingale
Nonlinear ®ltering and measure-valued processes
which has the quadratic variation
s; Tr DurrDu
n ÿ; l  0; 1; . . . ; ng is a discrete martingale
and has conditional quadratic variation
Remarks 3.2 The process Mu
l is a martingale also with respect to the
larger ®ltration Fl1
Using (9) and (13), we can express the process
su ds  Su
hh s; V j
Then applying Ito's rule to the exponential in the last term of (16) and
exploiting the fact that Y is a Brownian motion, we get
hh r; V j
D. Crisan, T. Lyons
4 The existence of the process X
We show ®rst that the sequence fXngn>0 is tight in DM0
Rd0; 1 endowed
with the Skorohod topology and then that it `stays mostly' within a compact
set. More precisely, we will prove that there exists a sequence of compact sets
Kk 2 Rd such that, for every e > 0
k!1 lim sup
~P 9t 2 0; 1
The two properties will ensure that the sequence fXngn>0 is tight in the space
Rd0; 1 endowed with the Skorohod topology. So ®rst we prove the
tightness over the space DM0
Rd0; 1. For this, it is sucient to prove (cf.
 ) that the processes f
s; ui, s 2 0; 1g form a tight sequence, where
fuigi0 is de®ned as follows: u0 is the constant function 1 and fui; i > 0g is a
dense set in C0
Rd (we will take them to be in D
A with compact support).
In order to prove that f
s; ui; s 2 0; 1g is a tight sequence for every
i  0, we use the following theorem (cf. )
Theorem 4.1 [Aldous] Let fang be a sequence of real valued processes with
caÂdlaÂg paths such that
tg is tight on the line for each t 2 0; 1.
(ii) For any arbitrary sequence of stopping times fsngn0 (with respect to the
natural ®ltration of fang) and any sequence fdngn0 of positive real numbers with limn!1 dn  0, we have
n!1 an sn  dn
  0 in probability :
Then fang is tight.
Condition (i) follows from the Proposition 4.2.
Proposition 4.2 For every t 2 0; 1 we have
Proof. Since
it is enough to prove that supn0 E
s; 12 is ®nite. Let us
From (17) we obtain
Nonlinear ®ltering and measure-valued processes
We prove that wn is bounded from above uniformly in n, by exploiting (22)
and using the Gronwall inequality. For this we give an upper bound for each
of the three terms of the right hand side of the inequality (22) of the form
The ®rst term
The second term
Doob's maximal inequality (cf , pp. 14) gives us the following upper
 4kvk nt
n  4kvk :
The third term
We ®nd ®rst an upper bound for ~E
n ; s2. We have that
h p; V j1
 h p; V j2
jh p; V j1
 h p; V j2
which gives us, as in Remark 3.1
D. Crisan, T. Lyons
75  ekhk2 ~E
Now using Burkholder-Davis-Gundy inequality and (25), we ®nd
 4ekhk2khk2
The last inequality gives the following upper bound on the third term of (22)
4ekhk2khk2
where K2 is a constant independent of n.
From (22), (23), (24) and (26) we obtain
t  3  12kvk
  12ekhk2khk2
Finally, using the Gronwall inequality (see, for instance pp. 287) we ®nd
def 3  12kvk
4khk2ekhk2
t 2 0; 1 :
So also supn1 ~E
s; 12  c
t which ®nishes the proof of the
proposition.
Remarks 4.3 Using a similar argument one can prove that, 8p  1, there
exists a function cp : 0; 1 ! R, such that
t 2 0; 1 :
We prove now that the processes
t; ui satisfy condition (ii) of Theorem
(4.1). Since C2
A is dense in C0
Rd (under the uniform norm) we
can take the functions ui; i  1 from this set.
Proposition 4.4 For any arbitrary sequence of stopping times fsngn0 any
positive real sequence fdngn0 with limn!1 dn  0 and u 2 C2
Rd [ f1g, we
Nonlinear ®ltering and measure-valued processes
Xn sn  dn
Xn sn  dn
for all e > 0.
Proof. Let a and b be the following quantities
t;x20;1Rdg
t; xk < 1
t;x20;1Rdg
Tr DurrDu
Obviously, if u is the constant function 1, then a  b  0. Using (17) we get
Xn sn  dn
We have, consecutively,
sn  dn ÿ Su
 K ~EhSu
sn  dn ÿ hSu
s; Tr DurrDu
sn  dn ÿ sn
D. Crisan, T. Lyons
 kvkkuk2 1  c
n ; sh s; V j
 khk2kuk2 ~E
 kuk2khk2c0
1 is obtained similarly to c
1 as an uniform upper bound for
The inequalities (31), (32), (33), (34) imply that all the terms from the right
hand side of (30) tend to 0 when n goes to 1, hence ~Ej
sn  dn; u
sn; uj2 tends to 0 as well.
We prove now that the sequence satis®es (19). For this, we need the
following two results.
Proposition 4.5 Let u 2 D
Rd such that u; u2 2 D
Nonlinear ®ltering and measure-valued processes
Proof. It is enough to prove that
Firstly, we observe that last integral can be taken from 0 to nt
changing the limit. Then, using (25) and Burkholder-Davis-Gundy inequality, we get
n ; r ÿ 1h
n ; r ÿ 1h
 kkhk2kuk2
2 kkhk2kuk2c
Thus one can eliminate Br
n ; r from the ®rst term of (35) without changing
the limit. After these 2 transformations, (35) becomes
Using once again Burkholder-Davis-Gundy inequality, we ®nd the following
upper bound for the terms of the sequence
 CkAu2 ÿ 2uAuk
which completes our proof (we used the classical identity Tr
DurrDu
 Au2 ÿ 2uAu).
Proposition 4.6 For uk de®ned as in the assumption () in section 2, there
exists an uniform constant M such that
p0; uk  M
for all t 2 0; 1.
D. Crisan, T. Lyons
Proof. Using equation (17), we have that
suk ds  Suk
Since for uk as above Suk
t and Muk
nt are martingales with mean zero
and also the last term has mean zero, we have that
  lim sup
and since limn!1 ~E
p0; uk and
sups20;1
we have our claim.
We want to prove that there exists a sequence of compact sets Kk; such
that, for all e > 0;
k!1 lim sup
9t 2 0; 1;
s; ICKk  e  0
which is equivalent to proving that
k!1 lim sup
s; ICKk  e  0
which, in turn, is implied by (using Chebychev's inequality)
k!1 lim sup
t; ICKk2
Proposition 4.7 For Kk 
0; Rk; where Rk was de®ned in assumption (),
(41) holds.
Proof. Since ICKk  uk it is enough to prove that
k!1 lim sup
suk ds  Suk
Nonlinear ®ltering and measure-valued processes
0 is convergent to p0 we have that
k!1 lim sup
p0; uk2  0 :
From the de®nition of the functions uk we have (as in the proof of the
previous proposition) that
k!1 lim sup
Using Burkholder-Davis-Gundy inequality
k!1 lim sup
k!1 lim sup
n ÿ 2unAun
k!1 lim sup
k!1 lim sup
k  uk, we have, using Fatou's lemma
k!1 lim sup
From (38) and (47) we obtain that
k!1 lim sup
Using (35) we obtain that
k!1 lim sup
k!1 lim sup
k!1 lim sup
D limk!1 lim supn!1 ~E supt20;T
. From (43),
(44), (45), (46), (48), (49) and Fatou's lemma we obtain that there exists a
constant K such that
D. Crisan, T. Lyons
for all T 2 0; 1 which implies our claim, using, once again, Gronwall's inequality.
We know now that the sequence Xn is tight in DMF
Rd0; 1, hence relatively
relatively
RdRm0; 1. Let
X; Y  be the limit process of one of its convergent
subsequences (to avoid even more cumbersome notation we re-index this
sequence as f
Xn; Y gn0). We will show that X is a solution of the `martingale problem' (4)+(5). We need ®rst several useful results.
Proposition 4.8 Let u be a continuous bounded function. Then, for all p  1
t; ujp < 1
Proof. Since fk : DR0; 1 ! R, fk
supt20;1 jatjp ^ k > 0 is a bounded
continuous function on DR0; 1 and the process t !
t; u converges in
distribution to the process t !
t; u, we have that, for all k > 0
t; ujp ^ k
where cp is the function de®ned in Remark 4.3.
Proposition 4.9 The process X has continuous paths in MF
Proof. With a similar proof to the one in Proposition 4.4 one shows that for
Rd and for all e > 0
d!0 lim sup
s;t20;1;jsÿtjd
Using the fact that supn1 ~E
s; 12 < 1 (see proof of Proposition 4.2), one then extends (52) to all u 2 C0
Rd by taking a sequence of
functions un 2 C2
Rd that converges uniformly to u. This implies that for
all u 2 C0
Rd and for all e > 0, one has
d!0 lim sup
s;t20;1;jsÿtjd
t; uj  e
Based on Theorem 15.5 from , (53) implies that the real valued process
t; u is continuous ~P-a.s.. for all u 2 C0
Rd and hence the process
Nonlinear ®ltering and measure-valued processes
t is continuous as a process with values in MF 0
Rd. Since t ! X
a genuine DMF
0; 1 process, we get that it is continuous as a MF
Rdvalued process.
Since the limit process is continuous, the one dimensional projections of the
sequence ± Xn
t ± are convergent in distribution to X
t and, in particular,
the sequence
t; u is convergent in distribution to
t; u for any
Proposition 4.10 Let u be a continuous bounded function. Then, for all p  1
t; ujp  ~Ej
t; ujp :
Proof. The proposition follows from the fact that
t; u is convergent in
distribution to
t; u, by using the uniform integrability of the sequence
and Remark 4.3.
We are now able to prove that X satis®es the martingale problem
Theorem 4.11 For u 2 D
A the process f
t; Ft _ Y; t 2 0; 1g where
is a square integrable martingale with the quadratic variation
s; vsu2 ds :
Proof. We will use the idea contained in the Theorem 8.2 from . Let M be
a separating subset of the set of continuous bounded functions on MF
and N be a separating subset of Cb
Rm. We want to prove that for all
for all m; m0  0, 0  t1 < t2 < . . . < tm  s  t, 0  t0
2 < . . . < t0
k1; . . . ; km 2 M and k0
1; . . . ; k0
m 2 N. We prove only (55), since (56) can be
done analogously. From the de®nition of Mu, (55) is equivalent to
D. Crisan, T. Lyons
We only need to show (57) for u with the property that u2 2 D
using the property () of A
s and the dominated convergence theorem we
can extend this to an arbitrary u 2 D
A. Using a proof analogous with the
one used in Proposition 4.10 one shows, consecutively, that since
converges in distribution to
Using theorem 2.2 from , we have that, since
Xn; Y  converges in distribution to
X; Y  also
su dYs converges in distribution to
su dYs and using (35) and, once again, an
argument similar to the one used in Proposition 4.10, we have that
Since u2 2 D
A, we have that Tr
DurrDu  Au2 ÿ 2uAu 2 Cb
n is a square integrable martingale such that
 kAu2 ÿ 2uAuk
From (58),(59),(60),(61) and (62) we obtain that
Nonlinear ®ltering and measure-valued processes
Remark 4.12 The martingale Mu is a martingale also with respect to the
initial ®ltration Ft and its conditional expectation with respect to Y is 0.
With this we conclude the existence of the process with the properties described in the introduction.
Remark 4.13 The normalised occupation measure ln of a sequence of points
chosen randomly with the distribution p0 will almost surely converge
(weakly) to p0. Therefore the entire construction is valid when Xn
0 is taken
to be ln. The readers may ®nd the arguments in this paper more intuitive if
they have in mind this initial data.
At this point in time, we have not had the energy required to prove the
uniqueness of the solution of the ®ltered martingale problem (4) + (5),
although we believe this to be unique. Uniqueness is not central to our
overall objective, achieved in the next section, where we show that, given Y ,
the (conditional) mean of Xn converges almost surely to the unique solution
of the Zakai equation and hence to the unnormalised distribution of the
5 Application to the nonlinear ®ltering problem
The process X is the solution of the `®ltered' martingale problem (4)+(5). It
follows that for u 2 D
A (and the uniform square integrability of
t; Au and
In establishing (64), we used the fact that for every integrable Ft-measurable
random variable A we have ~EAjY  ~EAjYt (since Y is a Brownian
motion) and if fUt; t  0g is an Ft-progressively measurable process such
s dt < 1; 8s  0 then
A proof of these observation can be found in . One can also obtain the
corresponding evolution equation for time dependent u.
x be the processes Xn and, respectively, X given the
observation path Y:
x. Let also ~Ex be the corresponding expectations given
t  ~ExXY
t, i.e., the measure obtained by integrating the
measure valued random variable XY
t (this is, actually, what we are
D. Crisan, T. Lyons
computing in numerical applications) and Zx
t  ~ExXY
t. Using Fubini's theorem, we have
Using (65), the evolution equation (64) becomes
From (67) and the fact that we assumed from the beginning that the solution
of the Zakai equation is unique, we deduce the following
Theorem 5.1 The unnormalised conditional distribution of the signal X given
the observation coincide with the conditional expectation of X given the observation.
The next theorem is the cornerstone of the numerical algorithm. It shows
that, in order to approximate the unnormalised conditional distribution qt,
we construct the process Xn up to time t (where n is taken so that the error is
as small as we want), keeping the observation path ®xed, and then compute
its (conditional) expectation.
Theorem 5.2 There exists X 2 X with ~P
X  1 such that for every x 2 X we
have limn!1 Zx
for every u continuous bounded function (qY:
is the unnormalised distribution
of the signal given the observation path Y:
Proof. Let M be a set containing a countable collection of C1
Rd functions, uniformly dense in C0
Rd and the constant function 1. To prove the
theorem, we only need to show that, for every function in M,
~P ÿ a:s: :
(to simplify the notation we will omit the x variable from now on). For this
we use the solution of the following backward ItoÃ equation
where u 2 M. From , pp. 126±134 or , we obtain that equation (70) has
a unique solution in appropriate spaces of solutions and qt
continuous
~P ÿ a:s:,
p0; w0  q0
w0, ~P-a.s.. Hence, in order to show (69),
we need to prove that
Nonlinear ®ltering and measure-valued processes
~P ÿ a:s: :
The ®rst step is to prove that
and then that
~P ÿ a:s: :
We have that
Since the number of osprings qj
n of the particle V j
n is independent of the
`future' of Yi
n, we have that
 dsÿ wiÿ1
D. Crisan, T. Lyons
We prove that
n is a Markov process, we have that
We compute ®rst
x  ~Eiÿ1
n ;x u V j
where the expectation ~Eiÿ1
n ;x is taken with respect to the probability ~Piÿ1
n ;x is taken so that V j
n start at time iÿ1
n from x. This will imply that the
conditional
expectation
n  (and, consequently, given Y _ Fiÿ1
n . Using the
fact that qt
n , we ®nd
n ;x u V j
 ds Y _ Fiÿ1
 ds Y _ Fi
Nonlinear ®ltering and measure-valued processes
From (77) and (78) we get that
 ~E ~E u V j
which proves (75). The identity (72) follows now from (74) and (75).
In the analysis above we considered V j
n de®ned up to time t, although in
the description of the branching system it is not, but obviously we can attach
`an extension' from i
n to t, satisfying the same SDE and independent of Y .
We prove now (73). Using Ito's formula we have that
j1;j2;j3;j41
~E h V jk
Using once again an argument based on the Gronwall inequality we obtain
and from this, using integration by parts, we ®nd the following upper bound
~E h V jk
 Mkhk4kuk4
D. Crisan, T. Lyons
where the constant M is independent of n. It follows that
tkhk4kuk4
(c4 is the function de®ned in Remark 4.3). Finally from (80) we obtain (73)
by a Borel-Cantelli type argument.
Remarks 5.3 The expectation Zn
t of the process XY
t, i.e., the process
t with ®xed observation path Y:, converges almost surely to the unnormalised conditional distribution of the signal qY:t . One can prove the following: let XY ;1
t; . . . ; XY ;m
n independent copies of XY
na and a > 0,
~P ÿ a:s::
So if we take m
n independent copies of the system consisting of n initial
particles of mass 1
n and let them evolve and branch at times k
n, by averaging
them we obtain an approximation of the unnormalised conditional distribution of the signal.
An alternative way of looking at the above approximation procedure is to
start with proportionally more particles so that, if the time step is 1
n, we start
n  n initial particles of mass
nn. In this way we see that the
measure valued process we have constructed is, in some sense, extremal, and
that, if we introduce slightly longer interbranching times relative to the
number of particles one starts with initially, one would get convergence to
the solution of the Zakai equation.
In this paper we have proved the existence of a solution to the ®ltered
martingale problem (4)+ (5). This is an extension of the classical Dawson-
Watanabe construction. Averaging the particle approximations over independent evolutions leads to numerical approximation of the Zakai equation.
A sequel in preparation to this paper will look at the numerical eectiveness of this method and closely related approaches.
Acknowledgment. The authors would like to thank Dr. Alison Etheridge with whom they had
many helpful discussions and the referee for his perceptive observations and appropriate references.