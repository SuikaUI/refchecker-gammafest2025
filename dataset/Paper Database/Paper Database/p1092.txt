Two-Stage Eagle Strategy with Diﬀerential Evolution
Xin-She Yang1 and Suash Deb2
1) Mathematics and Scientiﬁc Computing,
National Physical Laboratory, Teddington TW11 0LW, UK.
2) Department of Computer Science & Engineering,
C. V. Raman College of Engineering,
Bidyanagar, Mahura, Janla, Bhubaneswar 752054, INDIA.
Eﬃciency of an optimization process is largely determined by the search algorithm and its
fundamental characteristics. In a given optimization, a single type of algorithm is used in most
applications. In this paper, we will investigate the Eagle Strategy recently developed for global
optimization, which uses a two-stage strategy by combing two diﬀerent algorithms to improve
the overall search eﬃciency. We will discuss this strategy with diﬀerential evolution and then
evaluate their performance by solving real-world optimization problems such as pressure vessel
and speed reducer design. Results suggest that we can reduce the computing eﬀort by a factor
of up to 10 in many applications.
Keywords: eagle strategy; bio-inspired algorithm; diﬀerential evolution; optimization.
Reference to this paper should be made as follows:
Yang, X. S. and Deb, S., . ‘Two-Stage Eagle Strategy with Diﬀerential Evolution’,
Int. J. Bio-Inspired Computation, Vol. 4, No. 1, pp.1–5.
Introduction
Metaheuristic optimization and computational modelling have become popular in engineering design
and industrial applications. The essence of such paradigm is the eﬃcient numerical methods and
search algorithms. It is no exaggeration to say that how numerical algorithms perform will largely
determine the performance and usefulness of modelling and optimization tools .
Among all optimization algorithms, metaheuristic algorithms are becoming powerful for solving
tough nonlinear optimization problems . The aim of developing modern metaheuristic algorithms is to enable the
capability of carrying out global search, and good examples of nature-inspired metaheuristics are
particle swarm optimisation (PSO) and Cuckoo Search . Most metaheuristic algorithms have relatively high eﬃciency in terms of ﬁnding global
optimality.
The eﬃciency of metaheuristic algorithms can be attributed to the fact that they are designed
to imitate the best features in nature, especially the selection of the ﬁttest in biological systems
which have evolved by natural selection over millions of years. In real-world applications, most data
have noise or associated randomness to a certain degree, some modiﬁcations to these algorithms are
Objective functions f1(x), ..., fN(x)
Initialization and random initial guess xt=0
while (stop criterion)
Global exploration by randomization
Evaluate the objectives and ﬁnd a promising solution
Intensive local search around a promising solution
via an eﬃcient local optimizer
if (a better solution is found)
Update the current best
Update t = t + 1
Post-process the results and visualization.
Figure 1: Pseudo code of the eagle strategy.
often required, in combination with some form of averaging or reformulation of the problem. There
exist some algorithms for stochastic optimization, and the Eagle Strategy (ES), develop by Yang
and Deb, is one of such algorithms for dealing with stochastic optimization .
In this paper, we will investigate the Eagle Strategy further by hybridizing it with diﬀerential
evolution .
We ﬁrst validate the ES by
some multimodal test functions and then apply it to real-world optimization problems. Case studies
include pressure vessel design and gearbox speed reducer design. We will discuss the results and
point out directions for further research.
Eagle Strategy
Eagle strategy developed by Xin-She Yang and Suash Deb is a two-stage
method for optimization. It uses a combination of crude global search and intensive local search
employing diﬀerent algorithms to suit diﬀerent purposes. In essence, the strategy ﬁrst explores the
search space globally using a L´evy ﬂight random walk, if it ﬁnds a promising solution, then an
intensive local search is employed using a more eﬃcient local optimizer such as hill-climbing and
downhill simplex method. Then, the two-stage process starts again with new global exploration
followed by a local search in a new region.
The advantage of such a combination is to use a balanced tradeoﬀbetween global search which
is often slow and a fast local search. Some tradeoﬀand balance are important. Another advantage
of this method is that we can use any algorithms we like at diﬀerent stages of the search or even at
diﬀerent stages of iterations. This makes it easy to combine the advantages of various algorithms so
as to produce better results.
It is worth pointing that this is a methodology or strategy, not an algorithm. In fact, we can
use diﬀerent algorithms at diﬀerent stages and at diﬀerent time of the iterations. The algorithm
used for the global exploration should have enough randomness so as to explore the search space
diversely and eﬀectively. This process is typically slow initially, and should speed up as the system
converges (or no better solutions can be found after a certain number of iterations). On the other
hand, the algorithm used for the intensive local exploitation should be an eﬃcient local optimizer.
The idea is to reach the local optimality as quickly as possible, with the minimal number of function
evaluations. This stage should be fast and eﬃcient.
Diﬀerential Evolution
Diﬀerential evolution (DE) was developed by R. Storn and K. Price by their nominal papers in
1996 and 1997 . It is a vector-based evolutionary algorithm,
and can be considered as a further development to genetic algorithms. It is a stochastic search
algorithm with self-organizing tendency and does not use the information of derivatives. Thus, it is
a population-based, derivative-free method. Another advantage of diﬀerential evolution over genetic
algorithms is that DE treats solutions as real-number strings, thus no encoding and decoding is
As in genetic algorithms, design parameters in a d-dimensional search space are represented as
vectors, and various genetic operators are operated over their bits of strings. However, unlikely
genetic algorithms, diﬀerential evolution carries out operations over each component (or each dimension of the solution). Almost everything is done in terms of vectors. For example, in genetic
algorithms, mutation is carried out at one site or multiple sites of a chromosome, while in diﬀerential
evolution, a diﬀerence vector of two randomly-chosen population vectors is used to perturb an existing vector. Such vectorized mutation can be viewed as a self-organizing search, directed towards
an optimality. This kind of perturbation is carried out over each population vector, and thus can be
expected to be more eﬃcient. Similarly, crossover is also a vector-based component-wise exchange
of chromosomes or vector segments.
For a d-dimensional optimization problem with d parameters, a population of n solution vectors
are initially generated, we have xi where i = 1, 2, ..., n. For each solution xi at any generation t, we
use the conventional notation as
2,i, ..., xt
which consists of d-components in the d-dimensional space. This vector can be considered as the
chromosomes or genomes.
Diﬀerential evolution consists of three main steps: mutation, crossover and selection.
Mutation is carried out by the mutation scheme. For each vector xi at any time or generation
t, we ﬁrst randomly choose three distinct vectors xp, xq and xr at t, and then generate a so-called
donor vector by the mutation scheme
where F ∈ is a parameter, often referred to as the diﬀerential weight. This requires that the
minimum number of population size is n ≥4. In principle, F ∈ , but in practice, a scheme with
F ∈ is more eﬃcient and stable. The perturbation δ = F(xq −xr) to the vector xp is used to
generate a donor vector vi, and such perturbation is directed and self-organized.
The crossover is controlled by a crossover probability Cr ∈ and actual crossover can be
carried out in two ways: binomial and exponential. The binomial scheme performs crossover on
each of the d components or variables/parameters. By generating a uniformly distributed random
number ri ∈ , the jth component of vi is manipulated as
j,i = vj,i
otherwise it remains unchanged. This way, each component can be decided randomly whether to
exchange with donor vector or not.
Selection is essentially the same as that used in genetic algorithms. It is to select the most ﬁttest,
and for minimization problem, the minimum objective value.
Most studies have focused on the choice of F, Cr and n as well as the modiﬁcation of (2). In
fact, when generating mutation vectors, we can use many diﬀerent ways of formulating (2), and this
leads to various schemes with the naming convention: DE/x/y/z where x is the mutation scheme
(rand or best), y is the number of diﬀerence vectors, and z is the crossover scheme (binomial or
exponential). The basic DE/Rand/1/Bin scheme is given in (2). For a detailed review on diﬀerent
schemes, please refer to Price et al. .
ES with DE
As ES is a two-stage strategy, we can use diﬀerent algorithms at diﬀerent stage. The large-scale
coarse search stage can use randomization via L´evy ﬂights In the context of metaheuristics, the socalled L´evy distribution is a distribution of the sum of N identically and independently distribution
random variables .
This distribution is deﬁned by a Fourier transform in the following form
FN(k) = exp[−N|k|β].
The inverse to get the actual distribution L(s) is not straightforward, as the integral
cos(τs)e−α τ βdτ,
(0 < β ≤2),
does not have analytical forms, except for a few special cases. Here L(s) is called the L´evy distribution with an index β. For most applications, we can set α = 1 for simplicity. Two special cases are
β = 1 and β = 2. When β = 1, the above integral becomes the Cauchy distribution. When β = 2, it
becomes the normal distribution. In this case, L´evy ﬂights become the standard Brownian motion.
For the second stage, we can use diﬀerential evolution as the intensive local search. We know
DE is a global search algorithm, it can easily be tuned to do eﬃcient local search by limiting new
solutions locally around the most promising region. Such a combination may produce better results
than those by using pure DE only, as we will demonstrate this later. Obviously, the balance of local
search (intensiﬁcation) and global search (diversiﬁcation) is very important, and so is the balance
of the ﬁrst stage and second stage in the ES.
Validation
Using our improved ES with DE, we can ﬁrst validate it against some test functions which are highly
nonlinear and multimodal.
There are many test functions, here we have chosen the following 5 functions as a subset for our
validation.
Ackley’s function
f(x) = −20 exp
where d = 1, 2, ..., and −32.768 ≤xi ≤32.768 for i = 1, 2, ..., d. This function has the global minimum f∗= 0 at x∗= (0, 0, ..., 0).
The simplest of De Jong’s functions is the so-called sphere function
−5.12 ≤xi ≤5.12,
whose global minimum is obviously f∗= 0 at (0, 0, ..., 0). This function is unimodal and convex.
Rosenbrock’s function
(xi −1)2 + 100(xi+1 −x2
whose global minimum f∗= 0 occurs at x∗= (1, 1, ..., 1) in the domain −5 ≤xi ≤5 where
i = 1, 2, ..., d. In the 2D case, it is often written as
f(x, y) = (x −1)2 + 100(y −x2)2,
which is often referred to as the banana function.
Schwefel’s function
, −500 ≤xi ≤500,
whose global minimum f∗≈−418.9829n occurs at xi = 420.9687 where i = 1, 2, ..., d.
Shubert’s function
i + (i + 1)x
i + (i + 1)y
which has multiple global minima f∗≈−186.7309 for K = 5 in the search domain −10 ≤x, y ≤10.
Table I summarizes the results of our simulations, where 9.7% corresponds to the ratio of the
number of function evaluations in ES to the number of function evaluations in DE. That is the
computational eﬀort in ES is only about 9.7% of that using pure DE. As we can see that ES with
DE is signiﬁcantly better than pure DE.
Table 1: Ratios of computational time
Ackley (d = 8)
De Jong (d = 16)
Rosenbrock (d = 8)
Schwefel (d = 8)
Design Benchmarks
Now we then use the ES with DE to solve some real-world case studies including pressure vessel and
speed reducer problems.
Pressure Vessel Design
Pressure vessels are literally everywhere such as champagne bottles and gas tanks.
For a given
volume and working pressure, the basic aim of designing a cylindrical vessel is to minimize the total
cost. Typically, the design variables are the thickness d1 of the head, the thickness d2 of the body,
the inner radius r, and the length L of the cylindrical section .
This is a well-known test problem for optimization and it can be written as
minimize f(x) = 0.6224d1rL + 1.7781d2r2
1L + 19.84d2
subject to the following constraints
g1(x) = −d1 + 0.0193r ≤0
g2(x) = −d2 + 0.00954r ≤0
g3(x) = −πr2L −4π
3 r3 + 1296000 ≤0
g4(x) = L −240 ≤0.
The simple bounds are
0.0625 ≤d1, d2 ≤99 × 0.0625,
Table 2: Comparison of number of function evaluations
Case study
Pressure vessel
Speed reducer
Recently, Cagnina et al. used an eﬃcient particle swarm optimiser to solve this problem
and they found the best solution f∗≈6059.714 at
x∗≈(0.8125, 0.4375, 42.0984, 176.6366).
This means the lowest price is about $6059.71.
Using ES, we obtained the same results, but we used signiﬁcantly fewer function evaluations,
comparing using pure DE and other methods. This again suggests ES is very eﬃcient.
Speed Reducer Design
Another important benchmark is the design of a speed reducer which is commonly used in many
mechanisms such as a gearbox . This problem involves the optimization of 7 variables, including the face width, the number of teeth, the diameter of the shaft and others. All
variables are continuous within some limits, except x3 which only takes integer values.
f(x) = 0.7854x1x2
2(3.3333x2
3 + 14.9334x3 −43.0934)
−1.508x1(x2
7) + 7.4777(x3
+0.7854(x4x2
g2(x) = 397.5
g3(x) = 1.93x3
g4(x) = 1.93x3
+ 16.9 × 106 −1 ≤0
g6(x) = 1.0
+ 157.5 × 106 −1 ≤0
g7(x) = x2x3
g8(x) = 5x2
g10(x) = 1.5x6 + 1.9
g11(x) = 1.1x7 + 1.9
where the simple bounds are 2.6 ≤x1 ≤3.6, 0.7 ≤x2 ≤0.8, 17 ≤x3 ≤28, 7.3 ≤x4 ≤8.3,
7.8 ≤x5 ≤8.4, 2.9 ≤x6 ≤3.9, and 5.0 ≤x7 ≤5.5.
In one of latest studies, Cagnina et al. obtained the following solution
x∗= (3.5, 0.7, 17, 7.3, 7.8, 3.350214, 5.286683)
with fmin = 2996.348165.
Using our ES, we have obtained the new best
x∗= (3.5, 0.7, 17, 7.3, 7.8, 3.34336449, 5.285351)
with the best objective fmin = 2993.7495888. We can see that ES not only provides better solutions
but also ﬁnds solutions more eﬃciently using fewer function evaluations.
Discussions
Metaheuristic algorithms such as diﬀerential evolution and eagle strategy are very eﬃcient. We
have shown that a proper combination of these two can produce even better performance for solving
nonlinear global optimization problems. First, we have validated the ES with DE and compared
their performance. We then used them to solve real-world optimization problems including pressure
vessel and speed reducer design. Same or better results have been obtained, but with signiﬁcantly
less computational eﬀort.
Further studies can focus on the sensitivity studies of the parameters used in ES and DE so as to
identify optimal parameter ranges for most applications. Combinations of ES with other algorithms
may also prove fruitful. Furthermore, convergence analysis can provide even more profound insight
into the working of these algorithms.