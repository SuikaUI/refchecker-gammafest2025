Algorithms and Theory
for Multiple-Source Adaptation
Judy Hoffman
CS Department Stanford University
Stanford, CA 94305
 
Mehryar Mohri
Courant Institute and Google
New York, NY 10012
 
Ningshan Zhang
New York University
New York, NY 10012
 
This work includes a number of novel contributions for the multiple-source adaptation problem. We present new normalized solutions with strong theoretical
guarantees for the cross-entropy loss and other similar losses. We also provide
new guarantees that hold in the case where the conditional probabilities for the
source domains are distinct. Moreover, we give new algorithms for determining
the distribution-weighted combination solution for the cross-entropy loss and other
losses. We report the results of a series of experiments with real-world datasets.
We ﬁnd that our algorithm outperforms competing approaches by producing a
single robust model that performs well on any target mixture distribution. Altogether, our theory, algorithms, and empirical results provide a full solution for the
multiple-source adaptation problem with very practical beneﬁts.
Introduction
In many modern applications, often the learner has access to information about several source
domains, including accurate predictors possibly trained and made available by others, but no direct
information about a target domain for which one wishes to achieve a good performance. The target
domain can typically be viewed as a combination of the source domains, that is a mixture of their
joint distributions, or it may be close to such mixtures. In addition, often the learner does not have
access to all source data simultaneously, for legitimate reasons such as privacy, storage limitation, etc.
Thus the learner cannot simply pool all source data together to learn a predictor.
Such problems arise commonly in speech recognition where different groups of speakers (domains)
yield different acoustic models and the problem is to derive an accurate acoustic model for a broader
population that may be viewed as a mixture of the source groups [Liao, 2013]. In object recognition,
multiple image databases exist, each with its own bias and labeled categories [Torralba and Efros,
2011], but the target application may contain images which most closely resemble only a subset of
the available training data. Finally, in sentiment analysis, accurate predictors may be available for
sub-domains such as TVs, laptops and CD players, each previously trained on labeled data, but no
labeled data or predictor may be at the learner’s disposal for the more general category of electronics,
which can be modeled as a mixture of the sub-domains [Blitzer et al., 2007, Dredze et al., 2008].
The problem of transfer from a single source to a known target domain, either through unsupervised
adaptation techniques [Gong et al., 2012, Long et al., 2015, Ganin and Lempitsky, 2015, Tzeng et al.,
 
 
2015], or via lightly supervised ones (some amount of labeled data from the target domain) [Saenko
et al., 2010, Yang et al., 2007, Hoffman et al., 2013, Girshick et al., 2014], has been extensively
investigated in the past. Here, we focus on the problem of multiple-source domain adaptation and
ask how the learner can combine relatively accurate predictors available for each source domain to
derive an accurate predictor for any new mixture target domain? This is known as the multiple-source
adaption (MSA) problem ﬁrst formalized and analyzed theoretically by Mansour et al. 
and later studied for various applications such as object recognition [Hoffman et al., 2012, Gong et al.,
2013a,b]. Recently, Zhang et al. studied a causal formulation of this problem and analyzed the
same combination rules of Mansour et al. for classiﬁcation scenario. A closely related
problem is also that of domain generalization [Pan and Yang, 2010, Muandet et al., 2013, Xu et al.,
2014], where knowledge from an arbitrary number of related domains is combined to perform well
on a previously unseen domain.
Mansour et al. gave strong theoretical guarantees for a distribution-weighted combination
for the MSA problem, but they did not provide any algorithmic solution. Furthermore, the solution
they proposed could not be used for loss functions such as cross-entropy, which require a normalized
predictor. Their work also assumed a deterministic scenario (non-stochastic) with the same labeling
function for all source domains.
This work makes a number of novel contributions to the MSA problem. We give new normalized
solutions with strong theoretical guarantees for the cross-entropy loss and other similar losses. Our
guarantees hold even when the conditional probabilities for the source domains are distinct. A
by-product of our analysis is the extension of the theoretical results of Mansour et al. to
the stochastic scenario, where there is a joint distribution over the input and output space.
Moreover, we give new algorithms for determining the distribution-weighted combination solution
for the cross-entropy loss and other losses. We prove that the problem of determining that solution
can be cast as a DC-programming (difference of convex) and prove explicit DC-decompositions for
the cross-entropy loss and other losses. We also give a series of experimental results with several
datasets demonstrating that our distribution-weighted combination solution is remarkably robust. Our
algorithm outperforms competing approaches and performs well on any target mixture distribution.
Altogether, our theory, algorithms, and empirical results provide a full solution for the MSA problem
with very practical beneﬁts.
Problem setup
Let X denote the input space and Y the output space. We consider a multiple-source domain
adaptation (MSA) problem in the general stochastic scenario where there is a distribution over
the joint input-output space, X × Y. This is a more general setup than the deterministic scenario
in [Mansour et al., 2008, 2009], where a target function mapping from X to Y is assumed. This
extension is needed for the analysis of the most common and realistic learning setups in practice. We
will assume that X and Y are discrete, but the predictors we consider can take real values. Our theory
can be straightforwardly extended to the continuous case with summations replaced by integrals in
the proofs. We will identify a domain with a distribution over X × Y and consider the scenario where
the learner has access to a predictor hk, for each domain Dk, k = 1, . . . , p.
We consider two types of predictor functions hk, and their associated loss functions L under the
regression model (R) and the probability model (P) respectively,
L: R × Y →R+
hk : X × Y → 
L: →R+
We abuse the notation and write L(h, x, y) to denote the loss of a predictor h at point (x, y), that
is L(h(x), y) in the regression model, and L(h(x, y)) in the probability model. We will denote by
L(D, h) the expected loss of a predictor h with respect to the distribution D:
L(h, x, y)
D(x, y)L(h, x, y).
Much of our theory only assumes that L is convex and continuous. But, we will be particularly
interested in the case where in the regression model, L(h(x), y) = (h(x) −y)2 is the squared loss,
and where in the probability model, L(h(x, y)) = −log h(x, y) is the cross-entropy loss (log-loss).
We will assume that each hk is a relatively accurate predictor for the distribution Dk: there exists
ϵ > 0 such that L(Dk, hk) ≤ϵ for all k ∈[p]. We will also assume that the loss of the source
hypotheses hk is bounded, that is L(hk, x, y) ≤M for all (x, y) ∈X × Y and all k ∈[p].
In the MSA problem, the learner’s objective is to combine these predictors to design a predictor with
small expected loss on a target domain that could be an arbitrary and unknown mixture of the source
domains, the case we are particularly interested in, or even some other arbitrary distribution. It is
worth emphasizing that the leaner has no knowledge of the target domain.
How do we combine the hks? Can we use a convex combination rule, Pp
k=1 λkhk, for some λ ∈∆?
In Appendix A (Lemmas 7 and 8) we show that no convex combination rule will perform well even
in very simple MSA problems. These results generalize a previous lower bound of Mansour et al.
 . Next, we show that the distribution-weighted combination rule is the right solution.
Extending the deﬁnition given by Mansour et al. , we deﬁne the distribution-weighted combination of the functions hk, k ∈[p] as follows. For any z ∈∆, η > 0, and (x, y) ∈X × Y,
k(x) + η U1(x)
k(x) + ηU1(x)hk(x),
zkDk(x, y) + η U(x,y)
j=1 zjDj(x, y) + η U(x, y)hk(x, y),
where we denote by D1(x) the marginal distribution over X: D1(x) = P
y∈Y D(x, y), and U1(x)
the uniform distribution over X. This extension may seem technically straightforward in hindsight,
but the form of the predictor was not immediately clear in the stochastic case.
Theoretical analysis
In this section, we present theoretical analyses of the general multiple-source adaptation setting. We
ﬁrst introduce our main result for the general stochastic scenario. Next, for the probability model
with cross-entropy loss, we introduce a normalized distribution weighted combination and prove that
it beneﬁts from strong theoretical guarantees.
Our theoretical results rely on the measure of divergence between distributions. The one that
naturally comes up in our analysis is the Rényi Divergence [Rényi, 1961]. We will denote by
dα(D ∥D′) = eDα(D∥D′) the exponential of the α-Rényi Divergence of two distributions D and D′.
More details of the Rényi Divergence are given in Appendix F.
Stochastic scenario
Let DT be an unknown target distribution. We will denote by DT (·|x) and Dk(·|x) the conditional
probability distribution on the target and the source domain respectively. Given the same input
x, DT (·|x), Dk(·|x), k ∈[p] are not necessarily the same. This is a novel extension that was not
discussed in [Mansour et al., 2009], where in the deterministic scenario, exactly the same labeling
function f is assumed for all source domains.
For some choice of α > 1, deﬁne ϵT by
k(x)dα (DT (·|x)∥Dk(·|x))α−1
When the average divergence is small, α can be chosen to be very large and ϵT is close to ϵ.
Let DT be a mixture of source distributions, such that D1
T ∈D1 = {Pp
k : λ ∈∆} in the
regression model (R), or DT ∈D = {Pp
k=1 λkDk : λ ∈∆} in the probability model (P).
Theorem 1. For any δ > 0, there exists η > 0 and z ∈∆such that the following inequalities hold
for any α > 1:
z) ≤ϵT + δ,
z) ≤ϵ + δ.
The proof is given in Appendix B. The learning guarantees for the regression and the probability
model are slightly different, since the deﬁnitions of the distribution-weighted combinations are
different for the two models. Theorem 1 shows the existence of η > 0 and a mixture weight z ∈∆
with a remarkable property: in the regression model (R), for any target distribution DT whose
conditional probability DT (·|x) is on average not too far away from Dk(·|x) for any k ∈[p], and
T ∈D1, the loss of hη
z on DT is small. It is even more remarkable that, in the probability model
(P), the loss of hη
z is at most ϵ on any target distribution DT ∈D. Therefore, hη
z is a robust hypothesis
with favorable property for any such target distribution DT .
In many learning tasks, it is reasonable to assume that the conditional probability of the output labels
is the same for all source domains. For example, a dog picture represents a dog regardless of whether
the dog appears in an individual’s personal set of pictures or in a broader database of pictures from
multiple individuals. This is a straightforward extension of the assumption adopted by Mansour et al.
 in the deterministic scenario, where exactly the same labeling function f is assumed for all
source domains. Then DT (·|x) = Dk(·|x), ∀k ∈[p]. By deﬁnition, dα (DT (·|x)∥Dk(·|x)) = 1. Let
α →+∞, we recover the main result of Mansour et al. .
Corollary 2. Assume the conditional probability Dk(·|x) does not depend on k. Let Dλ be an
arbitrary mixture of source domains, λ ∈∆. For any δ > 0, there exists η > 0 and z ∈∆, such that
z) ≤ϵ + δ.
Corollary 2 shows the existence of a mixture weight z ∈∆and η > 0 with a remarkable property:
for any δ > 0, regardless of which mixture weight λ ∈∆deﬁnes the target distribution, the loss of
z is at most ϵ + δ, that is arbitrarily close to ϵ. hη
z is therefore a robust hypothesis with a favorable
property for any mixture target distribution.
To cover the realistic cases in applications, we further extend this result to the case where the distributions Dk are not directly available to the learner, and instead estimates bDk have been derived from
data, and further to the case where the target distribution DT is not a mixture of source distributions
(Corollary 11 in Appendix B). We will denote by bhη
z the distribution-weighted combination rule
based on the estimates bDk. Our learning guarantee for bhη
z depends on the Rényi divergence of bDk
and Dk, as well as the Rényi divergence of DT and the family of source mixtures.
Probability model with the cross-entropy loss
Next, we discuss the special case where L coincide with the cross-entropy loss in the probability
model, and present an analysis for a normalized distribution-weighted combination solution. This
analysis is a complement to Theorem 1, which only works for the unnormalized hypothesis hη
The cross-entropy loss assumes normalized hypotheses. Thus, the source functions are normalized for
every x: P
y∈Y hk(x, y) = 1, ∀x ∈X, ∀k ∈[p]. For any z ∈∆, η > 0, we deﬁne the normalized
weighted combination h
z(x, y) that is based on hη
z(x, y) in (2):
z(x, y) = hη
We will ﬁrst assume the conditional probability Dk(·|x) does not depend on k.
Theorem 3. Assume there exists µ > 0 such that Dk(x, y) ≥µU(x, y) for all k ∈[p] and
(x, y) ∈X × Y. Then, for any δ > 0, there exists η > 0 and z ∈∆, such that L(Dλ, h
for any mixture parameter λ ∈∆.
The result of Theorem 3 admits the same favorable property as that of Corollary 2. It can also be
extended to the case of arbitrary target distributions and estimated densities. When the conditional
probabilities are different across the source domains, we propose a marginal distribution-weighted
combination rule, which is already normalized. We can directly apply Theorem 1 to it and achieve
favorable guarantees. More details are given in Appendix C.
These results are non-trivial and important, as they provide a guarantee for an accurate and robust
predictor for a commonly used loss function, the cross-entropy loss.
Algorithms
We have shown that, for both the regression and the probability model, there exists a vector z deﬁning
a distribution-weighted combination hypothesis hη
z that admits very favorable guarantees. But how
we ﬁnd a such z? This is a key question in the MSA problem which was not addressed by Mansour
et al. : no algorithm was previously reported to determine the mixture parameter z (even
for the deterministic scenario). Here, we give an algorithm for determining that vector z.
In this section, we give practical and efﬁcient algorithms for ﬁnding the vector z in the important
cases of the squared loss in the regression model, or the cross-entropy loss in the probability model, by
leveraging the differentiability of the loss functions. We ﬁrst show that z is the solution of a general
optimization problem. Next, we give a DC-decomposition (difference of convex decomposition)
of the objective for both models, thereby proving an explicit DC-programming formulation of the
problem. This leads to an efﬁcient DC algorithm that is guaranteed to converge to a stationary point.
Additionally, we show that it is straightforward to test if the solution obtained is the global optimum.
While we are not proving that the local stationary point found by our algorithm is the global optimum,
empirically, we observe that that is indeed the case.
Optimization problem
Theorem 1 shows that the hypothesis hη
z based on the mixture parameter z beneﬁts from a strong
generalization guarantee. A key step in proving Theorem 1 is to show the following lemma.
Lemma 4. For any η, η′ > 0, there exists z ∈∆, with zk ̸= 0 for all k ∈[p], such that the following
holds for the distribution-weighted combining rule hη
zjL(Dj, hη
Lemma 4 indicates that for the solution z, hη
z has essentially the same loss on all source domains.
Thus, our problem consists of ﬁnding a parameter z verifying this property. This, in turn, can
be formulated as a min-max problem: minz∈∆maxk∈[p] L(Dk, hη
z) −L(Dz, hη
z), which can be
equivalently formulated as the following optimization problem:
s.t. L(Dk, hη
z) −L(Dz, hη
z) ≤γ, ∀k ∈[p].
DC-decomposition
We provide explicit DC decompositions of the objective of Problem (4) for the regression model with
the squared loss and the probability model with the cross-entropy loss. The full derivations are given
in Appendix D.
We ﬁrst rewrite hη
z as the division of two afﬁne functions for the regression model (R) and the
probability model (P): hz = Jz/Kz, where
k(x)hk(x) + η
pU1(x)hk(x),
Kz(x) = D1
z(x) + η U1(x),
Jz(x, y) =
zkDk(x, y)hk(x, y) + η
pU(x, y)hk(x, y),
Kz(x, y) = Dz(x, y) + η U(x, y)
Proposition 5 (Regression model, square loss). Let L be the squared loss. Then, for any k ∈[p],
z) −L(Dz, hη
z) = uk(z) −vk(z), where uk and vk are convex functions deﬁned for all z by
 Dk + ηU1Dk(·|x), hη
k + ηU1)(x) log Kz(x),
 Dz + ηU1Dk(·|x), hη
k + ηU1)(x) log Kz(x).
Proposition 6 (Probability model, cross-entropy loss). Let L be the cross-entropy loss. Then, for
k ∈[p], L(Dk, hη
z) −L(Dz, hη
z) = uk(z) −vk(z), where uk and vk are convex functions:
Dk(x, y) + η U(x, y)
log Jz(x, y),
Kz(x, y) log
−[Dk(x, y) + η U(x, y)] log Kz(x, y).
DC algorithm
Our DC decompositions prove that the optimization problem (4) can be cast as the following
variational form of a DC-programming problem [Tao and An, 1997, 1998, Sriperumbudur and
Lanckriet, 2012]:
 uk(z) −vk(z) ≤γ
k=1 zk −1 = 0
The DC-programming algorithm works as follows. Let (zt)t be the sequence deﬁned by repeatedly
solving the following convex optimization problem:
zt+1 ∈argmin
 uk(z) −vk(zt) −(z −zt)∇vk(zt) ≤γ
k=1 zk −1 = 0
where z0 ∈∆is an arbitrary starting value. Then, (zt)t is guaranteed to converge to a local
minimum of Problem (4) [Yuille and Rangarajan, 2003, Sriperumbudur and Lanckriet, 2012]. Note
that Problem (6) is a relatively simple optimization problem: uk(z) is a weighted sum of the negative
logarithm of an afﬁne function of z, plus a weighted sum of rational functions of z (squared loss),
and all other terms appearing in the constraints are afﬁne functions of z.
Problem (4) seeks a parameter z verifying L(Dk, hη
z) −L(Dz, hη
z) ≤γ, for all k ∈[p] for an
arbitrarily small value of γ. Since L(Dz, hη
k=1 zkL(Dk, hη
z) is a weighted average of the
expected losses L(Dk, hη
z), k ∈[p], the solution γ cannot be negative. Furthermore, by Lemma 4, a
parameter z verifying that inequality exists for any γ > 0. Thus, the global solution γ of Problem (4)
must be close to zero. This provides us with a simple criterion for testing the global optimality of the
solution z we obtain using a DC-programming algorithm with a starting parameter z0.
Experiments
This section reports the results of our experiments with our DC-programming algorithm for ﬁnding
a robust domain generalization solution when using squared loss and cross-entropy loss. We ﬁrst
evaluate our algorithm using an artiﬁcial dataset assuming known densities where we may compare
our result to the global solution and found that indeed our global objective approached the known
optimum of zero (see Appendix E for more details). Next, we evaluate our DC-programming solution
applied to real-world datasets: a sentiment analysis dataset [Blitzer et al., 2007] for squared loss, a
visual domain adaptation benchmark dataset Ofﬁce [Saenko et al., 2010], as well as a generalization
of digit recognition task, for cross-entropy loss.
For all real-world datasets, the probability distributions Dk are not readily available to the learner.
However, Corollary 11 extends the learning guarantees of our solution to the case where an estimate
bDk is used in lieu of the ideal distribution Dk. Thus, we used standard density estimation methods to
derive an estimate bDk for each k ∈[p]. While density estimation can be a difﬁcult task in general,
for our purpose straightforward techniques are sufﬁcient for our predictor bhη
z to achieve a high
performance, since the approximate densities only serve to indicate the relative importance of each
source domain. We give full details of our density estimation procedure in Appendix E.
Sentiment analysis task for squared loss
We use the sentiment analysis dataset proposed by Blitzer et al. and used for multiple-source
adaptation by Mansour et al. . This dataset consists of product review text and rating
Figure 1: MSE sentiment analysis under mixture of two domains: (left) dvd and electronics or (right)
kitchen and books.
Table 1: MSE on the sentiment analysis dataset of source-only baselines for each domain, K,D, B,E,
the uniform weighted predictor unif, KMM, and the distribution-weighted method DW based on the
learned z. DW outperforms all competing baselines.
labels taken from four domains: books (B), dvd (D), electronics (E), and kitchen (K), with
2000 samples for each domain. We deﬁned a vocabulary of 2,500 words that occur at least twice at
the intersection of the four domains. These words were used to deﬁne feature vectors, where every
sample is encoded by the number of occurrences of each word. We trained our base hypotheses using
support vector regression (SVR) with same hyper-parameters as in [Mansour et al., 2008, 2009].
We compare our method (DW) against each source hypothesis, hk. We also compute a privileged
baseline using the oracle λ mixing parameter, λ-comb: Pp
k=1 λkhk. λ-comb is of course not
accessible in practice since the target mixture λ is not known to the user. We also compare against
a previously proposed domain adaptation algorithm [Huang et al., 2006] known as KMM. It is
important to note that the KMM model requires access to the unlabeled target data during adaptation
and learns a new predictor for every target domain, while DW does not use any target data. Thus
KMM operates in a favorable learning setting when compared to our solution.
We ﬁrst considered the same test scenario as in [Mansour et al., 2008], where the target is a mixture of
two source domains. The plots of Figures 1a and 1b report the results of our experiments. They show
that our distribution-weighted predictor DW outperforms all baseline predictors despite the privileged
learning scenarios of λ-comb and KMM. We didn’t compare to the “weighted” predictor in empirical
studies by Mansour et al. because it is not a real solution, but rather taking the unknown target
mixture λ as z to compute hz.
Next, we compared the performance of DW with accessible baseline predictors on various target
mixtures. Since λ is not accessible in practice, We replace λ-comb with the uniform combination
of all hypotheses (unif), Pp
k=1 hk/p. Table 1 reports the mean and standard deviations of MSE
over 10 repetitions. Each column corresponds to a different target test data source. Our distributionweighted method DW outperforms all baseline predictors across all test domains. Observe that, even
when the target is a single source domain, our method successfully outperforms the predictor which is
trained and tested on the same domain. Results on more target mixtures are available in Appendix E.
Recognition tasks for cross-entropy loss
We consider two real-world domain adaptation tasks: a generalization of digit recognition task, and a
standard visual adaptation Ofﬁce dataset.
For each individual domain, we train a convolutional neural network (CNN) and use the output from
the softmax score layer as our base predictors hk. We compute the uniformly weighted combination
Table 2: Digit dataset statistics.
# train images
# test images
image size
Table 3: Digit dataset accuracy: We report accuracy
across six possible test domains.
Table 4: Ofﬁce dataset accuracy: We report accuracy across six possible test domains. We show
performance all baselines: CNN-a,w,d, CNN-unif, DW based on the learned z, and the jointly
trained model CNN-joint. DW outperforms all competing models.
75.7 ± 0.3
53.8 ± 0.7
53.4 ± 1.3
71.4 ± 0.3
73.5 ± 0.2
53.6 ± 0.8
69.9 ± 0.3
64.5 ± 0.6
45.3 ± 0.5
91.1 ± 0.8
91.7 ± 1.2
54.4 ± 0.5
50.0 ± 0.5
91.3 ± 0.8
57.5 ± 0.4
68.8 ± 0.7
50.4 ± 0.4
89.6 ± 0.9
90.9 ± 0.8
58.3 ± 0.4
54.6 ± 0.4
90.0 ± 0.7
61.0 ± 0.4
70.7 ± 0.6
69.7 ± 0.3
93.1 ± 0.6
93.2 ± 0.9
74.4 ± 0.4
72.1 ± 0.3
93.1 ± 0.5
75.9 ± 0.3
81.6 ± 0.5
75.2 ± 0.4
93.7 ± 0.6
94.0 ± 1.0
78.9 ± 0.4
77.2 ± 0.4
93.8 ± 0.6
80.2 ± 0.3
84.7 ± 0.5
72.1 ± 0.3
93.7 ± 0.5
93.7 ± 0.5
76.4 ± 0.4
76.4 ± 0.4
93.7 ± 0.5
79.3 ± 0.4
83.6 ± 0.4
of source predictors, hunif = Pp
k=1 hk/p. As a privileged baseline, we also train a model on
all source data combined, hjoint. Note, this approach is often not feasible if independent entities
contribute classiﬁers and densities, but not full training datasets. Thus this approach is not consistent
with our scenario, and it operates in a much more favorable learning setting than our solution. Finally,
our distribution weighted predictor DW is computed with hks, density estimates, and our learned
weighting, z. Our baselines then consists of the classiﬁers from hk, hunif, hjoint, and DW.
We begin our study with a generalization of digit recognition task, which consists of three digit
recognition datasets: Google Street View House Numbers (SVHN), MNIST, and USPS. Dataset
statistics as well as example images can be found in Table 2. We train the ConvNet (or CNN)
architecture following Taigman et al. as our source models and joint model. We use the
second fully-connected layer’s output as our features for density estimation, and the output from
the softmax score layer as our predictors. We use the full training sets per domain to learn the
source model and densities. Note, these steps are completely isolated from one another and may be
performed by unique entities and in parallel. Finally, for our DC-programming algorithm we use
small subset of 200 real image-label pairs from each domain to learn the parameter z.
Our next experiment uses the standard visual adaptation Ofﬁce dataset, which has 3 domains:
amazon, webcam, and dslr. The dataset contains 31 recognition categories of objects commonly
found in an ofﬁce environment. There are 4110 images total with 2817 from amazon, 795 from
webcam, and 498 from dslr. We follow the standard protocol from Saenko et al. , whereby
20 labeled examples are available for training from the amazon domain and 8 labeled examples are
available from both the webcam and dslr domains. The remaining examples from each domain
are used for testing. We use the AlexNet Krizhevsky et al. ConvNet (CNN) architecture, and
use the output from softmax score layer as our base predictors, pre-trained on ImageNet and use fc7
activations as our features for density estimation Donahue et al. .
We report the performance of our method and that of baselines on the digit recognition dataset in
Table 3, and report the performance on the Ofﬁce dataset in Table 4. On both datasets, we evaluate
on various test distributions: each individual domain, the combination of each two domains and the
fully combined set. When the test distribution equals one of the source distributions, our distributionweighted classiﬁer successfully outperforms (webcam,dslr) or maintains performance of the
classiﬁer which is trained and tested on the same domain. For the more realistic scenario where the
target domain is a mixture of any two or all three source domains, the performance of our method
is comparable or marginally superior to that of the jointly trained network, despite the fact that
we do not retrain any network parameters in our method and that we only use a small number of
per-domain examples to learn the distribution weights – an optimization which may be solved on a
single CPU in a matter of seconds for this problem. This again demonstrates the robustness of our
distribution-weighted combined classiﬁer to a varying target domain.
Conclusion
We presented practically applicable multiple-source domain adaptation algorithms for the crossentropy loss and other similar losses. These algorithms beneﬁt from very favorable theoretical
guarantees that we extended to the stochastic setting. Our empirical results further demonstrate
empirically their effectiveness and their importance in adaptation problems.