IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 20, NO. 12, DECEMBER 1998
Bayesian Classification
With Gaussian Processes
Christopher K.I. Williams, Member, IEEE Computer Society, and David Barber
Abstract—We consider the problem of assigning an input vector to one of m classes by predicting P(c|x) for c = 1, º, m. For a twoclass problem, the probability of class one given x is estimated by s(y(x)), where s(y) = 1/(1 + e-y). A Gaussian process prior is
placed on y(x), and is combined with the training data to obtain predictions for new x points. We provide a Bayesian treatment,
integrating over uncertainty in y and in the parameters that control the Gaussian process prior; the necessary integration over y is
carried out using Laplace’s approximation. The method is generalized to multiclass problems (m > 2) using the softmax function. We
demonstrate the effectiveness of the method on a number of datasets.
Index Terms—Gaussian processes, classification problems, parameter uncertainty, Markov chain Monte Carlo, hybrid Monte Carlo,
Bayesian classification.
——————————F——————————
INTRODUCTION
E consider the problem of assigning an input vector x
to one out of m classes by predicting P(c|x) for c = 1,
º, m. A classic example of this method is logistic regression. For a two-class problem, the probability of class 1
given x is estimated by s(w
Tx + b), where s(y) = 1/(1 + e-y).
However, this method is not at all “flexible,” i.e., the discriminant surface is simply a hyperplane in x-space. This
problem can be overcome, to some extent, by expanding the
input x into a set of basis functions {f(x)}, for example
quadratic functions of the components of x. For a highdimensional input space, there will be a large number of
basis functions, each one with an associated parameter, and
one risks “overfitting” the training data. This motivates a
Bayesian treatment of the problem, where the priors on the
parameters encourage smoothness in the model.
Putting priors on the parameters of the basis functions
indirectly induces priors over the functions that can be
produced by the model. However, it is possible (and we
would argue, perhaps more natural) to put priors directly
over the functions themselves. One advantage of functionspace priors is that they can impose a general smoothness
constraint without being tied to a limited number of basis
functions. In the regression case where the task is to predict
a real-valued output, it is possible to carry out nonparametric
regression using Gaussian Processes (GPs); see, e.g., ,
 . The solution for the regression problem under a GP
prior (and Gaussian noise model) is to place a kernel function on each training data point, with coefficients determined by solving a linear system. If the parameters u that
describe the Gaussian process are unknown, Bayesian inference can be carried out for them, as described in .
The Gaussian Process method can be extended to classification problems by defining a GP over y, the input to the
sigmoid function. This idea has been used by a number of
authors, although previous treatments typically do not take
a fully Bayesian approach, ignoring uncertainty in both the
posterior distribution of y given the data, and uncertainty
in the parameters u. This paper attempts a fully Bayesian
treatment of the problem, and also introduces a particular
form of covariance function for the Gaussian process prior
which, we believe, is useful from a modeling point of view.
The structure of the remainder of the paper is as follows:
Section 2, discusses the use of Gaussian processes for regression problems, as this is essential background for the
classification case. In Section 3, we describe the application
of Gaussian processes to two-class classification problems,
and extend this to multiple-class problems in Section 4. Experimental results are presented in Section 5, followed by a
discussion in Section 6. This paper is a revised and expanded version of .
GAUSSIAN PROCESSES FOR REGRESSION
It will be useful to first consider the regression problem, i.e.,
the prediction of a real valued output y* = y(x*) for a new
input value x*, given a set of training data ' = {(xi, ti), i = 1
º n}. This is of relevance because our strategy will be to
transform the classification problem into a regression
problem by dealing with the input values to the logistic
transfer function.
A stochastic process prior over functions allows us to
specify, given a set of inputs, x1, º xn, the distribution over
their corresponding outputs y
denote this prior over functions as P(y), and similarly, P(y*, y)
for the joint distribution including y*. If we also specify
P(t|y), the probability of observing the particular values
0162-8828/98/$10.00 © 1998 IEEE
²²²²²²²²²²²²²²²²
• C.K.I. Williams is with the Department of Artificial Intelligence, University of Edinburgh, Edinburgh EH1 2QL, Scotland, UK.
E-mail: .
• D. Barber is with RWCP, Theoretical Foundation SNN, University of
Nijmegen, 6525 EZ Nijmegen, The Netherlands.
E-mail: .
Manuscript received 1 Dec. 1997; revised 5 Oct. 1998. Recommended for acceptance by A. Webb.
For information on obtaining reprints of this article, please send e-mail to:
 , and reference IEEECS Log Number 108019.
WILLIAMS AND BARBER: BAYESIAN CLASSIFICATION WITH GAUSSIAN PROCESSES
t = (t1, º tn)
T given actual values y (i.e., a noise model),
then we have that
Hence, the predictive distribution for y* is found from the
marginalization of the product of the prior and the noise
model. Note that in order to make predictions, it is not necessary to deal directly with priors over function space, only
n- or n + 1-dimensional joint densities. However, it is still
not easy to carry out these calculations unless the densities
involved have a special form.
If P(t|y) and P(y*, y) are Gaussian, then P(y*|t) is a
Gaussian whose mean and variance can be calculated using
matrix computations involving matrices of size n ¥ n. Specifying P(y*, y) to be a multidimensional Gaussian (for all
values of n and placements of the points x*, x1, º xn) means
that the prior over functions is a Gaussian process. More
formally, a stochastic process is a collection of random variables {Y(x)|x Œ X} indexed by a set X. In our case, X will be
the input space with dimension d, the number of inputs. A
GP is a stochastic process which can be fully specified by its
mean function m(x) = E[Y(x)] and its covariance function
C(x, x’) = E[(Y(x) - m(x))(Y(x’) - m(x’))]; any finite set of Yvariables will have a joint multivariate Gaussian distribution. Below we consider GPs which have m(x) ∫ 0.
If we further assume that the noise model P(t|y) is
Gaussian with mean zero and variance s
2I, then the predicted mean and variance at x* are given by
where [K]ij = C(xi, xj) and k(x*) = (C(x*, x1), º, C(x*, xn))
e.g., ).
2.1 Parameterizing the Covariance Function
There are many reasonable choices for the covariance function. Formally, we are required to specify functions which
will generate a non-negative definite covariance matrix for
any set of points (x1, º, xk). From a modeling point of view,
we wish to specify covariances so that points with nearby
inputs will give rise to similar predictions. We find that the
following covariance function works well:
where xl is the lth component of x and q = (logv0, logv1,
logw1, º, logwd) is the vector of parameters that are
needed to define the covariance function. Note that q is
analogous to the hyperparameters in a neural network. We
define the parameters to be the log of the variables in (4)
since these are positive scale-parameters. This covariance
function can be obtained from a network of Gaussian radial
basis functions in the limit of an infinite number of hidden
units .
The wl parameters in (4) allow a different length scale on
each input dimension. For irrelevant inputs, the corresponding wl will become small, and the model will ignore
that input. This is closely related to the Automatic Relevance Determination (ARD) idea of MacKay and Neal
 . The v0 variable specifies the overall scale of the prior.
v1 specifies the variance of a zero-mean offset which has a
Gaussian distribution.
The Gaussian process framework allows quite a wide
variety of priors over functions. For example, the Ornstein-
Uhlenbeck process (with covariance function C(x, x’) =
e-|x-x’|) has very rough sample paths which are not meansquare differentiable. On the other hand, the squared exponential covariance function of (4) gives rise to an infinitely
m.s. differentiable process. In general, we believe that the
GP method is a quite general-purpose route for imposing
prior beliefs about the desired amount of smoothness. For
reasonably high-dimensional problems, this needs to be
combined with other modeling assumptions such as ARD.
Another modeling assumption that may be used is to build
up the covariance function as a sum of covariance functions, each one of which may depend on only some of the
input variables (see Section 3.3 for further details).
2.2 Dealing With Parameters
Given a covariance function, it is straightforward to make
predictions for new test points. However, in practical situations we are unlikely to know which covariance function to
use. One option is to choose a parametric family of covariance functions (with a parameter vector u), and then either to
estimate the parameters (for example, using the method of
maximum likelihood) or to use a Bayesian approach where a
posterior distribution over the parameters is obtained.
These calculations are facilitated by the fact that the log
likelihood l = log P('|u) can be calculated analytically as
+ s 2 and ~K denotes the determinant of ~K .
It is also possible to express analytically the partial derivatives of the log likelihood with respect to the parameters
(see, e.g., ).
Given l and its derivatives with respect to u, it is straightforward to feed this information to an optimization package
in order to obtain a local maximum of the likelihood.
In general one may be concerned about making point
estimates when the number of parameters is large relative
to the number of data points, or if some of the parameters
may be poorly determined, or if there may be local maxima
in the likelihood surface. For these reasons, the Bayesian
approach of defining a prior distribution over the parameters and then obtaining a posterior distribution once the
data ' has been seen is attractive. To make a prediction for
a new test point x* one simply averages over the posterior
distribution P(u|'), i.e.,
IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 20, NO. 12, DECEMBER 1998
For GPs, it is not possible to do this integration analytically
in general, but numerical methods may be used. If u is of
sufficiently low dimension, then techniques involving grids
in u-space can be used.
If u is high dimensional, it is very difficult to locate the
regions of parameter space which have high-posterior density by gridding techniques or importance sampling. In this
case, Markov chain Monte Carlo (MCMC) methods may be
used. These work by constructing a Markov chain whose
equilibrium distribution is the desired distribution P(u|');
the integral in (7) is then approximated using samples from
the Markov chain.
Two standard methods for constructing MCMC methods
are the Gibbs sampler and Metropolis-Hastings algorithms
(see, e.g., ). However, the conditional parameter distributions are not amenable to Gibbs sampling if the covariance function has the form given by (4), and the Metropolis-
Hastings algorithm does not utilize the derivative information that is available, which means that it tends to have an
inefficient random-walk behavior in parameter-space. Following the work of Neal on Bayesian treatment of neural networks, Williams and Rasmussen and Rasmussen
 have used the Hybrid Monte Carlo (HMC) method of
Duane et al. to obtain samples from P(u|'). The HMC
algorithm is described in more detail in Appendix D.
GAUSSIAN PROCESSES FOR TWO-CLASS
CLASSIFICATION
For simplicity of exposition, we will first present our
method as applied to two-class problems; the extension to
multiple classes is covered in Section 4.
By using the logistic transfer function to produce an output which can be interpreted as p(x), the probability of the
input x belonging to class 1, the job of specifying a prior
over functions p can be transformed into that of specifying
a prior over the input to the transfer function, which we
shall call the activation, and denote by y (see Fig. 1). For the
two-class problem we can use the logistic function p(x) =
s(y(x)), where s(y) = 1/(1 + e-y). We will denote the probability and activation corresponding to input xi by pi and yi,
respectively. Fundamentally, the GP approaches to classification and regression problems are similar, except that the
error model which is t , N(y, s
2) in the regression case is
replaced by t , Bern(s(y)). The choice of v0 in (4) will affect
how “hard” the classification is; i.e., if p(x) hovers around
0.5 or takes on the extreme values of 0 and 1.
Previous and related work to this approach is discussed
in Section 3.3.
As in the regression case, there are now two problems to
1)making predictions with fixed parameters and
2)dealing with parameters.
We shall discuss these issues in turn.
3.1 Making Predictions With Fixed Parameters
To make predictions when using fixed parameters, we
would like to compute $p
, which requires
us to find P(p*|t) = P(p(x*)|t) for a new input x*. This can be
done by finding the distribution P(y*|t) (y* is the activation
of p*), and then using the appropriate Jacobian to transform
the distribution. Formally, the equations for obtaining
P(y*|t) are identical to (1), (2), and (3). However, even if we
use a GP prior so that P(y*, y) is Gaussian, the usual expression for P
for classification data
(where the ts take on values of zero or one) means that the
marginalization to obtain P(y*|t) is no longer analytically
tractable.
Faced with this problem, there are two routes that we
can follow:
1)to use an analytic approximation to the integral in (1),
(2), and (3) or
2)to use Monte Carlo methods, specifically MCMC
methods, to approximate it.
Below, we consider an analytic approximation based on
Laplace’s approximation; some other approximations are
discussed in Section 3.3.
In Laplace’s approximation, the integrand P(y*, y|t, u) is
approximated by a Gaussian distribution centered at a
maximum of this function with respect to y*, y with an inverse covariance matrix given by -——logP(y*, y|t, u).
Finding a maximum can be carried out using the Newton-
Raphson iterative method on y, which then allows the approximate distribution of y* to be calculated. Details of the
maximization procedure can be found in Appendix A.
Fig. 1. p(x) is obtained from y(x) by “squashing” it through the sigmoid function s.
WILLIAMS AND BARBER: BAYESIAN CLASSIFICATION WITH GAUSSIAN PROCESSES
3.2 Integration Over the Parameters
To make predictions we integrate the predicted probabilities over the posterior P(u|t) µ P(t|u)P(q), as we saw in
Section 2.2. For the regression problem P(t|q) can be calculated exactly using P
, but this integral is not analytically tractable for the classification
problem. Let Y = log P(t|y) + log P(y). Using P ti yi
9, we obtain
log p . (8)
By using Laplace’s approximation about the maximum ~y
we find that
We denote the right-hand side of this equation by log
Pa(t|u) (where a stands for approximate).
The integration over u-space also cannot be done analytically, and we employ a Markov Chain Monte Carlo
method. Following Neal and Williams and Rasmussen we have used the Hybrid Monte Carlo (HMC)
method of Duane et al as described in Appendix D. We
use log Pa(t|u) as an approximation for log P(t|u), and use
broad Gaussian priors on the parameters.
3.3 Previous and Related Work
Our work on Gaussian processes for regression and classification developed from the observation in that a large
class of neural network models converge to GPs in the limit
of an infinite number of hidden units. The computational
Bayesian treatment of GPs can be easier than for neural
networks. In the regression case, an infinite number of
weights are effectively integrated out, and one ends up
dealing only with the (hyper)parameters. Results from 
show that Gaussian processes for regression are comparable
in performance to other state-of-the-art methods.
Nonparametric methods for classification problems can
be seen to arise from the combination of two different
strands of work. Starting from linear regression, McCullagh and Nelder developed generalized linear models
(GLMs). In the two-class classification context, this gives
rise to logistic regression. The other strand of work was
the development of nonparametric smoothing for the regression problem. Viewed as a Gaussian process prior
over functions this can be traced back at least as far as the
work of Kolmogorov and Wiener in the 1940s. Gaussian
process prediction is well known in the geostatistics field
(see, e.g., ) where it is known as “kriging”. Alternatively, by considering “roughness penalties” on functions,
one can obtain spline methods; for recent overviews, see
 and . There is a close connection between the GP
and roughness penalty views, as explored in . By combining GLMs with nonparametric regression one obtains
what we shall call a nonparametric GLM method for classification. Early references to this method include and
 , and discussions can also be found in texts such as 
There are two differences between the nonparametric
GLM method as it is usually described and a Bayesian
treatment. Firstly, for fixed parameters the nonparametric
GLM method ignores the uncertainty in y* and, hence, the
need to integrate over this (as described in Section 3.1).
The second difference relates to the treatment of the parameters u. As discussed in Section 2.2, given parameters u,
one can either attempt to obtain a point estimate for the
parameters or to carry out an integration over the posterior.
Point estimates may be obtained by maximum likelihood
estimation of u, or by cross-validation or generalized crossvalidation (GCV) methods, see e.g., , . One problem
with CV-type methods is that if the dimension of u is large,
then it can be computationally intensive to search over a
region/grid in parameter-space looking for the parameters
that maximize the criterion. In a sense, the HMC method
described above is doing a similar search, but using gradient information,
1 and carrying out averaging over the posterior distribution of parameters. In defense of (G)CV
methods, we note Wahba’s comments (e.g., in , referring
back to ) that these methods may be more robust
against an unrealistic prior.
One other difference between the kinds of nonparametric GLM models usually considered and our
method is the exact nature of the prior that is used. Often,
the roughness penalties used are expressed in terms of a
penalty on the kth derivative of y(x), which gives rise to a
power law power spectrum for the prior on y(x). There can
also be differences over parameterization of the covariance
function; for example it is unusual to find parameters like
those for ARD introduced in (4) in nonparametric GLM
models. On the other hand, Wahba et al have considered a smoothing spline analysis of variance (SS-ANOVA)
decomposition. In Gaussian process terms, this builds up a
prior on y as a sum of priors on each of the functions in the
decomposition
The important point is that functions involving all orders of
interaction (from univariate functions, which on their own
give rise to an additive model) are included in this sum, up
to the full interaction term which is the only one that we are
using. From a Bayesian point of view, questions as to the
kinds of priors that are appropriate is an interesting modeling issue.
There has also been some recent work which is related
to the method presented in this paper. In Section 3.1, we
mentioned that it is necessary to approximate the integral
in (1), (2), and (3) and described the use of Laplace’s
approximation.
Following the preliminary version of this paper presented in , Gibbs and MacKay developed an alternative analytic approximation, by using variational methods
to find approximating Gaussian distributions that bound
the marginal likelihood P(t|u) above and below. These
1. It would be possible to obtain derivatives of the CV-score with respect
to u, but this has not, to our knowledge, been used in practice.
IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 20, NO. 12, DECEMBER 1998
approximate distributions are then used to predict P(y*|t, u)
and thus $p x*2 7. For the parameters, Gibbs and MacKay estimated u by maximizing their lower bound on P(t|u).
It is also possible to use a fully MCMC treatment of the
classification problem, as discussed in the recent paper of
Neal . His method carries out the integrations over the
posterior distributions of y and u simultaneously. It works
by generating samples from P(y, u|') in a two-stage process. Firstly, for fixed u, each of the n individual yis are updated sequentially using Gibbs sampling. This “sweep”
takes time O(n
2) once the matrix K-1 has been computed (in
3)), so it actually makes sense to perform quite a
few Gibbs sampling scans between each update of the parameters, as this probably makes the Markov chain mix
faster. Secondly, the parameters are updated using the Hybrid Monte Carlo method. To make predictions, one averages over the predictions made by each y, u sample.
GPS FOR MULTIPLE-CLASS CLASSIFICATION
The extension of the preceding framework to multiple
classes is essentially straightforward, although notationally
more complex.
Throughout we employ a one-of-m class coding scheme,
and use the multiclass analogue of the logistic function—
the softmax function—to describe the class probabilities.
The probability that an instance labeled by i is in class c is
denoted by p c
i , so that an upper index to denotes the
example number, and a lower index the class label.
Similarly, the activations associated with the probabilities
are denoted by yc
i . Formally, the softmax link function
relates the activations and probabilities through
which automatically enforces the constraint Â
targets are similarly represented by tc
i , and are specified
using a one-of-m coding.
The log likelihood takes the form / Âi c
lnp , which
for the softmax link function gives
As for the two class case, we shall assume that the GP prior
operates in activation space; that is we specify the correlations between the activations yc
One important assumption we make is that our prior
knowledge is restricted to correlations between the activations of a particular class. Whilst there is no difficulty in
extending the framework to include interclass correlations,
we have not yet encountered a situation where we felt able
to specify such correlations. Formally, the activation correlations take the form,
2. That is, the class is represented by a vector of length m with zero entries everywhere except for the correct component which contains 1.
i i, ¢ is the i, i’ element of the covariance matrix for
the cth class. Each individual correlation matrix Kc has the
form given by (4) for the two-class case. We shall use a
separate set of parameters for each class. The use of m independent processes to perform the classification is redundant, but forcing the activations of one process to be, say,
zero would introduce an arbitrary asymmetry into the
For simplicity, we introduce the augmented vector notation,
where, as in the two-class case, yc
* denotes the activation
corresponding to input x* for class c; this notation is also
used to define t+ and p+. In a similar manner, we define y, t,
and p by excluding the values corresponding to the test
point x*. Let y*
With this definition of the augmented vectors, the GP
prior takes the form
where, from (12), the covariance matrix K + is block diagonal in the matrices, K
. Each individual matrix Kc
expresses the correlations of activations within class c.
As in the two-class case, to use Laplace’s approximation
we need to find the mode of P(y+|t). The procedure is described in Appendix C. As for the two-class case, we make
predictions for p(x*) by averaging the softmax function over
the Gaussian approximation to the posterior distribution of
y*. At present, we simply estimate this integral using 1,000
draws from a Gaussian random vector generator.
EXPERIMENTAL RESULTS
When using the Newton-Raphson algorithm, p was initialized each time with entries 1/m, and iterated until the
mean relative difference of the elements of W between consecutive iterations was less than 10-4.
For the HMC algorithm, the same step size e is used for
all parameters, and should be as large as possible while
keeping the rejection rate low. We have used a trajectory
made up of L = 20 leapfrog steps, which gave a low correlation between successive states. The priors over parameters were set to be Gaussian with a mean of -3 and a
standard deviation of 3. In all our simulations, a step size
e = 0.1 produced a low rejection rate (< 5 percent). The
parameters corresponding to the wls were initialized to -2
and that for v0 to 0. The sampling procedure was run for
200 iterations, and the first third of the run was discarded;
this “burn-in” is intended to give the parameters time to
come close to their equilibrium distribution. Tests carried
out using the R-CODA package
3 on the examples in Section
5.1 suggested that this was indeed effective in removing
3. Available from the Comprehensive R Archive Network at
 
WILLIAMS AND BARBER: BAYESIAN CLASSIFICATION WITH GAUSSIAN PROCESSES
the transients, although we note that it is widely recognized (see, e.g., ) that determining when the equilibrium distribution has been reached is a difficult problem.
Although the number of iterations used is much less than
typically used for MCMC methods, it should be remembered that
1)each iteration involves L = 20 leapfrog steps and
2)that by using HMC we aim to reduce the “random
walk” behavior seen in methods such as the Metropolis algorithm.
Autocorrelation analysis for each parameter indicated, in
general, that low correlation was obtained after a lag of a
few iterations.
The MATLAB code which we used to run our experiments is available from ftp://cs.aston.ac.uk/neural/willicki/gpclass/.
5.1 Two Classes
We have tried out our method on two well-known twoclass classification problems, the Leptograpsus crabs and
Pima Indian diabetes datasets.
4 We first rescale the inputs
so that they have mean of zero and unit variance on the
training set. Our Matlab implementations for the HMC
simulations for both tasks each take several hours on a
SGI Challenge machine (200MHz R10000), although good
results can be obtained in much less time. We also tried a
standard Metropolis MCMC algorithm for the Crabs
problem, and found similar results, although the sampling
by this method is somewhat slower than that for HMC.
The results for the Crabs and Pima tasks, together with
comparisons with other methods (from and ) are
given in Tables 1 and 2, respectively. The tables also include
results obtained for Gaussian processes using
1)estimation of the parameters by maximizing the penalized likelihood (found using 20 iterations of a
scaled conjugate gradient optimizer) and
2)Neal’s MCMC method.
Details of the set-up used for Neal’s method are given in
Appendix E.
In the Leptograpsus crabs problem, we attempt to classify the sex of crabs on the basis of five anatomical attributes, with an optional additional color attribute. There are
50 examples available for crabs of each sex and color, making a total of 200 labeled examples. These are split into a
training set of 20 crabs of each sex and color, making 80
training examples, with the other 120 examples used as the
test set. The performance of our GP method is equal to the
best of the other methods reported in , namely a two
hidden unit neural network with direct input to output
connections, a logistic output unit, and trained with maximum likelihood (Network(1) in Table 1). Neal’s method
gave a very similar level of performance. We also found
that estimating the parameters using maximum penalized
likelihood (MPL) gave similar performance with less than a
minute of computing time.
For the Pima Indians, diabetes problem we have used
the data as made available by Prof. Ripley, with his training/test split of 200 and 332 examples, respectively .
4. Available from 
The baseline error obtained by simply classifying each record
as coming from a diabetic gives rise to an error of 33 percent. Again, ours and Neal’s GP methods are comparable
with the best alternative performance, with an error of
around 20 percent, as shown in Table 2. It is encouraging
that the results obtained using Laplace’s approximation and
Neal’s method are similar.
5 We also estimated the parameters using maximum penalized likelihood, rather than
Monte Carlo integration. The performance in this case was
a little worse, with 21.7 percent error, but for only two minutes computing time.
Analysis of the posterior distribution of the w parameters in the covariance function (4) can be informative. Fig. 2
plots the posterior marginal mean and one standard deviation error bars for each of the seven input dimensions. Recalling that the variables are scaled to have zero mean and
unit variance, it would appear that variables 1 and 3 have
the shortest length scales (and therefore the most variability) associated with them.
5.2 Multiple Classes
Due to the rather long time taken to run our code, we were
only able to test it on relatively small problems, by which
we mean only a few hundred data points and several
classes. Furthermore, we found that a full Bayesian integration over possible parameter settings was beyond our
computational means, and we therefore had to be satisfied
with a maximum penalized likelihood approach. Rather
than using the potential and its gradient in a HMC routine,
we now simply used them as inputs to a scaled conjugate
gradient optimizer (based on ) instead, attempting to
find a mode of the class posterior, rather than to average
over the posterior distribution.
We tested the multiple-class method on the Forensic
Glass dataset described in . This is a dataset of 214 examples with nine inputs and six output classes. Because the
5. The performance obtained by Gibbs and MacKay in was similar.
Their method made four errors in the crab task (with color given), and 70
errors on the Pima dataset.
NUMBER OF TEST ERRORS
FOR THE LEPTOGRAPSUS CRABS TASK
Color given
Color not given
Neural Network(1)
Neural Network(2)
Linear Discriminant
Logistic regression
MARS (degree = 1)
PP regression (4 ridge
functions)
Gaussian Process (Laplace
Approximation, HMC)
Gaussian Process (Laplace
Approximation, MPL)
Gaussian Process (Neal’s
Comparisons are taken from from Ripley and Ripley , respectively.
Network(2) used two hidden units and the predictive approach (Ripley, )
which uses Laplace’s approximation to weight each network local minimum.
IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 20, NO. 12, DECEMBER 1998
dataset is so small, the performance is estimated from using
10-fold cross validation. Computing the penalized maximum likelihood estimate of our multiple GP method took
approximately 24 hours on our SGI Challenge and gave a
classification error rate of 23.3 percent. As we see from
Table 3, this is comparable to the best of the other methods.
The performance of Neal’s method is surprisingly poor; this
may be due to the fact that we allow separate parameters
for each of the y processes, while these are constrained to be
equal in Neal’s code. There are also small but perhaps significant differences in the specification of the prior (see
Appendix E for details).
DISCUSSION
In this paper, we have extended the work of Williams and
Rasmussen to classification problems, and have demonstrated that it performs well on the datasets we have
tried. We believe that the kinds of Gaussian process prior
we have used are more easily interpretable than models
(such as neural networks) in which the priors are on the
parameterization of the function space. For example, the
posterior distribution of the ARD parameters (as illustrated
in Fig. 2 for the Pima Indians diabetes problem) indicates
the relative importance of various inputs. This interpretability should also facilitate the incorporation of prior
knowledge into new problems.
There are quite strong similarities between GP classifiers
and support-vector machines (SVMs) . The SVM uses a
covariance kernel, but differs from the GP approach by using a different data fit term (the maximum margin), so that
the optimal y is found using quadratic programming. The
comparison of these two algorithms is an interesting direction for future research.
A problem with methods based on GPs is that they require computations (trace, determinants and linear solutions) involving n ¥ n matrices, where n is the number of
training examples, and hence run into problems on large
datasets. We have looked into methods using Bayesian numerical techniques to calculate the trace and determinant
 , , although we found that these techniques did not
work well for the (relatively) small size problems on which
we tested our methods. Computational methods used to
speed up the quadratic programming problem for SVMs
may also be useful for the GP classifier problem. We are
also investigating the use of different covariance functions
and improvements on the approximations employed.
APPENDIX A
MAXIMIZING P(y+|t): TWO-CLASS CASE
We describe how to find iteratively the vector y+ so that
P(y+|t) is maximized. This material is also covered in
[8, Section 5.3.3] and [25, Section 9.2]. We provide it here for
completeness and so that the terms in (9) are well-defined.
Let y+ denote (y*, y), the complete set of activations. By
Bayes’ theorem log P(y+|t) = log P(t|y) + log P(y+) - log P(t),
and let Y+ = log P(t|y) + log P(y+). As P(t) does not depend
on y+ (it is just a normalizing factor), the maximum of
NUMBER OF TEST ERRORS ON THE PIMA INDIAN DIABETES TASK
Pima Indian diabetes
Neural Network
Linear Discriminant
Logistic Regression
MARS (degree = 1)
PP regression (4 ridge functions)
Gaussian Mixture
Gaussian Process (Laplace
Approximation, HMC)
Gaussian Process (Laplace
Approximation, MPL)
Gaussian Process (Neal’s method)
Comparisons are taken from from Ripley and Ripley , respectively. The
neural network had one hidden unit and was trained with maximum likelihood;
the results were worse for nets with two or more hidden units (Ripley, ).
PERCENTAGE OF TEST ERROR
FOR THE FORENSIC GLASS PROBLEM
Forensic Glass
Neural Network (4HU)
Linear Discriminant
MARS (degree = 1)
PP regression (5 ridge functions)
Gaussian Mixture
Decision Tree
Gaussian Process (LA, MPL)
Gaussian Process (Neal’s method)
See Ripley for details of the methods.
Fig. 2. Plot of the log w parameters for the Pima dataset. The circle
indicates the posterior marginal mean obtained from the HMC run
(after burn-in), with one standard deviation error bars. The square
symbol shows the log w-parameter values found by maximizing the
penalized likelihood. The variables are: 1) the number of pregnancies, 2) plasma glucose concentration, 3) diastolic blood pressure,
4) triceps skin fold thickness, 5) body mass index, 6) diabetes pedigree function, 7) age. For comparison, Wahba et al. using generalized linear regression, found that variables 1, 2, 5, and 6 were
the most important.
WILLIAMS AND BARBER: BAYESIAN CLASSIFICATION WITH GAUSSIAN PROCESSES
P(y+|t) is found by maximizing Y+ with respect to y+.
, we obtain
where K+ is the covariance matrix of the GP evaluated at
x1, º xn, x*. Y is defined similarly in (8). K+ can be partitioned in terms of an n ¥ n matrix K, a n ¥ 1 vector k and a
scalar k*, viz.
As y* only enters into (14) in the quadratic prior term and
has no data point associated with it, maximizing Y+ with
respect to y+ can be achieved by first maximizing Y with
respect to y and then doing the further quadratic optimization to determine y*. To find a maximum of Y, we use the
Newton-Raphson iteration y
new = y - (——Y)-1—Y. Differentiating (8) with respect to y we find
—Y = (t - p) - K-1y (16)
——Y = - K-1 - W, (17)
where the “noise” matrix is given by W = diag(p1(1 - p1), ..,
pn(1 - pn)). This results in the iterative equation,
new = (K-1 + W)-1W(y + W-1(t - p)). (18)
To avoid unnecessary inversions, it is usually more convenient to rewrite this in the form
new = K(I + W K)-1(Wy + (t - p)). (19)
Note that -——Y is always positive definite, so that the optimization problem is convex.
Given a converged solution ~y for y, y* can easily be
found using y
from (16). var(y*) is given by K
5, where W+
is the W with a zero appended in the (n + 1)th diagonal position. Given the mean and variance of y* it is then easy to
, the mean of the distribution of
P(p*|t). In order to calculate the Gaussian integral over the
logistic sigmoid function, we employ an approximation
based on the expansion of the sigmoid function in terms of
the error function. As the Gaussian integral of an error
function is another error function, this approximation is fast
to compute. Specifically, we use a basis set of five scaled
error functions to interpolate the logistic sigmoid at chosen
6 This gives an accurate approximation (to 10-4) to
the desired integral with a small computational cost.
The justification of Laplace’s approximation in our case
is somewhat different from the argument usually put forward, e.g., for asymptotic normality of the maximum
6. In detail, we used the basis functions erf(lx)) for l = [0.41, 0.4, 0.37,
0.44, 0.39]. These were used to interpolate s(x) at x = [0, 0.6, 2, 3.5, 4.5, •].
likelihood estimator for a model with a finite number of
parameters. This is because the dimension of the problem
grows with the number of data points. However, if we consider the “infill asymptotics” (see, e.g., ), where the number of data points in a bounded region increases, then a local
average of the training data at any point x will provide a
tightly localized estimate for p(x) and hence y(x) (this reasoning parallels more formal arguments found in ).
Thus, we would expect the distribution P(y) to become
more Gaussian with increasing data.
APPENDIX B
DERIVATIVES OF logPa(t|u)wrtu
For both the HMC and MPL methods, we require the derivative of la = logPa(t|u) with respect to components of u,
for example qk. This derivative will involve two terms, one
due to explicit dependencies of
on qk, and also because a change in u will cause a change in
~y . However, as ~y is chosen so that —Y
0, we obtain
The dependence of |K-1 + W| on ~y arises through the dependence of W on ~p , and, hence, ~y . By differentiating
5, one obtains
and, hence, the required derivative can be calculated.
APPENDIX C
MAXIMIZING P(y+|t): MULTIPLE-CLASS CASE
The GP prior and likelihood, defined by (13) and (11), define the posterior distribution of activations, P(y+|t). As in
Appendix A we are interested in a Laplace approximation
to this posterior, and therefore need to find the mode with
respect to y+. Dropping unnecessary constants, the multiclass analogue of (14) is
By the same principle as in Appendix A, we define Y by
analogy with (8), and first optimize Y with respect to y,
afterwards performing the quadratic optimization of Y+
with respect to y*.
In order to optimize Y with respect to y, we make use of
the Hessian given by
——Y = -K-1 - W, (22)
where K is the mn ¥ mn block-diagonal matrix with blocks
Kc, c = 1, º, m. Although this is in the same form as for the
two-class case, (17), there is a slight change in the definition
of the “noise” matrix, W. A convenient way to define W is
IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 20, NO. 12, DECEMBER 1998
by introducing the matrix P which is a mn ¥ n matrix of the
form ’ = diag
. Using this notation, we can write the noise matrix in the form of a diagonal
matrix and an outer product,
As in the two-class case, we note that -——Y is again positive definite, so that the optimization problem is convex.
The update equation for iterative optimization of Y
with respect to the activations y then follows the same
form as that given by (18). The advantage of the representation of the noise matrix in (23) is that we can then
invert matrices and find their determinants using the
identities,
T)-1 = A-1 - A-1’(In + ’
det(A + ’’
T) = det(A)det(In + ’
TA-1’), (25)
9. As A is block-diagonal, it
can be inverted blockwise. Thus, rather than requiring
determinants and inverses of a mn ¥ mn matrix, we only
need to carry out expensive matrix computations on n ¥
n matrices. The resulting update equations for y are then
of the same form as given in (18), where the noise matrix
and covariance matrices are now in their multiple class
Essentially, these are all the results needed to generalize
the method to the multiple-class problem. Although, as we
mentioned above, the time complexity of the problem does
not scale with the m
3, but rather m (due to the identities in
(24), (25)), calculating the function and its gradient is still
rather expensive. We have experimented with several
methods of mode finding for the Laplace approximation.
The advantage of the Newton iteration method is its fast
quadratic convergence. An integral part of each Newton
step is the calculation of the inverse of a matrix M acting
upon a vector, i.e., M-1b. In order to speed up this particular step, we used a conjugate gradient (CG) method to solve
iteratively the corresponding linear system Mz = b. As we
repeatedly need to solve the system (because W changes as
y is updated), it saves time not to run the CG method to
convergence each time it is called. In our experiments, the
CG algorithm was terminated when 1
where r = Mz - b.
The calculation of the derivative of logPa(t|q) wrt q in
the multiple-class case is analogous to the two-class case
described in Appendix B.
APPENDIX D
HYBRID MONTE CARLO
HMC works by creating a fictitious dynamical system in
which the parameters are regarded as position variables,
and augmenting these with momentum variables p. The
purpose of the dynamical system is to give the parameters
“inertia” so that random-walk behavior in u-space can be
avoided. The total energy, H, of the system is the sum of the
kinetic energy, K = p
Tp/2 and the potential energy, E. The
potential energy is defined such that p(u|D) µ exp(-E),
i.e., E = - logP(t|u) - log P(u). We sample from the joint
distribution for u and p given by P(u, p) µ exp(-E - K); the
marginal of this distribution for u is the required posterior.
A sample of parameters from the posterior can therefore
be obtained by simply ignoring the momenta.
Sampling from the joint distribution is achieved by two steps:
1)finding new points in phase space with near-identical
energies H by simulating the dynamical system using
a discretised approximation to Hamiltonian dynamics
2)changing the energy H by Gibbs sampling the momentum variables.
Hamilton’s first-order differential equations for H are
approximated using the leapfrog method which requires
the derivatives of E with respect to u. Given a Gaussian
prior on u, logP(u) is straightforward to differentiate. The
derivative of logPa(t|u) is also straightforward, although
implicit dependencies of ~y (and, hence, ~p ) on q must be
taken into account as described in Appendix B. The calculation of the energy can be quite expensive as for each new
u, we need to perform the maximization required for
Laplace’s approximation, (9). This proposed state is then
accepted or rejected using the Metropolis rule depending
on the final energy H* (which is not necessarily equal to the
initial energy H because of the discretization).
APPENDIX E
SIMULATION SET-UP FOR NEAL’S CODE
We used the fbm software available from 
ca/radford/fbm.software.html. For example, the commands used
to run the Pima example are
gp-spec pima1.log 7 1 - - 0.1 / 0.05:0.5
x0.2:0.5:1
model-spec pima1.log binary
pima1.tr@1:200.
mypima.te@1:332.
gp-gen pima1.log fix 0.5 1
mc-spec pima1.log repeat 4 scan-values
200 heatbath hybrid 6 0.5
gp-mc pima1.log 500
which follow closely the example given in Neal’s documentation.
The gp-spec command specifies the form of the Gaussian process, and in particular the priors on the parameters
v0 and the ws (see (4)). The expression 0.05:0.5 specifies a
Gamma-distribution prior on v0, and x0.2:0.5:1 specifies
a hierarchical Gamma prior on the ws. Note that a “jitter”
of 0.1 is also specified on the prior covariance function;
this improves conditioning of the covariance matrix.
The mc-spec command gives details of the MCMC updating procedure. It specifies four repetitions of 200 scans of
the y values followed by six HMC updates of the parameters
(using a step-size adjustment factor of 0.5). gp-mc specifies
that this is sequence is carried out 500 times.
WILLIAMS AND BARBER: BAYESIAN CLASSIFICATION WITH GAUSSIAN PROCESSES
We aimed for a rejection rate of around 5 percent. If this
was exceeded, the stepsize reduction factor was reduced
and the simulation run again.
ACKNOWLEDGMENTS
We thank Prof. B. Ripley for making available the Leptograpsus crabs, Pima Indian diabetes, and Forensic Glass
datasets. This work was partially supported by EPSRC
grant GR/J75425, Novel Developments in Learning Theory for
Neural Networks, and much of the work was carried out at
Aston University. The authors gratefully acknowledge the
hospitality provided by the Isaac Newton Institute for
Mathematical Sciences (Cambridge, UK) where this paper
was written. We thank Mark Gibbs, David MacKay, and
Radford Neal for helpful discussions, and the anonymous
referees for their comments which helped improve the