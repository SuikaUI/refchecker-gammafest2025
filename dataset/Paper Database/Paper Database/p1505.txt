Face Detection using Deep Learning:
An Improved Faster RCNN Approach
Xudong Sun, Pengcheng Wu, Steven C.H. Hoi
DeepIR Inc.
{sunxd,tim,steven}@deepir.com
In this report, we present a new face detection scheme using deep learning and
achieve the state-of-the-art detection performance on the well-known FDDB face
detetion benchmark evaluation.
In particular, we improve the state-of-the-art
faster RCNN framework by combining a number of strategies, including feature
concatenation, hard negative mining, multi-scale training, model pretraining, and
proper calibration of key parameters. As a consequence, the proposed scheme obtained the state-of-the-art face detection performance, making it the best model in
terms of ROC curves among all the published methods on the FDDB benchmark.
Introduction
Face detection is a fundamental and important problem in computer vision and pattern recognition,
which has been widely studied over the past few decades. Face detection is one of the important
key steps towards many subsequent face-related applications, such as face veriﬁcation , face
recognition , and face clustering , etc. Following the pioneering work of ViolaJones
object detection framework , numerous methods have been proposed for face detection in the
past decade. Early research studies in the literature were mainly focused on extracting different types
of hand-crafted features with domain experts in computer vision, and training effective classiﬁers for
detection and recognition with traditional machine learning algorithms. Such approaches are limited
in that they often require computer vision experts in crafting effective features and each individual
component is optimized separately, making the whole detection pipeline often sub-optimal.
In recent years, deep learning methods, especially the deep convolutional neural networks (CNN),
has achieved remarkable successes in various computer vision tasks, ranging from image classiﬁcation to object detection and semantic segmentation, etc. In contrast to traditional computer vision
approaches, deep learning methods avoid the hand-crafted design pipeline and have dominated many
well-known benchmark evaluations, such as ImageNet Large Scale Visual Recognition Challenge
(ILSVRC) . Along with the popularity of deep learning in computer vision, a surge of research
attention has been emerging to explore deep learning for resolving face detection tasks.
In general, face detection can be considered as a special type of object detection task in computer
vision. Researchers thus have attempted to tackle face detection by exploring some successful deep
learning techniques for generic object detection tasks. One of very important and highly successful
framework for generic object detection is the region-based CNN (RCNN) method , which is a
kind of CNN extension for solving the object detection tasks. A variety of recent advances for face
detection often follow this line of research by extending the RCNN and its improved variants.
Following the emerging trend of exploring deep learning for face detection, in this paper, we propose
a new face detection method by extending the state-of-the-art Faster R-CNN algorithm . In
particular, our scheme improves the existing faster RCNN scheme by combining several important
strategies, including feature concatenation , hard negative mining, and multi-scale training, etc.
We conducted an extensive set of experiments to evaluate the proposed scheme on the well-known
 
Face Detection Dataset and Benchmark (FDDB) , and achieved the state-of-the-art performance
(ranking the best among all the published approaches).
The rest of this report is organized as follows. Section 2 brieﬂy reviews the related work in face
detection literature and recent advances of deep learning approaches. Section 3 presents the proposed deep learning approach for face detection. Section 4 discusses our experiments and empirical
results. Section 5 concludes this work.
Related Work
Face detection has extensively studied in the literature of computer vision. Before 2000, despite
many extensive studies, the practical performance of face detection was far from satisfactory until
the milestone work proposed by Viola and Jones . In particular, the VJ framework was
the ﬁrst one to apply rectangular Haar-like features in a cascaded Adaboost classiﬁer for achieving
real-time face detection. However, it has several critical drawbacks. First of all, its feature size was
relatively large. Typically, in a 24 × 24 detection window, the number of Haar-like features was
160,000 . In addition, it is not able to effectively handle non-frontal faces and faces in the wild.
To address the ﬁrst problem, much effort has been devoted to coming up with more complicated
features like HOG , SIFT, SURF and ACF . For example, in , a new type of feature
called NPD was proposed, which was computed as the ratio of the difference between any two pixel
intensity values to the sum of their values. Others aimed to speed up the feature selection in a
heuristic way . The well known Dlib C++ Library took SVM as the classiﬁer in its face
detector. Other approaches, such as random forest, have also been attempted.
Enhancing the robustness of detection was another extensively studied topic. One simple strategy was to combine multiple detectors that had been trained separately for different views or
poses . Zhu et al. applied multiple deformable part models to capture faces with
different views and expressions. Shen et al. proposed a retrieval-based method combined with
discriminative learning. Nevertheless, training and testing of such models were usually more timeconsuming, and the boost in detection performance was relatively limited. Recently, Chen et al. 
constructed a model to perform face detection in parallel with face alignment, and achieved high
performance in terms of both accuracy and speed.
Recent years have witnessed the advances of face detection using deep learning methods, which
often outperform traditional computer vision methods signiﬁcantly. For example, Li et al. presented a method for detecting faces in the wild, which integrates a ConvNet and a 3D mean face
model in an end-to-end multi-task discriminative learning framework. Recently, applied the
Faster R-CNN , one of state-of-the-art generic object detector, and achieved promising results.
In addition, much work has been done to improve the Faster R-CNN architecture. In , joint
training conducted on CNN cascade, region proposal network (RPN) and Faster R-CNN has realized end-to-end optimization. Wan et al. combined Faster R-CNN face detection algorithm with
hard negative mining and ResNet and achieved signiﬁcant boosts in detection performance on face
detection benchmarks like FDDB. In this work, we propose a new scheme for face detection by
improving the Faster RCNN framework.
Our Approach
Overview of Methodology
Our method follows the similar deep learning framework of Faster RCNN, which has been shown
to be a state-of-the-art deep learning scheme for generic object detection . It essentially consists
of two parts: (1) a Region Proposal Network (RPN) for generating a list of region proposals which
likely contain objects, or called regions of interest (RoIs); and (2) a Fast RCNN network for classifying a region of image into objects (and background) and reﬁning the boundaries of those regions.
In this work, we propose to extend the Faster RCNN architecture for face detection, and train our
face detection model by following the proposed procedure as shown in Figure 1.
First of all, we train the CNN model of Faster RCNN using the WIDER FACE dataset . We
further use the same dataset to test the pre-trained model so as to generate hard negatives. These
Figure 1: Flowchart of the training procedure of the proposed deep learning scheme
hard negatives are fed into the network as the second step of our training procedure. The resulting
model will be further ﬁne-tuned on the FDDB dataset. During the ﬁnal ﬁne-tuning process, we
apply the multi-scale training process, and adopt a feature concatenation strategy to further boost
the performance of our model. For the whole training processes, we follow the similar end-toend training strategy as Faster RCNN. As a ﬁnal optional step, we convert the resulting detection
bounding boxes into ellipses as the regions of human faces are more elliptical than rectangular.
In the following, we discuss three of the key steps in the proposed solution in detail.
Feature Concatenation
For traditional Fast RCNN networks, the RoI pooling is performed on the ﬁnal feature map layer to
generate features of the region. Such an approach is not always optimal and sometimes may omit
some important features, as features in deeper convolution layer output have wider reception ﬁelds,
resulting in a grosser granularity. In the proposed solution, in order to capture more ﬁne-grained
details of the RoIs, we propose to improve the RoI pooling by combining the feature maps of multiple convolution layers, including both lower-level and high-level features. Inspired by the study in
 , we propose to concatenate the pooling result of multiple convolutional feature maps to generate the ﬁnal pooling features for detection tasks. Speciﬁcally, features from multiple lower-level
convolution layers are ROI-pooled and L2-normalized, respectively. Those resulting features are
then concatenated and rescaled to match the original scale of the features as if feature-concatenation
had not been adopted. A 1x1 convolution is then applied to match the number of channels of the
original network. The detailed architecture of this approach is shown in Figure 2.
Figure 2: Network architecture of the proposed feature concatenation scheme
Hard Negative Mining
Hard negative mining has been shown as an effective strategy for boosting the performance of deep
learning, especially for object detection tasks including face detection . The idea behind this
method is that, hard negatives are the regions where the network has failed to make correct prediction. Thus, the hard negatives are fed into the network again as a reinforcement for improving our
trained model. The resulting training process will then be able to improve our model towards fewer
false positives and better classiﬁcation performance.
In our approach, hard negatives were harvested from the pre-trained model from the ﬁrst step of our
training process. We then consider a region as hard negative if its intersection over union (IoU) over
the ground truth region was less than 0.5. During the hard negative training process, we explicitly
add those hard negatives into the RoIs for ﬁnetuning the model, and balance the ratio of foreground
and background to be about 1:3, which is the same as the ratio that we use in the ﬁrst step.
Multi-Scale Training
The Faster RCNN architecture typically adopt a ﬁxed scale for all the training images. By resizing
the images to a random scale, the detector will be able to learn features across a wide range of sizes,
thus improving its performance towards scale invariant. In this work, we randomly assign one of
three scales for each image before it is fed into the network. The details are given in our experimental
section. Our empirical results show that the use of multi-scale training makes our model more robust
towards different sizes, and improve the detection performance on benchmark results.
Experiments
Experimental Setup
We conduct an empirical study of evaluating the proposed face detection solution on the well-known
FDDB benchmark testbed , which has a total of 5,171 faces in 2,845 images, including various
detection challenges, such as occlusions, difﬁcult poses, and low resolution and out-of-focus faces.
For implementation, we adopt the Caffe framework to train our deep learning models. VGG16
was selected to be our backbone CNN network, which had been pre-trained on ImageNet. For
the ﬁrst step, WIDER FACE training and validation datasets were selected as our training dataset.
We gave each ground-truth annotation a difﬁculty value, according to the standard listed in Table
1. Speciﬁcally, all faces were initialized with zero difﬁculty. If a face was satisﬁed with a certain
condition listed in Table 1, we add the corresponding difﬁculty value. We ignored those annotations
whose difﬁculty values greater than 2. Further, all the images with more than 1000 annotations were
also discarded.
Table 1: Difﬁculty Value Assignment Strategy
Expression
Illumination
Normal Blur
Heavy Blur
Extreme Expression
Extreme Illumination
Partial Occlusion
Heavy Occlusion
Atypical Pose
The pre-trained VGG16 model was trained on this aforementioned dataset for 110,000 iterations
with the learning rate set to 0.0001. During this training process, images were ﬁrst re-scaled while
always keeping the original aspect ratio. The shorter side was re-scaled to be 600, and the longer
side was capped at 1000. Horizontal ﬂipping was adopted as a data augmentation strategy. During
the training, 12 anchors were used for the RPN part, which covers a total size of 64×64, 128×128,
256 × 256, 512 × 512, and three aspect ratios including 1:1, 1:2, and 2:1. After the non-maximum
suppression (NMS), 2000 region proposals were kept. For the Fast RCNN classiﬁcation part, an
RoI is treated as foreground if its IoU with any ground truth is greater than 0.5, and background
otherwise. To balance the numbers of foregrounds and backgrounds, those RoIs were sampled to
maintain a ratio of 1:3 between foreground and background.
For the second step, the aforementioned dataset was fed into the network. Those output regions,
whose conﬁdence scores are above 0.8 while having IoU values with any ground-truth annotation
are less than 0.5, were regarded as the “hard negatives”. The hard negative mining procedure was
then taken for 100,000 iterations using a ﬁxed learning rate of 0.0001, where those hard negatives
were ensured to be selected along with other sampled RoIs. Finally, the resulting model was further
ﬁne-tuned on the FDDB dataset to yield our ﬁnal detection model.
To examine the detection performance of our face detection model on the FDDB benchmark, we
conducted a set of 10-fold cross-validation experiments by following the similar settings in .
For each image, in addition to performing the horizontal ﬂipping, we also randomly resize it before
feeding it into the network. Speciﬁcally, we resize each image such that its shorter side will be one
of 480, 600, 750. Similar to the policy taken in the ﬁrst step, we ensure that the longer side would
not exceed 1250.
During the training process, we apply the feature concatenation strategy as introduced in the previous
section. Speciﬁcally, we concatenated the features pooled from conv3 3, conv4 3, and conv5 3
layers. As illustrated in , the scale used after the features being concatenated could be either
reﬁned or ﬁxed. Here we used a ﬁxed scale of 4700 for the entire blob, both in the training and test
phases. We ﬁne-tuned the model for 40,000 iterations using a ﬁxed learning rate of 0.001 to obtain
our ﬁnal models.
During the test phase, a query image was ﬁrst re-scaled by following the same principle as in the ﬁrst
stage. For each image, a total of 100 region proposals were generated by the RPN network during
the region proposal generation step. A selected region proposal would be regarded as a face if the
classiﬁcation conﬁdence score is greater than 0.8. In our approach, the NMS threshold was set to
0.3. For the analysis purposes, we also output all the region proposals whose conﬁdence scores are
greater than 0.001 in our experiments.
Experimental Results on FDDB Benchmark
Figure 3 gives the detailed comparisons of two kinds of ROC scores for all the published methods
submitted to the FDDB benchmark. Compared with the other results of the published methods,
in terms of the standard ROC curves, the result obtained by our submitted model scores the highest
among all the published methods, especially for the continuous ROC score where our method clearly
outperforms the second highest method . The promising results validate the effectiveness of the
proposed method for face detection using deep learning techniques.
In addition to the quantitative evaluation results, we also randomly choose some qualitative results of
face detection examples for different cases, as shown in Figure 4, Figure 5, and Figure 6 (and more
other examples in Figure 8). For example, Figure 4 demonstrates that our model is able to detect
some difﬁcult cases, such as non-frontal faces, heavily occluded faces, faces with low resolution,
and faces with extreme poses and/or illumination. Figure 5 lists some selected false positives, where
it seems that most of the false positives are actually missing annotations. Figure 6 lists some of the
false negatives, which includes some very challenging cases, such as blur faces, heavily occluded
faces, and extremely small faces.
Ablation Experiments
To further gain the deep insights of the improvements obtained by the proposed method, we conduct
more additional experiments for ablation studies as listed in Table 2, where we aim to examine the
effectiveness and contributions of different strategies used in the proposed method. Figure 7 shows
the detailed experimental results of the ablation studies for examining several different settings.
Table 2: Additional experiments for ablation studies of the proposed solution
Train with WIDER FACE
Hard Negative Mining
Feature Concatenation
Multi-Scale Training
First of all, by examining the impact of anchor size, instead of using the default setting (9 anchors
for RPN) by traditional faster RCNN, we compare this with our modiﬁcation by adding a size group
of 64 × 64, thus increasing the number of anchors to 12. Using this modiﬁcation would allow our
model to detect more small detection boxes (as shown in Experiment ID 1 vs ID 2).
Figure 3: ROC curves of FDDB cross-validation result (top: continuous ROC result; bottom: discrete ROC result)
Figure 4: Selected detected faces (red: annotation; blue: detection result)
Figure 5: Selected false positives of the proposed method on FDDB (red: annotation; blue: detection
results; cyan: false positives)
Figure 6: Selected false negatives of the proposed method on FDDB (red: annotation; blue: detection results; yellow: false negatives)
Figure 7: Comparisons of Continuous ROC curves (top) and discrete ROC curves (bottom) for
different experimental settings for our ablation studies. These experimental results shown here are
only for the fold 7 of our cross-validation experiments; the other experimental folds are similar. The
ﬁgures on the bottom right are magniﬁed views of the selected regions. The detection bounding
boxes are not converted to ellipses. (Best viewed in color).
Second, we examine the impact of pre-training on our model on additional larger-scale face data
sets (such as WIDER FACE in our approach), since FDDB is a relatively small dataset (5171 faces
in 2845 images). However, the pre-training is not trivial as the WIDER FACE dataset is more challenging than FDDB, as it contains many difﬁcult cases. As seen from experiment ID 4, although the
detection recall was improved compared with Experiment ID 2, a simple training on WIDER FACE
will yield many more false positives. By using the hard negative mining (as shown in Experiment
ID 5), the number of false positives was reduced signiﬁcantly.
Third, we examine the impact of feature concatenation strategy. As shown in our ablation study
experiments (ID 2 vs ID 3, and ID 5 vs ID 6), feature concatenation turned out to be an effective strategy. By combining features from multiple layers, the model was able to learn features of
multiple sizes, and was therefore better at classiﬁcation.
Fourth, by further examining the impact of multi-scale training, we also observe a positive improvement from our ablation experiments (ID 6 vs ID 7). Speciﬁcally, by adopting the random scaling for
data augmentation, the detection performance was further increased.
Finally, combining all the above strategies yielded the best detection performance (as shown in
experiment ID 7).
Conclusions
In this work, we proposed a new method for face detection using deep learning techniques. Specifically, we extended the state-of-the-art Faster RCNN framework for generic object detection, and
proposed several effective strategies for improving the Faster RCNN algorithm for resolving face
detection tasks, including feature concatenation, multi-scale training, hard negative mining, and
proper conﬁguration of anchor sizes for RPN, etc. We conducted an extensive set of experiments
on the well-known FDDB testbed for face detection benchmark, and achieved the state-of-the-art
results which ranked the best among all the published methods. Future work will further address the
efﬁciency and scalability of the proposed method for real-time face detection.
Acknowledgments
We would like to thank Hanfu Zhang for his suggestions and contributions to this project.