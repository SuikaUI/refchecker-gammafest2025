Computing Contour Closure
James H. Elder 1 and Steven W. Zucker 2
1 NEC Research Institute, Princeton, N J, U.S.A.
2 Centre for Intelligent Machines, McGill University, Montreal, Canada.
Abstract. Existing methods for grouping edges on the basis of local
smoothness measures fail to compute complete contours in natural im-
ages: it appears that a stronger global constraint is required. Motivated
by growing evidence that the human visual system exploits contour clo-
sure for the purposes of perceptual grouping , we present
an algorithm for computing highly closed bounding contours from im-
ages. Unlike previous algorithms , no restrictions are placed
on the type of structure bounded or its shape. Contours are represented
locally by tangent vectors, augmented by image intensity estimates. A
Bayesian model is developed for the likelihood that two tangent vectors
form contiguous components of the same contour. Based on this model, a
sparsely-connected graph is constructed, and the problem of computing
closed contours is posed as the computation of shortest-path cycles in this
graph. We show that simple tangent cycles can be efficiently computed in
natural images containing many local ambiguities, and that these cycles
generally correspond to bounding contours in the image. These closure
computations can potentially complement region-grouping methods by
extending the class of structures segmented to include heterogeneous
structures.
Introduction
We address the problem of computing closed bounding contours in real images.
The problem is of interest for a number of reasons. A basic task of early vision
is to group together parts of an image that project from the same structure in
a scene. Studies of perceptual organization have demonstrated that the human
visual system exploits a range of regularities in image structure to solve this
task (12, 14, 28]. Inspired in part by these studies, algorithms have been devel-
oped to apply continuity, cocircularity and smoothness constraints to organize
local edges into extended contours . However, despite persua-
sive psychophysical demonstrations of the role of contour closure in perceptual
organization , closure constraints for computer vision algorithms
have been largely ignored (although see ). This is surprising, since exist-
ing algorithms, while capable of producing extended chains of edges, are seldom
successful in grouping complete contours. Closure is a potentially powerful cue
that could complement smoothness cues to allow more complete contours to be
In natural images, contours are fragmented due to occlusions and other ef-
fects, making local grouping cues weak and unreliable. While these local cues
may be summed or otherwise integrated along a contour to form global measures
of "smoothness", "likelihood" or "salience", such a global measure is as weak as
its weakest local constituent. This is illustrated in Fig. l(a): the most plausible
continuation of a contour viewed locally may be clearly incorrect when viewed
in global context. This error is not revealed in a summation of local grouping
cues over the curve, since both the correct and the incorrect continuations lead
to similar measures. A global feature is needed which is far more sensitive to
such local errors. Closure is a potentially powerful feature because a single local
error will almost certainly lead to a low measure of closure.
!i!ililililiiii~iiiiiiiiii
i!i!i!i!i!i!i
iiiiiii!i!iliiiiiii!iiii~
~iiiiiiiiii!iii
Binding contrast (%)
Fig. 1. (a) Locally, the most plausible continuation of fragment a is through frag-
ment b. Given global context, fragments instead group to form simple cycles with
high measures of closure. (b) A region grouping algorithm would segment this
image into 12 disjoint regions, yet human observers see two overlapping objects.
Regularities of the object boundaries must be exploited. (c) Psychophysical data
for shape identification task. Subjects must discriminate between a fragmented
concave shape (shown) and a 1-D equivalent convex shape (not shown), at very
low contrasts. Results show that contour closure cues greatly enhance perfor-
mance. No effect of texture cues is observed. From .
The computation of closed contours is also potentially useful for grouping
together image regions which project from common structures in the scene: ob-
jects, parts of objects, shadows and specularities. Existing techniques for region
grouping apply homogeneity or smoothness constraints on luminance, colour or
texture measures over regions of the image (e.g. 16, 20, 21). These techniques
have inherent limitations. While a region-grouping algorithm would segment the
image of Fig. l(b) into 12 disjoint components, human observers perceive two
irregularly painted, overlapping objects. Since these are nonsense objects, our
inference cannot be based on familiarity. We must be using the geometry of the
boundaries to group the objects despite their heterogeneity.
This situation is not artificial. Objects are often highly irregular in their sur-
face reflectance functions, and may be dappled in irregular ways by shadows and
specularities. While surface markings, shadows and specularities fragment im-
age regions into multiple components, geometric regularities of bounding contour
persist. Contour closure is thus potentially important for segmentation because
it broadens the class of structures that may be segmented to include such hetero-
geneous structures. Interestingly, recent psychophysical experiments suggest
that contour grouping cues such as closure may be more important than regional
texture cues for the perceptual organization of 2-D form (Fig. 1(c)).
Previous Work
The problem of contour grouping has been approached in many different ways.
Multi-scale smoothness criteria have been used to impose an organization on im-
age curves , sequential methods for tracking contours within a Bayesian
framework have recently been developed and parallel methods for computing
local "saliency" measures based on contour smoothness and total arclength have
been studied . In general, these techniques are capable of grouping edge
points into extended chains. However, no attempt is made to compute closed
chains; a necessary condition for computing global 2-D shape properties and for
segmenting structures from an image.
A separate branch of research investigates the grouping of occlusion edges into
complete contours, ordered in depth . While interesting from a theoretical
point of view, a large fraction of the edges in real images are not occlusion edges,
and a recent study suggests that it is not possible to locally distinguish
occlusion edges from other types of edges. It is our view that algorithms for
grouping contours must work for all types of structure in an image (e.g. objects,
shadows, surface markings).
3acobs has studied the problem of inferring highly-closed convex cycles
of line segments from an image, to be used as input for a part-based object
recognition strategy. Given the generality of boundary shape, it is clearly of great
interest to determine whether bounding contours can be recovered without such
restrictive shape constraints. Most similar to our work is a very recent study by
Alter on the application of shortest-path algorithms to the computation of
closed image contours. While similar in concept, these two independent studies
differ substantially in their implementation.
Overview of the Algorithm
Our goal here is to recover cycles of edge points which bound two-dimensional
structures in an image. The algorithm is to be fully automatic and no restrictions
are placed on the type of structure bounded or its shape. Since no constraint of
disjointness is imposed, in principle the bounding contours of an entire object,
its parts, markings, and shadows can be recovered.
Image contours are represented locally as a set of tangent vectors, augmented
by image intensity estimates. A Bayesian model is developed to estimate the
likelihoods that tangent pairs form contiguous components of the same image
contour. Applying this model to each tangent in turn allows the possible con-
tinuant tangents for each tangent to be sorted in order of their likelihood. By
selecting for each tangent the 6 most likely continuant tangents, a sparse (6-
connected), weighted graph is constructed, where the weights are the computed
pairwise likelihoods.
By assuming independence between tangent pair likelihoods, we show that
determining the most probable tangent cycle passing through each tangent can
be posed as a shortest path computation over this sparse graph. We can therefore
use standard algorithms (e.g. Dijkstra's algorithm ) to solve this problem in
low-order polynomial time.
Extended Tangents
Edges are detected by a multi-scale method which automatically adapts esti-
mation scale to the local signal strength and provides reliable estimates of edge
position and tangent orientation . In addition to the geometric properties of
position and orientation, we make use of local image intensity estimates provided
by our edge detector.
Due to uncertainty induced by discretization and sensor noise, contours gen-
erate noisy, laterally-displaced local edges (Fig. 2(a)). Tracing a contour through
these local tangents generates a curve corrupted by wiggles due to sensing ar-
tifacts. Also, due to blurring of the luminance function at the imaging and es-
timation stages, edge estimates near corners and junctions are corrupted (Fig.
Fig. 2. (a) The set of raw tangent estimates for a contour. Imposing an order-
ing on these local tangent estimates generates a contour distorted by sampling
artifacts. (b) The smoothing of the image at the sensing and estimation stages
corrupts tangent estimates near contour junctions and corners.
Achieving a more reliable local representation requires more global con-
straints. Here, we introduce a method for refining local edge information based
on an extended tangent representation, which represents a curve as a sequence
of disjoint line segments. Each local edge in the image generates a tangent line
passing through the edge pixel in the estimated tangent direction. The subset of
tangent estimates which are 8-connected to the local edge and which lie within
an e-neighbourhood of the local tangent line are identified with the extended
tangent model. The algorithm for selecting extended tangents to approximate a
contour is illustrated in Fig. 3. Given a connected set of local edges, the longest
line segment which faithfully models a subset of these is determined. This sub-
set is then subtracted from the original set. This process is repeated for the
connected subsets thus created until all local edges have been modeled.
Fig. 3. Computing the extended tangent representation. (a) For each connected
set of edge pixels, the subset of pixels underlying the longest extended tangent
is selected. (b) The edge points thus modeled are subtracted. (c) The process
is repeated for each connected set of edge pixels thus spawned.
Since the extended tangents selected must be consistent with the global geom-
etry of the curves, they provide more accurate estimates of contrast and tangent
orientation than do the corrupted local edges near the junction. The extended
tangent algorithm is conceptually simpler than most methods for computing
polygonal approximations , and does not require preprocessing of the edge
map to link local edges into ordered lists, as is required for most other methods
(e.g. 11,17,20).
A Bayesian Model for Tangent Grouping
The extended tangent representation leads naturally to a representation for
global contours as tangent sequences:
Definition 1. A tangent sequence tl --+ ... --+ tn is an injective mapping from a
finite set of integers to a set of extended tangents.
The injective property restricts our definition to sequences which do not
pass through the same extended tangent twice. The identification of extended
tangents with integers imposes an ordering on the tangents which distinguishes
a tangent sequence from an arbitrary clutter of tangents. If a contour bounds a
2-D structure in the image, this sequence will come back on itself. Thus bounding
contours are represented as cycles of extended tangents, tl -4 ... -4 tn --4 tl -4 ...
By this definition, any ordered set of tangents in an image can form a tangent
sequence. In order to compute bounding contours, some measure of the likeli-
hood of a tangent sequence must be established. For this purpose, we develop
a Bayesian model for estimating the posterior probability of a tangent sequence
given data on the geometric and photometric relations between adjacent tangent
tuples of the sequence.
We will begin by assuming that tangent links are independent: i.e.
p(tl --~ ... --~ tn) = p(tl -4 t2)p(t2 --4 t3)...p(tn-1 -~ tn)
This approximation will greatly simplify the computation of tangent sequence
likelihoods, reducing likelihood estimation for a tangent sequence to the problem
of estimating the likelihoods of its constituent links. The likelihood that two
tangents project from the same contour is modeled as the probability of their
rectilinear completion (Fig. 4), so that the probability of a link depends on the
following observables (see Sections 6 and 7 for details of the model):
1. The lengths !1 and 12 of the extended tangents.
2. The length r of the straight-line interpolant.
3. The 2 orientation changes 6a and ~b induced by the interpolation.
4. The differences in estimated image intensity Aih, AQ on the bright side and
the dark side of the tangents, respectively.
Fig. 4. Rectilinear interpolation model.
Setting o = {/1,/2, r, ~a, 0b, Ali h, Ail}, Bayes' theorem can be used to express
the posterior probability of a link from tangent tl to t2 (called the "link hypoth-
esis") in terms of the likelihoods of the observables:
p(tl -4 t210) = P(~
-4 t2)p(tl -4 t2)
Letting tl-~ t2 represent the hypothesis that t2 is not the continuant of tl
(the "no-link hypothesis"), the evidence p(o) can be expanded as
p(o) = p(o]tl -+ t2)p(tl --+ t2) + p(o[tl-fi t2)p(tl-fi t2).
It is convenient to rewrite the posterior probability as
p(tl -~ t21o) - (1 + LP)
p = p(tl-fi t2)
p(o[tl -~ t2)
p(tl --+ t2)
The prior ratio P represents the ratio of the probability that a curve ends
at tl, to the probability that the curve continues. For most images, curves are
expected to continue over many tangents. It is therefore appropriate to choose
a large vMue for the prior ratio: in our experiments we use P = 50.
The likelihood ratio L represents the ratio of the likelihood of the observables
given that t2 is not a continuant of tl to their likelihood given that t~ is a
continuant of tl. Models for these likelihoods are developed in the next two
Link Hypothesis
Likelihoods
In order to model the link hypothesis likelihoods p(o[tl --+ t2) we must consider
the distinct events that can split the image curve into two separate extended
tangents tl and t2. The three possible hypotheses for a tangent split considered
are termed respectively the curvature, interruption and corner hypotheses:
Curvature The contour is curving smoothly: two tangents are needed to model
the local edges to e accuracy. Relatively small values for r, ~a and t?b are
Interruption The contour is interrupted, for example by an occlusion, shadow,
or loss of contrast. We expect potentially large values for r, but again rela-
tively small values for Oa and 8 5 .
Corner The contour corners sharply: two tangents are generated on either side
of the corner. We expect a relatively small value for r, but possibly large
values for ~ and 8b.
Since each of these hypotheses generates different expectations for the ob-
servables, the corresponding link hypothesis likelihoods are decomposed into
likelihoods for the 3 disjoint events:
p(oltl --+ t2) = p(oltl -+ t2, curvature)p(curvature)
+ p(oltl -+ t2, interruption)p(interruption)
+ p(oltl -+ t2, corner)p(corner)
In a natural world of piecewise-smooth objects, the curvature hypothesis is
the most likely. For our experiments we assign
p(curvature) = 0.9 and p(interruption) = p(corner) = 0.05.
Combining the observables 11,12 and r into a normalized gap length r ~,
min{/1,12 }
we write a summarized set of observables as d = {r t, Oa,Ob, Ab, Ad}. Approx-
imating these as conditionally independent on the 3 tangent split hypotheses,
we use half-Gaussian functions to model the link hypothesis likelihoods for each
observables oi:
p(oiltl --+ t2) = ~
V/'~ O-o l
The scale constants ao~ used in this paper are shown in Table 1.
(TO a = (TOb 6tAb ~
(pixels) (pixels)
(grey levels)
interruption
Table 1. Scale constants for link hypothesis likelihood functions
Hypothesis
Likelihoods
Modelling the position of a tangent as a uniform distribution over the image
domain, for an L x L image, and r << L we can approximate the no-link
likelihood for r as p(r) ~ ~-z . No-link likelihood functions for ~?a and 85 follow
immediately from the assumption of isotropic tangent directions:
p(Oaltl-fl t2) = p(Obltl-~ t2) = -
0 < Oa,Ob < 7r.
Modelling image intensity i as a uniform distribution, 0 < i < 255, no-link
likelihood functions for Aih and Air, can be derived :
p(A~hltl ~ t2) = ~(
p(Aitltl --+ t2) ----- 25-~(1 - Air/255)
Constructing a Sparse Graph
Since tangent tuple observations provide only a weak means for discriminating
probable from improbable links (Fig. l(a)), it is essential that the data structure
from which tangent cyles are computed represent multiple potential continua-
tions for each tangent. This also allows for the co-occurrence of overlapping
cycles, which, as we shall see, occur frequently in natural images.
We construct an appropriate data structure by computing the likelihoods for
all tangent pairs, and then selecting for each tangent the m most likely contin-
uant tangents. In this way, we represent the image as a sparse, weighted graph
in which each vertex represents a tangent, directly connected to m other tan-
gents. Tangent links now become edges in this graph, weighted by the computed
posterior probabilities. We set m = 6 for the experiments presented here. 3
The complexity of building the sparse graph is O(n2), where n is the num-
ber of tangents in the image. In practice, this procedure takes approximately 1
minute of computation on a Sparc 10 for a moderately complex 300 • 400 image.
Likelihood
We set as our goal the computation of the maximum likelihood cycle for each
tangent in this tangent graph. By the identification between the vertices and
edges of this graph and the extended tangents and tangent links of the contour
model, these cycles correspond to highly closed contours in the image. Note that
since the graph is sparse, not all tangents lie on a cycle. Also, the same cycle will
often be computed by more than one tangent. These duplicate cycles are easily
detected and ignored. Finally, observe that any given tangent may lie on many
cycles, but each cycle must form the best closure for at least one tangent in the
Since tangent links are assumed to be independent, the likelihood of a tangent
sequence is simply the product of the probabilities of its constituent links:
p(ti -+ ... --~ tn) -~- p(ti -+ t2)p(t2 -+ t3)...p(tn-1 --+ tn)
Taking the natural logarithm, we have
logp(tl -+ ... -4 tn) = logp(tl -+ t2) + 1ogp(t2 -+ ta) + ... + 1ogp(t,_l --~ t,)
Since all of the terms on the right-hand side are negative, maximizing this sum
corresponds to minimizing the sum of the absolute values of the terms. The prob-
lem of computing a maximum likelihood sequence can therefore be expressed as
a minimization of the absolute sum of the log likelihoods for each link. Thus
computing the maximum likelihood cycle for each tangent is a shortest-path
problem, and can be solved using standard techniques, such as Dijkstra's algo-
rithm , allowing the maximum likelihood cycles for all tangents to be com-
puted in O(n 2 log n) operations, where n is the number of tangents in the image.
a Since a tangent may link to another tangent in 2 possible ways (contrast reversals
axe allowed), the size of the graph is effectively doubled.
Topological
Constraints
Up to this point we have ignored the topology of bounding contours: self-
intersecting contours have not been ruled out. Demanding that each extended
tangent appear at most once in any tangent sequence eliminates many intersect-
ing cycles (Fig. 5(a)), but there remain those cycles which intersect but which
do not overlap the same tangent twice (Fig. 5(b-c)). 4
Fig. 5. Topological constraints on tangent cycles. (a) Each tangent may appear
at most once in a tangent sequence. (b) By constraining cycles to have unit rota-
tion index, "figure eights" and "double loops" axe eliminated. (c) More complex
intersecting contours with unit rotation index are not restricted.
A subclass of these self-intersecting contours can be eliminated by constrain-
ing the rotation index of the underlying contour to be
(eo, + eb,) : •
This eliminates the more common types of erroneous cycles, such as "figure
eights" (rotation index 0) and "double loops" (rotation index •
(Fig. 5(b)).
However, more complex self-intersecting contours with rotation index -- •
still possible (Fig. 5(c)), and we do not detect these.
These topological constraints cannot be embodied in the weights of the tan-
gent graph, since the rotation index cannot be computed until a complete cycle
has been determined. However, by assuming an upper bound on the number of
different rotation indices that may be generated from each tangent, Dijkstra's
algorithm can be generalized to incorporate these constraints. This modification
does not change the complexity of the algorithm, which requires on the order of
1-2 minutes to complete in our experiments.
4 The rim of a smooth solid can generate a self-intersecting contour in the image .
However, the closure algorithm developed here is not restricted to the recovery of
occlusion boundaries. By imposing the constraint of non-intersection, we narrow
the class of boundaries which may be recovered. The recovery of more complex
boundaries will likely require information about the type of structure bounded.
Figs. 6 and 8 show the bounding contours computed for two different images.
For clarity, only cycles for extended tangents over 10 pixels in length are shown,
and cycles which share one or more extended tangents are shown in separate
images. Note that many overlapping cycles are computed, supporting our earlier
observation that a constraint of disjointness is too restrictive for natural images.
Fig. 6. (a) Image of mannequin and shadow. (b-c) Tangent cycles detected in
mannequin/shadow image.
Fig. 6 shows the bounding contours computed for the image of the mannequin
casting a shadow. The bounding contour of the cast shadow is recovered nearly
perfectly. The boundary of the mannequin itself is generally recovered, although
the right arm and left forearm are pinched off. The left forearm is recovered as
a separate bounding contour in Fig. 6(b), as is the attached shadow on the right
arm. Finally, the contour of the "hole" formed by the legs of the mannequin and
its shadow is recovered as a bounding contour.
The image of a totem pole shown in Fig. 7(a) (courtesy of David Lowe) poses a
greater challenge. Fig. 7(b) shows the edge groupings computed by the multiple
hypothesis tracking method of Cox et al., and Fig. 7(c) shows the groupings
computed by Lowe's smoothness criteria . While both methods group edges
into extended contours, neither method recovers complete contours which could
bound structural units in the image.
The tangent cycles selected as bounding contours by our closure computation
are shown in Fig. 8. Major structure boundaries are identified, including the
teeth, mouth, eyeball and left shoulder of the human figure and the tongue, lips,
eye and eyebrow of the wolf figure, as well as various shadows and decorative
markings. An error can be seen in Fig. 8(d), where the eyebrow of the human
figure and the lips of the wolf figure have been grouped as a single structure.
The results of these experiments show that bounding contours can be com-
puted as cycles of tangents in the image. While some errors are made, on the
Fig. 7. (a) Noisy image of a totem pole (courtesy of David Lowe). (b) Edges
grouped by multiple-hypothesis tracking . (c) Edges grouped by Lowe's
smoothness criteria :
whole these tangent cycles correspond to the boundaries of two-dimensional
structures in the scene: objects, object parts, surface markings and shadows.
Note that closure computations select the tangent cycle bounding the mouth
of the human figure in the totem pole (shown in white in Fig. 8(a)), even though
the region thus enclosed is highly heterogeneous, encompassing a second closed
contour (shown in black). While the many edges within the region of the mouth
would cause region-grouping schemes to carve the structure up into smaller corn-
Fig. 8. Closed contours of totem pole image. The bounding contour of the mouth
of the human figure (shown in white in (a)) is recovered despite the heterogeneity
of the region it bounds.
ponents, closure computations successfully detect the unitary structure on the
basis of regularities in the structure boundary. This may explain in part the re-
cent psychophysical results suggesting a stronger role for boundary cues than
regional cues in the perceptual organization of form (Fig. l(c)).
Conclusion
Bridging the gap between early visual data structures such as edge maps and
higher-level shape representations is a significant challenge for computer vision
algorithms. Recent emphasis has been placed on interactive methods which by-
pass this "weak link" (e.g. ), however the development of reliable, fully-
automatic methods for contour grouping remains a desirable but elusive goal.
In this paper, we have proposed that the strong global constraint of contour
closure may significantly aid in achieving this goal. To support our argument, we
have developed an algorithm for computing closed bounding contours as topo-
logically simple cycles of contour tangents. Unlike previous algorithms , this
closure algorithm does not impose hard constraints on the shape of the image
structures to be recovered. Since no constraint of disjointness is imposed, overlap-
ping contours and abutting structures may be computed. Experiments indicate
that this closure algorithm generally succeeds in segmenting two-dimensional
structures from a variety of real images. While these closure computations do
not produce a complete description of the image, they may serve to comple-
ment region-grouping methods by extending the class of segmented structures
to include heterogeneous structures.