General Disclaimer
One or more of the Following Statements may affect this Document
This document has been reproduced from the best copy furnished by the
organizational source. It is being released in the interest of making available as
much information as possible.
This document may contain data, which exceeds the sheet parameters. It was
furnished in this condition by the organizational source and is the best copy
available.
This document may contain tone-on-tone or color graphs, charts and/or pictures,
which have been reproduced in black and white.
This document is paginated as submitted by the original source.
Portions of this document are not fully legible due to the historical nature of some
of the material. However, it is the best reproduction available from the original
submission.
Produced by the NASA Center for Aerospace Information (CASI)
- LARS Technical Report 0=78 AWW----
W 14 W W W W W ii is
SW WW WW ^i f--^
— — — — — — — — — — — — — — — — —
— — — — — — — — —
-------- -- --
Ba scan Classification
r-,f C^._^.^^
SS 31 S Time-varving Environment _ ^^
,-3 S C-1 S
Philip H. Swain
(NASA-CR-151E60)
E411SI4N CIASSIFICATICW IT
A TI"F-VABYING ENVIFCWMENT (Surdue ariv.)
21 p HC A02/MF AV
G3/41 1181E
The Laboratory for Applications of Remote Sensing
Purdue Universi ty
West Lafayette, Indiana
1. Report No.
2, Government Accession No.
4 Tale and Subtitle
Bayesian Classification in a Time-Varying Environment
7 Author(s)
Philip H. Swain
9 Performing Organization Name and Address
Laboratory for Applications of Remote Sensing
1220 Potter Drive
West Lafayette, Indiana 47906
17 Sponsoring Agency Name and Address
3, Reclplent's l-- —
18 Distribution Stdternew
pattern classification, multitemporal
observations, remote sensing.
19 `.ecu r -t y Classlf (of this'ctc(ll
-- :0 Srcurlty oassi f (of oils Isagel
71 No .)f Page-,
,dlr t•s :hr N.IIun Jl 1vihlncal h0of,i.atron tierv-iv, 'ilHUly tn I.J. Vuyirlra 27161
i.F1RS Information Note 030178
BAYFSIAN CE SSIFICATION IN A
TIM -,-V71RYIPY. ; ENVI Ed7IVNQ,71'
Philip H. Swain
This taper deals with the problem of classifying a pattern based on
multiple observations made in a time-varying environment. The identity of
the pattern may itself change. A Bayesian solution is derived, after which
the conditions of the physical situation are invoked to produce a "Cascade"
classifier model. Experimental results based on remote sensing data demonstrate the effectiveness of the classifier.
Fey words: pattern classification, multitemhoral observations, rcmte
BAYESIAN CLASSIFICATION IN A
TIME-VARYING ENVIRONMENT
Philip H. Swain
Introduction
We pose the following pattern classification problem:
A series of observations is made on a pattern in a timevarying environment. The identity of the pattern itself may
change. It is desired to classify the pattern after the current
observation is made, drawing on information derived from earlier observations plus knowledge about the statistical behavior
of the environment.
An example of such a situation arises in remote sensing applications in which the sensor system: can make multiple passes
over the same grcund area [l]. The identity of the ground covr-r
may change between passes. In general it is desired to dotermino
the current identity of the qround cover, but pest observations
can be helpful in accomplishing the identification.
The classification strategy we shall develop is a Bayes
optimal (minimum risk) strategy . In the ordinary single
1 Philip 1I. Swain is with the School of Electrical Engineering and
the Laboratory for Applications of Remote Sensing, Purdue University, West Lafayette, IN 47907.
observation case, the approach is to select a decision rule so as
to minimize the conditional average loss
LX ((Lj i ) = I
A i j p(w j X)
X is an n-variate observation (feature) vector
{w j , j=1, 2,..., m} is the set of m classes
a ij is the cost resulting from classifying into
class i a pattern actually from class j
p(w i J X) is the conditional probability that, given
observation X, its class is wj
That is, L X Oki i ) is the expected loss incurred if an observation X
is classified as w i . Commonly (21 a ij is taken to be the 110-1
loss function," i.e.,
a ij = 0, i = j
(no cost for correct classification)
(unit cost for an error)
Then Eq. (1) becomes
LX ( w i ) = 1 - p((,I i IX)
and an appropriate decision rule which will minimize L X ((,) i ) is:
Decide X e w if and only if
p(X w i ) p(t,^ i ) - max p(XIw j )p(w j )
where p(XIIA i ) is the probability density function for the obser-
vat ions associated with class (,►i and p((, ►i ) is the a priori probability of class w i .
Thus the set of products (F)(XI(iji)p (III i),
i=l, 1,..., m) is a set of discriminant functions for the classification problem.
We now generalize this Bayes optimal approach to the case of
a series of observations. It will be convenient to assume t^:at obs ,z^rvations are made at two times. Generdiization to a larger number
of observation times is straightforward.
X(t ►) and X 2 = X(t 2 ) be n-variate random vectors,
the pattern observations at times t and t., respectively.
Let fv i = v i (t ►)l i=1,2,..., m ►} be the set of possible
classes at time t ►, and let { wi
(A)(t2)1 i=1,2,..., m I be the
set of possible classes at time t2.
We define a compound condi`.ional average loss
LX X ( wi ) = S
A ij p(r,►j IX ► , X 2 )
where A.- is the cost resulting from classifying into class i, at
time t 2 , a pattern actually from class j.
In this case ,.)((,)1X , X )
is the a posteriori probability that, given the observations X1
at time t and X 2 at time t 2 , the class of the pattern at time
once again assuming a "0-1 loss function," Eq. (4) becomes
LX ►X2(wi) = 1 - p([,►i X ►, X`)
ORIGINAL PAVE I5
OF POOR QUALITY
which is minimized if we choose w to maximize the a posteriori
probability p(w i lX 1 , X 2 ). Thus an appropriate set of discriminant
functions for a Bayes optimal classification strategy is the set
of a posteriori probabilities; i.e.
i = 1,2,..., m r
As usual, however, we wish to derive a set of equivalent discriminant functions expressed in terms of class-conditional density functions and a priori probabilities as in Eq. (3). This
may be accomplished proceed ing as follows. Fi rst we writ:
1P(w,Xi,X2)
p (W X 1 , X2)
For fixed X 1 and X 2 , the denominator in Eq. (6) is constant.
Let c = 1/p(X 1 , X 2 ) and write Eq. (6) as
p(61IX^,X^)
X I , X 2 )
p(XI, X 2 , v,w)
F F^(X, , X; I v,(,,)p0),w)
p(X, , X z Iv, ILJ)1)(wlv)p(v)
The summation is over the classes which can occur at time t
factor. p(X
i , X z lv,(,j) is a joint class-conditional density; p(wly)
may be interpreted as a transition probability (the probability
time t 2 given the class was
v at time td;
is an a priori
probability.
Thus, the multiobservational decision rule analogous to Eq.
Decide X 2 c (I) i if and only if
p(X 1 1 X 2 1v k , mi)p(wi1vk)p(vk)
P(X1, X 2 J\' k ,m j )P(m j lv k )p(v k )
and the set of discriminant functions is the set of sums of
p(X 1 , X 2 lv k ,w i )p(w i ^v k )p(v k ),
i=1,2,..., m
A "Cascade" Implementation
In practice, the terms in the discriminant functions must
be estimated from "training samples." The most formidable job is
estimating the m,. m 2 joint class-conditional densities
p(X 1 , X 2 Iv k ,a) i ), each of which is of dimension 2n. 2 Clearly a
large number of training samples will be required. When certain
approximations can be justified, the situation is eased considerably. We shall now show that these approximations lead to a rather
attractive model for a multitemporal classifier.
2 The observation vectors need not be of the same dimensionality.
components
X 2 has n 7
components,
is N-variate,
We are accustomed to assuming class-conditional independence
in the spatial domain; i.e., given the class at a particular point,
the random variable which is the measurement vector at that point
is independent of the class or measurement vector at any other
point. Applying this same idea to multitemporal measurements at
a given point, we say that given the classes v at t
1 and w i at
t ? , the random variables X
1 anO X are independent. Then we can
p(X1, Xjv k ,al i ) = p(X 1 1v
k ,(j i ) P(X ? 1v k ,w i )
and furthermore
p(X 1 jv k ,1I, i ) w' P(X 1 IVk
v k ,w i ) = p (X, I'°i )
Imposing these conditions, it follows that
1 , X,Ivk,(,)i) = p(XlIvk)1) (X,Iwi).
The discriminant functions, Eq. (9), then become
p ( X 1 lvk)p(X2 Iwi)E->((ili1vk)p(""k),
i=1,2,..., m ; J
From Fq. (12) we can model the discriminant function calculations
as indicated i n 1•' i (lure 1 , from which we derive the term "cascade
r 1,i--,si f ivi" to doscriht , this; imiI It 1 ;tit(IL, classifier.
Si[11111,11 it ' ll
. 1 1111 ' 'nt.11
1'h( cascade cl.u;., ;i fiet m(alcl w.ts progr,immod and app] jed to
, analysis of a svt of l,dncisat imiltispectral data.
Tht , data,
collected by the satellite on two successive passes, eighteen days
apart, over Fayette County, Illinois (see Table 1), were qeometrically registered at Purdue University's Laboratory for Applications of Remote Sensing. The objective of the analysis was
to discriminate among the ground cover classes "corn", "soybeans",
woods", and "other", where the last category was simply a catchall consisting of water, pasture, fallow and other relatively
minor ground covers. Each class was actually decomposed in the
analysiF process into a union of subclasses, each having a data
distribution describable as approximately multivariate normal.'
To provide a baseline for com-Darison, the data from each of
the passes was first analyzed separately. The a priori probabilities of the classes were approximated as being equal, and 557
test samples, independent of the training samples, were used to
evaluate the results. As shown in Table 1(a) and (b), tho performance of this conventional maximum Likelihood classifier was
68€ correct for the June 29, 1973 data, and 722 correct for the
July 17, 1973 data.
To impleme t the cascade analysis, it was assumed unlikely
that the ground cover would change identity over so short a time
span. Accordingly, the transition probabilities were estimated
as follows:
ORIGINAL PAGE IS
OF POOR QUALITY
p(w i 1v k ) = 0.8
for ^^ i = v k ,
and all other transition probabilities were set equal and such that
All t)robability densities were assumed to be multivariate normal
(Gaussian), characterized by mean vector and covariance matrix.
p ( w i l v k ) - 0.2.
Again the ar
p iori probabilities were assumed equal and the same
test samples were used to evaluate the results.
The results of this multitemporal classification, Table 1(c),
were substantially better than either of the unitemporal analyses.
The overall results were 84% correct. In addition, the performance
for each class wris better than the best attained for the class
in either of the unitemporal analyses. The unitemporal and
multitemporal results are comt-)ared in Figure 2.
The results can he sensitive, however, to the specification
of the transition probabilities and ar
p iori probabilities. This
is demonstrated in the following experiment.
Landsat data from two passes over Grant County, Kansas, were
analyzed in a manner similar to that used for the Fayette County
data. In this case, the two passes were separated by more than
two months and a different set of classes was involved ("'abl y 2) .
The transition probabilities were specified as in Eq. (13a) and
(13b); equal a priori probabilities were assumed.
As shown in Table 2 and Figure 3, in this case the overall perform. ice of the multitempor,tI cascade classifier was only marginally
better than the best unitemporal result. A closer look at the
class-by-class results is revealing. The largest detractors from
the mul.titemporal results were the classes "alfalfa" and "pasture."
In both of these cases, the unitemporal results for the second
pass were substantially lower than those obtained in the first
(There are physical explanations for why this is reasonable,
but this is not clermane to our oxpinrition of classifier behavior.)
Let us examine the impact that the relatively arbitrary
assignment of transition probabilities has on the classification
results. In case the actual transition probabilities are not
known (which was true for the cited examples), the assignment
can be made anywhere between two extremes. On the one hanr;, it
could be assumed that
k = 1,2,..., mt
i.e., equiprobable transitions. Then the discriminant functions
have the form
P(X t I v k )p(X ? 1w.)
P( X „I^, i )
p( X:Ivk )p(vk)
= m u(X^ I^^ i )p(X t ) .
Sinc( rr and p(::,) will be common to each of the discriminant
functions, the decision will depend only on p(X,Iw i ) and will be
independent of the first-stage results.
On the other hand we could make p(w i lv i ) = 1 and p(: i 'v j ) = C,
j ¢ i. Then the discriminant functions become
1) ( X Ivi)p(X21 Ui) p(v i).
Thus, in a sense, the contributions from the two stages are weighted
ORIGINAL. PAGE IS
' l%' PWR QUALITY
There is nn way to make the first_ sta ge in put dominate the
second stage.
In view of these considerations, another classification of
the Grant County data was performed. In this case, the transition
probabilities n(w i Iv i ) were set equal to unity for the "alfalfa"
and "pasture" classes in order to give as much strength as possible to the first stare results. Table 3 a-id r ioure 3 sho p, the
outcome o" this classification. The confusin.a influence resulting
from the second stage data has been rc,ciuc(-(,.
It is interestinct to compare the results obtained using the
cascade classifier to results lroduced by a "conventional" maximum
likelihood classifier using all. of the multitecnhoral features simultaneously. To perform the latter classifications, e(jual. e rrieri
oi)abilities were assume . The results were:
Fayhtte County: 80.8 percent correct
.rant: County:
64. 1 percent corrl!r.t
It is curious that neither of thhr;t- results is anv batter th."ln th-cascade cl-assifier results achieved.
it is lrossible that those
slightly poo rer r(-suits re prL-sent the price t)aid for 1;avinq to
estimate 9-dimen-;ic
statistics as opposed to 4-dimensional
statistics in the face of limited trainin g riata.
)Discussion anti Conclusions
The aoltroach we h.lve adotitecl for classi fyinq data ir, a nonstation.lry 4'I1:'lr(tnlnonI was 1+.l:i r ^l o n .1,+111 l r ',lt t
1 ,rl of cI ass- lCJ1
;t.lt l:;l 1 ,7.11
1r'1'l::lU.
:;t r.l lrlht turw.lttt
111 Il+nr'1
Ilr+wt Vt r,
('11111111 11,11`: l tl
t11 • 1 . 1"((,thin ti) .ir)prOYimotk-
st lt_i .t ic.11
111.1 ►11 it ios
pili!; r.tolt siinpl ifieA thr' intt-r-
+lopen 1.t1 . 11c1
of t 111 • data invrtivl • I all , ! 1'
"o.irt-a(l' classl' l' r"
model. Tn the time-varying environment, this model is seen to:
Succes.fully incorporate the temporal information in
-he classification process, resulting in improved classification
P,educe the dimensionality of the probability functions
used and thereby make less strinctent demands with respoct to the
size of the training set required;
Facilitate distribution of the com putational load over
Each time a set of observations becomes available, discriminant functions are calculated which can be used, if desirod,
to make a classification. however, the valuos of the discriminant functions are also Fussed along and contribute to a new set
o` discriminant functions calculated when the next set of observations
is obtained. Although we have demonstrated the use of the cascade
model only for the case of two stages, extension to an arbitrary
number of stages p resents no difficulty.
The p ros pective user of this anproach should he aware that
a casual implementation of the likelihood comnuters may result
in computational difficulties of two sorts: loss of precision
and very large computation times as comnared with, ray, a conventional jaussian maximum likelihood classifier. Roth of these
difficulties can be overcome or at least substantiall y reduced
by appropriate measures (scaling, ianoring zero terms, otc.)
in carrving out the likelihood computations.
ORIGINAL PAGE IS
OF POOR QUALITY
Ackncwledgements
The author wishes to thank Mr. Carlos A. Pomalaza for
programminn the cascade classifier model and testing it with
the remote sensing data. This research was supported in nirt
':AS' Contract _dAS9-14970.