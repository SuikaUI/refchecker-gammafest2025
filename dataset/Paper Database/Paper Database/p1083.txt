The Thirty-Third AAAI Conference on Artiﬁcial Intelligence (AAAI-19)
RobustSTL: A Robust Seasonal-Trend
Decomposition Algorithm for Long Time Series
Qingsong Wen, Jingkun Gao, Xiaomin Song, Liang Sun, Huan Xu, Shenghuo Zhu
Machine Intelligence Technology, Alibaba Group
Bellevue, Washington 98004, USA
{qingsong.wen, jingkun.g, xiaomin.song, liang.sun, huan.xu, shenghuo.zhu}@alibaba-inc.com
Decomposing complex time series into trend, seasonality, and
remainder components is an important task to facilitate time
series anomaly detection and forecasting. Although numerous methods have been proposed, there are still many time
series characteristics exhibiting in real-world data which are
not addressed properly, including 1) ability to handle seasonality ﬂuctuation and shift, and abrupt change in trend and reminder; 2) robustness on data with anomalies; 3) applicability on time series with long seasonality period. In the paper,
we propose a novel and generic time series decomposition algorithm to address these challenges. Speciﬁcally, we extract
the trend component robustly by solving a regression problem using the least absolute deviations loss with sparse regularization. Based on the extracted trend, we apply the the
non-local seasonal ﬁltering to extract the seasonality component. This process is repeated until accurate decomposition is
obtained. Experiments on different synthetic and real-world
time series datasets demonstrate that our method outperforms
existing solutions.
Introduction
With the rapid growth of the Internet of Things (IoT) network and many other connected data sources, there is an
enormous increase of time series data. Compared with traditional time series data, it comes in big volume and typically has a long seasonality period. One of the fundamental problems in managing and utilizing these time series
data is the seasonal-trend decomposition. A good seasonaltrend decomposition can reveal the underlying insights of
a time series, and can be useful in further analysis such
as anomaly detection and forecasting . For example, in anomaly detection a local anomaly could be a spike
during an idle period. Without seasonal-trend decomposition, it would be missed as its value is still much lower than
the unusually high values during a busy period. In addition,
different types of anomalies correspond to different patterns
in different components after decomposition. Speciﬁcally,
the spike & dip anomalies correspond to abrupt change of
remainder, and the change of mean anomaly corresponds to
Copyright c⃝2019, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.
abrupt change of trend. Similarly, revealing the trend of time
series can help to build more robust forecasting models.
As the seasonal adjustment is a crucial step for time series where seasonal variation is observed, many seasonaltrend decomposition methods have been proposed. The most
classical and widely used decomposition method is the STL
(Seasonal-Trend decomposition using Loess) . STL estimates the trend and the seasonality in an
iterative way. However, STL still suffers from less ﬂexibility when seasonality period is long and high noises are observed. In practice, it often fails to extract the seasonality
component accurately when seasonality shift and ﬂuctuation
exist. Another direction of decomposition is X-13-ARIMA-
SEATS and its variants such as
X-11-ARIMA, X-12-ARIMA , which are
popular in statistics and economics. These methods incorporate more features such as calendar effects, external regressors, and ARIMA extensions to make them more applicable and robust in real-world applications, especially in economics. However, these algorithms can only scale to small or
medium size data. Speciﬁcally, they can handle monthly and
quarterly data, which limits their usage in many areas where
long seasonality period is observed. Recently, more decomposition algorithms have been proposed . For example, in , a two-dimensional representation
of the seasonality component is utilized to learn the slowly
changing seasonality component. Unfortunately, it cannot
scale to time series with long seasonality period due to the
cost to learn the huge two-dimensional structure.
Although numerous methods have been proposed, there
are still many time series characteristics exhibiting in realworld data which are not addressed properly. First of all, seasonality ﬂuctuation and shift are quite common in real-world
time series data. We take a time series data whose seasonality period is one day as an example. The seasonality component at 1:00 pm today may correspond to 12:30 pm yesterday, or 1:30 pm the day before yesterday. Secondly, most
algorithms cannot handle the abrupt change of trend and remainder, which is crucial in anomaly detection for time series data where the abrupt change of trend corresponds to
the change of mean anomaly and the abrupt change of residual corresponds to the spike & dip anomaly. Thirdly, most
methods are not applicable to time series with long seasonality period, and some of them can only handle quarterly or
monthly data. Let the length of seasonality period be T, we
need to estimate T −1 parameters to extract the seasonality
component. However, in many IoT anomaly detection applications, the typical seasonality period is one day. If a data
point is collected every one minute, then T = 1440, which
is not solvable by many existing methods.
In this paper, we propose a robust and generic seasonaltrend decomposition method. Compared with existing algorithms, our method can extract seasonality from data with
long seasonality period and high noises accurately and effectively. In particular, it allows fractional, ﬂexible, and shifted
seasonality component over time. Abrupt changes in trend
and remainder can also be handled properly. Speciﬁcally,
we extract the trend component robustly by solving a regression problem using the least absolute deviations (LAD)
loss with sparse regularizations. After the trend is extracted, we apply the non-local
seasonal ﬁltering to extract the seasonality component robustly. This process is iterated until accurate estimates of
trend and seasonality components are extracted. As a result, the proposed seasonal-trend decomposition method is
an ideal tool to extract insights from time series data for the
purpose of anomaly detection. To validate the performance
of our method, we compare our method with other stateof-the-art seasonal-trend decomposition algorithms on both
synthetic and real-world time series data. Our experimental
results show that our method can successfully extract different components on various complicated datasets while other
algorithms fail.
Note that time series decomposition approaches can be either additive or multiplicative. In this paper we focus on the
additive decomposition, and the multiplicative decomposition can be obtained similarly. The remainder of this paper
is organized as follows: Section 2 brieﬂy introduces the related work of seasonal-trend decomposition; In Section 3 we
discuss our proposed seasonal-trend decomposition method
in detail; the empirical studies are investigated in comparison with several state-of-the-art algorithms in Section 4; and
we conclude the paper in Section 5.
Related Work
As we discussed in Section 1, the “classical” method
 continues to evolve from X-11, X-11-
ARIMA to X-13-ARIMA-SEATS and improve their capabilities to handle seasonality with better robustness. A recent
algorithm TBATS (Trigonometric Exponential Smoothing
State Space model with Box-Cox transformation, ARMA errors, Trend and Seasonal Components) is introduced to handle complex, noninteger seasonality. However, they all can be described by
the state space model with a lot of hidden parameters when
the period is long. They are suitable to process time series
with short seasonality period (e.g., tens of points) but suffer
from the high computational cost for time series with long
seasonality period and they cannot handle slowly changing
seasonality.
The Hodrick-Prescott ﬁlter ,
which is similar to Ridge regression, was introduced to decompose slow-changing trend and fast-changing residual.
While the formulation is simple and the computational cost
is low, it cannot decompose trend and long-period seasonality. And it only regularizes the second derivative of the ﬁtted
curve for smoothness. This makes it prone to spike and dip
and cannot catch up with the abrupt trend changes.
Based on the Hodrick-Prescott ﬁlter, STR (Seasonal-
decomposition
Regression) which
explores the joint extraction of trend, seasonality and
residual without iteration is proposed recently. STR is
ﬂexible to seasonal shift, and it can not only deal with
multiple seasonalities but also provide conﬁdence intervals
for the predicted components. To get a better tolerance to
spikes and dips, robust STR using ℓ1-norm regularization
is proposed. The robust STR works well with outliers.
But still, as the authors mentioned in the conclusion, STR
and robust STR only regularize the second difference of
ﬁtted trend curve for smoothness so it cannot follow abrupt
change on the trend.
The Singular Spectrum Analysis (SSA) is a modelfree approach that performs well on short time series. It
transforms a time series into a group of sliding arrays, folds
them into a matrix and then performs SVD decomposition
on this matrix. After that, it picks the major components
to reconstruct the time series components. It is very similar
to principal component analysis, but its strong assumption
makes it not applicable on some real-world datasets.
As a summary, when comparing different time series decomposition methods, we usually consider their ability in the
following aspects: outlier robustness, seasonality shift, long
period in seasonality, and abrupt trend change. The complete
comparison of different algorithms is shown in Table 1.
Table 1: Comparison of different time series decomposition
algorithms (Y: Yes / N: No)
Robustness
Seasonality
Trend Change
ARIMA/SEATS
Our RobustSTL
Robust STL Decomposition
Model Overview
Similar to STL, we consider the following time series model
with trend and seasonality
yt = τt + st + rt,
t = 1, 2, ...N
where yt denotes the observation at time t, τt is the trend in
time series, st is the seasonal signal with period T, and the rt
denotes the remainder signal. In seasonal-trend decomposition, seasonality typically describes periodic patterns which
ﬂuctuates near a baseline, and trend describes the continuous increase or decrease. Thus, usually it is assumed that
the seasonal component st has a repeated pattern which
changes slowly or even stays constant over time, whereas
the trend component τt is considered to change faster than
the seasonal component . Also note that in this decomposition we assume
the remainder rt contains all signals other than trend and
seasonality. Thus, in most cases it contains more than white
noise as usually assumed. As one of our interests is anomaly
detection, we assume rt can be further decomposed into two
rt = at + nt,
where at denotes spike or dip, and nt denotes the white
In the following discussion, we present our RobustSTL
algorithm to decompose time series which takes the aforementioned challenges into account. The RobustSTL algorithm can be divided into four steps: 1) Denoise time series by applying bilateral ﬁltering ; 2) Extract trend robustly by solving a LAD
regression with sparse regularizations; 3) Calculate the seasonality component by applying a non-local seasonal ﬁltering to overcome seasonality ﬂuctuation and shift; 4) Adjust
extracted components. These steps are repeated until convergence.
Noise Removal
In real-world applications when time series are collected,
the observations may be contaminated by various types of
errors or noises. In order to extract trend and seasonality
components robustly from the raw data, noise removal is indispensable. Commonly used denoising techniques include
low-pass ﬁltering , moving/median average , and Gaussian ﬁlter . Unfortunately, those ﬁltering/smoothing techniques destruct some underlying structure in τt and st in
noise removal. For example, Gaussian ﬁlter destructs the
abrupt change of τt, which may lead to a missed detection
in anomaly detection.
Here we adopt bilateral ﬁltering to remove noise, which is an edge-preserving
ﬁlter in image processing. The basic idea of bilateral ﬁltering is to use neighbors with similar values to smooth the
time series {yt}N
t=1. When applied to time series data, the
abrupt change of trend τt, and spike & dip in at can be fully
preserved.
Formally, we use {y′
t=1 to denote the ﬁltered time series
after applying bilateral ﬁltering:
J = t, t ± 1, · · · , t ± H
where J denotes the ﬁlter window with length 2H + 1, and
the ﬁlter weights are given by two Gaussian functions as
z is a normalization factor, δ2
i are two parameters which control how smooth the output time series will
After denoising, the decomposition model in Eq. (1) is
updated as
t = τt + st + r′
t = at + (nt −ˆnt)
where the ˆnt = yt −y′
t is the ﬁltered noise.
Trend Extraction
The joint learning of τt and st in Eq. (5) is challenging. As
the seasonality component is assumed to change slowly, we
ﬁrst perform seasonal difference operation for the denoised
t to mitigate the seasonal effects, i.e.,
gt = ∇T y′
= ∇T τt + ∇T st + ∇T r′
∇τt−i + (∇T st + ∇T r′
where ∇T xt = xt −xt−T is the seasonal difference operation, and ∇xt = xt −xt−1 is the ﬁrst order difference
operation.
Note that in Eq. (7), PT −1
i=0 ∇τt−i dominates gt as we assume the seasonality difference operator on st and r′
to signiﬁcantly smaller values. Thus, we propose to recover
the ﬁrst order difference of trend signal ∇τt from gt by minimizing the following weighted sum objective function
|∇2τt|, (8)
where ∇2xt = ∇(∇xt) = xt −2xt−1 + xt−2 denotes the
second order difference operation. The ﬁrst term in Eq. (8)
corresponds to the empirical error using the LAD instead of the commonly used sum-ofsquares loss function due to the its well-known robustness to
outliers. Note that here we assume that gt ≈PT −1
i=0 ∇τt−i.
This assumption may not be true in the beginning for some
t, but since the proposed framework employs an alternating
algorithm to update trend τt and seasonality st iteratively,
later we can remove ∇T st + ∇T r′
t from gt to make it hold.
The second and third terms are ﬁrst-order and second-order
difference operator constraints for the trend component τt,
respectively. The second term assumes that the trend difference ∇τt usually changes slowly but can also exhibit some
abrupt level shifts; the third term assumes that the trends are
smooth and piecewise linear such that ∇2xt = ∇(∇xt) =
xt −2xt−1 + xt−2 are sparse . Thus, we
expect the trend component τt can capture both abrupt level
shift and gradual change.
The objective function (8) can be rewritten in an equivalent matrix form as
||g −M∇τ||1 + λ1||∇τ||1 + λ2||D∇τ||1,
where ||x||1 = P
i |xi| denotes the ℓ1-norm of the vector x,
g and ∇τ are the corresponding vector forms as
g = [gT +1, gT +2, · · · , gN]T ,
∇τ = [∇τ2, ∇τ3, · · · , ∇τN]T ,
M and D are (N −T) × (N −1) and (N −2) × (N −1)
Toeplitz matrix, respectively, with the following forms
To facilitate the process of solving the above optimization
problem, we further formulate the three ℓ1-norms in Eq. (9)
as a single ℓ1-norm, i.e.,
||P∇τ −q||1,
where the matrix P and vector q are
M(N−T )×(N−1)
λ1I(N−1)×(N−1)
λ2D(N−2)×(N−1)
The minimization of the single ℓ1-norm in Eq. (12) is equivalent to the linear program as follows
where v is auxiliary vector variable. Let denote the output of the above optimization is [∇˜τ, ˜v]T with ∇˜τ
[∇˜τ2, ∇˜τ3, · · · , ∇˜τN]T , and further assume ˜τ1 = τ1 (which
will be be estimated later). Then, we can get the relative
trend output based on τ1 as
t = ˜τt −τ1 = ˜τt −˜τ1 =
Once obtaining the relative trend from the denoised time
series, the decomposition model is updated as
t = st + τ1 + r′′
t = at + (nt −ˆnt) + (τt −˜τt).
Seasonality Extraction
After removing the relative trend component, y′′
i can be considered as a “contaminated seasonality”. In addition, seasonality shift makes the estimation of si even more difﬁcult. Traditional seasonality extraction methods only considers a subsequence yt−KT , yt−(K−1)T , · · · , yt−T (or associated sequences) to estimate st, where T is the period length.
However, this approach fails when seasonality shift happens.
In order to accurately estimate the seasonality component, we propose a non-local seasonal ﬁltering. In the
non-local seasonal ﬁltering, instead of only considering
yt−KT , · · · , yt−T , we consider K neighborhoods centered at yt−KT , · · · , yt−T , respectively. Speciﬁcally, for
t−kT , its neighborhood consists of 2H + 1 neighbors
t−kT −H, y′′
t−kT −H+1, · · · , y′′
t−kT , y′′
t−kT +1, · · ·, y′′
Furthermore, we model the seasonality component st as
a weighted linear combination of y′′
j where y′′
j is in the
neighborhood deﬁned above. The weight between y′′
depends not only in how far they are in the time dimension
(i.e., the difference of their indices t and j), but also depends
on how close y′′
j are. Intuitively, the points in the
neighborhood with similar seasonality to yt will be given a
larger weight. In this way, we automatically ﬁnd the points
with most similar seasonality and solve the seasonality shift
problem. In addition, abnormal points will be given smaller
weights in our deﬁnition and makes the non-local seasonal
ﬁltering robust to outliers.
Mathematically, the operation of seasonality extraction by
non-local seasonal ﬁltering is formulated as
where the wt
(t′,j) and Ωare deﬁned as
(t′,j) = 1
Ω= {(t′, j)|(t′ = t −k × T, j = t′ ± h)}
k = 1, 2, · · · , K; h = 0, 1, · · · , H
by considering previous K seasonal neighborhoods where
each neighborhood contains 2H + 1 points.
To illustrate the robustness of our non-local seasonal
ﬁltering to outliers, we give an example in Figure 1(a).
Whether there is outlier at current time point t (dip), or at
historical time point around t−T (spike), the ﬁltered output
˜st (red curve) would not be affected as show in Figure 1(a).
Figure 1(b) illustrates why seasonality shift is overcome by
the non-local seasonal ﬁltering. As shown in the red curve
in Figure 1(b), when there is ∆t shift in the season pattern,
as long as the previous seasonal neighborhoods used in the
non-local seasonal ﬁlter satisfy H > ∆t, the extracted season can follow this shift.
After removing the season signal, the remainder signal is
t −˜st = at + (nt −ˆnt) + (τt −˜τt) + (st −˜st).
(a) Outlier robustness
(b) Season shift adaptation
Figure 1: Robust and adaptive properties of the non-local
seasonal ﬁltering (red curve denotes the extracted seasonal
Final Adjustment
In order to make the seasonal-trend decomposition unique,
we need to ensure that all seasonality components in a period sums to zero, i.e., Pi=j+T −1
si = 0. To this end, we
adjust the obtained seasonality component from Eq. (17) by
removing its mean value, which also corresponds to the estimation of the trend point τ1. Formally, we have
Therefore, the estimates of trend and seasonal components
are updated as follows:
ˆst = ˜st −ˆτ1,
ˆτt = ˜τ r
And the estimate of remainder can be obtained as
ˆrt = r′′′
ˆrt = yt −ˆst −ˆτt.
Furthermore, we can derive different components of the estimated ˆrt, i.e.,
at + nt + (st −ˆst) + (τ1 −ˆτ1),
at + nt + (st −ˆst) + (τt −˜τt),
Eq. (24) indicates that the remainder signal ˆrt may contain residual seasonal component (st−ˆst) and trend component (τt −˜τt). Also in the trend estimation step, we assume
i=0 ∇τt−i can be approximated using gt. Similar to alternating algorithm, after we obtained better estimates of τt,
st, and rt, we can repeat the above four steps to get more
accurate estimates of the trend, seasonality, and remainder
components. Formally, the procedure of the RobustSTL algorithm is summarized in Algorithm 1.
Algorithm 1 RobustSTL Algorithm Summary
Input: yt, parameter conﬁgurations.
Output: ˆτt, ˆst, ˆrt
Step 1: Denoise input signal using bilateral ﬁlter
Step 2: Obtain relative trend from ℓ1 sparse model
∇˜τ = arg min∇τ||P∇τ −q||1(see Eq. (8), (9), (12))
Step 3: Obtain season using non-local seasonal ﬁltering
(t′,j) = 1
(t′,j)∈Ωwt
Step 4: Adjust trend and season
ˆτt = ˜τ r
t + ˆτ1, ˆst = ˜st −ˆτ1, ˆrt = yt −ˆst −ˆτt
Step 5: Repeat Steps 1-4 for ˆrt until convergence
Experiments
We conduct experiments to demonstrate the effectiveness of
the proposed RobustSTL algorithm on both synthetic and
real-world datasets.
Baseline Algorithms
We use the following three state-of-the-art baseline algorithms for comparison purpose:
• Standard STL: It decomposes the signal into seasonality,
trend, and remainder based on Loess in an iterative manner.
• TBATS: It decomposes the signal into trend, level, seasonality, and remainder. The trend and level are jointly
together to represent the real trend.
• STR: It assumes the continuity in both trend and seasonality signal.
To test the above three algorithms, we use R functions
stl, tbats, AutoSTR from R packages forecast1
and stR2. We implement our own RobustSTL algorithm in
Python, where the linear program (see Eqs. (12) and (13)) in
trend extraction is solved using CVXOPT ℓ1-norm approximation3.
Experiments on Synthetic Data
To generate the synthetic dataset, we incorporate
complex season/trend shifts, anomalies, and noise to simulate real-world scenarios as shown in Figure 2. We ﬁrst generate seasonal signal using a square wave with minor random
seasonal shifts in the horizontal axis. The seasonal period is
set to 50 and a total of 15 periods are generated. Then, we
add trend signal with 10 random abrupt level changes and
14 spikes and dips as anomalies. The noise is added by zero
mean Gaussian with 0.1 variance.
Figure 2: Generated synthetic data where the top subplot
represents the raw data and the trend, the middle subplot
represents the seasonality, and the bottom subplot represents
the noise and anomalies.
1 
2 
3 
(a) RobustSTL
(b) Standard STL
Figure 3: Decomposition results on synthetic data for a) Robust STL; b) Standard STL; c) TBATS; and d) STR.
Experimental Settings
For the three baseline algorithms
STL, TBATS, and STR, their parameters are optimized using cross-validation. For our proposed RobustSTL algorithm, we set the regularization coefﬁcients λ1 = 10, λ2 =
0.5 to control the signal smoothness in the trend extraction,
and set the neighborhood parameters K = 2, H = 5 in the
seasonality extraction to handle the seasonality shift.
Decomposition Results
Figure 3 shows the decomposition results for four algorithms. The standard STL is affected
by anomalies leading to rough patterns in the seasonality
component. The trend component also tends to be smooth
and loses the abrupt patterns. TBATS is able to respond to
the abrupt changes and level shifts in trend, however, the
trend is affected by the anomaly signals. It also obtains almost the same seasonality pattern for all periods. Meanwhile, STR does not assume strong repeated patterns for
seasonality and is robust to outliers. However, it cannot handle the abrupt changes of trend. By contrast, the proposed
RobustSTL algorithm is able to separate trend, seasonality,
and remainders successfully, which are all very close to the
original synthetic signals.
To evaluate the performance quantitatively, we also compare mean squared error (MSE) and mean absolute error
(MAE) between the true trend/season in the synthetic dataset
and the extracted trend/season from four decomposition algorithms, which is summarized in Table 2. It can be observed that our RobustSTL algorithm achieves much better
results than STL, STR, and TBATS algorithms.
Table 2: Comparison of MSE and MAE for trend and seasonality components of different decomposition algorithms.
Algorithms
Standard STL
Experiments on Real-World Data
The real-world datasets to be evaluated include
two time series. One is the supermarket and grocery stores
turnover from 2000 to 2009 , which
has a total of 120 observations with the period T = 12.
We apply the log transform on the data and inject the trend
changes and anomalies to demonstrate the robustness ). The input data can
be seen in the top subplot of Figure 4 (a). We denote it as
real dataset 1. Another time series is the ﬁle exchange count
number in a computer cluster, which has a total of 4032 observations with the period being 288. We apply the linear
transform to convert the data to the range of for the
purpose of data anonymization. The data can be seen in the
top subplot of Figure 5 (a). We denote it as real dataset 2.
(a) RobustSTL
(b) Standard STL
Figure 4: Decomposition results on real dataset 1 for a) RobustSTL; b) Standard STL; c) TBATS and d) STR.
(a) RobustSTL
(b) Standard STL
Figure 5: Decomposition results on real dataset 2 for a) Robust STL; b) Standard STL; and c) TBATS.
Experimental Settings
For all four algorithms, period parameter T = 12 is used for real-world dataset 1, and T =
288 is used for dataset 2. The rest parameters are optimized
using cross-validation for the standard STL, TBATS, and
STR. For our proposed RobustSTL algorithm, we set the
neighbour window parameters K = 2, H = 2, the regularization coefﬁcients λ1 = 1, λ2 = 0.5 for real data 1, and
K = 2, H = 20, λ1 = 200, λ2 = 200 for real data 2. Notice
that as STR is not scalable to time series with long seasonality period, we do not report the decomposition result of
dataset 2 for STR.
Decomposition Results
Figure 4 and Figure 5 show the
decomposition results on both real-world datasets. Robust-
STL typically extracts smooth seasonal signals on realworld data. The seasonal component can adapt to the changing patterns and the seasonality shifts, as seen in Figure 4
(a). The extracted trend signal recovers the abrupt changes
and level shifts promptly and is robust to the existence of
anomalies. The spike anomaly is well preserved in the remainder signal. For the standard STL and STR, the trend
does not follow the abrupt change and the seasonal component is highly affected by the level shifts and spike anomalies in the original signal. TBATS can decompose the trend
signal that follows the abrupt change, however, the trend is
affected by the spike anomalies.
During the experiment, it is also observed that the computation speed of RobustSTL is signiﬁcantly faster than
TBATS and STR (note the result for STR is not available
in Figure 5 due to its long computation time), as the algorithm can be formulated as an optimization problem with ℓ1norm regularization and solved efﬁciently. While the standard STL seems computational efﬁcient, its sensitivity to
anomalies and incapability to capture the trend change and
level shifts make it difﬁcult to be used on enormous realworld complex time series data.
Based on the decomposition results from both the synthetic and the real-world datasets, we conclude that the proposed RobustSTL algorithm outperforms existing solutions
in terms of handling abrupt and level changes in the trend
signal, the irregular seasonality component and the seasonality shifts, the spike & dip anomalies effectively and efﬁciently.
Conclusion
In this paper, we focus on how to decompose complex long
time series into trend, seasonality, and remainder components with the capability to handle the existence of anomalies, respond promptly to the abrupt trend changes shifts,
deal with seasonality shifts & ﬂuctuations and noises, and
compute efﬁciently for long time series. We propose a robustSTL algorithm using LAD with ℓ1-norm regularizations
and non-local seasonal ﬁltering to address the aforementioned challenges. Experimental results on both synthetic
data and real-world data have demonstrated the effectiveness
and especially the practical usefulness of our algorithm. In
the future we will work on how to integrate the seasonaltrend decomposition with anomaly detection directly to provide more robust and accurate detection results on various
complicated time series data.