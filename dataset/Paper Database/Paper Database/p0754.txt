IEEE TRANSACTIONS ON AUTOMATIC CONTROL. VOL. AC-3 I . NO. 4. APRIL 1986
Distributed Asynchronous Optimal Routing in Data
Abstract-In
this paper we study the performance of B class of
distributed optimal routing algorithms of the gradient projection type
under weaker and more realistic assumptions than those considered thus
far. In particular, we show convergence to an optimal routing without
assuming synchronization of computation at all nodes and measurement
of link lengths at all links, while taking into account the possibility of link
flow transients caused by routing updates. This demonstrates the
robustness of these algorithms in a realistic distributed operating
environment.
I. JKTRODUCTION
HE most popular formulation of the optimal distributed
routing problem in a data. network is based on a
multicommodity flow optimization whereby a separable objective
function of the form
is minimized with respect to the
flow variables F'J subject to
multicommodity flow constraints [ 11- ,1121. Here (i, j ) denotes
a generic directed
network link, and D'J is a strictly
differentiable? increasing function of F'j which represents in turn
the total traffic arrival rate on link (i, j ) measured, for example. in
packets or bits per second.
We want to find a routing that minimizes this objective. By a
routing we mean a set of active paths for each origin-destination
(OD) pair (set of paths
carrying some traffic of that OD pair),
together with the fraction of total traffic of the
OD pair routed
along each active path.
example of adaptive distributed routing, patterned
after the ARPANET algorithm , operates roughly as follows.
The total link arrival rates F'J are measured by time averaging
over a period of time. and are communicated to all network nodes.
Upon reception of these measured rates each node updates the part
of the routing dealing with traffic originating at that node. The
updating method
is based on some rule, e.g., a shortest path
method , . or an iterative optimization algorithm [ 11, .
There are a number of variations of this idea: for example,
some relevant function of F'J may be measured in place of F'J
[such as average delay per packet crossing link (i, j)]. or a
somewhat different type of routing policy may be used, but these
will not concern us for the time being. The preceding algorithm is
used in this paper as an example which is interesting in its
right but also involves ideas that
are common to other types of
routing algorithms.
Most of the existing analysis of distributed routing algorithms
such as thc one above is predicated on several assumptions that are
to some extent violated in practice. These are as follows.
Manuscript received April 11. 1985; revised November 8. 1985. Paper
recommended by Associate Editor, T. L. Johnson. This work was supported
by DARPA under Contract ONR-N00014-75-C-I 183 and by an IBM Faculty
Development Award.
bridge. MA 02139.
The authors are with the Massachusetts Institute of Technology. Carn-
IEEE Log Number 8407380.
1) The quasi-static assumption, i.e., the external traffic
arrival process for each OD pair is stationary over time. This
assumption is approximately valid when there is a large number of
user-pair conversations associated with each OD pair, and each of
these conversations has an arrival rate that is small relative to the
total arrival rate for the OD pair (i.e.. a "many small users"
assumption). An asymptotic analysis of the effect of violation of
this assumption on the stationary character of the external traffic
arrival rates is given in .
2) The fast settling time assumption, i.e., transients in the
flows F'J due to changes in routing are negligible. In other words,
once the routing is updated, the flows F'J settle to their new values
within time which
is very small relative to the time between
routing updates. This assumption is typically valid in
networks but less so in virtual circuit networks where, existing
virtual circuits may not be rerouted after a routing update. When
this assumption is violated, link flow measurements F'J reflect a
dependence not just on the current routing but also on possibly
several past routings.
A seemingly good model is to represent
each F'j as a convex combination of the rates of arrival at (i, j )
corresponding to two or more past routing updates.
3) The synchronous update assumption, i.e., all link rates
F'j are measured simultaneously, and are received simultaneously
at all network nodes who in turn
simultaneously carry out
routing update. However. there may be technical reasons (such as
software complexity) that argue against enforcing a synchronous
update protocol. For example, the distributed routing algorithm of
the ARPANET is not operated synchronously. Furthermore,
in an asynchronous updating environment, the rates F'J are
typically measured as time averages that reflect dependence on
more than one update.
In this paper we study gradient projection methods, which are
one of the most interesting classes of algorithms for distributed
optimal routing. A typical iteration in a gradient method consists
of making a small update in a direction which improves the value
of the cost function, e.g., opposite to the direction of the gradient.
A gradient projection method is a modification of this idea, so that
constrained optimization problems (such as the multicommodity
flow problem of this paper) may be handled as well: namely,
whenever an update leads to a point outside the feasible set (which
is determined by the constraints of the problem), feasibility is
enforced by projecting that point back into the feasible set. The
first application of this type of gradient projection method in data
communication routing is due to Gallager [I] as explained later in
[ 141. Gallager's method operates in a space of link flow fractions.
Related gradient projection methods which operate in the space of
path flows are given in , . [ 151. and [ 161. This latter class of
methods is the starting point for the analysis of the present paper.
We conjecture, however. that qualitatively similar results hold for
Gallager's method a5 well as for its second derivative version .
Our main result
states that gradient projection methods for
optimal routing are valid even if the settling time and synchronous
update assumption are violated to a considerable extent. Even
though we retain
the quasi-static assumption in our analysis, we
conjecture that the result of this paper can be generalized along the
lines of another related study where it is shown that a routing
algorithm based on a shortest path rule converges to a neighbor-
hood of the optimum. The size of this neighborhood depends on
0018-9286/86/0400-0325$01 .OO @ 1986 IEEE
IEEE'TRANSACTIONS ON AUTOMATIC CONTROL, VOL. AC-31. NO. 4, APRIL 1986
the extent of violation of the quasi-static assumption. A similar
deviation from optimality can
be caused by errors in the
measurement of F'J. In our analysis, these errors are neglected.
A practical routing algorithm
that nearly
falls within the
framework of the present paper is the one implemented
CODEX network
1181. There destination nodes
of OD pairs
asynchronously assign and reroute virtual circuits to shortest paths
with respect to link lengths that relate to first derivatives of link
costs. Only one virtual circuit can be rerouted at a time.
several virtual circuits can be rerouted before new measurements
are received. More precisely, a destination
node assigns (or
reroutes) a virtual circuit to a path for which the assignment
(rerouting) results in minimum cost. This is equivalent to
assignment (rerouting) on a shortest path with
respect to link
lengths which are first derivatives of link costs evaluated at a flow
that lies between the current flow and the flow resulting once the
assignment (rerouting) is effected. Another difference is that, in
the CODEX network, each virtual circuit may carry flow that is a
substantial portion of a link's capacity. This may place a lower
bound on the amount of flow that can be diverted to a shortest path
at each iteration.
In the next section we provide some background on distributed
asynchronous algorithms and discuss the relation of the result of
the present paper
with earlier analyses. In Section ZII we
formulate our class of distributed asynchronous routing al-
gorithms and present our main results. In Section IV we study a
related algorithm. The proofs of our results may be found in the
11. ASYNCHRONOUS OPTIMIZATION ALGORITHMS
We provide here a brief discussion of the currently available
theory and tools of analysis of asynchronous distributed
gorithms. An extensive survey may be be found in
 . In a
typical such algorithm (aimed at solving an optimization problem)
each processor i has in its memory a vector xi which may be
interpreted as an estimate of an optimal solution. Each processor
obtains measurements. performs computations, and updates some
of the components of its vector. Concerning the other compo-
nents. it relies entirely on messages received from other proces-
sors. We are mainly interested in the case
where minimal
assumptions are placed on the orderliness of message exchanges.
There are two
distinct approaches for analyzing algorithmic
convergence. The first approach is essentially a generalization of
the Lyapunov function
method for proving convergence
centralized iterative processes. The idea here is that, no matter
what the precise sequence of message exchange is. each update by
any processor brings its vector xi closer to the optimum in some
sense. This approach applies primarily
to problems involving
monotone or contraction mappings with respect to a "sup-"norm
(e.g., a distributed shortest path algorithm) [SI, ; it is only
required that each processor communicates
to every other
processor an infinite number of times.
The second approach is based on the idea that if the processors
communicate fast enough relative to the speed of convergence of
the computation, then the evolution of their solution estimates x'
may be (up to first order in the step-size used) the same as if all
processors were communicating
to each other at each time
instance [ 101, [ 111. The latter case is, however, mathematically
equivalent to a centralized (synchronous) algorithm for
there is an abundance of techniques and results. Notice that in this
approach, slightly stronger assumptions are placed on the nature
communication process than
in the first one. This
compensated by the fact that the corresponding method of analysis
applies to broader classes of algorithms.
The method of analysis of the present paper is close in spirit to
the second approach outlined above. Unfortunately, however, the
results available cannot be directly applied to the routing problem
studied in this paper and a new proof is required. One reason is
that earlier results concern algorithms for unconstrained optimiza-
tion. In the routing problem, the nonnegativity and the conserva-
tion of flow introduce inequality and equality constraints. While
equality constraints could be taken care
of by eliminating some of
the variables, inequality constraints must be explicitly taken into
account. Another difference
arises because, in the routing
algorithm. optimization is carried out with respect to path flow
variables, whereas the messages being broadcast contain estimates
of the link
flows (see the next
section). In earlier results the
variables being communicated were assumed
to be the same as the
variables being optimized. Finally, the transient behavior of the
network (which results from the fact that we do not make the fast
settling time assumption) adds a few more particularities to the
model and the analysis.
111. THE ROUTING
We present here our basic assumptions, our notation, and the
model by which the nodes in a communication network may adjust
the routing of the flows through that network.
We are given a network described
by a directed graph G = (V,
E). (V is the set of nodes, E the set of directed links.) For each
pair w = (i, j ) of distinct nodes i and j (also called on origin-
destination. or OD pair) we introduce P,,., a set of directed paths
from i to j , containing no loops. (These are the candidate paths for
carrying the flour from i to j.) For each OD pair w = (i, j ) . let r,,
be the total arrival rate at node i of traffic that has to be sent to
nodej (measured. for example, in packets or bits per second). For
each path p E P,,., we denote by x,,p the amount of flow which is
routed through path p . Naturally, we have the constraints
x , 1 . , p 2 0 ,
v P E P,V, v w,
x,,.,p = r,,., v w.
Let us define a vector x, with components x,,..~, p E P,. Suppose
that there is a total of A4 OD pairs and let us index them so that w
takes values in { 1, . . . , M ) . Then. the totality of flows through
the network may be described by a vector x = (x,, . . e , x,%,).
Naturally, x is subject to the constraint x E G where G =
GI x Gz x * * . X GIf, and G,,, is the simplex defined by (3.1)
and (3.2).
For any link (i, j ) in the network.
let Fi' denote the
corresponding traffic arrival rate at that link. Clearly,
w = l P E P .
i.e., the total flow on link (i, j ) is the sum of path flows of all
paths traversing (i, j ) . Alternatively, (3.3) may be written as
F'I = (eo, y)
where (. , . ) denotes the usual inner product
and eiJ is an
appropriate vector with 0 or 1 entries.
A cost function, corresponding to some measure of congestion
through the network,
is introduced. We assume the separable
We assume that for each link (i, j ) E E, the function D i l is
practical reasons. however, one may wish to consider a smaller set P , . While
I A simple choice is to let P,, be the set of all directed paths from i toj. For
such a restriction may increase the optimal value of the cost function. there
paths in P, that carry positive flow will be involved in the calculations of the
may be benefits relating to ease of implementation. In any case. only those
augment P,. with new paths (see . [SI. and ).
following algorithm. Funhermore a shortest path algorithm can be used
TSITSIKLIS AND
BERTSEKAS:
ASYNCHRONOUS OPTIMAL ROUTING
defined on [0, m), is real valued (finite), convex, and continu-
ously differentiable. We also assume that the derivative of D'J is
Lipschitz continuous on any bounded interval. A typical example
is when D expresses average delay per message
based on the
Kleinrock independence assumption [ 121.
We are interested in the case where the nodes in the network
adjust the path
routing variables
so as to minimize (3.5).
Since a set of path flow variables ( ~ , , ~ : p
E P,, w E { 1, - * * ,
M ) } determines uniquely the link flow variables
F'J [through
(3.3)], it is more convenient to express the cost function in terms
of the path flow variables. We are thus led to the cost function
( i , j ) E E
DO(x)=p((&, x))
[compare to (3.4) and (3.5)]. Clearly, D'j inherits the convexity
and smoothness properties of D'J.
Let us now consider the situation where the flows change with
time, due to rerouting decisions made by the nodes in the network.
Accordingly, the flows at time n are described by a vector x(n) =
(xl@), 1 . , x,&~)) E G. Let us assume that the routing decisions
for the flow corresponding to a particular OD pair w = (i, j ) are
made by the origin node i. In an ideal situation, node i would have
access to the exact value of x(n) and could perform the gradient
projection update , [I51
aD (x@)) ] + .
Here, y is a positive scalar
step-size, pH. a positive scaling
constant, and [a] denotes the projection
on the simplex G , with
respect to the Euclidean norm. The vector x,&) can be used to
obtain the fraction of flow that should be directed on each path of
the OD pair w between times n and (n + 1). These fractions can
form the basis for implementation of the routing algorithm.
For reasons related to the convergence rate of the algorithm, we
may also wish to consider the following generalization of (3.7):
Here, y is again a positive scalar
step-size and M,(n) is a
symmetric positive
definite matrix (which
is time varying
projection
respect to the norm induced by M,(n). More precisely, for a
given x, the projection
[x]l~dn) is the unique vector
minimizes ((z - x), M,(n)(z - x)) over all z E G,. (In the
special case where
MJn) = I, [
coincides with the usual
projection with respect to the Euclidean norm.)
An equivalent
formulation is to define x , ( n + 1) as the (unique) solution of the
constrained optimization problem
(x(n)), (x,-x,(n))
Typically, MJn) is taken to be some estimate of the Hessian
matrix a2D/axt,. With such a choice (3.8) becomes an approxi-
mation to a projected Newton method. Such methods usually have
faster convergence, when compared to (3.7), for roughly the same
reasons that Newton methods for unconstrained optimization are
better than the ordinary gradient algorithm. Nevertheless, since
convergence rates are not studied in this paper, we do not need to
be specific on the choice of M,(n). We will only assume that there
exist positive constants 6, A such that
O < 6 Z ~ M x , ( n ) S A I , V n, PV,'
where I is the identity matrix of suitable dimension.
The convergence of an algorithm described by (3.7) or (3.8)
follows from known results . . However, in a practical
situation, iteration (3.7) or (3.8) is bound to
be unrealistic for
several reasons.
1) It assumes perfect synchronization of the computation of all
origin nodes.
2) It assumes that x(n) (or, equivalently, the link flows F'J(n)
at time n) may be measured exactly
at time n and that
measured values are instantly transmitted to every origin node
which needs these values. This, in turn presupposes a perfectly
synchronized exchange of messages carrying these values.
3) Even if the origin node i is able to compute x,,@ + 1)
exactly through (3.7) or (3.8), the actual flows through the
network, at time n + 1, will be different from the computed ones,
unless the settling time is negligible.
The above necessitates the development
of a more realistic
model, which is done below.
First, because of remark 3) we will differentiate between the
actual flows through the network (denoted
by x(n), x&),
and the desired flows, as determined by the computations of some
node; the latter will be denoted by an) and f,,.(n). The routing
decisions of some node at time n are determined by the desired
flows X,(n). However. due to transients, each component ~,,.,~(n)
of the actual flow x(n) will take some value between f,,.,Jn) and
- 1). It is therefore natural to assume that for each time n
and for each path p E P,, there exists some (generally unknown)
between 0 and 1 such that
x,,p(n) = Qw,P(n)%v,P(n) + (1 - Q w , p ( n ) ) x w , p ( n - 1).
We will also assume that for some a > 0,
a,,P(n)2cY,
v w , p , n.
The above assumptions are motivated from a consideration of
the way that routing strategies are implemented in actual data
networks and is mainly applicable to the case of virtual circuit
routing. If a certain path has more virtual circuits (x,,&)) then
desired (X,&)),
then no new virtual circuits will be assigned to
it, whereas some of the existing virtual circuits will be deleted
when the corresponding conversation terminates. A similar
situation prevails if x,,(n) < x,,Jn). Thus, x,,.&
expected to take values In the range postulated by (3.1 l), (3.12).
In the more realistic case, however, where arrivals and departures
of virtual circuits are random, (3.1 l), (3.12) will only hold with
some probability which converges to one as the violation of the
quasi-static assumption becomes smaller and smaller.
From (3.11) and the requirement that x, belongs to the simplex
G,, we conclude that the coefficients a,,,,,@) have to satisfy for
every w , n the condition
Q,,,(n>(fw,,(n) -xti.,(n - 1)) = 0.
We next introduce an algorithm for updating desired flows, and
try to model the effects of asynchronism. We postulate an update
rule of the form [cf. (3.8)]
f , ( n + 1 > = 1 x , ( n ) - y ~ ~ l ( n ) ~ , ~ ( n ) l . ~ ~ , : , , n , ,
Here X,(n) is some estimate of aD/ax,,.(x(n))
which is, in general,
inexact due to asynchronism and delays
in obtaining measure-
ments. However,
be unnatural
to assume that the
computation (3.14) is carried out at each time instance for each
The notation A 5 B, for matrices A, B, means that B - A is nonnegative
IEEE TRANSACTIONS ON AUTOMATIC CONTROL, VOL. AC-31, NO. 4. APRIL 1986
OD pair. We therefore define a
set T, of times for which (3.14) is
used. For all n
T,, we simply let gti(n + 1) = X,,@). We only
assume that the time between consecutive updates (equivalently,
the difference of consecutive elements of T,) is bounded, for each
w. In particular, we allow the possibility that iteration (3.14) is
executed for some
OD pairs w several times before
executed even once for some other OD pairs. This captures the
uncoordinated character of a realistic distributed environment
where the origin nodes of OD pairs carry out a routing update
whenever some
new information becomes available without
regard as to whether this information has reached other nodes. We
now describe the process by which X,,>(n) is formed.
For each link
(i, j ) , node i estimates from time to time the
amount of traffic through that link. Practically, these estimates do
not correspond to instantaneous measurements but to an average
of a set of measurements obtained over some period
Accordingly, at each time n, node i has available an estimate
cqn, rn)F'J(m).
Here, ciJ(n, rn) are (generally unknown) nonnegative scalars
summing to one (for fixed n), and Q is a bound on the time over
which measurements are averaged. These estimates are broadcast
from time to time (asynchronously and
possibly with
variable delay). Let us assume that the time between consecutive
broadcasts plus the communication delay
until the broadcasted
messages reach all nodes is bounded by_some T. It follows that at
time n each node k know,s the value of F'J(mk),
for some r n k with
n - T 5 m, s n. Combining this observation with (3.15) we
conclude that at time n, each node k knows an estimate Ff(n)
satisfying
d$(n, rn)F"(rn)
where C = T + Q and dy(n, rn) are (generally
nonnegative coefficients summing to one, for fixed n.
For each OD pair w, the corLesponding origin node (let us
denote it by k) uses the values of F;(n) to form an estimate X,(n)
of 8D/ax,(x(n)) as follows. Note that
Accordingly, a natural estimate is given (componentwise) by
The development of our model is now complete. To summa-
rize, the basic equation is (3.14), wher_e,x(n) is determined by
(3.11), X,@)
is determined by (3.18). F;(n) is given by (3.16).
and FiJ is related to x by (3.3).
Our main result states that the above described algorithm
converges to an optimal routing.
Theorem 3.1: With the algorithm and the assumptions intro-
duced above and provided that the step-size y is chosen small
enough, D(x(n)) converges to minXEG D(x) and any limit point of
(x(n)} is a minimizing
point. Moreover, x,,.(n) - x,(n)
converges to zero for all OD pairs w.
Corollary 3. I : Under the Assumptions of Theorem 3.1. if each
D'J is strictly convex (as a function of F'J), then the vector of link
flows F''(n) converges to the unique minimizing vector
of the cost
function (3.3, over all link flow vectors of the form (3.3) with the
path flow vector x ranging over the set G.
Let us point out
here that Theorem 3.1 and Corollary
remain valid even if our assumption (3.1 1) is replaced by the
following weaker assumption: there exist nonnegative coefficients
a,.,,(n; k ) and some scalars B 2 0, 0 E [O. 1) such that
a,,,(n; k)CrBPn-&, V n, k, w, p E P,<
This assumption basically requires that if X(k) is held constant, say
equal to X, then the actual flows x(n) converge to X with at least a
geometric rate.
of Theorem 3.1 indicates that convergence is
guaranteed if the step size y is chosen proportional to Q where CY is
the constant of inequality (3.12). Thus, if the settling time of the
network is small (a large), the step size can be also relatively
large. However, if the network settles slowly. a small step size is
used. This is quite reasonable because there is no point in using a
rapidly changing routing strategy on a network which can only
change slowly.
We close this section with a remark. A distributed asynchron-
ous version of the Bellman algorithm for shortest paths has been
shown to converge appropriately . even if the time between
consecutive broadcasts is unbounded. In our model however, we
have assumed a
finite bound T. The reason is that
convergence is not
guaranteed, as will be
shown below.
course, a boundedness assumption is always observed in practice.
A simple example
which demonstrates that without
bound the algorithm need not converge is the following. Consider
the network of Fig. 1. There are three origin nodes (nodes 1, 2,
and 3), with input arrival rate equal to 1 at each one of them, and a
single destination node (node 6). For each OD pair there are two
paths. For each origin node i, let X, denote the flow routed through
the path containing node 4. Let Dij(FiJ) =
for (i, j ) = (4,
6) or (5, 6) and D'J(FiJ)
= 0 for all other links. In terms of the
variables xl, x2, x3, the cost becomes
XZ, X ~ ) = ( X I + X ~ + X ~ ) ~ + ( ~ - X I - X ~ - X ~ ) * .
We assume that the settling time is zero, so that we do not need to
distinguish between actual and desired flows, and that each node i
(i = 1, 2, 3) knows xi exactly and is able to transmit its value
instantaneously to the remaining origin
nodes. Suppose that
initially xl = x2 = x3 = 1 and that each origin node executes a
large number of gradient projection iterations with a small step
size before communicating the current value
of x to the other
nodes. Then, effectively, node i solves the problem
thereby obtaining the value x; = 0. At that point the processors
broadcast their current values of xi. If this sequence of events is
repeated, each x; will become again equal to 1. So, (xl, x2, x3)
oscillates between (0, OI 0) and (1, 1, 1) without ever converging
to qn optimal routing. The same behavior is also observed if the
cost function (3.19) is modified by adding a term €(X: + xi +
xi), which makes
it strictly convex (consistently
assumptions of this paper), as long as
0 < E Q 1. Clearly, the
reason for divergence in this example is that the
spirit of the
"second approach" for proving convergence, discussed
Section 11, is violated.
TSITSIKLIS AND BERTSEKAS: DISTRIBUTED ASYNCHRONOUS OPTIMAL ROUTIKG
Fig. 1. A simple routing problem.
Iv. AN ALTERNATIVE
In this section we consider the following variation of the basic
update equation (3.14):
~ w ( n + l)=[x,(n)-y~,'(n)h,(n)~.~~(n,. (4.1)
The main difference is that X& + l), as obtained from (4.1), is a
small modification of the actual flow x&) rather than the desired
flow Z,<(n), as in (3.14). If the settling time in the network is very
small or if the step size y is very small, then X,,(n) = x&)
(4.1) coincides with (3.14). It is therefore, somewhat surprising
that (4. I) does not lead to a convergent algorithm
in general, as
we now explain.
Suppose that we were dealing with an unconstrained problem
and with perfect synchronization so that X,,,(n) = aD/ax(x(n)). In
that case, (4.1) could be combined with (3.11) to yield
x,,.(Tz+ l ) = ~ , ( n ) - ~ A , , ( n + l ) M ; l ( n ) -
( ~ ( n ) ) (4.2)
= diag { a,,,,p(n)} is diagonal and positive definite.
However. A,,@ + 1)M; l(n) need not be positive definite and the
update (4.2) may be in
a direction
of cost increase.
unconstrained case this issue may be taken care
M,,.(n) be diagonal, so that A,(n + l)M;'(n) > 0. Still, this
would not work for constrained problems because the projection
introduces a further "rotation" of the updates. This situation may
be remedied, however, by appropriately transforming the prob-
lem of projecting onto the simplex G,, to a problem of projecting
onto an orthant. More precisely,
we consider the following
modification of (4.1).
At each-time n E T,, X,,,(n + 1) is computed as follows.
1) Let i be the index of a shortest path for OD pair w with
respect to link lengths aDiJ/aFiJ, i.e.,
A,",;(n)shw,p(n), v P E pw3
2 ) Let MJn) be a diagonal matrix with 0 in the iih position.
The remaining diagonal entries are positive numbers
,~,,.,~(n),
satisfying
0<6Sp,,,(n)<A
where 6, A are fixed throughout the algorithm.
cumbersome.
A more precise notation would be ;&),
but this urould be unnecessarily
Xw,;(n+l)=r,-
I,', ,(n+l).
By our choice of i7 we have X,,Jn + 1) 5 x,,Jn), v p # 6
which implies X,Jn + 1) 2 x,,,+?) 2 0. Therefore, the vector
It can be easily checked that the vector X& + 1) is the solution
+ 1) computed by (4.41, (4.5) is feasible.
of the optimization problem
min (h,(n), x -
The main difference with the gradient projection updates of the
kst section is that now Mw(n) is not positive definite, due to the
ith diagonal entry which is zero. Nevertheless, the restriction of
M&) on the linear manifold containing G,,, is positive definite, so
that (4.6) has a unique solution.
Theorem 4. I: The conclusions of Theorem 4.1 (convergence
to an optimal routing) remain valid if (3.14) is replaced by (4.4),
V. CONCLUSIONS
Gradient projection algorithms for routing
in a data network
converge appropriately even in the face of substantial asynchron-
ism and even if the time required for the network to adjust to a
change in the routing policies
(settling time) is nonnegligible.
While convergence is proved under the assumption that the input
arrival rates r, are constant, it is expected that the algorithm will
be able to adjust appropriately in the face of small variations. If
input variations become substantial, however, and the quasi-static
assumption is violated, a more detailed analysis
is required,
incorporating stochastic effects.
Another idealization in our model arises in the measurement
equation (3.13), which assumes that measurements are noiseless.
This is a reasonable assumption if the time average runs over a
sufficiently long period but may be unrealistic otherwise, necessi-
tating again a more elaborate stochastic model.
Let us mention an important related
class of distributed
algorithms. In the present model the nodes measure and broadcast
messages with their estimates of the link flows F'j. Other nodes
receive the broadcasted messages
and use them to compute
estimates of the expression dD'J/dF'J(F'J) which is required in
the algorithm. An alternative possibility would be to let, say node
j , measure directly or compute the value of aD'j/aF'j(F'j) and
broadcast that value to the other nodes. For certain special choices
of the cost function D'J and under certain assumptions, the partial
derivative aD'j/aF'J equals the average delay
of a packet
traveling through link (i, j). In that case, it is very natural to
assume that this derivative may be measured directly, without first
measuring the flow F'j. Our result may be easily shown to be
valid for this class of algorithms as well.
We have not presented any numerical results on the perfonn-
ance of our algorithms, but a simulation of an actual data network,
operating in a realistic environment should be the next step in
future research.
Proof of Theorem 3.1: Let ( e , . ), (1 )I denote the Euclidean
inner product on R n and the associated norm, respectively. Let
be a symmetric positive definite matrix and define a new inner
product { -,
(x9 Y)M = (x, MY).
IEEE TRANSACTIONS ON AUTOMATIC CONTROL. VOL. AC-31. NO. 4, APRIL 1986
This inner product induces the norm 11 . lI.$, given by llxll if = ( X ,
X),$,. With the
notation introduced in Section 111, [a],:, is the
projection of Q on the closed convex set G C Rn, with respect to
the inner product ( e , ):$,. Therefore, the projection theorem [ 13,
p. 691 implies that
(U-[a],&, M ( x - [ u ] , : ~ ) ) ~ ~ ,
V X E G, V U . (A.l)
Replacing 4 with x + Q in (A.l) we obtain
We define s(n) to be the vector with components
(independent of y or n)
8n-klls(k)ll.
[The second inequality follows from (3.16), the third from (3.3),
the fourth is the triangle inequality, the fifth uses (A.9).] Using
Lipschitz continuity once more,
(A.9) and (A.lO) we finally
a,(n+ l)=~w(n)+s,v(n), v n.
obtain, for some
A8 2 0 (independent of n, y),
Using a first-order series expansion for D, we have
[Here, the second inequality was obtained from (A. 1 1); the third
from (AS).] Summing (A.12) for different values
rearranging terms, we obtain
D(f(n + 1)) 5 D(n(1))
(For convenience we are assuming that the routing algorithm is
initialized with x(1) = X(1). The proof is easily modified if this is
not the case.) Inequality
(A.8) shows that for some A I 2 0
(independent of y or n)
Suppose that y is small
so that A lo/y - A /( 1 - 8) >
0. Note that D is continuous and that X(n) takes values in a
A i o - / 4 1 1
0 i - k ] lls(k)l12. 64.13)
D(Z(n + 1)) is
below. Let n + 03
Ilx(n)-b(n)ll5Al 2 8n-kIIs(k)ll.
in (A.13) to obtain
Compare now (3.17) to (3.18)
continuity
Ils(k)ll*<-.
a@/aFij to conclude that for
A2, . * -, A7
TSITSIKLIS AND BERTSEKAS: DISTRIBUTED ASYNCHROKOUS OPTIMAL ROUTING
In particular, s(k) converges to zero, as k + 09, and using (A.9)
we obtain limk-,
Ilx(k) - X(k)II = 0. It also follows from
(A.13), (A.14) that D(f(n)) converges. as k -+ m.
Let us define for any w and for any positive definite symmetric
matrix M,,,
Let x* be a limit point of { x(n) }. (At least one exists because G is
compact.) Since we have assumed that the difference between
consecutive elements of T , is bounded, for any w , we conclude
that x* is also a limit point of { x(n): n E TI,.) . Notice also that the
set of matrices satisfying (3.10) is compact. It follows that there
exists a sequence { nk} c T, such that x(nk) converges to x* and
M,,.(nk) converges to some M$ satisfying (3.10). Finally, notice
that (due to (A.10), the convergence of s(n) to zero and the
continuity of aD/ax,$
lim X,,,(nk)= lim -
Putting everything together, and comparing (A.15) to (A.3), we
conclude that
&(x*, M:,) = lim s,(np) = 0.
(This step uses the fact that [a]:, is jointly continuous as a function
of a, M.) Consequently, for
each MI there is a matrix M:
satisfying (3.10) and such that fw(x*. Mz) = 0, VW. Using the
projection theorem
 and (A.15), we obtain (y(M:)-'aD/
ax,,.,(x*), M;(x,, - x:))
2 0, vx,,, E G,*, vw. Summing over all
MI'S we obtain (aD/ax(x*), x - x*) L 0, Vx E G and, since D is
convex. we have D(x) I
D(x*) + (aD/ax(x*). x - x * ) , Vx E
G . Therefore, x* minimizes D over the set G, thus proving part of
the theorem.
The above imply that minxEc D(x) = D(x*) is a limit point of
{ D(x(r7)) } . Since { D(x(n)) } is a convergent sequence, it con-
verges to min,Ec
D(x), thus completing the proof.
Proof of Corollary 3.1: By Theorem 3.1 any limit point of
{x(n)} minimizes D. Hence, any limit point of { F'J(n)}
minimizes D over the convex set consisting of link flows given by
(3.4) with x ranging over G . However, due to strict convexity. D
has a unique minimum over this set which proves the corollary. c
Proof of Theorem 4.1: Let s(n), S(n) be vectors with
components
s,,,(n)=x,,.(n+ l)-xJn)
Sti(n)=f,+(n+ l)-xti(n),
respectively. Using (3.11) we obtain
A , v ( ~ +
where A&) = diag {
We therefore have. for some
( U n ) , s,(n)i =
a,v.,p(n + 1)L,p(n)SLv,p(n)
= x a,,,(n + l)S,c,p(n)[A,,..p(n) - L.An)I
(The first equality follows from (A.18), the second from (3.13);
the first inequality follows from (4.4)
and a little algebra; the last
from (3.12).) Also notice that (4.5) implies
S , ; p ( n )
which finally yields, for some AI 2 0,
Combining (A. 19) and (A.20) we conclude that, for some A2 2 0
independent of y or n, we have
An argument similar to (A. 10) yields
We then obtain, similarly with (A. 12),
From here onl the proof follows the
lines of the proof of Theorem
3.1 and is, therefore, omitted. We only point out
some differ-
ences. First, fw(x, M,J should not be defined via (A. 15) but as the
(unique) solution of
min y - x , -
x) +- (y-x, M,(y-x)).
:AD. ( ) jT
Second, when we choose a convergent
Subsequence x@,), we
should take a further subsequence so that i is the same at all times 0