Collingridge and the dilemma of control: towards responsible and
accountable innovation
Audley Genus, Andrew Stirling
Publication date
05-10-2017
This work is made available under the CC BY-NC-ND 4.0 licence and should only be used in accordance with
that licence. For more information on the specific terms, consult the repository record for this item.
Document Version
Published version
Citation for this work (American Psychological Association 7th edition)
Genus, A., & Stirling, A. . Collingridge and the dilemma of control: towards responsible and accountable
innovation (Version 1). University of Sussex. 
 
Research Policy
Link to external publisher version
 
Copyright and reuse:
This work was downloaded from Sussex Research Open (SRO). This document is made available in line with publisher policy
and may differ from the published version. Please cite the published version where possible. Copyright and all moral rights to the
version of the paper presented here belong to the individual author(s) and/or other copyright owners unless otherwise stated. For
more information on this work, SRO or to report an issue, you can contact the repository administrators at .
Discover more of the University’s research at 
Contents lists available at ScienceDirect
Research Policy
journal homepage: www.elsevier.com/locate/respol
Research paper
Collingridge and the dilemma of control: Towards responsible and
accountable innovation
Audley Genusa,⁎, Andy Stirlingb
a Kingston Business School, Kingston University, Kingston upon Thames, KT2 7LB, United Kingdom
b Science Policy Research Unit, University of Sussex, Falmer, Brighton, BN1 9RH, United Kingdom
A R T I C L E I N F O
Accountability
David Collingridge
Dilemma of control
Governance of innovation
Incrementalism
Responsible innovation
A B S T R A C T
The paper critically reviews the work of David Collingridge in the light of contemporary concerns about responsibility and accountability in innovation, public engagement with science and technology, and the role of
scientiﬁc expertise in technology policy. Given continued interest in his thoughts on the ‘social control of
technology’, and the ‘dilemma of control’, this attention is both timely and overdue. The paper illuminates a
mismatch between the prevalence of citations to Collingridge’s work on the dilemma of control in the literature
on responsible innovation, and the depth of engagement with his arguments. By considering neglected aspects of
Collingridge’s substantive, methodological and philosophical analysis, important implications can be drawn for
theory and practice relating to the governance of innovation and co-evolution between technology and society.
The paper helps to improve understandings of wider political contexts for responsible innovation, especially in
relation to anticipatory, participatory and institutional aspects of governance.
1. Introduction
David Collingridge was an important contributor to the ﬁeld of
Science and Technology Studies. An active researcher from the late-
1970s to the early-1990s, he developed a distinctive and substantive
line of thinking concerning the ‘social control of technology’ – the scope
for conventionally excluded people and interests to shape the forms and
orientations
innovation
trajectories
particular
Collingridge’s work was concerned with increasing social agency over
technology – away from incumbent interests in what have come to be
called ‘innovation systems’. It drew on a critique of what he called the
“justiﬁcationist school” in decision-making, philosophy, and political
science. Language fashions change, and now more is spoken of the
‘governance’ of science, technology or innovation than of ‘social control’. The notion of control itself can be viewed as being as problematic
as it is helpful to Collingridge’s underlying aims . And a succession of vocabularies that have
burgeoned in this ﬁeld largely since Collingridge’s work (for instance,
around ‘precaution’, ‘participation’ and ‘engagement’), are now being
substituted in some quarters by the language of responsible (research
and) innovation .
Responsible innovation is not a new concern. Academic and policy
discussions over responsibilities, risks and ‘control’ in the governance of
science and technology go back many years . Over 70 years ago landmark contributions to understandings of
the history of science and relationships among science and society were
produced by Bernal and Haldane . In the 1960s,
signiﬁcant contributions emphasised the social responsibility of science
and greater public understanding of science . The British Society for Social Responsibility in Science
ran from 1969 to 1991 whilst its US equivalent was active between
1949 and 1976. These societies were concerned with the transparency
and openness of science policy-making as well as the environmental
and health consequences associated with the operation of new technologies implicated in scientiﬁc discoveries and inventions.
There have been longstanding concerns regarding the framing and
promotion of scientiﬁc citizenship or ‘citizen science’ , which now ﬁgure in discussions of responsible research and
innovation . An important development was the
emergence of the ELSI approach towards the end of the 1980s, connected with the ethical, legal and societal implications of, for instance,
the Human Genome project and the proper governance of scientiﬁc
research and technological innovation. More recently, there have been
concerns to address the limitations of the ELSI approach and to elicit
more active or responsive public engagement with science and
 
Received 25 February 2016; Received in revised form 10 February 2017; Accepted 25 September 2017
⁎ Corresponding author.
E-mail addresses: (A. Genus), (A. Stirling).
Research Policy xxx (xxxx) xxx–xxx
0048-7333/ © 2017 Published by Elsevier B.V.
Please cite this article as: Genus, A., Research Policy , 
technology .
In the UK, a landmark parliamentary select committee report recognised citizens’ distrust of conventionally-institutionalised science,
following a number of high proﬁle technological controversies and
crises which brought into question the accountability and autonomy of
science and the role of society therein . Moreover, it represented a moment of reﬂection on what it meant for science
and innovation to be conducted ‘responsibly’. As subsequent discussion
has shown, this ‘responsibility’ may be understood in relation to what
may be considered proper behaviour – or ‘responsiveness’ – in deﬁned
contexts (i.e. the ethical dimension of responsible innovation), and in
terms of who is to be held ‘responsible’ for what (‘role responsibility’).
Temporally, consequentialist notions of accountability on the part
of science/scientists and innovation/innovators pertain to whether and
how they should be held to account for the consequences of actions
taken in the past . But
they also concern more immediate democratic accountabilities for the
contemporary driving motivations of innovation processes – with respect to impacts which may not have been reasonably foreseeable with any particularity, but which nonetheless arise
from the prioritisation in any given setting of some kinds of general
orientation for innovation rather than others .
While some analyses of responsible research and innovation (RRI) include consideration of accountability , others are explicitly critical of what is portrayed as the “traumatic” and “infantilising” eﬀects on processes of innovation . For the most part, the RRI literature tends to neglect
the quality of accountability. The associated relevance of democracy to
the orientation of technology is also thereby downplayed. Collingridge’s
emphasis on Popperian qualities of openness and his development of
speciﬁc qualities around which to structure accountability oﬀer crucial
but under-realised values for understanding responsible research and
innovation.
Putting problems of accountability to the fore, this paper seeks to
identify aspects of Collingridge’s work that have not been especially
well assimilated or further developed in attempts to implement a framework for responsible governance of research innovation. More
fruitful analysis would draw on Collingridge’s contribution to engage
more strongly with accountability in debates bearing on key elements
of responsible innovation, such as anticipatory technological decisionmaking
deliberation.
discussion,
Collingridge’s ideas are themselves subject to productive critique,
which may also helpfully inform understanding and practice of RRI.
The paper has the following structure. Section 2 outlines developments in practice and research connected with building and institutionalising frameworks for responsible innovation. Section 3 discusses how Collingridge’s work addresses core concerns of RRI,
focusing initially on the ‘Collingridge dilemma’ and the ‘corrigibility’ of
technology. Section 4 critically reviews the contribution of Collingridge’s work to RRI. Section 5 considers revisions and extensions that
may be made to Collingridge’s contribution which have the potential to
improve understandings of responsible innovation. Section 6 concludes
the paper, reﬂecting on implications of the foregoing sections for future
research on – and practice of – more responsible and accountable innovation.
2. The practice and a framework of responsible innovation
Multiple labels, approaches and genealogies alluded to in diﬀerent
areas of the responsible research and innovation literature make this
subject diﬃcult to characterise in any deﬁnitive way. What is clear is
that an expanding body of analysis and policy practice has built up over
the last decade around notions of “responsibility” in this area. This may
be identiﬁed with a number of key journal articles such as by Guston
 , Guston and Sarewitz , Roco et al. and Stilgoe
et al. , the book by Owen et al. , and the launch of the
Journal of Responsible Innovation . Reading across
multiple deﬁnitions Wickson and Carew identify the following core characteristics of RRI: a focus on addressing ‘signiﬁcant
socio-ecological needs and challenges’; a commitment to actively engage a range of stakeholders for the purpose of substantively improving
decision-making and mutual learning; a dedicated attempt to anticipate
potential problems; and a willingness among all participants to act and
adapt according to these ideas.
The EU employs RRI as a cross-cutting theme within its Horizon
2020 funding framework (alongside ‘science with and for society’).
Horizon 2020 is itself a core element of the ﬂagship Innovation Union
programme, which in turn is a central aspect of the EU2020 strategy.
Taken as a whole, EU initiatives and policies tend to characterise innovation in an undiﬀerentiated way – as a self-evidently generally
“good thing” irrespective of the speciﬁc kind of innovation involved or
the alternatives that might thereby be foreclosed . Thus
“pro-innovation” policies are prized as a means to ‘smart growth’,
which is in turn seen simply in terms of the gross numbers of jobs involved – rather than in terms of net comparisons with numbers and
kinds of jobs that would be created by the same investments by other
means .
In this view, innovation is whatever happens to emerge from incumbent structures of interest, privilege and power in prevailing innovation systems . Justiﬁcation is provided by reference
to variously direct or indirect engagement with societal challenges,
such as those connected with promoting green and secure energy, food
security, climate action, and ‘smart’ transport. But these “solutions” are
typically addressed by starting ﬁrst with the incumbent innovation
trajectory and simply highlighting those problems that it may promise
to address. Far less attention is given to any analysis starting with the
challenges themselves, in order to decide which innovation trajectories
might be most appropriate .
Of course, this highly pressurized and expedient approach needs to
be understood in relation to EU concerns about the need to close the
“competitiveness gap” with other global economic blocs and countries,
notionally by increasing R & D . And it is here that it is
relevant that ‘responsible innovation’ has also been strongly invoked
(under similar dynamics) in US policy on research and innovation –
notably in the governance of nanotechnology. Examples here are the
National Nanotechnology Initiative’s strategic plan and the
National Science Foundation’s Nanotechnology in Society network
 .
Such initiatives raise a key point regarding the emergence of responsible innovation. This concerns the potential for understandings of
RRI to become unduly attenuated or instrumentalised, resulting in more
attention being devoted to deciding on how to implement an incumbent
innovation pathway, than on choosing which pathway to follow . To address the shortcomings of these more instrumentalised approaches, it is often urged that responsible innovation
move beyond preoccupation with research and development and economic beneﬁts of individual technologies to address the innovation
process more fully, including social as well as technical and other aspects .
Whilst orientations and emphases vary, four resulting interacting
dimensions are highlighted as means by which RRI might mitigate such
criticisms. First, RRI aims to be anticipatory in the sense of exploring
possibilities (not making predictions) and analysing ‘intended and potentially unintended impacts that might arise’. It aims to be ‘deliberative’ – ‘inclusively…inviting and listening to wider perspectives from
publics and diverse stakeholders’. It prioritises ‘reﬂectiveness’ regarding
‘underlying purposes, motivations and potential impacts’. And ﬁnally,
RRI is argued to be ‘responsive’, ‘using this collective process of re-
ﬂexivity to both set the direction and inﬂuence the subsequent trajectory and pace of innovation’ . Among other issues, these processual aspirations of RRI
raise a number of implications for the accountability of research and
A. Genus, A. Stirling
Research Policy xxx (xxxx) xxx–xxx
innovation.
First, proponents of RRI are concerned about the limitations of riskoriented approaches in providing reliable ‘early warnings’ of potentially
deleterious eﬀects of new technologies . Here,
they emphasise instead anticipatory approaches involving expert studies of diverging futures and socio-technical imaginaries. In this view,
anticipation in responsible innovation involves an intermediate position between the ‘closing down’ of governance through the making of
predictions and promises and the full ‘opening up’ of spaces for more
direct forms of public accountability in substantive citizen participation. .
The timing of accountabilities is also an important aspect of anticipation, with RRI enjoining eﬀective early instigation of “upstream”
governance processes. Whether referred to as deliberation or inclusion , responsible innovation
prioritises the admission of ‘new voices’ to the governance of science
and innovation. A plethora of divergent forms of public engagement
have emerged. Yet these have been criticised for remaining marginal to
governance of science and innovation, with the key commitments undertaken elsewhere, often even further ‘upstream’ in innovation processes . A further risk of erosion in accountability
arises here in tendencies to favour designs for “invited” forms of public
engagement that reinforce (rather than fully interrogate) political closures .
For its part, reﬂexivity is a key quality in inclusive deliberation.
Here, RRI literatures are informed by Beck’s seminal work
on reﬂexive modernisation, in which he argues that increasing diﬃculties in calculating scientiﬁc and technological risks will lead scientists themselves to become more reﬂexive – heralding what he calls a
‘second modernity’. In this vein, Stilgoe et al. draw on work by
Wynne to argue for ‘institutional reﬂexivity’ among funders, regulators and users of scientiﬁc research concerning the assumptions and practices implicated in science and innovation and their
governance. But in order to contribute to the ‘opening up’ of accountabilities, reﬂexivity must be more than a private process of self-questioning regarding values and interests in science and innovation. Rather
than a quality located in individual social actors, reﬂexivity needs to be
recognised as a plural and distributed social capability . In this sense, reﬂexivity is a public practice, capacities for
which may be enabled by application of standards and codes of conduct
 .
In all these ways and more, RRI involves mutual accommodation
and adjustment in the needs, interests and values of contending “stakeholders”. In particular, the quality of ‘responsiveness’ – for instance
according to Owen et al. – involves an ‘open process’ of
‘adaptive learning’. In such ways, interwoven principles of anticipatory
governance and inclusive deliberation help confer mutual responsiveness on the part of participating interests – and enjoin reﬂexivity over
the positions and values that they themselves and others hold. But
again, there tends to be relatively little explicit, direct, or substantive
provision for addressing power dynamics in these processes of adaptation, learning and responsiveness. It is these kinds of power dynamic
that are addressed in wider notions of political accountability.
With these dimensions of RRI in mind, the following section outlines
how Collingridge’s work has been and could be employed in the elaboration of RRI. In particular, it considers how his ideas on the dilemma
of control and corrigibility of decisions about technology might address
issues of accountability referred to above.
3. Collingridge’s contribution to RRI
When RRI literatures draw on Collingridge, the most explicitly invoked theme is the ‘dilemma of control’ (or ‘Collingridge dilemma’)
 . The dilemma runs thus: ‘attempting to
control a technology is diﬃcult…because during its early stages, when
it can be controlled, not enough can be known about its harmful social
consequences to warrant controlling its development; but by the time
these consequences are apparent, control has become costly and slow’
 . This leads to the importance of a second
theme in more detailed accounts, concerning the corrigibility of innovation trajectories . And alongside these explicit references to his work, Collingridge’s thinking also has implicit inﬂuence on RRI – for instance in
the recognition of the signiﬁcance of corrigibility in the form of ‘responsiveness’. Stilgoe et al. describe this as the ‘capacity
to change shape or direction in response to stakeholder and public
values and changing circumstances’.
In general Collingridge’s work is used as fundamental grounding for
framing: (a) the problem agenda of RRI; and (b) particular strategies for
steering technology-society more eﬀectively. The dilemma of control
has been invoked in a general sense to underpin discussions of how to
govern uncertain or potentially undesirable innovations in contexts
where knowledge is unavailable or contested . In
this sense, RRI emerges as a direct response to the Collingridge dilemma, in which respect a number of other approaches for governing
emerging technologies have been found wanting . In essence, the argument is that the Collingridge dilemma can be overcome
when responsibility is embedded in emerging technologies in the form
of enhanced reﬂexivity among researchers alongside wider provision
for ‘upstream’ engagement .
Reference to Collingridge is especially prominent where RRI seeks
to address the ‘ﬁrst horn’ of the Collingridge dilemma (concerning the
dearth of necessary early information about technological implications). Eschewing simplistic instrumental approaches, attention focuses
on exposing developments to a range of ‘mid-stream, multidisciplinary
perspectives’ of kinds that were undeveloped when Collingridge ﬁrst
developed his ‘dilemma’ . Other particular dimensions of
RRI that involve elaboration of core ideas from Collingridge, include
recognition for the importance of continuing dialogue processes as a
means to enhance the corrigibility of decisions. In this regard, ‘dialogical responsiveness’ involves destruction and reconstituting of the
identities of those participating in deliberations about scientiﬁc research and innovation .
well-recognised
Collingridge’s work are under-acknowledged in RRI, and oﬀer signiﬁcant potential for useful inﬂuence. For instance, Collingridge’s approach to seeking social control over technology is often interpreted
simply to involve monitoring and continual search for error – with remediation best facilitated by ensuring that those pathways that are
pursued are as corrigible as possible. However, this is only part of the
story. Other themes in Collingridge’s work that are undervalued in the
RRI literature involve other strategies than corrigibility and address the
afore-mentioned dimensions of RRI. For instance, in relation to anticipatory technological decision-making Collingridge describes a series of
‘equivalent’ ways of ‘overcoming obstacles to the control of technology’,
including: keeping options open; increasing the insensitivity of performance of technology to error; escaping the ‘hedging circle’; enhancing
controllability; managing entrenchment; reducing dogmatism of experts; and minimising the diseconomies of scale.
Collingridge argues that keeping future options open facilitates the social control of technology by enhancing the ﬂexibility of
decisions. Having a range of technical options available avoids reliance
on any one technology. For Collingridge, the choice of which nascent
innovation pathways to pursue (or not) is a matter of societal and
technological choice, implicated with competing visions of the purposes, beneﬁts and limitations of technology and more or less eﬀective
processes for decision-making. In relation to the ﬁrst horn of his dilemma, the knowledge required to avoid ‘big mistakes’ may be
knowledge pertaining to a class of similar decisions about technology,
A. Genus, A. Stirling
Research Policy xxx (xxxx) xxx–xxx
albeit that operational knowledge about the technology in question
may not yet be available. In Nordmann’s terms, RRI should
emphasise the search for alternative scenarios and technological options, rather than comprehensive ‘knowledge of the future’. This increases freedom of manoeuvre, opening up a wider range of possible
future actions. In this way, a system composed of many small units of
operation or production presents far wider options than dependence on
a few very large units which rely on highly specialised and capital intensive infrastructure. The trade-oﬀis between ﬂexibility of decisions
on one hand and the loss of the economies of scale from the more in-
ﬂexible technology on the other. Public accountability may also be
more practicable in cases when technology is insensitive to error, that is
when the time taken to discover and remedy a ‘mistaken’ decision is
short and the costs of the mistake compared with those of following the
 .
A particular problem for anticipatory decision–making is manifest
in what Collingridge calls the ‘hedging circle’. This
refers to a process in which liberal ‘just-in-case’ assumptions (e.g. in the
energy sector about future energy demand growth and GDP) interlock
with existing ‘low variety’ supply technology to create a vicious circle in
which supply is increased in the expectation of growing demand, and
demand growth materialises as consumers adjust to supply increases.
Decision-makers understand the cost of error in terms of failure to
supply (energy) according to expected demand as generously forecasted. In this way, it appears as if expansion of the prevailing lowvariety system (in this case based on centralised generation of non-renewable electricity), has a lower cost of error, than investment in a
more decentralised supply system or energy eﬃciency. Subsequent
thinking and experience has illuminated this fallacy .
Here, Collingridge distinguishes between ‘controllability’ and ‘corrigibility’ in that the former relates to the eﬃcacy, cost and timeliness
with which wider social agency can be asserted over the orientation of a
technological trajectory, and not just to the ease with which speciﬁc
errors may be corrected. Decisions that are easily controlled will have
what Collingridge calls low ‘control cost’, which he deﬁnes as the costs
of applying a remedy to a mistaken decision .
Where such costs are unknown in advance, then options with low ﬁxed
costs are preferable. If these decisions are mistaken then the losses of
sunk costs associated with highly capital intensive options may be kept
Assuring responsiveness to changed circumstances or values is dif-
ﬁcult in situations where technologies are ‘entrenched’ . Entrenchment may be
thought of in terms of the ‘second horn’ of the Collingridge dilemma,
extending beyond problems of information regarding the future performance of technology to challenges of insuﬃcient agency – a developed technology is more clear in its implications but more entrenched
in the face of eﬀorts to reshape it , though
continued monitoring may be possible. In addition to entrenchment,
however, Collingridge identiﬁes further impediments to responsiveness,
which tend not to be considered in RRI literatures.
First, responsiveness may become diﬃcult due to competition
(which may for Collingridge be between ﬁrms, nation-states or regional
blocs). This is due to the ways in which competition can serve to restrict
the number of options while dulling the reﬂexivity, or critical ability, of
inﬂuential stakeholders. This occurs, for example, when the technology
in question becomes so intrinsically embedded in imaginations of the
future that competition is based entirely around optimising this trajectory, rather than exploring alternatives.
Secondly, responsiveness is impaired by dogmatism, which serves to
reduce societal reﬂexivity and inclusive deliberation. This involves the
many ways in which incumbent interests that are associated with a
particular entrenched technology can avoid criticism of their favoured
commitments. Dogmatism ﬂourishes in the absence of transparent
processes of scrutiny or where such monitoring is conducted too lightly
or by groups unable to exercise independent views of the technology
concerned . Scientiﬁc experts and the
use of scientiﬁc expertise are central to dogmatism. Collingridge argues
that scientiﬁc experts distort the ‘proper task’ of technology which is
supposed to be to meet societal needs and fail to address more human
aspects of technology. Instead, they and their work tend to be unduly
optimistic, overly technical and serve the narrow needs of large organisations and government, by and for which their expertise is commissioned .
Thirdly, responsiveness is inhibited by diseconomies of scale.
Collingridge identiﬁed a number of indicators of scale,
and applied these to a variety of case studies, including system-built
high-rise buildings, nuclear power, large irrigation schemes in developing countries, and the US space shuttle. The indicators thereby implicated include long lead time, large unit size, capital intensity and
dependence on specialised infrastructure. Collingridge shows how these
characteristics of large inﬂexible technologies may bring economies of
scale once they are deployed but impose severe diseconomies of scale in
terms of response time and control costs on society if decisions are
subsequently found to be mistaken.
In all these ways, more fulsome institutionalisation of Collingridge’s
ideas to RRI might additionally emphasise and combine attention to: (a)
ﬂexible, incremental decisions, which are more likely to be taken by (b)
incremental decision-making processes accountable to stakeholders
who are usually left out of such mechanisms ; and (c) increased criticism (and relaxed reliance on) the
worldviews of the kinds of professional experts that tend to be most
implicated in RRI – again a key focus of ‘accountability’ as distinct from
‘responsibility’ . But Collingridge’s work is of
course also susceptible to critique – not least in relation to other
emerging insights in RRI. In particular, this discussion relates to a series
of analyses that have emerged since Collingridge ceased active research, including research on: constructive technology assessment and
discourse; the dynamics of expectations; and socio-technical scenarios
and imaginaries. It is to this that attention will now turn.
4. A critique of Collingridge’s work in relation to RRI
Over the last three decades, Collingridge’s own approach has been
subject to much useful criticism. Sometimes – despite its age –
prompting fresh research questions even now, this also oﬀers signiﬁcant
insights for developing RRI agendas. For instance, some critics of
Collingridge have read his work as an “externalist” view, unduly separating of relations between ‘technology’ and ‘society’ . Collingridge’s (somewhat defensive)
response is that (to him) the ‘story of technology… obviously involves
its social and institutional aspects as well’. But it is important here to
understand connections between the content of inﬂexible technologies
and the closed processes and interactions (i.e. between policy-makers
and large ﬁrms) through which they are promoted. In Kiran’s 
view RRI approaches should not seek to ‘appropriate’ this position. In
other words, governing technologies responsibly requires a more
nuanced approach to the relatively simple distinction between upstream or downstream ‘design strategies’ implied in the Collingridge
dilemma. Instead contemporary ‘mid-stream’ multidisciplinary perspectives recognise the mutual interdependence of the ‘technical’ and
the ‘social’, and oﬀer the potential to allow participants to work out
questions of function and meaning in the fray of sociotechnical development.
A second kind of criticism emanates from contributions to RRI literature which emphasise (and problematise) the responsiveness of actors to each other .
These juxtapose ideals of deliberative democracy working towards ‘the
common good’ with corresponding critiques from the ﬁeld of science
A. Genus, A. Stirling
Research Policy xxx (xxxx) xxx–xxx
and technology studies (STS) which stress the plurality of knowledges
and assumptions which can ‘inform collective action’ . Here however, there is actually a strong consistency with Collingridge’s position on the role of scientiﬁc expertise in technological
controversies, which emphasises how scientiﬁc experts called upon to
present knowledge for opposing sides in technical controversies, will
obviously disagree over interpretations and implications . Yet Collingridge does envisage
that mutual rapprochement of experts may be secured if appeals are
successful to ‘background values’ . For
its part, STS recognises that these values themselves are typically contestable .
Here again, however, Collingridge does nonetheless
still converge with pluralist STS, in that his notion of associated trial
and error learning ‘requires mutual co-ordination between disparate
interest groups sharing power, each having a veto’. It is from this (in
STS terms) more reﬂexive process, that more ﬂexible sociotechnical
conﬁgurations may be selected. These may be far from perfect, but they
may be expected to better serve the people aﬀected by them – as well as
proving better adapted to realities of human ignorance about the future.
In any case, this kind of appeal to shared or ‘background values’ can
also to be found in the STS-informed RRI literature – for instance in von
Schomberg’s description of the EU approach to RRI . The extent and depth in which underlying social values must be
diﬀerentiated, or may be assumed to be shared, could usefully be
problematized and subject to further scrutiny in future RRI research.
Two further key points here arise in the extent to which processes of
technology development embody or enable democratic inﬂuence of
those who stand to be aﬀected. Relating to the accountability issues
mentioned above, these concern the requisite diversity of stakeholders
involved in ‘alignment’ processes, as well as the capacities of these
processes for reﬂection and responsiveness to plural values and interests. Relevant here is Collingridge’s concern that debates about technologies be seen as continuing processes, rather than one-oﬀexercises.
Accordingly, his work highlights the need to conceive of accountabilities not consequentially in relation to postulated future outcomes,
but rather pragmatically in terms of more immediately apprehensible
contemporary qualities of innovation processes themselves: like inclusion, openness, incrementalism, ﬂexibility and reversibility.
Also, in Collingridge’s terms, the focus should not only be on
emerging technologies but also on monitoring those which have become entrenched. Recognising that judgements regarding the ﬂexibility
or robustness of technologies are always provisional, Collingridge argues that scrutiny should persist for as long as it is possible for debate to
continue. However, he does not say how the category of ‘aﬀected’
parties is to be determined in practice ex ante. Nor does he oﬀer guidance about how democratic governance should be practised so as to
admit such potential participants, let alone how to ensure in the presence of encompassing power gradients, that they exert inﬂuence over
decisions. Instead, Collingridge simply analyses cases where such actors
are ‘missing' and cautions about potentially inﬁnite
regress in criticism in (or of) science. Subsequent contributions, including contemporary approaches to RRI, still struggle to address these
issues eﬀectively. Here in particular, there seems much further scope
for further critical research and action.
One area where exactly these issues where this challenge was
especially addressed is Constructive Technology Assessment (CTA).
Also in danger of neglect in subsequent RRI research – and especially in
parallel ﬁelds like transition management – CTA focuses directly on
the open and inherently political nature of alignment processes.
Focussing on the dynamics of negotiating between promotion and
control, a range of strategies emerge on the part of regulators, marketing or environmental departments in ﬁrms and their various protagonists in wider political debate . In
Jasanoﬀ's work on sociotechnical imaginaries, as well, visions and understandings on the part of non-specialists are aﬀorded equal attention
and signiﬁcance to expert perspectives, with systematic contrasts observed between circumstances in contrasting national settings . Here, RRI shares in common with many other subsequent academic contributions to technology governance – including
transition management and CTA – a tendency to be most preoccupied
with interactions between social scientists, scientists, research funders,
policy makers and entrepreneurial or innovating ﬁrms. They have been
less directly concerned with relations (like accountability) extending to
NGOs and citizens more widely.
For example Owen et al. refer to the important role of
‘universities, institutes, and research funders’ who enjoy ‘co-responsibility’ for deﬁning responsible innovation and to ‘institutionally embed’
the RRI framework they advocate. In CTA reference is made to ‘the
relevant institutions and networks that are directly involved [in technology development], but also to “third parties” who can provide or
withhold credibility and legitimation .
Thus citizen perspectives and democratic control of technology can
appear secondary (even ‘tertiary’) considerations. This is despite declared aspirations and recognition that the institutionalising of new
technologies is an inherently social process in the widest sense, implicating broad societal and environmental concerns and unintended
eﬀects. Again, Jasanoﬀ’s discussion of ‘technologies of humility’
oﬀers some especially salient principles for ‘upstream’ citizen engagement, of kinds that remain to be institutionalised in any eﬀective way in
RRI. Indeed, tendencies discussed here in some RRI practices and
structures towards relatively instrumental orientation, narrow scope
and circumscribed participation, mean these may sometimes more accurately be referred to in Jasanoﬀ’s terms as ‘technologies of hubris’.
For his part, however, Collingridge may in these terms also be criticised for lack of attention to wider patterns of institutional organisation and practice around technological decision-making. Albeit still
under-developed, this is an important area of emerging attention in
contemporary work in RRI . Seen, after Giddens, as
recursive rules and resources through which social practices are made
and reproduced , institutions are ‘by deﬁnition’ the
most enduring features of social life in modern societies. They are thus
crucial to the dynamics of emerging sociotechnical conﬁgurations.
This said, though he does not explicitly use the term, it is clear that
Collingridge is strongly aware of institutional dynamics. For example,
Collingridge refers to how his approach can enable
more eﬀective criticism of those features of existing social institutions
that give rise to inﬂexible technologies. It could be argued, then, that
Collingridge’s views have implications for the formal or regulative institutional arrangements which could (or should, in his view) be
adopted to promote the responsible governance of innovation. These
involve the state avoiding gold plating favoured technologies through
ﬁnancial subsidies or taxation allowances. They also highlight the
limitations of a ‘picking winners’ approach to technology and innovation policy, with incrementalism more closely ﬁtting a policy of generating and preserving alternatives. Thus, to adapt Collingridge’s approach, analysis of relevant policies should seek to investigate not just
the governmental institutional arrangements, but also wider societal
and cultural contexts, which might bear on the shaping of more open
forms of research or more ﬂexible conﬁgurations for innovation capable
of being implemented by smaller and more diverse kinds of organisations .
In relation to institutionalised practices for monitoring decisions
about technology, Collingridge notes that conventional ‘administrative
rules’ serve to impede discovery of expert bias due to a series of factors.
First, there is unequal funding to expertise aligned with diﬀerent interests, making expertise unfair both in its availability and orientation.
Second, there is the tendency to domination of research ﬁelds and
agendas by a few experts – the so-called ‘Kehoe’ problem. This refers to
A. Genus, A. Stirling
Research Policy xxx (xxxx) xxx–xxx
the leading scientiﬁc authority on environmental lead in the 1930s,
whose ﬁndings came to determine an erroneous threshold limit for safe
exposure to lead. Third, there are bureaucratic rules which impose secrecy or protect key “facts” from criticism – as repeatedly documented
in public inquiries . This is also one in which it is recognised
that ‘there is nothing wrong’ in scientists being ‘advocates’ for particular perspectives or policies. As explored further by Pielke ,
however, this holds only for as long as scientiﬁc practices and norms are
adhered to in a broader sense – as well as wider values of reasoned
deliberation .
Collingridge’s work is informed by the contribution of Charles
Lindblom on the prevalence and reduction of ‘professional impairment’
 . A contemporary development of such thinking directs attention to ‘normative’ institutional arrangements which govern
the training of scientists and social scientists – for example, in relation
to public engagement and ethics, and in terms of their capacity for selfcriticism, reﬂection and proactive accountability. But what does not
feature so directly in Collingridge’s thinking, are institutionalised rules
implicated with understandings, beliefs and expectations concerning
participation of publics per se. This includes such rules concerning the
responsibilities of (and requirements for) citizens to play active roles in
technology development, to help guard against unfair or unwise innovations. But again, this gap in Collingridge’s thinking also seems to
persist equally in much contemporary academic thought.
The following section reﬂects on how RRI might usefully engage
more deeply with Collingridge’s ideas and the implications of doing so
for developing both understanding and practice of RRI. This discussion
also beneﬁts from appreciation for how Collingridge’s thinking is informed by Charles Lindblom’s work on political incrementalism and the
associated ‘Popperian’ fallibilist approach to decision-making under
conditions of uncertainty or ignorance. The discussion oﬀers for RRI a
sceptical view of anticipatory decision-making. It also oﬀers insights
into the constituting of reﬂexivity and responsiveness and to some extent inclusive deliberation of kinds that are emergent in Collingridge’s
work but not referenced within RRI literatures, even amongst those
contributions which cite him.
5. Building RRI: revisiting Collingridge?
Collingridge’s approach emphasises active processes of learning
from a particular class of past decisions in order to inform future decision-making about technology development, scientiﬁc research and
innovation. This contrasts with the more hubristic techno-scientiﬁc
approaches to ‘futures’ which form one branch of the technology assessment literature . Collingridge is concerned pragmatically with the qualities of emerging innovations, rather than consequentially with their outcomes. This should not be confused with
questions about the availability or not of knowledge regarding a focal,
emerging technology of a kind that might otherwise be the central
framing adopted in current approaches to responsible innovation.
Whereas his contributions are often thought of as being preoccupied
with lock-in and the closing down of governance processes, it is the
incrementalist and Popperian underpinning of Collingridge’s thinking
that most emphasise the need for open processes .
These themes are developed in the paragraphs below.
5.1. Incrementalism
Some contributions to RRI literature which refer to Collingridge’s
work, neglect to recognise its immersion in a wider pool of thinking
around incremental policy, strategy and decision-making. The writings
of Charles Lindblom, for instance, are a particularly strong inﬂuence on
Collingridge’s thinking about what he called the ‘management of scale’
and ﬂexible decision-making about technology.
For Lindblom incrementalism involves two aspects: a) an
emphasis on relatively small changes from some pre-existing state of
aﬀairs (which may nonetheless be large in their cumulative eﬀects); and
b) the participation of likely-aﬀected ‘partisans’ whose continual
proactive ‘mutual adjustments’ help to prevent the more egregious
kinds of mistake associated with centralised planning. Later, Lindblom
 emphasised the role and need for wider citizen engagements,
allowing the probing of past and prospective decisions. So too, in
Collingridge’s view, the post-hoc monitoring of past technological decisions should be encouraged in the form of public debate, with
recognition that this may periodically entail the reversal of deep commitments. In ways that chime with Van de Poel’s emphasis on
the need to include ‘outsiders’ and Winner’s concern with
‘missing actors’, both Lindblom and Collingridge see this in terms of
potentially empowering and involving those who are often left out of
technological decision-making. To the extent that some of the more
instrumental applications of RRI practice are seen (as discussed above)
in conservative quarters as substitutes for waves of policy enthusiasm
for ‘public engagement’, this work of Collingridge’s serves as a reminder
that wider inclusion and empowerment are central to – and constitutive
of – responsibility.
The resulting issues extend very widely. Collingridge identiﬁed as
one of the ‘most pressing problems of our time’, the question of: ‘can we
control our [sic] technology’? . In summarising his overall response, Collingridge notes that what is required
extends well beyond speciﬁc bolt-on methods, tools and practices, to
encompass the entire ‘normal machinery of politics’ . For
him, it is this ‘normal decision-making’ that needs to be much more
strongly conditioned by incrementalism. Thus he states that ‘we’ ought
to avoid those decisions that can’t be taken incrementally – a clear,
normative commitment with extensive repercussions not just for policy
but for the politics of technology more widely. It is in this way that
Collingridge seeks to escape the excessively deterministic connotations
of “control” . And it is in these senses that he oﬀers
what are arguably some of his most salient messages for RRI.
5.2. Ignorance and fallibility
Reaching back especially to the work of Popper , Collingridge’s incremental approach to the social control of technology is
based on the philosophy of fallibilism. Here, Collingridge considers
error to be an unavoidable part of being human. He contrasts his emphasis on human fallibility, with then (and still) prevailing conditions
under which incumbent governance cultures aspire – and claim −synoptically
probabilistic
methods for risk-based decision-making even more prominent today
than they were in Collingridge’s time, such attitudes are also exempliﬁed in the current emphasis on ‘sound science’ and ‘evidence
based decision-making’ – as if these permitted single self-evidently
deﬁnitive prescriptions .
This continuing ‘dominant tradition’ rests on what Collingridge refers to as the justiﬁcationist model, in which only those decisions which
can be fully justiﬁed are seen as rational. As a result, strong pressures
are formed to suppress recognition for uncertainties, ambiguities and
irreducible ignorance. In “Bayesian” and kindred approaches critiqued
by Collingridge, these kinds of indeterminacy and intractability are
aggregated
probabilities.
Collingridge’s insights that these kinds of ‘reductive aggregative’ tools
are deeply misleading. Yet many parts of the responsible innovation
literature that otherwise draw on his work, are not so clear concerning
these kinds of problems with what continue to be dominant methods
 .
There is a key parallel here between the Popperian process in which
A. Genus, A. Stirling
Research Policy xxx (xxxx) xxx–xxx
scientiﬁc progress rests on eﬀective falsiﬁcation of conjectures, and
ways in which wider capacities for reasoned societal interrogation can
expose ﬂaws in technology development and operation. It is arguably
here that the importance of accountability becomes most signiﬁcant –
as an element of responsibility relating not to anticipated consequences,
but to the appropriate prioritisation of ‘Collingridge qualities’ in
emerging technologies themselves. It is in qualities of inclusion, openness, incrementalism, ﬂexibility and reversibility that the parallels are
strongest between Popper and Collingridge. Conditions favouring robust knowledge and robust technology are not so diﬀerent. Again, the
implications for RRI are quite direct.
Taken together, there arise in the foregoing discussions a number of
searching questions with quite practical implications: 1). What are the
diﬀerent meanings and forms of RRI and how do these relate to concrete qualities identiﬁed by Collingridge? 2). To what extent is RRI
becoming institutionally embedded as a means to assert, or alternatively to challenge, processes of justiﬁcation? 3). What visions and
styles of scientiﬁc expertise and discourse are most promoted by RRI –
openly contending or apparently harmonious? 4) What are the relations
between public participation and stakeholder engagement with RRI – as
a source of challenge and substantive orientation, or a resource for
securing legitimacy? 5) What are the implications of practices and
structures of RRI for wider qualities of democratic accountability – do
these tend to be emphasised and reinforced, or suppressed and substituted?
6. Conclusion
This paper seeks to make a three-fold contribution. First it oﬀers a
relatively full and systematic critical analysis of the work of David
Collingridge – which is acknowledged to have exercised an important
inﬂuence on the currently burgeoning ﬁeld of responsible (research
and) innovation (RRI), but of which some of the wider and deeper
implications have arguably been neglected. Second, the paper has explored some speciﬁc implications of this relative neglect, for some
central themes in RRI – for instance arising in the importance of
pragmatic incrementalism rather than consequentialist justiﬁcation.
The third contribution has been to analyse some signiﬁcant limitations
in Collingridge’s approach as illuminated in the light of subsequent
developments. This also raises practical issues for RRI, particularly with
regard to the strengthening of ‘Collingridge qualities’ – including inclusion, openness, diversity, incrementalism, ﬂexibility and reversibility.
Of course, some problems are presented for aspects of Collingridge’s
analysis by the advent of contemporary ‘grand challenges’ for innovation policy, such as climate change and social justice. In particular,
serious questions appear to be raised for his vision of incrementalism,
by imperatives to achieve urgent and broad-scale transformations.
These may partly be alleviated by pointing to the potentially radical
cumulative eﬀects of incrementalism in achieving occasionally transformative emergent cultural “murmurations” . But the
tension still remains.
Likewise, there are also criticisms that Collingridge presents a decisionistic and ‘machinery view’ of technology in society, more consistent with ‘risk regulation’ than the ‘innovation governance’ of RRI
approaches. This links to the paradoxically deterministic connotations
of the ‘control’ metaphor that Collingridge uses to communicate his
analysis. Again, Collingridge’s choice of metaphor is of its time. His
prescriptions of inclusion, openness, diversity, incrementalism, ﬂexibility and reversibility might all now be better expressed in terms of
qualities other than ‘control’ – including care, solidarity, mutualism,
non-consequentialist notions of accountability and responsibility itself.
Nonetheless, whilst the questions raised for RRI still stand, these
limitations in Collingridge’s approach do detract from its contemporary
value. And, though he highlights the problem well, Collingridge’s work
also fails eﬀectively to resolve how to achieve the necessary kinds of
wider and deeper democratic deliberation, including by vulnerable
marginalised communities who are repeatedly deeply aﬀected by incumbent patterns of decision-making, but who remain perennially
‘missing actors’ . It is in this area that work in subsequent decades around modalities for participatory deliberation,
marginalised interests and responsiveness to ‘uninvited’ collective action arguably have most to oﬀer .
This reinforces a point that is already quite well appreciated in
particular areas of RRI but which may fruitfully be restated in terms of
three implications of the paper for future RRI research and practice and
the directions that these should take. First there is a need to develop
and invigorate more concrete and assertive frameworks for enabling
practice of critical citizen engagement and participatory deliberation
 . Attention to
the full scope of Collingridge’s analysis would fortify such moves. But it
would also have the eﬀect of raising particular questions and pointers.
Secondly, and in relation to the previous point, RRI needs to have
due regard to Collingridge’s emphasis on fallibility and the ever-present
intractabilities of ignorance. In terms of the direction of ensuing RRI
research and practice this highlights the value of processes and discourses that illuminate, rather than suppress, contention among specialists and wider societal interests. Particular challenges are raised by
this for the search for “right impacts” in RRI .
Here, an implication of the paper is that responsibility lies not in engineering consensus, but in exploring dissensus . And it is
in this regard that the ‘Collingridge qualities’ – around inclusion,
openness, diversity, incrementalism, ﬂexibility and reversibility – oﬀer
concrete constituting (albeit sometimes contending) axes meriting further deliberation in RRI.
Thirdly, to the extent that RRI approaches can fully embrace
Collingridge’s contributions, they will need to grapple not only with
contending qualities and principles for rationalistic decision making but
also with the fundamental realities (foundational for Collingridge) that
the governance of research and innovation are fundamentally about
‘muddling through’ in the presence of steep power gradients and
strongly asserted interests. In this sense, it is a core feature of responsibility that it is often better engaged with as a struggle against incumbent power, than as an instrumental facilitation .
Thus understood, one of the most important properties of responsibility
lies in the reinforcing – rather than the attenuation – of accountabilities.
In the end, the kinds of humility and pluralism urged by Collingridge in
the face of ignorance and contending interests, underscore the point
that the most responsible way to govern innovation is by democracy
itself. The institutions and practices of RRI are arguably only progressive insofar as they helps to strengthen, rather than weaken, this
general aim.