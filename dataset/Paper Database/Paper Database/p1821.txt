Building High-level Features
Using Large Scale Unsupervised Learning
Quoc V. Le
 
Marc’Aurelio Ranzato
 
Rajat Monga
 
Matthieu Devin
 
 
Greg S. Corrado
 
 
Andrew Y. Ng
 
We consider the problem of building highlevel, class-speciﬁc feature detectors from
only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a 9layered locally connected sparse autoencoder
with pooling and local contrast normalization
on a large dataset of images (the model has
1 billion connections, the dataset has 10 million 200x200 pixel images downloaded from
the Internet). We train this network using
model parallelism and asynchronous SGD on
a cluster with 1,000 machines (16,000 cores)
for three days. Contrary to what appears to
be a widely-held intuition, our experimental
results reveal that it is possible to train a face
detector without having to label images as
containing a face or not. Control experiments
show that this feature detector is robust not
only to translation but also to scaling and
out-of-plane rotation. We also ﬁnd that the
same network is sensitive to other high-level
concepts such as cat faces and human bodies. Starting with these learned features, we
trained our network to obtain 15.8% accuracy in recognizing 20,000 object categories
from ImageNet, a leap of 70% relative improvement over the previous state-of-the-art.
Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012.
Copyright 2012 by the author(s)/owner(s).
1. Introduction
The focus of this work is to build high-level, classspeciﬁc feature detectors from unlabeled images. For
instance, we would like to understand if it is possible to
build a face detector from only unlabeled images. This
approach is inspired by the neuroscientiﬁc conjecture
that there exist highly class-speciﬁc neurons in the human brain, generally and informally known as “grandmother neurons.”
The extent of class-speciﬁcity of
neurons in the brain is an area of active investigation,
but current experimental evidence suggests the possibility that some neurons in the temporal cortex are
highly selective for object categories such as faces or
hands , and perhaps even speciﬁc people .
Contemporary computer vision methodology typically
emphasizes the role of labeled data to obtain these
class-speciﬁc feature detectors. For example, to build
a face detector, one needs a large collection of images
labeled as containing faces, often with a bounding box
around the face. The need for large labeled sets poses
a signiﬁcant challenge for problems where labeled data
are rare. Although approaches that make use of inexpensive unlabeled data are often preferred, they have
not been shown to work well for building high-level
This work investigates the feasibility of building highlevel features from only unlabeled data.
A positive
answer to this question will give rise to two signiﬁcant
results. Practically, this provides an inexpensive way
to develop features from unlabeled data. But perhaps
more importantly, it answers an intriguing question as
to whether the speciﬁcity of the “grandmother neuron”
could possibly be learned from unlabeled data. Informally, this would suggest that it is at least in principle
possible that a baby learns to group faces into one class
Building high-level features using large-scale unsupervised learning
because it has seen many of them and not because it
is guided by supervision or rewards.
Unsupervised feature learning and deep learning have
emerged as methodologies in machine learning for
building features from unlabeled data. Using unlabeled
data in the wild to learn features is the key idea behind the self-taught learning framework . Successful feature learning algorithms and their
applications can be found in recent literature using
a variety of approaches such as RBMs , autoencoders , sparse coding 
and K-means .
So far, most of
these algorithms have only succeeded in learning lowlevel features such as “edge” or “blob” detectors. Going beyond such simple features and capturing complex invariances is the topic of this work.
Recent studies observe that it is quite time intensive
to train deep learning algorithms to yield state of the
art results . We conjecture that
the long training time is partially responsible for the
lack of high-level features reported in the literature.
For instance, researchers typically reduce the sizes of
datasets and models in order to train networks in a
practical amount of time, and these reductions undermine the learning of high-level features.
We address this problem by scaling up the core components involved in training deep networks: the dataset,
the model, and the computational resources.
we use a large dataset generated by sampling random
frames from random YouTube videos.1 Our input data
are 200x200 images, much larger than typical 32x32
images used in deep learning and unsupervised feature learning .
Our model, a
deep autoencoder with pooling and local contrast normalization, is scaled to these large images by using
a large computer cluster. To support parallelism on
this cluster, we use the idea of local receptive ﬁelds,
e.g., . This
idea reduces communication costs between machines
and thus allows model parallelism (parameters are distributed across machines). Asynchronous SGD is employed to support data parallelism.
The model was
trained in a distributed fashion on a cluster with 1,000
machines (16,000 cores) for three days.
Experimental results using classiﬁcation and visualization conﬁrm that it is indeed possible to build highlevel features from unlabeled data. In particular, using
a hold-out test set consisting of faces and distractors,
we discover a feature that is highly selective for faces.
1This is diﬀerent from the work of who
trained their model on images from one class.
This result is also validated by visualization via numerical optimization. Control experiments show that
the learned detector is not only invariant to translation
but also to out-of-plane rotation and scaling.
Similar experiments reveal the network also learns the
concepts of cat faces and human bodies.
The learned representations are also discriminative.
Using the learned features, we obtain signiﬁcant leaps
in object recognition with ImageNet. For instance, on
ImageNet with 20,000 categories, we achieved 15.8%
accuracy, a relative improvement of 70% over the stateof-the-art.
2. Training set construction
Our training dataset is constructed by sampling frames
from 10 million YouTube videos. To avoid duplicates,
each video contributes only one image to the dataset.
Each example is a color image with 200x200 pixels.
Appendix A. To check the proportion of faces in
the dataset, we run an OpenCV face detector on
60x60 randomly-sampled patches from the dataset
( This experiment shows that patches, being detected as faces by
the OpenCV face detector, account for less than 3% of
the 100,000 sampled patches
3. Algorithm
In this section, we describe the algorithm that we use
to learn features from the unlabeled training set.
3.1. Previous work
Our work is inspired by recent successful algorithms in unsupervised feature learning and deep
 . It is strongly
inﬂuenced by the work of 
on sparse coding.
According to their study, sparse
coding can be trained on unlabeled natural images to yield receptive ﬁelds akin to V1 simple
cells .
One shortcoming of early approaches such as sparse
coding is that their architectures are shallow and typically capture low-level
concepts (e.g., edge “Gabor” ﬁlters) and simple invariances. Addressing this issue is a focus of recent work in
deep learning which
build hierarchies of feature representations. In particular, Lee et al show that stacked sparse RBMs
can model certain simple functions of the V2 area of
the cortex. They also demonstrate that convolutional
Building high-level features using large-scale unsupervised learning
DBNs , trained on aligned images of
faces, can learn a face detector. This result is interesting, but unfortunately requires a certain degree of
supervision during dataset construction: their training
images (i.e., Caltech 101 images) are aligned, homogeneous and belong to one selected category.
Figure 1. The architecture and parameters in one layer of
our network. The overall network replicates this structure
three times. For simplicity, the images are in 1D.
3.2. Architecture
Our algorithm is built upon these ideas and can be
viewed as a sparse deep autoencoder with three important ingredients:
local receptive ﬁelds, pooling
and local contrast normalization. First, to scale the
autoencoder to large images, we use a simple idea
known as local receptive ﬁelds .
This biologically inspired idea proposes that each feature in the autoencoder can connect only to a small
region of the lower layer.
Next, to achieve invariance to local deformations, we employ local L2 pooling and local
contrast normalization . L2 pooling, in particular, allows the learning of invariant features .
Our deep autoencoder is constructed by replicating
three times the same stage composed of local ﬁltering,
local pooling and local contrast normalization.
output of one stage is the input to the next one and
the overall model can be interpreted as a nine-layered
network (see Figure 1).
The ﬁrst and second sublayers are often known as ﬁltering (or simple) and pooling (or complex) respectively. The third sublayer performs local subtractive
and divisive normalization and it is inspired by biological and computational models .2
As mentioned above, central to our approach is the use
of local connectivity between neurons. In our experiments, the ﬁrst sublayer has receptive ﬁelds of 18x18
pixels and the second sublayer and the second sublayer pools over 5x5 overlapping neighborhoods of features (i.e., pooling size). The neurons in the ﬁrst sublayer connect to pixels in all input channels (or maps)
whereas the neurons in the second sublayer connect
to pixels of only one channel (or map).3
ﬁrst sublayer outputs linear ﬁlter responses, the pooling layer outputs the square root of the sum of the
squares of its inputs, and therefore, it is known as L2
Our style of stacking a series of uniform modules,
selectivity
reminiscent
Neocognition
HMAX .
It has also
been argued to be an architecture employed by the
brain .
Although we use local receptive ﬁelds,
not convolutional:
the parameters are not shared
across diﬀerent locations in the image.
a stark diﬀerence between our approach and previous work .
In addition to being more biologically plausible, unshared weights allow the learning
of more invariances other than translational invariances .
In terms of scale, our network is perhaps one of the
largest known networks to date. It has 1 billion trainable parameters, which is more than an order of magnitude larger than other large networks reported in literature, e.g., with around 10 million parameters.
worth noting that our network is still tiny compared to the human visual cortex, which is 106
times larger in terms of the number of neurons and
synapses .
3.3. Learning and Optimization
During learning, the parameters of the
second sublayers (H) are ﬁxed to uniform weights,
subtractive
normalization
neighboring
iuv Guvhi,j+u,i+v
normalization
gi,j,k/ max{c, (P
i,j+u,i+v)0.5},
to be a small number, 0.01, to prevent numerical errors.
G is a Gaussian weighting window. 
3For more details regarding connectivity patterns and
parameter sensitivity, see Appendix B and E.
Building high-level features using large-scale unsupervised learning
whereas the encoding weights W1
and decoding
weights W2 of the ﬁrst sublayers are adjusted using
the following optimization problem
1 x(i) −x(i)
ǫ + Hj .4
ﬁrst term in the objective ensures the representations
encode important information about the data, i.e.,
they can reconstruct input data; whereas the second
term encourages pooling features to group similar features together to achieve invariances.
Optimization:
All parameters in our model were
trained jointly with the objective being the sum of the
objectives of the three layers.
To train the model, we implemented model parallelism
by distributing the local weights W1, W2 and H to
diﬀerent machines.
A single instance of the model
partitions the neurons and weights out across 169 machines (where each machine had 16 CPU cores).
set of machines that collectively make up a single copy
of the model is referred to as a “model replica.” We
have built a software framework called DistBelief that
manages all the necessary communication between the
diﬀerent machines within a model replica, so that users
of the framework merely need to write the desired upwards and downwards computation functions for the
neurons in the model, and don’t have to deal with the
low-level communication of data across machines.
We further scaled up the training by implementing
asynchronous SGD using multiple replicas of the core
For the experiments described here, we divided the training into 5 portions and ran a copy of
the model on each of these portions. The models communicate updates through a set of centralized “parameter servers,” which keep the current state of all parameters for the model in a set of partitioned servers
(we used 256 parameter server partitions for training
the model described in this paper). In the simplest
4In , the encoding weights and the decoding weights are tied: W1 = W2.
However, for better parallelism and better features, our
implementation does not enforce tied weights.
implementation, before processing each mini-batch a
model replica asks the centralized parameter servers
for an updated copy of its model parameters. It then
processes a mini-batch to compute a parameter gradient, and sends the parameter gradients to the appropriate parameter servers, which then apply each
gradient to the current value of the model parameter. We can reduce the communication overhead by
having each model replica request updated parameters every P steps and by sending updated gradient
values to the parameter servers every G steps (where
G might not be equal to P). Our DistBelief software
framework automatically manages the transfer of parameters and gradients between the model partitions
and the parameter servers, freeing implementors of the
layer functions from having to deal with these issues.
Asynchronous SGD is more robust to failure than standard (synchronous) SGD. Speciﬁcally, for synchronous
SGD, if one of the machines goes down, the entire
training process is delayed; whereas for asynchronous
SGD, if one machine goes down, only one copy of SGD
is delayed while the rest of the optimization can still
In our training, at every step of SGD, the gradient is
computed on a minibatch of 100 examples. We trained
the network on a cluster with 1,000 machines for three
days. See Appendix B, C, and D for more details regarding our implementation of the optimization.
4. Experiments on Faces
In this section, we describe our analysis of the learned
representations in recognizing faces (“the face detector”) and present control experiments to understand
invariance properties of the face detector. Results for
other concepts are presented in the next section.
4.1. Test set
sampled from two datasets:
Labeled Faces In the
Wild dataset and ImageNet
dataset .
There are 13,026 faces
sampled from non-aligned Labeled Faces in The Wild.5
The rest are distractor objects randomly sampled from
ImageNet. These images are resized to ﬁt the visible
areas of the top neurons. Some example images are
shown in Appendix A.
4.2. Experimental protocols
After training, we used this test set to measure the
performance of each neuron in classifying faces against
distractors. For each neuron, we found its maximum
5 
Building high-level features using large-scale unsupervised learning
and minimum activation values, then picked 20 equally
spaced thresholds in between. The reported accuracy
is the best classiﬁcation accuracy among 20 thresholds.
4.3. Recognition
Surprisingly, the best neuron in the network performs
very well in recognizing faces, despite the fact that no
supervisory signals were given during training.
best neuron in the network achieves 81.7% accuracy in
detecting faces. There are 13,026 faces in the test set,
so guessing all negative only achieves 64.8%. The best
neuron in a one-layered network only achieves 71% accuracy while best linear ﬁlter, selected among 100,000
ﬁlters sampled randomly from the training set, only
achieves 74%.
To understand their contribution, we removed the local contrast normalization sublayers and trained the
network again.
Results show that the accuracy of
best neuron drops to 78.5%.
This agrees with previous study showing the importance of local contrast
normalization .
We visualize histograms of activation values for face
images and random images in Figure 2. It can be seen,
even with exclusively unlabeled data, the neuron learns
to diﬀerentiate between faces and random distractors.
Speciﬁcally, when we give a face as an input image, the
neuron tends to output value larger than the threshold,
0. In contrast, if we give a random image as an input
image, the neuron tends to output value less than 0.
Histograms of faces (red) vs.
no faces (blue).
The test set is subsampled such that the ratio between
faces and no faces is one.
4.4. Visualization
In this section, we will present two visualization techniques to verify if the optimal stimulus of the neuron is
indeed a face. The ﬁrst method is visualizing the most
responsive stimuli in the test set. Since the test set
is large, this method can reliably detect near optimal
stimuli of the tested neuron.
The second approach
is to perform numerical optimization to ﬁnd the optimal stimulus . In particular, we ﬁnd the normbounded input x which maximizes the output f of the
tested neuron, by solving:
x∗= arg min
x f(x; W, H), subject to ||x||2 = 1.
Here, f(x; W, H) is the output of the tested neuron
given learned parameters W, H and input x. In our
experiments, this constraint optimization problem is
solved by projected gradient descent with line search.
These visualization methods have complementary
strengths and weaknesses.
For instance, visualizing
the most responsive stimuli may suﬀer from ﬁtting to
noise. On the other hand, the numerical optimization
approach can be susceptible to local minima. Results,
shown in Figure 13, conﬁrm that the tested neuron
indeed learns the concept of faces.
Figure 3. Top: Top 48 stimuli of the best neuron from the
test set. Bottom: The optimal stimulus according to numerical constraint optimization.
4.5. Invariance properties
We would like to assess the robustness of the face detector against common object transformations, e.g.,
translation, scaling and out-of-plane rotation. First,
we chose a set of 10 face images and perform distortions to them, e.g., scaling and translating. For outof-plane rotation, we used 10 images of faces rotating
in 3D (“out-of-plane”) as the test set. To check the robustness of the neuron, we plot its averaged response
over the small test set with respect to changes in scale,
3D rotation (Figure 4), and translation (Figure 5).6
6Scaled, translated faces are generated by standard
cubic interpolation. For 3D rotated faces, we used 10 se-
Building high-level features using large-scale unsupervised learning
Figure 4. Scale (left) and out-of-plane (3D) rotation (right)
invariance properties of the best feature.
Figure 5. Translational invariance properties of the best
feature. x-axis is in pixels
The results show that the neuron is robust against
complex and diﬃcult-to-hard-wire invariances such as
out-of-plane rotation and scaling.
Control experiments on dataset without faces:
As reported above, the best neuron achieves 81.7% accuracy in classifying faces against random distractors.
What if we remove all images that have faces from the
training set?
We performed the control experiment by running a
face detector in OpenCV and removing those training
images that contain at least one face. The recognition
accuracy of the best neuron dropped to 72.5% which
is as low as simple linear ﬁlters reported in section 4.3.
5. Cat and human body detectors
Having achieved a face-sensitive neuron, we would like
to understand if the network is also able to detect other
high-level concepts.
We observed that the most common objects in the
YouTube dataset are body parts and pets and hence
suspected that the network also learns these concepts.
To verify this hypothesis and quantify selectivity properties of the network with respect to these concepts,
we constructed two datasets, one for classifying human bodies against random backgrounds and one for
classifying cat faces against other random distractors.
quences of rotated faces from The Sheﬃeld Face Database –
 
Diﬀerent sequences record rotated faces of diﬀerent individuals. The dataset only contains rotated faces up to 90
degrees. See Appendix F for a sample sequence.
Figure 6. Visualization of the cat face neuron (left) and
human body neuron (right).
For the ease of interpretation, these datasets have a
positive-to-negative ratio identical to the face dataset.
The cat face images are collected from the dataset described in . In this dataset, there
are 10,000 positive images and 18,409 negative images
(so that the positive-to-negative ratio is similar to the
case of faces). The negative images are chosen randomly from the ImageNet dataset.
Negative and positive examples in our human body
dataset are subsampled at random from a benchmark
dataset . In the original dataset,
each example is a pair of stereo black-and-white images. But for simplicity, we keep only the left images.
In total, like in the case of human faces, we have 13,026
positive and 23,974 negative examples.
We then followed the same experimental protocols as
before. The results, shown in Figure 14, conﬁrm that
the network learns not only the concept of faces but
also the concepts of cat faces and human bodies.
Our high-level detectors also outperform standard
baselines in terms of recognition rates, achieving 74.8%
and 76.7% on cat and human body respectively. In
comparison, best linear ﬁlters (sampled from the training set) only achieve 67.2% and 68.1% respectively.
In Table 1, we summarize all previous numerical results comparing the best neurons against other baselines such as linear ﬁlters and random guesses. To understand the eﬀects of training, we also measure the
performance of best neurons in the same network at
random initialization.
During the development process of our algorithm, we
also tried several other algorithms such as deep autoencoders and K-means . In our implementation, deep autoencoders are also locally connected and use sigmoidal activation function. For Kmeans, we downsample images to 40x40 in order to
lower computational costs.
We also varied the parameters of autoencoders, Kmeans and chose them to maximize performances
Building high-level features using large-scale unsupervised learning
Table 1. Summary of numerical comparisons between our algorithm against other baselines. Top: Our algorithm vs.
simple baselines.
Here, the ﬁrst three columns are results for methods that do not require training: random guess,
random weights (of the network at initialization, without any training) and best linear ﬁlters selected from 100,000
examples sampled from the training set. The last three columns are results for methods that have training: the best
neuron in the ﬁrst layer, the best neuron in the highest layer after training, the best neuron in the network when the
contrast normalization layers are removed. Bottom: Our algorithm vs. autoencoders and K-means.
Same architecture
Best neuron without
with random weights
linear ﬁlter
layer neuron
contrast normalization
Human bodies
Deep autoencoders
Deep autoencoders
K-means on
40x40 images
Human bodies
Table 2. Summary of classiﬁcation accuracies for our method and other state-of-the-art baselines on ImageNet.
Dataset version
2009 (∼9M images, ∼10K categories)
2011 (∼16M images, ∼20K categories)
State-of-the-art
16.7% 
9.3% 
Our method
16.1% (without pretraining)
13.6% (without pretraining)
19.2% (with pretraining)
15.8% (with pretraining)
given resource constraints.
In our experiments, we
used 30,000 centroids for K-means. These models also
employed parallelism in a similar fashion described in
the paper. They also used 1,000 machines for three
days. Results of these baselines are reported in the
bottom of Table 1.
6. Object recognition with ImageNet
We applied the feature learning method to the
recognizing
dataset .
After unsupervised
training on YouTube and ImageNet images, we added
one-versus-all logistic classiﬁers on top of the highest
We ﬁrst trained the logistic classiﬁers and
then ﬁne-tuned the network. Regularization was not
employed in the logistic classiﬁers. The entire training
was carried out on 2,000 machines for one week.
We followed the experimental protocols speciﬁed
by , in
which, the datasets are randomly split into two halves
for training and validation. We report the performance
on the validation set and compare against state-of-theart baselines in Table 2. Note that the splits are not
identical to previous work but validation set performances vary slightly across diﬀerent splits.
The results show that our method, starting from
scratch (i.e., raw pixels), bests many state-of-the-art
baselines with hand-engineered features. On ImageNet
with 10K categories, our method yielded a 15% relative
improvement over previous best published result. On
ImageNet with 20K categories, our method achieved a
70% relative improvement over the highest other result
of which we are aware ).
7. Conclusion
In this work, we simulated high-level class-speciﬁc neurons using unlabeled data. We achieved this by combining ideas from recently developed algorithms to
learn invariances from unlabeled data. Our implementation scales to a cluster with thousands of machines
thanks to model parallelism and asynchronous SGD.
Our work shows that it is possible to train neurons to
be selective for high-level concepts using entirely unlabeled data. In our experiments, we obtained neurons
that function as detectors for faces, human bodies, and
cat faces by training on random frames of YouTube
videos. These neurons naturally capture complex invariances such as out-of-plane and scale invariances.
Using the learned representations, we obtain 15.8% accuracy for object recognition on ImageNet with 20,000
categories, a signiﬁcant leap of 70% relative improvement over the state-of-the-art.
Acknowledgements:
Adam Coates, Tom Dean, Mark Mao, Peter Norvig,
Paul Tucker, Andrew Saxe, and Jon Shlens for helpful
discussions and suggestions.