Cascade R-CNN: Delving into High Quality Object Detection
Zhaowei Cai
UC San Diego
 
Nuno Vasconcelos
UC San Diego
 
In object detection, an intersection over union (IoU)
threshold is required to deﬁne positives and negatives. An
object detector, trained with low IoU threshold, e.g. 0.5,
usually produces noisy detections. However, detection performance tends to degrade with increasing the IoU thresholds. Two main factors are responsible for this: 1) over-
ﬁtting during training, due to exponentially vanishing positive samples, and 2) inference-time mismatch between the
IoUs for which the detector is optimal and those of the input hypotheses. A multi-stage object detection architecture,
the Cascade R-CNN, is proposed to address these problems. It consists of a sequence of detectors trained with
increasing IoU thresholds, to be sequentially more selective against close false positives. The detectors are trained
stage by stage, leveraging the observation that the output of a detector is a good distribution for training the
next higher quality detector. The resampling of progressively improved hypotheses guarantees that all detectors
have a positive set of examples of equivalent size, reducing the overﬁtting problem. The same cascade procedure
is applied at inference, enabling a closer match between
the hypotheses and the detector quality of each stage. A
simple implementation of the Cascade R-CNN is shown to
surpass all single-model object detectors on the challenging COCO dataset. Experiments also show that the Cascade R-CNN is widely applicable across detector architectures, achieving consistent gains independently of the baseline detector strength. The code will be made available at
 
1. Introduction
Object detection is a complex problem, requiring the solution of two main tasks. First, the detector must solve the
recognition problem, to distinguish foreground objects from
background and assign them the proper object class labels.
Second, the detector must solve the localization problem, to
assign accurate bounding boxes to different objects. Both
of these are particularly difﬁcult because the detector faces
person: 1.00
person: 1.00
person: 0.99
person: 0.99
person: 0.87
person: 0.82
person: 0.77
person: 0.70
person: 0.64
person: 0.63
person: 0.56
frisbee: 1.00
frisbee: 1.00
frisbee: 0.99
frisbee: 0.97
(a) Detection of u = 0.5
person: 1.00
person: 0.99
person: 0.96
person: 0.94
person: 0.55
frisbee: 0.99
frisbee: 0.99
frisbee: 0.99
frisbee: 0.93
(b) Detection of u = 0.7
Output IoU
Localization Performance
(c) Regressor
IoU Threshold
Detection Performance
u=0.5 (AP=0.349)
u=0.6 (AP=0.354)
u=0.7 (AP=0.319)
(d) Detector
Figure 1. The detection outputs, localization and detection performance of object detectors of increasing IoU threshold u.
many “close” false positives, corresponding to “close but
not correct” bounding boxes. The detector must ﬁnd the
true positives while suppressing these close false positives.
Many of the recently proposed object detectors are based
on the two-stage R-CNN framework , where
detection is framed as a multi-task learning problem that
combines classiﬁcation and bounding box regression. Unlike object recognition, an intersection over union (IoU)
threshold is required to deﬁne positives/negatives. However, the commonly used threshold values u, typically
u = 0.5, establish quite a loose requirement for positives.
The resulting detectors frequently produce noisy bounding
boxes, as shown in Figure 1 (a). Hypotheses that most humans would consider close false positives frequently pass
the IoU ≥0.5 test. While the examples assembled under
the u = 0.5 criterion are rich and diversiﬁed, they make
it difﬁcult to train detectors that can effectively reject close
false positives.
In this work, we deﬁne the quality of an hypothesis as its
IoU with the ground truth, and the quality of the detector as
the IoU threshold u used to train it. The goal is to investi-
gate the, so far, poorly researched problem of learning high
quality object detectors, whose outputs contain few close
false positives, as shown in Figure 1 (b). The basic idea is
that a single detector can only be optimal for a single quality level. This is known in the cost-sensitive learning literature , where the optimization of different points of
the receiver operating characteristic (ROC) requires different loss functions. The main difference is that we consider
the optimization for a given IoU threshold, rather than false
positive rate.
The idea is illustrated by Figure 1 (c) and (d), which
present the localization and detection performance, respectively, of three detectors trained with IoU thresholds of
u = 0.5, 0.6, 0.7. The localization performance is evaluated as a function of the IoU of the input proposals, and
the detection performance as a function of IoU threshold,
as in COCO . Note that, in Figure 1 (c), each bounding
box regressor performs best for examples of IoU close to
the threshold that the detector was trained. This also holds
for detection performance, up to overﬁtting. Figure 1 (d)
shows that, the detector of u = 0.5 outperforms the detector of u = 0.6 for low IoU examples, underperforming it
at higher IoU levels. In general, a detector optimized at a
single IoU level is not necessarily optimal at other levels.
These observations suggest that higher quality detection requires a closer quality match between the detector and the
hypotheses that it processes. In general, a detector can only
have high quality if presented with high quality proposals.
However, to produce a high quality detector, it does not
sufﬁce to simply increase u during training. In fact, as seen
for the detector of u = 0.7 of Figure 1 (d), this can degrade
detection performance. The problem is that the distribution
of hypotheses out of a proposal detector is usually heavily
imbalanced towards low quality. In general, forcing larger
IoU thresholds leads to an exponentially smaller numbers
of positive training samples. This is particularly problematic for neural networks, which are known to be very example intensive, and makes the “high u” training strategy quite
prone to overﬁtting. Another difﬁculty is the mismatch between the quality of the detector and that of the testing hypotheses at inference. As shown in Figure 1, high quality
detectors are only necessarily optimal for high quality hypotheses. The detection could be suboptimal when they are
asked to work on the hypotheses of other quality levels.
In this paper, we propose a new detector architecture,
Cascade R-CNN, that addresses these problems.
multi-stage extension of the R-CNN, where detector stages
deeper into the cascade are sequentially more selective
against close false positives. The cascade of R-CNN stages
are trained sequentially, using the output of one stage to
train the next. This is motivated by the observation that the
output IoU of a regressor is almost invariably better than
the input IoU. This observation can be made in Figure 1
(c), where all plots are above the gray line. It suggests that
the output of a detector trained with a certain IoU threshold is a good distribution to train the detector of the next
higher IoU threshold. This is similar to boostrapping methods commonly used to assemble datasets in object detection literature . The main difference is that the resampling procedure of the Cascade R-CNN does not aim to
mine hard negatives. Instead, by adjusting bounding boxes,
each stage aims to ﬁnd a good set of close false positives
for training the next stage. When operating in this manner, a sequence of detectors adapted to increasingly higher
IoUs can beat the overﬁtting problem, and thus be effectively trained. At inference, the same cascade procedure is
applied. The progressively improved hypotheses are better matched to the increasing detector quality at each stage.
This enables higher detection accuracies, as suggested by
Figure 1 (c) and (d).
The Cascade R-CNN is quite simple to implement and
trained end-to-end. Our results show that a vanilla implementation, without any bells and whistles, surpasses all previous state-of-the-art single-model detectors by a large margin, on the challenging COCO detection task , especially under the higher quality evaluation metrics. In addition, the Cascade R-CNN can be built with any two-stage
object detector based on the R-CNN framework. We have
observed consistent gains (of 2∼4 points), at a marginal
increase in computation. This gain is independent of the
strength of the baseline object detectors. We thus believe
that this simple and effective detection architecture can be
of interest for many object detection research efforts.
2. Related Work
Due to the success of the R-CNN architecture, the
two-stage formulation of the detection problems, by combining a proposal detector and a region-wise classiﬁer has
become predominant in the recent past. To reduce redundant CNN computations in the R-CNN, the SPP-Net 
and Fast-RCNN introduced the idea of region-wise feature extraction, signiﬁcantly speeding up the overall detector. Later, the Faster-RCNN achieved further speedsup by introducing a Region Proposal Network (RPN). This
architecture has become a leading object detection framework. Some more recent works have extended it to address
various problems of detail. For example, the R-FCN 
proposed efﬁcient region-wise fully convolutions without
accuracy loss, to avoid the heavy region-wise CNN computations of the Faster-RCNN; while the MS-CNN and
FPN detect proposals at multiple output layers, so as
to alleviate the scale mismatch between the RPN receptive
ﬁelds and actual object size, for high-recall proposal detection.
Alternatively, one-stage object detection architectures
have also become popular, mostly due to their computational efﬁciency. These architectures are close to the classic
sliding window strategy . YOLO outputs very
sparse detection results by forwarding the input image once.
When implemented with an efﬁcient backbone network, it
enables real time object detection with fair performance.
SSD detects objects in a way similar to the RPN ,
but uses multiple feature maps at different resolutions to
cover objects at various scales. The main limitation of these
architectures is that their accuracies are typically below that
of two-stage detectors. Recently, RetinaNet was proposed to address the extreme foreground-background class
imbalance in dense object detection, achieving better results
than state-of-the-art two-stage object detectors.
Some explorations in multi-stage object detection have
also been proposed. The multi-region detector introduced iterative bounding box regression, where a R-CNN
is applied several times, to produce better bounding boxes.
CRAFT and AttractioNet used a multi-stage procedure to generate accurate proposals, and forwarded them
to a Fast-RCNN. embedded the classic cascade architecture of in object detection networks. iterated a
detection and a segmentation task alternatively, for instance
segmentation.
3. Object Detection
In this paper, we extend the two-stage architecture of the
Faster-RCNN , shown in Figure 3 (a). The ﬁrst stage
is a proposal sub-network (“H0”), applied to the entire image, to produce preliminary detection hypotheses, known
as object proposals. In the second stage, these hypotheses are then processed by a region-of-interest detection subnetwork (“H1”), denoted as detection head. A ﬁnal classi-
ﬁcation score (“C”) and a bounding box (“B”) are assigned
to each hypothesis. We focus on modeling a multi-stage detection sub-network, and adopt, but are not limited to, the
RPN for proposal detection.
3.1. Bounding Box Regression
A bounding box b = (bx, by, bw, bh) contains the four
coordinates of an image patch x. The task of bounding box
regression is to regress a candidate bounding box b into a
target bounding box g, using a regressor f(x, b). This is
learned from a training sample {gi, bi}, so as to minimize
the bounding box risk
Lloc(f(xi, bi), gi),
where Lloc was a L2 loss function in R-CNN , but updated to a smoothed L1 loss function in Fast-RCNN .
To encourage a regression invariant to scale and location,
Lloc operates on the distance vector ∆= (δx, δy, δw, δh)
µx = 0.0020
µy = 0.0022
σx = 0.1234
σy = 0.1297
µx = 0.0048
µy = −0.0012
σx = 0.0606
σy = 0.0613
µx = 0.0032
µy = −0.0021
σx = 0.0391
σy = 0.0376
µw = 0.0161
µh = 0.0498
σw = 0.2272
σh = 0.2255
µw = −0.0007
µh = 0.0122
σw = 0.1221
σh = 0.1230
µw = −0.0017
µh = 0.0004
σw = 0.0798
σh = 0.0773
Figure 2. Sequential ∆distribution (without normalization) at different cascade stage. Red dots are outliers when using increasing
IoU thresholds, and the statistics are obtained after outlier removal.
δx = (gx −bx)/bw,
δy = (gy −by)/bh
δw = log(gw/bw),
δh = log(gh/bh).
Since bounding box regression usually performs minor adjustments on b, the numerical values of (2) can be very
Hence, the risk of (1) is usually much smaller
than the classiﬁcation risk. To improve the effectiveness
of multi-task learning, ∆is usually normalized by its mean
and variance, i.e. δx is replaced by δ′
x = (δx −µx)/σx.
This is widely used in the literature .
Some works have argued that a single regression step of f is insufﬁcient for accurate localization. Instead, f is applied iteratively, as a post-processing step
f ′(x, b) = f ◦f ◦· · · ◦f(x, b),
to reﬁne a bounding box b. This is called iterative bounding box regression, denoted as iterative BBox. It can be
implemented with the inference architecture of Figure 3 (b)
where all heads are the same. This idea, however, ignores
two problems. First, as shown in Figure 1, a regressor f
trained at u = 0.5, is suboptimal for hypotheses of higher
IoUs. It actually degrades bounding boxes of IoU larger
than 0.85. Second, as shown in Figure 2, the distribution of
bounding boxes changes signiﬁcantly after each iteration.
While the regressor is optimal for the initial distribution it
can be quite suboptimal after that. Due to these problems,
iterative BBox requires a fair amount of human engineering, in the form of proposal accumulation, box voting, etc.
 , and has somewhat unreliable gains. Usually,
there is no beneﬁt beyond applying f twice.
3.2. Classiﬁcation
The classiﬁer is a function h(x) that assigns an image
patch x to one of M + 1 classes, where class 0 contains
(a) Faster R-CNN
(b) Iterative BBox at inference
(c) Integral Loss
(d) Cascade R-CNN
Figure 3. The architectures of different frameworks. “I” is input image, “conv” backbone convolutions, “pool” region-wise feature extraction, “H” network head, “B” bounding box, and “C” classiﬁcation. “B0” is proposals in all architectures.
background and the remaining the objects to detect. h(x) is
a M + 1-dimensional estimate of the posterior distribution
over classes, i.e. hk(x) = p(y = k|x), where y is the
class label. Given a training set (xi, yi), it is learned by
minimizing a classiﬁcation risk
Lcls(h(xi), yi),
where Lcls is the classic cross-entropy loss.
3.3. Detection Quality
Since a bounding box usually includes an object and
some amount of background, it is difﬁcult to determine if
a detection is positive or negative. This is usually addressed
by the IoU metric. If the IoU is above a threshold u, the
patch is considered an example of the class. Thus, the class
label of a hypothesis x is a function of u,
IoU(x, g) ≥u
where gy is the class label of the ground truth object g. This
IoU threshold u deﬁnes the quality of a detector.
Object detection is challenging because, no matter
threshold, the detection setting is highly adversarial. When
u is high, the positives contain less background, but it is dif-
ﬁcult to assemble enough positive training examples. When
u is low, a richer and more diversiﬁed positive training set
is available, but the trained detector has little incentive to
reject close false positives. In general, it is very difﬁcult
to ask a single classiﬁer to perform uniformly well over all
IoU levels. At inference, since the majority of the hypotheses produced by a proposal detector, e.g. RPN or selective search , have low quality, the detector must be more
discriminant for lower quality hypotheses. A standard compromise between these conﬂicting requirements is to settle
on u = 0.5. This, however, is a relatively low threshold,
leading to low quality detections that most humans consider
close false positives, as shown in Figure 1 (a).
A na¨ıve solution is to develop an ensemble of classiﬁers,
with the architecture of Figure 3 (c), optimized with a loss
Figure 4. The IoU histogram of training samples. The distribution
at 1st stage is the output of RPN. The red numbers are the positive
percentage higher than the corresponding IoU threshold.
that targets various quality levels,
Lcls(h(x), y) =
Lcls(hu(x), yu),
where U is a set of IoU thresholds.
This is closely
related to the integral loss of , in which U
{0.5, 0.55, · · · , 0.75}, designed to ﬁt the evaluation metric
of the COCO challenge. By deﬁnition, the classiﬁers need
to be ensembled at inference. This solution fails to address
the problem that the different losses of (6) operate on different numbers of positives. As shown in the ﬁrst ﬁgure
of Figure 4, the set of positive samples decreases quickly
with u. This is particularly problematic because the high
quality classiﬁers are prone to overﬁtting. In addition, those
high quality classiﬁers are required to process proposals of
overwhelming low quality at inference, for which they are
not optimized. Due to all this, the ensemble of (6) fails to
achieve higher accuracy at most quality levels, and the architecture has very little gain over that of Figure 3 (a).
4. Cascade R-CNN
In this section we introduce the proposed Cascade R-
CNN object detection architecture of Figure 3 (d).
4.1. Cascaded Bounding Box Regression
As seen in Figure 1 (c), it is very difﬁcult to ask a single
regressor to perform perfectly uniformly at all quality levels. The difﬁcult regression task can be decomposed into
a sequence of simpler steps, inspired by the works of cascade pose regression and face alignment . In the
Cascade R-CNN, it is framed as a cascaded regression problem, with the architecture of Figure 3 (d). This relies on a
cascade of specialized regressors
f(x, b) = fT ◦fT −1 ◦· · · ◦f1(x, b),
where T is the total number of cascade stages. Note that
each regressor ft in the cascade is optimized w.r.t. the sample distribution {bt} arriving at the corresponding stage, instead of the initial distribution of {b1}. This cascade improves hypotheses progressively.
It differs from the iterative BBox architecture of Figure
3 (b) in several ways. First, while iterative BBox is a postprocessing procedure used to improve bounding boxes, cascaded regression is a resampling procedure that changes the
distribution of hypotheses to be processed by the different
stages. Second, because it is used at both training and inference, there is no discrepancy between training and inference distributions. Third, the multiple specialized regressors {fT, fT −1, · · · , f1} are optimized for the resampled
distributions of the different stages. This opposes to the
single f of (3), which is only optimal for the initial distribution. These differences enable more precise localization
than iterative BBox, with no further human engineering.
As discussed in Section 3.1, ∆= (δx, δy, δw, δh) in (2)
needs to be normalized by its mean and variance for effective multi-task learning. After each regression stage, these
statistics will evolve sequentially, as displayed in Figure 2.
At training, the corresponding statistics are used to normalize ∆at each stage.
4.2. Cascaded Detection
As shown in the left of Figure 4, the distribution of the
initial hypotheses, e.g. RPN proposals, is heavily tilted towards low quality. This inevitably induces ineffective learning of higher quality classiﬁers. The Cascade R-CNN addresses the problem by relying on cascade regression as a
resampling mechanism. This is is motivated by the fact that
in Figure 1 (c) all curves are above the diagonal gray line,
i.e. a bounding box regressor trained for a certain u tends
to produce bounding boxes of higher IoU. Hence, starting
from a set of examples (xi, bi), cascade regression successively resamples an example distribution (x′
i) of higher
IoU. In this manner, it is possible to keep the set of positive examples of the successive stages at a roughly constant
size, even when the detector quality (IoU threshold) is increased. This is illustrated in Figure 4, where the distribution tilts more heavily towards high quality examples after
each resampling step. Two consequences ensue. First, there
is no overﬁtting, since examples are plentiful at all levels.
Second, the detectors of the deeper stages are optimized for
higher IoU thresholds. Note that, some outliers are sequentially removed by increasing IoU thresholds, as illustrated
in Figure 2, enabling a better trained sequence of specialized detectors.
At each stage t, the R-CNN includes a classiﬁer ht and
a regressor ft optimized for IoU threshold ut, where ut >
ut−1. This is guaranteed by minimizing the loss
L(xt, g) = Lcls(ht(xt), yt) + λ[yt ≥1]Lloc(ft(xt, bt), g),
where bt = ft−1(xt−1, bt−1), g is the ground truth object
for xt, λ = 1 the trade-off coefﬁcient, [·] the indicator function, and yt is the label of xt given ut by (5). Unlike the
integral loss of (6), this guarantees a sequence of effectively
trained detectors of increasing quality. At inference, the
quality of the hypotheses is sequentially improved, by applications of the same cascade procedure, and higher quality detectors are only required to operate on higher quality
hypotheses. This enables high quality object detection, as
suggested by Figure 1 (c) and (d).
5. Experimental Results
The Cascade R-CNN was evaluated on MS-COCO 2017
 , which contains ∼118k images for training, 5k for validation (val) and ∼20k for testing without provided annotations (test-dev). The COCO-style Average Precision
(AP) averages AP across IoU thresholds from 0.5 to 0.95
with an interval of 0.05. These evaluation metrics measure
the detection performance of various qualities. All models
were trained on COCO training set, and evaluated on val
set. Final results were also reported on test-dev set.
5.1. Implementation Details
All regressors are class agnostic for simplicity. All cascade detection stages in Cascade R-CNN have the same architecture, which is the head of the baseline detection network. In total, Cascade R-CNN have four stages, one RPN
and three for detection with U = {0.5, 0.6, 0.7}, unless otherwise noted. The sampling of the ﬁrst detection stage follows . In the following stages, resampling is implemented by simply using the regressed outputs from the previous stage, as in Section 4.2. No data augmentation was
used except standard horizontal image ﬂipping. Inference
was performed on a single image scale, with no further bells
and whistles. All baseline detectors were reimplemented
with Caffe , on the same codebase for fair comparison.
Baseline Networks
To test the versatility of the Cascade R-CNN, experiments were performed with three popular baseline detectors: Faster-RCNN with backbone VGG-Net , R-FCN
 and FPN with ResNet backbone . These baselines have a wide range of detection performances. Unless
noted, their default settings were used. End-to-end training
was used instead of multi-step training.
IoU Threshold
Detection Performance
u=0.5 (AP=0.349)
u=0.6 (AP=0.354)
u=0.7 (AP=0.319)
u=0.6 (AP=0.367)
u=0.7 (AP=0.352)
IoU Threshold
Detection Performance
u=0.5 (AP=0.394)
u=0.6 (AP=0.457)
u=0.7 (AP=0.495)
Figure 5. (a) is detection performance of individually trained detectors, with their own proposals (solid curves) or Cascade R-CNN
stage proposals (dashed curves), and (b) is by adding ground truth
to the proposal set.
IoU Threshold
u=0.5 (AP=0.355)
u=0.6 (AP=0.352)
u=0.7 (AP=0.256)
IoU Threshold
u=0.5 (AP=0.365)
u=0.6 (AP=0.383)
u=0.7 (AP=0.355)
IoU Threshold
u=0.5 (AP=0.368)
u=0.6 (AP=0.384)
u=0.7 (AP=0.383)
Figure 6. The detection performance of all Cascade R-CNN detectors at all cascade stages.
Faster-RCNN: The network head has two fully connected
layers. To reduce parameters, we used to prune less
important connections. 2048 units were retained per fully
connected layer and dropout layers were removed. Training started with a learning rate of 0.002, reduced by a factor
of 10 at 60k and 90k iterations, and stopped at 100k iterations, on 2 synchronized GPUs, each holding 4 images per
iteration. 128 RoIs were used per image.
R-FCN: R-FCN adds a convolutional, a bounding box regression, and a classiﬁcation layer to the ResNet. All heads
of the Cascade R-CNN have this structure. Online hard
negative mining was not used. Training started with
a learning rate of 0.003, which was decreased by a factor of
10 at 160k and 240k iterations, and stopped at 280k iterations, on 4 synchronized GPUs, each holding one image per
iteration. 256 RoIs were used per image.
FPN: Since no source code is publicly available yet
for FPN, our implementation details could be different.
RoIAlign was used for a stronger baseline. This is
denoted as FPN+ and was used in all ablation studies. As
usual, ResNet-50 was used for ablation studies, and ResNet-
101 for ﬁnal detection. Training used a learning rate of
0.005 for 120k iterations and 0.0005 for the next 60k iterations, on 8 synchronized GPUs, each holding one image
per iteration. 256 RoIs were used per image.
5.2. Quality Mismatch
Figure 5 (a) shows the AP curves of three individually trained detectors of increasing IoU thresholds of U =
Output IoU
Localization Performance
iterative 1st
iterative 3rd
cascade 1st
cascade 3rd
IoU Threshold
Integral Loss
u=0.5 (AP=0.354)
u=0.6 (AP=0.355)
u=0.7 (AP=0.337)
ensemble (AP=0.354)
Figure 7. (a) is the localization comparison, and (b) is the detection
performance of individual classiﬁers in the integral loss detector.
{0.5, 0.6, 0.7}. The detector of u = 0.5 outperforms the detector of u = 0.6 at low IoU levels, but underperforms it at
higher levels. However, the detector of u = 0.7 underperforms the other two. To understand why this happens, we
changed the quality of the proposals at inference. Figure
5 (b) shows the results obtained when ground truth bounding boxes were added to the set of proposals. While all
detectors improve, the detector of u = 0.7 has the largest
gains, achieving the best performance at almost all IoU levels. These results suggest two conclusions. First, u = 0.5
is not a good choice for precise detection, simply more robust to low quality proposals. Second, highly precise detection requires hypotheses that match the detector quality.
Next, the original detector proposals were replaced by the
Cascade R-CNN proposals of higher quality (u = 0.6 and
u = 0.7 used the 2nd and 3rd stage proposals, respectively).
Figure 5 (a) also suggests that the performance of the two
detectors is signiﬁcantly improved when the testing proposals closer match the detector quality.
Testing all Cascade R-CNN detectors at all cascade
stages produced similar observations. Figure 6 shows that
each detector was improved when used more precise hypotheses, while higher quality detector had larger gain. For
example, the detector of u = 0.7 performed poorly for the
low quality proposals of the 1st stage, but much better for
the more precise hypotheses available at the deeper cascade
stages. In addition, the jointly trained detectors of Figure
6 outperformed the individually trained detectors of Figure
5 (a), even when the same proposals were used. This indicates that the detectors are better trained within the Cascade
R-CNN framework.
5.3. Comparison with Iterative BBox and Integral Loss
In this section, we compare the Cascade R-CNN to iterative BBox and the integral loss detector. Iterative BBox
was implemented by applying the FPN+ baseline iteratively,
three times. The integral loss detector has the same number of classiﬁcation heads as the Cascade R-CNN, with
U = {0.5, 0.6, 0.7}.
FPN+ baseline
Iterative BBox
Integral Loss
Cascade R-CNN
Table 1. The comparison with iterative BBox and integral loss.
test stage
FPN+ baseline
Table 2. The stage performance of Cascade R-CNN. 1 ∼3 indicates the ensemble of three classiﬁers on the 3rd stage proposals.
Localization: The localization performances of cascade
regression and iterative BBox are compared in Figure 7 (a).
The use of a single regressor degrades localization for hypotheses of high IoU. This effect accumulates when the regressor is applied iteratively, as in iterative BBox, and performance actually drops. Note the very poor performance
of iterative BBox after 3 iterations. On the contrary, the cascade regressor has better performance at later stages, outperforming iterative BBox at almost all IoU levels.
Integral Loss: The detection performances of all classi-
ﬁers in the integral loss detector, sharing a single regressor,
are shown in Figure 7 (b). The classiﬁer of u = 0.6 is the
best at all IoU levels, while the classiﬁer of u = 0.7 is the
worst. The ensemble of all classiﬁers shows no visible gain.
Table 1 shows, both iterative BBox and integral loss detector improve the baseline detector marginally. The cascade R-CNN has the best performance for all evaluation
metrics. The gains are mild for low IoU thresholds but signiﬁcant for the higher ones.
5.4. Ablation Experiments
Ablation experiments were also performed.
Stage-wise Comparison: Table 2 summarizes stage performance. The 1st stage already outperforms the baseline
detector, due to the beneﬁts of multi-stage multi-task learning. The 2nd stage improves performance substantially, and
the 3rd is equivalent to the 2nd. This differs from the integral loss detector, where the higher IOU classiﬁer is relatively weak. While the former (later) stage is better at low
(high) IoU metrics, the ensemble of all classiﬁers is the best
IoU Thresholds: A preliminary Cascade R-CNN was
trained using the same IoU threshold u = 0.5 for all heads.
In this case, the stages differ only in the hypotheses they
Table 3. The ablation experiments. “IoU↑” means increasing IoU
thresholds, and “stat” exploiting sequential regression statistics.
# stages test stage
Table 4. The impact of the number of stages in Cascade R-CNN.
receive. Each stage is trained with the corresponding hypotheses, i.e. accounting for the distributions of Figure 2.
The ﬁrst row of Table 3 shows that the cascade improves on
the baseline detector. This suggests the importance of optimizing stages for the corresponding sample distributions.
The second row shows that, by increasing the stage threshold u, the detector can be made more selective against close
false positives and specialized for more precise hypotheses,
leading to additional gains. This supports the conclusions
of Section 4.2.
Regression Statistics: Exploiting the progressively updated regression statistics, of Figure 2, helps the effective
multi-task learning of classiﬁcation and regression. Its beneﬁt is noted by comparing the models with/without it in Table 3. The learning is not sensitive to these statistics.
Number of Stages: The impact of the number of stages is
summarized in Table 4. Adding a second detection stage
signiﬁcantly improves the baseline detector. Three detection stages still produce non-trivial improvement, but the
addition of a 4th stage (u = 0.75) led to a slight performance decrease. Note, however, that while the overall AP
performance degrades, the four-stage cascade has the best
performance for high IoU levels. The three-stage cascade
achieves the best trade-off.
5.5. Comparison with the state-of-the-art
The Cascade R-CNN, based on FPN+ and ResNet-101
backbone, is compared to state-of-the-art single-model object detectors in Table 5. The settings are as described in
Section 5.1.1, but a total of 280k training iterations were
run and the learning rate dropped at 160k and 240k iterations. The number of RoIs was also increased to 512. The
ﬁrst group of detectors on Table 5 are one-stage detectors,
the second group two-stage, and the last group multi-stage
(3-stages+RPN for the Cascade R-CNN). All the compared
state-of-the-art detectors were trained with u = 0.5. It is
YOLOv2 
DarkNet-19
SSD513 
ResNet-101
RetinaNet 
ResNet-101
Faster R-CNN+++ *
ResNet-101
Faster R-CNN w FPN 
ResNet-101
Faster R-CNN w FPN+ (ours)
ResNet-101
Faster R-CNN by G-RMI 
Inception-ResNet-v2
Deformable R-FCN *
Aligned-Inception-ResNet
Mask R-CNN 
ResNet-101
AttractioNet *
VGG16+Wide ResNet
Cascade R-CNN
ResNet-101
Table 5. Comparison with the state-of-the-art single-model detectors on COCO test-dev. The entries denoted by “*” used bells and
whistles at inference.
cascade train
test-dev (20k)
speed speed
AP50 AP75 APS APM APL
AP50 AP75 APS APM APL
Faster R-CNN
0.12s 0.075s 278M
0.14s 0.115s 704M
0.24s 0.075s 184M
ResNet-101
0.23s 0.075s 206M
0.29s 0.083s 256M
0.30s 0.095s 165M
0.33s 0.115s 272M
ResNet-101
0.38s 0.115s 238M
Table 6. Detailed comparison on multiple popular baseline object detectors. All speeds are reported per image on a single Titan Xp GPU.
noted that our FPN+ implementation is better than the original FPN , providing a very strong baseline. In addition,
the extension from FPN+ to Cascade R-CNN improved performance by ∼4 points. The Cascade R-CNN also outperformed all single-model detectors by a large margin, under all evaluation metrics. This includes the single-model
entries of the COCO challenge winners in 2015 and 2016
(Faster R-CNN+++ , and G-RMI ), and the very
recent Deformable R-FCN , RetinaNet and Mask
R-CNN . The best multi-stage detector on COCO, AttractioNet , used iterative BBox for proposal generation. Although many enhancements were used in AttractioNet, the vanilla Cascade R-CNN still outperforms it by
7.1 points. Note that, unlike Mask R-CNN, no segmentation information is exploited in the Cascade R-CNN. Finally, the vanilla single-model Cascade R-CNN also surpasses the heavily engineered ensemble detectors that won
the COCO challenge in 2015 and 2016 (AP 37.4 and 41.6,
respectively)1.
5.6. Generalization Capacity
Three-stage Cascade R-CNN of all three baseline detectors are compared in Table 6. All settings are as above, with
the changes of Section 5.5 for FPN+.
1 
Detection Performance: Again, our implementations are
better than the original detectors . Still, the Cascade R-CNN improves on these baselines consistently by
2∼4 points, independently of their strength. These gains
are also consistent on val and test-dev. These results
suggest that the Cascade R-CNN is widely applicable across
detector architectures.
Parameter and Timing: The number of the Cascade R-
CNN parameters increases with the number of cascade
stages. The increase is linear in the parameter number of
the baseline detector heads. In addition, because the computational cost of a detection head is usually small when
compared to the RPN, the computational overhead of the
Cascade R-CNN is small, at both training and testing.
6. Conclusion
In this paper, we proposed a multi-stage object detection framework, the Cascade R-CNN, for the design of high
quality object detectors. This architecture was shown to
avoid the problems of overﬁtting at training and quality
mismatch at inference. The solid and consistent detection
improvements of the Cascade R-CNN on the challenging
COCO dataset suggest the modeling and understanding of
various concurring factors are required to advance object
detection. The Cascade R-CNN was shown to be applicable to many object detection architectures. We believe that
it can be useful to many future object detection research efforts.
Acknowledgment We would like to thank Kaiming He for
valuable discussions.