Transfer Entropy as a Log-likelihood Ratio
Lionel Barnett∗
Sackler Centre for Consciousness Science
School of Informatics
University of Sussex
Brighton BN1 9QJ, UK
Terry Bossomaier†
Centre for Research in Complex Systems
Charles Sturt University
Panorama Ave, Bathurst NSW 2795, Australia
November 27, 2024
Transfer entropy, an information-theoretic measure of time-directed information transfer between joint processes, has steadily gained popularity in the analysis of complex
stochastic dynamics in diverse ﬁelds, including the neurosciences, ecology, climatology
and econometrics. We show that for a broad class of predictive models, the log-likelihood
ratio test statistic for the null hypothesis of zero transfer entropy is a consistent estimator
for the transfer entropy itself. For ﬁnite Markov chains, furthermore, no explicit model is
required. In the general case, an asymptotic χ2 distribution is established for the transfer
entropy estimator. The result generalises the equivalence in the Gaussian case of transfer
entropy and Granger causality, a statistical notion of causal inﬂuence based on prediction via vector autoregression, and establishes a fundamental connection between directed
information transfer and causality in the Wiener-Granger sense.
Transfer entropy (TE) was formulated by Schreiber as a non-parametric measure of
directed (time-asymmetric) information transfer between joint processes. It has since rapidly
gained popularity, particularly in neuroscience , as a tool for data-driven
detection of functional coupling between joint processes. In it was shown that for Gaussian
vector autoregressive (VAR) processes, transfer entropy is equivalent to Granger causality
 . Noting that the Granger causality statistic may be formalised as a log-likelihood
ratio, this Letter extends the result in (see also ) to a very general class of continuous
or discrete Markov models in a maximum likelihood framework. In the case of a ﬁnite state
space, moreover, no explicit model is required since the result applies to the conventional
plug-in estimator for TE.
The result is of particular signiﬁcance since estimation of TE in sample—particularly
for continuous systems—is notoriously awkward ; furthermore, little has been
∗ 
† 
 
known previously about its sampling properties. The likelihood formulation presented here
provides a convenient route to estimation and statistical inference of TE in a broad parametric
context, and on a conceptual level pinpoints the relationship between information-theoretic
directed information transfer in the Schreiber sense and predictive, model-based causality in
the Wiener-Granger sense.
Firstly we introduce some notation 1: for a time-indexed sequence x = (xt), t = 1, 2, . . .
we write xt = (x1, x2, . . . , xt) for the subsequence up to time t, and xk
t = (xt−k, . . . , xt−1) for
the k-lag history of the sequence up to time t −1. Suppose now that (X, Y ) = (Xt, Yt) are
jointly stationary stochastic processes taking values in the state space SX × SY . (Later we
shall also require an ergodicity condition on the joint process.) We then have the following
expressions for the entropy of Xt conditional on the joint (k-lag) history of X and Y , and on
the history of X only:
log p(Xt|Xk
log p(Xt|Xk
(assuming that the expectations are < ∞) where p(xt|xk
t ), p(xt|xk
t ) are respectively the
marginal probability density functions (pdfs) of Xt conditioned on the history of X and Y ,
and on the history of X only. By stationarity, these densities do not depend on t. The (k-lag)
transfer entropy from Y →X is then deﬁned by:
which may be read as “the degree to which the history of Y disambiguates current X beyond
the degree to which X is already disambiguated by its own history”.
Suppose now given a parametrised Markov (predictive) model for Xt in terms of the
history of X and Y :
p(xt|xt−1, yt−1; θ) = f(xt|xk
where θ = (θ1, . . . , θm) is a vector of parameters in a (Euclidean) parameter space Θ, f(·|·, ·; θ)
is a conditional probability density function from SX×Sk
Y → and p(xt|xt−1, yt−1; θ)
is the marginal pdf of Xt conditioned on the entire history of X and Y under the model
assumption with parameter vector θ. Eq. (3) describes a “partial” model, insofar as only the
marginal conditional distribution of X is speciﬁed. We assume that the model is identiﬁable
and well-speciﬁed: that is, θ1 ̸= θ2 =⇒f(·|·, ·; θ1) ̸= f(·|·, ·; θ2), and there is a unique true
parameter vector θ∗satisfying
p(xt|xt−1, yt−1) = f(xt|xk
t ; θ∗) = p(xt|xk
We do not demand that the joint process (X, Y ) satisfy a Markov property analogous to (4).
To apply likelihood methods we require a “full” rather than a partial, model 2. However,
we are not really interested in modelling Y , but just in how its history “drives” X.
a mathematical device, then, we extend the partial model (somewhat arbitrarily) to a full
model, for which the marginal distribution of Xt conditional on joint history agrees with (3).
1In what follows upper case symbols denote random variables and bold typeface indicates vector quantities.
2An alternative approach would be to regard the yt as nuisance parameters; however, we believe this
complicates the analysis.
Let q(y) be the marginal (unconditional) pdf of Yt. We deﬁne the extended model (again
parametrised by θ ∈Θ) by 3
p(xt, yt|xt−1, yt−1; θ) = f(xt|xk
t ; θ)q(yt) ,
where p(xt, yt|xt−1, yt−1; θ) is the conditional joint pdf of Xt, Yt on their joint history under
the model assumption with parameter vector θ. Eq. (5) may be interpreted as “the Yt are
independent of Xt conditioned on joint history”.
Note that in fact this condition will in
general not actually hold for the joint process (X, Y ); i.e. in general there will be no θ ∈Θ
such that p(xt, yt|xt−1, yt−1) = f(xt|xk
t ; θ)q(yt) [cf. (4)]. In other words, the model (5)
will generally be misspeciﬁed. As we shall see, however, this is not problematic.
Misspeciﬁed or not, there is nothing preventing calculation of likelihoods for the extended
model (5). Suppose given a realisation (xn, yn) of length n sampled from the joint process
(X, Y ). The likelihood of θ given this realisation is deﬁned as
L(θ|xn, yn) ≡p(xn, yn; θ) ,
i.e. the pdf of the joint history (Xn, Y n) under the model assumption with parameter vector
θ, and the average log-likelihood estimator is deﬁned to be
ˆℓ(θ|xn, yn) ≡
n −k log L(θ|xn, yn)
(the factor of n −k is due to the eﬀective loss of k samples due to lags). We have by Bayes’
L(θ|xn, yn) = p(xn, yn|xn−1, yn−1; θ)p(xn−1, yn−1; θ)
n; θ)q(yn) L(θ|xn−1, yn−1)
from (3), leading to
L(θ|xn, yn) = p(xk, yk)
t ; θ)q(yt)]
where p(xk, yk), the initial joint distribution, is assumed given independently of θ. Noting
that the q(yt) do not reference the parameter vector θ, we see that up to an additive factor
not depending on θ—which does not aﬀect calculation of either maximum likelihood (ML)
estimates or likelihood ratios—and assuming q(y) ̸= 0 almost everywhere (which in fact
follows from the ergodic assumption introduced below), the average log-likelihood estimator
ˆℓ(θ|xn, yn) =
log f(xt|xk
In practice this expression may be used to estimate an appropriate model order (i.e. number of
lags k) via standard likelihood-based techniques such as the Akaike or Bayesian Information
Criteria .
3In fact, as regards the subsequent argument, the marginal Yt pdf q(y) in (5) could be replaced by an
arbitrary pdf ˜q(y) with ˜q(y) ̸= 0 almost everywhere.
We now make the following ergodic assumption:
The process U is ergodic, where Ut ≡(Xt−k, . . . , Xt, Yt−k, . . . , Yt−1) .
The Birkhoﬀ-Khinchin ergodic theorem then applies, so that 4
ˆℓ(θ|Xn, Y n)
log f(Xt|Xk
as n →∞, again assuming that the expectation exists (at least for almost all θ). In particular,
for the true parameter θ∗it follows from (4) and the deﬁnition (1) that
Proposition 1.
ˆℓ(θ∗|Xn, Y n)
Proposition 1 encapsulates the relationship between average log-likelihood and conditional
entropy for a Markov model, which is key to our main result. Now by Gibbs’ Inequality, we
 log f(Xt|Xk
 log p(Xt|Xk
for all θ, with equality iﬀf(·|·, ·; θ) =
p(·|·, ·) almost everywhere. By uniqueness of θ∗, θ = θ∗maximises ˆℓ(θ|xn, yn) almost surely
in the limit n →∞and we have
Proposition 2.
ˆθ(Xn, Y n)
as n →∞, where ˆθ(Xn, Y n) is the ML estimator for the extended model (5).
Thus, notwithstanding that the extended model may be misspeciﬁed, its ML estimator
ˆθ(Xn, Y n) is nonetheless a consistent estimator for the true value θ∗of the parameter vector
for the partial model (3). In particular, Proposition 1 holds with θ∗replaced by ˆθ(Xn, Y n).
We now deﬁne a nested null model, with the object of testing the null hypothesis that
the TE (2) is zero. Assuming the partial model (3) with parameter vector θ, it is clear that
T Y →X = 0 iﬀf(xt|xk
t ; θ) does not depend on yk
t . Accordingly, we deﬁne the null set
Θ0 ≡{θ ∈Θ | f(xt|xk
t ; θ) does not depend on yk
We assume that Θ0 ̸= ∅. Given a realisation (xn, yn) of the joint process (X, Y ), the likelihood
ratio test statistic for the null hypothesis H0 : θ ∈Θ0 is
Λ(xn, yn) ≡L(ˆθ0|xn, yn)
L(ˆθ |xn, yn)
where ˆθ and ˆθ0 are ML estimators for θ over the full parameter set Θ and the null subset Θ0
respectively. The following Theorem justiﬁes deﬁning the model TE estimator
bT Y →X (xn, yn) ≡−
n −k log Λ(xn, yn) .
Theorem 1.
−−→denotes almost sure convergence.
(a) bT Y →X (Xn, Y n)
−−→T Y →X as n →∞.
(b) If T Y →X = 0, then 2(n −k) bT Y →X (Xn, Y n) has an asymptotic χ2(d) distribution,
where the number of degrees of freedom d is the diﬀerence between the number of parameters in the full and null models.
If T Y →X > 0, the asymptotic distribution is
non-central χ2(d; λ) with non-centrality parameter λ = 2(n −k) T Y →X.
Theorem 1a follows immediately from Propositions 1,2 and deﬁnitions (2) and (7); the estimator (16) is thus consistent, although it will generally be biased. Theorem 1b follows from
the standard large-sample theory (but note that convergence to the non-central χ2 will
generally be slower than in the null case). It enables signiﬁcance testing of the null hypothesis of zero TE, and the construction of conﬁdence intervals for the estimator if the sample is
suﬃciently large.
We note the ergodicity condition (10) restricts the class of models for which our analysis
applies, although the restriction may not be that stringent. For example, for a (possibly
nonlinear) VAR process of the form Xt = g(Xk
t ) + εt with iid residuals εt, the joint process
(Xt−ℓ, . . . , Xt) will be ergodic for any lag ℓif (roughly) for any region R ⊂SX, P(εt ∈R) =
R has measure zero . (This will be the case, for instance, if the residuals are
nondegenerate multivariate Gaussian.) A discrete-valued Markov processes is ergodic if every
state is aperiodic and positive recurrent .
For a linear VAR partial model of the form Xt = Pk
i=1 AiXt−i +Pk
i=1 BiYt−i +εt with iid
multivariate Gaussian residuals εt with covariance matrix Σ and regression coeﬃcient matrices
Ai, Bi, the ergodicity condition is met provided the generalised variance |Σ| is > 0. The
parameter vector is θ = (Ai, Bi, Σ) and the null set Θ0 is given by B1 = . . . = Bk = 0.
The ML is (up to a factor) |bΣ|−(n−k)/2 where bΣ is the ML estimator for Σ, which we note is
asymptotically equivalent to the conventional OLS estimator . The TE estimator (16) is
then just half the Granger causality from Y to X , and we recover the result of .
Given a third process Z jointly distributed with (X, Y ), the eﬀect of Z on the information
ﬂow Y →X may be “conditioned out” by deﬁning the conditional transfer entropy 
T Y →X|Z ≡H
It may be veriﬁed that Theorem 1 extends to the conditional case for partial Markov models
of the form
p(xt|xt−1, yt−1, zt−1; θ) = f(xt|xk
t , zt−1; θ) .
In the discrete case, the various densities p(· · · ) are actual probabilities. We may calculate
from (9) [for notational compactness we suppress explicit dependence on a realisation (xn, yn)]
t ) log f(ξt|ξk
are plug-in estimates for the densities p(xt, xk
t ) (by the ergodic assumption they are are
consistent). Eq. (19) then furnishes a direct route to calculation of the maximum-likelihood
estimator ˆθ and thence the TE estimator (16).
In the absence of an explicit model, the conventional non-parametric estimator for TE in
the discrete case is the plug-in estimator
bT p Y →X ≡−
t ) log ˆp(ξt|ξk
t ) log ˆp(ξt|ξk
(with the obvious notation). Now in the case of a ﬁnite state space, we can consider the
transition probabilities p(ξt|ξk
t ) themselves as model parameters; i.e. the θ in a partial
Markov model (3).
Then it is clear that the ˆp(ξt|ξk
t ) will be ML estimators, and the
plug-in estimator (21) is just the model estimator (16). If the cardinalities of the state spaces
SX, SY are a, b respectively, then there are (a−1)akbk independent parameters for the non-null
model and (a −1)ak for the null model. Theorem 1b then states that the plug-in estimator
has an asymptotic χ2 distribution with (a −1)ak(bk −1) degrees of freedom. Note that this
scales polynomially with state space size and exponentially with model order.
This is illustrated in the following example of a stationary, bivariate ﬁrst-order Markov
chain on the binary state space {0, 1} × {0, 1}. Although manifestly a toy model, we present
this example partly for its close resemblance to a canonical minimal model analysed in ,
but mostly as it illustrates nicely the asymptotic convergence of the TE estimator to the
theoretical χ2 distribution. For t = 1, 2, . . ., εt and ηt are iid B(1
2) random variables 5 and
ut, vt are iid B(θ), B(ϕ) respectively. We then deﬁne
Xt = utYt−1 + (1 −ut)εt
Yt = vtXt−1 + (1 −vt)ηt .
It is clear that the ergodic requirement is satisﬁed provided θ < 1 and ϕ < 1. We may
p(xt, yt|xt−1, yt−1) = p(xt|xt−1, yt−1)q(yt|xt−1, yt−1)
where the conditional marginals are
p(xt|xt−1, yt−1) = θδ(xt, yt−1) + 1
q(yt|xt−1, yt−1) = ϕδ(yt, xt−1) + 1
Note that in this case the extended model (5) is indeed misspeciﬁed, since from (22) it can
be seen that Yt is not independent of Xt conditioned on joint history; the joint conditional
pdf (23) does not factor according to (5).
By the x ↔y,θ ↔ϕ symmetry, it follows that the stationary joint density is uniform
p(x, y) = 1
4 for all x, y, and we may calculate
T Y →X = 1
2(1 + θ) log(1 + θ) + 1
2(1 −θ) log(1 −θ) .
By Theorem 1 the TE plug-in estimator (21) in this case has an asymptotic χ2(2) distribution under the null hypothesis of zero TE, and a non-central χ2(2) distribution under the
alternative hypothesis. FIG. 1 plots empirical vs. theoretical χ2(2) cumulative distributions
(cdfs) of bT p Y →X for a null model (θ = 0, FIG. 1A) and a non-null model (θ = 0.4, FIG. 1B),
estimated from 105 realisations each of a selection of sequence lengths. The ϕ parameter was
set to 0.6. We see that the null distribution converges more quickly to its χ2(2) asymptote
5B(p) denotes a Bernoulli trial taking the value 1 with probability p.
Figure 1: Cumulative distribution functions (cdfs) for the plug-in TE estimator (21) and
corresponding scaled χ2(2) theoretical asymptotic distributions (bold lines), for A a null model
(θ = 0) and B a non-null model (θ = 0.4) for the binary Markov process (22) at a series of sequence
lengths n. The vertical arrow marks the actual TE value T Y →X ≈0.0823.
than the non-null distribution.
With regard to application of the ﬁnite-state plug-in estimator result, we note that it is
not uncommon to discretise continuous time series data for causal analysis, sometimes after
a diﬀerencing step. A more sophisticated discretisation approach is the recently introduced
symbolic transfer entropy , currently gaining in popularity as a technique for inference of
time-directed information ﬂow applicable to systems of continuous variables.
A recognised problem with transfer entropy estimation in the non-parametric case is the
so-called “curse of dimensionality” , in particular with regard to scaling of degrees of freedom with number of lags. Thus for continuous processes, naive coarse-graining and binning
of data points is likely to be extremely ineﬃcient in practice, yielding large estimation errors;
worse, estimators derived in this fashion may not even converge monotonically to the correct
value . There are several approaches to mitigation of this problem, including adaptive partitioning, kernel density methods and k-nearest neighbour statistics . An interesting
avenue of research is whether any of these methods might be framed in a parametric context
for which our result applies, thus yielding a useful χ2 sampling distribution. Another promising approach is proposed in , where transfer entropy is decomposed into contributions
of individual lags and then conditional dependencies reduced using methods from graphical
model theory . Again, it would be of interest to investigate whether a similar dimensional
reduction could be achieved within a model-based ML framework.
In a parametric context, it might be argued that dimensionality is a lesser curse: prior
to parametric TE estimation an empirical model order should be selected in accordance with
the size of the available sample, most conveniently, as noted previously, via the average loglikelihood estimator (9). In practice this will limit the dimensionality of the parameter space
and will frequently yield tractable model orders, resulting in acceptably eﬃcient estimators.
Thus for example, Granger causality has been eﬀectively applied (especially in the neurosciences) for highly multivariate data. For discrete systems, and in particularly for symbolic
transfer entropy, it seems not unreasonable to expect similar, although further research is
The special case of Granger causality suggests a useful range of applications for Theo-
rem 1. Linear VAR modelling seems sometimes to be taken as a convenient “one size ﬁts all”
approach, insofar as (almost) any wide-sense stationary process may be modelled as a linear
VAR, albeit of potentially high model order . However, this is certainly not to say that
a linear VAR model will necessarily be a good model for given time series data. In particular,
high empirical model orders (as indicated by model selection criteria) may well be indicative
of failure of a model to reﬂect parsimoniously the statistical structure of the data. Physical
considerations or supplementary analysis may suggest alternative models. Thus for example
a nonlinear VAR approach might be suspected on physical grounds, heteroscedasticity
may suggest a GARCH model or long-term memory a fractional ARIMA model .
Now it may be far from clear how one should deﬁne a Granger-like predictive statistic for
such models. Theorem 1, and its implied equivalence (at least in the Gaussian case) with
transer entropy, suggests that the principled generalisation of Granger causality is just the
model transfer entropy, operationalised as a log-likelihood ratio - and in addition furnishes
an asymptotic sampling distribution.
In summary, our result uniﬁes the established machinery of maximum likelihood and
the concomitant large-sample theory with the information-theoretic notion of directed information transfer.
Given a—perhaps physically motivated—parametric model (or, if the
state space is discrete, an implicit Markov chain model) it thereby facilitates estimation and
statistical inference of transfer entropy. In particular it furnishes generic asymptotic χ2 distributions for signiﬁcance testing and estimation of conﬁdence intervals, obviating the need
for surrogate/subsampling methods.
Finally, current research by the authors suggests an extension of the result to point processes, with application to inference of information ﬂow in spiking neural systems .
Author Barnett’s work has been supported by the Dr. Mortimer and Theresa Sackler
Foundation via the Sackler Centre for Consciousness Science, and a visiting fellowship at the
Centre for Research in Complex Systems.