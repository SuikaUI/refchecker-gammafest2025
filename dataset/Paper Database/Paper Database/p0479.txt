Adapting SVM Classiﬁers to Data with Shifted Distributions
School of Computer Science
Carnegie Mellon University
Pittsburgh, PA 10523
 
IBM T.J.Watson Research Center
19 Skyline Drive
Hawthorne, NY 10532
 
Alexander G. Hauptmann
School of Computer Science
Carnegie Mellon University
Pittsburgh, PA 10523
 
Many data mining applications can beneﬁt from adapting existing classiﬁers to new data with shifted distributions. In this paper, we present Adaptive Support Vector
Machine (Adapt-SVM) as an efﬁcient model for adapting a
SVM classiﬁer trained from one dataset to a new dataset
where only limited labeled examples are available. By introducing a new regularizer into SVM’s objective function,
Adapt-SVM aims to minimize both the classiﬁcation error
over the training examples, and the discrepancy between the
adapted and original classiﬁer. We also propose a selective
sampling strategy based on the loss minimization principle
to seed the most informative examples for classiﬁer adaptation. Experiments on an artiﬁcial classiﬁcation task and
on a benchmark video classiﬁcation task shows that Adapt-
SVM outperforms several baseline methods in terms of accuracy and/or efﬁciency.
Introduction
Many real-world applications face a common problem
that the data distribution associated with a speciﬁc topic or
category is likely to shift, especially in streaming data generated over a long period of time or heterogenous data gathered from multiple sources. This creates a fundamental dif-
ﬁculty for learning methods such as supervised classiﬁers
that assume the training and testing data are drawn from the
same distribution. This problem has been frequently seen in
data mining (as concept drift), adaptive ﬁltering (as users’
changing preferences), and text/multimedia document classiﬁcation (as large in-class variances). Applications in these
areas can largely beneﬁt from an efﬁcient method for adapting existing classiﬁers to a new set of data with a different
distribution.
We formulate this general problem into the following
scenario. Consider a binary classiﬁcation task with respect
to a given topic in a primary dataset, where only a limited number of examples are labeled. Besides, there is a
fully-labeled auxiliary dataset, and an auxiliary classiﬁer
has been trained from it. The primary data is drawn from a
distribution that is related to, but different from, the distribution of the auxiliary data in a way unknown to the learner.
We call this kind of distribution as a shifted distribution.
To classify the primary data, the auxiliary classiﬁer may
not perform well since it is biased to the training distribution. On the other hand, a new classiﬁer trained only from
the limited examples in the primary data, although unbiased, may suffer from a high variance. To achieve a better bias-variance tradeoff, various methods have been proposed in the data mining and machine learning community to leverage the knowledge of the auxiliary (old) data
to build better classiﬁers for the primary (new) data. Two
main approaches are to construct an “ensemble” combining
the output of classiﬁers trained independently from the two
datasets , or to train an “aggregated” classiﬁer on the
labeled examples combined from both datasets . In
this paper, we seek a rather different approach that adapts
the auxiliary classiﬁer (more precisely, its decision function) to the primary data using its limited labeled examples
(which results in an adapted classiﬁer), with three goals:
Efﬁciency: Adapting an existing classiﬁer must be less expensive than training a classiﬁer on the labeled examples combined from the primary and auxiliary set.
Accuracy: On average, the adapted classiﬁer is expected
to outperform existing approaches based on ensemble
classiﬁers and aggregated classiﬁers.
Minimum human effort: Adapting a classiﬁer should require signiﬁcantly fewer labeled examples than what is
needed to train a new classiﬁer of the same accuracy.
We propose Adaptive Support Vector Machines (Adapt-
SVM) as an efﬁcient and principled method for adapting the
auxiliary classiﬁer to the primary data with a shifted distribution using its limited labeled examples. The key idea is
to modify the regularizer in the objective function of SVMs
so that both the classiﬁcation error over the training examples and the discrepancy between the adapted and the auxiliary classiﬁer are minimized. A fundamental difference
between this method and existing methods in drifting concept detection and transfer learning is that
it directly manipulates the auxiliary classiﬁer and involves
no auxiliary data in its training process. This makes it applicable to domains where old data are unaccessible, and also
more efﬁcient than models trained over old data. Moreover, based on the loss minimization principle, a selective
sampling strategy is proposed to identify the most useful
examples to help the adaptation of the auxiliary classiﬁer.
Experiments on a synthetic dataset and a benchmark video
classiﬁcation task show that our approach outperform other
methods in terms of accuracy and/or efﬁciency, and using
selective sampling offers further improvement.
Adaptive Support Vector Machines
We use D = {xi, yi}N
i=1 to denote a set of N labeled
instances in the primary dataset, where xi is the ith data
vector and yi ∈{−1, 1} is its binary label. In addition to
D, there is a large number of unlabeled data in the primary
dataset to be classiﬁed. Moreover, D′ = {x′
i=1 denotes a set of N ′ labeled instances in the auxiliary dataset.
The Linear Model
In standard linear SVM, the label of a data vector x is
determined by the sign of a linear decision function, i.e.,
ˆy = sgn(f(x)) = sgn(xT β), where β = {βi}M
the model parameters1. Training a linear SVM classiﬁer
involves the following optimization problem:
subject to
ξi ≥0, yixT
i β ≥1 −ξi ∀i
i ξi measures the total classiﬁcation error, and
∥β∥2 is a regularization term that is inversely related to margin between training examples of two classes.
Adapt-SVM extends linear SVM to incorporate the
knowledge of the auxiliary data D′ through a modiﬁed regularization term. We assume the auxiliary classiﬁer trained
from D′ to be a linear SVM as f ′(x) = xT β′, where β′ can
be represented as β′ = N′
i according to the representer’s theorem. Since the distribution of D is relevant
to that of D′, it is reasonable to treat the auxiliary classiﬁer
f ′(x) as a “prior model” of the adapted classiﬁer f(x) to
1This linear function is equivalent to f(x) = xT β + b if we add a
constant term as an additional dimension of every data vector x.
be learned. This is achieved by modifying the regularizer to
penalize the discrepancy between the new parameters β and
the parameters β′ of the auxiliary classiﬁer. Speciﬁcally, we
replace ∥β′∥2 in Eq.(1) with a new regularizer ∥β −β′∥2:
2∥β −β′∥2 + C
subject to
ξi ≥0, yixT
i β ≥1 −ξi ∀i
This modiﬁed objective function seeks to reduce the distance between β and β′ while minimizing the classiﬁcation error.
Based on the triangular inequality, we have
∥β′∥+ ∥β −β′∥≥∥β∥. Because ∥β∥2 is inversely related
to the margin, and ∥β′∥is a constant, minimizing ∥β −β′∥2
is equivalent to maximizing the lower bound of the margin.
Therefore, Eq.(2) also ensures a decision boundary with a
large margin. The objective function in Eq.(2) can be rewritten as the following (primal) Lagrangian:
2∥β−β′∥2+C
i β−(1−ξi)}−
where αi ≥0, µi ≥0 are Lagrange multipliers. We minimize LP by setting its derivative with respect to β and ξ to
zero, which gives β = N
i=1 αiyixi + β′ and αi = C −µi
for every i. Substituting β and αi into Eq.(3), we get the
Lagrange dual objective function:
(1 −λi)αi −1
αiαjyiyjxT
where λi = yi
j = yif ′(xi). The model is
now parameterized by {αi}N
i=1, which can be estimated by
maximizing LD under the constraints 0 ≤αi ≤C. This is
a quadratic programming (QP) problem solved using Platt’s
sequential minimal optimization algorithm . Given the
solutions ˆα, the decision function of linear Adapt-SVM is:
f(x) = f ′(x) +
ˆαiyixT xi
The resulted classiﬁer can be seen as adapted from the auxiliary classiﬁer f ′(x) with additional support vectors from
the primary set as DSV = {(xi, yi) ∈D|αi > 0}.
A key difference between the dual form of SVM and
that of Adapt-SVM in Eq.(4) is that that latter contains the
extra term λ. A larger αi is preferred in order to maximize
LD if λi < 0, i.e., if the auxiliary classiﬁer f ′ misclassiﬁes xi because λi = yif ′(xi), and vice versa. This is
intuitive because αi is the weight of each support vector
xi ∈DSV in the adapted classiﬁer f(x) in Eq.(5). If the
auxiliary classiﬁer misclassiﬁes xi (or sgn(f ′(xi)) ̸= yi),
the output of the adapted classiﬁer f(xi) needs to be made
different from f ′(xi) such that it can classify xi correctly
(or sgn(f(xi)) = yi), which is realized by adding a support vector xi with a large weight αi.
The Kernel Model
To achieve non-linear decision boundaries, we project
each data vector x into a feature vector φ(x) in a space
of a higher or even inﬁnite dimension, and learn f(x) =
φ(x)T β in the projected feature space. Based on the “kernel trick”, we can replace xT
i xj in objective function Eq.(4)
by the kernel function K(xi, xj) = ⟨φ(xi), φ(xj)⟩in order
to learn f(x), even if the feature map φ(·) is unknown. The
dual form of kernel Adapt-SVM can be written as:
(1 −λi)αi −1
αiαjyiyjK(xi, xj)
which is maximized under constraint 0 ≤αi ≤C. The
decision function of kernel Adapt-SVM is f(x) = f ′(x) +
i=1 ˆαiyiK(x, xi).
Discussion
Learning cost. Given the dual form in Eq.(4) and (6),
Adapt-SVM does not introduce any extra variables or constraints into the optimization problem of SVM. The only
extra term is λi. Based on its deﬁnition, computing all the
λi involves computing xT
j (or K(xi, x′
j) in kernel model)
for any xi ∈D and xj ∈D′, so this is a one-time computational cost of N × N ′ evaluations of the dot product or
kernel function. Also, since λi = yif ′(xi), λi can be computed even when auxiliary data {x′
i} are unavailable.
Cost factor C. Since αi is the weight of each support
vector xi ∈D and 0 ≤αi ≤C, the cost factor C is an
upper bound on the contribution of xi to the adapted classi-
ﬁer f(x). Similarly, the cost factor of the auxiliary classiﬁer
C′ is the upper bound for every x′
i ∈D′. Thus, C and C′
controls the relative contribution of the auxiliary and primary data on a per instance basis. In general, we expect
C > C′ because the classiﬁer is intended for data drawn
from the same distribution as D. The appropriate ratio of
C/C′ should largely depend on the similarity between the
two distributions. If the distribution of D and D′ is similar,
a smaller C/C′ is preferred so that the model relies more
on the auxiliary classiﬁer, and vice versa.
Comparison with other models. The decision function
f(x) deﬁned by Eq.(5) has the same form as an ensemble classiﬁer: the ﬁrst term is the auxiliary classiﬁer f ′(x)
trained from D′, and the second term resembles a classiﬁer
learned from D. However, it is different from a genuine ensemble classiﬁer that combines two base classiﬁers trained
independently from D and D′ , because {αi} are estimated under the inﬂuence of f ′(x) and their values are
different from those estimated entirely from D. Moreover,
our model is also different from an “aggregated” SVM classiﬁer trained from D∪D′ , because the latter treats
both {αi} and {α′
i} as parameters, because we treat {α′
constants. With N ′ fewer parameters to estimate, our model
is more efﬁcient as N ′ is typically larger than N.
Selective Sampling for Adaptation
An question related to classiﬁer adaptation is to identify which examples in the primary set we should choose to
label in order to efﬁciently adapt existing classiﬁers. Intuitively, using informative samples would generate a better
classiﬁer than the one learned from random samples. While
sample selection strategy has been studied in active learning , the existing methods are mainly for building new
classiﬁers. Here, we are interested in ﬁnding samples that
provide complementary information to the auxiliary classi-
ﬁer and help its adaptation to the primary data in the most ef-
ﬁcient way. In this section, we propose a selective sampling
strategy for classiﬁer adaptation with a theoretical justiﬁcation based on the loss minimization principle.
Formally, let P be a pool of instances in the primary
dataset, and D be a set of instances sampled from P for
user labeling. Also, let P(y|x) be the conditional probability of an example x in P, and P(x) be its marginal
probability.
Given a margin-based classiﬁer f, such as
SVM, the estimated loss of x is written as L(yf(x)). Thus,
the expected risk of the decision function f is deﬁned as
R(f) = ExEy|x(L(yf(x)).
Suppose f D is the classiﬁer adapted from an existing
classiﬁer f ′ using examples in D. f D is equivalent to f ′
when D = ∅, and it gradually deviates from f ′ when more
examples are included in D. In this case, the optimal sample set is the one that can be used to minimize the expected
risk of the adapted classiﬁer f D, or equivalently, the one
that achieves the largest risk reduction from the auxiliary
classiﬁer f ′, i.e., Dopt = argmaxD(R(f ′) −R(f D)).
Given the difﬁculty of computing the expected risk over
the full distribution P(x), it is more feasible to measure this risk over the data in the pool P, i.e., R(f) =
x∈P Ey|x(L(yf(x)). Therefore, Dopt is given by:
Dopt = argmax
L(yf ′(x)) −L(yf D(x))
Theoretically, maximizing Eq.(7) leads to the optimal sample set. In practice, however, this is prohibitively expensive
because there are 2|P| possible choices for D and for each
choice f D needs to be re-trained to update the estimate of
the expected loss. To provide a tractable solution, we use
the risk reduction over the sample set D to approximate the
risk reduction over the whole collection P. Moreover, we
assume that the updated classiﬁer f D can always correctly
predict the labels of any x ∈D. Therefore, the risk of f D
D Ey|xL(yf D(x)) is so small that it can be dropped.
With these two assumptions, Eq.(7) can be reduced to
Dopt = argmax
Ey|xL(yf ′(x)).
Eq.(8) eliminates the computationally intensive step of retraining f D for every choice of D.
To further simplify,
we assume the samples are collected in a “greedy” manner.
That is, we repeatedly choose x using the following criterion and add it to the existing sample set, i.e., D = D∨{x}:
P(y|x)L(yf ′(x)).
Finally, we need to estimate the conditional probability
P(y|x). Although the classiﬁer outputs a conﬁdence score
f(x) indicating the relevance of each x, due to the limited training examples, it is unlikely a reliable estimate of
P(y|x) even after it is normalized to . We develop two
probability estimation models based on the hinge loss function of SVM, i.e., L(yf(x)) = max(0, 1 −yf(x)) .
Prior Model: We assume P(y|x) is unrelated to the prediction made by f ′; instead, we set it to the prior distribution
of y in the auxiliary data D′, i.e., P(y = ±1|x) ≈PD′(y =
±1), where PD′(y = ±1) is the ratio of positive (or negative) instances in D′. In this case, the sample selection
criterion in Eq.(9) is written as:
PD′(y = 1) max(0, 1 −f ′(x))
+PD′(y = −1) max(0, 1 + f ′(x))
This is related to the “Random Labels” model in which
dissociates p(y|x) with f(x) and set it uniformly.
model is more accurate when the two classes are unbalanced, typical in applications like concept or event detection.
Best Worst Model We approximate the expected loss
with the smallest loss among all the possible labels, which
implicitly assume that f ′ correctly predicts the label of x,
i.e., y = sgn(f ′(x)). Thus Eq.(9) can be written as:
y=−1,1 max(0, 1 −yf ′(x))
max[0, 1 −sgn(f ′(x))f ′(x)] = argmax
This model chooses the most ambiguous examples, which
are also the examples closest to the decision boundary of
f ′. This is similar to the uncertainty sampling strategy in
active learning .
(a) Auxiliary data DA
(b) Primary data DP
(c) Aux on DP (20.5% error)
(d) New on DP (16.7% error)
(e) Aggr on DP (16.8% error)
(f) Adapt on DP (15.0% error)
Figure 1. The decision boundary of various
classiﬁers on a synthetic primary dataset
Experiments
A Synthetic Dataset
To illustrate our model, we generate a synthetic auxiliary
set DA and a primary set DP , from different distributions in
a 2-d feature space. Each set has 100 positive and 500 negative data. The positive data in each set are generated from a
Gaussian mixture model with 3 components, and the negative data are sampled uniformly outside the area of the positive data. For DA, the 3 Gaussian components are centered
at (−0.4, 0.5), (0.5, 0.7), and (−0.1, −0.6), while for DP
their means shift to (−0.4, 0.3), (0.5, 0.3), and (0, −0.65).
Figure 1 (a) and (b) shows the distribution of DA and
DP , where small circles denote positive instances and dots
denote negative instances. We assume all the instances in
DA are labeled, while only 20 instances are labeled in DP ,
including 3 positive and 17 negative instances, shown as
large dots in Figure 1 (b). To classify DP , we use four classiﬁers trained on SVM using a RBF kernel K(xi, xj) =
e−ρ∥xi−xj∥2 with ρ = 5. They are (1) an Aux classiﬁer
trained from the 600 labeled instances in DA, (2) a New
classiﬁer trained from the 20 labeled instances in DP , (3) an
Aggr classiﬁer trained from all the 620 labeled instances in
# of positive examples
Mean average precision (MAP)
# of positive examples
Mean average precision (MAP)
# of positive examples
Mean average precision (MAP)
Figure 2. Comparison of ﬁve classiﬁers on video classiﬁcation performance averaged across 360
concept-program settings (random sampling).
DA ∪DP ; (4) an Adapt classiﬁer adapted from Aux using
the 20 instances in DP based on Adapt-SVM. In the training of these classiﬁer, we set C′ = 1 for the instances in DA
and C = 10 for the instances in DP to reﬂect the relative
importance of the two datasets. We plot the decision boundary of the four classiﬁers on DP in Figure 1 (c) to (f). The
error rate of each classiﬁer is shown below each ﬁgure. Not
surprisingly, Aux and Aggr are biased towards the distribution of DA, and unable to accurately classify DP . New is
unbiased, but has a large variance due to the limited training
data. Adapt achieves the lowest error rate, and its decision
boundary captures the distribution of the positive data in
DP more precisely than the other classiﬁers.
News Video Classiﬁcation
We evaluate Adapt-SVM based on a benchmark video
classiﬁcation task TRECVID 2005 . It contains 86-hour
video footage of 13 TV news programs from 6 channels. All
but one channels have two news programs, and the remaining one has two programs. The video in the collection has
been segmented into 74,523 shots. Each shot is represented
by one video frame as its “keyframe”, and a keyframe is associated with a 273-d feature vector describing its color and
texture properties. This collection comes with manually assigned labels with respect to 34 semantic concepts.
In each setting of the experiment, we pick one of the 34
concepts as the target concept, and one of the 13 programs
as the primary program. The other program in the same
channel as the primary program is treated as the auxiliary
program. We train a SVM classiﬁer for the target concept
using all the shots in the target program (based on their feature vectors), and adapt it to the target program using a limited number of shots sampled from it. The adapted classiﬁer
is evaluated on the shots in the target program except those
used as training examples. We convert the classiﬁer output
into a shot list ranked by their relevance scores, and measure
the quality of this list using average precision (AP). We also
use mean average precision (MAP) to average the AP scores
in multiple settings. By varying the target concept and primary program, we have 34 × 13 concept-program settings.
We remove the settings where the number of relevant shots
is less than 10, which results in 360 settings.
We compare our adapted classiﬁer Adapt with another
3 SVM classiﬁers: Aux trained from all the data in the auxiliary program, New trained from the labeled instances in
the primary program, and Aggr trained from the labeled
instances in both programs with different weights. We also
include an Ensemble classiﬁer which computes the relevance score of each instance as a weighted sum of the
scores of New and Aux. All these classiﬁers are trained
with RBF kernel with ρ = 0.1. To make Adapt comparable to Aggr and Ensemble, we ensure that the weight
C′ for auxiliary instance/classiﬁer and the weight C for primary instance/classiﬁer in these models are the same. We
use C′ = 1 in all the experiments while vary C from 1 to
10 in order to learn its impact on the performance.
Classiﬁcation Accuracy: Figure 2 shows the performance of the 5 classiﬁers in terms of MAP across 360
concept-program settings against the number of positive
training examples 2. Random sampling is used in this experiment. On average, Adapt outperforms the other four
classiﬁers in most of the cases. Only when C = 10 and
training examples are scarce that Adapt performs slightly
worse than Aggr and Aux. Knowing that Adapt is better
than Aggr and Ensemble is especially encouraging, since
they represent two widely used approaches to exploiting the
knowledge of auxiliary data.
We ﬁnd the performance of Adapt closely related to the
choice of the cost factor C. When C = 1, Adapt relies
more on the prior model and it behaves similar to Aux. This
gives Adapt a “warm start” with very limited examples,
but also makes it too conservative to fully utilize the incoming examples. When C = 10, Adapt relies more on the
labeled examples. As a result, its performance suffers a bit
2Since most concepts are infrequent (the ratio of positive instances of a
concept is 3.7% on average), the positive examples are more valuable for
training a classiﬁer and thus its number is a better indicator of the amount
of information available. The number of negative examples used depends
on the positive-negative ratio in each program.
Number of examples
Mean average precision (MAP)
Sampling methods on the Adapt classifier
Selective (Prior)
Selective (Best−Worst)
Figure 3. Sampling methods on Adapt
initially due to a high variance, but ends up higher when
more examples become available. Since it is not legitimate
to choose C based on the performance on the test set, in
practice we need to choose C by cross-validation.
Efﬁciency: We compare the training time of Adapt
with that of New and Aggr. Aux is trained “ofﬂine” and
thus its cost does not matter, and the cost of Ensemble is
equal to that of New. The total training time in minutes for
all the settings, with C = 3 and 10 positive examples (approx. 164 total examples), is 17.4 for New or Ensemble,
20.1 for Adapt, and 271.9 for Aggr.
This shows that
adapting a classiﬁer is only slightly more expensive than
training one from the new examples, but an order of magnitude less expensive than training a “big” classiﬁer using
aggregated data. This makes the proposed method applicable to interactive scenarios and/or large-scale problems.
Selective Sampling: We compare two selective sampling strategies described in Section 3,
Best-Worst, with random sampling. Since they select
different samples from the data which cause the remaining
to be different, we evaluate them based on all the data in
the target program. Figure 3 shows the MAP of all the settings achieved by Adapt with the three sampling methods.
Both selective sampling methods are considerably better
than random sampling, showing that using more informative samples does help classiﬁer adaptation. Between them,
Prior is slightly better than Best-Worst except when
there are only 50 samples.
Related Work and Discussion
The problem of classiﬁer adaptation has been studied
in many related areas. It is closely related to the problem
of drifting concept detection in mining of streaming data,
which is solved either by constructing an ensemble classi-
ﬁer combining a set of base classiﬁers trained from different
chunks of the data stream (e.g., , ), or by training a
single classiﬁer using aggregated (and weighted) instances
sampled from the data stream (e.g., ). Our work also belongs to transfer learning, which aims to apply knowledge
learned in one or more tasks to improve the performance on
a related task. Many methods for transfer learning 
take the “aggregation” approach, which incorporate the labeled data of related tasks into the current training set in order to build better classiﬁers. Our method is fundamentally
different since it directly modiﬁes an existing model to ﬁt
the new data, which avoids the cost of training over aggregated data. Our method can be also used as an incremental
learning algorithm, and it is more efﬁcient than existing incremental algorithms (e.g., ) that involve training over (at
least) part of the previous data.