IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X, XX 200X
Multiobjective Neural Network Ensembles based
on Regularized Negative Correlation Learning
Huanhuan Chen, Member, IEEE, and Xin Yao, Fellow, IEEE
Abstract—Negative Correlation Learning (NCL) , is a neural network ensemble learning algorithm which introduces a correlation
penalty term to the cost function of each individual network so that each neural network minimizes its mean-square-error (MSE) together
with the correlation. This paper describes NCL in detail and observes that the NCL corresponds to training the entire ensemble as a
single learning machine that only minimizes the MSE without regularization. This insight explains that NCL is prone to overﬁtting the
noise in the training set. The paper analyzes this problem and proposes the multiobjective regularized negative correlation learning
(MRNCL) algorithm which incorporates an additional regularization term for the ensemble and uses the evolutionary multiobjective
algorithm to design ensembles. In MRNCL, we deﬁne the crossover and mutation operators and adopt nondominated sorting algorithm
with ﬁtness sharing and rank-based ﬁtness assignment. The experiments on synthetic data as well as real-world data sets demonstrate
that MRNCL achieves better performance than NCL, especially when the noise level is non-trivial in the data set. In the experimental
discussion, we give three reasons why our algorithm outperforms others.
Index Terms—Multiobjective algorithm, Multiobjective Learning, Neural Network Ensembles, Neural Networks, Negative Correlation
Learning, Regularization.
INTRODUCTION
Nsemble of multiple learning machines, i.e. a group
of learners that work together as a committee, has
attracted a lot of research interests in the machine
learning community since it is considered as a good
approach to improve the generalization ability . Most
ensemble learning algorithms train the individual neural
network independently or sequentially, so the advantages of interaction and cooperation among the individual networks are not exploited. However, Liu and Yao
 , have shown that the cooperation with ensemble
members is useful for obtaining better ensembles. This
new approach opens a new research area where the
design and training of the different networks can be
interdependent.
Negative Correlation Learning (NCL) , emphasizes the interaction and cooperation among individual
neural networks in the ensemble and has performed
well on a number of empirical applications, including
regression problems and classiﬁcation problems .
NCL introduces a correlation penalty term to the cost
function of each individual network so that each neural
network minimizes its MSE together with the correlation
with the ensemble.
According to the deﬁnition of NCL, it seems that
the correlation term in the cost function acts as the
regularization term. However, we observe that the train-
• The authors are with The Centre of Excellence for Research in Computational Intelligence and Applications (CERCIA), School of Computer Science, University of Birmingham, Birmingham B15 2TT, United Kingdom
(email: {H.Chen, X.Yao}@cs.bham.ac.uk).
Manuscript received May 19, 2008; revised March 19, 2009 and July 5, 2009;
accepted September 22, 2009.
ing of NCL with the penalty coefﬁcient λ setting to 1
corresponds to treating the entire ensemble as a single
estimator and considering only the empirical training
error without regularization. In this case, NCL only reduces the empirical MSE of the ensemble, and it pays less
attention to regularizing the complexity of the ensemble,
which leads NCL to be prone to overﬁtting the noise in
the training set. Similarly, setting a zero or small positive
λ corresponds to independently training these estimators
without regularization and in this case, NCL is prone to
overﬁtting as well.
NCL can use the penalty coefﬁcient λ to explicitly alter
the emphasis on the MSE and correlation portion of the
ensemble and thus alleviate the overﬁtting problem to
some extent. However, NCL could not totally overcome
the overﬁtting problem by tuning this parameter without
regularization, especially when dealing with data with
non-trivial noise, which will be implicitly evidenced by
the empirical work on multi-objective implementation
of NCL in this paper. The regularization term is especially beneﬁcial to NCL since large weights are usually
connected with near linear dependence among groups of
units in the network, negative correlation learning would
seem to potentiate the appearance of large weights in the
Another problem with NCL is that the parameter λ,
which controls the trade-off between empirical error and
correlation, needs to be tuned. Although this parameter
is crucial to the performance of NCL, there is no formulated approach to select the parameter. Optimization of
the parameter usually involves cross validation, whose
computation is extremely expensive.
In order to address these problems, this paper proposes a multiobjective regularized negative correlation
Digital Object Indentifier 10.1109/TKDE.2010.26
1041-4347/10/$26.00 © 2010 IEEE
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
Authorized licensed use limited to: University of Leeds. Downloaded on March 12,2010 at 12:48:43 EST from IEEE Xplore. Restrictions apply.
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X, XX 200X
learning (MRNCL) algorithm. MRNCL incorporates an
additional regularization term for the ensemble, which
can be decomposed into different parts for each network.
By incorporating an additional regularization term, the
training of an individual neural network in MRNCL
involves minimization of the three terms: empirical
training error term, correlation penalty term and the
regularization term.
However, how to balance the tradeoff among the three
terms is crucial for the generalization performance of
ensemble. Poor generalization occurs if the tradeoff is
unbalanced. The usual approach is to assign coefﬁcient
parameters to these terms and choose the appropriate
coefﬁcients based on tedious trial-and-error processes.
The idea of the paper is the introduction of an evolutionary multiobjective algorithm to search the best
tradeoff among the three terms: the empirical error, correlation and regularization. Evolutionary multiobjective
algorithms are well suited to search the optimal tradeoff among different objectives by parallelizing the search
using a population of networks and biasing toward the
Pareto front and, at the same time maintaining population diversity to obtain as many candidate solutions
as possible. These properties are especially important in
ensemble design.
Since the regularization term is considered as one
objective in MRNCL, the networks with appropriate regularization are preferable in MRNCL. Thus the obtained
ensemble is regularized and is more robust to noise in
the training set.
MRNCL algorithm not only addresses the issues concerned with NCL, but also provides the following advantages: (1) Being a multiobjective algorithm, the approach
is able to produce a diverse ensemble. Some individuals
are good at minimizing the training error; some pay
more attention to cooperation and the others manage to
control the complexity. (2) The parameters of individual
networks can be effectively obtained in the evolutionary
multiobjective algorithm. (3) Due to the regularization
term, the obtained ensemble is regularized and is more
robust to noise in the training set. (4) There is no
need to weigh the different objectives by optimizing the
coefﬁcient parameters.
The key contributions of this paper include a) we point
out that NCL is prone to overﬁtting and verify this claim
using theoretical and extensive empirical work; b) we
propose to add an additional regularization term to control the complexity of the ensemble; c) we implement the
algorithm using evolutionary multi-objective algorithm
and d) we carry out extensive experimental studies to
evaluate and compare MRNCL with some existing ones.
The rest of this paper is organized as follows. After
the background description in Section 2, the proposed
algorithm is introduced in Section 3. Experimental results and discussions are presented in Section 4. Finally,
Section 5 concludes the paper.
BACKGROUND
Neural network ensembles are a learning paradigm
where a collection of neural networks is trained for the
same task. There have been many ensemble methods
studied in the literature, such as Bagging , Boosting
 , ensemble of features and so on. Most ensemble
learning algorithms train the individual neural network
independently or sequentially.
Negative correlation learning is a successful
neural network ensemble learning algorithm. It is different from previous works such as bagging or boosting, since NCL emphasizes interaction and cooperation
among the individual learners in the ensemble by using
an unsupervised penalty term in the error function
to produce biased individuals whose errors tend to be
negatively correlated.
In 2000, Abbass ﬁrstly proposed a memetic multiobjective evolutionary approach to evolve artiﬁcial
neural networks. Two objectives are considered in this
algorithm. One is to minimize the error and the other
is to minimize the number of hidden units, which can
be thought as a kind of regularization measure. This
method ﬁrstly proposed the idea to consider both regularization and accuracy in the multiobjective algorithm
and to combine the individuals in the pareto front for
ﬁnal predictions.
In 2001, McKay et al. presented an alternative anticorrelation measure, root-quartic negative correlation
learning (RTQRT–NCL) and used the anti-correlation
in training neural network ensembles. The empirical
results showed signiﬁcant improvements for both arti-
ﬁcial neural networks (ANN) and genetic programming
(GP) learning machines. They also derived a theoretical
explanation of the improved performance of RTQRT–
NCL in larger ensembles. Later, Abbass employed
a multiobjective evolutionary algorithm and a gradientbased local search method to train neural networks
and simultaneously optimize their architecture. A neural
network ensemble can be generated by combining the
networks in the ﬁnal generation.
In 2004, Jin et al. used a multi-objective evolutionary algorithm to optimize the accuracy and regularization of neural networks. As a natural by-product of
the multi-objective evolutionary approach to neural network learning, neural network ensembles can be easily
constructed using the obtained networks with different
levels of model complexity.
Islam et al. took a constructive approach to
building the ensemble, starting from a small group of
networks with a minimal architecture. The networks are
all partially trained using NCL. The approach can automatically determine weights, network topologies and
ensemble membership. In the following work, Brown
et al. formalized NCL, providing a statistical interpretation of its success. Furthermore, for estimators that
are linear combinations of other functions, they derive
an upper bound on the penalty coefﬁcient, based on
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
Authorized licensed use limited to: University of Leeds. Downloaded on March 12,2010 at 12:48:43 EST from IEEE Xplore. Restrictions apply.
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X, XX 200X
properties of the Hessian matrix.
Diverse and accurate ensemble learning algorithm
 , is an approach that combines evolving neural
network and multiobjective algorithm. In this paper,
adaptive Gaussian variance is employed for generating
the offspring and memetic pareto artiﬁcial neural network algorithm is used for evolving neural networks.
Finally, diverse and accurate classiﬁers can be achieved
through these procedures. Oliveira et al. use multiobjective evolutionary algorithms to generate an ensemble to solve the handwritten recognition problem.
This algorithm produces a set of classiﬁers with a small
number of features and a low error rate by evolving
these classiﬁers with different randomly chosen features.
The combination weights of ensemble are obtained by
a multiobjective algorithm with two different objectives:
diversity and accuracy.
Cooperative coevolution of artiﬁcial neural network
ensembles combines the coevolution of different
subpopulations of diverse networks and the evolution
of the combination weights of these networks. In this algorithm, the cooperation with the rest of the population
is deﬁned as one objective, and each network is evaluated in the evolutionary process using a multiobjective
evolutionary method. Thus, the algorithm encourages
the collaboration among individuals and improves the
combination schemes for the ensemble.
Chen et al. propose to incorporate bootstrap of
data, random feature subspaces and evolutionary
algorithms with NCL to automatically design accurate
and diverse ensembles. The idea promotes the diversity
within the ensemble and simultaneously emphasizes the
accuracy and cooperation in the ensemble. Dam et al.
 apply the NCL algorithm to train the neural network
ensemble in learning classiﬁer systems, where NCL is
shown to improve the generalization of the ensemble.
In , Chen and Yao propose the regularized negative correlation learning (RNCL) algorithm with λ set
to 1 and make use of Bayesian inference to infer the
explicit regularization parameters. In this paper, we
formulate the regularized negative correlation learning
as a multi-objective evolutionary learning problem. A
multi-objective evolutionary algorithm is used to search
effectively the best trade-off among these objectives
without searching for the combination parameters to
weigh these objectives. Compared with RNCL by gradient descent with Bayesian inference in , MRNCL
often achieves a little better performance by considering
an additional weighting coefﬁcient λ of the correlation
term. The potential advantages of the multiobjective
approach include: It enables us to observe the interaction
and trade-off among different objectives; and it enables
us to add or remove an objective easily without changing
the overall algorithm. However, the beneﬁts come with
the price, more computational time to train MRNCL.
MULTIOBJECTIVE REGULARIZED NEGATIVE
CORRELATION LEARNING
This section analyzes NCL and its potential risk of over-
ﬁtting. In order to address the problem, a multiobjective
regularized NCL algorithm is proposed.
Negative Correlation Learning
NCL introduces a correlation penalty term to the error
function of each individual network in the ensemble so
that all the networks can be trained interactively on the
same training data set.
Given the training set {xn, yn}N
n=1, NCL combines M
neural networks fi(x) to constitute the ensemble.
fens(xn) = 1
In training network fi, the cost function ei for network
i is deﬁned by
(fi(xn) −yn)2 + λpi,
where λ is a weighting parameter on the penalty term
⎩(fi(xn) −fens(xn))
(fj(xn) −fens(xn))
(fi(xn) −fens(xn))2 .
The ﬁrst term on the right-hand side of (1) is the
empirical training error of network i. The second term
pi is a correlation penalty function. The purpose of
minimizing pi is to negatively correlate each network’s
error with the error for the rest of the ensemble. The λ
parameter controls a trade-off between the training error
term and the penalty term. With λ = 0, we would have
an ensemble with each network trained independently.
If λ is increased, more and more emphasis would be
placed on minimizing the penalty.
Based on the individual error function, Equation (1),
the error function for the ensemble can be obtained by
averaging these individual network errors ei. If λ = 1,
the average error E of all the individual networks ei is
obtained as follows:
(fi(xn) −yn)2 −(fi(xn) −fens(xn))2
(fens(xn) −yn)2.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
Authorized licensed use limited to: University of Leeds. Downloaded on March 12,2010 at 12:48:43 EST from IEEE Xplore. Restrictions apply.
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X, XX 200X
As explained in , minimizing each ei individually
also minimizes E. According to Equation (3), the error
function of NCL is equivalent to training a single estimator fens(xn) instead of training each individual network
separately. It is also observed that NCL only minimizes
the empirical training MSE
n=1(fens(xn) −yn)2 but
does not regularize the complexity of the ensemble. As
discussed in Section 1, only minimizing MSE leads to
overﬁtting. In Section 4, we will present the empirical
evidence showing that NCL is prone to overﬁtting1.
In order to improve the generalization ability of NCL,
the next section presents a new multiobjective regularized NCL algorithm.
Multiobjective Regularized Negative Correlation
Learning (MRNCL)
Following the traditional strategy to avoid overﬁtting,
a regularization term is incorporated into the ensemble
error function:
(fi(xn) −yn)2 −
(fi(xn) −fens(xn))2 +
where wi = (wi,1, · · · , wi,ni)T is the weight vector of
neural network i and ni is the total number of weights
in network i.
This regularization term
i wi is the weight
decay term for the entire ensemble. In order to train
each neural network with its regularization, we have to
decompose the regularization term into M parts, each
part for a network. The error function for network i can
be obtained as follows:
(fi(xn) −yn)2 −
(fi(xn) −fens(xn))2 + αiwT
Comparing this error function with the cost function
of NCL, Equation (1), MRNCL imposes a regularization
term on every individual neural network and MRNCL
needs to optimize both the correlation coefﬁcient λ and
the regularization parameters αi.
According to Equation (5), the training of an individual neural network in MRNCL involves minimization
of three terms: empirical training error term, correlation
penalty term and the regularization term. The generalization of ensemble depends on the tradeoff among the
three terms and how to balance the tradeoff among the
three terms for different problems becomes an important problem. This paper makes use of an evolutionary
multiobjective algorithm to balance the tradeoff.
1. We also notice that NCL performs well in the previous studies and
we suppose that those data sets used by NCL in the previous studies
do not have large noise.
The formulation of MRNCL is not heuristic but based
on the Bayesian statistical model. According to Appendix A, MRNCL is an application of the Bayesian
framework in an ensemble system. The squared weight
decay term, i.e. the regularization term, corresponds to
the prior of the weight vector in the ensemble. This is
the reason why we only include the squared weight
decay term as the regularization term in the multiobjective algorithm. This intrinsic Bayesian characteristic
of MRNCL potentially facilitates the incorporation of
Bayesian methods in evolutionary multiobjective algorithms to improve the performance of MRNCL.
According to Equation (5), MRNCL deﬁnes the following three objectives.
• Objective of Performance
n=1(fi(xn) −yn)2
This objective measures the empirical mean square
error based on the training set.
• Objective of Correlation −
n=1(fi(xn)−fens(xn))2
This correlation term measures the amount of variability among the ensemble members and this term
can also be treated as the diversity measure .
From both theoretical and experimental results it
has been shown that, if the individual networks
in an ensemble are unbiased, the most effective
combination of them occurs when the errors of
the individual networks are negatively correlated.
This objective encourages individual networks to
negatively correlate their errors and thus helps to
generate a diverse ensemble.
• Objective of Regularization wT
Based on the regularization theory , the weight
decay term is employed to punish large
weights. The weight decay term causes the weights
to converge to smaller absolute values than they
otherwise would. The regularization term helps the
generalization ability of a neural network because
large weights can hurt generalization in two different ways: a) excessively large weights leading
to hidden nodes can cause the output function to
be too rough, possibly with near discontinuities.
Excessively large weights leading to output nodes
can cause wild outputs far beyond the range of
the data if the output activation function is not
bounded to the same range as the data. b) Large
weights can cause excessive variance of the output
 . The regularization term is beneﬁcial to NCL
since large weights are usually connected with near
linear dependence among groups of nodes in the
network, and NCL would seem to potentiate the
appearance of large weights in the ensemble.
Component Networks and Evolutionary Operators
The component network in the ensemble is a radial basis
function (RBF) network. The output of RBF network is
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
Authorized licensed use limited to: University of Leeds. Downloaded on March 12,2010 at 12:48:43 EST from IEEE Xplore. Restrictions apply.
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X, XX 200X
computed as a linear combination of K basis functions
wkφk(x) = ΦT w,
where w = (w1, · · · , wK)T denotes the weight vector in
the output layer and Φ = (φ1, · · · , φk) is the vector
of basis functions. The Gaussian basis functions φk are
φk(x) = exp(∥x −μk ∥2
where μk and σk denote means and widths of the
Gaussian, respectively. The training of RBF network is
separated into two steps. In the ﬁrst step, the means μk
are initialized with randomly selected data points from
the training set and the variances σk are determined
as the Euclidean distance between μk and the closest
μi(i ̸= k, i ∈{1, · · · , K}). Then in the second step
we perform gradient descent in the regularized error
function (weight decay)
(yn −f(xn))2 + α
In order to ﬁne-tune the centers and widths, we simultaneously adjust the output weights, the RBF centers
and variances. Taking the derivative of Equation (6) with
respect to RBF means μk and variances σ2
k we obtain
(f(xn) −yn)∂f(xn)
with ∂f(xn)
φk(xn) and
(f(xn) −yn)∂f(xn)
with ∂f(xn)
φk(xn). These two derivatives
are employed in the minimization of Equation (6) by
scaled conjugate gradient descent, where we always
compute the optimal output weights in every evaluation
of the error function. The optimal output weights w can
be computed in closed form by
w = (ΦT Φ + αI)−1ΦT y,
where y =(y1, · · · , yn)T denotes the output vector, and
I is an identity matrix.
We use RBF networks as the base learners because of
the following advantages. 1) If the centers and widths of
the basis functions have been chosen, the optimal output
weights w can be efﬁciently computed in closed form,
which means the performance mostly depends on the
selection of basis functions. 2) It is reasonable to deﬁne
crossover and mutation operators in structural-evolving
RBF networks by tuning these basis functions.
Based on the above reasons, the crossover and mutation operators for RBF networks are described as follows.
• Crossover Operator
Since the performance of a RBF network mostly
depends on the basis functions, i.e. the centers and
the widths, the crossover operator is deﬁned to
exchange the basis functions of two RBF networks.
Many crossover techniques exist in the literatures,
such as one-point crossover, two-point crossover
and “cut and splice” crossover . In a RBF network ensemble, as different networks may have
different numbers of basis functions, the “cut and
splice” approach has been adopted by randomly
choosing separate crossover points for two RBF
networks and swap their basis functions beyond
those points.
• Mutation Operator
This paper deﬁnes two structural mutation operators for RBF networks.
1) Deleting one basis function. Randomly select
one basis function and delete it.
2) Adding one basis function. The center of the
new basis function is determined by a randomly selected data point from the training set.
Then, the width of the basis function is chosen
as the minimal distance from other centers in
this RBF network.
As the crossover and mutation operations may not
generate the optimal combination of basis functions,
in order to ﬁne-tune the center, width and the weight
vector, we simultaneously adjust the output weights, the
RBF centers and widths based on Equations (7), (8) and
(9). This procedure is also called parametric mutation
 , which modiﬁes the parameters of the network without modifying its topology. This parametric mutation is
performed for a few iterations (in our experiments, only
one scaled-conjugate-gradient update is employed).
Multiobjective Evolution of Ensemble and Rankbased Fitness Assignment
In this paper, we will consider a population of individuals who have three objectives and a multiobjective
algorithm is employed to select a set of best classiﬁers
with respect to the three objectives. There are a lot of
multiobjective algorithms available and the selection of
the most suitable algorithm is not a trivial task .
In this paper, nondominated sorting with ﬁtness sharing and rank-based ﬁtness assignment are employed. The idea underlying nondominated sorting is
the use of a ranking selection method to emphasize
current nondominated individuals and a niching method
to maintain diversity in the population. Nondominated
sorting is based on layers of Pareto front, which ranks
the individuals in the population by fronts that lead to
fast convergence to Pareto front in the ﬁnal population
and the diversity is maintained by a niching method in
the population.
The nondominated sorting algorithm consists of two
stages: One is to obtain the nondominated fronts of
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
Authorized licensed use limited to: University of Leeds. Downloaded on March 12,2010 at 12:48:43 EST from IEEE Xplore. Restrictions apply.
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X, XX 200X
different layers and every individual of these fronts is assigned an equal dummy ﬁtness. The algorithm used for
obtaining the nondominated set of solutions compares
the individuals pairwise and marks as dominated all the
individuals that are dominated by at least one member
of the population. The second is that the members of
every front share their ﬁtness with the constraints
that none of the members of a front gets a higher ﬁtness
than any of the members of the previous front.
Since the dummy ﬁtness assigned by nondominated
sorting is raw, sometimes the range of the raw ﬁtness
is too large, leading to the situation that some networks
reproduce too rapidly, taking over the population too
quickly, and preventing the evolutionary algorithm from
searching other areas of the solution space. This paper
employs rank-based ﬁtness assignment to reassign the
ﬁtness to the networks because rank-based ﬁtness assignment behaves in a more robust manner than proportional ﬁtness assignment. In rank-based ﬁtness assignment, the population is sorted according to the raw
ﬁtness values. The ﬁtness assigned to each individual
depends only on its position in the individuals’ ranking
and not on the actual raw ﬁtness value.
Assume the best individual in a population ranks the
ﬁrst. The probability of selecting individual i can be
calculated as follows :
M (ηmax −(ηmax −ηmin) i −1
where M is the population size, ηmax and ηmin are two
parameters.
ηmax ≥ηmin ≥0,
ηmax + ηmin = 2.
In order to encourage diversity in the population, our
algorithm uses the recommended values , ηmax = 1.1
and ηmin = 0.9, to have an appropriate selection pressure. Since we compare the children with the parents
before being admitted into the population, a large selective pressure will lead some individuals to reproduce
too rapidly and thus limits the search ability of the
evolutionary algorithm. It is the reason why we use
ηmax = 1.1 and ηmin = 0.9 in our paper.
Algorithm Description
The details about Multiobjective Regularized Negative
Correlation Learning (MRNCL) are summarized in Figure 1. Note that in the crossover and mutation operations, the comparison of the child network with the
parent network is conducted as follows.
1) Evaluate the three objective values of the child
2) Include the child network into the population, then
apply non-dominant sorting with ﬁtness sharing
algorithm to obtain the raw ﬁtness values2 of the
2. The raw ﬁtness values depend on their ranked layers (fronts)
in the population. If they are in the same layer (front), e.g. they are
both non-dominant solutions, the one in less crowded area will receive
greater ﬁtness according to the ﬁtness sharing algorithm.
child network and the parent network.
3) Compare the raw ﬁtness values and keep the better
To determine the time to stop evolution, we selected
three threshold values (t1 = t2 = t3 = 10−3 in this paper)
and compare the thresholds with the differences between
the old minimal objective values with the new minimal
objective values. If all the differences are lower than the
thresholds, the algorithm will be terminated. Otherwise,
continue. The maximal number of generations is 200.
EXPERIMENTAL STUDIES
In this section we present the experimental results of
MRNCL and MNCL, which employs a multiobjective
algorithm (two objectives: training error and correlation
term) to train negative correlation ensemble. We use
MNCL instead of gradient-based NCL because MRNCL
uses multiobjective algorithm and it is fair and natural
to employ the multiobjective algorithm to train NCL.
In order to compare our algorithm with previous work
on multi-objective ensemble learning, we have obtained
the source code from Dr. Yaochu Jin and used the same
parameters as their algorithm in . This algorithm
evolves multi-layer perception (MLP) using two objectives (training error and regularization, i.e. number of
connections in MLP) and we name the algorithm as
multiobjective neural network (MoNN) in this paper.
In this section, ﬁrstly, we present experimental results
of MRNCL and other algorithms on four synthetic classiﬁcation problems in order to understand the behavior
of these algorithms. We also design two experiments
with different noise levels to study the characteristics
of MRNCL, MNCL and MoNN on noisy data. Secondly,
we carry out extensive experiments on 16 benchmark
classiﬁcation data sets to compare the performance of
MRNCL, MNCL and other classiﬁers.
Experimental Setup
In our experiments, radial basis function (RBF) networks
are used as the individual classiﬁers. The number of
hidden nodes is randomly selected but restricted in the
range of 5 to 15. The parameters in the evolutionary
algorithm are set to: the population size M (100), the
number of crossover in one generation 20, the number
of mutation in one generation 10, the number of generations (200), the parameter of ﬁtness sharing σshare (0.2).
These parameters are chosen after some preliminary
experiments. They are not meant to be optimal.
In the experiments, we restrict the minimal hidden
nodes of RBF networks as 3 in MRNCL and MNCL to
discourage improperly simple networks.
Synthetic Data Sets
As the ﬁrst experiment, we demonstrate the results of
MRNCL on four synthetic data sets in two dimensions
in order to illustrate graphically the decision boundaries.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
Authorized licensed use limited to: University of Leeds. Downloaded on March 12,2010 at 12:48:43 EST from IEEE Xplore. Restrictions apply.
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X, XX 200X
1. Generate an initial RBF network population: Generate an initial population of M RBF Networks, the number of hidden nodes for each network, ni(i = 1, ..., M) is speciﬁed randomly
restricted by the maximal number of hidden nodes. The centers μi,k are initialized with randomly selected data points from the training set and the width σi,k are determined as the
Euclidian distance between μi,k and the closest μi,j(j ̸= k, j ∈{1, · · ·, ni}).
2. Train the initial RBF network population and recode the three objective values for each network.
3. Apply nondominated sorting with rank-based ﬁtness assignment algorithm to obtain the rankbased ﬁtness.
4. For 1 to maximal generation
• Perform a desired number of crossover operations.
Choose parents based on roulette wheel selection algorithm and perform crossover. Then
perform a few number of updates for weight, center and width. Compare the children
with parents and keep the better ones.
• Perform a desired number of mutation operations.
Choose parents based on roulette wheel selection algorithm and perform mutation. Then
perform a few number of updates for weight, center and width. Compare the children
with parents and keep the better ones.
• Apply nondominated sorting algorithm and obtain the rank-based ﬁtness for the new
population.
5. Combine all the classiﬁers in the population to form the ensemble. (The members of ensemble
have equal weights)
Fig. 1. Multiobjective Regularized Negative Correlation Learning Algorithm
These four data sets are as follows (1) synth is generated from mixtures of two Gaussians by . (2)
Overlap comes from two Gaussian distributions with
equal covariance, and is expected to be separated by a
linear plane. (3) Bumpy comes from two equal Gaussians
but being rotated by 90 degrees. Quadratic boundaries
are required. (4) Relevance is a case where only one
dimension of the data is relevant to separating the data.
In Figure 2 we present a comparison of MRNCL,
MNCL and MoNN. We can observe a similar performance of MRNCL and MNCL in the case of Relevance.
Since the data set is noise-free, MRNCL and MNCL successfully separate the two classes. In this data set, MoNN
generates two linear lines with unnecessary training error.
The reason is that MoNN can reduce the regularization
by deleting connections and nodes of MLP while it
could not always reduce the MSE due to the intrinsic
complexity of the data set. In the end, MoNN tends to
select the networks with small regularization and thus
over-regularizes the ensemble in some cases.
The situation is similar in the case of Overlap. Since it is
difﬁcult for RBF networks, which are used as component
learners in MRNCL and MNCL, to obtain linear decision
boundaries , MRNCL produces near-linear boundary,
while the boundary of MNCL is a little twisty. MoNN
generates a linear line according to the expectation to
separate the data set.
We observe that MRNCL gives more accurate results
in other cases. In the cases of Synth and Bumpy, MRNCL
produces smooth boundary and disregards the outliers
in the training points. In the case of Synth, MoNN tries to
use a near-linear boundary to separate the non-linear data
set consisted of four Gaussians. The generated model is
over-regularized and thus degrades the performance. In
the case of Bumpy, although the decision boundary of
MoNN is smooth, it does not generate an appropriate
boundary according to expectation. (The optimal boundary is a quadratic one.) Since the noise level is large
because of these overlapping points in the case of Bumpy,
MNCL does not generalize and produces the twisty
boundary. In the case of Synth, MNCL concentrates on
several outliers and generates a corner in the boundary.
Figure 3 illustrates the mean values of these three objectives in different generations. The arrow points from
the ﬁrst generation to the ﬁnal generation. According
to these ﬁgures, MRNCL algorithm tries to minimize
the three objectives. However, based on the analysis in
Section 3, the empirical training error is negatively correlated with the correlation term. Instead of minimizing
the three objectives simultaneously, MRNCL seeks to
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
Authorized licensed use limited to: University of Leeds. Downloaded on March 12,2010 at 12:48:43 EST from IEEE Xplore. Restrictions apply.
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X, XX 200X
(b) Overlap
(d) Relevance
Fig. 2. Comparison of MRNCL, MNCL and MoNN on four
synthetic classiﬁcation data sets. Two classes are shown
as crosses and dots. The separating lines were obtained
by projecting test data over a grid.
7UDLQJ(UURU
5HJXODUL]DWLRQ
&RUUHODWLRQ
7UDLQJ(UURU
5HJXODUL]DWLRQ
&RUUHODWLRQ
(b) Overlap
7UDLQJ(UURU
5HJXODUL]DWLRQ
&RUUHODWLRQ
7UDLQJ(UURU
5HJXODUL]DWLRQ
&RUUHODWLRQ
(d) Relevance
Illustration of the mean value of these three
objectives in different generations. The arrow points from
the beginning (Generation = 1) to end (Generation = 100).
The gray scale indicates generations.
ﬁnd a good balance between the two objectives, training
error and the correlation term, and MRNCL always
minimizes the third objective, the regularization term,
in the evolutionary algorithm.
In order to illustrate the effect of negative correlation
term in these algorithms, we employ a popular diversity
measure, Q statistics3 , and measure the diversity
3. The deﬁnition and calculation of Q statistics have been described
in Appendix B.
*HQHUDWLRQ
4VWDWLVWLFV
'LYHUVLW\&KDQJHGLQ(YROXWLRQDU\
*HQHUDWLRQ
4VWDWLVWLFV
'LYHUVLW\&KDQJHGLQ(YROXWLRQDU\
(b) Overlap
*HQHUDWLRQ
4VWDWLVWLFV
'LYHUVLW\&KDQJHGLQ(YROXWLRQDU\
*HQHUDWLRQ
4VWDWLVWLFV
'LYHUVLW\&KDQJHGLQ(YROXWLRQDU\
(d) Relevance
Fig. 4. Illustration of diversity (measured by a commonlyuse diversity measure Q statistics) during the evolution.
in each generation for these three algorithms. The results are presented in Figure 4. In this ﬁgure, MRNCL
and MNCL encourage diversity4 in the evolution while
MoNN does not pay much attention to increasing diversity in the evolution. In Figure 4(d), since Relevance is
a noise-free data set, most networks concentrate on the
training error and MRNCL does not need more diversity
to classify this data set. This indicates that MRNCL
can choose the best tradeoff among these objectives for
different problems. Based on the formulation of MRNCL
and the observations, the main function of the negative
correlation term is to encourage diversity in the ensemble.
The 3D view of the last population is illustrated in
Figure 5. The negative correlation between the empirical
error term and the correlation term has been conﬁrmed
by these ﬁgures. The ﬁnal population distributes a good
tradeoff between these three objectives for all the data
sets. According to this ﬁgure, we also notice that almost
80%-90% of the solutions in the last generation are nondominated solutions. In Section 4.5, we will present
the performance of ensembles by using only the nondominated solutions in MRNCL.
Experimental Results on Noisy Data
In order to explore the behavior of MRNCL and other
multi-objective learning methods with different noise
levels, we conduct two additional experiments. In the
experiments, we select two data sets: synth and banana5
To change the noise level, we randomly select different
percentages of data points and reverse their labels. We
4. Small Q statistics indicates large diversity.
5. 
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
Authorized licensed use limited to: University of Leeds. Downloaded on March 12,2010 at 12:48:43 EST from IEEE Xplore. Restrictions apply.
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X, XX 200X
5HJXODUL]DWLRQ
RISRLQWV
FRQVLVWRI3DUHWR)URQW
7UDLQJ(UURU
&RUUHODWLRQ
3RLQWVLQWKHILUVWOD\HU
3RLQWVLQWKHVHFRQGOD\HU
5HJXODUL]DWLRQ
RISRLQWV
FRQVLVWRI3DUHWR)URQW
7UDLQJ(UURU
&RUUHODWLRQ
3RLQWVLQWKHILUVWOD\HU
3RLQWVLQWKHVHFRQGOD\HU
(b) Overlap
5HJXODUL]DWLRQ
RISRLQWV
FRQVLVWRI3DUHWR)URQW
7UDLQJ(UURU
&RUUHODWLRQ
3RLQWVLQWKHILUVWOD\HU
3RLQWVLQWKHVHFRQGOD\HU
5HJXODUL]DWLRQ
RISRLQWV
FRQVLVWRI3DUHWR)URQW
7UDLQJ(UURU
&RUUHODWLRQ
3RLQWVLQWKHILUVWOD\HU
3RLQWVLQWKHVHFRQGOD\HU
(d) Relevance
Fig. 5. 3D view of the last population with three objectives: training error, regularization and correlation for four
synthetic classiﬁcation data sets.
run 100 times and report the average results in Figure
6. Figure 6(a) and Figure 6(b) visualize the decision
boundaries of MRNCL, MNCL and MoNN with 20%
Though the noise level is high, MRNCL produces
smooth boundaries. MNCL tries to minimize the training
error and it does not generalize well. MoNN generates
an over-smooth (inappropriate) decision boundary disregarding the data distribution for the synth data set.
Both boundaries are biased from the optimal boundary.
We also plot the curves, Figures 6(c) and 6(d), of
classiﬁcation error vs. noise level for these two data
sets. In these two ﬁgures, MRNCL is a little better in
the beginning, but as the noise level increases, MRNCL
signiﬁcantly outperforms MNCL and MoNN.
In both data sets, MoNN exhibits similar curves in
Figures 6(c) and 6(d). In the beginning, the added noise
is very small. MoNN over-regularized the ensemble and
the obtained performance is worse than MRNCL. When
the noise levels are increased (less than 0.1∼0.15), MoNN
achieves a similar performance to MRNCL since the
large regularization in MoNN helps. However, with the
increase of noise levels, MoNN could not be comparable to MRNCL due to the large regularization and
small diversity in the obtained ensembles. The results of
MRNCL are promising on these classiﬁcation problems.
After the analysis with synthetic data sets, the next
section presents the results of the real-world benchmark
Benchmark Results
In order to evaluate the performance of MRNCL, we
compare MRNCL, MNCL and other algorithms on 16
(a) Synth with 20% noise
(b) Banana with 20% noise
QRLVHOHYHOV
HUURUUDWH
(c) Synth with different noise
QRLVHOHYHOV
HUURUUDWH
(d) Banana with different noise
Comparison of MRNCL, MNCL and MoNN on
two classiﬁcation data sets. Two classes are shown as
crosses and dots. The separating lines were obtained
by projecting test data over a grid. In Figure 6(a) and
6(b), these decision boundaries are MRNCL (gray thick),
MNCL (black medium) and MoNN (dotted), respectively.
The randomly-selected noise points are marked with a
circle. Figure 6(c) and 6(d) show classiﬁcation error of
MRNCL, MNCL and MoNN vs. noise levels on synth and
banana data sets. The results are based on 100 runs.
Summary of Classiﬁcation Data Sets.
Training Points
Test Points
Input Dimensions
10-fold-cv
10-fold-cv
10-fold-cv
benchmark problems. These data sets used in this paper
have been summarized in Table 1.
The ﬁrst 13 data sets have been preprocessed and
organized by R¨atsch et al.6 These data sets include one
synthetic set (banana) and 12 data sets come from the
UCI , DELVE7 and STATLOG repositories. The main
difference between the original and R¨atsch’s data is that
6. 
7. delve/data/datasets.html
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
Authorized licensed use limited to: University of Leeds. Downloaded on March 12,2010 at 12:48:43 EST from IEEE Xplore. Restrictions apply.
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X, XX 200X
R¨atsch converted every problem into binary classes and
randomly partitioned every data set into 100 training
and testing folds (Splice and Image have only 20 folds
in R¨atsch’s implementation). In addition, every instance
is normalized dimension-wise to have zero mean and
unit standard deviation. The last three data sets including magic04, satellite and spam are obtained from
UCI machine learning repository . The 10-fold crossvalidation is used and the results are based on the 100
runs for each dataset.
For Adaboost and Bagging, we combine 200 based
learners. Clearly, this number of ensemble size is somewhat arbitrary and may not be optimal. As the base
learner we use RBF nets with adaptive centers as described in Section III.C. The parameters of SVM (σ, C)
(C is the regularization constant and σ is the width of
the RBF-kernel being used) are optimized on the ﬁrst ﬁve
training folds of each data set. On each of training folds,
a 10-fold-cross validation procedure with grid search
will be performed8. Finally, the model parameters are
computed as the median of the ﬁve estimations.
The performance of MRNCL, MNCL, MoNN, Adaboost, Bagging, SVM and RBF network over 100 runs
(20 runs for Splice and Image) is summarized in Table
2. The performance of RBF network, Adaboost and
SVM for the ﬁrst 13 data sets is obtained from R¨atsch’s
implementation9. We followed the similar methodology
for parameter selection and reported the performance of
these algorithms for the last three data sets.
According to Table 2, MRNCL outperforms all the
other methods in 10 out of 16 data sets, comes second
in 6 cases. In comparison with MNCL, MRNCL wins
14 times out of 16 and of them 9 wins are statistically
signiﬁcant. In the results, MNCL performs well in the
cases with little noise: Image, Thyroid and Twonorm,
which are all synthetic data with little noise (see the
lower error rates). The observation validates that MNCL
achieves better results when noise is small.
Adaboost with 200 learners seems to overﬁt the noise
and it does not achieve comparable performance to other
methods. SVM with cross validation search obtains a
good performance in these algorithms as it ranks 1st
place on 4 out of 16 data sets.
Based on the empirical results, we notice that MoNN is
prone to generate “simple” neural networks with small
regularization. The reason is that there are only two
objectives, regularization and mean square error (MSE),
in MoNN and the regularization term can be reduced to
an arbitrary small value while MSE could hardly do it
due to the intrinsic complexity of the data set, especially
when the data lies in a high-dimensional space.
MoNN uses an elitist non-dominated sorting genetic
algorithms (NSGA-II) algorithm , which will archive
8. The ranges of cross validation search for SVM are C
{1, 10, · · · , 100} and θ ∈{0.1, 0.3, · · · , 10} (The data has been normalized to unit standard deviation) in both synthetic data sets and
benchmark data sets.
9. 
non-dominated solutions in this evolution. In this case,
the ﬁnal population is consisted of many individuals
with very small regularization but large MSE, leading
the pareto front to be biased to include more individuals
with smaller regularization but large error. This is the
reason of performance degradation in both synthetic and
benchmark experiments for MoNN.
Our algorithm makes use of an additional objective,
negative correlation term, to encourage diversity in the
population. This objective encourages these networks to
behave differently in the population, and thus alleviates
the above problem in MoNN. In the experiments, we
further restrict the minimal hidden nodes in RBF networks as 3 in MRNCL and MNCL to further discourage
improperly simple networks.
regression
threedimensional Ackley function, is employed to validate
the algorithm ability. The Ackley function is a continuous, multimodal function obtained by modulating an
exponential function with a cosine wave of moderate
amplitude. For this kind of data sets with lots of local
maxima and minima, “simple” networks are beneﬁcial
to address the overﬁtting problems.
Ensemble Size and Non-dominated Solutions
In the previous section, we have reported the performance of MRNCL using all the networks in the population. It is suggested in , that it might be better
to use a subset of available neural networks than to use
all. For this purpose, we will use the non-dominated
solutions to construct a neural network ensemble.
Figure 5 shows the non-dominated solutions in the
population and more than 80% of the solutions are nondominated. We also report the performance and the ensemble size of MRNCL using the entire population and
the non-dominated solutions only on the 16 benchmark
data sets in Table 3, respectively.
According to this table, the performance of the ensemble using non-dominated solutions is a little better than
that using all solutions in the population. The ensemble
size is reduced to almost 80%-90% of the population
size by adopting the non-dominated solutions. Based on
these results, adopting the non-dominated solutions instead of the entire population can improve the ensemble
performance and reduce its size. It also gives a potential
direction to improve our work by selecting a subset
of the non-dominated solutions to constitute a smaller
As we observed in Figure 5, although some individuals in the population have large regularization and some
have small regularization, most individuals will have
appropriate regularization according to different problems. For example, since the data are linear-separable
in the relevance data set (Figure 5(d)), the ensemble
does not need large regularization. In this case, most
of the networks have small regularization. Therefore, an
ensemble of all networks would have an appropriate
regularization.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
Authorized licensed use limited to: University of Leeds. Downloaded on March 12,2010 at 12:48:43 EST from IEEE Xplore. Restrictions apply.
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X, XX 200X
Comparison among 7 methods on 16 benchmark Data Sets: MRNCL, MNCL, MoNN, Adaboost, Bagging, support
vector machine and single RBF classiﬁer. The generalization error in % (standard deviation) on 16 data sets (best
method in bold face) has been reported. A win-loss-tie summarization based on mean value and t test (signiﬁcance
level α = 0.05) is attached at the bottom of the table. The performance is based on 100 runs (20 runs for Splice and
Image). MRNCL gives the best overall performance.
Signiﬁcant
Comparison of the performance and the ensemble size
of MRNCL using the entire population and the
non-dominated solutions on 16 benchmark Data Sets.
Population
The mean rank of MRNCL, MNCL, MoNN and SVM
based on 16 data sets.
Statistical Comparisons over Multiple Data Sets
Statistical tests on multiple data sets for multiple algorithms are preferred for comparing different algorithms
over multiple data sets . In this section, we will
conduct statistical tests over multiple data sets by using
the Friedman test with the corresponding post-hoc
The Friedman test is a non-parametric equivalence of
the repeated-measures analysis of variance (ANOVA)
under the null hypothesis that all the algorithms are
equivalent and so their ranks should be equal , .
This paper uses an improved Friedman test proposed by
Iman and Davenport .
The Friedman test is carried out to test whether all
the algorithms are equivalent. If the test result rejects the
null hypothesis, i.e. these algorithms are equivalent, we
can proceed to a post-hoc test. The power of the posthoc test is much greater when all classiﬁers are compared
with a control classiﬁer and not among themselves. We
do not need to make pairwise comparisons when we in
fact only test whether a newly proposed method is better
than the existing ones.
Based on this point, we would like to choose MRNCL
as the control classiﬁer to be compared with. Since the
baseline classiﬁcation algorithms are not comparable to
other algorithms, this section will analyze only three
algorithms: MNCL, MoNN and SVM against the control
algorithm MRNCL.
The Bonferroni-Dunn test is used as post-hoc tests
when all classiﬁers are compared to the control classiﬁer.
The performance of pairwise classiﬁers is signiﬁcantly
different if the corresponding average ranks10 differ by
at least the critical difference
where j is the number of algorithms, T is the number of
data sets and critical values qα can be found in . For
10. We rank these algorithms based on the metric on each data set
and record the ranking of each algorithm as 1, 2 and so on. Average
ranks are assigned in case of ties. The average rank of one algorithm
is obtained by averaging over all of data sets. Please refer to Table 4
for the mean rank of these algorithms.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
Authorized licensed use limited to: University of Leeds. Downloaded on March 12,2010 at 12:48:43 EST from IEEE Xplore. Restrictions apply.
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X, XX 200X
example, when j = 4, q0.05 = 2.394, where the subscript
0.05 is the signiﬁcance level.
Table 4 lists the mean rank of these algorithms using
different training algorithms. Table 5 gives the Friedman
test results. Since we employ the same threshold 0.05 for
these ensemble training algorithms, the critical difference
CD = 1.0927, where j = 4 and T = 16, is the same for
these algorithms. Several observations can be made from
our results.
Firstly, the null hypothesis that all the algorithms
are equivalent is rejected for each algorithm in Table 4. Secondly, the differences between MRNCL and
other algorithms including MNCL, MoNN and SVM are
greater than the critical difference, so the differences
are signiﬁcant, which means the MRNCL is signiﬁcantly
better than these algorithms in this current experimental
There are at least three reasons why the performance
of our algorithm is better than the performance of others.
1) Effective parameters of RBF ensemble, obtained
by the evolutionary algorithm, improve the performance of the ensemble. The performance of
RBF networks mostly depends on the number of
basis functions and the selection of centers and the
widths in these basis functions. In RBF network
ensemble, better performance is achieved when
these individuals cooperate with each other. How
to select these parameters is crucial for the ensemble. In most of the existing ensemble algorithms,
we have to tune these parameters manually, suffering from the tedious trial-and-error process in
practice. However, our algorithm can determine
these parameters automatically according to different problems given that you specify some parameters for the evolutionary algorithm. We do not
observe great sensitivity to GA parameters, such as
the population size, crossover rate and generation
number, within their commonly accepted ranges.
2) The multiobjective algorithm promotes the accuracy, diversity and regularization in the ensemble. The accuracy and diversity are considered as
two important factors in ensemble algorithms. Our
analysis reveals that besides these two factors, regularization of ensemble is another important part
for ensemble performance. The regularization term
controls the complexity of ensemble and improves
the performance of ensemble against noise. The
existing ensemble algorithms either focus on accuracy, e.g. Adaboost, and/or diversity, e.g. Bagging
and NCL. In order to take all these terms into
consideration, our strategy adopts a multiobjective
algorithm to generate the accurate, diverse and
regularized ensemble.
3) Our algorithm uses a multiobjective algorithm to
construct an ensemble to balance the tradeoff for
different problems. There is no need to weigh
objectives by selecting the coefﬁcients.
Computational Complexity and Running Time
Based on the algorithm in Figure 1, the major running
time of MRNCL is consumed by the training of RBF
networks. In the initialization step, we need to train each
component RBF network, totally M, in the population. In
each generation, indicated by G, we need to train 2C +u
RBF networks, where C is the number of crossover in
one generation and u is the number of mutation in one
generation. In total, we need to train M + (2C + u)G
RBF networks in MRNCL. To train each RBF network
after performing crossover and mutation, we only need
to perform a few scaled-conjugate-gradient updates (in
our experiments, only one scaled-conjugate-gradient update is employed) to simultaneously adjust the output
weights and the RBF centers and widths. This can be
performed quickly.
In MRNCL and MNCL, we perform three scaledconjugate-gradient (SCG) updates on each RBF network
in the initialization step. Since only one SCG update is
employed to simultaneously adjust the output weights
and the RBF centers and widths after crossover and
mutation, the total number of SCG is 3M + (2C + u)G =
10, 300 given that these parameters are set with the size
of population M = 100, the number of crossover in
one generation C = 20, the number of mutation in one
generation u = 10 and the number of generation G = 200
in this algorithm. The number of training epoches is
similar for different data sets.
In MoNN , the RProp+ algorithm is employed
to train neural networks. The population size is 100 the
maximal generation is 200. In each generation, MoNN
generates a new population of 100 offspring. With this
parameter setting, in total, it will call 100×200 = 20, 000
RProp+ algorithm. Note that RProp+ is implemented in
C++ and the training is faster than SCG.
Table 6 shows the average running time of MRNCL,
MNCL and MoNN over 100 runs. The running time is
the “training and evaluation” time (in seconds) of these
algorithm including MRNCL, MNCL and MoNN in one
run, which includes the execute time of the algorithm
in Figure 1 (for MRNCL) and the evaluation time to
calculate the error statistic on test set. The running time
in Table 6 is averaged over 100 runs. Note that the
running time is not CPU time since there are two CPUs
in our computational platform.
The computational environment is windows XP with
Intel Core 2 Duo 1.66G CPU and 2G RAM. The algorithms are implemented in Matlab and C language,
where C language is used for MATLAB MEX ﬁles to
implement the RBF network training algorithm and nondominated sorting algorithm. From Table 6, MRNCL and
MNCL consume similar computational time and MoNN
takes less time because MoNN is implemented by C++
and our algorithm is programmed by MATLAB. In fact,
if MRNCL is implemented by C++, it will cost less time
than MoNN since the RBF training is faster than MLP.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
Authorized licensed use limited to: University of Leeds. Downloaded on March 12,2010 at 12:48:43 EST from IEEE Xplore. Restrictions apply.
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X, XX 200X
Friedman tests with the corresponding post-hoc tests, Bonferroni-Dunn, to compare estimators and classiﬁers for
multiple data sets. The signiﬁcance level is 0.05, and q0.05 = 2.394.
Algorithms
Friedman test
Test Results
Running Time of MRNCL, MNCL and MoNN using different data sets in seconds. Results are averaged over 100
CONCLUSIONS
This paper analyzes NCL and points out that NCL is
prone to overﬁtting the noise because NCL does not regularize its complexity. We have proposed a new multiobjective regularized NCL (MRNCL), which incorporates
an additional regularization term for NCL. This paper
adopts a multiobjective algorithm and treats the training
MSE, regularization and correlation as three separate
objectives.
In MRNCL, the crossover and mutation operators are
deﬁned to vary the structure of RBF networks. The nondominated sorting algorithm with ﬁtness sharing and
rank-based ﬁtness assignment are employed to promote
diversity in MRNCL.
Several experiments have been carried out to evaluate
MRNCL. The experiments on four synthetic classiﬁcation problems demonstrate the behavior of MRNCL,
MNCL and MoNN. These results showed clearly about
the advantages and effectiveness of MRNCL due to
its regularization term for noisy data. The higher the
noise level, the better MRNCL’s performance is in comparison with MNCL. The experiments also show that
MoNN tends to over-regularize the ensemble and thus
degrade the performance. The experiments on two additional classiﬁcation problems with different noise levels
demonstrate further that MRNCL achieves better performance than MNCL, especially when the noise is nontrivial in data sets.
Then, we carry out extensive experiments on 16 benchmark classiﬁcation data sets to compare the performance
of MRNCL, MNCL and other state-of-the-art algorithms.
MRNCL performs quite favorably on these data sets.
The three major reasons why the performance of our
algorithm was so good are given in this paper. 1) Effective parameters of the RBF ensemble, obtained by
the evolutionary algorithm, improve the performance of
ensembles. 2) The multiobjective algorithm promotes the
accuracy, diversity and regularization in the ensemble. 3)
The best tradeoff of the three objectives can be achieved
by constructing an ensemble generated by multiobjective
algorithm.
In , Chen et al. demonstrated that the performance
of the ensemble can be improved by selecting a small
subset of ensemble members using a probabilistic ensemble pruning method. It is one of our future work to
incorporate the ensemble selection/pruning algorithms
into the multiobjective ensemble learning algorithms to
generate more compact ensembles.
Other future work for this study includes a more
in-depth study of different evolutionary operators and
other ﬁtness ranking methods used in the multi-objective
evolutionary algorithms.
ACKNOWLEDGMENT
This work is partially supported by a Dorothy Hodgkin
Postgraduate Scholarship to the ﬁrst author and an
EPSRC grant (GR/T10671/01) to the second author.
The authors also thank Dr. Yaochu Jin for providing
the source code on regularizing neural networks using
multi-objective evolutionary algorithms for comparison with our algorithm.
APPENDIX A
BAYESIAN INTERPRETATION OF MRNCL
This subsection describes the probabilistic interpretation
of MRNCL and the function of the regularization term.
Given the training set D = {xn, yn}N
n=1, we follow the
standard probabilistic formulation and assume that the
targets are sampled from the model with additive noise:
yn = fens(xn) + en = 1
fi(xn) + en,
where en is independent sample from some noise process which is further assumed to be mean-zero Gaussian
with variance β−1.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
Authorized licensed use limited to: University of Leeds. Downloaded on March 12,2010 at 12:48:43 EST from IEEE Xplore. Restrictions apply.
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X, XX 200X
According to the Bayesian theorem, given the hyperparameters μ = (μ1, · · · , μM)11 and β. We obtain the
weigh parameters w = (wT
1 , · · · , wT
M)T by maximizing
the posterior P(w | D).
P(w | D) = P(D | w,β)P(w | μ)
P(D | μ, β)
where the probability P(D | μ, β) is a normalization
factor which is independent of w.
The weight vector of each network wi is assumed to
have a Gaussian distribution with zero mean and variance μ−1
i . The prior of the weight vector w is obtained
as follows.
P(w | μ) =
where ni is the total number of weights in network i.
Since noise en follows a Gaussian distribution with
zero mean and variance β−1, the likelihood P(D | w,β)
can be written as
P(D | w,β) =
We omit all constants and normalization factor, and
apply Bayesian rules:
P(w | D) ∝exp
Taking the negative logarithm, the maximum of the
posteriori model parameters w is obtained as the solution to the following optimization problem:
(fi(xn) −yn)2 −
(fi(xn) −fens(xn))2 +
where αi = μi/β. We substitute μi and β with one parameter αi because the minimization of J1 only depends
on the ratio αi = μi/β.
Comparing Equation (15) with (4), MRNCL is equivalent to maximization of the posterior under Bayesian
framework when λ = 1. The likelihood P(D | w,β)
corresponds to the empirical training error terms and the
prior over weight vector P(w | μ) corresponds to the
regularization term. The regularization term penalizes
11. μi, i = 1, 2, · · · M, is the inverse variance of the Gaussian
distribution of weights for network i.
A 2 × 2 table of the relationship between a pair of
classiﬁers fi and fj. N ab is the number of data points for
which fi and fj are correct/wrong when a = 1/0 and
fj correct(1)
fj wrong(0)
fi correct(1)
fi wrong(0)
large weights, causing the weights to converge to smaller
absolute values than they otherwise would.
Based on the above analysis, MRNCL is an application
of Bayesian framework in ensemble system.
APPENDIX B
Q STATISTICS
Yule’s Q statistics computes the “coefﬁcient of association” for two classiﬁers, fi and fj, is
Qi,j = N 11N 00 −N 01N 10
N 11N 00 + N 01N 10 .
Q statistics varies between -1 and 1. For statistically
independent classiﬁers, the expectation of Qi,j is 0.
Classiﬁers that tend to classify the same objects correctly
will have positive values of Q, and those which commit
errors on different objects will produce negative Q value.
For an ensemble of M classiﬁers, the average Q statistics
over all pairs of classiﬁers is,