Purdue University
Purdue University
Purdue e-Pubs
Purdue e-Pubs
Department of Computer Science Technical
Department of Computer Science
Evaluating Probabilistic Queries over Imprecise Data
Evaluating Probabilistic Queries over Imprecise Data
Reynold Cheng
Dmitri V. Kalashnikov
Sunil Prabhakar
Purdue University, 
Report Number:
Cheng, Reynold; Kalashnikov, Dmitri V.; and Prabhakar, Sunil, "Evaluating Probabilistic Queries over
Imprecise Data" . Department of Computer Science Technical Reports. Paper 1544.
 
This document has been made available through Purdue e-Pubs, a service of the Purdue University Libraries.
Please contact for additional information.
Evaluating Probabilistic Queries over Imprecise Data'
Reynold Cheng
Dmitri V. Kalashnikov
Sunil Prabhakar
Department of Computer Science, Purdue University
Email: {ckcheng,dvk,sunil}@cs.purdue.edu
Figure 1: EXlUIIple of sensor data and uncertainty.
This inherent uncertainty of data affects the accuracy of
a.nswers to queries. Figure l(a) illustrates a query that determines the sensor (either x or y) that reports the lower
temperature reuding. Based upon the data available in the
database (xo and Yo), the query returns liZ" lIS the result.
In reality, the temperature readings could bave chnnged to
values Xl lUld Yh in which case "y" is the correct answer.
This example demonstrates that the database does not always truly capture the state of the external world, Wld the
value of the sensor readings can change without being recdetect if hazardOiL" materials are present and how they are
spreading.
In a moving object database, objects are constantly monitored and a central database may collect their
updated locations.
The frllmework for many of these applicntions iucludes
a database or server to which the readings obtained by the
sensors or the locations of the moving objects arc scnt. Users
query this database in order to find information of interest.
Due to several factors such lIS limiled network bandwidth
to the server and limited battery power of the mobile device, it is often infeasible for the database to contain the
exnct status of Il1\ entity being monitored at every moment
in time. An inherent property of these applications is that
readings from scnsors are sent to the central server periodically. In particular, at any given point in time, the recorded
sensor reading is likely to be different from the actual value.
The correct volue of a sensor's rending is known only when
an update is received. Under these conditions, the data in
the database is only an estimnte of the actual stale of the
environment at most points in time.
c:J Boundfor f:U~nt "0111"
R"cord"d "olue
Possib/" cuTT",rl \'Qlu"
Many applications employ sensors for monitoring entities
such iLS tempernture and wind speed. A centralized datahnse
tracks these entities to enable query processing. Due to continuous changes in these values llJ1d limited resources (e.g.,
network bandwidth and battery power), it is often infeasible to store the exact values at all times. A similar situation
exists for moving object environments that track the constantly changing locations of objects. In this environment,
it is possible for dotahose queries to produce incorrect or
invulid results based upon old data. However, if the degree
of error (or uncertllinty) between the actual value and the
database value is controlled, we cun place more confidence
in the ilIlSWCf'S to queries.
More generally, query IlII5WCrs
cun be augmented with probabilistic estimates of the validity of the answers.
Tn this chapter we study prohabilistic
query evaluation based upon uncertain data. A classification of queries is made based upon the nature of the result
For each class, we develop algorithms for computing
probabilistic ans....-ers.
We address the important issue of
measuring the quality of the answers to these queries, and
provide algorithms for efficiently pulling data from relevant
sensors or moving objects in order to improve the quality of
the executing queries. Extensive experiments are performed
to examine the effectiveness of several data update policies.
In many npplications, sensors are used to continuously
track or monitor the status of an environment.
from the sensors are sent back to the applicatioll, and decisions are mnde based on these readings. For example, temperature sensors installed in a building are used by n central
air-conditioning system to decide whether the temperature
of any room needs to be adjusted or to detect other problems. SeDSOre distributed in the environment can be used to
'" Portions of this work were supported by an Intel Ph.D.
fellowship, NSF CAREER grant IIS-9985019, NSF grant
OOlO044-CCR
INTRODUCTION
Permission [0 make digilal or hard copies of all or part of this work for
pernllllli or classroom usc is grn!ted without fee provided W[ copies are
not made or distributed for profit or commercial adv'llllagc and W[ copies
bearthis notice and the full eiL:llion on the firsl p:1gc. To copy oLheTWise, 10
n:publish, to paSt on servers orto redistribute [0 lislS, requires prior specific
permission llrldlor a fee.
SIGMOD 2003, June 9-12, San Diego, CA.
Copyrighl2003 ACM 1-58113-6)4·XI03J06 ...S5.00.
ognized by the database. Sistln et. al. [ltl! identify this type
of data as a dynamic attribute, whose value cho.nges over
time even if it is not explicitly updated in the database. In
this example, because the exact values of the data items are
not known to the database between successive updates, the
database incorrectly assumcs that the recorded value is the
actual value and produces incorrect results.
Given the uncertainty of the data, providing meaningful
answers seeIIlli to be a futile exercise. However, olle can argue that in mally applications, the values of objects cannot
change drastically in a short period of time; instead, the degree and/or rate of change of an object may be constrained.
For example, the temperature recorded by a. sensor may not
change by Inore than a degree in 5 minutes. Such informa·
tion can help solve the problem. Consider the above exo.mple
again. Suppose we can provide a guarantee that at the time
the query is evaluated, the o.ctual values monitored by x and
y could be no more than some deviations, dz and dw, from
xo and Yo, rcspectively, as shown in Figure l(b). With this
information, we can state with confidence that x yields the
minimum value.
In general, the uncertainty of the objects may not allow us
to identify a single object that has the minimum value. For
example, in Figure l(c), both x and y have the possibility of
recording the minimum value since the reading of x may not
be lower than that of y. A similar situation exists for other
types of queries such as those that request a numerical value
~What is the lowest temperature reading?"). For these
queries too, providing a single value may be infeasible due to
the uncertainty in eacl1 object's value. Instead of providing
a definite answer, the database can associate diIIerent levels
of confidence with each answer (e.g. as a probability) based
upon the uncertainty of the queried objects.
The notion of probabilistic answers to queries over uncertain data has not been well studied. WolfSOil et. 0.1 briefly
touched upon this idea [161 for the case of range queries in
the context of a moving object database. The objects are assumed to move in straight lines with a known average speed.
The answers to the queries consist of objects' identities and
the probability that each object is located in the specified
range. In this chapter we extend the notion of probabilistic queries to cover 0. mtlch brouder cluss of queries.
class of queries considered includes aggrego.te queries that
compute answers over 0. number of objects.
We also discuss the importance of the nature of onswer requested by n
query (identity of object versus the vnJue). For example, we
show tho.t there is a significant difference between the following two queries: "Which object has the minimum temperoture?" versus "Who.t is the minimum temperature?".
Furthermore, we relax the model of uncertainty so thnt any
rco.sonoble model co.n be used by the opplication. Our techniques o.re opplicable to the common models of uncertainty
thot hove been proposed elsewhere.
The probabilities in the answer allow the user to place
appropriate confidence in the answer as opposed to having
an incorrect answer or no answer at all.
Depending upon
the application, one may choose to report only the object
with the highest probability as having the minimum vo.lue,
or only those objects whose probability exceeds a minimum
probability threshold.
Our proposed work will be able to
work witb any of these models.
Answering aggregate queries (such as minimum or average) is much more challenging than range queries, especinlly
in the presence of uncertainty. The answer to a probabilistic
range query consists of a set of objects along with 0. non-zero
probability tlmt the object lie; in the query range. Each object's probability is determined by the uncertainty of the
object's value and the query range. However, for aggregate
querics, the interplay between multiple objects is critical.
The resulting probabilities are greatly influenced by the uncertainty of attribute valnes of other object..~. For example,
in Figure l(c) the probability thot x has the minimum vnlue
is affected by the relative value and bounds for y.
A probabilistic answer also
reflecL~ a certain level of uncertainty that results from the uncertainty of the queries object values. If the Wlcertainty of all (or some) of the object..~
was reduced (or eliminated completely), the uncerto.inty of
the result improves. For e:'{ample, without any knowledge
ahout the value of an object, one could arguably state that
it fnlls within a query range with 50% probability. On the
othcr hand, if lhe value is known perfectly, one can state
with 100% confidence that the object either falls within or
outside the query range. Thus the quality of the result is
measured by degree of ambiguity in the ans....-er. We therefore need metrics to evaluate the quality of a probabilistic
We propose metrics for evaluating the quality of
the probabilistic answers in this chapter.
As we sholl sec,
it turns out that different metrics are suitable for different
classes of queries.
It is possible that the quality of a query result may not be
acceptable for certain applications - a more definite result
may be desirable. Since the poor quality is directly relnted
to the uncertainty in the object values, one possibility for
improving the re:>ults is to delay the query until the quality
improves. However this is an unreasonoble solution due to
the increased query response time.
Instead, the dntaba.se
could request updates from all objects (e.g. sensors) - this
solution ineurs a heavy load on the resources. In this chopler, we propose to request updates only from objects that ore
being queried, and furthermore those that are likely to improve the quality of the query result. We present n number
of heuristics and an experimental evaluation. These policies
attempt to optimize the use of the constrained resource (e.g.
network bandwidth to the server) to improve average query
It should be noted that the imprecision in the query answers is inherent in this problem (due to uncertainty in the
nctuol vulues of the dynamic attribute), in contrast to the
problem of providing approximate answers for improved performance wherein accuro.cy is tro.ded for efficiency.
To sum up, the contributions introduced in this chapter
• A broad classification of probabilistic queries over uncertain data, based npon a Aexible model of uncertainty;
• Teclmiques for evaluating probabilistic queries, including optimizations;
• Metrics for quantifying the quality of answers to probnbilistie queries;
• Policies for improving the quality of answers to probabilistic qucries under resource constraints.
The rest of tlLis chapter is organized as follows. In Seetion 2 we describe a general model of uncertainty, and the
concept of probabilistic queries.
Sections 3 and 4 discuss
the algorithms for evaluating different kiuds of probabilistic
queries. Section 5 discusses quality metrics that are appropriate to these queries, Section 6 proposes update policies
that improve the query answer quality. We present an e.xperimental evnluation of the effectivcness of these update
policies in Section 7. Section 8 discusses related work and
Section 9 concludes the chapter.
PROBABILISTIC QUERIES
In this section, we describe the model of unccrtainty considered in this chapter. This is a generic model, as it can accommodate a large number of application paradigms. Based
on this model, we introduce a number of probabilistic qtleries.
Uncertainty Model
One popular model for uncertainty for a dynllIIlic attribute
is that at nny point in time, the actual value is within a certain bound, d of its last reported value. If the actual vnluc
changes further than d, then the sensor reports its new valuc
to the databasc and possibly ch1lllges d. For e,xample, [16J
describes a moving-object model where the location of an
object is a dynamic attribute, and an object reports its 10cntion to the server if its deviation from the last reported
location exceeds II. threshold. Anothcr model ~umes that
the attribute value changes with known speed, but the speed
mny change each timc the value is reported. Other model<;
include those that have no uncertainty. For example, in '
the exact speed and direction of movement ofeach object are
known. This model requires updates at. the server whenever
an object's speed or direction change.
For the plUpose of our discussion, the exact model of uncertainty is unimportant. AU that is required is that at the
time of query execution the rangc of possible values of the
attribute of interest are known. We are interested in queries
over somc dynamic attribute, n, of a set of database objects,
Also, we assume thll.t a is a real-valued attribute, although our models and algorithms can be extended to other
domains easily.
We denote the ith object of T by T. and
the value of II.ttribute a of Ti by T,.a (where i = 1, ... , IT!).
Throughout this chapter, we treat Ti.a at any time instant
t as a continuous mndom variable. Sometimes instead of
writing T•.a(t) meaning the value of the attribute at time
instant t we write just T;.n for short.
The uncertainty of
Ti.a(t) can be chnracterized by the following two definitions
(we use pdlto abbreviate the tena "probability density function"):
Definition /: An uncertainty intervul ofT•.a{t), denoted
by Ui(t), is on interval [li(t),U,(t)J such that li(t) and u;(t)
are real-valued functions oft, li(t) :5 Ui(t), and thll.t the con·
ditions Ui(t);::: li(t) and Ti.a(t) E [l;{t),u.;(t)] always hold.
Definition 2:
An uncertainty pdf
of TJ.a(t), denoted
by flex, t), is a pdf of Ti.a(t) such that hex, t) = 0 for
'<Ix r;. U;{t).
Notice that since fl(x,t) is a pdf, it has the property that
fl~(g) h (x, t)dx = 1. The ubove definition spccifies the uncertainty of n.a(t) in terms of a closed interval and the
probability distribution of T•.a(t). Notice that this definition does not specit"y how the uncertainty interval evolves
over time, and whnt the pdf Ii (x, t) is inside the uncertainly
intervn1. The only requirement for f;(x, t) is that its value is
ooutside the uncertainty interval. Usually, the scope of un·
certainty is determined by the last recorded value, the time
elapsed since its last update, and some application-specific
assumptions. For example, one may decide that U;{t) contains all thc values within a distance of (t-t"pdnlc) xv from
it,<; last reported value, where t"pdate is the time that the last
update was obtained, and v is the maximum rate of chlUlge
of the value. One may also specify that T,.a(t) is unlfonnly
distributed inside thc interval, i.e., fi(x, t) = If[u;(t) -li(t)]
for '<Ix E Ui(t), assuming that u.(t) > li(t). It should be
noted that the unifonn distribution reprcscnts the worstcase uncertainty over a given interval.
Classification of Probabilistic Queries
We now present a cla..'-sification of probabilistic queries
and example; of common representative qllCries for each
class. We identify two importunt dimensions for classifying
database queries. First, queries can be classified nccording
to the nature of the answers. An en/ity-bll5oo query returns
a set of objects (e,g., sensors) that satisfy the condition of
the query. A vClltlc-bll5ed query returns a single valuc, examples of which include querying the value of a particular
senoor, and computing the average value of a subset of sen·
sor readings. Thc second property for classifylng queries is
whether II.ggrcgat.ion is involved. We use the term aggregation loosely to refer to queries where interplay betwecn objects determines the result. In the following definitions, we
use the following nnming convention: the first letter is either
E (for entity-based queries) or V (for value-based queries).
1. Value-based Non-Aggregate Class
This is the simplest type of query in our discussions. It returns a.n attribute value of an object as the only answer, and
involves no aggregate operntors. One example of a probabilistic query for this cla.ss is the VSingleQ;
Definition 3: Probabilistic Single Value Query
(VSingleQ)
When querying Tk.a(t), a VSingleQ returns
bounds land u of an uncertainty region of n.n(t) and its
pdf h(x,t).
An example ofVSingleQ is "What is the wind speed recorded
by sensor sn?" Observe how this definition expresses the answer in tenns of n bounded probabilistic value, instead of a
single vulue. Also notice that J;;c.<;> fi(X, t) ib; = 1.
2. Entity-based Non-Aggregate Class
This type of query returns II. set of objects, each of which
satisfies the condition(s) of the query, independent of other
objects. A typical example of this class is the ERQ, defined
Definition 4: Probabilistic Range Query (ERQ) Given
at time instant t a closed interval [I,uJ, where I,u E !R
and l .:5 u, an ERQ returns set R of alI tuples (Ti,p;),
where Pi is the non·zero probability that Ti.a(t) E [I, uJ,
i.e. R = ((n,Pi) : P; = P(Ti.a(t) E [I, un and pi > 0)
An ERQ returns a set of objects, tlugmented with probnbilities, thll.t sntisfy the query interval.
3. Entity-based Aggregate Class
The third class of query returns u set of objects which
satisfy an aggregate condition.
We present the definitions
of three typical queries for this class. The first tv.·o return
objects with the minimum or mnxim\lm value of Ti.a:
Definition 5: Probabilistic Minimum (MaximUIn) Query
(EMinQ (EMaxQ»
An EMinQ (EMaxQ) returns set R
of all tuples (Ti,Pi), where Pi is the non-zero probability
that Ti.a is the minimum (maximum) value of a among all
objects in T.
B....ntlf.,
C.n",'V,"",
----------- •• ->.
-._-------q _._------~:- ._-- -----------
-.~-------------.------------
A one-dimensional nearest lleighbor query, which rct\lms
object(s) having a minimum absolute difference of To.a and
a given value q, is also defined:
Definition 6: Probabilistic Nearest Neighbor Query
Given a value q E R, an ENNQ retums set R of
all tuples (Ti,Pi), where Pi is the non-zero probability that
ITi.a -ql is lhe minimum umong (111 objects in T.
Note that for all the queries we defined in tlLis class the
condition LT,ERP; = 1 holds.
4. Value-based Aggregate Class
The final class involves aggregate operators that return a
single value. Example queries for this class include:
Definlfion 7: Probabilistic Average (Sum) Query (VAvgQ
(VSumQ» A VAvgQ (VSumQ) returns bounds I and '1.1 of
an uncertainty interval and pdf fx(x) ofr.v. X representing
the average (sum) of the values of a for all objects in T.
Definition 8: Probabilistic Minimum (Maximum) Value
Query (VMinQ (VMaxQ» A VMinQ (VMaxQ) returns
bounds 1 and
'1.1 of an uncertainty interval and pdf fx(x)
of r.v. X representing the minimum (maximum) value of a
among all objects in T.
All tbese aggregate queries return answers in the fonn or a
pdf fx{x) and a closed interval [I, '1.1], such that.r fx{x)dz =
Table 2.2 summarizes the basic properties of the probabilistic queries discussed (1bove.
For illustrating the difference between probabilistic o.nd non-probabilistic queries,
the lost row of the table lists the forms of answers expected
if probability information is not augmented to the result of
the queries e.g., the non-probabilistic version of EMaxQ is
a q\lery that returns object(s) with maximum valUes based
only on the recorded voJues of T,.a.
It cun be seen that
the probabilistic queries provide more information on the
o.nswers than their non-probo.bilistic counterparts.
Example. We illustrate the properties of the probabilistic queries with a simple example. In Figure 2, readings of
four sensors SI,S2,53 and 54, each with a different uncertainty interval, are being queried at time t.
Assume that
readings of these sensors Sl{t), S2{t), S3{t), and S4{t) are
uniformly distributed on their uncertainty intervals [II, '1.11],
[12, '1.12], lb,u3l and [14, tJ4j. A VSingleQ applied on 84 (1t time
t gives us tbe result: [4, tJ4, f'4{X) = 1/('1.14 -14). When an
ERQ (represented by the interval (I, uJ) is invoked at time t
to find out how likely each reading is inside [I, '1.1), we sec that
the reading of Sl is always inside the intervoJ. It therefore
Figure 2: Illustrating the probabilistic queries
has a probability of 1 for satisfying the ERQ. The reading
of 54 is always outside the rectangle, thus it has a probability of 0 of being located inside [I, '1.1]. Since U2(t) a.nd U3 (t)
partially overlap [1,'1.1], 52 and S3 have some chance of satisfying the query. Tn this example, the resull of the ERQ is:
({51, 1), (52, 0.7), (53, 0.4)}.
In the same figure, nn EMinQ is issued at time I. We observe that 51 has a high probability of ho.ving the minimum
value, because a large portion of the Ul{t) has a smaller
value than the others. The reading of 51 has a higb chance
of being located in this portion because 51(t) has the unifonn
distribution. The reading of S4 does not have any chance of
yielding the minimum value, since none of the values inside
U4(1) is smaller than others. The result of the EMinQ for
tlLis example is: {(Sl' 0.7), (S2' 0.2), (53, 0.1)}. On the other
hand, an EMaxQ will return ({S-I' I)} as the only result
since every value in U4(t) is larger than any readings fron:
the other sensors, and we are assured tho.t 84 yields the max·
imum value. An ENNQ with a query value q is also shown,
where the results are:
({51, 0.2), (52, 0.5), (53,0.3)}.
When a value-based aggregate query is applied to the scenario in Figure 2, a bounded pdf p(x) is retumed.
VSumQ is issued, the result is a. distribution in [h +12 +b +
1-1, '1.11 + '1.12 + '1.13 + 'U.4}; each x in this interval is the sum of
the readings from the four sensors. The result of a VAvgQ
is n pdf in [(It + 12 + b + 14)/4, {UI + '1.12 + '1.13 + '1.14)/41. The
results of VMinQ and VMaxQ are probability distributions
in [lhud and [/4,'I.I4J respectively, since only the values in
these ranges have (1 non-zero probability value of sa.tisfying
the queries.
EVALUATING ENTITY- QUERIES
In this section we e."amine how the probabilistic entitybased queries introduced in the last section CIl.D be answered.
We start with the discussion of an ERQ, followed by a more
complex algorithm for nnswering an ENNQ. We also show
hoI\' the algorithm for answering an ENNQ cun be easily
changed for EMinQ and EMaxQ.
Evaluation ofERQ
Recall that ERQ returns a set of tuples (n,Pi) where Pi is
the non-zero probability that T;.a is within a given interval
Let R be the set of tuples returned by the ERQ.
The algorithm for evaluo.ting the ERQ at time instant t is
described ill Figure 3.
In this algorithm, ench object in T is checked once. To
evaluate p. for Ti, we first compute the overlapping interval
: 1 S; S T "Pi> 0
2. fori_Ito ITI do
(a) D _ Ui(t) n [I,uJ
(b) if (D # 0) then
i. Pi +- In fi(X,l) dx
ii. if Pi #0 then R -RU{{Ti,pi)}
3. return R
Figure 3; ERQ Algorithm.
D of the two intervals: Ui(() aud [I, uJ (Step 20.). If D is the
empty set, we are assured that Tj.a does not lie in [I, uj, and
by the definition of ERQ, Ti is not included in the result.
Otherwise, we calculate the probability that Ti.a is inside
[I, u] by integrating !i(X, t) over D, and put the result into
R if Pi # 0 (Step 2b). The set of tuples (1'l,pi), stored in R,
are returned in Step 3.
Evaluation ofENNQ
Processing an ENNQ involves evaluating the probability
of the attribute a of each object Ti being the closest to
(nearest-neighbor of) a value q. In general, this query can
be applied to multiple attributes, such as coordinates. In
pa.rticular, it could be 0. nearest-neighbor query for moving
objects. Unlike the case of ERQ, we can no longer determine
the probability for a object independent of the other objects.
Reco.lI that an ENNQ returns a set of tuples (Ti,Pi) where Pi
denotes the non·zero probability that Ti has the minimum
value of !Ti.a - ql. Let S be the set of objects to be considered by the ENNQ, and let R be the set of tuples returned
by the query.
The algorithm presented here consists of 4
phases: projeclJon, pruning, bounding and evalualion. The
first three phases filter out objects in T whose values of a
have no chance of being the closest to q. The final phase,
evaluation, is the core of our solution; for every object Tj
that remains after the first three phases, the probability that
T;.a is nearest to q is computed.
I. Projection Phase.
In this phase, the uncertainty interval of each Ti.a is computed based on the uncertainty model used by the application.
Figure 4(0.) shows the last recorded values of T;.a
in S at time to, and the uncertainty intervals are shown in
Figure 4(b).
2. Pruning Phase.
Consider two uncertainty intervals Ul(l) and U2(t).
the smallest distance between Udt) o.nd q is larger tho.n the
largest distance between U2 (t) and q, we can immedio.tely
conclude that T1 is not an answer to the ENNQ: even if
~:.·aIUi~·~IUi··_·[~-1f
q ai, :112.
Figure 4: Phases of the ENNQ algorithm.
thc actual value of T2.a is as fill' IlS possible from q, Tj.a
still has no chance to be closer to q than T2.a.
1. fori_l to lSI do
(a) if q E U;(t) then Ni _ q
i. if Iq -I;(t») < Iq - u;(t)1 then Ni +-li(t)
ii. else Ni +- u;(t)
(c) if Iq -l.(t)[ < Iq - ui(t)1 then Pi +- lli(t)
(d) else F; _l.(t)
2. f +- minl~i~ISdH- qli m _
3.fori_ltomdo
if(JN. -q[ > f) then S _S ..... {Ti}
4. return S
Figure 5: Algorithm for the Pruning Phll.ge of ENNQ.
thls observation, we can eliminate objects from T by the
algorithm shown in Figure 5. In this algorithm, Ni and Fi
record the closest and farthest possible vo.ll1t'S of Ti.a to q,
respectively. Steps 1(0.) to (d) assign proper values to N;
and Fi. If q is iru;ide the interval Ui(t), thcn Ni is taken
as the point q itself. Otherwise, Ni is either li(t) or lli(t),
depending on which V<llue is closer to q.
Pi is assigned in
II. similar mll.llller. After this phase, S contains the (possibly fewer) objects which must be considered by q. This is
the minimal set of objects which must be considered by the
query since lilly of them can have II. value of 11.a closest to
q. Figure 4{b) illustrates how this phase removes T~, which
is ilTelevll.llt to the ENNQ, from S.
3. Bounding Phase.
For each object ill S, there is no need to examine all portions in it." uncertainty interval. We only need to look ut the
regions that arc located no farther than f from q. We do
this conceptually by drawing a bounding interval B of length
2/, centered at q. Any portion of the uncertainty interval
olltside B can be ignored.
Figure 4(c) shows a bo\mding
interval with length 2f, and (d) illustrute the result of this
The phases we have just described attempt to reduce the
number of objects to be evaluated, and derive II.ll upper
bound on the range of values to be considered.
4. Evaluation Phase.
Based on S and the bounding interval H, our aim is to
calcula\..e, for each object in 5, the probability that it is the
nearest neighbor or q. In the pruning pha.se, we huve already
rOlmd Ni , the point in U,(t) nell.rest to q. Let us culllNi -qj
the nearAistance OrTi, or fli. Let as define new r.v. Xi such
2. Sort the elements in 8 in ascending order of ni, II.lld
rename the sorted elements in 8 as TI, Tz,·· . ,TISI
3. niSi+! +- f
4. for i +- 1 to 181 do
(a) Pi +-0
(b) for j +- i to 181 do
i. P +- f~J+1 I; (x) . nLI"k#i(l-F~.{x»ch
n. Pi +-Pi+P
(c) R of-- R U ({Ti,pi)}
5. return R
Figure 6: Algorithm for the Evaluation Phase ofENNQ.
that Xi = ]T..a{t) - ql. Also, let Fi(X) be the Xi'S cdf, i.e.,
F,{x) = P(IT,.a(t) - ql :5 x), and f;(x) be its pdf. Figure 6
presents the ulgorithm for this phase.
Note that if T,.a(t) hIlS no uncertainty i.e., Ui(t) is exactly
cqulll to Ti.a(t), the evaluation ph(l.5C n1gorithm needs to
be modified.
Our technical report [21 discusses how this
n1gorithm can be changed to oonpt to such situntions.
the rcst of this section, we will explain how the evaluation
phllSe works, ossuming non-zero uncertainty.
Evaluation of F;(x) and f;(x)
To understand how the
evnlulltion phase works, it is crucial to know how to obtain
FI(x). As introduced before, Fi(X) is the cdf of Xi, and thus
Fi(X) ~ P{ITI.a(t) - ql:5 x). We illustrate the evnluation
of FI(x) in Figure 7.
Rccull that f,(x) is the pdf of X; and f;(x, t) is the pdr of
Ti.a(t). If FI(x) is (l. differentiable, li{X) is the derivative of
Evaluation of Pi'
We can now explain how Pi, the probability that T;.(1 is closest to q, is computed. In terms of X,'s
1. if x < n; return a
2. if x> Iq - Fil, return 1
3. D+-U;{t)n[q-x,q+x)
4. return fDf;(x,t)dx
Figure 7: Computation of F';(;r:).
the question is formulated as how Pi, the probability that
X, has the minimum value among all Xi'S, is computed.
Let j;(x) dx for indefinitely small dx be the probability
that (1) Xi E [x,x+dx] and (2) Xi = minl:!>k'::;ISIXIo. Then
Equation 1 outlines the structure of O\lr solution:
The ii(X) r1x is equal to probability P(X; E [x, x+dxll times
the probability that Xi is the minimum among the ntl X;s.
The former probability is equal to fi{X)dx since f;(x) is
Xi'S pdf. The latter probability is equal to the probability
that each Xi in 8 except for Xi have values greater than
Xi, which equals to nLs21"k;iiP(Xk > x), which a!so can
be written os nL:lI"k;ii(1- FdX»). Thus the formula for
Pi can be written as:
Pi = l~f;{X) ~j~L(l- H(X») dx
Observe that each 1 - Fdx) term registers the probability
thut Tk.a is foxther from q than Ti.a.
Efficient Computation of Pi
The computation time
for Pi can be improved. Note that Fk(X) has a value of a if
x < nk. This means if x < nk then 1-Fk(X) is always 1, and
Tk hIlS no effect on the computation of Pi. Instead of always
considering 181 -
1 objects in the n term of Equation 2
throughout [ni,f]' we may actually consider fewer objects
in some ranges, resulting in a hetter computation speed.
This can be achieved by first sorting the objects according
to their near_distance from q. Next, the integration intervnl
[ni,/J is broken down into a number of intervuls, with end
points defined by the neaT_distance of the objects. The probability of an object having a value of a closest to q is then
evaluated for each interval in t1 wny similar to Equution 2, except that we only consider n.n with non-zero Fk(x). Then
p; is equal to the sum of the probability values for ull these
intervals. The final fonnula for PI becomes:
Pi = ~l:1+I;(X)~JIJ1 - Fk(X») ax
Here we let nlSI+J he f for notational convenience. Instead of considering lSI - 1objects in the n tenn, Equation 3 only handles j -1 objects in interval [ni' ni+11. This
optimization is shown in Figure 6.
Let us use our previous example to illustrate
how the evaluation phase works. After 4 objects TI, . .. ,T4
were cnptured (Figure 4(d)), Figure 8 shows the result after
these objects have been sorted in ascending order of their
near_distance, with the x-axis being the absolute difference
The lower (upper) bound of the integration interval are evaltlated according to the possible minimum (maximum) value
We can generalize this result for summing the uncertainty
intervals of 11'1 objects by picking two intervals, swnming
them up using the nhove formula, and using the resulting
illterv-dl to add to another interval. The process is repeated
until we finish adding all the intervals. The resulting interval
should have the following form:
[LI;(t), L
Figure 8; Illustrating the evaluation phase.
EVALUATING VALUE- QUERIES
In this section, we discuss how to answer the probabilistic
value-based queries defined in Section 2.2.
Evaluation of VSingleQ
Evaluating a VSingleQ is simple, since by the definition
of VSingleQ, only one object, Tk, needs to be considered.
Suppose VSingleQ is executed at time t. Then the answer
returned is the uncertainty information of Tk.a at time t,
I.e., lk(t), Uk(t) and its pdf !k(x, t).
Evaluation of VSumQ and VAvgQ
Let us first consider the case where we wnnt to find the
swn of two uncertainty intervols {it(t), Ul(t)] a.nd (h(t), U2(t)j
for objects 1'1 and T2 •
Notice that the vuJues in the answer that have non-zero probability values lie in the range
[h(t) + I2(t),ul(t) + U2(t)]. For any x inside this interval,
Ix(x) (the pdf of random variable X = 1'1.a + T2.a) is:
fx(x) = {;
j,(x, t~Jl,.(I-Pk(X,t))
,"Ix E [lj,li+d, I $. i :5 181
Also notice that if x E [lj, lj+l) and k > i, then f;(x, t) = O.
Thus fonnuln for fx(x) can be written as;
Ix(x) =t (J;(x, t~Jl"(I-Pdx,t))), "Ix E [1j,lj+lJ,1 :5 j :518J
fx(x) = ~(fi(X,t)kj~tJI-Pk(X,t)) ), "Ix E [I,u) (5)
Since if x E [lj,Ii+t) and k > i, then Pk(x, t) = 0, therefore terms (1- Pdx, t)
are equal to 1 for such x's and k's
and need not be considered by the fonnula. The Simplified
formula is thus:
VAvgQ is essentially the same as VSumQ except for II. division by the llllmher of objects over which the aggregation is
Evaluation of VMinQ and VMaxQ
To 811:.wer a VMinQ, we need to find the bounds of uncertainty region [I, uJ, a11d pdf fx (x) of r.v. X = mill1:>iSITI T; .a(t).
Like for EMinQ the lower bound I can beset as minl:Si:SISlli(t)
and upper bound U as mill1:>iSlsl Ui(t), because X cannot
take values outside [I, ul The steps of the algorithm are similar to first three phases of ENNQ (projection, pruning,
botmdillg) when q is set to be equal to I. Each Ti such that
li(t) > u is removed from set S of the relevant tuples. Then
all tuples in S are sorted in ascending order of I;. For notational convenience we introduce an additional parameter
IISI+1 nnd set it equal to u.
To compute fx(x) notice that probability P(X E [x,x+
dx]) for some small dx can be computed as sum of probabilities for each Ti.a(t) to be inside [x, x + dx] times the
probability that the other Ti.a(t)'s are in (x+ dx, +=). As
we tend dx to zero we bave:
VMaxQ is handled in an analogous fashion.
QUALITYOFPROBABILlST1CRESULTS
In this section, we di.scuss several metries for measuring
the quality of the results returned by probabilistic queries.
It is interesting to see that different metries are suitable for
different query classes.
Entity-Based Non-Aggregate Queries
For queries that belong to the entity-bll.Sed non-aggregate
query class, it suffices to define the quality metric for ea.ch
min.{Lo,(Cl,:Z:-I,(tlJ
h(y,t)h(x-y,t)dy
ma:z:{ll (l),:Z:-U2(t)}
Evaluation of EMinQ and EMaxQ
We ean treat E:M.inQ and EMaxQ as special cases of ENNQ.
In fact, answering an EMinQ is equivalent to answering an
ENNQ with q equals the minimum lower bound of all Ui(T)
We can thererore modify the ENNQ algorithm to
solve an EMinQ as follows: after the projection phase, we
evaluate the minimum value of li(t) among nil uncertainty
intervals. Then we set q to that value. We then obtain the
results to the EMinQ after we execnte the rest of the ENNQ
algorithm. SolVing an EMaxQ is symmetric to solving an
EMinQ in which we set q to the maximum of Ui(t) after the
projection phase of ENNQ.
of Ti.a hom q, and "5 eqmlls f. The probability Pi of each
Ti.a being the nearest neighbor of q is equal to the integral
of ji(X) over the interval [m, n5].
Let us see how we evaluate uncertainty intervals when
computing P2. Equation 3 tells us that P2 is evaluated by
integrating over [n2' n5]. Sinee objects are sorted according
to ni) we do not need to consider all 5 of them through.
out [n2' TIs]. Instead, we split [n2, ns] into 3 sub-intervals,
namely [n2,n3), [n3' 114 1 and [n4,ns], and cOllSider possibly
fewer uncerlainty intervals in each sub-interval. For example, in [n2' n3], only Vl and U2 need to be considered.
Figure 9: Illustrating how the entropy and the width of
B affect the quality ofanswers for entity-based aggregate
queries. The four figures show the uncertainty intervals
(Ud/o) and U2(/o)) inside B after the bounding phase.
Within the same bounding interval, (b) has a lower entropy than (a), and (d) has a lower entropy than (c).
However, both (c) and (d) have less uncertainty than (a)
and (b) because of smnller bounding intervals.
Y take vahle i with probability Pi if und only ir (Ti,Pi) E R.
The propert.y t.hat E?=I Pi = 1 holds. Then H(Y) measures
the unccrtainty of the answer to these queries; the lower the
value of H(Y), the more certain is the answer.
Bounding Interval.
Uncertainty of an answer also depends on another important ractor: the bounding interval B.
Recall tlmt before evaluating one of these aggregate queries,
we need to find B tlmt dictates all possible values we have to
consider. Then we consider all the portions of uncertainty
intervals that lie within B. Note that t.he decision of which
object satisfies the Qnery is only made wit.hin this interval.
Also notice that. the width of B is dctermined by t.he width
of the uncertaint.y intervals associated with objects; a large
width of B is the result. of large uncertainty intervals. Therefore, if B is small, it indicates t.hat. the uncertainty intervals
of objects that participate in the final result. of t.he query are
also small. In thc extrcme Cllsc, when the uncertainty intervals or participant objects have 7.ero width, then the width
of B is zero too. The width of B therefore gives us a good
indico.tor or how uncertain 11 query answer
An example at this point will make our discussions clear.
Figure 9 shows four different scenarios of two uncertainty intervnls, Ul (tol and
V~(to), after the bounding phase for un
EMinQ. We can sec that in (a.), Ul (to) is thesa.me as V~(tO).
If we assume a uniform distribution for both unccrtainty intervnls, both Tl and n will have equal probability of having
the minimum value of a. In (b), it is obvious thaL T~ has
n much greater chance than Tl to ho.ve the minimum value
of a. Using Equation 10, we can observe that the answer
in (b) enjoys a lower degree of uncertainty than (n). In (c)
and (d), all the uncertainty intervllls are halved of those in
(a) and (b) respectively. Hence (d) still has a lower entropy
value than (c). However, since the uncertainty intervals in
(c) and (d) are reduced, their answers should be more certain than those of (a) and (b). Notice that the widths of B
for (c) and (d) are all less than (a) and (b).
The QualiLy of entity-bused aggrega.te queries is thus decided by two factors:
(1) entropy H(Y) of the result set,
and (2) width of B. TIleir scores are defined as follows:
......~! ."
In Equation 8, we measure the difference betwccn Pi and
0.5. Its highest value, which equals 1, is obtained when Pi
equal" 0 or I, and its lowest. vnlue, which cqunls 0, occurn
when P; eq\lllls 0.5.
Hence the v-diue of Equation 8 varies
between °to 1, and a large value represents good quality.
Let us now define the score of an ERQ:
1 ,,[p, - 0.51
Score of nn ERQ = ]RI L..-
(Ti, Pi) individually, independent of other tuples in the result. This is because whethcr nil object satisfies the query
or not is independent of the presence of other objects. We
illustrate this point. by expluining how the metric of ERQ is
For an ERQ with query r(lnge (I,ul, the re:>ult is t.he best
if we llIe sure either T;.(l is completely inside or outside [I, ul·
Uncertainty arise:;- when we are less than 100% sure whether
the value of Ti.a is inside [I, ul. Wc arc confident that T;.a
is inside [I,ul if a large part of V;(t) overlaps [I,u] I.e., Pi
is large. Likewise, we are also confident that Ti.a is ouwide
[I, uJ if only ll. very small portion or Viet) overlaps [I, u] Le.,
Pi is small. The worst case happens when Pi is 0.5, where
we cannot tell if Ti.a satisfies the range query or not. Hence
a reasonable metric for the quality of Pi L,,:
where R is t.he set of tuples (Ti.a,Pi) returned by an ERQ.
Essentially, Equation 9 evaluates the average over all tuples
Notice that. in defining the metric of ERQ, Equation 8 is
defined for each Ti, disregarding other objects. In general,
to define quality metries for the entity-based non-aggregate
query dEISS, we can define the qtlaIity of each object individually. The overall score can then be obtained by averaging
the quality value for each object.
Entity-Based Aggregate Queries
Contnuy to an entity-based non-aggregate query, we observe that for an entity-based nggrega.te query, whether an
object appears in the result depends on the existence of
other objects. For example, consider the following two sets
ofanswers to an EMinQ: {(n.a,D.6), (T2 .o, 0.4)} and {(TI.a,D.G),
(n.a,O.3), (T3.a,0.1)}. How can we tell which answer is better? We identify t.wo important components of qualit.y for
this class: entropy and interval width.
Let r.V. X take values Irom set {Xl, ... , xn.} with
respective probabilities p(XI), ... , p(x,,) such that E~=l p(Xi) =
1. The entropy of X is a measure H(X):
H(X) = 8P(X;) log2 p(Xi)
If Xi'S llIe treated as messages and p(Xi)'S as their probability to appear, then the entropy H(X) mC&'>uteS the average
number of bits required to encode X, or the amount of infonnation carried in X (13). If H(X) equals 0, there exists
some i such that p(Xi) = I, and we are certain that Xi is the
mc:ssnge, and there is no uncertainty llSSOciatcd with X. On
the other hand, H(X) attains the maximum value when all
the messages are equally likely, in which case H(X) equals
Recall that the result to the queries we defined in tills class
is returned in a set R consisting of tuples (Ti,pi). Let r.v.
Value-Based Queries
Recall that the results returned by value-based queries are
all in the fonn an uncertainty interval [I, uj, and pdf f(x). To
measure the qllality of such queries, we can use the concept
of entropy 01 a continuous di5tribu/l0n, defllled as follows:
Score of an EntiLy, Aggr Query = -H(Y)· width of B
Notice that the query answer gets a. high score if either
H(Y) is low, or the width of B is low.
In particular, if
either H(Y) or the width of B is zero, lheu H(Y) = 0 is the
maximum score.
where H(X) is the enLropy of continuous random variable
X with pdf I(x) defined in the interval [I, ul [13J. Similar
to the notion of entropy, H{X) measures the uncertainty
nssocinted with the value of X.
Moreovcr, X attains the
maximum value, 1092(u-I) when X is uniformly distributed
in [I,u). Entropy fleX) can be negative, e.g. for uniform
r.v. X", UfO, ~l.
We use the notion of entropy of a continuous distribution
to measure the quality of value-based queries. Specifically,
we apply Equation 12 to f(x) as a measure of how much
uncertainty is inherent to the answer of a value-based qucry.
The lower the entropy vnlue, the more certain.is the answer,
II.nd hence the better quality is the IlIiSWCr. We now define
the score of a probabilistic value-based query:
Score of a Value-Balled Query = -fl(X)
The quality of II. value-based query can thus be measured
by the uncertainty associated with its result: the lower the
uncertn.inty, the higher score can be obtained os indicated
by Equntion 13.
Ple85e notice that though not presented here m(l.fly more
different metrics from those discussed in these rCSCl.lrch are
possible; e.g. one might choose the standard deviation as a
metric for the quality of VMinQ etc.
flex) = -l~ I(x)logd(x)dx
object with the minimum value computed in Formuln 8, with
an attempt to improve the score of ERQ.
Improving the Quality of Other Queries Several update policies are proposed for queries other thllJ1 ERQ;
1. Glb..RR. This policy updates the database in a roundrobin fashion using the available bandwidth i.e., it update; the data itcms olle by one, making sure that each
item get.<; a fair chance of being refreshed.
2. Loc..RR.
This policy is similar to Glb_RR, except
tlml the round-robin policy is applied only to the data
items that are related to the query, e.g., the set of objects with \lllcertainty intervals overlapping the bounding interval of an
3. MinMin.
An object with its lower bound of the
uncertainty imerv-dl equal to the lower bound of B is
chosen for update. This attempts to reduce the width
of B and improve the score.
4. MaxUnc.
This heuristic simply chooses the \lllCertainty interval with the maximum width to \lpdate,
with an attempt to reduce the overlapping of the uncertainty intervals.
5. MinExpEntropy.
Another heuristic is to check, for
each Ti.a that overlaps B, the eIIect to the entropy if
we choose to updnte the value of Ti.a. Suppose once
Ti.a is updated, its llllcertmnty interval will shrink to
a single value. The new uncertainty is then a point in
tbe uncertainty interval before the update. For each
value in the uncertainty interval before the update, we
evaluate the entropy, assuming that Ui(t) shrinks to
that vll1ue nItcr the update. The metul of these entropy
values is then computed. The object that yields the
minimum expected entropy is updated.
EXPERIMENTAL RESULTS
In this section, we experimentll1ly study the relative behaviors of the various update policies described above, with
respect to improving the quality of the query results. We
will discuss the simulation model followed by the results.
IMPROVING ANSWER QUALITY
In tWs section, we disc::uss several update policies that
can be used to improve the quality of probabilistic queries,
defllled in the last section. We DSSUme that the sensor.> cooperate with the central server i.e., a sensor can respond to
update requests from the sensor by sending the newest value
to the server, as in the system model described in .
Suppose after the execution of a probabilistic query, some
slack time is nvoilable for the query. The server Ctul improve
the qunlity of the answers to that query by requesting updates from sensors, so that the uncertainty intervals of some
sensor data are reduced, potentially resulting in an improvement of the answer quality. Ideally, a system can demand
updates from all sensors involved in the querYi however, this
is not practical in a limited-bandwidth environment. The issue is, therefore, to improve the quality with as few updates
as possible. Depending on the types of queries, we propose
n number of update policies.
Improving the Quality of ERQ The policy for choosing
objects to update for an ERQ is very simple: choose the
Simulation Model
The evaluation is conducted using n discrete event simulation representing a server with a flxed network bandwidth (8
messages per second) and 1000 sensors. Each update from
a sensor updates the value nnd the uncertainty interval for
the sensor stored at the server. The uncertainty model used
in the experiments is
II.S follows;
An update from sensor
Ti at time tupdulc specifies the current value of the sensor,
Ti.a.~u, and the rnte,
T;.r.~u at which the uncertainty region (centered nt Ti.a.~U) grmvs. Thus at any time instant,
t, following the update, the uncertainty interval (U,(t)) of
sensor T; is given by Ti.a.~u ±Ti.r.~u x (t -T;.t~pd~tc). The
distribution of values within this interval is assumed to be
The actual value; of the sensors are modeled (L5 random
wnlks within the normalized domain
(L5 in [101. The maximum rate of change of individual sensors are unifonnly distributed between 0 and Rm"".
At any time instant, the
value of n sensor lies within its current uncertainty interval
specified by the last update sent to the server. An update
..... ······-O-MinMin
.....Ma>:-U""
increnses for nil policics, appronching the perfect score of
zero for EMinQ. This is e'Xplained by the fact that with
higher bandwidth the updates requested by the qucries urc
received fasler. Thus for higher bandwidth the uncertainty
regions for freshly updated sensors tend to be smaller thRll
those using lower bandwidth. Smaller wlcertainty regions
translate into smaller uncertainty of the result set, and consequently higher score. TIle reduction in uncertainty regions
with increasing bandwidth can he observed from Figure 12.
All schemes that favor updates for sensors being queried
significantly outperfonn the the only scheme that ignores
tItis information: GlbJUL The best perfonnance is achieved
by thc MinMin policy, which updates a sensor with the lower
bound of the Wlcertainty region lief) equal to the minimum
lower bound among all sensors considered by the query. The
MinExpEntropy policy showed worse results1 than the Minr..Hn and MaxUnc policies in Figures 10 and 12 and worse
results than those of the MinMin policy for VMinQ queries,
Figure H. When comparing the MinMin and MIl.XUnc policies, the bettcr score of the MinMin policy is explained by
the fact that the sensor picked for an update by the Min-
Min policy tends to have large uncertainty too - in fact, the
mcertainty intervnl is ut least as large as the width of the
bounding interval. In addition the v-dlue of its attribute a
tends to ho.ve higher probnbility of being minimum.
Response Time.
Figurc 13 shows response time as a
function ofavailable bandwidth for EMinQ. Unlike the other
experiments, in this experiment 0 query execution is stopped
as soon as the goal score g (-0.06) is reoched. Once o.gain
the MinMin strategy showed the best results, reaching the
goo.! score faster than the other policies. The difference in
response time is especially noticeo.ble for smaller values of
bandwidth, where it is almost twice as good as the other
stmtegies.
Predictably, the response time decreases when
more bandwidth becomes available.
Arrival Rate.
Figures 14 o.nd 15 show the scores achieved
by EMinQ and VMinQ queries for various update policies as
u function of query nrrivo.l rate >'q. As >'q increases from 5 to
25, more queries request updutes and reduce the uncertainty
regions. As a result, the uncertainty decreases, which leads
to better scores (Figure 16). When >'q reaches 25 the entire
network bandwidth is utilized. As >'q continue to incrCllSC
IThe experiment with bandwidth of 200 did not complete
in time for the submission. The filial version of the paper
will contain all results.
Figure 10: EMinQ score as function of B
Due to limited space, we only show the most important
experimental results. Interested readers are referred to our
technical report [21 for more detailed discussions of our experiments. All figures in this section show averages.
Bandwidth.
Figure 10 shows scores for EMinQ achieved
by various update policies for different values of bandwidth.
The quality metric in this case is negated entropy times the
size of the uncertainty region of the result set.
is annlogous to Figure 10 but shows scores for VMinQ instead of EMinQ. The score for VMinQ Queries is negated
continuous entropy.
In Figures 10 and
H, the scores increase as bandwidth
Simulation parameters and their default
Irom the sensor is necessitated when a sensor is close to the
edge of its current uncertainty region. Additionally, in order
to avoid excessively large levels of uncertainty, un update is
sent if either the total size of the uncertainty region or the
time since the last update exceed threshold vallles.
The repr~entativeexperiments presented considcred either EMinQ or VMinQ queries only.
In each experiment
the qllerie; arrive at the server following a Poisson distribution with arrival rate >'q.
Each query is executed over
a subset of the sensol1l. The subsets are selected randomly
following the 80-20 hot-cold distribution (20% of the sensors
are selected 80% of the time). The cardinality of each set
was fi'Xed at N~nb=100. The maximWll number of concurrent qllerie; was limited to N q = 10. Each query is allowed
to reqllcst at most N m .'1 updatcs Irolll sensors in order to
improve the quality of its result.
In order to study different aspects of the policics, query
tennination can be specified either as (i) a lixed time interval (Toc'inc) after which the query is completed even iI its
requested updates have not arrived (due to lletwork congestion) or (ii) when u turget qUlllity (9) is achieved. Depending upon the policy, we study either the average achieved
quality (score), the average size of the uncertainty region,
or the average response time needed to achieve the desired
quality. AU measurements were made after a suitable warm
up period had elapsed. For fairness of comparison, in each
experiment, the arrival of queries as well as the changes to
the sensor values was identical.
Tllble 7.1 summarizes the major parameters and their default values. The simulation parameters were chosen such
that llverage cardinality of the rcsult sets achieved by the
best updute policies was between 3 and 10.
II Pm= I Default I Meaning
Domain of attribute a
Maximum rote of chllIlge of a (sec-I)
Maximum # of concurrent queries
Query arrival rate (query/sec)
Cardinality of query subset
Query active time (sec)
Network bandwidth msg/sec)
Maximum # of updntes per query
The # of concurrent updates pcr query
,,~----------------~
.. ~------------------,
__••__•. ,__ ,__•__
_•••.•••.•••
............u""
......._.,,-,--,- --.--
Figure 11: VMinQ score as function of B
Figure 13: Response tilDe as function of B
"r-------------------
.L--~_~~____J
610'520~30"'''O<S
.............·(q<>OtY'-'1
-8-Glb_/IR
-ll-l.J>c_RR
•••••••••••••__•
..... ltIC_RR
-----------------------------_ ......Uro;;
.......MInE>;pEnU
Figure 12: Uncertainty as function of B
Figure 14: EMinQ score as function of ),q
queries are able to send fewer requests for updates and receive fewer updates in time, leading to poor result quo.lity
and larger uncertainty.
We can observe from Figures 14, 15, and 16 that the relative perfonTIancc of the various policies remain.s the same
over a wide range of arrival rates (..\'l E ).
The experiments show that all policies that favor querybased updates o.chieve much higher levels of quality. For the
queries considered, the MinMin policy gi...es the best pcrformance. Evaluution of the policies for all types of queries
is beyond the scope of this thesis. We plan to address this
issue as part of futurc work.
RELATED WORK
Many studies have focu55Cd on providing approximate aD-
SWCTE to database queries.
These techniques approximate
query results hased only upon a subset of data.
Vrbsky et. al studied how to pro...ide approximate answers
to set,.vaIued queries (where a query unswer contains a set
of objects) and single-...alued queries (where a query answer
contains a singlc value). An exuct answer E can be approximated by two sets: a certain set C which is the subset of
E, and a possible set P such that CUP is a superset of
E. Unlike our assumptions, thcir model a.ssuIn(5 there is no
uncertainty in the attribute values.
Other techniques usc
precomputation (11], sampling and synopses [ll to produce statisticul results. While these efforts in...estigate OJ)proximate unswers based upon a subset of the (exact) values
of the data, om work addresses probabilistic answers based
upon all the (imprecise) values of the data.
The problem of balancing the tradeoff between precision
and performance for querying replicated data WIIS studied
by Olston et. al. [9,8, 10). In their model, the cache in the
server cannot keep track of the exact values ofsensor sources
due to limited network bandwidth. Instead of storing the
actual ...alue for each data item in the ser...er's cache, they
propose to store an interval for each item within which the
current value must be located. A query is then answered by
using these intervnls, together with the actual values fetched
from the sources.
In [9), the problem of minimizing the
update cost within an error bound specified by aggregute
queries is studied. In (8], algorithms for tuning the intervals
of the datu items slored in the cuche for best perfonnance are
proposed. In , the problem of minimizing the di...ergence
between the server and the sources gi...en a. limited amount
of bUlldwidth is discussed.
Khanna et. al extend Olston's work by proposing an
online algorithm that identifies a set of elements with minimum update cost so that a query cun be answered within an
error bound. Three models of precision nre discussed: absolute, relative 6lld rank. In the absolute (relati...e) precision
model, an answer a is cnIled o-precise if the actual value 1J
de...iates from a by not more than un ndditive (multiplicative) factor of o. The Tlluk preeision model is used to deal
Figure 15: VMinQ score as function of }..q
Figure 16: Uncertainty as function of >'0
a probabil..Ultic query, we can cla."Sify queries in two dimensionll, based. on whether they arc aggregate/non-aggregate
queries, and whether they arc entity-bnscd/valuc-bascd. Algorithms for computing typicnl q\leries in each query class
are demoll5trated. We present novel metries for mcasuring
quality of answers to these queries, and also discuss several
update heuristics for improving the quality of rC'i'mlts. The
bencfit of qucry-based updates was also shown experimentally.