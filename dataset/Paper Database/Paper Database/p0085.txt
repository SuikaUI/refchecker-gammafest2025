Self-supervised Equivariant Attention Mechanism
for Weakly Supervised Semantic Segmentation
Yude Wang1,2, Jie Zhang1,2, Meina Kan1,2, Shiguang Shan1,2,3, Xilin Chen1,2
1Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS),
Institute of Computing Technology, CAS, Beijing, 100190, China
2University of Chinese Academy of Sciences, Beijing, 100049, China
3CAS Center for Excellence in Brain Science and Intelligence Technology, Shanghai, 200031, China
 , {zhangjie, kanmeina, sgshan, xlchen}@ict.ac.cn
Image-level weakly supervised semantic segmentation is
a challenging problem that has been deeply studied in recent years. Most of advanced solutions exploit class activation map (CAM). However, CAMs can hardly serve as the
object mask due to the gap between full and weak supervisions. In this paper, we propose a self-supervised equivariant attention mechanism (SEAM) to discover additional supervision and narrow the gap. Our method is based on the
observation that equivariance is an implicit constraint in
fully supervised semantic segmentation, whose pixel-level
labels take the same spatial transformation as the input images during data augmentation. However, this constraint
is lost on the CAMs trained by image-level supervision.
Therefore, we propose consistency regularization on predicted CAMs from various transformed images to provide
self-supervision for network learning. Moreover, we propose a pixel correlation module (PCM), which exploits context appearance information and reﬁnes the prediction of
current pixel by its similar neighbors, leading to further improvement on CAMs consistency. Extensive experiments on
PASCAL VOC 2012 dataset demonstrate our method outperforms state-of-the-art methods using the same level of
supervision. The code is released online1.
1. Introduction
Semantic segmentation is a fundamental computer vision task, which aims to predict pixel-wise classiﬁcation
results on images. Thanks to the booming of deep learning researches in recent years, the performance of semantic
segmentation model has achieved great progress ,
promoting many practical applications, e.g., autopilot and
1 
Figure 1. Comparisons of CAMs generated by input images with
different scales. (a) Conventional CAMs. (b) CAMs predicted by
our SEAM, which are more consistent over rescaling.
medical image analysis. However, compared to other tasks
such as classiﬁcation and detection, semantic segmentation
needs to collect pixel-level class labels which are timeconsuming and expensive. Recently many efforts are devoted to weakly supervised semantic segmentation (WSSS)
which utilizes weak supervisions, e.g., image-level classiﬁcation labels, scribbles, and bounding boxes, attempting to
achieve equivalent segmentation performance of fully supervised approaches. This paper focuses on semantic segmentation by image-level classiﬁcation labels.
To the best of our knowledge, most of advanced WSSS
methods are based on the class activation map (CAM) ,
which is an effective way to localize objects by image classiﬁcation labels. However, the CAMs usually only cover
the most discriminative part of the object and incorrectly
activate in background regions, which can be summarized
as under-activation and over-activation respectively. Moreover, the generated CAMs are not consistent when images
are augmented by afﬁne transformations.
As shown in
Fig. 1, applying different rescaling transformations on the
same input images causes signiﬁcant inconsistency on the
 
generated CAMs. The essential causes of these phenomena
come from the supervision gap between fully and weakly
supervised semantic segmentation.
In this paper, we propose a self-supervised equivariant attention mechanism (SEAM) to narrow the supervision gap mentioned above. The SEAM applies consistency
regularization on CAMs from various transformed images
to provide self-supervision for network learning. To further improve the network prediction consistency, SEAM introduces the pixel correlation module (PCM), which captures context appearance information for each pixel and
revises original CAMs by learned afﬁnity attention maps.
The SEAM is implemented by a siamese network with
equivariant cross regularization (ECR) loss, which regularizes the original CAMs and the revised CAMs on different
branches. Fig. 1 shows that our CAMs are consistent over
various transformed input images, with fewer over-activated
and under-activated regions than baseline. Extensive experiments give both quantitative and qualitative results, demonstrating the superiority of our approach.
In summary, our main contributions:
• We propose a self-supervised equivariant attention
mechanism (SEAM), incorporating equivariant regularization with pixel correlation module (PCM), to narrow the supervision gap between fully and weakly supervised semantic segmentation.
• The design of siamese network architecture with
equivariant cross regularization (ECR) loss efﬁciently
couples the PCM and self-supervision, producing
CAMs with both fewer over-activated and underactivated regions.
• Experiments on PASCAL VOC 2012 illustrate that our
algorithm achieves state-of-the-art performance with
only image-level annotations.
2. Related Work
The development of deep learning has led to a series
of breakthroughs on fully supervised semantic segmentation in recent years. In this section, we
introduce some works, including weakly supervised semantic segmentation and self-supervised learning.
2.1. Weakly Supervised Semantic Segmentation
Compared to fully supervised learning, WSSS uses weak
labels to guide network training, e.g., bounding boxes , scribbles and image-level classiﬁcation labels . A group of advanced researches utilizes
image-level classiﬁcation labels to train models. Most of
them reﬁne the class activation map (CAM) generated
by the classiﬁcation network to approximate the segmentation mask. SEC proposes three principles, i.e., seed,
expand, and constrain, to reﬁne CAMs, which are followed
by many other works. Adversarial erasing is a popular CAM expansion method, which erases the most discriminative part of CAM, guides the network to learn classiﬁcation features from other regions and expands activations. AfﬁnityNet trains another network to learn the
similarity between pixels, which generates a transition matrix and multiplies with CAM several times to adjust its activation coverage. IRNet generates a transition matrix
from the boundary activation map and extends the method
to weakly supervised instance segmentation. Here are also
some researches endeavor to aggregate self-attention module in the WSSS framework, e.g., CIAN proposes cross-image attention module to learn activation maps
from two different images containing the same class objects
with the guidance of saliency maps.
2.2. Self-supervised Learning
Instead of using massive annotated labels to train network, self-supervised learning approaches aim at designing pretext tasks to generate labels without additional manual annotations. Here are many classical self-supervised
pretext tasks, e.g., relative position prediction , spatial
transformation prediction , image inpainting , and
image colorization .
To some extent, the generative
adversarial network can also be regarded as a selfsupervised learning approach that the authenticity labels for
discriminator do not need to be annotated manually. Labels generated by pretext tasks provide self-supervision for
the network to learn a more robust representation. The feature learned by self-supervision can replace the feature pretrained by ImageNet on some tasks, such as detection 
and part segmentation .
Considering there is a large supervision gap between
fully and weakly supervised semantic segmentation, it is
an intuition that we should seek additional supervision to
narrow the gap. Since image-level classiﬁcation labels are
too weak for network to learn segmentation masks which
should well ﬁt object boundary, we design pretext task using the equivariance of ideal segmentation function to provide additional self-supervision for network learning with
only image-level annotations.
3. Approach
This section details our SEAM method. Firstly, we illustrate the motivation of our work. Then we introduce the
implementation of equivariant regularization by a sharedweight siamese network. The proposed pixel correlation
module (PCM) is integrated into the network to further improve the consistency of prediction. Finally, the loss design
of SEAM is discussed. Fig. 2 shows our SEAM network
structure.
Figure 2. The siamese network architecture of our proposed SEAM method. The SEAM is the integration of equivariant regularization
(ER) (Section. 3.2) and pixel correlation module (PCM) (Section. 3.3). With specially designed losses (Section 3.4), the revised CAMs not
only keep consistent over afﬁne transformation but also well ﬁt the object contour.
3.1. Motivation
We denote ideal pixel-level semantic segmentation function as Fws(·) with parameters ws. For each image sample
I, the segmentation process can be formulated as Fws(I) =
s, where s denotes pixel-level segmentation mask. The formulation is also consistent in classiﬁcation task. With additional image-level label l and pooling function Pool(·),
classiﬁcation task can be represented as Pool(Fwc(I)) = l
with parameters wc. Most WSSS approaches are based on
the hypothesis that the optimal parameters for classiﬁcation
and segmentation satisfy wc = ws. Therefore, these methods train a classiﬁcation network ﬁrstly and remove pooling
function to tackle segmentation task.
However, it is easy to ﬁnd the properties of classiﬁcation and segmentation function are different. Suppose there
is an afﬁne transformation A(·) for each sample, the segmentation function is more inclined to be equivariant, i.e.,
Fws(A(I)) = A(Fws(I)). While the classiﬁcation task focuses more on invariance, i.e., Pool(Fwc(A(I))) = l. Although the invariance of classiﬁcation function is mainly
caused by pooling operation, there is no equivariant constraint for Fwc(·), which makes it nearly impossible to
achieve the same objective of segmentation function during network learning. Additional regularizers should be integrated to narrow the supervision gap between fully and
weakly supervised learning.
Self-attention is a widely accepted mechanism that can
signiﬁcantly improve the network approximation ability. It
revises feature maps by capturing context feature dependency, which also meets the ideas of most WSSS methods
using the similarity of pixels to reﬁne the original activation
map. Following the denotation of , the general selfattention mechanism can be deﬁned as:
f(xi, xj)g(xj) + xi,
f(xi, xj) = eθ(xi)Tφ(xj).
Here x and y denote input and output feature, with spatial
position index i and j. The output signal is normalized by
∀j f(xi, xj). Function g(xj) gives a representation of input signal xj at each position and all of them are
aggregated into position i with the similarity weights given
by f(xi, xj), which calculates the dot-product pixel afﬁnity
in an embedding space. To improve the network ability for
consistent prediction, we propose SEAM by incorporating
self-attention with equivariant regularization.
3.2. Equivariant Regularization
During the data augmentation period of fully supervised
semantic segmentation, the pixel-level labels should be applied with the same afﬁne transformation as input images.
It introduces an implicit equivariant constraint for the network. However, considering that the WSSS can only access
image-level classiﬁcation labels, the implicit constraint is
missing here. Therefore, we propose equivariant regularization as follows:
RER = ||F(A(I)) −A(F(I))||1.
Here F(·) denotes the network, and A(·) denotes any spatial
afﬁne transformation, e.g., rescaling, rotation, ﬂip. To integrate regularization on the original network, we expand the
network into a shared-weight siamese structure. One branch
applies the transformation on the network output, the other
branch warps the images by the same transformation before
the feedforward of the network. The output activation maps
from two branches are regularized to guarantee the consistency of CAMs.
3.3. Pixel Correlation Module
Although equivariant regularization provides additional
supervision for network learning, it is hard to achieve ideal
equivariance with only classical convolution layers. Selfattention is an efﬁcient module to capture context information and reﬁne pixel-wise prediction results. To integrate the
classical self-attention module given by Eq. (1) and Eq. (2)
for CAM reﬁnement, the formulation can be written as:
eθ(xi)Tφ(xj)g(ˆyj) + ˆyi,
where ˆy denotes the original CAM and y denotes the revised
CAM. In this structure, the original CAM is embedded into
residual space by function g. Each pixel aggregates with
others with similarity given by Eq. (2). Three embedding
functions θ, φ, g can be implemented by individual 1 × 1
convolution layers.
To further reﬁne original CAMs by context information,
we propose a pixel correlation module (PCM) at the end of
the network to integrate the low-level feature of each pixel.
The structure of PCM refers to the core part of the selfattention mechanism with some modiﬁcations and trained
by the supervision from equivariant regularization. We use
cosine distance to evaluate inter-pixel feature similarity:
f(xi, xj) =
θ(xi)Tθ(xj)
||θ(xi)|| · ||θ(xj)||.
Here we take the inner-product in normalized feature space
to calculate the afﬁnity between current pixel i and others.
The f can be integrated into Eq. (1) with some modiﬁcations as:
θ(xi)Tθ(xj)
||θ(xi)|| · ||θ(xj)||)ˆyj.
The similarities are activated by ReLU to suppress negative
values. The ﬁnal CAM is the weighted sum of the original
CAM with normalized similarities. Fig. 3 gives an illustration of the PCM structure.
Compared to classical self-attention, PCM removes the
residual connection to keep the same activation intensity
of the original CAM. Moreover, since the other network
branch provides pixel-level supervision for PCM, which is
not as accurate as ground truth, we reduce parameters by
removing embedding function φ and g to avoid overﬁtting
on inaccurate supervision. We use ReLU activation function with L1 normalization to mask out irrelevant pixels and
generate an afﬁnity attention map which is smoother in relevant regions.
original CAM
modified CAM
Pixel Correlation Module (PCM)
Figure 3. The structure of PCM, where H, W, C/C1/C2 denote
height, width and channel numbers of feature maps respectively.
3.4. Loss Design of SEAM
Image-level classiﬁcation label l is the only humanannotated supervision that can be used here. We employ
the global average pooling layer at the end of the network
to achieve prediction vector z for image classiﬁcation and
adopt multi-label soft margin loss for network training. The
classiﬁcation loss is deﬁned for C −1 foreground object
category as:
ℓcls(z, l) = −
1 + e−zc )
+ (1 −lc) log(
1 + e−zc )].
Formally we denote the original CAMs of siamese network
as ˆyo and ˆyt, where ˆyo comes from the branch with original image input and ˆyt stems from the transformed images.
The global average pooling layer aggregates them into prediction vector zo and zt respectively. The classiﬁcation loss
is calculated on two branches as:
2(ℓcls(zo, l) + ℓcls(zt, l)).
The classiﬁcation loss provides learning supervision for object localization. And it is necessary to aggregate equivariant regularization on original CAM to preserve the consistency of output. The equivariant regularization (ER) loss on
original CAM can be easily deﬁned as:
LER = ||A(ˆyo) −ˆyt||1.
Here A(·) is an afﬁne transformation which has already
been applied to the input image in the transformation branch
of the siamese network.
Moreover, to further improve
the ability of network for equivariance learning, the original CAMs and features from the shallow layers are fed
into PCM for reﬁnement. The intuitive idea is introducing
equivariant regularization between revised CAMs yo and
yt. However, in our early experiments, the output maps of
PCM fall into the local minimum quickly that all pixels in
the image are predicted the same class. Therefore, we propose an equivariant cross regularization (ECR) loss as:
LECR = ||A(yo) −ˆyt||1 + ||A(ˆyo) −yt||1.
The PCM outputs are regularized by the original CAMs on
the other branch of the siamese network. This strategy can
avoid CAM degeneration during PCM reﬁnement.
Although the CAMs are learned by foreground object
classiﬁcation loss, there are many background pixels, which
should not be ignored during PCM processing. The original foreground CAMs have zero vectors on these background positions, which cannot produce gradients to push
feature representations closer between those background
pixels. Therefore, we deﬁne the background score as:
ˆyi,bkg = 1 −
1≤c≤C−1 ˆyi,c,
where ˆyi,c is the activation score of original CAM for category c at position i. We normalize the activation vectors of
each pixel by suppressing foreground non-maximum activations to zeros and concatenate with additional background
score. During inference, we only keep the foreground activation results and set the background score as ˆyi,bkg = α,
where α is the hard threshold parameter.
In summary, the ﬁnal loss of SEAM is deﬁned as:
L = Lcls + LER + LECR.
The classiﬁcation loss is used to roughly localize objects
and the ER loss is used to narrow the gaps between pixeland image-level supervisions. The ECR loss is used to integrate PCM with the trunk of the network, in order to make
consistent predictions over various afﬁne transformations.
The network architecture is illustrated in Fig. 2. We give
the details of network training settings and carefully investigate the effectiveness of each module in the experiments
4. Experiments
4.1. Implementation Details
We evaluate our approach on PASCAL VOC 2012
dataset with 21 class annotations, i.e., 20 foreground objects and the background. The ofﬁcial dataset separation has
1464 images for training, 1449 for validation and 1456 for
testing. Following the common experimental protocol for
semantic segmentation, we take additional annotations from
SBD to build an augmented training set with 10582 images. Noting that only image-level classiﬁcation labels are
available during network training. Mean intersection over
union (mIoU) is used as a metric to evaluate segmentation
In our experiments, ResNet38 is adopted as backbone network with output stride = 8. We extract the feature maps from stage 3 and stage 4, reduce their channel
numbers into 64 and 128 respectively by individual 1 × 1
convolution layers. In PCM, these features are concatenated
with images and fed into function θ in Eq. (5), which is
implemented by another 1 × 1 convolution layer. The images are randomly rescaled in the range of by the
longest edge and then cropped by 448 × 448 as network inputs. The model is trained on 4 TITAN-Xp GPUs with batch
size 8 for 8 epochs. The initial learning rate is set as 0.01,
following the poly policy lr itr = lr init(1 −
max itr )γ with
γ = 0.9 for decay. Online hard example mining (OHEM) is
employed on the ECR loss remaining the largest 20% pixel
During network training, we cut off gradients backpropagation at the intersection point between PCM stream
and the trunk of the network to avoid the mutual interference. This setting simpliﬁes the PCM into a pure context
reﬁnement module which still can be trained with the backbone of the network at the same time. And the learning of
original CAMs will not be affected by PCM reﬁnement process. During inference, since our SEAM is a shared-weight
siamese network, only one branch needs to be restored. We
adopt multi-scale and ﬂip test during inference to generate
pseudo segmentation labels.
4.2. Ablation Studies
To verify the effectiveness of our SEAM, we generate
pixel-level pseudo labels from revised CAMs on PASCAL
VOC 2012 train set. In our experiments, we traverse all
background threshold options and give the best mIoU of
pseudo labels, instead of comparing with the same background threshold. Because the highest pseudo label accuracy represents the best matching results between CAMs
and ground truth segmentation masks.
Speciﬁcally, the
foreground activation coverage will expand with the increase of average activation intensity, while its matching
degree with ground truth is not changed. And the highest
pseudo label accuracy will not be improved when CAMs
only increase average activation intensity rather than becoming more matchable with ground truth.
Comparison with Baseline:
Tab. 1 gives an ablation
study of each module in our approach. It shows that using the siamese network with equivariant regularization has
a 2.47% improvement compared to baseline.
achieves signiﬁcant performance elevation by 5.18%. After applying OHEM on equivariant cross regularization loss,
the generated pseudo labels further achieve 55.41% mIoU
on PASCAL VOC train set. We also test the baseline CAM
with dense CRF to reﬁne predictions. The results show that
dense CRF improves the mIoU to 52.40%, which is lower
than the SEAM result 55.41%. And our SEAM can further
improve the performance up to 56.83% after aggregating
dense CRF as post process. Fig. 4 shows that the CAMs
Table 1. The ablation study for each part of SEAM. ER: equivariant regularization. PCM: pixel correlation module. OHEM:
online hard example mining. CRF: conditional random ﬁeld.
CAM + SEAM
Table 2. Evaluation of various weakly supervised localization
methods with semantic segmentation metric (mIoU).
generated by SEAM have fewer over-activations and more
complete activation coverage, whose shape is closer to the
ground truth segmentation masks than baseline. To further
verify the effectiveness of our proposed SEAM, we visualize the afﬁnity attention maps generated by PCM. As shown
in Fig. 5, the selected foreground and background pixels are
very close in spatial, while their afﬁnity attention maps are
greatly different. It proves that the PCM can learn boundary
sensitive features from self-supervision.
Improved Localization Mechanism:
It is an intuition
that improved weakly supervised localization mechanism
will elevate mIoU of pseudo segmentation labels.
verify the idea, we simply evaluate GradCAM and
GradCAM++ before aggregating our proposed SEAM.
However, the evaluation results given by Tab. 2 illustrates
that both GradCAM and GradCAM++ cannot narrow the
supervision gap between fully and weakly supervised semantic segmentation tasks, since the best mIoU results do
not have improvement. We believe the improved localization mechanisms are only designed to represent object correlated parts without any constraints by low-level information, which is not suitable for the segmentation task. The
CAMs generated by these improved localization methods
are not becoming more matchable with ground truth masks.
The following experiments further illustrate that our proposed SEAM can substantially improve the quality of CAM
to ﬁt the shape of object masks.
Afﬁne Transformation:
Ideally, the A(·) in Eq. (3) can
be any afﬁne transformation. Several transformations are
conducted in the siamese network to evaluate the effect of
them on equivariant regularization. As shown in Tab. 3,
there are four candidate afﬁne transformations: rescaling
Figure 4. The visualization of CAMs. (a) Original images. (b)
Ground truth segmentations. (c) Baseline CAMs. (d) CAMs produced by SEAM. The SEAM not only suppresses over-activation
but also expands CAMs into complete object activation coverage.
foreground pixels with attention maps
background pixels with attention maps
Figure 5. The visualization of afﬁnity attention map on foreground
and background. The red and green crosses denote the selected
pixels, with similar feature representation in blue color.
with 0.3 down-sampling rate, random rotation in [-20, 20]
degrees, translation by 15 pixels and horizontal ﬂip. Firstly,
our proposed SEAM simply adopts rescaling during network training. Tab. 3 shows that the mIoU of pseudo labels has signiﬁcant improvement from 47.43% to 55.41%.
Tab. 3 also shows that simply incorporating different transformations is not much effective. When rescaling transformation integrates with ﬂip, rotation, and translation respectively, only ﬂip makes tiny improvement. In our view, it
is because the activation maps between ﬂip, rotation, and
translation are too similar to produce sufﬁcient supervision.
Without additional instructions, we only preserve rescaling
as the key transformation with 0.3 down-sampling rate in
our other experiments.
Augmentation and Inference:
Compared to the original
one-branch network, the siamese structure expands the augmentation range of image size in practice. To investigate
whether the improvement stems from the rescaling range,
translation
Table 3. Experiments of various transformations on equivariant
regularization.
Simply aggregating different afﬁne transformations cannot bring signiﬁcant improvement.
random rescale
 
 
 
Table 4. Experiments of augmentation rescaling range. Here the
rescale rate of SEAM is set to 0.5.
test scale
baseline (mIoU)
ours (mIoU)
[0.5, 1.0, 1.5, 2.0]
Table 5. Experiments with various single- and multi-scale test.
we evaluate the baseline model with a larger scale range and
Tab. 4 gives the experiment results. It shows that simply increasing the rescaling range cannot improve the accuracy
of generated pseudo labels, which proves that the performance improvement comes from the combination of PCM
and equivariant regularization instead of data augmentation.
During inference, it is a common practice to employ
multi-scale test by aggregating the prediction results from
images with different scales to boost the ﬁnal performance.
It can also be regarded as a method to improve the equivariance of predictions. To verify the effectiveness of our
propose SEAM, we evaluate the CAMs generated by both
single-scale and multi-scale test. Tab. 5 illustrates that our
proposed model outperforms baseline with higher peak performance in both single- and multi-scale test.
Source of Improvement:
The improvement of CAM
quality mainly stems from more complete activation coverage or fewer over-activated regions. To further analyze the
improvement source of our SEAM, we deﬁne two metrics to
represent the degree of under-activation and over-activation:
Image scale
mFN baseline
mFP baseline
Figure 6. The curves of over-activation and under-activation.
Lower mFN curve represents fewer under-activation regions, and
lower mFP represents fewer over-activated regions.
Here TPc denotes the pixel number of true positive prediction of class c, FPc and FN c denote false positive and
false negative respectively. These two metrics exclude the
background category since the prediction of background is
inverse to the foreground. Speciﬁcally, if there are more
false negative regions when CAMs do not have complete
activation coverage, mFN will have a larger value. Relatively, larger mFP means there are more false positive regions, meaning that CAMs are over-activated.
Based on these two metrics, we collect the evaluation
results from both baseline and our SEAM, then plot the
curves in Fig. 6 which illustrates a large gap between baseline and our method. The SEAM achieves lower mFN and
mFP, meaning that the CAMs generated by our approach
have more complete activation coverage and fewer overactivated pixels. Therefore, the prediction maps of SEAM
better ﬁt the shape of ground truth segmentation. Moreover, the curves of SEAM are more consistent than baseline
model over different image scales, which proves that the
equivariance regularization works during network learning
and contributes to the improvement of CAM.
4.3. Comparison with State-of-the-arts
To further elevate the accuracy of pseudo pixel-level annotations, we follow the work of to train an AfﬁnityNet based on our revised CAM. The ﬁnal synthesized
pseudo labels achieve 63.61% mIoU on PASCAL VOC
2012 train set.
Then we train the classical segmentation model DeepLab with ResNet38 backbone on these
pseudo labels in full supervision to achieve ﬁnal segmentation results. Tab. 6 shows the mIoU of each class on val
set and Tab. 7 gives more experiment results of previous
approaches. Compared to the baseline method, our SEAM
signiﬁcantly improves the performance on both val and test
set with the same training setting. Moreover, our method
presents the state-of-the-art performance using only imagelevel labels on PASCAL VOC 2012 test set. Noting that
Figure 7. Qualitative segmentation results on PASCAL VOC 2012 val set. (a) Original images. (b) Ground truth. (c) Segmentation results
predicted by DeepLab model retrained on our pseudo labels.
bkg aero bike bird boat bottle bus car
cat chair cow table dog horse mbk person plant sheep sofa train tv mIoU
68.5 25.5 18.0 25.4 20.2 36.3 46.8 47.1 48.0 15.8 37.9 21.0 44.5 34.5 46.2 40.7
30.4 36.3 22.2 38.8 36.9 35.3
MIL+seg 
79.6 50.2 21.6 40.9 34.9 40.5 45.9 51.5 60.6 12.6 51.2 11.6 56.8 52.9 44.8 42.7
31.2 55.4 21.5 38.8 36.9 42.0
82.4 62.9 26.4 61.6 27.6 38.1 66.6 62.7 75.2 22.1 53.5 28.3 65.8 57.8 62.3 52.5
32.5 62.6 32.1 45.4 45.3 50.7
AdvErasing 83.4 71.1 30.5 72.9 41.6 55.9 63.1 60.2 74.0 18.0 66.5 32.4 71.7 56.3 64.8 52.4
37.4 69.1 31.4 58.9 43.9 55.0
AfﬁnityNet 
88.2 68.2 30.6 81.1 49.6 61.0 77.8 66.1 75.1 29.0 66.0 40.2 80.4 62.0 70.4 73.7
42.5 70.7 42.6 68.1 51.6 61.7
88.8 68.5 33.3 85.7 40.4 67.3 78.9 76.3 81.9 29.1 75.5 48.1 79.9 73.8 71.4 75.2
48.9 79.8 40.9 58.2 53.0 64.5
Table 6. Category performance comparisons on PASCAL VOC 2012 val set with only image-level supervision.
EM-Adapt 
MIL+seg 
AdvErasing 
SeeNet 
AfﬁnityNet 
FickleNet 
Our baseline
Table 7. Performance comparisons of our method with other stateof-the-art WSSS methods on PASCAL VOC 2012 dataset.
our performance elevation stems from neither the larger network structure nor the improved saliency detector. The performance improvement mainly comes from the cooperation
of additional self-supervision and PCM, which produces
better CAMs for the segmentation task. Fig. 7 shows some
qualitative results, which verify that our method works well
on both large and small objects.
5. Conclusion
In this paper, we propose a self-supervised equivariant
attention mechanism (SEAM) to narrow the supervision gap
between fully and weakly supervised semantic segmentation by introducing additional self-supervision. The SEAM
embeds self-supervision into weakly supervised learning
framework by exploiting equivariant regularization, which
forces CAMs predicted from various transformed images
to be consistent. To further improve the ability of network
for generating consistent CAMs, a pixel correlation module (PCM) is designed, which reﬁnes original CAMs by
learning inter-pixel similarity. Our SEAM is implemented
by a siamese network structure with efﬁcient regularization
losses. The generated CAMs not only keep consistent over
different transformed inputs but also better ﬁt the shape of
ground truth masks. The segmentation network retrained by
our synthesized pixel-level pseudo labels achieves state-ofthe-art performance on PASCAL VOC 2012 dataset, which
proves the effectiveness of our SEAM.
Acknowledgement:
supported by National Key R&D Program of China (No.
2017YFA0700800), CAS
Research Project (No.
QYZDJ-SSWJSC009) and Natural
Science Foundation of China (Nos. 61806188, 61772496).