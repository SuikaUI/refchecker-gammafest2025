Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 402–412,
Baltimore, Maryland, USA, June 23-25 2014. c⃝2014 Association for Computational Linguistics
Incremental Joint Extraction of Entity Mentions and Relations
Computer Science Department
Rensselaer Polytechnic Institute
Troy, NY 12180, USA
{liq7,jih}@rpi.edu
We present an incremental joint framework to simultaneously extract entity mentions and relations using structured perceptron with efﬁcient beam-search.
segment-based decoder based on the idea
of semi-Markov chain is adopted to the
new framework as opposed to traditional
token-based tagging. In addition, by virtue
of the inexact search, we developed a number of new and effective global features
as soft constraints to capture the interdependency among entity mentions and
relations. Experiments on Automatic Content Extraction (ACE)1 corpora demonstrate that our joint model signiﬁcantly
outperforms a strong pipelined baseline,
which attains better performance than the
best-reported end-to-end system.
Introduction
The goal of end-to-end entity mention and relation extraction is to discover relational structures of entity mentions from unstructured texts.
This problem has been artiﬁcially broken down
into several components such as entity mention
boundary identiﬁcation, entity type classiﬁcation
and relation extraction. Although adopting such
a pipelined approach would make a system comparatively easy to assemble, it has some limitations: First, it prohibits the interactions between
components. Errors in the upstream components
are propagated to the downstream components
without any feedback. Second, it over-simpliﬁes
the problem as multiple local classiﬁcation steps
without modeling long-distance and cross-task dependencies.
By contrast, we re-formulate this
task as a structured prediction problem to reveal
the linguistic and logical properties of the hidden
1 
structures. For example, in Figure 1, the output
structure of each sentence can be interpreted as a
graph in which entity mentions are nodes and relations are directed arcs with relation types. By
jointly predicting the structures, we aim to address
the aforementioned limitations by capturing: (i)
The interactions between two tasks. For example, in Figure 1a, although it may be difﬁcult for
a mention extractor to predict “1,400” as a Person (PER) mention, the context word “employs”
between “tire maker” and “1,400” strongly indicates an Employment-Organization (EMP-ORG)
relation which must involve a PER mention. (ii)
The global features of the hidden structure. Various entity mentions and relations share linguistic and logical constraints.
For example, we
can use the triangle feature in Figure 1b to ensure that the relations between “forces”, and each
of the entity mentions “Somalia/GPE”, “Haiti/GPE”
and “Kosovo/GPE”, are of the same type (Physical
(PHYS), in this case).
Following the above intuitions, we introduce
a joint framework based on structured perceptron with
beam-search to extract entity mentions and relations simultaneously. With the beneﬁt of inexact
search, we are also able to use arbitrary global
features with low cost. The underlying learning
algorithm has been successfully applied to some
other Natural Language Processing (NLP) tasks.
Our task differs from dependency parsing ) in that relation structures are more ﬂexible, where each node can have
arbitrary relation arcs. Our previous work used perceptron model with token-based
tagging to jointly extract event triggers and arguments. By contrast, we aim to address a more challenging task: identifying mention boundaries and
types together with relations, which raises the issue that assignments for the same sentence with
different mention boundaries are difﬁcult to syn-
The tire maker
still employs 1,400
(a) Interactions between Two Tasks
and Kosovo
(b) Example of Global Feature
Figure 1: End-to-End Entity Mention and Relation Extraction.
chronize during search. To tackle this problem,
we adopt a segment-based decoding algorithm derived from based on the idea of semi-Markov
chain (a.k.a, multiple-beam search algorithm).
Most previous attempts on joint inference of entity mentions and relations ) assumed that entity
mention boundaries were given, and the classiﬁers
of mentions and relations are separately learned.
As a key difference, we incrementally extract entity mentions together with relations using a single
model. The main contributions of this paper are as
1. This is the ﬁrst work to incrementally predict
entity mentions and relations using a single
joint model (Section 3).
2. Predicting mention boundaries in the joint
framework raises the challenge of synchronizing different assignments in the same beam. We
solve this problem by detecting entity mentions
on segment-level instead of traditional tokenbased approaches (Section 3.1.1).
3. We design a set of novel global features based
on soft constraints over the entire output graph
structure with low cost (Section 4).
Experimental results show that the proposed
performance
pipelined approaches, and global features provide
further signiﬁcant gains.
Background
Task Deﬁnition
extraction
extraction tasks we are addressing are those
of the Automatic Content Extraction (ACE)
ACE deﬁned 7 main entity types
including Person (PER), Organization (ORG),
Geographical Entities (GPE), Location (LOC),
2 
(VEH). The goal of relation extraction3 is to
extract semantic relations of the targeted types
between a pair of entity mentions which appear in the same sentence.
ACE’04 deﬁned 7
main relation types:
Physical (PHYS), Person-
(PER-SOC),
Employment-Organization
(EMP-ORG), Agent-Artifact (ART), PER/ORG
Afﬁliation
(Other-AFF),
GPE-Afﬁliation
(GPE-AFF) and Discourse (DISC). ACE’05 kept
PER-SOC, ART and GPE-AFF, split PHYS into
PHYS and a new relation type Part-Whole,
removed DISC, and merged EMP-ORG and
Other-AFF into EMP-ORG.
Throughout this paper, we use ⊥to denote nonentity or non-relation classes. We consider relation asymmetric. The same relation type with opposite directions is considered to be two classes,
which we refer to as directed relation types.
Most previous research on relation extraction
assumed that entity mentions were given In this
work we aim to address the problem of end-to-end
entity mention and relation extraction from raw
Baseline System
In order to develop a baseline system representing state-of-the-art pipelined approaches, we
trained a linear-chain Conditional Random Fields
model for entity mention extraction and a Maximum Entropy model for relation extraction.
Entity Mention Extraction Model We re-cast
the problem of entity mention extraction as a sequential token tagging task as in the state-of-theart system . We applied the
BILOU scheme, where each tag means a token is
the Beginning, Inside, Last, Outside, and Unit of
an entity mention, respectively. Most of our features are similar to the work of except that we do not
have their gazetteers and outputs from other mention detection systems as features. Our additional
features are as follows:
• Governor word of the current token based on dependency parsing .
• Preﬁx of each word in Brown clusters learned
from TDT5 corpus .
Relation Extraction Model Given a sentence
with entity mention annotations, the goal of baseline relation extraction is to classify each mention
pair into one of the pre-deﬁned relation types with
direction or ⊥(non-relation). Most of our relation
extraction features are based on the previous work
of and . We
designed the following additional features:
• The label sequence of phrases covering the two
mentions. For example, for the sentence in Figure 1a, the sequence is “NP VP NP”. We also
augment it by head words of each phrase.
• Four syntactico - semantic patterns described in
 .
• We replicated each lexical feature by replacing
each word with its Brown cluster.
Our goal is to predict the hidden structure of
each sentence based on arbitrary features and constraints. Let x ∈X be an input sentence, y′ ∈Y
be a candidate structure, and f(x, y′) be the feature vector that characterizes the entire structure.
We use the following linear model to predict the
most probable structure ˆy for x:
ˆy = argmax
f(x, y′) · w
where the score of each candidate assignment is
deﬁned as the inner product of the feature vector
f(x, y′) and feature weights w.
Since the structures contain both entity mentions relations, and we also aim to exploit global
features. There does not exist a polynomial-time
algorithm to ﬁnd the best structure. In practice
we apply beam-search to expand partial conﬁgurations for the input sentence incrementally to ﬁnd
the structure with the highest score.
Joint Decoding Algorithm
One main challenge to search for entity mentions
and relations incrementally is the alignment of different assignments. Assignments for the same sentence can have different numbers of entity mentions and relation arcs.
The entity mention extraction task is often re-cast as a token-level sequential labeling problem with BIO or BILOU
scheme . A naive solution to our task is to adopt this
strategy by treating each token as a state. However, different assignments for the same sentence
can have various mention boundaries.
It is unfair to compare the model scores of a partial mention and a complete mention. It is also difﬁcult to
synchronize the search process of relations. For
example, consider the two hypotheses ending at
“York” for the same sentence:
AllanU-PER from? NewB-ORG YorkI-ORG Stock Exchange
AllanU-PER from? NewB-GPE YorkL-GPE Stock Exchange
The model would bias towards the incorrect assignment “New/B-GPE York/L-GPE” since it can
have more informative features as a complete
mention (e.g., a binary feature indicating if the
entire mention appears in a GPE gazetter). Furthermore, the predictions of the two PHYS relations cannot be synchronized since “New/B-FAC
York/I-FAC” is not yet a complete mention.
To tackle these problems, we employ the idea of
semi-Markov chain ,
in which each state corresponds to a segment
of the input sequence.
They presented a variant of Viterbi algorithm for exact inference in
semi-Markov chain. We relax the max operation
by beam-search, resulting in a segment-based decoder similar to the multiple-beam algorithm in
 . Let ˆd be the upper bound
of entity mention length. The k-best partial assignments ending at the i-th token can be calculated as:
y′∈{y[1..i]|y[1:i−d]∈B[i−d], d=1... ˆd}
f(x, y′) · w
where y[1:i−d] stands for a partial conﬁguration
ending at the (i-d)-th token, and y[i−d+1,i] corresponds to the structure of a new segment (i.e., subsequence of x) x[i−d+1,i]. Our joint decoding algorithm is shown in Figure 2. For each token index
i, it maintains a beam for the partial assignments
whose last segments end at the i-th token. There
are two types of actions during the search:
Input: input sentence x = (x1, x2, ..., xm).
k: beam size.
T ∪{⊥}: entity mention type alphabet.
R ∪{⊥}: directed relation type alphabet.4
dt: max length of type-t segment, t ∈T ∪{⊥}.
Output: best conﬁguration ˆy for x
1 initialize m empty beams B[1..m]
2 for i ←1...m do
for t ∈T ∪{⊥} do
for d ←1...dt, y′ ∈B[i −d] do
k ←i −d + 1
B[i] ←B[i] ∪APPEND(y′, t, k, i)
B[i] ←k-BEST(B[i])
for j ←(i −1)...1 do
for y′ ∈B[i] do
if HASPAIR(y′, i, j) then
for r ∈R ∪{⊥} do
buf ←buf ∪LINK(y′, r, i, j)
buf ←buf ∪{y′}
B[i] ←k-BEST(buf)
17 return B[m] 
Joint Decoding for Entity Mentions and Relations. HASPAIR(y′, i, j) checks
if there are two entity mentions in y′ that
end at token xi and token xj, respectively.
APPEND(y′, t, k, i) appends y′ with a type-t
segment spanning from xk to xi.
LINK(y′, r, i, j) augments y′ by assigning a directed relation r to the pair of entity mentions
ending at xi and xj respectively.
1. APPEND (Lines 3-7).
First, the algorithm
enumerates all possible segments (i.e., subsequences) of x ending at the current token with
various entity types.
A special type of segment is a single token with non-entity label (⊥).
Each segment is then appended to existing partial assignments in one of the previous beams to
form new assignments. Finally the top k results
are recorded in the current beam.
2. LINK (Lines 8-16). After each step of APPEND,
the algorithm looks backward to link the newly
identiﬁed entity mentions and previous ones (if
any) with relation arcs. At the j-th sub-step,
it only considers the previous mention ending
at the j-th previous token. Therefore different
4The same relation type with opposite directions is considered to be two classes in R.
conﬁgurations are guaranteed to have the same
number of sub-steps. Finally, all assignments
are re-ranked with new relation information.
There are m APPEND actions, each is followed by
at most (i−1) LINK actions (line 8). Therefore the
worst-case time complexity is O( ˆd·k ·m2), where
ˆd is the upper bound of segment length.
Example Demonstration
Figure 3: Example of decoding steps.
and y-axis represent the input sentence and entity types, respectively. The rectangles denote segments with entity types, among which the shaded
ones are three competing hypotheses ending at
“1,400”. The solid lines and arrows indicate correct APPEND and LINK actions respectively, while
the dashed indicate incorrect actions.
Here we demonstrate a simple but concrete example by considering again the sentence described
in Figure 1a. Suppose we are at the token “1,400”.
At this point we can propose multiple entity mentions with various lengths. Assuming “1,400/PER”,
“1,400/⊥” and “(employs 1,400)/PER” are possible assignments, the algorithm appends these new
segments to the partial assignments in the beams
of the tokens “employs” and “still”, respectively.
Figure 3 illustrates this process. For simplicity,
only a small part of the search space is presented.
The algorithm then links the newly identiﬁed mentions to the previous ones in the same conﬁguration. In this example, the only previous mention is “(tire maker)/ORG”. Finally, “1,400/PER” will
be preferred by the model since there are more
indicative context features for EMP-ORG relation
between “(tire maker)/PER” and “1,400/PER”.
Structured-Perceptron Learning
To estimate the feature weights, we use structured perceptron , an extension
of the standard perceptron for structured prediction, as the learning framework.
al. proved the convergency of structured
perceptron when inexact search is applied with
violation-ﬁxing update methods such as earlyupdate . Since we use
beam-search in this work, we apply early-update.
In addition, we use averaged parameters to reduce
overﬁtting as in .
Figure 4 shows the pseudocode for structured perceptron training with early-update. Here
BEAMSEARCH is identical to the decoding algorithm described in Figure 2 except that if y′, the
preﬁx of the gold standard y, falls out of the beam
after each execution of the k-BEST function (line 7
and 16), then the top assignment z and y′ are returned for parameter update. It is worth noting that
this can only happen if the gold-standard has a segment ending at the current token. For instance, in
the example of Figure 1a, B cannot trigger any
early-update since the gold standard does not contain any segment ending at the second token.
Input: training set D = {(x(j), y(j))}N
maximum iteration number T
Output: model parameters w
1 initialize w ←0
2 for t ←1...T do
foreach (x, y) ∈D do
(x, y′, z) ←BEAMSEARCH (x, y, w)
if z ̸= y then
w ←w + f(x, y′) −f(x, z)
7 return w
Figure 4: Perceptron algorithm with beamsearch and early-update. y′ is the preﬁx of the
gold-standard and z is the top assignment.
Entity Type Constraints
Entity type constraints have been shown effective
in predicting relations . We automatically collect a mapping table of permissible entity types for each relation type from our training data. Instead of applying the constraints in post-processing inference,
we prune the branches that violate the type constraints during search. This type of pruning can
reduce search space as well as make the input for
parameter update less noisy. In our experiments,
only 7 relation mentions (0.5%) in the dev set and
5 relation mentions (0.3%) in the test set violate
the constraints collected from the training data.
An advantage of our framework is that we can
easily exploit arbitrary features across the two
This section describes the local features
(Section 4.1) and global features (Section 4.2) we
developed in this work.
Local Features
We design segment-based features to directly evaluate the properties of an entity mention instead of
the individual tokens it contains. Let ˆy be a predicted structure of a sentence x. The entity segments of ˆy can be expressed as a list of triples
(e1, ..., em), where each segment ei = ⟨ui, vi, ti⟩
is a triple of start index ui, end index vi, and entity
type ti. The following is an example of segmentbased feature:
f001(x, ˆy, i) =
if x[ˆy.ui,ˆy.vi] = tire maker
ˆy.t(i−1), ˆy.ti = ⊥,ORG
This feature is triggered if the labels of the (i−1)th and the i-th segments are “⊥,ORG”, and the text
of the i-th segment is “tire maker”. Our segmentbased features are described as follows:
Gazetteer features Entity type of each segment
based on matching a number of gazetteers including persons, countries, cities and organizations.
Case features Whether a segment’s words are
initial-capitalized, all lower cased, or mixture.
Contextual features Unigrams and bigrams of
the text and part-of-speech tags in a segment’s
contextual window of size 2.
Parsing-based features Features derived from
constituent parsing trees, including (a) the phrase
type of the lowest common ancestor of the tokens
contained in the segment, (b) the depth of the lowest common ancestor, (c) a binary feature indicating if the segment is a base phrase or a sufﬁx of a
base phrase, and (d) the head words of the segment
and its neighbor phrases.
In addition, we convert each triple ⟨ui, vi, ti⟩to
BILOU tags for the tokens it contains to implement token-based features. The token-based men-
tion features and local relation features are identical to those of our pipelined system (Section 2.2).
Global Entity Mention Features
By virtue of the efﬁcient inexact search, we are
able to use arbitrary features from the entire
structure of ˆy to capture long-distance dependencies. The following features between related entity
mentions are extracted once a new segment is appended during decoding.
Coreference consistency Coreferential entity
mentions should be assigned the same entity type.
We determine high-recall coreference links between two segments in the same sentence using
some simple heuristic rules:
• Two segments exactly or partially string match.
• A pronoun (e.g., “their”,“it”) refers to previous
entity mentions.
For example, in “they have
no insurance on their cars”, “they” and “their”
should have the same entity type.
• A relative pronoun (e.g., “which”,“that”, and
“who”) refers to the noun phrase it modiﬁes in
the parsing tree. For example, in “the starting
kicker is nikita kargalskiy, who may be 5,000
miles from his hometown”, “nikita kargalskiy”
and “who” should both be labeled as persons.
Then we encode a global feature to check
whether two coreferential segments share the same
entity type. This feature is particularly effective
for pronouns because their contexts alone are often not informative.
Neighbor coherence Neighboring entity mentions tend to have coherent entity types. For example, in “Barbara Starr was reporting from the
Pentagon”, “Barbara Starr” and “Pentagon” are
connected by a dependency link prep from and
thus they are unlikely to be a pair of PER mentions. Two types of neighbor are considered: (i)
the ﬁrst entity mention before the current segment,
and (ii) the segment which is connected by a single word or a dependency link with the current
segment. We take the entity types of the two segments and the linkage together as a global feature.
For instance, “PER prep from PER” is a feature
for the above example when “Barbara Starr” and
“Pentagon” are both labeled as PER mentions.
Part-of-whole consistency If an entity mention is semantically part of another mention (connected by a prep of dependency link), they should
be assigned the same entity type. For example,
in “some of Iraq’s exiles”, “some” and “exiles”
are both PER mentions; in “one of the town’s two
meat-packing plants”, “one” and “plants” are both
FAC mentions; in “the rest of America”, “rest” and
“America” are both GPE mentions.
Global Relation Features
Relation arcs can also share inter-dependencies or
obey soft constraints.
We extract the following
relation-centric global features when a new relation hypothesis is made during decoding.
Role coherence If an entity mention is involved
in multiple relations with the same type, then its
roles should be coherent.
For example, a PER
mention is unlikely to have more than one employer. However, a GPE mention can be a physical
location for multiple entity mentions. We combine
the relation type and the entity mention’s argument
roles as a global feature, as shown in Figure 5a.
Triangle constraint Multiple entity mentions
are unlikely to be fully connected with the same
relation type. We use a negative feature to penalize
any conﬁguration that contains this type of structure. An example is shown in Figure 5b.
Inter-dependent compatibility If two entity
mentions are connected by a dependency link, they
tend to have compatible relations with other entities. For example, in Figure 5c, the conj and dependency link between “Somalia” and “Kosovo”
indicates they may share the same relation type
with the third entity mention “forces”.
Neighbor coherence Similar to the entity mention neighbor coherence feature, we also combine
the types of two neighbor relations in the same
sentence as a bigram feature.
Experiments
Data and Scoring Metric
Most previous work on ACE relation extraction
has reported results on ACE’04 data set.
we will show later in our experiments, ACE’05
made signiﬁcant improvement on both relation
type deﬁnition and annotation quality. Therefore
we present the overall performance on ACE’05
data. We removed two small subsets in informal
genres - cts and un, and then randomly split the remaining 511 documents into 3 parts: 351 for training, 80 for development, and the rest 80 for blind
test. In order to compare with state-of-the-art we
also performed the same 5-fold cross-validation on
bnews and nwire subsets of ACE’04 corpus as in
previous work. The statistics of these data sets
(GPE Somalia)
(PER forces)
(GPE Somalia)
(PER forces)
(GPE Haiti)
(GPE Somalia)
(PER forces)
(GPE Kosovo)
Figure 5: Examples of Global Relation Features.
# of training iterations
mention local+global
mention local
(a) Entity Mention Performance
# of training iterations
relation local+global
relation local
(b) Relation Performance
Figure 6: Learning Curves on Development Set.
are summarized in Table 1. We ran the Stanford
CoreNLP toolkit5 to automatically recover the true
cases for lowercased documents.
# sentences
# mentions
# relations
Table 1: Data Sets.
We use the standard F1 measure to evaluate the
performance of entity mention extraction and relation extraction. An entity mention is considered
correct if its entity type is correct and the offsets
of its mention head are correct. A relation mention is considered correct if its relation type is
correct, and the head offsets of two entity mention arguments are both correct. As in Chan and
5 
Roth , we excluded the DISC relation type,
and removed relations in the system output which
are implicitly correct via coreference links for fair
comparison. Furthermore, we combine these two
criteria to evaluate the performance of end-to-end
entity mention and relation extraction.
Development Results
In general a larger beam size can yield better performance but increase training and decoding time.
As a tradeoff, we set the beam size as 8 throughout the experiments. Figure 6 shows the learning curves on the development set, and compares
the performance with and without global features.
From these ﬁgures we can clearly see that global
features consistently improve the extraction performance of both tasks.
We set the number of
training iterations as 22 based on these curves.
Overall Performance
Table 2 shows the overall performance of various
methods on the ACE’05 test data. We compare
our proposed method (Joint w/ Global) with the
pipelined system (Pipeline), the joint model with
only local features (Joint w/ Local), and two human annotators who annotated 73 documents in
ACE’05 corpus.
We can see that our approach signiﬁcantly outperforms the pipelined approach for both tasks. As
a real example, for the partial sentence “a marcher
from Florida” from the test data, the pipelined approach failed to identify “marcher” as a PER mention, and thus missed the GEN-AFF relation between “marcher” and “Florida”. Our joint model
correctly identiﬁed the entity mentions and their
Figure 7 shows the details when the
joint model is applied to this sentence.
token “marcher”, the top hypothesis in the beam
is “⟨⊥, ⊥⟩”, while the correct one is ranked second best. After the decoder processes the token
“Florida”, the correct hypothesis is promoted to
the top in the beam by the Neighbor Coherence
features for PER-GPE pair.
Furthermore, after
Entity Mention (%)
Relation (%)
Entity Mention + Relation (%)
Joint w/ Local
Joint w/ Global
Annotator 1
Annotator 2
Inter-Agreement
Table 2: Overall performance on ACE’05 corpus.
hypotheses
ha? marcher?i
ha? marcherPERi
ha? marcher?
ha? marcherPER from?i
ha? marcherPER from? FloridaGPEi
ha? marcher?
from? FloridaGPEi
ha? marcherPER from? FloridaGPEi
ha? marcher?
from? FloridaGPEi
Two competing hypotheses for “a
marcher from Florida” during decoding.
linking the two mentions by GEN-AFF relation,
the ranking of the incorrect hypothesis “⟨⊥, ⊥⟩”
is dropped to the 4-th place in the beam, resulting
in a large margin from the correct hypothesis.
The human F1 score on end-to-end relation extraction is only about 70%, which indicates it is a
very challenging task. Furthermore, the F1 score
of the inter-annotator agreement is 51.9%, which
is only 2.4% above that of our proposed method.
Compared to human annotators, the bottleneck
of automatic approaches is the low recall of relation extraction. Among the 631 remaining missing relations, 318 (50.3%) of them were caused
by missing entity mention arguments.
nominal mention heads rarely appear in the training data, such as persons (“supremo”, “shepherd”, “oligarchs”, “rich”), geo-political entity
mentions (“stateside”), facilities (“roadblocks”,
“cells”), weapons (“sim lant”, “nukes”) and vehicles (“prams”). In addition, relations are often
implicitly expressed in a variety of forms. Some
examples are as follows:
• “Rice has been chosen by President Bush to
become the new Secretary of State” indicates
“Rice” has a PER-SOC relation with “Bush”.
• “U.S. troops are now knocking on the door of
Baghdad” indicates “troops” has a PHYS relation with “Baghdad”.
• “Russia and France sent planes to Baghdad” indicates “Russia” and “France” are involved in
an ART relation with “planes” as owners.
In addition to contextual features, deeper semantic knowledge is required to capture such implicit semantic relations.
Comparison with State-of-the-art
Table 3 compares the performance on ACE’04
corpus. For entity mention extraction, our joint
model achieved 79.7% on 5-fold cross-validation,
which is comparable with the best F1 score 79.2%
reported by on singlefold. However, Florian et al. used some
gazetteers and the output of other Information Extraction (IE) models as additional features, which
provided signiﬁcant gains ).
Since these gazetteers, additional data sets and external IE models are all not publicly available, it is
not fair to directly compare our joint model with
their results.
For end-to-end entity mention and relation extraction, both the joint approach and the pipelined
baseline outperform the best results reported
by under the same setting.
Related Work
Entity mention extraction ) and
relation extraction ) have
drawn much attention in recent years but were
Entity Mention (%)
Relation (%)
Entity Mention + Relation (%)
Chan and Roth 
Joint w/ Local
Joint w/ Global
Table 3: 5-fold cross-validation on ACE’04 corpus. Bolded scores indicate highly statistical signiﬁcant
improvement as measured by paired t-test (p < 0.01)
usually studied separately. Most relation extraction work assumed that entity mention boundaries
and/or types were given. Chan and Roth reported the best results using predicted entity mentions.
Some previous work used relations and entity mentions to enhance each other in joint
inference frameworks, including re-ranking , Integer Linear Programming (ILP) , and Card-pyramid
Parsing .
work noted the advantage of exploiting crosscomponent interactions and richer knowledge.
However, they relied on models separately learned
for each subtask.
As a key difference, our approach jointly extracts entity mentions and relations using a single model, in which arbitrary soft
constraints can be easily incorporated. Some other
work applied probabilistic graphical models for
joint extraction ). By contrast, our work employs an
efﬁcient joint search algorithm without modeling
joint distribution over numerous variables, therefore it is more ﬂexible and computationally simpler. In addition, used goldstandard mention boundaries.
Our previous work used structured perceptron with token-based decoder to
jointly predict event triggers and arguments based
on the assumption that entity mentions and other
argument candidates are given as part of the input.
In this paper, we solve a more challenging problem: take raw texts as input and identify
the boundaries, types of entity mentions and relations all together in a single model. Sarawagi and
Cohen proposed a segment-based CRFs
model for name tagging. Zhang and Clark 
used a segment-based decoder for word segmentation and pos tagging. We extended the similar idea
to our end-to-end task by incrementally predicting
relations along with entity mention segments.
Conclusions and Future Work
In this paper we introduced a new architecture
for more powerful end-to-end entity mention and
relation extraction.
For the ﬁrst time, we addressed this challenging task by an incremental
beam-search algorithm in conjunction with structured perceptron. While detecting mention boundaries jointly with other components raises the challenge of synchronizing multiple assignments in
the same beam, a simple yet effective segmentbased decoder is adopted to solve this problem.
More importantly, we exploited a set of global features based on linguistic and logical properties of
the two tasks to predict more coherent structures.
Experiments demonstrated our approach signiﬁcantly outperformed pipelined approaches for both
tasks and dramatically advanced state-of-the-art.
In future work, we plan to explore more soft and
hard constraints to reduce search space as well as
improve accuracy. In addition, we aim to incorporate other IE components such as event extraction
into the joint model.
Acknowledgments
We thank the three anonymous reviewers for their
insightful comments. This work was supported by
the U.S. Army Research Laboratory under Cooperative Agreement No. W911NF-09-2-0053 (NS-
CTA), U.S. NSF CAREER Award under Grant
IIS-0953149, U.S. DARPA Award No. FA8750-
13-2-0041 in the Deep Exploration and Filtering
of Text (DEFT) Program, IBM Faculty Award,
Google Research Award and RPI faculty start-up
The views and conclusions contained in
this document are those of the authors and should
not be interpreted as representing the ofﬁcial policies, either expressed or implied, of the U.S. Government. The U.S. Government is authorized to
reproduce and distribute reprints for Government
purposes notwithstanding any copyright notation