DisturbLabel: Regularizing CNN on the Loss Layer
Lingxi Xie1 ∗Jingdong Wang2
Meng Wang4
1Department of Statistics, University of California, Los Angeles, Los Angeles, CA, USA
2Microsoft Research, Beijing, China
3Department of Computer Science, Shanghai Jiao Tong University, Shanghai, China
4School of Computer and Information, Hefei University of Technology, Hefei, Anhui, China
5Department of Computer Science, University of Texas at San Antonio, San Antonio, TX, USA
 
 
 
 
 
During a long period of time we are combating over-
ﬁtting in the CNN training process with model regularization, including weight decay, model averaging, data augmentation, etc. In this paper, we present DisturbLabel, an
extremely simple algorithm which randomly replaces a part
of labels as incorrect values in each iteration. Although
it seems weird to intentionally generate incorrect training
labels, we show that DisturbLabel prevents the network
training from over-ﬁtting by implicitly averaging over exponentially many networks which are trained with different
label sets.
To the best of our knowledge, DisturbLabel
serves as the ﬁrst work which adds noises on the loss layer.
Meanwhile, DisturbLabel cooperates well with Dropout to
provide complementary regularization functions. Experiments demonstrate competitive recognition results on several popular image recognition datasets.
1. Introduction
Deep Convolutional Neural Networks (CNNs) have
shown signiﬁcant performance gains in image recognition . The large image repository, ImageNet , and the
high-performance computational resources such as GPUs
played very important roles in the resurgence of CNNs.
Meanwhile, a number of research attempts on various aspects have been made to learn the deep hierarchical structure better and faster .
CNN also provides
efﬁcient visual features for other tasks .
∗This work was done when Lingxi Xie and Zhen Wei were interns
at MSR. This work was supported by ARO grant W911NF-15-1-0290,
Faculty Research Gift Awards by NEC Labs of America and Blippar, and
NSFC 61322201, 61429201 and 61432019. We thank Prof. Alan Yuille
and the anonymous reviewers for instructive discussions.
Many regularization techniques have been developed
to prevent neural network from over-ﬁtting, e.g., the ℓ2regularization over the weights (a.k.a., weight decay) ,
Dropout which discards randomly-selected activations on the (hidden) layers during training, DropConnect which sets randomly-selected weights to zero
during training, data argumentation which manipulates the
input data , and early stopping the iteration .
In this paper, we propose DisturbLabel which imposes
the regularization within the loss layer. In each training
iteration, DisturbLabel randomly selects a small subset of
samples (from those in the current mini-batch) and randomly sets their ground-truth labels to be incorrect, which
results in a noisy loss function and, consequently, noisy
gradient back-propagation. To the best of our knowledge,
this is the ﬁrst attempt to regularize the CNN on the loss
layer. We show that DisturbLabel is an alternative approach
to combining a large number of models that are trained with
different noisy data. Experimental results show that DisturbLabel achieves comparable performance with Dropout
and that it, in conjunction with Dropout, obtains better
performance on several image classiﬁcation benchmarks.
The rest of this paper is organized as follows. Section 2
brieﬂy introduces related work.
The DisturbLabel algorithm is presented in Section 3. The discussions and the
cooperation with Dropout are presented in Sections 4 and 5,
respectively. Experimental results are shown in Section 6,
and we conclude our work in Section 7.
2. Related Work
The recent great success of CNNs in image recognition has beneﬁtted from and inspired a wide range of research efforts, such as designing deeper network structures , exploring or learning non-linear activation functions , developing new pooling oper-
 
weight decay
DropConnect
data augmentation
stochastic pooling
DisturbLabel
hidden nodes
input nodes
pooling layer
loss layer
Table 1. Comparison with different CNN regularization techniques. Please refer to the texts for detailed references.
Figure 1. An illustration of the DisturbLabel algorithm (α = 10%). A mini-batch of 10 training samples is used as the toy example. Each
sample is disturbed with the probability α. A disturbed training sample is marked with a red frame and the disturbed label is written below
the frame. Even if a sample is disturbed, the label may remain unchanged (e.g., the digit 3 in the 3rd mini-batch).
ations , introducing better optimization techniques , regularization techniques preventing the network from over-ﬁtting , etc.
Avoiding over-ﬁtting is a major challenge against training robust CNN models. The early solutions include reducing the model complexity by using fewer parameters or
sharing parameters , early stopping in which training is stopped before convergence, weight decay which
can be interpreted as a way of constraining the parameters
using the ℓ2-regularization and is now widely-adopted.
Recently, various regularization methods have been introduced. Data augmentation generates more training data
as the input of the CNN by randomly cropping, rotating and
ﬂipping the input images , and adding noises to the
image pixels . Dropout randomly discards a part
of neuron response (the hidden neurons) during the training and only updates the remaining weights in each minibatch iteration.
DropConnect instead only updates
a randomly-selected subset of weights.
Stochastic Pooling changes the deterministic pooling operation and
randomly samples one input as the pooling result in probability during training. Probabilistic Maxout instead
turns the Maxout operation to stochastic. In contrast,
our approach (DisturbLabel) imposes the regularization at
the loss layer.
A comparison of different regularization
methods is summarized in Table 1.
There are other research works that are related to noisy
labeling. explores the performance of discriminativelytrained CNNs on the noisy data, where there are some
freely available labels for each image which may or may
not be accurate. In contrast, our approach (DisturbLabel)
assumes the labeling is correct and randomly changes the
labels in a small probability in each mini-batch iteration,
which means that the label of a training sample is correct in
most iterations. Different from other works adding noise
to the input unit , our work is a way of
regularizing a neural network by adding noise to its loss
layer (related to the output unit).
3. The DisturbLabel Algorithm
We start with the typical CNN training process.
image dataset is given as D = {(xn, yn)}N
n=1, in which the
data point is a D-dimensional vector xn ∈RD, and the label is a C-dimensional vector yn = [0, · · · , 0, 1, 0, · · · , 0]⊤
with the entry of the corresponding class being 1 and all
the others being 0. The goal is to train a CNN model M:
f(x; θ) ∈RC, in which θ represents the model parameters.
θ is often initialized as a set of white noises θ0, then
updated using stochastic gradient descent (SGD) . The
t-th iteration of SGD updates the current parameters θt as:
θt+1 = θt + γt ·
∇θt[l(x, y)].
Here, l(x, y) is a loss function, e.g., softmax or square loss.
∇θt[l(x, y)] is computed using gradient back-propagation.
Dt is a mini-batch randomly drawn from the training dataset
D, and γt is the learning rate.
DisturbLabel works on each mini-batch independently.
It performs an extra sampling process, in which a disturbed
label vector ey = [ey1, ey2, . . . , eyC]⊤is randomly generated for each data (x, y) from a Multinoulli (generalized
Bernoulli) distribution P(α):
The Multinoulli distribution P(α) is deﬁned as pc
· α and pi =
C · α for i ̸= c. α is the noise
rate, and c is the ground-truth label (i.e., in the true label
vector y, yc = 1). In other words, we disturb each training
sample with the probability α. For each disturbed sample,
the label is randomly drawn from a uniform distribution
over {1, 2, . . . , C}, regardless of the true label.
Algorithm 1 DisturbLabel
1: Input: D = {(xn, yn)}N
n=1, noise rate α.
2: Initialization: a network model M: f(x; θ0) ∈RC;
3: for each mini-batch Dt = {(xm, ym)}M
for each sample (xm, ym) do
Generate a disturbed label eym with Eqn (2);
Update the parameters θt with Eqn (1);
8: end for
9: Output: the trained model M′: f(x; θT ) ∈RC.
The pseudo codes of DisturbLabel are listed above. An
illustration of DisturbLabel is shown in Figure 1.
3.1. The Effect of the Noise Rate
The noise rate α determines the expected fraction ( C−1
α) of training data in a mini-batch which are assigned incorrect labels. When α = 0%, there are no noises involved,
and the algorithm degenerates to the ordinary case. When
α →100%, we are actually discarding most of the labels
and the training process becomes nearly unsupervised (as
the probability assigned to any class is nearly 1
C ). It is often
necessary to set a relatively small α, although it is possible
to obtain an efﬁcient network with a rather large α (e.g.,
training the LeNet with α = 90% achieves < 2% testing
error rate on MNIST).
We evaluate the recognition accuracy on both MNIST
and CIFAR10, by training the LeNet with different noise
rates α, We summarize the results in Figures 2 and 3, respectively. It is observed that DisturbLabel with a relatively
small α (e.g., 10% or 20%) achieves higher recognition
accuracy than the model without regularization (α = 0%).
This veriﬁes that DisturbLabel does improve the generalization ability of the trained CNN model (Section 3.2 provides
an empirical veriﬁcation that the improvement comes from
preventing over-ﬁtting).
When the noise rate α goes up
to 50%, DisturbLabel signiﬁcantly causes the network to
converge slower, meanwhile produces lower recognition
accuracy compared to smaller noises, which is reasonable
as the labels of the training data are not reliable enough.
3.2. DisturbLabel as a Regularizer
We empirically show that DisturbLabel is able to prevent
the network training from over-ﬁtting. Figures 4 and 5 show
the results on the MNIST and CIFAR10 datasets using the
normal training without regularization and the DisturbLabel
algorithm over the same CNN structure. In addition, we
also report the results when training the CNN with Dropout
which is an alternative approach of CNN regularization.
We can observe that without regularization, the training
error quickly drops to quite a low level, e.g., almost 0% on
MNIST and close to 3% on CIFAR10, but the testing error
stops decreasing at a high level. In contrast, the training
error with DisturbLabel drops slower and is consistently
larger than that without regularization. However, the testing error becomes lower, verifying that the improvement
comes from preventing over-ﬁtting. Similar results are also
obtained in the case with the Dropout regularization. This
reveals that training a CNN with regularization (either DisturbLabel or Dropout) yields stronger generalization ability.
Theoretically, we apply DisturbLabel to a convex model.
Consider a linear regression task on the dataset D, the
linear model y
w⊤x, and the loss function L
The gradient over w is
xn. In our approach, each label yn
may be disturbed as eyn, and the gradient becomes ∂L
 w⊤xn −eyn
xn. Their difference is PN
yn)xn assuming w is the same. With ℓ2-regularization, the
extra term λ
2 is added to the loss function, and the
term λw added to the gradient over w. It is different from
our approach which adds PN
n=1 (eyn −yn) xn. Therefore,
our approach, observed from the simple convex problem,
has a damping effect, but different from ℓ2-regularization.
4. Discussions
4.1. Difference from Soft Labeling
Consider the soft labeling problem, where each data
point x is assigned to a label with probability. Denote the
label vector by y′, which is a C-dimensional vector, with
the c-th dimension being 1 −C−1
· α and all others being
C , and α is the noise level. Then we can normally train
the CNN over the same data x and the soft label y′, using
which the loss function is changed. Here we consider the
standard cross-entropy loss function, and the derivation of
other choices (e.g., logistic loss, square loss, etc.) is similar.
The gradient for a training sample (x, y′) is:
n −f|1 = −
However in DisturbLabel, the gradient is computed as:
∂θ |eyn −f|1 = −
∂|eyn −f|1
Number of Epochs
Recognition Error Rate
Figure 2. MNIST recognition error rate with respect to the
noise level α (using LeNet).
Number of Epochs
Recognition Error Rate
Figure 3. CIFAR10 recognition error rate with respect to
the noise level α (using LeNet).
Number of Epochs
Recognition Error Rate
No Reg., training
No Reg., testing
Dropout, training
Dropout, testing
DropLabel, training
DropLabel, testing
Figure 4. MNIST training vs. testing error on the LeNet
with: no regularization, Dropout and DisturbLabel.
Number of Epochs
Recognition Error Rate
No Reg., training
No Reg., testing
Dropout, training
Dropout, testing
DropLabel, training
DropLabel, testing
Figure 5. CIFAR10 training vs. testing error on the LeNet
with: no regularization, Dropout and DisturbLabel.
The empirical evaluation on the MNIST and CIFAR10
datasets is shown in Figures 6 and 7, respectively.
can observe that using soft labels generates nearly the same
accuracy compared to ordinary training, whereas DisturbLabel signiﬁcantly improves recognition accuracy. It is not
surprising that DisturbLabel is not equivalent to soft label
though the expectation of the gradient in DisturbLabel is
equal to the gradient in soft label (as E(ey) = y′). This reveals that using soft labels does not bring the regularization
ability as DisturbLabel does, which is also validated in the
distillation solution , similar to the soft labeling, though
it brings an advantage, making the network converge faster.
4.2. Interpretation as Model Ensemble
We show that DisturbLabel can be interpreted as an
implicit model ensemble. Consider a normal noisy dataset
(xn, eyn)N
, which is generated by assigning an
incorrect label eyn ̸= yn to xn with a probability α for
each data point in D. Combining neural network models
that are trained on different noisy sets is usually helpful .
However, separately training nets is prohibitively expensive
as there are exponentially many noisy datasets. Even if we
have already trained many different networks, combining
them at the testing stage is very costly and often infeasible.
Each iteration in the DisturbLabel training process is like
an iteration when the network is trained over a different
noisy dataset eD where a mini-batch of samples eDt are
drawn. Thus, training a neural network with DisturbLabel
can be regarded as training many networks with massive
weight sharing but over different training data, where each
training sample is used very rarely.
It is interesting that Dropout can be interpreted as a way
of approximately combining exponentially many different
neural network architectures trained on the same data ef-
ﬁciently, while DisturbLabel can be regarded as a way of
approximately combining exponentially many neural networks with the same architecture but trained on different
noisy data efﬁciently.
In Section 5, we will show that
DisturbLabel cooperates with Dropout to produce better
results than individual models.
Number of Epochs
Recognition Error Rate
soft: α = 10%
noise: α = 10%
soft: α = 20%
noise: α = 20%
MNIST recognition error rate with soft labels
and noisy labels (using the LeNet).
Number of Epochs
Recognition Error Rate
soft: α = 10%
noise: α = 10%
soft: α = 20%
noise: α = 20%
Figure 7. CIFAR10 recognition error rate with soft labels
and noisy labels (using the LeNet).
4.3. Interpretation as Data Augmentation
We analyze DisturbLabel from a data augmentation perspective. Considering a data point (x, y) and its incorrect
label ey, the contribution to the loss is |f(x) −ey|1. This
contribution can be rewritten as |(f(x) −ey + y) −y|1,
where ef(x)
.= f(x) −ey + y can be viewed as a noisy
output. Inspired by , we can project the noisy output
ef(x) back into the input space by minimizing the squared
ef(x) −f(ex)
2, where ex is the augmented sample.
In summary, the data point with a disturbed label (x, ey) can
be transformed to an augmented data point (ex, y).
To verify that DisturbLabel indeed acts as data augmentation, we evaluate the algorithm on the MNIST
dataset with only 1% (600) and 10% (6000) training
samples, meanwhile keep the total number of iterations
unchanged, i.e., each training sample is used 100× and
10× times as it is used in the original training process.
With the LeNet , we obtain 10.92% and 2.83% error
rates on the original testing set, respectively, which are
dramatic compared to 0.86% when the network is trained
on the complete set. Meanwhile, in both cases, the training
error rates quickly decrease to 0, implying that the limited
training data cause over-ﬁtting. DisturbLabel signiﬁcantly
decreases the error rates to 6.38% and 1.89%, respectively.
As a reference, the error rate on the complete training
set is further decreased to 0.66% by DisturbLabel. This
indicates that DisturbLabel improves the quality of network
training with implicit data augmentation, thus it serves as
an effective algorithm especially in the case that the amount
training data is limited.
4.4. Relationship to Other CNN Training Methods
We brieﬂy discuss the relationship between DisturbLabel
and other network training algorithms.
• Other regularization methods.
There exist other
network regularization methods, including DropConnect , Stochastic Pooling , Probabilistic Maxout , etc.
Like Dropout which regularizes
CNNs on the hidden neurons, these methods add regularization on other places such as neuron connections and pooling operations. DisturbLabel regularizes
CNNs on the loss layer, which, to the best of our
knowledge, has never been studied before.
will show in the next section, DisturbLabel cooperates
well with Dropout to obtain superior results to individual modules. We believe that DisturbLabel can also
provide complementary information to other network
regularization methods.
• Other methods dealing with noises. Some previous
works aim at training CNNs with noisy labels.
We emphasize that DisturbLabel is intrinsically different with these methods since the problem settings
are completely different. In these problems, training
data suffer from noises (incorrect annotations), and
researchers discuss the possibility of overcoming the
noises towards an accurate training process. DisturbLabel, on the other hand, assumes that all the groundtruth labels are correct, and intentionally generates
incorrect labels on a small fraction of data to prevent
the network from over-ﬁtting. In summary, inaccurate
annotations may be harmful, but factitiously introducing noises is helpful to training a robust network.
• Other network structures.
We are also interested
in other sophisticated network structures, such as
the Maxout Networks , the Deeply-Supervised
Nets , the Network-in-Network and the Recurrent Neural Networks . Thanks to the generality, DisturbLabel can be adopted on these networks to
improve their generalization ability.
Number of Epochs
Recognition Error Rate
drop = 0.5, α = 0%
drop = 0.5, α = 10%
drop = 0.5, α = 20%
Figure 8. MNIST recognition error rate with drop rate 0.5
and different noise levels α (using the LeNet).
Number of Epochs
Recognition Error Rate
drop = 0.5, α = 0%
drop = 0.5, α = 5%
drop = 0.5, α = 10%
CIFAR10 recognition error rate with drop rate
0.5 and different noise levels α (using the LeNet).
5. Cooperation with Dropout
We have shown that DisturbLabel regularizes the CNN
on the loss layer. This is different from Dropout , which
regularizes the CNN on hidden layers.
DisturbLabel is
an approximate ensemble of many CNN models with the
same structure trained over different noisy datasets, while
Dropout is an approximate ensemble of many CNN models with different structures trained over the same data.
These two regularization strategies are complementary. We
empirically discuss the combination of DisturbLabel with
Dropout, which leads to an ensemble of many CNN models
with different structures trained over different noisy data.
We report the results with various noise levels α for
DisturbLabel and a ﬁxed drop rate for Dropout over the
MNIST and CIFAR10 datasets in Figures 8 and 9, respectively. In general, the proper combination of Dropout with
DisturbLabel beneﬁts the recognition accuracy improvement. In the MNIST dataset, the best result is obtained
when α = 10%, meanwhile α = 20% performs much
worse. We note that in Figure 2, without Dropout, α = 10%
and α = 20% produce comparable results. In the CIFAR10
dataset, α = 10% does not help to improve the accuracy
(close to baseline), while in Figure 3, we get comparable
better results using α = 10% and α = 20%. The above
experiments show that both DisturbLabel and Dropout add
regularization to network training.
If both strategies are
adopted, we need to reduce the regularization power properly to prevent “under-ﬁtting”.
In the later experiments, if both Dropout and DisturbLabel are used, we will reduce the noise level α by half to
prevent the regularization on network training from being
too strong. In the case that DisturbLabel provides strong
regularization, e.g., in the case of ImageNet training where
the wrong label is distributed over all the 1000 categories,
we will slightly decrease the drop rate of Dropout for the
same purpose.
6. Experiments
We evaluate DisturbLabel on ﬁve popular datasets, i.e.,
MNIST and SVHN for digit recognition, CI-
FAR10/CIFAR100 for natural image recognition, and
ImageNet for large-scale visual recognition.
6.1. The MNIST Dataset
MNIST is one of the most popular datasets for
handwritten digit recognition.
This dataset consists of
60000 training images and 10000 testing images, uniformly
distributed over 10 classes (0–9).
All the samples are
28 × 28 grayscale images.
We use a modiﬁed version of the LeNet as the
baseline. The input image is passed through two units consisting of convolution, ReLU and max-pooling operations.
In which, the convolutional kernels are of the scale 5×5, the
spatial stride 1, and max-pooling operators are of the scale
2 × 2 and the spatial stride 2. The number of convolutional
kernels are 32 and 64, respectively. After the second maxpooling operation, a fully-connect layer with 512 ﬁlters is
added, followed by ReLU and Dropout. The ﬁnal layer is
a 10-way classiﬁer with the softmax loss function. We use
a set of abbreviation to represent the above network con-
ﬁguration as:
[C5(S1P0)@32-MP2(S2)]-[C5(S1P0)@64-
MP2(S2)]-FC512-D0.5-FC10.
To obtain higher recognition accuracy, we also train
a more complicated BigNet.
The cross-map normalization is adopted after each pooling layer, and the parameter K for normalization is proportional to the logarithm
of the number of kernels. The network conﬁguration is abbreviated as: [C5(S1P2)@128-MP3(S2)]-[C3(S1P1)@128-
D0.7-C3(S1P1)@256-MP3(S2)]-D0.6- [C3(S1P1)@512]-
D0.5-[C3(S1P1)@1024-MPS(S1)]-D0.4-FC10. Here, the
number S is the map size before the ﬁnal (global) maxpooling, before which the down-sampling rate is 4. Therefore, if the input image size is W × W, S = ⌊W/4⌋. The
Jarrett 
Sermanet 
Zeiler 
Zeiler 
Goodfellow 
Goodfellow 
Liang 
Liang 
LeNet, no Reg.
LeNet, no Reg.
LeNet, Dropout
LeNet, Dropout
LeNet, DisturbLabel
LeNet, DisturbLabel
LeNet, both Reg.
LeNet, both Reg.
BigNet, no Reg.
BigNet, no Reg.
BigNet, Dropout
BigNet, Dropout
BigNet, DisturbLabel
BigNet, DisturbLabel
BigNet, both Reg.
BigNet, both Reg.
Table 2. Recognition error rates (%) on the MNIST and SVHN datasets. DA: data augmentation (random cropping).
BigNet is feasible for data augmentation based on image
cropping as the input image size is variable.
For data augmentation, we randomly crop input images
into 24 × 24 pixels.
We apply (40, 20, 20, 20) training
epochs for the LeNet-based conﬁgurations with learning
 10−3, 10−4, 10−5, 10−6
For the BigNet-based
conﬁgurations, the numbers are (200, 100, 100, 100) and
 10−2, 10−3, 10−4, 10−5
, respectively.
We evaluate DisturbLabel with the noise level α = 20%.
According to the results shown in Table 2, DisturbLabel
produces consistent accuracy gain over models without regularization, and also cooperates with Dropout to further
improve the recognition performance. Train the BigNet using both Dropout and DisturbLabel achieves a 0.33% error
rate without data augmentation, which outperforms several
recently reported results . In comparison with 
which applies more complicated data augmentation (e.g.,
image rotation), we only use randomly image cropping and
obtain a comparable error rate (0.28% vs. 0.23%).
6.2. The SVHN Dataset
The SVHN dataset is a larger collection of 32 × 32
RGB images, i.e., 73257 training samples, 26032 testing
samples, and 531131 extra training samples. We preprocess
the data as in the previous methods , i.e., selecting 400
samples per category from the training set as well as 200
samples per category from the extra set, using these 6000
images for validation, and the remaining 598388 images as
training samples. We also use Local Contrast Normalization
(LCN) for data preprocessing .
We use another version of the LeNet.
32 × 3 image is passed through three units consisting
of convolution, ReLU and max-pooling operations.
Using abbreviation, the network conﬁguration can be written
[C5(S1P2)@32-MP3(S2)]-[C5(S1P2)@32-MP3(S2)]-
[C5(S1P2)@64-MP3(S2)]-FC64-D0.5-FC10.
Padding of
2 pixels wide is added in each convolution operation to
preserve the width and height of the data. The BigNet is
also used to achieve higher accuracy. The training epochs,
learning rates and data augmentation settings remain the
same as in the MNIST experiments.
We evaluate DisturbLabel with the noise level α = 20%,
and summarize the results in Table 2. We can observe that
DisturbLabel improves the recognition accuracy, either with
or without using Dropout. With data augmentation and both
regularization methods, we achieve a competitive 2.02%
error rate.
6.3. The CIFAR Datasets
The CIFAR10 and CIFAR100 datasets are both
subsets drawn from the 80-million tiny image database .
There are 50000 images for training, and 10000 images for
testing, all of them are 32 × 32 RGB images. CIFAR10
contains 10 basic categories, and CIFAR100 divides each
of them into a ﬁner level. In both datasets, training and testing images are uniformly distributed over all the categories.
We use exactly the same network conﬁguration as in the
SVHN experiments, and add left-right image ﬂipping into
data augmentation with the probability 50%.
We evaluate DisturbLabel with the noise level α = 10%.
In CIFAR-100, we slightly modify DisturbLabel by only
allowing disturbing the label among 10 ﬁner-level categories. We compare our results with the state-of-the-arts
in Table 3. Once again, DisturbLabel produces consistent
accuracy gain in every single case, either with or without
Dropout. On CIFAR10, the BigNet with Dropout produces
an excellent baseline (7.08% error rate), and DisturbLabel
further improves the performance (6.98% error rate) with
Zeiler 
Zeiler 
Goodfellow 
Goodfellow 
Srivastava 
Liang 
Liang 
LeNet, no Reg.
LeNet, no Reg.
LeNet, Dropout
LeNet, Dropout
LeNet, DisturbLabel
LeNet, DisturbLabel
LeNet, both Reg.
LeNet, both Reg.
BigNet, no Reg.
BigNet, no Reg.
BigNet, Dropout
BigNet, Dropout
BigNet, DisturbLabel
BigNet, DisturbLabel
BigNet, both Reg.
BigNet, both Reg.
Table 3. Recognition error rates (%) on the CIFAR10 and CIFAR100 datasets. DA: data augmentation (random cropping and ﬂipping).
0.18 (−2%)
0.23 (−1%)
0.28 (+0%)
0.33 (+1%)
0.38 (+2%)
0.43 (+3%)
0.48 (+4%)
ILSVRC2012
Number of Epochs
Recognition Error Rate (Gain)
drop = 0.50, α = 0% (1)
drop = 0.43, α = 5% (2)
accuracy gain: (1) −(2)
Figure 10.
The error rate and accuracy gain curves on the
ILSVRC2012 validation set (the AlexNet is used).
a complementary regularization function to Dropout. The
success on the CIFAR datasets veriﬁes that DisturbLabel is
generalized: it not only works well in relatively simple digit
recognition, but also helps natural image recognition tasks.
6.4. The ImageNet Database
Finally we evaluate DisturbLabel on the ILSVRC2012
classiﬁcation
database which contains 1000 object categories. The
training set, validation set and testing set contain 1.3M, 50K
and 150K images, respectively. We use the AlexNet 
(provided by the CAFFE library ) with the dropout rate
0.5 as the baseline. The AlexNet structure is abbreviated as:
C11(S4)@96-MP3(S2)-LRN-C5(S1P2)@256-MP3(S2)-
C3(S1P1)@384-C3(S1P1)@384-C3(S1P1)@256-
MP3(S2)-FC4096-D0.5-FC4096-D0.5-FC1000.
that when a training sample is chosen to be disturbed, the
label will be uniformly distributed among all the 1000
classes, introducing strong noises to the training process,
even when the noise level is relatively low (α = 5% is
used). Therefore, we decrease the dropout rate to 0.43 (less
data are dropped) to perform weaker regularization.
The top-1 and top-5 error rates produced by the original
AlexNet are 43.1% and 19.9%, respectively. When DisturbLabel is adopted, the error rates are reduced to 42.8%
and 19.7%, respectively. We emphasize that the accuracy
gain is not so small as it seems (e.g., the VGGNet 
combines two individually trained nets to get a 0.1% gain),
which, once again, veriﬁes that DisturbLabel and Dropout
cooperate well to provide regularization in different aspects.
Figure 10 shows the error rate curve on the validation set.
After about 20 epochs, the model with DisturbLabel produces higher recognition accuracy at each testing phase.
While we only evaluate DisturbLabel on the AlexNet,
we believe that it can also cooperate with other network
architectures, such as the GoogLeNet and the VG-
GNet , since regularization is a common requirement
of deep neural networks.
7. Conclusions
In this paper, we present DisturbLabel, a novel algorithm which regularizes CNNs on the loss layer. DisturbLabel is surprisingly simple, which works by randomly
choosing a small subset of training data, and intentionally setting their ground-truth labels to be incorrect. We
show that DisturbLabel consistently improves the network
training process by preventing it from over-ﬁtting, and that
DisturbLabel can be explained as an alternative solution of
implicit model ensemble and data augmentation.
Meanwhile, DisturbLabel cooperates well with Dropout, which
regularizes CNNs on the hidden neurons.
Experiments
verify that DisturbLabel achieves competitive performance
on several popular image classiﬁcation benchmarks.