Return of Frustratingly Easy Domain Adaptation
Baochen Sun
Department of Computer Science
University of Massachusetts Lowell
Lowell, MA 01854, USA
 
Jiashi Feng
Department of EECS, UC Berkeley,
USA & Department of ECE, National
University of Singapore, Singapore
 
Kate Saenko
Department of Computer Science
University of Massachusetts Lowell
Lowell, MA 01854, USA
 
Unlike human learning, machine learning often fails to handle changes between training (source) and test (target) input
distributions. Such domain shifts, common in practical scenarios, severely damage the performance of conventional machine learning methods. Supervised domain adaptation methods have been proposed for the case when the target data
have labels, including some that perform very well despite
being ‚Äúfrustratingly easy‚Äù to implement. However, in practice, the target domain is often unlabeled, requiring unsupervised adaptation. We propose a simple, effective, and efÔ¨Åcient
method for unsupervised domain adaptation called CORrelation ALignment (CORAL). CORAL minimizes domain shift
by aligning the second-order statistics of source and target
distributions, without requiring any target labels. Even though
it is extraordinarily simple‚Äìit can be implemented in four
lines of Matlab code‚ÄìCORAL performs remarkably well in
extensive evaluations on standard benchmark datasets.
‚ÄúEverything should be made as simple as possible, but
not simpler.‚Äù
Albert Einstein
Introduction
Machine learning is very different from human learning.
Humans are able to learn from very few labeled examples
and apply the learned knowledge to new examples in novel
conditions. In contrast, supervised machine learning methods only perform well when the given extensive labeled
data are from the same distribution as the test distribution.
Both theoretical and practical results have shown that the test error of
supervised methods generally increases in proportion to the
‚Äúdifference‚Äù between the distributions of training and test
examples. For example, Donahue et al. showed that
even state-of-the-art Deep Convolutional Neural Network
features learned on a dataset of 1.2M images are susceptible to domain shift. Addressing domain shift is undoubtedly
critical for successfully applying machine learning methods
in real world applications.
Copyright c‚Éù2016, Association for the Advancement of ArtiÔ¨Åcial
Intelligence (www.aaai.org). All rights reserved.
 
 


  
 
Figure 1: Two Domain Shift Scenarios: object recognition
across visual domains (left) and sentiment prediction across
text domains (right). When data distributions differ across
domains, applying classiÔ¨Åers trained on one domain directly
to another domain is likely to cause a signiÔ¨Åcant performance drop.
To compensate for the degradation in performance due to
domain shift, many domain adaptation algorithms have been
developed, most of which assume that some labeled examples in the target domain are provided to learn the proper
model adaptation. Daume III proposed a supervised
domain adaptation approach notable for its extreme simplicity: it merely changes the features by making domainspeciÔ¨Åc and common copies, then trains a supervised classiÔ¨Åer on the new features from both domains. The method
performs very well, yet is ‚Äúfrustratingly easy‚Äù to implement.
However, it cannot be applied in the situations where the target domain is unlabeled, which unfortunately are quite common in practice.
In this work, we present a ‚Äúfrustratingly easy‚Äù unsupervised domain adaptation method called CORrelation ALignment (CORAL). CORAL aligns the input feature distributions of the source and target domains by exploring their
second-order statistics. More concretely, CORAL aligns the
distributions by re-coloring whitened source features with
the covariance of the target distribution. CORAL is simple and efÔ¨Åcient, as the only computations it needs are (1)
computing covariance statistics in each domain and (2) applying the whitening and re-coloring linear transformation
to the source features. Then, supervised learning proceeds
as usual‚Äìtraining a classiÔ¨Åer on the transformed source features.
Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence (AAAI-16)
Despite being ‚Äúfrustratingly easy‚Äù, CORAL offers surprisingly good performance on standard adaptation tasks.
We apply it to two tasks: object recognition and sentiment prediction (Figure 1), and show that it outperforms
many existing methods. For object recognition, we demonstrate that it works well with both standard ‚ÄúÔ¨Çat‚Äù bag-ofwords features and with state-of-the-art deep CNN features , outperforming existing methods, including recent deep CNN adaptation
approaches . The latter approaches are quite complex
and expensive, requiring re-training of the network and tuning of many hyperparameters such as the structure of the
hidden adaptation layers. In contrast, CORAL only needs to
compute the covariance of the source and target features.
Related Work
Domain shift is a fundamental problem in machine learning, and has also attracted a lot of attention in the speech,
natural language and vision communities . For supervised adaptation, a variety of techniques have been proposed. Some consider the source domain as a prior that regularizes the learning problem in the
sparsely labeled target domain, e.g., . Others minimize the distance between the target and source domains, either by re-weighting the domains
or by changing the feature representation according to some
explicit distribution distance metric .
Some learn a transformation on features using a contrastive
loss . Arguably the simplest and most
prominent supervised approach is the ‚Äúfrustratingly easy‚Äù
feature replication . Given a feature vector
x, it deÔ¨Ånes the augmented feature vector Àúx = (x; x; 0) for
data points in the source and Àúx = (x; 0; x) for data points
in the target. A classiÔ¨Åer is then trained on augmented features. This approach is simple, however, it requires labeled
target examples, which are often not available in real world
applications.
Early techniques for unsupervised adaptation consisted of
re-weighting the training point losses to more closely reÔ¨Çect
those in the test distribution . Dictionary learning methods try to learn a dictionary where the
difference between the source and target domain is minimized in the new representation. Recent state-of-the-art unsupervised approaches 
have pursued adaptation by projecting the source and target
distributions into a lower-dimensional manifold, and Ô¨Ånding
a transformation that brings the subspaces closer together.
Geodesic methods Ô¨Ånd a path along the subspace manifold,
and either project source and target onto points along that
path , or Ô¨Ånd a closedform linear map that projects source points to target . Alternatively, the subspaces can be aligned
by computing the linear map that minimizes the Frobenius
norm of the difference between them . However, these approaches
Figure 2: (a-c) Illustration of CORrelation ALignment
(CORAL) for Domain Adaptation: (a) The original source
and target domains have different distribution covariances,
despite the features being normalized to zero mean and unit
standard deviation. This presents a problem for transferring
classiÔ¨Åers trained on source to target. (b) The same two domains after source decorrelation, i.e. removing the feature
correlations of the source domain. (c) Target re-correlation,
adding the correlation of the target domain to the source
features. After this step, the source and target distributions
are well aligned and the classiÔ¨Åer trained on the adjusted
source domain is expected to work well in the target domain. (d) One might instead attempt to align the distributions by whitening both source and target. However, this will
fail since the source and target data are likely to lie on different subspaces due to domain shift. (Best viewed in color)
only align the bases of the subspaces, not the distribution of
the projected points. They also require expensive subspace
projection and hyperparameter selection.
Adaptive deep neural networks have recently been explored for unsupervised adaptation. DLID trains a joint source and target
CNN architecture, but is limited to two adaptation layers.
ReverseGrad , DAN , and DDC directly optimize
the deep representation for domain invariance, using additional loss layers designed for this purpose. Training with
this additional loss is costly and can be sensitive to initialization, network structure, and other optimization settings. Our
approach, applied to deep features (top layer activations),
achieves better or comparable performance to these more
complex methods, and can be incorporated directly into the
network structure.
Correlation Alignment for Unsupervised
Domain Adaptation
We present an extremely simple domain adaptation method‚Äì
CORrelation ALignment (CORAL)‚Äìwhich works by align-
ing the distributions of the source and target features in an
unsupervised manner. We propose to match the distributions
by aligning the second-order statistics, namely, the covariance.
Formulation and Derivation
We describe our method by taking a multi-class classiÔ¨Åcation problem as the running example. Suppose we are given
source-domain training examples DS = {‚Éóxi}, ‚Éóx ‚ààRD
with labels LS = {yi}, y ‚àà{1, ..., L}, and target data
= {‚Éóui}, ‚Éóu ‚ààRD. Here both ‚Éóx and ‚Éóu are the Ddimensional feature representations œÜ(I) of input I. Suppose Œºs, Œºt and CS, CT are the feature vector means and
covariance matrices. As illustrated in Figure 2, Œºt = Œºs = 0
after feature normalization while CS Ã∏= CT .
To minimize the distance between the second-order statistics (covariance) of the source and target features, we apply
a linear transformation A to the original source features and
use the Frobenius norm as the matrix distance metric:
A ‚à•C ÀÜS ‚àíCT ‚à•2
A ‚à•A‚ä§CSA ‚àíCT ‚à•
where C ÀÜS is covariance of the transformed source features
DsA and ‚à•¬∑ ‚à•2
F denotes the matrix Frobenius norm.
If rank(CS) ‚â•rank(CT ), then an analytical solution can
be obtained by choosing A such that C ÀÜS = CT . However,
the data typically lie on a lower dimensional manifold ,
and so the covariance matrices are likely to be low rank . We derive a solution for
this general case, using the following lemma.
Lemma 1. Let Y be a real
matrix of rank rY and X a real matrix of rank at most r,
where r ‚©ΩrY ; let Y = UY Œ£Y VY be the SVD of Y , and
Œ£Y [1:r], UY [1:r], VY [1:r] be the largest r singular values and
the corresponding left and right singular vectors of Y respectively. Then, X‚àó= UY [1:r]Œ£Y [1:r]VY [1:r]
‚ä§is the optimal solution to the problem of min
X ‚à•X ‚àíY ‚à•2
Theorem 1. Let Œ£+ be the Moore-Penrose pseudoinverse
of Œ£, rCS and rCT denote the rank of CS and CT respectively. Then, A‚àó= USŒ£+
‚ä§UT [1:r]Œ£T [1:r]
2 UT [1:r]
the optimal solution to the problem in Equation (1) with
r = min(rCS, rCT ).
Proof. Since A is a linear transformation, A‚ä§CSA does not
increase the rank of CS. Thus, rC ÀÜ
S ‚©ΩrCS. Since CS and
CT are symmetric matrices, conducting SVD on CS and CT
gives CS = USŒ£SUS
‚ä§and CT = UT Œ£T U ‚ä§
T respectively.
We Ô¨Årst Ô¨Ånd the optimal value of C ÀÜS through considering
the following two cases:
Case 1. rCS > rCT . The optimal solution is C ÀÜS = CT .
Thus, C ÀÜS = UT Œ£T UT
‚ä§= UT [1:r]Œ£T [1:r]UT [1:r]
optimal solution to Equation (1) where r = rCT .
Case 2. rCS ‚©ΩrCT . Then, according to Lemma 1, C ÀÜS =
UT [1:r]Œ£T [1:r]UT [1:r]
‚ä§is the optimal solution to Equation (1) where r = rCS.
Combining the results in the above two cases yields that
= UT [1:r]Œ£T [1:r]UT [1:r]
‚ä§is the optimal solution to
Equation (1) with r = min(rCS, rCT ). We then proceed to
solve for A based on the above result. Let C ÀÜS = A‚ä§CSA,
and we get:
A‚ä§CSA = UT [1:r]Œ£T [1:r]UT [1:r]
Since CS = USŒ£SUS
‚ä§, we have
‚ä§A = UT [1:r]Œ£T [1:r]UT [1:r]
This gives:
‚ä§A) = UT [1:r]Œ£T [1:r]UT [1:r]
Let E = Œ£+
‚ä§UT [1:r]Œ£T [1:r]
2 UT [1:r]
‚ä§, then the right
hand side of the above equation can be re-written as
E‚ä§Œ£SE. This gives
‚ä§A) = E‚ä§Œ£SE
By setting US
‚ä§A to E, we get the optimal solution of A as
‚ä§)(UT [1:r]Œ£T [1:r]
2 UT [1:r]
We can think of transformation A in this way intuitively: the
Ô¨Årst part USŒ£+
‚ä§whitens the source data while the second part UT [1:r]Œ£T [1:r]
2 UT [1:r]
‚ä§re-colors it with the target
covariance. This is illustrated in Figure 2(b) and Figure 2(c)
respectively. The traditional whitening is adding a small regularization parameter Œª to the diagonal elements of the covariance matrix to explicitly make it full rank and then multiply the original feature by the inverse square root (or square
root for coloring) of it. The whitening and re-coloring here
are slightly different from them since the data are likely to
lie on a lower dimensional space and the covariance matrices
could be low rank.
In practice, for the sake of efÔ¨Åciency and stability, we can
perform the classical whitening and coloring. This is advantageous because: (1) it is faster (e.g., the whole CORAL
transformation takes less than one minute on a regular laptop
for DS ‚ààR795√ó4096 and DT ‚ààR2817√ó4096) and more stable, as SVD on the original covariance matrices might not be
stable and might slow to converge; (2) as illustrated in Figure 3, the performance is similar to the analytical solution in
Equation (2) and very stable with respect to Œª. In this paper,
we set Œª to 1. The Ô¨Ånal algorithm can be written in four lines
of MATLAB code as illustrated in Algorithm 1.
One might instead attempt to align the distributions by
whitening both source and target. As shown in Figure 2(d),
this will fail as the source and target data are likely to lie on
Accuracy (%)
Figure 3: Sensitivity of Covariance Regularization Parameter Œª with Œª ‚àà{0, 0.001, 0.01, 0.1, 1}. When Œª = 0, there is
no regularization and we use the analytical solution in Equation (2). Please refer to Section 4.1 for details of tasks.
Algorithm 1 CORAL for Unsupervised Domain Adaptation
Input: Source Data DS, Target Data DT
Output: Adjusted Source Data D‚àó
CS = cov(DS) + eye(size(DS, 2))
CT = cov(DT ) + eye(size(DT , 2))
DS = DS ‚àóC
% whitening source
% re-coloring with target covariance
different subspaces due to domain shift. An alternative approach would be whitening the target and then re-coloring
it with the source covariance. However, as demonstrated
in and our
experiments, transforming data from source to target space
gives better performance. This might be due to the fact that
by transforming the source to target space the classiÔ¨Åer was
trained using both the label information from the source and
the unlabelled structure from the target.
After CORAL transforms the source features to the target
space, a classiÔ¨Åer f ‚Éów parametrized by ‚Éów can be trained on
the adjusted source features and directly applied to target
features. For a linear classiÔ¨Åer f‚Éów(I) = ‚ÉówT œÜ(I), we can
apply an equivalent transformation to the parameter vector
‚Éów instead of the features u. This results in added efÔ¨Åciency
when the number of classiÔ¨Åers is small but the number and
dimensionality of target examples is very high.
Since correlation alignment changes the features only, it
can be applied to any base classiÔ¨Åer. Due to its efÔ¨Åciency,
it can also be especially advantageous when the target domains are changing rapidly, e.g., due to scene changes over
the course of a long video stream.
Relationship to Existing Methods
Relationship to Feature Normalization
It has long been
known that input feature normalization improves many machine learning methods, e.g., .
However, CORAL does not simply perform feature normalization, but rather aligns two different distributions. Standard feature normalization (zero mean and unit variance)
does not address this issue, as illustrated in Figure 2(a). In
this example, although the features are normalized to have
zero mean and unit variance in each dimension, the differences in correlations present in the source and target domains cause the distributions to be different.
Relationship to Manifold Methods
Recent state-of-theart unsupervised approaches project the source and target distributions into a lower-dimensional manifold and
Ô¨Ånd a transformation that brings the subspaces closer together . CORAL
avoids subspace projection, which can be costly and requires
selecting the hyper-parameter that controls the dimensionality of the subspace. We note that subspace-mapping approaches 
only align the top k (subspace dimensionality) eigenvectors
of the source and target covariance matrices. On the contrary, CORAL aligns the covariance matrices, which can
only be re-constructed using all eigenvectors and eigenvalues. Even though the eigenvectors can be aligned well,
the distributions can still differ a lot due to the difference
of eigenvalues between the corresponding eigenvectors of
the source and target data. CORAL is a more general and
much simpler method than the above two as it takes into account both eigenvectors and eigenvalues of the covariance
matrix without the burden of subspace dimensionality selection.
Relationship to MMD methods
Maximum Mean Discrepancy (MMD) based methods , DAN ) for domain adaptation can
be interpreted as ‚Äúmoment matching‚Äù and can express arbitrary statistics of the data. Minimizing MMD with polynomial kernel (k(x, y) = (1 + x‚Ä≤y)d with d = 2) is similar to the CORAL objective, however, no previous work
has used this kernel for domain adaptation nor proposed
a closed form solution to the best of our knowledge. The
other difference is that MMD based approaches usually apply the same transformation to both the source and target domain. As demonstrated in , asymmetric transformations are more Ô¨Çexible and often yield better
performance for domain adaptation tasks. Intuitively, symmetric transformations Ô¨Ånd a space that ‚Äúignores‚Äù the differences between the source and target domain while asymmetric transformations try to ‚Äúbridge‚Äù the two domains.
Application to Deep Neural Networks
Suppose œÜ(I) was computed by a multilayer neural network,
then the inputs to each layer œÜk can suffer from covariate shift as well. Batch Normalization tries to compensate for internal covariate shift by
normalizing each mini-batch to be zero-mean and unitvariance. However, as illustrated in Figure 2, such normalization might not be enough. Even if used with full whitening, Batch Normalization may not compensate for external
covariate shift: the layer activations will be decorrelated for
a source point but not for a target point. What‚Äôs more, as
mentioned in Section 3.2, whitening both domains still does
not work. Our method can be easily integrated into a deep
architecture by treating layers as features ). Although we experiment only with CORAL applied to one hid-
den layer at each time, multilayer CORAL could be used by
implementing the transformations Al as extra layers which
follow each original layer l.
Experiments
We evaluate our method on object recognition and sentiment analysis with both shallow and deep features, using standard
benchmarks and protocols. In all experiments we assume the
target domain is unlabeled.
We follow the standard procedure and use a linear SVM as the base
classiÔ¨Åer. The model selection approach of is used to set the C parameter for the SVM by doing
cross-validation on the source domain. Since there are no
other hyperparameters (except the common regularization
parameter Œª for whitening and coloring, which we discussed
in Section 3.2 and Figure 3) required for our method, the results in this paper can be easily reproduced. To compare to
published methods, we use the accuracies reported by their
authors or conduct experiments using the source code provided by the authors.
Object Recognition
In this set of experiments, domain adaptation is used to
improve the accuracy of an object classiÔ¨Åer on novel image domains. Both the standard OfÔ¨Åce 
and extended OfÔ¨Åce-Caltech10 datasets
are used as benchmarks in this paper. OfÔ¨Åce-Caltech10
contains 10 object categories from an ofÔ¨Åce environment
(e.g., keyboard, laptop, etc.) in 4 image domains: Webcam,
DSLR, Amazon, and Caltech256. The standard OfÔ¨Åce
dataset contains 31 (the same 10 categories from OfÔ¨Åce-
Caltech10 plus 21 additional ones) object categories in 3
domains: Webcam, DSLR, and Amazon. Later, we also
conduct a larger (more data and categories) scale evaluation
on OfÔ¨Åce-Caltech10 and the Cross-Dataset Testbed dataset.
Object Recognition with Shallow Features
the standard protocol of and conduct experiments on the OfÔ¨Åce-Caltech10 dataset with shallow features
(SURF). The SURF features were encoded with 800-bin
bag-of-words histograms and normalized to have zero mean
and unit standard deviation in each dimension. Since there
are four domains, there are 12 experiment settings, namely,
A‚ÜíC (train classiÔ¨Åer on (A)mazon, test on (C)altech),
A‚ÜíD (train on (A)mazon, test on (D)SLR), A‚ÜíW, and
so on. We follow the standard protocol and conduct experiments in 20 randomized trials for each domain shift and
average the accuracy over the trials. In each trial, we use
the standard setting and randomly sample the same
number (20 for Amazon, Caltech, and Webcam; 8 for
DSLR as there are only 8 images per category in the DSLR
domain) of labelled images in the source domain as training
set, and use all the unlabelled data in the target domain as
the test set.
In Table 1, we compare our method to Ô¨Åve recent published methods: SVMA ,
DAM , GFK , SA , and TCA as well as
the no adaptation baseline (NA). GFK, SA, and TCA are
manifold based methods that project the source and target
distributions into a lower-dimensional manifold. GFK integrates over an inÔ¨Ånite number of subspaces along the subspace manifold using the kernel trick. SA aligns the source
and target subspaces by computing a linear map that minimizes the Frobenius norm of their difference. TCA performs
domain adaptation via a new parametric kernel using feature extraction methods by projecting data onto the learned
transfer components. DAM introduces smoothness assumption to enforce the target classiÔ¨Åer share similar decision values with the source classiÔ¨Åers. Even though these methods
are far more complicated than ours and require tuning of hyperparameters (e.g., subspace dimensionality), our method
achieves the best average performance across all the 12 domain shifts. Our method also improves on the no adaptation baseline (NA), in some cases increasing accuracy signiÔ¨Åcantly (from 56% to 86% for D‚ÜíW).
Object Recognition with Deep Features
We follow the
standard protocol of and
conduct experiments on the standard OfÔ¨Åce dataset with
deep features. DLID trains a joint source and target CNN architecture
with an ‚Äúinterpolating path‚Äù between the source and target domain. DANN incorporates the Maximum Mean Discrepancy (MMD) measure as a regularization to reduce the distribution mismatch. DA-NBNN presents
an NBNN-based domain adaptation algorithm that iteratively learns a class metric while inducing a large margin
separation among classes. DECAF 
uses AlexNet pretrained on ImageNet and extracts the fc6
or fc7 layers in the source domains as features to train a
classiÔ¨Åer. It then applies the classiÔ¨Åer to the target domain
directly. DDC adds a domain confusion
loss to AlexNet 
and Ô¨Åne-tunes it on both the source and target domain.
DAN and ReverseGrad are the two most recent domain adaptation approaches based on deep architectures. DAN is similar
to DDC but utilizes a multi-kernel selection method for better mean embedding matching and adapts in multiple layers.
ReverseGrad introduces a gradient reversal layer to allow direct optimization through back-propagation. Both DDC and
ReverseGrad add a new binary classiÔ¨Åcation task by treating
the source and target domain as two classes. They maximize
the binary classiÔ¨Åcation loss to obtain invariant features.
To have a fair comparison, we apply CORAL to both
the pre-trained AlexNet (CORAL-fc6 and CORAL-fc7)
and to AlexNet Ô¨Åne-tuned on the source with SURF
features, following the protocol of .
ReverseGrad
Table 2: Object recognition accuracies of all 6 domain shifts
on the standard OfÔ¨Åce dataset with deep
features, following the protocol of .
and CORAL-FT7). However, the Ô¨Åne-tuning procedures of
DDC, DAN, and ReverseGrad are very complicated as there
is more than one loss and hyper-parameters are needed to
combine them. They also require adding new layers and
data from both source and target domains. We use standard Ô¨Åne-tuning on the source domain only to get the baseline NA results (NA-FT6 and NA-FT7). Since there are
three domains, there are 6 experiment settings. We follow
the protocol of and conduct experiments on
5 random training/test splits and get the mean accuracy for
each domain shift.
In Table 2 we compare our method to the 11 baseline
methods discussed before. Again, our method outperforms
all of these techniques in almost all cases, sometimes by
a very large margin. Note that most of the deep structures
based methods report results only on some settings. We
Ô¨Ånd that the higher level fc7/FT7 features lead to better
performance than fc6/FT6. What‚Äôs more, the NA baselines
also achieve very good performance, even better than all
the manifold methods and some deep methods. However,
CORAL outperforms it consistently and is the only method
achieves better AVG performance across all the 6 shifts. It
also achieves better peformance than the two latest deep
methods (DAN and ReverseGrad) in 2 out of the 3 shifts
they reported.
One interesting Ô¨Ånding is that, although Ô¨Åne-tuning on
the source domain only (NA-FT6 and NA-FT7) does not
achieve better performance on the target domain compared
to the pre-trained network (NA-fc6 and NA-fc7), applying CORAL to the Ô¨Åne-tuned network (CORAL-FT6 and
CORAL-FT7) achieves much better performance than applying CORAL to the pre-trained network (CORAL-fc6
and CORAL-fc7). One possible explanation is that the pretrained network might be underÔ¨Åtting while the Ô¨Åne-tuned
network is overÔ¨Åtting. Since CORAL aligns the source feature distribution to target distribution, overÔ¨Åtting becomes
less of a problem.
A Larger Scale Evaluation
In this section, we repeat the
evaluation on a larger scale. We conduct two sets of experiments to investigate how the dataset size and number
of classes will affect the performance of domain adaptation
methods. In both sets of experiments, we use the ‚Äúfull training‚Äù protocol, where all the source data are used for training, compared to the standard subsampling protocol in the
previous two sections. Since all the target data are used in
the previous two sections, the only difference between these
two settings is the training dataset size of the source domain. To have a direct comparison to Table 1, we conduct
the Ô¨Årst set of experiments on the OfÔ¨Åce-Caltech10 dataset
with SURF features. To investigate the effect of the number of classes, we conduct the second set of experiments on
the Cross-Dataset Testbed 
dataset, with 3847 images for Caltech256 , 4000 images for ImageNet , and 2626 images for SUN over
40 classes, using the only publicly available deep features
(DECAF-fc7).
In Tables 3 and 4, we compare CORAL to SA, GFK, TCA
which have available source code as well as the NA baseline. Table 3 shows the result of the OfÔ¨Åce-Caltech10 dataset
and Table 4 shows the result on the Cross-Dataset Testbed
dataset. In both experiments, CORAL outperforms all the
baseline methods and again the margin on deep features is
Table 3: Object recognition accuracies of all 12 domain shifts on the OfÔ¨Åce-Caltech10 dataset with SURF
features, using the ‚Äúfull training‚Äù protocol.
Table 4: Object recognition accuracies of all 6 domain
shifts on the Testbed Cross-Dataset dataset with DECAF-fc7 features, using the ‚Äúfull
training‚Äù protocol.
Table 5: Review classiÔ¨Åcation accuracies of the 4 standard
domain shifts on the Amazon dataset with bag-ofwords features.
much larger than on shallow features. Comparing Table 3
to Table 1, we can say that the performance difference between NA and other methods is smaller as more source data
is used. This may be due to the fact that as more training data
is used, the classiÔ¨Åer is stronger and can generalize better to
other domains.
Sentiment Analysis
We also evaluate our method on sentiment analysis using
the standard Amazon review dataset . We use the
processed data from , in
which the dimensionality of the bag-of-words features was
reduced to keep the top 400 words without losing performance. This dataset contains Amazon reviews on 4 domains:
Kitchen appliances, DVD, Books, and Electronics. For each
domain, there are 1000 positive and 1000 negative reviews.
We follow the standard protocol of and conduct experiments on 20 random training/test splits and report the mean accuracy for each domain
In Table 5, we compare our method to Ô¨Åve published
methods: TCA , GFS , GFK , SCL , and KMM as well as the no adaptation baseline (NA). GFS is
a precursor of GFK and interpolates features using a Ô¨Ånite
number of subspaces. SCL introduces structural correspondence learning to automatically induce correspondences
among features from different domains. KMM presents
a nonparametric method to directly produce re-sampling
weights without distribution estimation. One interesting observation is that, for this sentiment analysis task, three stateof-the-art methods (TCA, GFS, and GFK) actually perform
worse than the no adaptation baseline (NA). Despite the dif-
Ô¨Åculty of this task, CORAL still performs well and achieves
the best average classiÔ¨Åcation accuracy across the 4 standard
domain shifts.
Discussion
One interesting result is that the margin between CORAL
and other published methods is much larger on deep features (e.g. 64.0 of CORAL-fc6 compared to 49.1 of SAfc6 in Table 2) than on bag-of-words features. This could
be because deep features are more strongly correlated than
bag-of-words features (e.g. the largest singular value of the
covariance matrix of Amazon-fc6 is 354 compared to 27 of
Amazon-SURF). Similarly, the improvement on images (Tables 1-4) is much larger than text (Table 5), possibly because
bag-of-words text features are extremely sparse and less correlated than image features. As demonstrated in , high level deep features are more ‚Äúparts‚Äù
or ‚Äúobjects‚Äô. Intuitively, ‚Äúparts‚Äù or ‚Äúobjects‚Äù should be more
strongly correlated than ‚Äúedges‚Äù (e.g., arm and head of a
person are more likely to appear jointly).
These Ô¨Åndings suggest that CORAL is extremely valuable
in the era of deep learning. Applying CORAL to deep text
features is part of future work.
Conclusion
In this article, we proposed an simple, efÔ¨Åcient and effective
method for domain adaptation. The method is ‚Äúfrustratingly
easy‚Äù to implement: the only computation involved is recoloring the whitened source features with the covariance of
the target domain.
Extensive experiments on standard benchmarks demonstrate the superiority of our method over many existing
state-of-the-art methods. These results conÔ¨Årm that CORAL
is applicable to multiple features types, including highlyperforming deep features, and to different tasks, including
computer vision and natural language processing.
Acknowledgments
The authors would like to thank Mingsheng Long, Judy
Hoffman, and Trevor Darrell for helpful discussions and
suggestions; the reviewers for their valuable comments.
The Tesla K40 used for this research was donated by the
NVIDIA Corporation. This research was supported by NSF
Awards IIS-1451244 and IIS-1212928.