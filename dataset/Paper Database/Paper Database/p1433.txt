Finding Similar Time Series
Gautam Das 1 and Dimitrios Gunopulos 2 and Heikki Mannila 3
i Univ. of Memphis, Memphis TN, . Research done
while the author was visiting the Univ. of Helsinki.
2 IBM Almaden RC K55/B1, 650 Harry Rd., San Jose CA 95120, USA,
 . Research done while the author was visiting the Univ.
of Helsinld.
Univ. of Helsinki, Dept. of Computer Science, FIN-00014 Helsinki, Finland,
 .
Abstract. Similarity of objects is one of the crucial concepts in sev-
eral applications, including data mining. For complex objects, similarity
is nontrivial to define. In this paper we present an intuitive model for
measuring the similarity between two time series. The model takes into
account outliers, different scaling functions, and variable sampling rates.
Using methods from computational geometry, we show that this notion
of similarity can be computed in polynomial time. Using statistical ap-
proximation techniques, the algorithms can be speeded up considerably.
We give preliminary experimental results that show the naturalness of
the notion.
Introduction
Being able to measure the similarity or dissimilarity between objects is a crucial
point in many data retrieval and data mining applications; see for a general
discussion on similarity queries. For complex objects, defining similarity is by no
means trivial. In this paper we consider the problem of defining the similarity
between time series.
Time series are an important class of complex data objects. They arise in
several financial and scientific applications; examples include stock price indices,
the volume of product sales, telecommunications data, one-dimensional medical
signals, audio data, and environmental measurement sequences.
In many cases it is necessary to search within a time series database for
those series that are similar to a given query sequence. This primitive is needed,
for example, for prediction and clustering purposes. While the statistical liter-
ature on time-series is vast, it has not studied similarity notions that would be
appropriate for, e.g., data mining applications.
Intuitively, we consider two sequences similar if they exhibit similar behavior
for a large subset of their length. We assume that the sequences to be compared
outliers, i.e., values that are measurement errors and should be omitted when
comparing the sequence against others;
different scaling factors and baselines: the sequences can, e.g., be measure-
ments done using different devices, and the scaling and baseline values can
be different.
Our goal is to obtain a measure of similarity that would be resistant 4 with respect
to such changes. That is, if we have a sequence X and modify it to sequence X I
by introducing outliers, by scaling and translation, and by adding or removing
some observations, the sequences X and X ~ should still be considered reasonably
We give a definition of similarity that fulfills these conditions and study
algorithms that can be used to compute the similarity between sequences. We
also discuss some generalizations and specializations of the similarity concept.
In detail, the paper is organized as follows. In Section 2 we present the similarity
model. In Sections 3 and 4 we give an exact algorithm that finds the similarity
of two time sequences, where similarity is defined as above. In Section 5 we
give a faster approximation algorithm. This algorithm was implemented and in
Section 6 we present some experimental results. Finally, Section 7 is a short
conclusion.
The results we present here represent preliminary work, to demonstrate the
validity of the approach. A rigorous comparison with different methods will
follow. In this extended abstract some of the proofs of lemmas and theorems
appear in the Appendix.
similarity
A time series is a finite sequence X of integers: (ml,..., m~).
Fix a set U of transforraation functions for mapping integers to integers. The
set 5 v could consist of, say, all linear functions m ~ am + b, all scaling functions
m ~-~ am, all quadratic functions, all monotone functions, or just the identity
Intuitively, we say that that two sequences X = (ml, m2,..., m~) and Y =
(yl,y2,...,y~) are U-similar, if there is a function f E U such that a long
subsequence X ~ of X can be approximately mapped to a long subsequence Y~
of Y using f.
It is important to note here that X ~ or yr does not consist of consecutive
points of X (respectively Y). Rather, the points of X' (Y'), appear in the same
relative order in X (Y). This means that the matched subsequences allow for
a number of holes (outliers) in the original sequences. Clearly, if X and Y are
similar, the number of outliers will be small, and X ~ and Y~ will approximate
them in length.
Definltionl. Given two time series X = (ml,..., m,~) and Y = (yl,..., y,~),
and numbers 0 < 7,6 _~ 1, the sequences X and Y are (U, 7,6)-similar if and
only if there exist a function f E ~" and subsequences Xf = (mq,...mi,~) and
4 See , pages 1-6 for a discussion of resistance and robustness os statistical
procedures.
',l.car' .....
100 150 200 250 300 350 400 450 500
Fig. 1. Two telecommunication sequences: Each sequence represents the number of
connections on a given physical line over time.
Y] = (yj~,...yj~,,), where ik < i~+1 and j~ < jk+z for all k = 1,...,7n- 1, such
that Vk, 1 < k < 7n,
The parameter 7 (0 < 3' < 1) is used to control the length of the subsequence
of X that can be mapped to Y. The parameter c controls how close we want the
sequences to match. When yj~ and xi~ satisfy the above condition, we say that
they are c-close.
Definition2. For given X, Y, โข, c, the similarity of X and Y is
Sim~,~ (X, Y) = {max7 [ X, Y are (:T, 7, e)-similar}
Sire:r,, (X, Y) is therefore a number between 0 and 1, with numbers closer
to 1 signifying greater similarity. In this paper we mostly consider the collection
of functions 3rli n consisting of linear functions:
:Tli n : {x ~-+ ax + b I a,b C ~}.
This set of functions is reasonably simple, but allows us to find similarities be-
tween sequences with different scaling factors and base values. We call (~lin, 7, r
similarity simply (7, r
Next we very briefly mention some related work; for lack of space, this sec-
tion is strongly abbreviated. The problem of searching for similar sequences was
brought to the database community perhaps mostly by the papers .
The idea of using longest common subsequence in measuring similarity between
sequences of objects has been proposed in . The similarity model presented
here however does not account for different scaling factors and different baseline
values. A similar model has been proposed by Agrawal et. al. . The main dif-
ference is that, this model does not allow outliers within windows of a specified
length W, and the linear function can vary slightly in the length of the matched
common subsequence. See also for a collection of material on sequence com-
subsequences
If we know the function f C Y that is to be used, determining (2-, V, z)-similarity
between X and Y is easy: we form the sequence f(X) by applying f to each ele-
ment of X, and then locate the longest common subsequence between f(X) and
Y. Two numbers are considered equal if they are e-close. The longest common
subsequenee can be found by simple dynamic programming in O(n ~) time (The-
orem 8, in the Appendix); time O(hn) can also be obtained, when the length of
the longest common subsequence is at least n - h ( , Theorem 8 in the Ap-
pendix gives a sketch of the algorithm.) We refer to this algorithm as the less
algorithm, and will use it as a subroutine in the next sections.
The lcss algorithm is able to solve in a simple fashion a seemingly complex
problem of determining which elements of two complex objects correspond to
each other in the maximal pairing between the objects. Note that the sequence
aspect is crucial here: finding maximal pairing between two sets is NP-complete.
A polynomial
for (% s)-similarity
In this section we present a correct algorithm that, given a pair of sequences
X and Y, finds the linear transformation f that maximizes the length of the
longest common subsequence of f(A), B (within r
The algorithm is based on
the use of methods from computational geometry.
The main idea of the algorithm is to locate all fundamentally different linear
transformations and check each one. Given two linear transformations fl and f2,
specified by pairs (al, bl) and (a2, b2), we say that they are equivalent, denoted
fl =li,~ f2, if for all 1 _< i, j < n we have: fl maps zi e-close to yj if and only if
f2 maps z~ r
Lemma 3. There are at most O(n 4) equivalence classes of =tin.
Algorithm 1 Find if sequences A, B are (% E)-similar.
1. For all equivalence classes of--tin, find a representative (a, b).
2. For each pair of (a, b), run the Icss algorithm for the sequences aX + b and
Y, and test whether the length of the longest common subsequence is at least
The following theorem is a corollary of the Algorithm 1 and Lemma 1.
Given two time series X = (xl, . . . , xn) and Y : (Yl, . . . , Yn), and
numbers 0 < 7, e < 1, we can compute if X and Y are (7, ~)-similar in O(n 6)
If we consider the smaller family of scaling functions :Tsc = {~ ~-~ ax [ a C N},
then we obtain the following result.
Theorem 5. Given two time series X -- (~1,..., xn) and Y -~ (Yl,..., Yn), and
0 < %6 < 1, we can compute ifX and Y are (3:sc,%e)-similar in O(n 4) time.
An Approximate Algorithm
The algorithm presented in the previous section shows that the problem of de-
ciding similarity is solvable in polynomial time, but it is of no practical use. In
this section we show how to obtain a faster approximation algorithm.
The main idea is to reduce the number of candidate pairs of (a, b). To do so
we use some statistical arguments to compute bounds for possible values of a
Let X',Y~ be two matched subsequences of length 7n. Then y~/(1 + e) <_
ax~ + b < y~(1 + e), and after summing for all i we obtain:
E(Y')/(1 +e) <_ aE(X') ยง
<_ E(Y')(1 +e)
Let X,~i,~, Y,~i,~ be the subsequences of X and Y of length 7n that minimize
the average, and Xmax, Ym~z be the subsequences that maximize the average.
These subsequences can be found easily, given the value of % after sorting the
points in the input sequences. After we compute E(im~),
E(Xmin), E(Ymin),
E(Y,,~), we can bound the values of E(Y') an E(X') in the above inequality
from above and below. Thus we obtain the following inequalities:
1. b >_ -E(X,~=) a+ E(Ymi,)/(1Tr
2. b < -E(Xm~) a + E(Ymo~)(1 + ~)
These two inequalities define an infinite wedge in (a, b) space (see Figure
2). To get a finite convex area we need at least another inequality. In order
to do that, we use the deviation of the sequences. The deviation of a sequence
X = (xl,...,x,~)
23.308 - 300.156 * x
Fig. 2. These two fines represent the two inequalities that were obtained for a specific
pair of sequences, using the subsequences that minimized or maximized the average.
Ix' - E(X)I
Note that D(a X -4- b) = a D(X).
Lemma 6. Let X ~, Y~ be two matched subsequences of length "yn. Then:
ID(Y') - D(aXt + b)l <_ 27nelE(Y')[
Let Xdmin , Ydmin be the subsequences of length 7n that minimize the devia-
tion, and Xd,~, Ya,~= be the subsequences that maximize the deviation. Then,
from the previous inequality, we have:
2. aD(Xd~)< D(Yd~o=) + 2~neE(Y~,~)
These two inequalities together with the other two ones define a bounded
quadrilateral in (a, b) space.
To use these two inequalities however we have to find the subsequences that
minimize or maximize the deviation.
Given a sequence X = (~z .... ,~n) and 7
9 , assume that
the subsequence of length ~n of X that minimizes the deviation is Xm~n --
1~,~,.8~229Q.cal.junkO.068035-O.865372"
14070272!'cal'junkO"
068035-0.865372"
.............
....... T; ..... T .... , .....
..... ; .... "i ...... ;
100 150 200 250 300 350 400 450 500
Fig. 3. This figure shows the same sequences shown in Figure 1. The linear transfor-
mation 0.068 x - 0.865 maximizes the length of the longest common subsequence for
these sequences.
..., x~n ). If xrn~n = min(z~, ... , x.m) and Xrna= =
.. ., ~.y,~), then
for all zi E X \ Xmin, either xi __< Train/ or T i ~ ~rnazt
The previous lemma shows that the following O(n log n) running time algo-
rithm computes the subsequence of length 7n that minimizes the deviation.
2 Find the subsequence that minimizes the deviation.
1. Sort the points.
2. Slide a window of size 7n,
inside the window.
and compute the deviation of the subsequence
The deviation of the new sequences can be computed incrementally, so step
two of this algorithm can be performed in linear time. To find the subsequence
that maximizes the deviation we use a similar argument. In this case we slide a
window of length (1- 7)n. Now it is the points outside this window that are the
points in the subsequence.
We can now give the outline of the approximation algorithm.
Algorithm 3 Find if sequences X, Y are (7, e)-similar.
1. Compute bounds for a, b.
These define a convex area in (a, b) space.
2. Use a grid to sample the area defined by the bounds.
3. For each grid point (a, b), apply the linear transformation z~ = a~ + b and
run the Icss algorithm for Y, X'.
The running time of the algorithm is O(M(1-7)n2), where M is the number
of sampling points. We are trying to find a longest common subsequence of length
at least ~/n, so the running time of the lcss algorithm is 0(1--y)n2). The accuracy
of the algorithm depends on the size of the sampling grid. In our experiments,
we use a sampling interval of (e/2)aj for a, and a constant value for b.
Experimental
The approximate algorithm was implemented in C, and we used this implementa-
tion to find similar sequences among a set of telecommunication sequences. Each
sequence represented the number of telephone connections that went through a
given physical telephone line over time. The measurements were obtained by
sampling the line every 15 minutes. Some sequences represented the number of
connections that were established during this time, and some represented the
number of connections that were on (but might have been established earlier).
Each sequence was 480 points long (5 days.)
We used a set of 34 sequences, and ran the algorithm for each pair. We
used large values for e, between 0.2 and 0.3, but we observed little variation on
the final results for different values of e. For each pair, 480 minus the length
of longest common subsequence found was used as the distance between two
sequences. Thus we obtained a 34 x 34 distance matrix, which was fed to the
SAS clustering software package.
The results of the clustering were compared to the results of visual classi-
fication of the sequences. The two different kinds of sequences were in differ-
ent clusters. Office phone lines, which present a distinct pattern were clustered
together. Pairs of sequences that appeared similar to a human observer were
clustered together. In addition, similarities that we didn't notice before, mainly
due to different scale, were brought forward. For example Figure 3 shows the
best match for the two sequences of Figure 1. Figure 4 gives an example of the
matchings obtained.
"Y809051.cal"
"ar' -I~[-
O0 150 200 250 300 350 400 450 500
Fig. 4. Of the sequences shown, Y809051 and Y802291 were clustered together, and so
were Y801130 and Y801191, but the two pairs were in different clusters (e = 0.2.)
Discussion
We present an intuitive model to capture the similarity of two time series, and
a practical approximate algorithm to measure the similarity under this model.
The algorithm has been implemented, and has been applied to a set of telecom-
munication data with encouraging results.
These results represent preliminary work. More experimental work has to
be done to properly evaluate the behavior of the model and to compare this
approach with existing different ones.
The model can be modified in several ways. One of the most interesting
possible changes is the bounded-offset restriction, which means that each element
mi may only be mapped to an element yj of sequence Y such that [i - j] < K,
where K is a constant ( .) This restriction has the role of forbidding very large
timing differences between the sequences, and it seems to be quite reasonable
in several application domains. In the bounded offset model, the complexities of
the algorithms are typically a factor of n lower than in the general model, as the
longest common subsequence computation can be speeded up.
The approximation techniques presented in Section 5 can be sharpened by
noting that the linear transformations preserve the distributional properties of
the sequences very well. For example, if there are m of repeated values in se-
quence X, then in order for Y to be (?,E)-similar there must be in Y approxi-
mately m - 7n values that are within a factor of 6 from each other.
An important future research direction is to consider the database problem:
Given a set of time series and a query sequence, find the ones that are similar to
the query. In order to avoid comparing the query sequence with each sequence
in the database, we have to use some approximation (fingerprint) scheme that
reduces the dimension of the sequences, such as the wavelet transformation,
or the deviation of subsequences. To compute fingerprints of small dimension
Agrawal et al use the Discrete Fourier Transform, Shatkay et al use
feature extraction, and other methods have been suggested; see for some
general discussions on fingerprinting.