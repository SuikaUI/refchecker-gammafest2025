A D.C. OPTIMIZATION ALGORITHM FOR SOLVING
THE TRUST-REGION SUBPROBLEM∗
PHAM DINH TAO† AND LE THI HOAI AN†
SIAM J. OPTIM.
⃝1998 Society for Industrial and Applied Mathematics
Vol. 8, No. 2, pp. 476–505, May 1998
This paper is devoted to diﬀerence of convex functions (d.c.)
optimization: d.c.
duality, local and global optimality conditions in d.c. programming, the d.c. algorithm (DCA), and
its application to solving the trust-region problem. The DCA is an iterative method that is quite
diﬀerent from well-known related algorithms. Thanks to the particular structure of the trust-region
problem, the DCA is very simple (requiring only matrix-vector products) and, in practice, converges
to the global solution. The inexpensive implicitly restarted Lanczos method of Sorensen is used to
check the optimality of solutions provided by the DCA. When a nonglobal solution is found, a simple
numerical procedure is introduced both to ﬁnd a feasible point having a smaller objective value and
to restart the DCA at this point. It is shown that in the nonconvex case, the DCA converges to
the global solution of the trust-region problem, using only matrix-vector products and requiring at
most 2m+2 restarts, where m is the number of distinct negative eigenvalues of the coeﬃcient matrix
that deﬁnes the problem. Numerical simulations establish the robustness and eﬃciency of the DCA
compared to standard related methods, especially for large-scale problems.
Key words. d.c. optimization, d.c. duality, global and local optimality conditions, regularization techniques, DCA, Lanczos method, trust-region subproblem
AMS subject classiﬁcations. 65K05, 65K10, 90C30, 90C35
PII. S1052623494274313
1. Introduction. In this paper we shall be concerned with the following
nonconvex quadratic optimization problems with nonempty solution sets:
2xT Ax + bT x :
2xT Ax + bT x :
where A is an n × n real symmetric matrix, b ∈R, r is a positive number and
∥· ∥denotes the Euclidean norm of Rn. If A is positive semideﬁnite, then (Q1) is
a convex quadratic problem; in general, (Q1) is nonconvex. Problem (Q2), whose
feasible domain is a sphere, is always nonconvex even if A is positive semideﬁnite.
(Q1) and (Q2) are among a few nonconvex optimization problems which possess a
complete characterization of their solutions. These problems play an important role
in optimization and numerical analysis.
For example, for solving the problem of
minimizing a twice continuously diﬀerentiable function on the whole space Rn, D. M.
Gay , J. J. Mor´e and D. C. Sorensen , , , and T. Pham Dinh and his
coworkers , , , , have used trust-region methods. It is known that these
methods are of Newton type and consist of solving subproblems of the form (Q1);
consequently, (Q1) has been often called a trust-region subproblem. Furthermore, in
numerical analysis, several problems, e.g., constrained eigenvalue and quadratically
∗Received by the editors August 20, 1994; accepted for publication (in revised form) November
 
†Mathematical Modelling and Applied Optimization Group, LMI-INSA Rouen - CNRS URA
1378, BP 08, 76131 Mont Saint Aignan, France ( , ).
DCA FOR SOLVING THE TRUST-REGION SUBPROBLEM
constrained least squares problems, can be formulated in the forms of (Q1) and (Q2)
To our knowledge, the ﬁrst eﬃcient (primal-dual) algorithm for solving (Q1) is due
to J. J. Mor´e and D. C. Sorensen . These authors used a safeguarding technique
combined with an adapted Newton method (due to Hebden) for computing a saddlepoint of the Lagrangian function L(x, λ). In the same primal-dual approach T. Pham
Dinh and L. T. Hoai An , proposed a dichotomy process as an alternative
for the safeguarding technique of J. J. Mor´e and D. C. Sorensen. According to many
comparative numerical simulations , , , the dichotomy algorithm seems to be
less expensive than the safeguarding one. Moreover, it can be also applied to solving
G. H. Golub, W. Gander, and U. Von Matt , studied (Q2) from both theoretical and computational viewpoints. These authors mentioned algorithmic diﬃculties
of (Q2) caused by the nonconvexity of the constraint {x : ∥x∥= r}. In the sensitivity of the solutions to the primal problem was discussed. More recently, G. H.
Golub and U. Von Matt proposed a new computational approach to the solution
of (Q2) in the normal case. The method again uses the theoretical tools developed in
 . It seems to be well suited when A is a large sparse matrix.
J. M. Martinez has investigated the nature of local nonglobal solutions of
(Q1) and (Q2) and has shown the following interesting property (especially for local
algorithms): these problems have at most one local nonglobal solution. Moreover,
being inspired by G. E. Forsythe and G. H. Golub’s work , S. Lucidi, L. Palagi,
and M. Roma have stated a very nice result: in (Q1) the objective function can
admit at most 2m+2 diﬀerent values at Kuhn–Tucker points, where m is the number
of distinct negative eigenvalues of A.
The algorithms in , require matrix factorizations which are not feasible
in the large-scale setting. Recently, matrix-free methods , , have been
introduced to solve large-scale trust-region subproblems. These methods recast the
trust-region subproblem in terms of a parametrized eigenvalue problem and require
matrix–vector products only. Sorensen’s algorithm provides a superlinearly convergent scheme to adjust the parameter and ﬁnd the optimal solution from the eigenvector of the parametrized problem, as long as the hard case does not occur. The
so-called hard case is characterized by whenever the vector b is orthogonal to the
eigenspace of A corresponding to its smallest eigenvalue λ1 and there is a solution u to
the system (A −λ1I)u = −b such that ∥u∥< r. This algorithm is linearly convergent
in the hard case. The implicitly restarted Lanczos method (IRLM) introduced by
D. C. Sorensen , which meets the requirements of limited storage and reliance
only on matrix–vector products is the recommended technique used in to ﬁnd the
smallest eigenvalue and the corresponding eigenvector of the parameterized problem.
A primal-dual semideﬁnite framework for the trust-region subproblem is proposed by
F. Rendl and H. Wolkowicz in , where a dual simplex-type method is used in
the general iteration and a primal simplex-type method provides steps for the hard
case iteration. In a block Lanczos routine is used at each iteration instead of
the IRLM. The new matrix-free algorithm of S. A. Santos and D. C. Sorensen 
improves upon that of D. C. Sorensen by introducing a uniﬁed iteration that naturally
includes the hard case. It is shown that this algorithm is superlinearly convergent in
all cases. Numerical simulations given in proved the superiority of S. A. Santos
and D. C. Sorensen’s algorithm upon that of D. C. Sorensen. Moreover, these tests
indicate that the former has advantage over F. Rendl and H. Wolkowicz’s algorithm.
PHAM DINH TAO AND LE THI HOAI AN
In convex approach to nonconvex nondiﬀerentiable optimization the ﬁrst author
has extensively studied subgradient methods for solving convex maximization problems (see and references therein). The d.c. duality investigated by J. F. Toland
 and the works on d.c. optimization by T. Pham Dinh and L. T. Hoai An , ,
 , , can be considered as a natural generalization of the aforementioned
works concerning convex maximization. DCA based on the duality in d.c. optimization had been introduced by T. Pham Dinh and S. Elbernoussi in . Important
developments and improvements for the DCA from both theoretical and numerical
viewpoints have been completed after the works by the authors , , , , ,
 appeared. These algorithms are actually among a few algorithms which allow to
solve large-scale d.c. optimization problems , . Due to their local character they
cannot guarantee the globality of computed solutions for general d.c. programs. In
general the DCAs, converge to a local solution; however, we observe that the DCAs,
converge quite often to a global one , .
The d.c. objective function (of a d.c. program) has inﬁnitely many d.c. decompositions which may have an important inﬂuence on the qualities (robustness, stability,
rate of convergence, and globability of sought solutions) of the DCA. So, it is particularly interesting to obtain various equivalent d.c. forms for the primal and dual
problems. The Lagrangian duality without gap in d.c. optimization , , and
regularization techniques partially answer this concern. In practice, regularization
techniques using the kernel λ/2∥· ∥2 and inf-convolution may provide interesting d.c.
decompositions of objective functions for the DCA , , . Furthermore, it is
worth noting that by using conjointly suitable d.c. decompositions of convex functions
and proximal regularization techniques , , we can obtain the proximal point
algorithm , and the Goldstein–Levitin–Polyak subgradient projection method
 as particular cases of the DCA. It would be interesting to ﬁnd conditions on the
choice of the d.c. decompositions and the initial point xo to ensure the convergence of
the DCA to a global minimizer. In practice, the DCA have been successfully applied
to many large-scale d.c. optimization problems and proved to be more robust and
eﬃcient than related standard methods , , , .
The main part of the paper is dealing with the d.c. optimization framework (d.c.
duality, local and global optimalities for d.c. programming, and the DCA) and its
application to the treatment of problem (Q1) since (Q2) can be simply transformed
into an equivalent problem of the form (Q1).
We ﬁrst brieﬂy present global optimality conditions in (Q1) and (Q2) , , ,
 , , , , , . These results express the same important fact: writing
the constraints in (Q1) and (Q2) in equivalent forms, we obtain , the stability
of the Lagrangian duality relative to them, i.e., there is no duality gap and the solution
sets of (Q1) and (Q2) can be described with the help of their dual solutions exactly
as in convex programming. This approach emphasizes main properties of the dual
objective function and is particularly useful to the development of various primal-dual
algorithms for solving these problems. The algorithms in , , , , are
originated from this primal-dual approach.
In the third section we study the d.c. optimization framework, the description
of the DCA and its convergence.
The key point which makes a uniﬁed and deep
d.c. optimization theory possible relies on the particular structure of the objective
function to be minimized on Rn:
f(x) = g(x) −h(x)
with g and h being convex on Rn. One works then actually with the powerful convex
DCA FOR SOLVING THE TRUST-REGION SUBPROBLEM
analysis tools applied to the two d.c. components g and h of the d.c. function f. With
the help of the functional conjugate notion, the d.c. duality associates a primal d.c.
program with a dual d.c. one and states relationships between them. More precisely,
the d.c. duality is built on the fundamental feature of proper lower semicontinuous
convex functions; such functions θ(x) are the supremum of the aﬃne functions
sup{⟨x, y⟩−θ∗(y) : y ∈Rn}.
Thanks to a symmetry in the d.c. duality (the bidual d.c. program is exactly the
primal one) and the d.c. duality transportation of global minimizers, solving a d.c.
program implies solving the dual one and vice versa. Furthermore, it may be very
useful when one program is easier to be solved than the other (for example, one
can directly solve Problem (Q1) but not its dual d.c. program). The equality of the
optimal value in the primal and dual d.c. programs can be easily translated (with
the help of ε-subdiﬀerentials of the d.c. components) in global optimality conditions.
These conditions have been stated for the ﬁrst time by J. B. Hiriart-Urruty in
a complicated way and mark the passage from convex optimization to nonconvex
optimization. They are nice but diﬃcult to use for devising solution methods to d.c.
Local d.c. optimality conditions constitute the basis of the DCA. In general, it is
not easy to state them as in global d.c. optimality and very few properties have been
found which are useful in practice. Therefore, we shall present in section 3 the most
signiﬁcative results on d.c. programming; most of them are new. In particular, we
give there a new elegant property concerning suﬃcient local d.c. optimality conditions
and their consequences, e.g., the d.c. duality transportation of local minimizers ((ii)
of Theorem 6). The latter is very helpful in establishing relationships between local
minimizers of primal and dual d.c. programs. All these results are indispensable in
the understanding of DCA for locally solving primal and dual d.c. programs. The
proof of the convergence of the DCA will be presented in the appendix.
An application of the DCA to solving the trust-region subproblem (Q1) is given
in the fourth section. The DCA for this problem is quite diﬀerent from the aforementioned algorithms: it is an iterative method based on the local optimality in d.c.
programming. For solving (Q1) we propose a quite appropriate d.c. decomposition. It
turns out that the DCA becomes very simple: it indiﬀerently treats both the standard
(or normal) and hard cases and requires matrix–vector products only. Theoretically,
the DCA generates a sequence of feasible points {xk} which decrease the values of
the original quadratic function and converges to a Kuhn–Tucker point of (Q1). Main
results for d.c. optimization show the convergence of the DCA to a local solution for
certain classes of d.c. programs. These do not concern (Q1) directly; however, the
foundations of the d.c. optimization theory enable us to conjecture that the DCA
converges to a local solution to (Q1) and so, in general, to a global solution to this
problem according to J. M. Martinez’s results . For the trust-region subproblem,
it is interesting to note the following paradox: checking a global solution is easier
than checking a local nonglobal one . We take advantage of this fact to introduce
a simple numerical procedure for checking the global optimality of solutions x∗given
by the DCA or ﬁnding a feasible point ¯x having a smaller objective value in case x∗
is not global. This procedure uses the eﬃcient and inexpensive IRLM to compute
the smallest eigenvalue of A and a corresponding eigenvector. In case of nonglobal
solutions, we restart DCA with the new initial point ¯x. Finally, we can aﬃrm that the
DCA (with at most 2m + 2 restarting procedures), which requires only matrix–vector
products too, converges to a global solution.
PHAM DINH TAO AND LE THI HOAI AN
In the last section we present computational results and comments. A lot of numerical experiments have been done to compare the DCA with some known related
algorithms, among them the new matrix-free algorithm of S. A. Santos and D. C.
Sorensen . They have proved the robustness and the eﬃciency of the DCA, especially in the large-scale setting, and the fact that in practice the DCA (without
restarting procedure) converges to a global solution of the trust-region subproblem.
2. Global optimality conditions for (Q1) and (Q2). We ﬁrst summarize
several well-known global optimality conditions for (Q1) whose proofs can be found
in , , , , , , .
THEOREM 2.1. x∗is a solution to Problem (Q1) if and only if there exists λ∗≥0
(i) (A + λ∗I)x∗= −b,
(ii) λ∗(∥x∗∥−r) = 0, ∥x∗∥≤r,
(iii) (A + λ∗I) is positive semideﬁnite.
Moreover, λ∗is unique.
The conditions (i) and (ii) are Kuhn–Tucker conditions (necessary local optimality
conditions). So, only the last condition is crucial and does express the passage from
“convex” to “nonconvex” in (Q1).
We note that (Q2) is equivalent to a problem of the form (Q1). Namely, it is
equivalent to
2xT (A + γI)x + bT x
where γ is a real number such that A + γI is not positive semideﬁnite. Indeed, (Q2)
is equivalent to
2xT (A + γI)x + bT x
and in case A + γI is not positive semideﬁnite problems (1) and (2), by Theorem 2.1,
have the same sets of solutions. Thus, solving (Q2) is reduced to solving problem (1)
which is of the form (Q1).
In D. C. Sorensen gave a suﬃcient condition for optimality to problem (Q2).
In T. Pham Dinh proved that this condition is not only suﬃcient, but also necessary. This result was also given partially in R. Fletcher using the optimality
conditions of Theorem 2.1. It looks as follows.
THEOREM 2.2. x∗is a solution to (Q2) if and only if there exists λ∗such that
(i) (A + λ∗I) is positive semideﬁnite,
(ii) (A + λ∗I)x∗= −b,
(iii) ∥x∗∥= r.
This number λ∗is unique.
Denote by λ1 ≤· · · ≤λn the eigenvalues of A. Let φ be a function deﬁned on
R\{−λi : i = 1, . . . , n} by
φ(λ) = ∥x(λ)∥,
where x(λ) is the solution of (A + λI)x = −b.
The following nice result which has been stated very recently by J. Martinez 
strengthens the ability for the DCA to reach a solution (global minimizer) of (Q1).
DCA FOR SOLVING THE TRUST-REGION SUBPROBLEM
THEOREM 2.3. (i) If x∗is a local nonglobal minimizer for (Q1) or (Q2), then
(A + λ∗I)x∗= −b with λ∗∈] −λ2, −λ1[ and φ′(λ∗) ≥0. If x∗is a local nonglobal
minimizer for (Q1), then λ∗≥0.
(ii) There exists at most one local nonglobal minimizer for (Q1) or (Q2).
(iii) If ∥x∗∥= r, (A + λ∗I)x∗= −b for some λ∗∈] −λ2, −λ1[ and φ′(λ∗) > 0,
then x∗is a strict local minimizer for (Q2). If, in addition, λ∗> 0, then x∗is also a
strict local minimizer for (Q1).
(iv) If b is orthogonal to some eigenvector associated with λ1, then there is no
local nonglobal minimizer for (Q1) and (Q2).
Finally, a result in S. Lucidi, L. Palagi, and M. Roma guarantees that in the
nonconvex case the restarting procedure can be repeated at most 2m+2 times, where
m is the number of the distinct negative eigenvalues of A.
THEOREM 2.4. In (Q1) the objective function can admit at most 2m + 2 diﬀerent values at Kuhn–Tucker points, where m is the number of the distinct negative
eigenvalues of A.
3. D.c. optimization. Let the space X = Rn be equipped with the canonical
inner product ⟨·, ·⟩. Thus the dual space Y of X can be identiﬁed with X itself. The
Euclidean norm of X is denoted by ∥· ∥= ⟨·, ·⟩1/2. Denote by Γo(X) the set of all
proper lower semicontinuous convex functions on X. The conjugate function g∗of
g ∈Γo(X) is a function belonging to Γo(Y ) and deﬁned by
g∗(y) = sup{⟨x, y⟩−g(x) : x ∈X}.
For a convex set C in X the indicator function of C is denoted by χC(x) = 0 if
x ∈C, +∞otherwise. We shall use the following usual notations of 
dom g = {x ∈X : g(x) < +∞}.
For ϵ > 0 and xo ∈dom g, the symbol ∂ϵg(xo) denotes ϵ-subdiﬀerential of g at xo,
∂ϵg(xo) = {y ∈Y : g(x) ≥g(xo) + ⟨x −xo, y⟩−ϵ
while ∂g(xo) stands for the usual (or exact) subdiﬀerential of g at xo. Also, dom ∂g =
{x ∈X : ∂g(x) ̸= ∅} and range ∂g = ∪{∂g(x) : x ∈dom ∂g}. We adopt in the sequel
the convention +∞−(+∞) = +∞.
A d.c. program is that of the form
α = inf{f(x) := g(x) −h(x) : x ∈X},
where g and h belong to Γo(X). Such a function f is called a d.c. function on X while
g and h are called its d.c. components.
Using the deﬁnition of conjugate functions, we have
α = inf{g(x) −h(x) : x ∈X} = inf{g(x) −sup{⟨x, y⟩−h∗(y) : y ∈Y } : x ∈X}
= inf{β(y) : y ∈Y }
β(y) = inf{g(x) −(⟨x, y⟩−h∗(y)) : x ∈X}.
PHAM DINH TAO AND LE THI HOAI AN
It is clear that β(y) = h∗(y) −g∗(y) if y ∈dom h∗, +∞otherwise. Finally, we state
the dual problem
α = inf{h∗(y) −g∗(y) : y ∈dom h∗}
which is written according to the above convention as
α = inf{h∗(y) −g∗(y) : y ∈Y }.
We observe the perfect symmetry between primal and dual programs (P) and (D):
the dual program to (D) is exactly (P).
Note that the ﬁniteness of α merely implies that
dom g ⊂dom h
dom h∗⊂dom g∗.
Such inclusions will be assumed throughout the paper.
This d.c. duality was ﬁrst studied by J. F. Toland in a more general framework.
It can be considered as a logical generalization of our earlier works concerning convex
maximization ( and references therein).
It is worth noting the richness of the set of d.c.
functions on X, denoted by
DC(X) , , , :
(i) DC(X) is a subspace containing the class of lower-C2 functions (f is said to be
lower-C2 if f is locally a supremum of a family of C2 functions). In particular, DC(X)
contains the space C1,1(X) of functions whose gradient is locally Lipschitzian on X.
(ii) DC(X) is closed under all the operations usually considered in optimization. In
particular, a linear combination of fi ∈DC(X) belongs to DC(X), a ﬁnite supremum
of d.c. functions is d.c. Moreover, the product of two d.c. functions remains d.c. ,
 , , .
(iii) Under some caution we can say that DC(X) is the subspace generated by
the convex cone Γo(X) : DC(X) = Γo(X) −Γo(X). This relation marks the passage
from convex optimization to nonconvex optimization and also indicates that DC(X)
constitutes a minimal realistic extension of Γo(X).
A point x∗is said to be a local minimizer of g −h if g(x∗) −h(x∗) is ﬁnite (i.e.,
x∗∈dom g ∩dom h) and there exists a neighborhood U of x∗such that
g(x∗) −h(x∗) ≤g(x) −h(x)
Under the convention +∞−(+∞) = +∞, the property (4) is equivalent to g(x∗) −
h(x∗) ≤g(x) −h(x),
∀x ∈U ∩dom g.
A point x∗is said to be a critical point of g −h if ∂g(x∗) ∩∂h(x∗) ̸= ∅.
The interior of the set S in X is denoted by int S. Moreover, if S is convex then
ri S stands for the relative interior of S.
A convex function f on X is said to be essentially diﬀerentiable if it satisﬁes the
following three conditions :
(i) C = int (dom f) ̸= ∅,
(ii) f is diﬀerentiable on C,
(iii) limk→∞∥∇f(xk)∥= +∞for every sequence {xk} which converges to a point at
the boundary of C.
Let ρ ≥0 and C be a convex subset of X. One says that the function θ : C −→
R ∪{+∞} is ρ −convex if
θ[λx + (1 −λ)x′] ≤λθ(x) + (1 −λ)θ(x′) −λ(1 −λ)
ρ∥x −x′∥2 ∀λ ∈]0, 1[ ∀x, x′ ∈C.
DCA FOR SOLVING THE TRUST-REGION SUBPROBLEM
It amounts to say that θ−(ρ/2)∥·∥2 is convex on C. The modulus of strong convexity
of θ on C, denoted by ρ(θ, C) or ρ(θ) if C = X, is given by
ρ(θ, C) = sup{ρ ≥0 : θ −(ρ/2)∥· ∥2 is convex on C}.
Clearly, the ρ−convexity implies the convexity. One says that θ is strongly convex
on C if ρ(θ, C) > 0.
For f ∈Γo(X) and λ > 0 the Moreau–Yosida regularization of f with parameter
λ, denoted by fλ, is the inf-convolution of f and 1/2λ∥· ∥2. The function fλ is continuously diﬀerentiable, underapproximates f without changing the set of minimizers
and (fλ)µ = fλ+µ. More precisely, ∇fλ = 1/λ[I −(I + λ∂f)−1] is Lipschitzian with
the ratio 1/λ. The operator (I + λ∂f)−1 is called the proximal mapping associated
to λf .
Let P and D denote the solution sets of problems (P) and (D), respectively, and
Pl = {x∗∈X : ∂h(x∗) ⊂∂g(x∗)},
Dl = {y∗∈Y : ∂g∗(y∗) ⊂∂h∗(y∗)}.
We present below some fundamental results of d.c. optimization which constitute
the basis of the DCA presented in subsection 3.3.
3.1. Duality and global optimality for d.c. optimization.
THEOREM 3.1. Let P and D be the solution sets of problems (P) and (D), respectively. Then
(i) x ∈P if and only if ∂ϵh(x) ⊂∂ϵg(x)
(ii) Dually, y ∈D if and only if ∂ϵg∗(y) ⊂∂ϵh∗(y)
(iii) ∪{∂h(x) : x ∈P} ⊂D ⊂dom h∗.
The ﬁrst inclusion becomes equality if g∗is subdiﬀerentiable in D (in particular,
if D ⊂ri(dom g∗) or if g∗is subdiﬀerentiable in dom h∗). In this case D ⊂(dom ∂g∗∩
(iv) ∪{∂g∗(y) : y ∈D} ⊂P ⊂dom g.
The ﬁrst inclusion becomes equality if h is subdiﬀerentiable in P (in particular,
if P ⊂ri(dom h) or if h is subdiﬀerentiable in dom g). In this case P ⊂(dom ∂g ∩
The relationship between primal and dual solutions: ∪{∂h(x) : x ∈P} ⊂D
and ∪{∂g∗(y) : y ∈D} ⊂P is due to J. F. Toland in the general context of the
duality principle dealing with linear vector spaces in separating duality. A direct proof
of the results (except Properties (i) and (ii)), based on the theory of subdiﬀerential for
convex functions is given in , , . The properties (i) and (ii) have been ﬁrst
established by J. B. Hiriart-Urruty . His proof (based on his earlier work concerning
the behavior of the ϵ-directional derivative of a convex function as a function of the
parameters ϵ) is quite complicated. The following proof of these properties is very
simple and well suited to our d.c. duality framework , , . In fact, they are
nothing but a geometrical translation of the equality of the optimal value in the primal
and dual d.c. programs (P) and (D).
Indeed, in virtue of the d.c. duality, x∗∈P if and only if x∗∈dom g and
g(x∗) −h(x∗) ≤h∗(y) −g∗(y)
∀y ∈dom h∗,
g(x∗) + g∗(y) ≤h(x∗) + h∗(y)
∀y ∈dom h∗.
PHAM DINH TAO AND LE THI HOAI AN
On the other hand, for x∗∈dom h, the property ∂ϵh(x∗) ⊂∂ϵg(x∗)
∀ϵ > 0 is, by
deﬁnition, equivalent to
∀ϵ > 0, ⟨x∗, y⟩+ ϵ ≥h(x∗) + h∗(y) ⇒⟨x∗, y⟩+ ϵ ≥g(x∗) + g∗(y).
It is easy to see the equivalence between (7) and (8), and property (i) is thus proved.
The global optimality condition in (i) is diﬃcult to use for deriving solution methods
to problem (P). The DCA which will be described in subsection 3.3 is based on local
optimality conditions. The relations (ii) and (iv) indicate that solving the primal d.c.
program (P) implies solving the dual d.c. program (D) and vice versa. It may be
useful if one of them is easier to solve than the other.
3.2. Duality and local optimality conditions for d.c. optimization.
THEOREM 3.2. (i) If x∗is a local minimizer of g −h, then x∗∈Pl.
(ii) Let x∗be a critical point of g −h and y∗∈∂g(x∗) ∩∂h(x∗). Let U be a
neighborhood of x∗such that U ∩dom g ⊂dom ∂h. If for any x ∈U ∩dom g there is
y ∈∂h(x) such that h∗(y) −g∗(y) ≥h∗(y∗) −g∗(y∗), then x∗is a local minimizer of
g −h. More precisely,
g(x) −h(x) ≥g(x∗) −h(x∗)
∀x ∈U ∩dom g.
Property (i) is well known , , , . For completeness we give below a short
proof for it.
Property (ii) is new; it establishes an interesting suﬃcient condition
(dealing with the d.c. duality) for local d.c. optimality.
Proof. (i) If x∗is a local minimizer of g −h, then there exists a neighborhood of
x∗such that
g(x) −g(x∗) ≥h(x) −h(x∗)
∀x ∈U ∩dom g.
Hence for y∗∈∂h(x∗) we have g(x) −g(x∗) ≥⟨x −x∗, y∗⟩
∀x ∈U ∩dom g. The
convexity of g then implies that y∗∈∂g(x∗).
(ii) The condition y∗∈∂g(x∗) ∩∂h(x∗) implies g(x∗) + g∗(y∗) = ⟨x∗, y∗⟩=
h(x∗) + h∗(y∗). Hence
g(x∗) −h(x∗) = h∗(y∗) −g∗(y∗).
For any x ∈U ∩dom g, by assumption, there is y ∈∂h(x) such that
h∗(y) −g∗(y) ≥h∗(y∗) −g∗(y∗).
On the other hand, we have h(x) + h∗(y) = ⟨x, y⟩≤g(x) + g∗(y). Hence,
g(x) −h(x) ≥h∗(y) −g∗(y).
Combining (9), (10), (11), we get g(x) −h(x) ≥g(x∗) −h(x∗) ∀x ∈U ∩dom g.
A function θ ∈Γo(X) is said to be polyhedral convex if 
θ(x) = max{⟨ai, x⟩−αi : i = 1, . . . , m} + χC(x)
where C is a nonempty polyhedral convex set in X.
Polyhedral d.c. optimization occurs when either g or h is polyhedral convex. This
class of d.c. optimization problems, which is frequently encountered in practice, enjoys
interesting properties (from both theoretical and practical viewpoints) concerning
DCA FOR SOLVING THE TRUST-REGION SUBPROBLEM
local optimality and the convergence of the DCA, and has been extensively developed
in , .
COROLLARY 3.3 (suﬃcient local optimality).
Let x∗be a point that admits a
neighborhood U such that ∂h(x) ∩∂g(x∗) ̸= ∅
∀x ∈U ∩dom g. Then x∗is a local
minimizer of g −h. More precisely, g(x) −h(x) ≥g(x∗) −h(x∗)
∀x ∈U ∩dom g.
Proof. Let x ∈U ∩dom g and let y ∈∂h(x) ∩∂g(x∗). Since y ∈∂h(x) we have
h(x) + h∗(y) = ⟨x, y⟩≤g(x) + g∗(y). So g(x) −h(x) ≥h∗(y) −g∗(y). Similarly,
y ∈∂g(x∗) implies that g(x∗)+g∗(y) = ⟨x∗, y⟩≤h(x∗)+h∗(y). Hence h∗(y)−g∗(y) ≥
g(x∗)−h(x∗). If y∗∈∂h(x∗)∩∂g(x∗), then g(x∗)+g∗(y∗) = ⟨x∗, y∗⟩= h(x∗)+h∗(y∗).
Hence g(x∗) −h(x∗) = h∗(y∗) −g∗(y∗). The assumptions of Theorem 3.2 (ii) are
fulﬁlled. Thus, the proof is complete.
Corollary 3.3 can be used to prove the following well-known result due to C.
Michelot (in the case where g, h belonging to Γo(X) are ﬁnite on the whole X) and
generalized by the authors , to the case of arbitrary g and h belonging to Γo(X):
the converse of property (i) of Theorem 3.2 in case h is polyhedral convex.
COROLLARY 3.4 (suﬃcient strict local optimality). If x∗∈int (dom h) veriﬁes
∂h(x∗) ⊂int (∂g(x∗)), then x∗is a strict local minimizer of g −h.
Proof. From the upper semicontinuity of the operator ∂h at x∗∈int (dom h) 
it follows that for any open set O containing ∂h(x∗) there is a neighborhood U of x∗
such that ∂h(x) ⊂O ∀x ∈U.
Hence by letting O = int (∂g(x∗)) and taking Corollary 3.3 into account, we
have x∗is a local minimizer of g −h. But x∗is actually a strict local minimizer
of g −h. Indeed, since ∂h(x) is compact for x ∈V = U ∩int (dom h), we have
∃ϵ(x) > 0 such that ∂h(x) + ϵ(x)B ⊂O (B being the closed unit ball of the
Euclidean norm).
Now let x ∈V \{x∗} and y ∈∂h(x). Then
g(x) −g(x∗) ≥
x −x∗, y +
∥x −x∗∥(x −x∗)
= ϵ(x)∥x −x∗∥+ ⟨x −x∗, y⟩
≥ϵ(x)∥x −x∗∥+ h(x) −h(x∗).
The proof is complete.
It may happen that it is easier to solve locally the dual d.c. program (D) than
the primal d.c. program (P). So it is useful to state results relative to the d.c. duality
transportation of local minimizers. Paradoxically, such a result is more complicated
than the d.c. duality transportation of global minimizers in Theorem 3.1.
COROLLARY 3.5 (d.c. duality transportation of a local minimizer).
dom ∂h be a local minimizer of g−h, and let y∗∈∂h(x∗) (i.e., ∂h(x∗) is nonempty and
x∗admit a neighborhood U such that g(x) −h(x) ≥g(x∗) −h(x∗)
∀x ∈U ∩dom g).
y∗∈int (dom g∗) and
∂g∗(y∗) ⊂U
((12) holds if g∗is diﬀerentiable at y∗), then y∗is a local minimizer of h∗−g∗.
According to (i) of Theorem 3.2 we have y∗∈∂h(x∗) ⊂∂g(x∗).
x∗∈∂g∗(y∗) ∩∂h∗(y∗). Under the assumption (12) and the upper semicontinuity
of ∂g∗, y∗admits a neighborhood V ⊂int (dom g∗) such that ( ) ∂g∗(V ) ⊂U.
More precisely, ∂g∗(V ) ⊂(U ∩dom g) since we have range ∂g∗= dom ∂g and
dom ∂g ⊂dom g. Using the dual property (in the d.c. duality) in (ii) of Theorem 3.2
PHAM DINH TAO AND LE THI HOAI AN
we deduce that y∗is a local minimizer of h∗−g∗. If g∗is diﬀerentiable at y∗, then
x∗= ∂g∗(y∗) and we have (12) .
By the symmetry of the d.c. duality, Corollary 3.5 has its corresponding dual
This result improves an earlier result of J. F. Toland where he
assumed that g∗is diﬀerentiable on the whole dual space Y . In , we have
proved that this result remains true if g∗is only essentially diﬀerentiable.
3.3. Description of the DCA for general d.c. programs. For each ﬁxed
x∗∈X we consider the problem
inf{h∗(y) −g∗(y) : y ∈∂h(x∗)},
which is equivalent to the convex maximization one
inf{⟨x∗, y⟩−g∗(y) : y ∈∂h(x∗)}.
Similarly, for each ﬁxed y∗∈Y , for duality, we deﬁne the problem
inf{g(x) −h(x) : x ∈∂g∗(y∗)}.
This problem is equivalent to
inf{⟨x, y∗⟩−h(x) : x ∈∂g∗(y∗)}.
Let S(x∗), T (y∗) denote the solution sets of Problems (S(x∗)) and (T(y∗)), respectively.
The complete form of the DCA is based upon duality of d.c. optimization deﬁned
by (P) and (D). It allows approximating a point (x∗, y∗) ∈Pl × Dl. Given a point
xo ∈dom g, the algorithm constructs two sequences {xk} and {yk} deﬁned by
yk ∈S(xk);
xk+1 ∈T (yk).
The complete DCA can be viewed as a sort of a decomposition approach of the
primal and dual problems (P), (D). From a practical point of view, although problems
(S(xk)) and (T(xk)) are simpler than (P), (D) (we work in ∂h(xk) and ∂g∗(yk) with
convex maximization problems), they remain nonconvex programs and thus are still
diﬃcult (see subsection 3.5). In practice the following simpliﬁed form of the DCA is
• Simpliﬁed form of the DCA: The idea of the simpliﬁed DCA is quite natural:
it constructs two sequences {xk} and {yk} (candidates to primal and dual solutions)
which are easy to calculate and satisfy the following conditions:
(i) The sequences (g −h)(xk) and (h∗−g∗)(yk) are decreasing.
(ii) Every limit point x∗(resp. y∗) of the sequence {xk} (resp. {yk}) is a critical
point of g −h (resp. h∗−g∗).
These conditions suggest constructing two sequences {xk} and {yk}, starting from a
given point xo ∈dom g, by setting
yk ∈∂h(xk);
xk+1 ∈∂g∗(yk).
Interpretation of the simpliﬁed DCA: At each iteration k we do the following:
xk ∈∂g∗(yk−1) →yk ∈∂h(xk)
= argmin{h∗(y) −[g∗(yk−1) + ⟨xk, y −yk−1⟩] : y ∈Y },
DCA FOR SOLVING THE TRUST-REGION SUBPROBLEM
yk ∈∂h(xk) →xk+1 ∈∂g∗(yk) = argmin{g(x)−[h(xk)+⟨x−xk, yk⟩] : x ∈X}.
Problem (Pk) is a convex program obtained from (P) by replacing h with its aﬃne
minorization deﬁned by yk ∈∂h(xk). Similarly, the convex problem (Dk) is obtained
from (D) by using the aﬃne minorization of g∗deﬁned by xk ∈∂g∗(yk−1). Here
we can see a complete symmetry between problems (Pk) and (Dk), and between the
sequences {xk} and {yk} relative to the duality of d.c. optimization. The two forms
of the DCA are identical if g∗and h are essentially diﬀerentiable.
• Well deﬁniteness of the DCA: The DCA is well deﬁned if one can construct
two sequences {xk} and {yk} as above from an arbitrary initial point xo ∈dom g.
We have xk+1 ∈∂g∗(yk) and yk ∈∂h(xk) ∀k ≥0. So {xk} ⊂range ∂g∗= dom ∂g
and {yk} ⊂range ∂h = dom ∂h∗. Then the following lemma is clear.
LEMMA 3.6. Sequences {xk}, {yk} in the DCA are well deﬁned if and only if
dom ∂g ⊂dom ∂h and dom ∂h∗⊂dom ∂g∗.
Since for ϕ ∈Γo(X) we have ri (dom ϕ) ⊂dom ∂ϕ ⊂dom ϕ ( ) (ri (dom ϕ) stands
for the relative interior of dom ϕ) we can say, under the essential assumption (3), that
the DCA is, in general, well deﬁned.
Remark. A d.c. function f has inﬁnitely many d.c. decompositions. For example,
if f = g −h, then f = (g +θ)−(h+θ) for every θ ∈Γo(X) ﬁnite on the whole X. It is
clear that the primal d.c. programs (P) corresponding to the two d.c. decompositions
of the objective function f are identical. But their dual programs are quite diﬀerent
and so is the DCA relative to these d.c. decompositions. In other words, there are as
many DCAs as there are d.c. decompositions of the objective function f. It is useful
to ﬁnd a suitable d.c. decomposition of f since it may have an important inﬂuence on
the eﬃciency of the DCA for its solution. This question is intimately related to the
regularization techniques in d.c. programming , , .
3.4. Convergence of the DCA for general d.c. programs. Let ρi and
i , (i = 1, 2) be real nonnegative numbers such that 0 ≤ρi < ρ(fi) (resp. 0 ≤ρ∗
i )) where ρi = 0 (resp. ρ∗
i = 0) if ρ(fi) = 0 (resp. ρ(f ∗
i ) = 0) and ρi (resp. ρ∗
may take the value ρ(fi) (resp. ρ(f ∗
i )) if it is attained. We next set f1 = g and f2 = h.
Also let dxk := xk+1 −xk and dyk := yk+1 −yk.
The basic convergence theorem of the DCA for general d.c. programming will be
stated below. Its proof is very technical and long. We will present it in the appendix
and refer the reader to our previous works , for more details.
THEOREM 3.7.
Suppose that the sequences {xk} and {yk} are deﬁned by the
simpliﬁed DCA. Then we have
(g −h)(xk+1) ≤(h∗−g∗)(yk) −max
2 ∥dxk∥2, ρ∗
≤(g −h)(xk)
∥dxk∥2, ρ∗
2 ∥dyk−1∥2 + ρ2
2 ∥dxk∥2, ρ∗
2 ∥dyk−1∥2 + ρ∗
The equality (g −h)(xk+1) = (g −h)(xk) holds if and only if xk ∈∂g∗(yk), yk ∈
∂h(xk+1)and (ρ1 + ρ2)dxk = ρ∗
1dyk−1 = ρ∗
2dyk = 0. In this case
• (g −h)(xk+1) = (h∗−g∗)(yk) and xk, xk+1 are the critical points of g −h
satisfying yk ∈(∂g(xk) ∩∂h(xk)) and yk ∈(∂g(xk+1) ∩∂h(xk+1)),
PHAM DINH TAO AND LE THI HOAI AN
• yk is a critical point of h∗−g∗satisfying [xk, xk+1] ⊂((∂g∗(yk) ∩∂h∗(yk)),
• xk+1 = xk if ρ(g)+ρ(h) > 0, yk = yk−1 if ρ(g∗) > 0 and yk = yk+1 if ρ(h∗) > 0.
(ii) Similarly, for the dual problem we have
(h∗−g∗)(yk+1) ≤(g −h)(xk+1) −max
2 ∥dxk+1∥2, ρ∗
≤(h∗−g∗)(yk)
2 ∥dxk+1∥2 + ρ2
2 ∥dxk∥2, ρ∗
2 ∥dyk∥2 + ρ2
2 ∥dxk∥2, ρ∗
The equality (h∗−g∗)(yk+1) = (h∗−g∗)(yk) holds if and only if xk+1 ∈∂g∗(yk+1), yk ∈
∂h(xk+1) and (ρ∗
2)dyk = ρ2dxk = ρ1dxk+1 = 0. In this case
• (h∗−g∗)(yk+1) = (g −h)(xk+1) and yk, yk+1 are the critical points of h∗−g∗
satisfying xk+1 ∈(∂g∗(yk) ∩∂h∗(yk)) and xk+1 ∈(∂g∗(yk+1) ∩∂h∗(yk+1)),
• xk+1 is a critical point of g −h satisfying [yk, yk+1] ⊂((∂g(xk+1) ∩∂h(xk+1)),
• yk+1 = yk if ρ(g∗) + ρ(h∗) > 0, xk+1 = xk if ρ(h) > 0 and xk+1 = xk+2 if
(iii) If α is ﬁnite, then the decreasing sequences {(g −h)(xk)} and {(h∗−g∗)(yk)}
converge to the same limit β ≥α, i.e., limk→+∞(g−h)(xk) = limk→+∞(h∗−g∗)(yk) =
β. If ρ(g) + ρ(h) > 0 (resp. ρ(g∗) + ρ(h∗) > 0), then limk→+∞{xk+1 −xk} = 0 (resp.
limk→+∞{yk+1 −yk} = 0). Moreover, limk→+∞{g(xk) + g∗(yk) −⟨xk, yk⟩} = 0 =
limk→+∞{h(xk+1) + h∗(yk) −⟨xk+1, yk⟩}.
(iv) If α is ﬁnite and the sequences {xk} and {yk} are bounded, then for every
limit x∗of {xk} (resp. y∗of {yk}) there exists a cluster point y∗of {yk} (resp. x∗
of {xk}) such that
• (x∗, y∗) ∈[∂g∗(y∗) ∩∂h∗(y∗)] × [∂g(x∗) ∩∂h(x∗)] and (g −h)(x∗) = (h∗−
g∗)(y∗) = β,
• limk→+∞{g(xk) + g∗(yk)} = limk→+∞⟨xk, yk⟩.
Comments on Theorem 3.7. (i) Properties (i) and (ii) prove that the DCA
is a descent method for both primal and dual programs. The DCA provides critical
points for (P) and (D) after ﬁnitely many operations if there is no strict decrease of
the primal (or dual) objective function.
(ii) If C and D are convex sets such that {xk} ⊂C and {yk} ⊂D, then Theorem
3.7 remains valid if we replace ρ(fi) by ρ(fi, C) and ρ(f ∗
i ) by ρ(f ∗
i , D) for i = 1, 2.
By this way we may improve the results in the theorem.
(iii) In (ii) of Theorem 3.7, the convergence of the whole sequence {xk} (resp.
{yk}) can be ensured under the following conditions , :
• {xk} is bounded;
• The set of limit points of {xk} is ﬁnite;
• limk→+∞∥xk+1 −xk∥= 0.
(iv) The only diﬀerence between the simpliﬁed DCA and the complete DCA lies
on the choice of yk in ∂h(xk) and xk+1 in ∂g∗(yk). The convergence result of the
complete DCA is thus improved: in Theorem 3.7, the nonemptiness of a subdiﬀerential
intersection is replaced by a subdiﬀerential inclusion , , . In other words, the
complete DCA permits to obtain a couple of elements (x∗, y∗) ∈Pl × Dl. In practice
the simpliﬁed DCA usually yields a local minimizer which is also global .
(v) In general, the qualities (robustness, stability, rate of convergence, and globality of sought solutions) of the DCA, in both complete and simpliﬁed forms, depend
upon the d.c. decomposition of the function f. Theorem 3.7 shows how strong convexity of d.c. components in primal and dual problems can inﬂuence the DCA. To
DCA FOR SOLVING THE TRUST-REGION SUBPROBLEM
make the d.c. components (of the primal objective function f = g−h) strongly convex
we usually apply the following process
f = g −h =
In this case the d.c. components in the dual problem will be continuously diﬀerentiable.
Similarly inf-convolution of g and h with λ/2∥· ∥2 will make the d.c. components (in
dual problems) strongly convex and the d.c.
components of the primal objective
function continuously diﬀerentiable. For a detailed study of regularization techniques
in the d.c. optimization, see , , .
3.5. How to restart the simpliﬁed DCA for obtaining x∗such that
∂h(x∗) ⊂∂g(x∗). As mentioned above, the complete DCA theoretically provides
a x∗such that ∂h(x∗) ⊂∂g(x∗). In practice, except for the cases where the convex
maximization problems (S(xk) and (T(yk)) are easy to solve, one generally uses the
simpliﬁed DCA. It is worth noting that if the simpliﬁed DCA terminates at some point
x∗for which ∂h(x∗) is not contained in ∂g(x∗), then one can reduce the objective
function value by restarting it from a new initial point xo = x∗with yo ∈∂h(xo) such
that yo /∈∂g(xo). In fact, since
g(x1) + g∗(yo) = ⟨x1, yo⟩≤h(x1) −h(xo) + ⟨xo, yo⟩
and ⟨xo, yo⟩< g(xo) + g∗(yo) because yo /∈∂g(xo), we have
g(x1) + g∗(yo) < h(x1) −h(xo) + g(xo) + g∗(yo).
g(x1) −h(x1) < g(xo) −h(xo).
We have given the main concept of the d.c. programming and the DCA. In the
next section we shall apply this technique to the trust-region subproblem.
4. Solving trust-region subproblem (Q1) by the DCA.
4.1. DCA for solving Problem (Q1). We describe below the DCA for solving
(Q1). For this we must point out d.c. decompositions of the objective function in (Q1).
2xT Ax + bT x + χE(x) : x ∈Rn
where E = {x ∈Rn : ∥x∥≤r} and χE stands for its indicator function. The following
d.c. decomposition seems to be the most natural
2xT Ax + bT x + χE(x) = g1(x) −h1(x)
2xT (A + ρI)x + xT b + χE(x), h1(x) = 1
and ρ is a positive real number such that A + ρI is positive semideﬁnite.
PHAM DINH TAO AND LE THI HOAI AN
For this case in the simpliﬁed DCA yk = ρxk and xk+1 is a solution of the problem
2xT (A + ρI)x + xT (b −yk) : ∥x∥≤r
Thus, at each iteration, the algorithm requires solving a convex quadratic program
and so is expensive, especially in large-scale problems. In practice the algorithm with
this d.c. decomposition is unstable ( ). Note that if A is positive semideﬁnite then
DCA with this decomposition reduces to the well-known proximal point algorithm
 , .
From the computational viewpoint the following decomposition, in our opinion,
is the most eﬃcient: f(x) = g(x) −h(x) with
2ρ∥x∥2 + bT x + χE(x),
2xT (ρI −A)x,
and ρ is a positive number such that ρI −A is positive semideﬁnite.
Clearly, g, h ∈Γo(Rn) and thus (Q1) takes the form
min{g(x) −h(x) :
The simpliﬁed DCA applied to this case can be formulated as follows. Let xo ∈Rn
and k ≥0. Further, let yk = (ρI −A)xk and xk+1 be a solution of the problem
2∥x∥2 + xT (b −yk) + χE(x) : x ∈Rno
Thus, xk+1 is, in fact, the projection of (yk −b)/ρ onto E, i.e.,
ρ(Axk + b)
Summing up, we state the chosen DCA as follows:
Let xo ∈Rn and k ≥0
a) If ∥(ρI −A)xk −b∥≤ρr take xk+1 = (ρI−A)xk−b
b) Otherwise, take xk+1 = r (ρI−A)xk−b
∥(ρI−A)xk−b∥.
If ∥xk+1 −xk∥≤ϵ, terminate. Otherwise, increase k by 1 and return to a).
Remark. (i) In case b = 0, except if A is positive semideﬁnite (for which zero
is a solution), we choose xo such that yo = (ρI −A)xo ̸= 0, since yo = 0 implies
xk = 0 ∀k ≥1.
DCA FOR SOLVING THE TRUST-REGION SUBPROBLEM
(ii) We have presented the two d.c. decompositions (14), (16) (of the objective
function f) which give rise to quite diﬀerent DCA. These algorithms treat indiﬀerently the normal and hard cases of (Q1). However, the DCA corresponding to the
decomposition (16) requires only matrix–vector products since the solution (19) is
explicit. This DCA seems to be more stable and more eﬃcient than the former. The
following convergence results are a consequence of Theorem 3.7.
THEOREM 4.1. (i) f(xk+1) ≤f(xk) −1/2(ρ + λ)∥xk+1 −xk∥2, where λ is the
smallest eigenvalue of (ρI −A).
(ii) f(xk) ↘α′ ≥α and limk→∞∥xk+1 −xk∥= 0.
(iii) Every limit point x∗of the sequence {xk} is a Kuhn–Tucker point; i.e., there
exists λ∗≥0 such that (A + λ∗I)x∗= −b, λ∗(∥x∗∥−r) = 0 and ∥x∗∥≤r.
Proof. For the d.c. decomposition (16) of f, we have ρ(g, E) = ρ, ρ(h) = ρ −λn.
Since the sequence {xk} is contained in E and the supremum ρ(g, E) in (5) is attained,
according to (i) of Theorem 3.7 and (i) of comments on Theorem 3.7, we get
f(xk+1) ≤f(xk) −1
2(2ρ −λn)∥xk+1 −xk∥2.
Property (ii) then follows from (iii) of the above theorem.
Now let x∗be a limit point of {xk}.
Since the sequences {xk} and {yk} are
bounded, Property (iv) of Theorem 3.7 then implies
∂h(x∗) = ∇h(x∗) ⊂∂g(x∗).
We have ∇h(x∗) = (ρI −A)x∗, ∂g(x∗) = ρx∗+ b + ∂χE(x∗) with ∂χE(x∗) = {0} if
∥x∗∥< r, {λx∗: λ ≥0}, otherwise. So the relation (20) is equivalent to
(A + λ∗I)x∗= −b, λ∗(∥x∗∥−r) = 0, and ∥x∗∥≤r
for some nonnegative real λ∗. The proof is complete.
4.2. Using the DCA for globally solving (Q1). Let x∗be a point produced
by the DCA (Theorem 4.1). It is clear that if A is positive semideﬁnite, then (P)
in (17) is a “false” d.c. optimization problem (i.e., it is a convex one in reality) and
the condition (iii) is actually a characterization of (Q1). In other words, the DCA
converges to a solution of (Q1) in this case. In general, using Theorem 2.1 we can
calculate λ∗and check the global optimality. Indeed, from Theorem 2.1 it follows that
λ∗= −⟨x∗, Ax∗⟩−⟨x∗, b⟩
So, checking the global optimality of x∗can be done, for example, by applying the
inexpensive algorithm IRLM to compute the smallest eigenvalue λ1 of A and a corresponding eigenvector u:
If λ∗+ λ1 ≥0, then x∗is a global solution to (Q1). Otherwise,
uT (A + λ∗I)u = (λ∗+ λ1)uT u < 0.
In this case we will indicate below how to restart the DCA, say, how to ﬁnd ¯x such
that ∥¯x∥≤r and f(¯x) < f(x∗). First let us mention the following property.
PHAM DINH TAO AND LE THI HOAI AN
LEMMA 4.2. If f(x) = 1/2⟨x, Ax⟩+ ⟨b, x⟩, with A being symmetric, and (A +
µI)y = −b, then
f(x) = f(y) −µ
2 (∥x∥2 −∥y∥2) + 1
2⟨x −y, (A + µI)(x −y)⟩∀x.
Proof. We have
f(x) = f(y) + ⟨x −y, Ay + b⟩+ 1
2⟨x −y, A(x −y)⟩
= f(y) −µ⟨x −y, y⟩+ 1
2⟨x −y, (A + µI)(x −y)⟩−µ
2 ⟨x −y, x −y⟩.
Since µ/2⟨x −y, x −y⟩= µ/2(∥x∥2 + ∥y∥2) −µ⟨x, y⟩, we get
2 ⟨x −y, x −y⟩−µ⟨x −y, y⟩= −µ
2 (∥x∥2 + ∥y∥2) + µ∥y∥2 = −µ
2 (∥x∥2 −∥y∥2).
The proof is complete.
How to compute the initial point for restarting the DCA. a) If ⟨b, x∗⟩> 0,
then taking ¯x = −x∗we have f(¯x) < f(x∗). Indeed, in virtue of Lemma 4.2,
f(x) = f(x∗) −λ∗
2 (∥x∥2 −∥x∗∥2) + 1
2⟨x −x∗, (A + λ∗I)(x −x∗)⟩.
This implies
f(¯x) = f(x∗) + 2⟨(A + λ∗I)x∗, x∗⟩= f(x∗) −2⟨b, x∗⟩< f(x∗).
So we can restart the DCA from the initial point ¯x.
b) If ⟨b, x∗⟩≤0, then we distinguish two cases:
(b.1). If either ∥x∗∥< r or ∥x∗∥= r and uT x∗̸= 0, then we take ¯x = x∗+ γu,
where γ ̸= 0 is chosen such that ∥¯x∥= r. More precisely, γ is a nontrivial solution of
the following equation:
∥u∥2γ2 + 2uT x∗γ + ∥x∗∥2 −r2 = 0,
which is given explicitly by
−2(uT x∗)/∥u∥2
if ∥x∗∥= r,
−(uT x∗) ±
if ∥x∗∥< r,
where ∆= (uT x∗)2 −∥u∥2(∥x∗∥2 −r2).
So we can choose ¯x as the initial point for restarting the DCA, since
f(¯x) = f(x∗) + γ2
2 ⟨u, (A + λ∗I)u⟩< f(x∗).
Note that in (23) the greater γ2 is, the smaller f(¯x) becomes. Then the better value
of γ is given by γ = (−(uT x∗) +
∆)/∥u∥2 if uT x∗< 0, (−(uT x∗) −
otherwise.
(b.2). If ∥x∗∥= r, and uT x∗= 0, then we ﬁnd a new vector v = u + τx∗with
τ < 0 such that vT (A + λ∗I)v < 0 and vT x∗̸= 0. Return to (b.1) with v instead of u.
DCA FOR SOLVING THE TRUST-REGION SUBPROBLEM
To prove the existence of such a vector we will proceed as follows: we have
vT x∗= uT x∗+ τ∥x∗∥2 = τ∥x∗∥2. So vT x∗< 0 if τ < 0. Since
⟨v, (A + λ∗I)v⟩= τ 2⟨x∗, (A + λ∗I)x∗⟩+ 2τ⟨u, (A + λ∗I)x∗⟩+ ⟨u, (A + λ∗I)u⟩
= −τ 2⟨b, x∗⟩−2τ⟨b, u⟩+ ⟨u, (A + λ∗I)u⟩
we easily deduce the following properties:
• If bT x∗= 0 and bT u ≤0, then vT (A + λ∗I)v < 0 for all τ < 0. If bT x∗= 0 and
bT u > 0, then vT (A + λ∗I)v < 0 for 0 > τ > uT (A + λ∗I)u/bT u.
• If bT x∗< 0, then vT (A + λ∗I)v < 0 for τ1 < τ < 0, where τ1 is the smallest
root of the second degree polynomial of τ, −bT x∗τ 2 −2bT uτ + uT (A + λ∗I)u, i.e.,
τ1 = [bT u + ((bT u)2 + bT x∗uT (A + λ∗I)u]1/2)]/bT x∗.
Summing up, we conclude that if a Kuhn–Tucker point x∗produced by the DCA
is not a global solution to (Q1) then another point ¯x (such that ∥¯x∥≤r and f(¯x) <
f(x∗)) is already available for restarting the DCA.
Remark. In case (b.2) the optimal choice for τ is a bit complicated because it
deals with roots of a third degree polynomial of τ. Finally, we state here our global
algorithm for solving (Q1) in the nonconvex case.
Algorithm GDCA: (globally solving (Q1)).
Initialization. Compute λ1 and u by the IRLM.
Compute an approximation ˜λn to λn by the IRLM.
Let ρ := ˜λn + 0.1, ¯x ∈C, stop := false.
stop = false do
1. Apply the DCA from starting point xo := ¯x to obtain x∗.
2. Let λ∗= (−⟨x∗, Ax∗⟩−⟨x∗, b⟩)/r2.
If λ∗≥−λ1 then stop := true, x∗is a global solution of (Q1)
else compute ¯x such that f(¯x) < f(x∗) and return to 1.
4.3. Relation between the DCA and the Goldstein–Levitin–Polyak gradient projection algorithm for solving (Q1) in the convex case. In case the
matrix A in (Q1) is positive semideﬁnite, the Goldstein–Levitin–Polyak gradient projection algorithm applied to (Q1) looks as follows:
xk+1 = PE(xk −ρ−1(Axk + b)) = F(xk).
The following well-known convergence result can be proved by using classical arguments of ﬁxed point theory (B. Polyak ).
PROPOSITION 4.3. Let A be positive semideﬁnite and ρ > 0. Then
(i) ∥F(x) −F(x′)∥≤max{| 1 −ρ−1λn |, | 1 −ρ−1λ1 |}∥x −x′∥.
(ii) If ρ > λn/2, then every limit point of {xk} is a solution of (Q1). Moreover, if
the solution set of (Q1) is ﬁnite, then the whole sequence {xk} converges to a solution
(iii) If A is positive deﬁnite and 0 < ρ−1 < 2λ−1
n , then F is a contraction with
constant q(ρ) < 1. Moreover, ¯ρ = (λn +λ1)/2 is the best choice which minimizes q(ρ)
over ]λn/2, +∞[:
q(¯ρ) = λn −λ1
Remark. (i) The Goldstein–Levitin–Polyak gradient projection can be considered
as a special case of the DCA applied to (Q1).
PHAM DINH TAO AND LE THI HOAI AN
(ii) In the DCA ρ must be greater or equal to λn, while Proposition 4.3 requires
only that ρ > λn/2.
(iii) The assertion (ii) of Proposition 4.3 is a direct consequence of Theorem 4.1.
(iv) Actually, the whole sequence {xk} converges to a solution of (Q1) if this
problem admits a solution. The proof of this result is based on the theory of maximal
monotone operators.
4.4. Optimal choice of the regularization parameter ρ. In practice, the
convergence rate of the DCA depends on the value ρ. Except for the case where the
matrix A is positive deﬁnite for which the “theoretically optimal” value (λ1 + λn)/2
(that is not “practically optimal,” however, as shown in Table 5) of ρ has been pointed
out in Proposition 4.3, the general optimal choice of ρ is not easy. Numerical experiments proved that, in general, the closer to λn the positive parameter ρ is, the better
the DCA converges. Such good parameters ρ belong to {λ > 0 : λ ∈]ρ∗, ρ∗+ε]}, where
ε > 0 is suﬃciently small and ρ∗= λn if λn > 0, 0 otherwise. In practice, such a ρ can
be computed by using the quite inexpensive IRLM due to D.C. Sorensen . We
need only a low accuracy for an approximation ˜λn given by the IRLM of the largest
eigenvalue λn of A. In other words, we are satisﬁed with an approximation ˜λn such
that ˜λn ≤λn ≤˜λn + ∆˜λn, where the variation ∆˜λn is given by: if |˜λn| = α10k with
α ∈[0, 10[ and k integer, then ∆˜λn = 2.10k−1 when α ≥5, 10k−1 when 0 < α < 5, 0
when α = 0.
Such an approximation ˜λn can be provided by the IRLM with the tolerance equal
to 0.1 at little cost. A good practical choice of ρ is then max{˜λn + ∆˜λn, 10−3}.
5. Numerical experiments. In this section, we present some computational
tests on the performance of the DCA for diﬀerent sets of test problems. Our experiments are composed of ﬁve sets of tests. In the ﬁrst set we compare the DCA
with safeguarding and dichotomy , algorithms. The algorithms have been
coded in PASCAL under Unix system and run on Sun SPARC-2 station with double
precision. In the second set, we provide a comparison between the DCA and the
approach proposed by S. A. Santos and D. C. Sorensen . The third set reports the
performance of the DCA and the gradient projection algorithm in the convex case.
Finally, in the fourth and ﬁfth sets we study the sensitivity of the DCA, respectively,
for diﬀerent choices of ρ and several sizes of the radius. For the last four sets the algorithms have been coded in FORTRAN 77 and run on Sun SPARC-10 station with
double precision.
The stopping criterion of the DCA was actually er ≤ϵ, where
 ∥xk+1 −xk∥2/∥xk∥2
if ∥xk∥> 1,
∥xk+1 −xk∥2
otherwise,
with ϵ = 10−6. The initial point of the DCA was always chosen as xo
i = r/√n, i =
1, . . . , n.
5.1. Comparison with safeguarding and dichotomy algorithms. In the
ﬁrst experiment we solved 150 problems (ﬁve problems per dimension n) whose data
was randomly generated in a similar way as described in .
The matrix A is
of the form A = UDUT for some orthogonal matrix U and a diagonal matrix D.
Let b = Ug for some vector g. The orthogonal matrix U was of the form Q1Q2Q3
where Qj = I −2wjwT
j = 1, 2, 3 and the components wj were random
numbers in (−1, 1). The elements of g were chosen as random numbers in (−1, 1)
while the diagonal elements of matrix D are random numbers in (−5, 5). This choice
DCA FOR SOLVING THE TRUST-REGION SUBPROBLEM
leads to the normal case.
The hard case is generated by setting to zero all the
components of g corresponding to the smallest element of D (that is λ1) and then by
taking r greater than ∥(A−λ1I)+b∥(here “+” denotes the Moore–Penrose generalized
inverse), i.e., r > ∥d∥where di = gi/(Dii −λ1) if Dii ̸= λ1, 0 otherwise. A positive
deﬁnite case (resp. positive semideﬁnite) was obtained by replacing Dii < 0 by |Dii|
(resp. 0). In the normal case, r is randomly chosen in (1, 100). The values of ρ
(in the DCA) were chosen as 0.25∥A∥1 or 0.35∥A∥1. For the safeguarding algorithm
(Sfg) we took σ1 = 10−4, σ2 = 10−2. For the dichotomy algorithm (Dct) we chose
ε3 = 0.001(λk
U). The optimal values provided by the three algorithms are, to
within 10−3, equal.
Tables 1 and 2 indicate, respectively, the average iteration (IT) and the average
CPU time in seconds (on Sun SPARC-2) of three algorithms in nonconvex and convex
Comparison with dichotomy and safeguarding algorithms, A is indeﬁnite, the normal case (left)
and the hard case (right).
Comparison with dichotomy and safeguarding algorithms, A is positive deﬁnite (left) and A is
positive semideﬁnite (right).
5.2. Comparison with the new matrix-free algorithm. In the second experiment we solved two diﬀerent families of 112 problems by the DCA and the new
matrix-free algorithm (NMFA). We used the code in MATLAB of S. A. Santos and
D. C. Sorensen to generate the data. First, the matrix A takes the form L −5I,
where L is the standard 2-D discrete Laplacian on the unit square based upon a 5-point
stencil with equally-spaced meshpoints. The shift of −5I was introduced to make A
indeﬁnite. The vector b was randomly generated with entries uniformly distributed
on (0, 1). The hard case is generated by performing the operation b ←b −q1(qT
to orthogonalize the vector b against q1, the eigenvector of A corresponding to the
smallest eigenvalue λ1. The radius was always equal to 100.
In the second family of problems, the matrix A is of the form UDUT and generated
as in subsection 5.6. of . D was a diagonal matrix and U = I−2uuT , uT u = 1. The
elements of D = diag(d1, . . . , dn) were randomly generated and uniformly distributed
PHAM DINH TAO AND LE THI HOAI AN
on (−5, 5). The entries of u and b were randomly selected from a uniform distribution
on (−0.5, 0.5). The vector u was normalized to have unit length. As in the ﬁrst family,
an orthogonalization of b against q1 generated a hard case. A noise vector of norm
10−8 was added to b. To ensure the hard case the radius was chosen as r = 2rmin
where rmin = ∥(A −d1I)+b∥. In the normal case the radius was ﬁxed at r = 100
when n = 256, n = 576, n = 1024 and r = 20 when n = 100.
We used the IRLM implemented in the package ARPACK , for
computing the two smallest eigenpairs at each iteration in the NMFA. For the
IRLM we choose nine Lanczos basis vectors, six shifts on each implicit restart,
and diﬀerent tolerances at each case of the two families. In the ﬁrst family (A =
L −5I) the initial tolerance was εR = 0.5 for all dimensions in both cases, except εR = 0.1 when n = 1024 in the normal case.
Subsequently, in the normal case εR = max{min{εR, |r −∥xk∥/r|}, 0.075} when n = 100, n = 256, n =
576; εR = max{min{εR, |r −∥xk∥/r}, 0.01} when n = 1024 and in the hard case;
εR = max{min{εR, |r −∥xk∥/1000r|, |τ 2(zT Az −λk)/(1000(bT xk+ λkr2)|}, 0.01}
max{min{εR, |r −∥xk∥/1000r|,
|τ 2(zT Az −λk)/1000(bT xk + λkr2|}, 0.001} when n = 1024.
In the second family (A = UDU T ) the initial tolerance was εR = 10−4 (resp., εR = 10−2 ) when
n = 100, εR = 10−6 (resp., εR = 10−3 ) when n = 256, n = 576, and εR =
10−7 (resp., εR = 10−4) when n = 1024 in the hard case (resp., the normal case).
Subsequently, εR = min{εR, |r −∥xk∥/1000r|, |τ 2(zT Az −λk)/(1000(bT xk + λkr2))|}
(resp., εR = min{εR,
|r −∥xk∥/r|, |τ 2(zT Az −λk)/(bT xk + λkr2)|}). For a ﬁxed
tolerance εR, the stopping condition in the IRLM is (∥f∥|eT
j y|)2 ≤εR|µ|G(j) (cf.
206, 222]).
In our experiments j = 3.
The IRLM was started with
v = (1, . . . , 1)T /√n + 1 and then the previously calculated eigenvector corresponding
to the smallest eigenvalue was used as the initial vector.
The parameters for the
NMFA were the following: εδ = εhc = 10−6, εν = 10−2, α0 = min{0, αU} and the
initial of δS was δS = min{Aii : i = 1, . . . , n} + 0.5 in the hard case with A = UDU T
and δS = min{Aii : i = 1, . . . , n} in other cases. (See for these notations.)
For computing ρ in the DCA we also applied the IRLM to the matrix A with the
tolerance εR = 0.5 in the ﬁrst family (A = L −5I) and εR = 0.1 in the second family
(A = UDU T ). So we obtained an approximation ˜λn of the largest eigenvalue λn of A
and took ρ = ˜λn + 0.1 (resp. ρ = ˜λn + 0.5) when A = L −5I (resp. A = UDU T ).
For each case (normal and hard cases) seven problems per dimension were generated with diﬀerent seeds for each family and solved by both Santos and Sorensen’s
algorithm (NMFA) and our code (DCA). The average results are indicated in Tables 3 and 4.
In these tables we used the following notation: IT stands for the
number of iterations; MVP stands for the number of matrix–vector products; KTC =
∥b + (A + λ∗I)x∗∥/∥b∥(this presents the Kuhn–Tucker condition); time: CPU time
in seconds (on Sun SPARC-10). The value λ∗is the average of the obtained multipliers provided by each algorithm. Note that for the DCA the number of required
matrix–vector products is exactly the sum of the number of iterations in the DCA and
the number of matrix–vector products in the IRLM. In our experiments we observe
from numerical results that the last quantity was always equal to nine. The quantity
KTC in the DCA was equal to zero because λ∗was deduced from the expression
(A + λ∗I)x∗= −b. CPU time of the DCA was presented in two parts: the ﬁrst (resp.
second) part indicated CPU time of the IRLM (resp. DCA).
5.3. Comparison with the gradient projection algorithm in the convex
case. In the third experiment we solved 56 problems whose data was generated as
DCA FOR SOLVING THE TRUST-REGION SUBPROBLEM
Comparison with the new matrix-free method, A = L −5I.
0.07 + 0.5
Comparison with the new matrix-free method, A = UDUT .
13.2+476.4
13.2+576.4
in subsection 5.1. We considered two types of matrices for A: positive semideﬁnite
(p.s.d.) and positive deﬁnite (p.d.) with n = 250 and n = 500. The diagonal elements
of D were in (−5, 5) when n = 250 and in (−50, 50) when n = 500. The elements of
g were random numbers in (−1, 1). As in subsection 5.1, a p.d. (resp., p.s.d.) matrix
A = UDU T was obtained by replacing Dii < 0 by |Dii| (resp., 0). We considered two
cases (normal and hard case) when A is a p.s.d. matrix. For each type of A seven
problems per dimension and per case were solved by the gradient projection algorithm
(GPA) and by the DCA. In the GPA we took ρ = 1/2λn + 0.1 if A is p.s.d. and the
theoretically optimal ρ = 1/2(λ1 + λn) if A is p.d. In the DCA we took ρ = λn. The
average result is reported in Table 5.
PHAM DINH TAO AND LE THI HOAI AN
Comparison with the gradient projection method in the convex case.
normal case
normal case
5.4. Diﬀerent choices for ρ. In the fourth experiment we solved 20 problems
(ten per dimension) of the second family generated exactly as in subsection 5.2. We
considered the normal case when n = 256 and the hard case when n = 1024. In
the ﬁrst case the radius was equal to 100 and in the last case it varied in the interval
(110, 701). Each of these problems was solved ﬁve times, with ρ = ∥A∥1, ρ = 1/2∥A∥1,
ρ = 1/3∥A∥1, ρ = 5, and ρ = ˜λn + 0.5. The value ˜λn was an approximation to
the largest eigenvalue of A calculated by the IRLM with the tolerance tol = 0.1. In
these problems, ∥A∥1 were in the interval (18, 19.5). The average result is indicated in
Table 6. CPU time (on Sun SPARC-10) in case ρ = ˜λn+0.5 was presented in two parts
as in Tables 3 and 4. The quantity avOPT presented the average of optimal values.
Average behavior for diﬀerent choices of ρ.
13.2 + 502.7
5.5. Diﬀerent sizes for the radius. In the last experiment (Table 7) we solved
10 problems of the second family mentioned above.
We considered here the normal case with n = 500.
The radius varied by a factor of 10 through the values
100, . . . , 0.001. ρ was always equal to 5.
5.6. Comments on computational results. (i) For every test problem the
DCA (without restarting procedure) always provided a global solution.
DCA FOR SOLVING THE TRUST-REGION SUBPROBLEM
Average behavior for diﬀerent sizes of the radius.
(ii) The parameter ρ as well as the d.c. representation of the objective function
have an important inﬂuence on the convergence rate of the DCA. The practical choice
(subsection 4.6) of ρ seems to be well suited (Table 6). We observe (see Table 5) the
following:
• If A is positive deﬁnite, the choice ρ = λn is much better than the theoretically
optimal choice ρ = (λ1 + λn)/2 given in Proposition 1. The ratio of execution times
is 2.5 for n = 250 and 8.7 for n = 500.
• If A is positive semideﬁnite, the choice ρ = λn is better than the choice ρ =
0.5λn + 0.1 in the hard case. The ratio of execution times is 5.4 when n = 250 and 2
when n = 500. The situation reverses in the normal case (1.6 when n = 250 and 1.35
when n = 500).
(iii) The DCA is faster than the Sfg. Table 1 indicates that in the normal case
(resp., hard case) with A being indeﬁnite the ratio of execution times varies between
2.4 and 8 (resp., 1.7 and 4.7). In the convex case Table 2 shows that the ratio of
execution times varies between 1.2 and 16.8 (resp., 1.7 and 16.6) when A is positive
deﬁnite (resp., positive semideﬁnite).
(iv) The DCA is faster than the NMFA. In the case where A = L −5I, Table 3
indicates that the ratio of execution times belongs to the interval ]1, 18[. It is more
signiﬁcant in the hard case (equal to 18 when n = 100, 12 when n = 256, 10 when
n = 576 and 11.8 when n = 1024). In the normal case the ratio is smaller (equal to 6
when n = 100, 5 when n = 256 and 2.6 when n = 1024).
In the case where A = UDU T , Table 4 shows similar results. In the normal case
the ratio of execution times is 1.4 when n = 100, 2.6 when n = 256, 3 when n = 576,
and 4.5 when n = 1024. It becomes (in the hard case) 3.2 when n = 100, 7.6 when
n = 256, 10.6 when n = 576, and 7.4 when n = 1024.
(v) One of the referees suggested the example: A = Diag(1, −1), b = (1, 1), r = 2,
and ρ = 1.1, where the pure DCA (i.e., without the restarting procedure) with the
choice xo = (r/√n, r/√n) = (
2) does not lead to a global solution. However,
we observe that the random choice of xo : xo
i = 2[random(100) −0.5], i = 1, 2 yields
a global one.
6. Conclusion. We have presented a thorough study of the d.c. optimization,
its algorithm DCA, and the application of the DCA to solving the trust-region subproblems.
By its very approach the DCA is completely diﬀerent from other available methods
for the trust-region problem , , , , . The DCA is quite simple and
requires matrix–vector products only. Moreover, it indiﬀerently treats the normal and
hard cases of the trust-region subproblem. Theoretically, it has been stated that the
DCA converges to a Kuhn–Tucker point of the trust-region subproblem. We observe,
however, that in all numerical examples we tried, convergence occurred to a global
minimizer. The foundations of the d.c. optimization theory enable us to conjecture
that the DCA converges to a local minimizer (of the trust-region subproblem) and
so, most times, to a global one according to Martinez’s results. In the absence of a
PHAM DINH TAO AND LE THI HOAI AN
theoretical proof of the conjecture, we have pointed out a simple numerical procedure
to restart the DCA with a new initial point-in-case when the solution provided by the
DCA is not global. This restarting procedure needs computing the smallest eigenvalue
of the matrix A (in the trust-region subproblem) and a corresponding eigenvector and
uses for that the quite inexpensive Implicitly Restarted Lanczos Method introduced by
D. C. Sorensen . Since the IRLM meets the requirements of limited storage and
reliance only on matrix–vector products, the DCA with at most 2m + 2 restartings
(Theorem 4) requires only matrix–vector products too and converges to a global
solution. In practice the DCA rarely has recourse to the restarting procedure. From
the computational viewpoint, a lot of our numerical experiments proved the robustness
and eﬃciency of the DCA with respect to other well-known algorithms, especially in
the large scale trust-region subproblem.
Proof of the basic convergence theorem of the DCA for
general d.c. programming. First, we need the following results.
PROPOSITION A.1. Suppose that the sequences {xk} and {yk} are generated by
the simpliﬁed DCA. Then we have
(g −h)(xk+1) ≤(h∗−g∗)(yk)−ρ2
2 ∥dxk∥2 ≤(g −h)(xk)−ρ1 + ρ2
The equality (g −h)(xk+1) = (g −h)(xk) holds if and only if
xk ∈∂g∗(yk), yk ∈∂h(xk+1) and (ρ1 + ρ2)∥dxk∥= 0.
(ii) Similarly, by duality we have
(h∗−g∗)(yk+1) ≤(g −h)(xk+1) −ρ∗
2 ∥dyk∥2 ≤(h∗−g∗)(yk) −ρ∗
The equality (h∗−g∗)(yk+1) = (h∗−g∗)(yk) holds if and only if
xk+1 ∈∂g∗(yk+1), yk ∈∂h(xk+1) and (ρ∗
2)∥dyk∥= 0.
Proof of Proposition A.1.
(i) Since yk ∈∂h(xk) we have h(xk+1) ≥h(xk) +
⟨xk+1 −xk, yk⟩+ ρ2/2∥dxk∥2. Hence,
(g −h)(xk+1) ≤g(xk+1) −⟨xk+1 −xk, yk⟩−h(xk) −ρ2
Likewise, xk+1 ∈∂g∗(yk) implies
g(xk) ≥g(xk+1) + ⟨xk −xk+1, yk⟩+ ρ1
g(xk+1) −⟨xk+1 −xk, yk⟩−h(xk) ≤(g −h)(xk) −ρ1
On the other hand,
xk+1 ∈∂g∗(yk) ⇔⟨xk+1, yk⟩= g(xk+1) + g∗(yk),
yk ∈∂h(xk) ⇔⟨xk, yk⟩= h(xk) + h∗(yk).
DCA FOR SOLVING THE TRUST-REGION SUBPROBLEM
g(xk+1) −⟨xk+1 −xk, yk⟩−h(xk) = h∗(yk) −g∗(yk).
Finally, combining (26), (27), and (30), we get
(g −h)(xk+1) ≤(h∗−g∗)(yk) −ρ2
2 ∥dxk∥2 ≤(g −h)(xk) −ρ1 + ρ2
If ρ1 + ρ2 > 0, the last statement of (i) is an immediate consequence of the equality
dxk = 0 and the construction of the sequences {xk} and {yk}.
It is clear that there exist ρ1 and ρ2 such that ρ1+ρ2 > 0 if and only if ρ(h)+ρ(g) >
0. In case ρ(h) = ρ(g) = 0, (29) implies the equivalence between (g −h)(xk+1) =
(g −h)(xk) and the combination of (32) and (33)
(g −h)(xk+1) = (h∗−g∗)(yk),
(h∗−g∗)(yk) = (g −h)(xk).
We then deduce from (28) and (32) that h(xk+1) + h∗(yk) = ⟨xk+1, yk⟩,
i.e., yk ∈
∂h(xk+1). Similarly, (29) and (33) give g(xk) + g∗(yk) = ⟨xk, yk⟩, i.e., xk ∈∂g∗(yk).
Property (ii) is proved analogously.
The following result is an important consequence of Proposition A.1.
COROLLARY A.2.
(g−h)(xk+1) ≤(h∗−g∗)(yk)−ρ2
2 ∥dxk∥2 ≤(g−h)(xk)−
2 ∥dyk−1∥2 + ρ2
(g−h)(xk+1) ≤(h∗−g∗)(yk)−ρ∗
2 ∥dyk∥2 ≤(g−h)(xk)−
2 ∥dyk−1∥2 + ρ∗
The equality (g −h)(xk+1) = (g −h)(xk) holds if and only if
xk ∈∂g∗(yk), yk ∈∂h(xk+1) and (ρ1 + ρ2)dxk = ρ∗
1dyk−1 = ρ∗
Similarly, by duality we have
(h∗−g∗)(yk+1) ≤(g−h)(xk+1)ρ∗
2 ∥dyk∥2 ≤(h∗−g∗)(yk)−
2 ∥dyk∥2 + ρ2
(iv)(h∗−g∗)(yk+1) ≤(g−h)(xk+1)−ρ1
2 ∥dxk+1∥2 ≤(h∗−g∗)(yk)−
2 ∥dxk+1∥2 + ρ2
The equality (h∗−g∗)(yk+1) = (h∗−g∗)(yk) holds if and only if
xk+1 ∈∂g∗(yk+1), yk ∈∂h(xk+1) and (ρ∗
2)dyk = ρ2dxk = ρ1dxk+1 = 0.
Proof. The inequalities in (i) and (ii) are easily deduced from Properties (i) and
(ii) of Proposition A.1. The inequalities in (iii) and (iv) can be shown by the same
arguments as in the proof of Proposition A.1.
We are now in a position to demonstrate Theorem 3.7.
PHAM DINH TAO AND LE THI HOAI AN
Proof of Theorem 3.7. Properties (i) and (ii) are proved analogously; therefore,
we give here the proof for (i) only.
The ﬁrst inequality of (i) is an immediate consequence of (i) and (ii) of Corollary
• If ρ2∥dxk∥2 ≤ρ∗
2∥dyk∥2, then it follows from (ii) of Corollary A.2 that
(h∗−g∗)(yk) −max
2 ∥dxk∥2, ρ∗
= (h∗−g∗)(yk) −ρ∗
≤(g −h)(xk) −
2 ∥dyk−1∥2 + ρ∗
Similarly, Property (i) of Corollary A.2 implies
(h∗−g∗)(yk) −ρ∗
2 ∥dyk∥2 ≤(h∗−g∗)(yk) −ρ2
≤(g −h)(xk) −
2 ∥dyk−1∥2 + ρ2
On the other hand, by (i) of Proposition A.1,
(h∗−g∗)(yk)−ρ∗
2 ∥dyk∥2 ≤(h∗−g∗)(yk)−ρ2
2 ∥dxk∥2 ≤(g −h)(xk)−ρ1 + ρ2
Combining these inequalities, we get the second inequality of (i).
2∥dyk∥2 ≤ρ2∥dxk∥2, then by using the same arguments we can easily show
the second inequality of (i). The ﬁrst property of (iii) is evident. We will prove the
Taking (30) and (i) into account, we have
k→+∞(g −h)(xk+1) =
k→+∞{g(xk+1) −⟨xk+1 −xk, yk⟩−h(xk)} =
k→+∞(g −h)(xk).
The second equality implies limk→+∞{g(xk+1) −⟨xk+1 −xk, yk⟩−g(xk)} = 0, i.e.,
limk→+∞{g(xk) + g∗(yk) −⟨xk, yk⟩} = 0, since xk+1 ∈∂g∗(yk).
Likewise, it results from the ﬁrst equality that limk→+∞{h(xk+1−⟨xk+1−xk, yk⟩−
h(xk)} = 0, i.e., limk→+∞{h(xk+1) + h∗(yk) −⟨xk+1, yk⟩} = 0 since yk ∈∂h(yk).
(iv) We assume α is ﬁnite and the sequences {xk} and {yk} are bounded. Let
x∗be a limit point of {xk}. For the sake of simplicity we write limk→+∞xk = x∗.
We can suppose (by extracting a subsequence if necessary) that the sequence {yk}
converges to y∗∈∂h(x∗). Property (iii) then implies
k→+∞{g(xk) + g∗(yk)} =
k→+∞⟨xk, yk⟩= ⟨x∗, y∗⟩.
Let θ(x, y) = g(x) + g∗(y) for (x, y) ∈X × Y . It is clear that θ ∈Γo(X × Y ). Then
the lower semicontinuity of θ implies
θ(x∗, y∗) ≤
k→+∞inf θ(xk, yk) =
k→+∞θ⟨xk, yk⟩= ⟨x∗, y∗⟩,
i.e., θ(x∗, y∗) = g(x∗) + g∗(y∗) = ⟨x∗, y∗⟩.
In other words, y∗∈∂g(x∗). According to Lemma A.3 stated below we have
k→+∞h(xk) = h(x∗) and lim
k→+∞h∗(yk) = h∗(y∗) since yk ∈∂h(xk), xk →x∗and yk →y∗.
DCA FOR SOLVING THE TRUST-REGION SUBPROBLEM
Hence, in virtue of (iii),
k→+∞(g −h)(xk) =
k→+∞g(xk) −
k→+∞h(xk) =
k→+∞g(xk) −h(x∗) = β,
k→+∞(h∗−g∗)(yk) =
k→+∞h∗(yk) −
k→+∞g∗(yk) = h∗(y∗) −
k→+∞g∗(yk) = β.
It then suﬃces to show that
k→+∞g(xk) = g(x∗);
k→+∞g∗(yk) = g∗(y∗).
Since limk→+∞g(xk) and limk→+∞g∗(yk) exist, (iii) implies
g(x∗) + g∗(y∗) =
k→+∞{g(xk) + g∗(yk)} =
k→+∞g(xk) +
k→+∞g∗(yk).
Further, because of the lower semicontinuity of g and g∗,
k→+∞g(xk) =
k→+∞inf g(xk) ≥g(x∗),
k→+∞g∗(yk) =
k→+∞inf g∗(yk) ≥g∗(y∗).
The former equalities imply that these last inequalities are in fact equalities. The
proof of Theorem 3.7 is complete.
LEMMA A.3. Let h ∈Γo(X) and {xk} be a sequence of elements in X such that
(i) xk →x∗;
(ii) there exists a bounded sequence {yk} with yk ∈∂h(xk);
(iii) ∂h(x∗) is nonempty.
Then limk→+∞h(xk) = h(x∗).
Proof. Indeed, let y∗∈∂h(x∗), then h(xk) ≥h(x∗) + ⟨xk −x∗, y∗⟩
yk ∈∂h(xk) we have h(x∗) ≥h(xk) + ⟨x∗−xk, yk⟩
∀k. Hence, h(xk) ≤h(x∗)+
⟨xk −x∗, yk⟩
∀k. As xk →x∗, we have limk→+∞⟨xk −x∗, y∗⟩= 0.
limk→+∞⟨xk −x∗, yk⟩= 0, since the sequence {yk} is bounded.
Consequently,
limk→+∞h(xk) = h(x∗).
Acknowledgments. The authors are grateful to the referees and to Professor
J. M. Martinez for their helpful comments and suggestions as well as for their example
in 5.6 (v) which have improved the presentation of the revised paper. Thanks also go
to Dr. S. A. Santos and Professor D. C. Sorensen for making their MATLAB code
available to us for experimentation.