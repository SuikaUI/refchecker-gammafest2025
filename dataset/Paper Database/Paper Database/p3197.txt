Deep Adaptive Input Normalization
for Time Series Forecasting
Nikolaos Passalis, Anastasios Tefas, Juho Kanniainen, Moncef Gabbouj, and Alexandros Iosiﬁdis
Abstract—Deep Learning (DL) models can be used to tackle
time series analysis tasks with great success. However, the performance of DL models can degenerate rapidly if the data are not
appropriately normalized. This issue is even more apparent when
DL is used for ﬁnancial time series forecasting tasks, where the
non-stationary and multimodal nature of the data pose signiﬁcant
challenges and severely affect the performance of DL models. In
this work, a simple, yet effective, neural layer, that is capable of
adaptively normalizing the input time series, while taking into
account the distribution of the data, is proposed. The proposed
layer is trained in an end-to-end fashion using back-propagation
and leads to signiﬁcant performance improvements compared to
other evaluated normalization schemes. The proposed method
differs from traditional normalization methods since it learns
how to perform normalization for a given task instead of using a
ﬁxed normalization scheme. At the same time, it can be directly
applied to any new time series without requiring re-training. The
effectiveness of the proposed method is demonstrated using a
large-scale limit order book dataset, as well as a load forecasting
Index Terms—time series forecasting, data normalization, limit
order book data, deep learning
I. INTRODUCTION
Forecasting time series is an increasingly important topic,
with several applications in various domains , , ,
 , , , , . Many of these tasks are nowadays
tackled using powerful deep learning (DL) models , ,
 , , , which often lead to state-of-the-art results outperforming the previously used methods. However, applying
deep learning models to time series is challenging due to the
non-stationary and multimodal nature of the data. This issue
is even more apparent for ﬁnancial time series, since ﬁnancial
data can exhibit signiﬁcantly different behavior over the time
due to a number of reasons, e.g., market volatility.
To allow for training deep learning models with time series
data, the data must be ﬁrst appropriately normalized. Perhaps
the most widely used normalization scheme for time series
when using DL is the z-score normalization, i.e., subtracting
the mean value of the data and dividing by their standard
deviation. However, z-score normalization is unable to efﬁciently handle non-stationary time series, since the statistics
used for the normalization are ﬁxed both during the training
and inference. Several recent works attempt to tackle this
Nikolaos Passalis, Juho Kanniainen and Moncef Gabbouj are with the Faculty of Information Technology and Communication, Tampere University, Finland. Anastasios Tefas is with the School of Informatics, Aristotle University
of Thessaloniki, Greece. Alexandros Iosiﬁdis is with the Department of Engineering, Electrical and Computer Engineering, Aarhus University, Denmark.
E-mail: , , ,
 , 
issue either by employing more sophisticated normalization
schemes , , or by using carefully handcrafted
stationary features . Even though these approaches can
indeed lead to slightly better performance when used to
train deep learning models, they exhibit signiﬁcant drawbacks,
since they are largely based on heuristically-designed normalization/feature extraction schemes, e.g., using price change
percentages instead of absolute prices, etc., while there is no
actual guarantee that the designed scheme will be indeed be
optimal for the task at hand.
To overcome these limitations, we propose a Deep Adaptive
Input Normalization (DAIN) layer that is capable of a) learning
how the data should be normalized and b) adaptively changing
the applied normalization scheme during inference, according
to the distribution of the measurements of the current time
series, allowing for effectively handling non-stationary and
multimodal data. The proposed scheme is straightforward to
implement, can be directly trained along with the rest of the
parameters of a deep model in an end-to-end fashion using
back-propagation and can lead to impressive improvements
in the forecasting accuracy. Actually, as we experimentally
demonstrate in Section III, the proposed method allows for
directly training deep learning models without applying any
form of normalization to the data, since the raw time series is
directly fed to the used deep learning model.
The main contribution of this work is the proposal of
a deep learning layer that learns how the data should be
normalized according to their distribution instead of using
ﬁxed normalization schemes. To this end, the proposed layer
is formulated as a series of three sublayers, as show in Fig. 1.
The ﬁrst layer is responsible for shifting the data into the
appropriate region of the feature space (centering), while the
second layer is responsible for linearly scaling the data in
order to increase or reduce their variance (standardization)
The third layer is responsible for performing gating, i.e., nonlinearly suppressing features that are irrelevant or not useful
for the task at hand. Note that the aforementioned process
is adaptive, i.e., the applied normalization scheme depends
on the actual time series that is fed to the network, and it
is also trainable, i.e., the way the proposed layers behave
is adapted to the task at hand using back-propagation. The
effectiveness of the proposed approach is evaluated using a
large-scale limit order book dataset that consists of 4.5 million
limit orders , as well as a load forecasting dataset . An
open-source implementation of the proposed method, along
with code to reproduce the experiments conducted in this
paper, are available at 
To the best of our knowledge this is the ﬁrst time that
 
Aggergator
Deep Neural
Time-series
Normalized
Time-series
Deep Adaptive Input Normalization Layer
Aggergator
Aggergator
Fig. 1. Architecture of the proposed Deep Adaptive Input Normalization Layer (DAIN)
an adaptive and trainable normalization scheme is proposed
and effectively used in deep neural networks. In contrast to
regular normalization approaches, e.g., z-score normalization,
the proposed method a) learns how to perform normalization
for the task at hand (instead of using some ﬁxed statistics
calculated beforehand) and b) effectively exploits information
regarding all the available features (instead of just using
information for each feature of the time series separately). The
proposed approach is also related to existing normalization
approaches for deep neural networks, e.g., batch normalization , instance normalization , layer normalization 
and group normalization . However, these approaches are
not actually designed for normalizing the input data and, most
importantly, they are merely based on the statistics that are
calculated during the training/inference, instead of learning
to dynamically normalize the data. It is worth noting that
it is not straightforward to use non-linear neural layers for
adaptively normalizing the data, since these layers usually
require normalized data in the ﬁrst place in order to function
correctly. In this work, this issue is addressed by ﬁrst using two
robust and carefully initialized linear layers to estimate how
the data should be centered and scaled, and then performing
gating on the data using a non-linear layer that operates on
the output of the previous two layers, effectively overcoming
this limitation.
The rest of the paper is structured as follows. First, the
proposed method is analytically described in Section II. Then,
an extensive experimental evaluation is provided in Section III,
while conclusions are drawn in Section IV.
II. DEEP ADAPTIVE INPUT NORMALIZATION
Let {X(i) ∈Rd×L; i = 1, ..., N} be a collection of N time
series, each of them composed of L d-dimensional measurements (or features). The notation x(i)
∈Rd, j = 1, 2, . . . , L
is used to refer to the d features observed at time point
j in time series i. Perhaps the most widely used form of
normalization is to perform z-score scaling on each of the
features of the time series. Note that if the data were not
generated by a unimodal Gaussian distribution, then using the
mean and standard deviation can lead to sub-optimal results,
especially if the statistics around each mode signiﬁcantly differ
from each other. In this case, it can be argued that data
should be normalized in an mode-aware fashion, allowing
for forming a common representation space that does not
depend on the actual mode of the data. Even though this
process can discard useful information, since the mode can
provide valuable information for identifying each time series,
at the same time it can hinder the generalization abilities of
a model, especially for forecasting tasks. This can be better
understood by the following example: assume two tightly
connected companies with very different stock prices, e.g., 1$
and 100$ respectively. Even though the price movements can
be very similar for these two stocks, the trained forecasting
models will only observe very small variations around two
very distant modes (if the raw time series are fed to the model).
As a result, discarding the mode information completely can
potentially improve the ability of the model to handle such
cases, as we will further demonstrate in Section III, since the
two stocks will have very similar representations.
The goal of the proposed method is to learn how the
measurements x(i)
should be normalized by appropriately
shifting and scaling them:
where ⊘is the Hadamard (entrywise) division operator. Note
that global z-score normalization is a special case with α(i) =
α = [µ1, µ2, . . . , µd] and β(i) = β = [σ1, σ2, . . . , σd], where
µk and σk refer to the global average and standard deviation
of the k-th input feature:
However, as it was already discussed, the obtained estimations
for α and β might not be the optimal for normalizing
every possible measurement vector, since the distribution of
the data might signiﬁcantly drift, invalidating the previous
choice for these parameters. This issue becomes even more
apparent when the data are multimodal, e.g., when training
model using time series data from different stocks that exhibit
signiﬁcantly different behavior (price levels, trading frequency,
etc.). To overcome these limitations we propose to dynamically
estimate these quantities and separately normalize each time
series by implicitly estimating the distribution from which
each measurement was generated. Therefore, in this work, we
propose normalizing each time series so that α and β are
learned and depend on the current input, instead of being the
global averages calculated using the whole dataset.
The proposed architecture is summarized in Fig. 1. First
a summary representation of the time series is extracted by
averaging all the L measurements:
This representation provides an initial estimation for the mean
of the current time series and, as a result, it can be used
to estimate the distribution from which the current time
series was generated, in order to appropriately modify the
normalization procedure. Then, the shifting operator α(i) is
deﬁned using a linear transformation of the extracted summary
representation as:
α(i) = Waa(i) ∈Rd,
where Wa ∈Rd×d is the weight matrix of the ﬁrst neural
layer, which is responsible for shifting the measurements
across each dimension. Employing a linear transformation
layer ensures that the proposed method will be able to handle
data that are not appropriately normalized (or even not normalized at all), allowing for training the proposed model in an
end-to-end fashion without having to deal with stability issues,
such as saturating the activation functions. This layer is called
adaptive shifting layer, since it estimates how the data must
be shifted before feeding them to the network. Note that this
approach allows for exploiting possible correlations between
different features to perform more robust normalization.
After centering the data using the process described in (3),
the data must be appropriately scaled using the scaling operator β(i). To this end, we calculate an updated summary
representation that corresponds to the standard deviation of
the data as:
k = 1, 2, . . . , d.
Then, the scaling function can be similarly deﬁned as a linear
transformation of this summary representation allowing for
scaling each of the shifted measurements:
β(i) = Wbb(i) ∈Rd,
where Wb ∈Rd×d is the weight matrix the scaling layer.
This layer is called adaptive scaling layer, since it estimates
how the data must be scaled before feeding them to the
network. Also, note that this process corresponds to scaling
the data according to their variance, as performed with z-score
normalization.
Finally, the data are fed to an adaptive gating layer, which is
capable of suppressing features that are not relevant or useful
for the task as hand as:
where ⊙is Hadamard (entrywise) multiplication operator and
γ(i) = sigm(Wcc(i) + d) ∈Rd,
sigm(x) = 1/(1 + exp(−x)) is the sigmoid function, Wc ∈
Rd×d and d ∈Rd are the parameters of the gating layer, and
c(i) is a third summary representation calculated as:
Note that in contrast with the previous layers, this layer is nonlinear and it is capable of suppressing the normalized features.
In this way, features that are not relevant to the task at hand
or can harm the generalization abilities of the network, e.g.,
features with excessive variance, can be appropriate ﬁltered
before being fed to the network. Overall, α(i), β(i), γ(i) are
dependent on current ’local’ data on window i and the ’global’
estimates of Wa, Wb, Wc, d that are trained using multiple
samples on time-series, {X(i) ∈Rd×L; i = 1, ..., M}, where
M is the number of samples in the training data.
The output of the proposed normalization layer, which is
called Deep Adaptive Input Normalization (DAIN), can be
obtained simply by feed-forwarding through its three layers,
as shown in Fig. 1, while the parameters of the layers are kept
ﬁxed during the inference process. Therefore, no additional
training is required during inference. All the parameters of the
resulting deep model can be directly learned in an end-to-end
fashion using gradient descent:
Wa, Wb, Wc, d, W
where L denotes the loss function used for training the network
and W denotes the weights of the neural network that follows
the proposed layer. Therefore, the proposed normalization
scheme can be used on top of every deep learning network and
the resulting architecture can be trained using the regular backpropagation algorithm, as also experimentally demonstrated
in Section III. Note that separate learning rates are used for
the parameters of each sub-layer, i.e., ηa, ηb and ηc. This
was proven essential to ensure the smooth convergence of
the proposed method due to the enormous differences in the
resulting gradients between the parameters of the various sublayers.
III. EXPERIMENTAL EVALUATION
For evaluating the proposed method a challenging largescale dataset , that contains limit order book data,
was employed . The data were collected from 5 Finnish
companies traded in the Helsinki Exchange (operated by
Nasdaq Nordic) and the ten highest and ten lowest ask/bid
order prices were measured. The data were gathered over a
period of 10 business days from 1st June 2010 to 14th June
2010. Then, the pre-processing and feature extraction pipeline
proposed in was employed for processing the 4.5 million
limit orders that were collected, leading to a total of 453,975
144-dimensional feature vectors that were extracted.
We also followed the anchored evaluation setup that was
proposed in . According to this setup the time series that
were extracted from the ﬁrst day were used to train the model
ABLATION STUDY USING THE FI-2010 DATASET
12.71 ± 13.22
0.0010 ± 0.0014
z-score norm.
53.76 ± 0.99
0.3059 ± 0.0157
Sample avg norm.
41.80 ± 3.58
0.1915 ± 0.0284
Batch Norm.
52.72 ± 1.94
0.2893 ± 0.0264
Instance Norm.
59.13 ± 2.94
0.3717 ± 0.0406
57.37 ± 3.16
0.3536 ± 0.0417
DAIN (1+2)
66.71 ± 2.02
0.4896 ± 0.0289
DAIN (1+2+3)
66.92 ± 1.70
0.4934 ± 0.0238
12.61 ± 12.89
0.0003 ± 0.0006
z-score norm.
50.94 ± 1.12
0.2570 ± 0.0184
Sample avg norm.
53.49 ± 3.38
0.2934 ± 0.0458
Batch Norm.
45.89 ± 3.40
0.1833 ± 0.0517
Instance Norm.
57.05 ± 1.61
0.3396 ± 0.0219
59.79 ± 1.46
0.3838 ± 0.0199
DAIN (1+2)
61.91 ± 3.65
0.4136 ± 0.0574
DAIN (1+2+3)
63.02 ± 2.40
0.4327 ± 0.0358
31.61 ± 0.40
0.0075 ± 0.0024
z-score norm.
52.29 ± 2.10
0.2789 ± 0.0295
Sample avg norm.
49.47 ± 2.73
0.2277 ± 0.0403
Batch Norm.
51.42 ± 1.05
0.2668 ± 0.0147
Instance Norm.
54.01 ± 3.41
0.2979 ± 0.0448
55.34 ± 2.88
0.3164 ± 0.0412
DAIN (1+2)
64.21 ± 1.47
0.4501 ± 0.0197
DAIN (1+2+3)
63.95 ± 1.31
0.4461 ± 0.0168
and the data from the second day were used for evaluating the
method. Then, the ﬁrst two days were employed for training
the methods, while the data from the next day were used
for the evaluation. This process was repeated 9 times, i.e.,
one time for each of the days available in the dataset (except
from the last one, for which no test data are available). The
performance of the evaluated methods was measured using the
macro-precision, macro-recall, macro-F1 and Cohen’s κ. Let
TPc, FPc, TNc and FNc be the true positives, false positives,
true negatives and false negatives of class c. The precision of
a class is deﬁned as precc = TPc/(TPc + FPc), the recall
as recallc = TPc/(TPc + FNc), while the F1 score for a
class c is calculated as the harmonic mean of the precision
and the recall: F1c = 2 · (precc · recallc)/(precc + recallc).
These metrics are calculated for each class separately and
then averaged (macro-averaging). Finally, using the Cohen’s
κ metric allows for evaluating the agreement between two
different sets of annotations, while accounting for the possible
random agreements. The mean and standard deviation values
over the anchored splits are reported. The trained models were
used for predicting the direction of the average mid price (up,
stationary or down) after 10 and 20 time steps, while a stock
was considered stationary if the change in the mid price was
less than to 0.01% (or 0.02% for the prediction horizon of 20
time steps).
Three different neural network architectures were used
for the evaluation: a Multilayer Perceptron (MLP) , a
Convolutional Neural Network (CNN) , and a Recurrent Neural Network (RNN) composed of Gated Recurrent
Units . All the evaluated models receive as input the 15
most recent measurement (feature) vectors extracted from the
time series and predict the future price direction. For the MLP
the measurements are ﬂattened into a constant length vector
with 15 × 144 = 2, 160 measurements, maintaining in this
way the temporal information of the time series. The MLP
is composed of one fully connected hidden layer with 512
neurons (the ReLU activation function is used ) followed
by a fully connected layer with 3 output neurons (each one
corresponding to one of the predicted categories). Dropout
with rate of 0.5% is used after the hidden layer . The
CNN is composed of a 1-D convolution layer with 256 ﬁlters
and kernel size of 3, followed by two fully connected layers
with the same architectures as in the employed MLP. The RNN
is composed of a GRU layer with 256 hidden units, followed
by two fully connected layers with the same architectures as
in the employed MLP. The networks were trained using the
cross-entropy loss.
First, an ablation study was performed to identify the effect
of each normalization sub-layer on the performance of the
proposed method. The results are reported in Table I. The
notation “DAIN (1)” is used to refer to applying only (3) for
the normalization process, the notation “DAIN (1+2)” refers
to using the ﬁrst two layers for the normalization process,
while the notation “DAIN (1+2+3)” refers to using all the
three normalization layers. The optimization ran for 20 epochs
over the training data, while for the evaluation the ﬁrst 3 days
(1, 2 and 3) were employed using the anchored evaluation
scheme that was previously described. The proposed method
is also compared to a) not applying any form of normalization
to the data (“No norm.”), b) using z-score normalization, c)
subtracting the average measurement vector from each time series (called “Sample avg norm.” in Table I), d) using the Batch
Normalization and e) Instance Normalization layers 
directly on the input data. Note that Batch Normalization
and Instance Normalization were not originally designed for
normalizing the input data. However, they can be used for this
task, providing an additional baseline. All the three models
(MLP, CNN and RNN) were used for the evaluation, while
the models were trained for 20 training epochs over the data.
Furthermore, the data were sampled with probability inversely
proportional to their class frequency, to ensure that each class
is equally represented during the training. Thus, data from the
less frequent classes were sampled more frequently and vice
versa. For all the conducted experiments of the ablation study
the prediction horizon was set for the next 10 time steps.
Several conclusions can be drawn from the results reported
in Table I. First, using some form of normalization is essential
for ensuring that the models will be successfully trained,
since using no normalization leads to κ values around 0
(random agreement). Using either z-score normalization or
performing sample-based normalization seems to work equally
well. Batch Normalization yields performance similar to the
z-score normalization, as expected, while Instance Normalization improves the performance over all the other baseline
normalization approaches. When the ﬁrst layer of the proposed
DAIN method is applied (adaptive shifting) the performance
of the model over the ﬁxed normalization approaches increases
EVALUATION RESULTS USING THE FI-2010 DATASET
Normalization Method
Macro Precision
Macro Recall
Macro F1 score
50.50 ± 2.03
65.31 ± 4.29
54.65 ± 2.34
0.3206 ± 0.0351
Instance Normalization
54.89 ± 2.88
70.08 ± 2.90
59.67 ± 2.26
0.3827 ± 0.0316
65.67 ± 2.26
71.58 ± 1.21
68.26 ± 1.67
0.5145 ± 0.0256
52.08 ± 2.33
64.41 ± 3.58
54.66 ± 2.68
0.3218 ± 0.0361
Instance Normalization
57.34 ± 2.67
70.77 ± 2.32
61.12 ± 2.33
0.3985 ± 0.0305
62.10 ± 2.09
70.48 ± 1.93
65.31 ± 1.62
0.4616 ± 0.0237
53.73 ± 2.42
54.63 ± 2.88
53.85 ± 2.66
0.3018 ± 0.0412
Instance Normalization
58.68 ± 2.51
57.72 ± 3.90
57.85 ± 2.23
0.3546 ± 0.0346
61.80 ± 3.19
70.92 ± 2.53
65.13 ± 2.37
0.4660 ± 0.0363
53.05 ± 2.28
55.79 ± 2.43
53.97 ± 2.31
0.2967 ± 0.0353
Instance Normalization
58.13 ± 2.39
60.11 ± 2.24
58.75 ± 1.53
0.3588 ± 0.0234
59.16 ± 2.21
68.51 ± 1.54
62.03 ± 2.20
0.4121 ± 0.0331
EVALUATION RESULTS USING THE HOUSEHOLD POWER CONSUMPTION
Normalization Method
Accuracy (%)
Instance Normalization
Instance Normalization
(relative improvement) by more than 15% for the MLP, 30%
for the CNN and 13% for the RNN (Cohen’s κ), highlighting that learning how to adaptively shift each measurement
vector, based on the distribution from which the sample was
generated, can indeed lead to signiﬁcant improvements. Note
that the adaptive shifting layer directly receives the raw data,
without any form of normalization, and yet it manages to
learn how they should be normalized in order to successfully
train the rest of the network. A key ingredient for this was
to a) avoid using any non-linearity in the shifting process
(that could possibly lead to saturating the input neurons) and
b) appropriately initializing the shifting layer, as previously
described. Using the additional adaptive scaling layer, that
also scales each measurement separately, further improves the
performance for all the evaluated model. Finally, the adaptive
gating layer improves the performance for the MLP and CNN
(average relative improvement of about 2.5%). However, it
does not further improve the performance of the GRU. This
can be explained since GRUs already incorporate various
gating mechanisms that can provide the same functionality
as the employed third layer of DAIN.
Then, the models were evaluated using the full training
data (except from the ﬁrst day which was used to tune the
hyper-parameters of the proposed method) and two different
prediction horizons (10 and 20 time steps). The experimental
results are reported in Table II using the two best performing
models (MLP and RNN). Again, no other form of normalization, e.g., z-score, etc., was employed for the model that
uses the proposed (full) DAIN layer and the Instance Normalization layer. Using Instance Normalization leads to better
performance over the plain z-score normalization. However,
employing the proposed method again signiﬁcantly improves
the obtained results over the rest of the evaluated methods for
both models.
Finally, the proposed method was also evaluated on an additional dataset, the Household Power Consumption dataset .
The forecasting task used for this dataset was to predict
whether the average power consumption of a household will
increase or decrease the next 10 minutes, compared to the
previous 20 minutes (a 90%-10% training/testing split was
employed for the evaluation). The same MLP and RNN architectures as before were used for the conducted experiments,
while 20 7-dimensional feature vectors with various measurements (one feature vector for each minute), were fed to the
models. The results of the experimental evaluation are reported
in Table III. Again, the proposed method leads to signiﬁcant
improvements over the three other evaluated methods. Also,
note that even through the GRU model leads to signiﬁcantly
better results when simpler normalization methods are used,
e.g., z-score, it achieves almost the same performance with the
MLP when the proposed DAIN layer is used.
We also performed one additional experiment to evaluate
the ability of the proposed approach to withstand distribution
shifts and/or handle heavy-tailed datasets. More speciﬁcally,
all the measurements fed to the model during the evaluation
were shifted (increased) by adding 3 times their average value
(except of the voltage measurements). This led to a decrease
of classiﬁcation performance from 75.39% to 56.56% for the
MLP model trained with plain z-score normalization. On the
other hand, the proposed method was only slightly affected:
the classiﬁcation accuracy was reduced less than 0.5% (from
78.59% to 78.21%).
Hyper-parameters: The learning hyper-parameters were
tuned for the FI-2010 dataset using a simple line search
procedure (the ﬁrst day of the dataset was used for the
evaluation). The base learning rate was set to η = 10−4,
while the learning rates for the sub-layers were set as follows:
ηa = 10−6/10−2/10−2, ηb = 10−3/10−9/10−8, and ηc =
10/10/10 (MLP/CNN/RNN respectively). For the household
power consumption dataset the learning rates were set to
ηa = 10−5, ηb = 10−2, and ηc = 10. The weights of the
adaptive shifting and adaptive scaling layers were initialized
to the identity matrix, i.e., Wa = Wb = Id×d, while the rest
of the parameters were randomly initialized by drawing the
weights from a normal distribution. The RMSProp algorithm
was used for optimizing the resulting deep architecture .
IV. CONCLUSIONS
A deep adaptive normalization method, that can be trained
in an end-to-end fashion, was proposed in this paper. The
proposed method is easy to implement, while at the same
allows for directly using the raw time series data. The ability of
the proposed method to improve the forecasting performance
was evaluated using three different deep learning models and
two time series forecasting datasets. The proposed method
consistently outperformed all the other evaluated normalization approaches.
There are several interesting future research direction. First,
alternative and potentially stabler learning approaches, e.g.,
multiplicative weight updates, can be employed for updating the parameters of the DAIN layer reducing the need
of carefully ﬁne-tuning the learning rate for each sub-layer
separately. Furthermore, more advanced aggregation methods
can also be used for extracting the summary representation,
such as extending the Bag-of-Features model to extract
representations from time-series . Also, in addition to zscore normalization, min-max normalization, mean normalization, and scaling to unit length can be also expressed as
special cases in the proposed normalization scheme, providing,
among others, different initialization points. Finally, methods
that can further enrich the extracted representation with mode
information (which is currently discarded) can potentially
further improve the performance of the models.