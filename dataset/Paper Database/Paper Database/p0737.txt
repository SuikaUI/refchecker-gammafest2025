The Thirty-Third AAAI Conference on Artiﬁcial Intelligence (AAAI-19)
Where to Go Next: A Spatio-Temporal
Gated Network for Next POI Recommendation
Pengpeng Zhao,1∗Haifeng Zhu,1 Yanchi Liu,2 Jiajie Xu,1∗Zhixu Li,1
Fuzhen Zhuang,3+ Victor S. Sheng,4 Xiaofang Zhou5
1Institute of Artiﬁcial Intelligence, School of Computer Science and Technology, Soochow University, China
2Rutgers University, USA 3Key Lab of IIP of Chinese Academy of Sciences (CAS), ICT, CAS, Beijing, China
4University of Central Arkansas, USA 5The University of Queensland, Australia
 , , , {zhixuli, xujj}@suda.edu.cn,
 , , 
Next Point-of-Interest (POI) recommendation is of great
value for both location-based service providers and users.
However, the state-of-the-art Recurrent Neural Networks
(RNNs) rarely consider the spatio-temporal intervals between
neighbor check-ins, which are essential for modeling user
check-in behaviors in next POI recommendation. To this end,
in this paper, we propose a new Spatio-Temporal Gated Network (STGN) by enhancing long-short term memory network, where spatio-temporal gates are introduced to capture
the spatio-temporal relationships between successive checkins. Speciﬁcally, two pairs of time gate and distance gate
are designed to control the short-term interest and the longterm interest updates, respectively. Moreover, we introduce
coupled input and forget gates to reduce the number of parameters and further improve efﬁciency. Finally, we evaluate
the proposed model using four real-world datasets from various location-based social networks. The experimental results
show that our model signiﬁcantly outperforms the state-ofthe-art approaches for next POI recommendation.
Introduction
Recent years have witnessed the rapid growth of locationbased social network services, such as Foursquare, Facebook Places, Yelp and so on. These services have attracted
many users to share their locations and experiences with
massive amounts of geo-tagged data accumulated, e.g., 55
million users generated more than 10 billion check-ins on
Foursquare until December 2017. These online footprints
(or check-ins) provide an excellent opportunity to understand users’ mobile behaviors. For example, we can analyze
and predict where a user will go next based on historical
footprints. Moreover, such analysis can beneﬁt POI holders
to predict the customer arrival in the next time period.
Copyright c⃝2019, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.
∗Corresponding author
+ Fuzhen Zhuang is also with University of CAS, Beijing,
(a) Language Modeling
(b) Next Basket RS
(c) Next POI RS
Figure 1: wi in (a) represents the i-th word. In (b), pi represents the i-th item and △t is time interval between two
neighbor items. In (c), △d further represents distance interval between two successive check-ins.
In the literature, approaches like latent factor model and
Markov chain have been widely applied for sequential data
analysis and recommendation. Rendle et al. proposed
Factorizing Personalized Markov Chain (FPMC), which
bridges matrix factorization and Markov chains together,
for next-basket recommendation. Cheng et al. extended FPMC to embed personalized Markov chain and user
movement constraint for next POI recommendation. He et
al. proposed a uniﬁed tensor-based latent model to
capture the successive check-in behavior by exploring the latent pattern-level preference for each user. Recently, Recurrent Neural Networks (RNNs) have been successfully employed to model sequential data and become state-of-the-art
methods. Hidasi et al. focused on RNN solutions for
session-based recommendation task, where no user id exists,
and recommendations are made on short session data. Zhu
et al. proposed a variant of Long-Short Term Memory
network (LSTM), called Time-LSTM, to equip LSTM with
time gates to model time intervals for next item recommendation.
However, none of the above recommendation methods
considers both time intervals and geographical distances between neighbor items, which makes next POI recommenda-
tion different from other sequential tasks such as language
modeling and next-basket recommender system (RS). As
shown in Figure 1, there is no spatio-temporal interval between neighbor words in language modeling, and there is no
distance interval between neighbor items in next-basket RS,
while there are time and distance intervals between neighbor
check-ins in next POI recommendation. Some recent efforts
have been made to extend RNNs for modeling dynamic time
and distance intervals. For example, HST-LSTM combines spatio-temporal inﬂuence into LSTM
while it is for general location recommendation. A recent
work ST-RNN tried to extend RNN to
model the temporal and spatial context for next location prediction. In order to model temporal context, ST-RNN models
multi-check-ins in a time window in each RNN cell. Meanwhile, ST-RNN employs time-speciﬁc and distance-speciﬁc
transition matrices to characterize dynamic time intervals
and geographical distances, respectively. However, there exists some challenges preventing ST-RNN from becoming the
best solution for next POI recommendation.
First of all, ST-RNN may fail to model spatial and temporal relations of neighbor check-ins properly. ST-RNN adopts
time-speciﬁc and distance-speciﬁc transition matrices between cell hidden states within RNN. Due to data sparsity,
ST-RNN cannot learn every possible continuous time intervals and geographical distances but partition them into discrete bins. Secondly, ST-RNN is designed for short-term interests and not well designed for long-term interests. Jannach et al. reported that users’ short-term and longterm interests are both signiﬁcant on achieving the best performance. The short-term interest here means that recommended POIs should depend on recently visited POIs, and
the long-term interest means that recommended POIs should
depend on all historical visited POIs. Thirdly, it is hard to select the proper width of the time window for different applications in ST-RNN since it models multi-elements in a ﬁxed
time period.
To this end, in this paper, we propose a new Spatio-
Temporal Gated Network by enhancing long short term
memory, named STGN, to model users’ sequential visiting
behaviors. Time intervals and distance intervals of neighbor check-ins are modeled by time gate and distance gate,
respectively. Note that there are two time gates and two distance gates in the STGN model. One pair of time gate and
distance gate are designed to exploit time and distance intervals to capture the short-term interest, and the other pair
are introduced to memorize time and distance intervals to
model the long-term interest. Furthermore, enlightened by
Greff et al. , we use the coupled input and forget gates
to reduce the number of parameters, making our model more
efﬁcient. Experimental results on four real-world datasets
show STGN signiﬁcantly improves next POI recommendation performance.
To summarize, our contributions are listed as follows.
• We propose an innovative gate mechanism way to model
spatio-temporal intervals between check-ins under LSTM
architecture to learn user’s visiting behavior for the next
POI recommendation.
• A STGN model is proposed to incorporate carefully designed time gates and distance gates to capture the spatiotemporal interval information between check-ins. As a result, STGN well models user’s short-term and long-term
interests simultaneously.
• Experiments on four large-scale real-world datasets are
conducted to evaluate the performance of our proposed
model. Our experimental results show that our method
outperforms state-of-the-art methods.
Related Work
In this section, we discuss related work from two aspects,
which are POI recommendation and leveraging neural networks for recommendation.
POI Recommendation
Different from traditional recommendations (e.g., movie
recommendation, music recommendation), POI recommendation is characterized by geographic information and no explicit rating information .
Moreover, additional information, such as social inﬂuence,
temporal information, review information, and transition between POIs, has been leveraged for POI recommendation.
Ye et al. integrated the social inﬂuence with a userbased collaborative ﬁltering model and modeled the geographical inﬂuence by a Bayesian model. Yuan et al. 
utilized the temporal preference to enhance the efﬁciency
and effectiveness of the solution. Kurashima et al. 
proposed a topic model, in which a POI is sampled based
on its topics and the distance to historical visited POIs of a
target user. Liu et al. exploited users’ interests and
their evolving sequential preferences with temporal interval
assessment to recommend POI in a speciﬁed time period.
Next POI recommendation, as a natural extension of general POI recommendation, is recently proposed and has attracted great research interest. Research has shown that the
sequential inﬂuence between successive check-ins plays a
crucial role in next POI recommendation since human movement exhibits sequential patterns. A tensor-based model,
named FPMC-LR, was proposed by integrating the ﬁrstorder Markov chain of POI transitions and distance constraints for next POI recommendation .
He et al. further proposed a tensor-based latent model
considering the inﬂuence of user’s latent behavior patterns,
which are determined by the contextual temporal and categorical information. Feng et al. proposed a personalized ranking metric embedding method (PRME) to model
personalized check-in sequences for next POI recommendation. Xie et al. proposed a graph-based embedding learning approach, named GE, which utilized bipartite
graphs to model context factors in a uniﬁed optimization
framework. Chang et al. utilized a check-in context
layer and a text content layer to capture the geographical in-
ﬂuence of POIs from the check-in sequence of a user and the
characteristics of POIs from the text content.
Neural Networks for Recommendation
Neural networks are not only naturally used for feature
learning to model various features of users or items, but
also explored as a core recommendation model to simulate nonlinear, complex interactions between users and items
 . Yang et al. proposed a deep neural architecture named PACE for POI recommendation,
which utilizes the smoothness of semi-supervised learning
to alleviate the sparsity of collaborative ﬁltering. Yang et
al. jointly modeled a social network structure and
users’ trajectory behaviors with a neural network model.
Zhang et al. tried to learn user’s next movement intention and incorporated different contextual factors to improve next POI recommendation. Zhu et al. proposed
a Time-LSTM model and two variants, which equip LSTM
with time gates to model time intervals for next item recommendation.Huang et al. integrated the RNN-based
networks with knowledge base enhanced key-value memory
network (KV-MN) to capture sequential user preference and
attribute-level user preference. Lin et al. proposed a
K-plet recurrent neural network to accommodate multiple
sequences jointly to capture global structure and localized
relationships at the same time.
A recently proposed ST-RNN, which is closely related to
our work, considers spatial and temporal contexts to model
user behavior for next location prediction .
However, our proposed STGN model differs signiﬁcantly
from ST-RNN in two aspects. First, STGN equips the LSTM
model with time and distance gates while ST-RNN adds
spatio-temporal transition matrices to the RNN model. Second, STGN well models time and distance intervals between
neighbor check-ins to extract long-term and short-term interests. However, ST-RNN recommends next POI depending
only on POIs in the nearest time window which may be hard
to distinguish short-term and long-term interests. A more
recent work HST-LSTM combines
spatio-temporal inﬂuences into LSTM for location prediction. However, HST-LSTM is designed for general location recommendation while our proposed model focuses on
next POI recommendation. Moreover, our model is equipped
with new time and distance gates while HST-LSTM introduces spatio-temporal factors into exists gates in LSTM.
Preliminaries
In this section, we ﬁrst give the formal problem deﬁnition
of next POI recommendation, and then brieﬂy introduce
Problem Formulation
Let U = {u1, u2, . . . , uM} be the set of M users and V =
{v1, v2, . . . , vN} be the set of N POIs. For user u, she has a
sequence of historical POI visits up to time ti−1 represented
t2, · · ·, vu
ti−1}, where vu
ti means user u visit
POI v at time ti. The goal of next POI recommendation is
to recommend a list of unvisited POIs for a user to visit next
at time point ti. Speciﬁcally, a higher prediction score of a
user u to an unvisited POI vj indicates a higher probability
that the user u would like to visit vj at time ti. According to
prediction scores, we can recommend top-k POIs to user u.
LSTM , a variant of
RNN, is capable of learning short and long-term dependencies. LSTM has become an effective and scalable model
for sequential prediction problems, and many improvements
have been made to the original LSTM architecture. We use
the basic LSTM model in our approach for the concise and
general purpose, and it is easy to extend to other variants of
LSTM. The basic update equations of LSTM are as follows:
it = σ(Wi[ht−1, xt] + bi),
ft = σ(Wf[ht−1, xt] + bf),
ect = tanh(Wc[ht−1, xt] + bc),
ct = ft ⊙ct−1 + it ⊙ect,
ot = σ(Wo[ht−1, xt] + bo),
ht = ot ⊙tanh(ct),
where it, ft, ot represent the input, forget and output gates
of the t-th object, deciding what information to store, forget and output, respectively. ct is the cell activation vector
representing cell state, which is the key to LSTM. xt and
ht represent the input feature vector and the hidden output
vector, respectively. σ represents a sigmoid layer to map the
values between 0 to 1, where 1 represents “complete keep
this” while 0 represents “completely get rid of this”. Wi,
Wf, Wo and Wc are the weights of gates. bi, bf, bo and bc
are corresponding biases. And ⊙represents for the elementwise (Hadamard) product. The update of cell state ct has two
parts. The former part is the previous cell state ct−1 that is
controlled by forget gate ft, and the latter part is the new
candidate value scaled by how much to add state value.
Our Approach
In this section, we ﬁrst propose a Spatio-Temporal Gated
Network (STGN) by enhancing long-short term memory,
which utilizes time and distance intervals to model user’s
short-term interest and long-term interest simultaneously.
Then, we improve STGN with coupled input and output
gates for efﬁciency.
Spatio-Temporal Gated Network
When using LSTM for next POI recommendation, xt represents user’s last visited POI, which can be exploited to learn
user’s short-term interest. While ct−1 contains the information of user’s historical visited POIs, which reﬂect user’s
long-term interest. However, how much the short-term interest determines where to go next heavily depends on the
time interval and the geographical distance between the last
POI and the next POI. Intuitively, a POI visited long time
ago and long distance away has little inﬂuence on next POI,
Figure 2: STGN has two time gates and two distance gates,
i.e., T1t, T2t, D1t and D2t. T1t and D1t are designed to
model time and distance intervals for short-term interests
while T2t and D2t are to model time and distance intervals
for long-term interest.
and vice versa. In our proposed spatio-temporal gated network model, we use time gate and distance gate to control
the inﬂuence of the last visited POI on next POI recommendation. Furthermore, the time gate and the distance gate can
also help to store time and distance intervals in cell state ct,
which memorizes user’s long-term interest. In this way, we
utilize time and distance intervals to model user’s short-term
interest and long-term interest simultaneously.
As shown in two dotted red rectangles in Figure 2, we add
two time gates and two distance gates to LSTM, denoted as
T1t, T2t, D1t and D2t respectively. T1t and D1t are used
to control the inﬂuence of the latest visited POI on next POI,
and T2t and D2t are used to capture time and distance intervals to model user’s long-term interest. Based on LSTM, we
add equations for time gates and distance gates as follows:
T1t =σ(xtWxt1 + σ(△ttWt1) + bt1),
s.t.Wxt1 ≤0
T2t = σ(xtWxt2 + σ(△ttWt2) + bt2),
D1t =σ(xtWxd1 + σ(△dtWd1) + bd1),
s.t.Wxd1 ≤0
D2t = σ(xtWxd2 + σ(△dtWd2) + bd2).
We then modify Eq. (4)-(6) to:
ˆct = ft ⊙ct−1 + it ⊙T1t ⊙D1t ⊙˜ct,
ct = ft ⊙ct−1 + it ⊙T2t ⊙D2t ⊙˜ct,
ot = σ(Wo[ht−1, xt] + △ttWto + △dtWdo + bo),
ht = ot ⊙tanh(ˆct),
where △tt is the time interval and △dt is the distance interval. Besides input gate it, T1t can be regarded as an input
Figure 3: A variant of STGN using coupled input and forget
information ﬁlter considering time interval, and D1t can be
regarded as another input information ﬁlter considering distance interval. We add a new cell state ˆct to store the result,
then transfer to the hidden state ht and ﬁnally inﬂuences next
recommendation. Along this line, ˆct is ﬁltered by time gate
T1t and distance gate D1t as well as input gate it on current
recommendations.
Cell state ct is used to memory users general interest, i.e.,
long-term interest. We designed a time gate and a distance
gate to control the cell state ct update. T2t ﬁrst memorizes
△tt then transfers to ct, further to ct+1, ct+2, · · · . So T2t
helps store △tt to model user long-term interest. In the similar way, D2t memorizes △dt and transfers to cell state ct to
help model user long-term interest. In this way, ct captures
user long-term interest by memorizing not only the order
of user’s historical visited POIs, but also the time and distance interval information between neighbor POIs. Modeling distance intervals can help capture user’s general spatial
interest, while modeling time intervals helps capture user’s
periodical visiting behavior.
Normally, a more recently visited POI with a shorter distance should have a larger inﬂuence on choosing next POI.
To incorporate this knowledge in the designed gates, we add
constraints Wxt1 ≤0 and Wxd1 ≤0 in Eq. (7) and Eq. (9).
Accordingly, if △tt is smaller, T1t would be larger according to Eq. (7). In the similar way, if △dt is shorter, D1t
would be larger according to Eq. (9). For example, if time
and distance intervals are smaller between xt and next POI,
then xt better indicates the short-term interest, thus its inﬂuence should be increased. If △tt or △dt is larger, xt would
have a smaller inﬂuence on the new cell state ˆc. In this case,
the short-term interest is uncertain, so we should depend
more on the long-term interests. It is why we set two time
gates and two distance gates to distinguish the short-term
and long-term interests update.
Variation of Coupled Input and Forget Gates
Enlightened by , we propose another version of STGN, named STGCN, to reduce the number of parameters and improve efﬁciency. STGCN uses coupled input
and forget gates instead of separately deciding what to forget and what new information to add, as shown in Figure 3.
Speciﬁcally, we remove the forget gate, and modify Eq. (11)
and Eq. (12) to:
ˆct =(1 −it ⊙T1t ⊙D1t) ⊙ct−1
+ it ⊙T1t ⊙D1t ⊙˜ct,
ct = (1 −it) ⊙ct−1 + it ⊙T2t ⊙D2t ⊙˜ct.
Since time gate T1t and distance gate D1t are regarded
as input ﬁlters, we replace the forget gate with (1 −it ⊙
T1t ⊙D1t) in Eq. (15). T2t and D2t are used to store time
intervals and distance intervals respectively, thus we use (1−
it) in Eq. (16).
The way we adapt our model to next POI recommendation is as follows. Firstly we transform Hu to
1, d(l1, l2)), (vu
2, d(l2, l3)), · · · , (vu
n, d(ln, lq))]. Then xt in STGN is equivalent to vu
t , △tt is
equivalent to tu
t , and △dt is equivalent to d(lt+1, lt),
where d(· , · ) is the function computing the distance between two geographical points. Moreover, we make use of
all users’ behavioral histories for learning and recommendation. We leverage the mini-batch learning method, and train
the model on users’ existing histories until convergence. The
model output is a probability distribution on all POIs calculated by ht and vu
t . And then we take a gradient step to
optimize the loss based on the output and one-hot representations of vu
We use Adam, a variant of Stochastic Gradient Descent(SGD), to optimize the parameters in STGN, which
adapts the learning rate for each parameter by performing
smaller updates for frequent parameters and larger updates
for infrequent parameters. We use the projection operator
described in to meet
the constraints Wt1 ≤0 in Eq. (7) and Wd1 ≤0 in Eq. (9).
If we have Wt1 > 0 during the training process, we set
Wt1 = 0. And parameter Wd1 is set in the same way.
The computational complexity of learning LSTM models
per weight and time step with the stochastic gradient descent
(SGD) optimization technique is O(1). Hence, the LSTM algorithm is very efﬁcient, with an excellent update complexity of O(W), where W is the number of weights and can be
calculated as W = nc×nc×4+ni×nc×4+nc×no+nc×3,
where nc is the number of memory cells, ni is the number of
input units, and no is the number of output units. Similarly,
STGN computational complexity is also O(W) and can be
calculated as W = nc×nc×5+ni×nc×8+nc×no+nc×9.
Experiments
In this section, we conduct experiments to evaluate the performance of our proposed model STGN on four real-world
datasets. We ﬁrst brieﬂy depict the datasets, followed by
baseline methods. Finally, we present our experimental results and discussions.
We use four public LBSNs datasets that have user-POI interactions of users and locations of POIs. The statistics of the
Table 1: Statistics of the four datasets
Brightkite
four datasets are listed in Table 1. CA is a Foursquare dataset
from users whose homes are in California, collected from
January 2010 to February 2011 and used in Gao et al. .
SIN is a Singapore dataset crawled from Foursquare used by
 . Gowalla and Brightkite are two widely
used LBSN datasets, which have been used in many related research papers. We eliminate users with fewer than 10
check-ins and POIs visited by fewer than 10 users in the four
datasets. Then, we sort each user’s check-in records according to timestamp order, taking the ﬁrst 70% as the training
set, the remaining 30% as the testing set.
Baseline Methods
We compare our proposed model STGN with eight representative methods for next POI recommendation.
• FPMC-LR : It combines the personalized Markov chains with the user movement constraints
around a localized region. It factorizes the transition tensor matrices of all users and predicts next location by
computing the transition probability.
• PRME-G : It utilizes the Metric Embedding method to avoid drawbacks of the MF. Speciﬁcally, it embeds users and POIs into the same latent space
to capture the user transition patterns.
• GE : It embeds four relational graphs
(POI-POI, POI-Region, POI-Time, POI-Word) into a
shared low dimensional space. The recommendation
score is then calculated by a linear combination of inner
products for these contextual factors.
• RNN : This method leverages the temporal dependency in user’s behavior sequence through a
standard recurrent structure.
• LSTM This is a variant of RNN model, which contains a memory cell and
three multiplicative gates to allow long-term dependency
• GRU : This is a variant of RNN model,
which is equipped with two gates to control the information ﬂow.
• ST-RNN : Based on the standard RNN
model, ST-RNN replaces the single transition matrix in
RNN with time-speciﬁc transition matrices and distancespeciﬁc transition matrices to model spatial and temporal
 
 
• HST-LSTM : It introduces spatiotemporal factors into gate mechanism in LSTM to mitigate data sparsity problem. Since we do not have session information in our application scenario, we use its
ST-LSTM version here.
Evaluation Metrics
To evaluate the performance of our proposed model ST-
LSTM and compare with the seven baselines described
above, we use two standard metrics Acc@K and Mean Average Precision (MAP). These two metrics are popularly used
for evaluating recommendation results, such as . Note that for an instance in testing set, Acc@K is 1 if the visited POI appears
in the set of top-K recommendation POIs, and 0 otherwise.
The overall Acc@K is calculated as the average value of all
testing instances. In this paper, we choose K = {1, 5, 10, 15,
20} to illustrate different results of Acc@K.
Results and Discussions
Method Comparison. The performance of our proposed
model STGN and the eight baselines on four datasets evaluated by Acc@K and MAP is shown in Table 2. The cell size
and the hidden state size are set to 128 in our experiments.
The number of epochs is set to 100, and the batch size is set
to 10 for our proposed model. For the parameters of other
baselines, we follow the best settings in their papers.
From the experimental results, we can see the following observations: RNN performs better than Markov chain
method FPMC-LR and embedding method PRME-G, due
to its capability in modeling sequential data and user interests using RNN cell. Both LSTM and GRU slightly improve
the performance compared with RNN because of their advantages in modeling long-term interests. The result of GE
is not good for missing social and textual information in our
datasets. The performance of the state-of-the-art method ST-
RNN is close to the standard RNN method, which may be
caused by the difﬁculty of manually setting the windows
of time and distance intervals. HST-LSTM performs better than ST-RNN. It proves the effectiveness of the idea of
combining spatial-temporal factors with gates mechanism.
Our proposed STGN and STGCN model all perform signiﬁcantly better than existing state-of-the-art methods evaluated here on the four datasets in all metrics. Speciﬁcally,
STGCN outperforms the Markov chain based methods considerably by a large margin. Moreover, STGCN consistently outperforms ﬁve RNN-based methods: RNN, LSTM,
GRU, ST-RNN, and HST-LSTM. The performance gains
provided by STGCN over these ﬁve counterparts are about
34.8% - 68.6%, 16.3% - 80.0%, 32.9% - 97.3% and 2.5%
- 34.2% in terms of Acc@1 metric on CA, SIN, Gowalla,
and Brightkite respectively. The signiﬁcant improvement indicates that the mechanism to model temporal and spatial
contexts in STGCN can better catch the user’s sequential behaviors and is effective for the task of next POI recommendation. This is because we add time and distance gates to integrate time and distance intervals into the model. Moreover,
STGCN not only reduces the number of parameters but also
marginally improve the performance compared with STGN.
STGCN with D1t=1,D2t=1
STGCN with T1t=1,T2t=1
STGCN with T2t=1,D2t=1
STGCN with T1t=1,D1t=1
(a) Gowalla - Acc@K
STGCN with D1t=1,D2t=1
STGCN with T1t=1,T2t=1
STGCN with T2t=1,D2t=1
STGCN with T1t=1,D1t=1
(b) CA - Acc@K
Figure 4: The performance with different time and distance
gates in STGCN
Effectiveness of Time and Distance Gates. There are
two time gates and two distance gates in our STGCN model.
We ﬁrst investigate the effectiveness of time and distance
gates on modeling time and distance intervals. Speciﬁcally,
we set D1t = 1 and D2t = 1, in Eq. (9) and Eq. (10),
respectively. That is, we close two distance gates and only
consider the time intervals. Similarly, we set T1t = 1 and
T2t = 1, in Eq. (7) and Eq. (8), respectively. That is, we
close two time gates and only consider distance information. From Figure 4, we can see that the time gates and distance gates have similar importances on both datasets (i.e.,
Gowalla and CA). Moreover, they both are critical for improving the recommendation performances.
We also investigate the effectiveness of time and distance
gates on modeling short-term and long-term interests. We set
T2t = 1 and D2t = 1, in Eq. (8) and Eq. (10), which means
we close time and distance gates on long-term interests and
only activate time and distance gates on short-term interest.
Similarly, we set T1t = 1 and D1t = 1, in Eq. (7) and
Eq. (9), which means we close time and distance gates for
short-term interest. As shown in Figure 4, we can observe
that they all perform worse than original STGCN, which
means that time and distance intervals are not only critical to
short-term interests but also important to long-term interests.
Distance intervals may help model user general spatial preference and time intervals may help to model user long-term
periodical behavior.
(a) Gowalla - Acc@K
(b) BrightKite - Acc@K
Figure 5: The performance of cold start on two datasets
Performance of Cold Start. We also evaluate the performance of STGN by comparing with other next POI recommendation competitors for cold-start users. If a user just vis-
Table 2: Evaluation of next POI recommendation in terms of Acc@K and MAP on four datasets
Brightkite
(a) Different Cell Size
(b) Different Batch Size
Figure 6: The performance with different cell sizes and batch
sizes on Gowalla
its a few POIs in the datasets, which means we can hardly
learn user preference on POIs, we think the user is a cold
case. Speciﬁcally, we take users with less than 5 check-ins
as a cold user in our experiments. We conduct the experiments on two datasets (i.e., Gowalla and BrightKite) and use
Acc@K as the measure metric. As shown in Figure 5, we can
observe that STGCN and STGN perform much better than
the other two under cold start scenario, and STGN performs
the best among all methods. The reason is that STGN and
STGCN model long-term interests as well as short-term interests with considering time and distance intervals, which
proves that our method can work out well with sparse data.
Impact of Parameters. In the standard RNN, different
cell sizes and batch sizes may lead to different performances.
We investigate the impact of these two parameters for STGN
and STGCN. We vary cell sizes and batch sizes to observe
the performance and the training time of our proposed two
models. We only show the impact of the two parameters on
Gowalla dataset due to space constraint. As shown in Figure
6, increasing the cell size can improve our model in terms
of the Acc@10 metric, and a proper batch size can help
achieve the best performance. The cell size determines the
model complexity, and the cell with a larger size may ﬁt the
data better. Moreover, a small batch size may lead to local
optimum, and a big one may lead to insufﬁcient updating of
parameters in our two models.
Conclusions
In this paper, a spatio-temporal gated network, named
STGN, was proposed for next POI recommendation by enhancing long short term memory network. In STGN, time
and distance intervals between neighbor check-ins, which
are essential to describe user behaviors, were modeled using newly introduced spatio-temporal gates. Speciﬁcally, we
added a new cell state, and so there are two cell states to
memorize users’ short-term and long-term interests, respectively. we designed a pair of time and distance gates to
control user’s short-term interest update and another pair
of gates to control the long-term interest update. Furthermore, we coupled time and distance gates to reduce number
of parameters and improve STGN efﬁciency. Experimental
results on four large-scale real-world datasets demonstrated
the effectiveness of our model, which performed better than
the state-of-the-art methods. In future work, we would incorporate more context information such as social network and
textual description content into the model to further improve
the next POI recommendation performance.
Acknowledgments
NSFC(61876117,
61772242) and the Suzhou Science and Technology
Development Program(SYG201803).