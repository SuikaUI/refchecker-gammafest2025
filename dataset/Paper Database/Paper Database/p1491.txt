Technological University Dublin
Technological University Dublin
ARROW@TU Dublin
ARROW@TU Dublin
Conference papers
School of Computer Science
2017-07-20
An Analysis of the Application of Simplified Silhouette to the
An Analysis of the Application of Simplified Silhouette to the
Evaluation of k-means Clustering Validity
Evaluation of k-means Clustering Validity
Technological University Dublin, 
Hector-Hugo Franco-Penya
Technological University Dublin, 
John D. Kelleher
Technological University Dublin, 
See next page for additional authors
Follow this and additional works at: 
Part of the Analysis Commons, Artificial Intelligence and Robotics Commons, Other Computer
Sciences Commons, and the Theory and Algorithms Commons
Recommended Citation
Recommended Citation
Franco-Penya, H. et al. An Analysis of the Application of Simplified Silhouette to the Evaluation of
k-means Clustering Validity. 13th International Conference on Machine Learning and Data Mining MLDM
2017, July 15-20, 2017, New York, USA.
This Conference Paper is brought to you for free and open access by the School of Computer Science at
ARROW@TU Dublin. It has been accepted for inclusion in Conference papers by an authorized administrator of
ARROW@TU Dublin. For more information, please contact , ,
 .
This work is licensed under a Creative Commons Attribution-NonCommercial-Share Alike 4.0 International License.
Fei Wang, Hector-Hugo Franco-Penya, John D. Kelleher, John Pugh, and Robert J. Ross
This conference paper is available at ARROW@TU Dublin: 
An Analysis of the Application of Simpliﬁed
Silhouette to the Evaluation of k-means
Clustering Validity
Fei Wang1,3, Hector-Hugo Franco-Penya1, John D. Kelleher1,3, John Pugh2,
and Robert Ross1,3
1 School of Computing, Dublin Institute of Technology, Ireland
2 Nathean Technologies Ltd. Dublin, Ireland
3 ADAPT Research Centre
 
Abstract. Silhouette is one of the most popular and eﬀective internal
measures for the evaluation of clustering validity. Simpliﬁed Silhouette
is a computationally simpliﬁed version of Silhouette. However, to date
Simpliﬁed Silhouette has not been systematically analysed in a speciﬁc
clustering algorithm. This paper analyses the application of Simpliﬁed
Silhouette to the evaluation of k-means clustering validity and compares
it with the k-means Cost Function and the original Silhouette from both
theoretical and empirical perspectives. The theoretical analysis shows
that Simpliﬁed Silhouette has a mathematical relationship with both the
k-means Cost Function and the original Silhouette, while empirically, we
show that it has comparative performances with the original Silhouette,
but is much faster in calculation. Based on our analysis, we conclude
that for a given dataset the k-means Cost Function is still the most
valid and eﬃcient measure in the evaluation of the validity of k-means
clustering with the same k value, but that Simpliﬁed Silhouette is more
suitable than the original Silhouette in the selection of the best result
from k-means clustering with diﬀerent k values.
Keywords: k-means, clustering validity, internal measures, Simpliﬁed
Silhouette, Silhouette, Cost Function
Introduction
As a fundamental method in data mining and machine learning, clustering aims
to partition data into homogeneous groups . Unlike supervised machine
learning methods, clustering does not require external labels as ground truth,
but investigates the intrinsic structure and characteristics of data, and partitions
data into clusters such that the data in the same cluster are more similar to
each other than the data in other clusters. Clustering has been applied in many
This is the pre-print version of the paper. The ﬁnal publication is available at
link.springer.com.
domains, such as image and text analysis, biology and so on , and also noted
as an important part of unsupervised learning in many data mining and machine
learning text books .
Our research focuses on the application of clustering to the domain of Business Intelligence. The eﬀective segmentation of customer data is a vital tool for
commercial users. For this purpose, two speciﬁc characteristics need to be considered in the clustering: (1) there are a large proportion of categorical features in
customer data; and (2) users don’t have much a priori knowledge about clustering. In our previous research , we compared diﬀerent methods for categorical
data clustering, such as 1-of-k coding and k-prototypes. In this paper, we look at
k-means clustering, and aim to ﬁnd the best way to automate the selection of the
best clustering result from a set of k-means clusterings with diﬀerent parameter
conﬁgurations.
k-means is one of the most widely used clustering algorithms due to its
ease of implementation, simplicity, eﬃciency and empirical success . There
are two parameters that need to be set before the start of k-means clustering
- the number of clusters k and the initial centroids. Given a ﬁxed parameter
conﬁguration, k-means will output a ﬁxed clustering result. However, because
diﬀerent parameter conﬁgurations usually lead to diﬀerent clustering results,
a single k-means clustering cannot guarantee the best clustering result. The
common way to implement k-means is to run it multiple times with diﬀerent
parameter conﬁgurations and select the best one from all the clustering results.
The process to ﬁnd the best result is normally based on the evaluation of the
clustering validity, that is, the goodness or quality of the clustering result for a
dataset .
In this paper, we mainly analyse the application of an internal measure for
evaluating the clustering validity - Simpliﬁed Silhouette - and compare it with
other related measures in k-means clustering. We start with a brief introduction
to the background of the evaluation of k-means clustering validity in Sect. 2,
followed by a theoretical analysis in Sect. 3. In Sect. 4, we outline the design for
our empirical analysis, and then in Sect. 5 present and analyse the experimental
results. Finally, in Sect. 6 we draw conclusions and outline future work.
Background
Normally, there are three types of measures that can be used to evaluate clustering validity in empirical studies : internal measures, external measures and
relative measures. Internal measures are based on the intrinsic structure and
characteristics of the dataset. External measures are based on labelled datasets
such as the ground truth, and compare the clustering results with the existing
labels to uncover how good the clustering is. Relative measures are used to compare diﬀerent clustering usually with the same clustering algorithm but diﬀerent
parameter settings. Because clustering is usually used for the situation in which
users do not have any labelled data, internal measures are the most generally
used measures for the evaluation of clustering validity in practice and therefore
our research focus in this paper.
Internal measures are usually some indices designed to show the compactness
and separation of data . The compactness means that the data within the
same cluster should be close to each other, and the separation means that the
data in diﬀerent clusters should be widely spaced. There are numerous diﬀerent
internal measures for the evaluation of clustering validity. Diﬀerent measures
show these two concepts in diﬀerent ways.
First of all, for some clustering algorithms like k-means, the design of the
algorithm aims to minimise a cost function. Intuitively, the cost function can
be considered as an internal measure for evaluating the clustering validity of
this speciﬁc algorithm. The k-means Cost Function is deﬁned as the sum of
all the distances of each point to its cluster centroid. The process of k-means
is designed speciﬁcally to reduce the Cost Function by centroid shifts and reassignments of the data to its closest cluster until the Cost Function converges
to a minimum (the optimum), so the convergence of the Cost Function is a
monotonic process in k-means. Additionally, because the distances of each data
point to its centroid have been calculated during the process of k-means, the
calculation of the k-means Cost Function is only to sum up these distances,
which requires few extra calculations. Therefore, we can consider the k-means
Cost Function as the default internal measure for k-means and the clustering
result with the smallest Cost Function as the best result or global optimum.
However, for the evaluation of the validity of clustering with diﬀerent k values,
using the Cost Function measure is problematic because it tends to reduce as the
k value increases and, consequently, the Cost Function measure has an intrinsic
bias toward selecting the result with the largest k as the best result . Therefore
we have to use other internal measures.
In addition to the kind of internal measures designed speciﬁcally for a clustering algorithm like the k-means Cost Function, there are quite a lot of general
internal measures that can be applied in the evaluation of the validity of a set
of clustering algorithms: the Dunn index adopts the maximum intra-cluster
distance and the minimum inter-cluster distance, the Davies-Bouldin (DB) index evaluates the dispersion of data based on the distances between cluster
centroids, the C-index takes the sum of a set of the smallest distances as the
baseline, and the SD index is deﬁned based on the concepts of the average
scattering for clusters and total separation between clusters.
Silhouette analyses the distances of each data point to its own cluster
and its closest neighbouring cluster (deﬁned as the average distance of a data
point to all the other data points in its own cluster and that to all the data points
in the neighbouring cluster nearest to the data point). Diﬀerent from most other
internal measures, Silhouette is not only used for the evaluation of the validity of
a full clustering, but also can be used for that of a single cluster or even a single
data point to see if it is well clustered. The calculation of Silhouette starts from
each data point, and the Silhouette value of a cluster or a full clustering is just
the average of point Silhouette values for all the data involved. Regarding our
focus on customer segmentation, it is the advantage of Silhouette that it shows
if each customer or customer cluster is well segmented.
Compared with that of the k-means Cost Function, the bias of Silhouette
in k-means clustering toward selecting the result with the largest k as the best
result exists only when the number of clusters is almost as big as the number of
data points. In other situations they can be applied to evaluate the validity of
k-means clustering with diﬀerent k values and select the best result, which can
be seen in the experimental results in Sect. 5.4.
Since it was created, Silhouette has become one of the most popular internal
measures for clustering validity evaluation. In it is compared with a set
of other internal measures and proven to be one of the most eﬀective and generally applicable measures. However, when Silhouette is applied in the evaluation
of k-means clustering validity, many more extra calculations are required, and
the extra calculations increase following a power law corresponding to the size
of the dataset, because the calculation of the Silhouette index is based on the
full pairwise distance matrix over all data. This is a challenging disadvantage of
Silhouette. From this perspective, Silhouette needs to be simpliﬁed for k-means
to improve its eﬃciency.
Simpliﬁed Silhouette was, to our knowledge, ﬁrst introduced by Hruschka in
 , and used as one of the internal measures in his following research. It inherits
most characteristics from Silhouette and therefore can be used in the evaluation
of the validity of not only a full clustering but also a single cluster or a single data
point. On the other hand, the distance of a data point to a cluster in Simpliﬁed
Silhouette is represented with the distance to the cluster centroid instead of the
average distance to all (other) data points in the cluster, just as in the k-means
Cost Function.
However, Simpliﬁed Silhouette has not been systematically analysed or introduced to the evaluation of k-means clustering validity. In this paper, the
application of Simpliﬁed Silhouette to k-means will be analysed and compared
with that of the k-means Cost Function and the original Silhouette from both
theoretical and empirical perspectives. The speciﬁc research targets are to solve
these two questions:
1 Does Simpliﬁed Silhouette or the original Silhouette perform as well as the
k-means Cost Function in the evaluation of k-means clustering validity?
2 Does Simpliﬁed Silhouette have competitive performances to the original Silhouette in the evaluation of k-means clustering validity?
In the next section, we will start with theoretical analysis of the mathematical
relationships between Simpliﬁed Silhouette and the other two internal measures.
Theoretical Analysis
Mathematics Expressions
Let X = {X1, X2, ..., Xn} be a set of n data points. Xi (1 ≤i ≤n) is one of
the data points, which can be represented as [xi,1, xi,2, ..., xi,m], where m is the
number of features. Given the set of data points X, an integer k (2 ≤k ≤n)
and k initial centroids in the domain of X, the k-means algorithm aims to ﬁnd a
clustering of X into k clusters such that it minimises the k-means Cost Function,
which is deﬁned as the sum of the distances from a data point to the centroid of
the cluster it is assigned to as follows:
CF(X, C) =
wi,ldE(Xi, Cl)
where dE(·, ·) is the squared Euclidean distance, which is the most commonly
used distance for clustering , C = {C1, C2, ..., Ck}, which is a set of cluster
centroids after clustering, and wi,l is the indicator function, which equals to 1
when Xi is in Cl and 0 when Xi is not in Cl. As deﬁned, the smaller the cost
function is, the better the corresponding k-means clustering result is, so it can
be considered as the default internal measure for k-means clustering. However,
for the evaluation of the validity of clustering with diﬀerent k values, using the
Cost Function measure is problematic because it tends to reduce as the k value
increases. Therefore, we need other general internal measures like Silhouette.
The calculation of Silhouette doesn’t use any representative of a cluster (such
as the cluster centroids used by the Cost Function), but is based on the full
pairwise distance matrix over all data. For a single data point Xi, its Silhouette
value sil(i) is calculated as:
b(i) −a(i)
max{a(i), b(i)}
where a(i) is the distance of Xi to its own cluster, which is deﬁned as the average
distance of Xi to all the other data points in its own cluster h as4:
wp,hdE(Xi, Xp)
where nh is the number of data points in the cluster h. b(i) is the distance of
Xi to its closest neighbouring cluster, which is deﬁned as the average distance
of Xi to all the data points in its closest neighbouring cluster as:
b(i) = minimum
p=1 wp,ldE(Xi, Xp)
The sil(i) ranges from −1 to 1. When a(i) is much smaller than b(i), which means
the distance of the data point to its own cluster is much smaller than that to
other clusters, the sil(i) is close to 1 to show this data point is well clustered.
In the opposite way, the sil(i) is close to −1 to show it is badly clustered.
4 Here we assume that there are at least two diﬀerent data points in the cluster.
Otherwise, the a(i) is set to be 0, and the sil(i) will be 1.
The Silhouette value of a whole cluster or a full clustering is deﬁned as the
average value of sil(i) across all the data involved, e.g. the Silhouette value for
a full clustering Sil is deﬁned as follows:
Therefore, the Silhouette value for a full clustering Sil also ranges from −1,
which shows a very bad clustering, to 1, which shows a perfect clustering.
Simpliﬁed Silhouette adopts a similar approach as that of the original Silhouette, but simpliﬁes the distance of a data point to a cluster from the average
distance of Xi to all (other) data points in a cluster to the distance to the
centroid of the cluster as follows:
′ = dE(Xi, Ch)
′ = minimum
dE(Xi, Cl);
And the Simpliﬁed Silhouette value for a single data point ss(i) is deﬁned as:
In the same way, the Simpliﬁed Silhouette value for a full clustering SS is deﬁned
The Simpliﬁed Silhouette value also ranges from −1 to 1. −1 shows a very bad
clustering, while 1 shows a perfect clustering.
Theoretical Comparison
In some sense, Simpliﬁed Silhouette can be considered as the medium between
the k-means Cost Function and Silhouette, because it evaluates the distances
of each data point to its own cluster and its closest neighbouring cluster as
Silhouette, and adopts the centroids from the k-means Cost Function as the
representatives of clusters. In this section, we compare these diﬀerent internal
measures from a mathematical perspective.
Firstly, because at the end of k-means clustering the distances of a data point
to its closest neighbouring cluster centroid b(i)
′ is always greater than or equal
to the distance to its own cluster centroid a(i)
′, max{a(i)
′} in (8) can be
simpliﬁed to b(i)
′. The Simpliﬁed Silhouette value for a single data point can
also be simpliﬁed as follows:
ss(i) = 1 −a(i)
It can be easily found that ss(i) is always greater than or equal to 0 after kmeans, as well as SS(i).
For the comparison with the Cost Function in (1), Simpliﬁed Silhouette for
all data points in (9) can also be written as:
′ dE(Xi, Cl))
nb(i)′ dE(Xi, Cl) can be considered as the weighted distance of Xi to the
centroid of its cluster l, and ∑k
nb(i)′ dE(Xi, Cl)) can also be considered as the weighted Cost Function of k-means. The weight
nb(i)′ is the only
diﬀerence from Cost Function as (1). With the weight, the distance of Xi to its
closest neighbouring cluster is taken into account. Given the same Cost Function,
when the weight gets larger, that is, the data points are far from the centroid
of its closest neighbouring cluster, the weighted Cost Function gets smaller and
Simpliﬁed Silhouette gets a larger value that is closer to 1 to present a good cluster. Otherwise, the weighted Cost Function gets larger and Simpliﬁed Silhouette
gets a smaller value that is closer to 0 to present a bad cluster.
For the comparison with Silhouette, we ﬁrstly expand a(i) in (3) by expanding
the squared Euclidean distance as follows:
j=1(xi,j −xp,j)2)
Similarly a(i)
′ in (6) can be expanded as follows:
p=1 wp,h(xi,j −xp,j))2
We look into the mathematical relationship between (12) and (13), and get the
equality as follows:
q=1 wp,hwq,hdE(Xp, Yq)
2nh(nh −1)
It is shown that the a(i) adds a weight
nh−1 that is greater than 1 into a(i)
takes into account another factor - the sum of all the pairwise distances within
its cluster with a weight
2nh(nh−1), therefore is always bigger than a(i)
Similarly, we can re-write b(i) and b(i)
′ as follows:
b(i) = minimum
p=1 wp,l(xi,j −xp,j)2
′ = minimum
p=1 wp,l(xi,j −xp,j))2
where we denote
p=1 wp,l(xi,j−xp,j)2
as DE(Xi, l), the distance from a data
point Xi to a cluster l that it does not belong to based on Silhouette, while
p=1 wp,l(xi,j−xp,j))2
E(Xi, l) based on Simpliﬁed Silhouette. Then
DE(Xi, l) = D
E(Xi, l) +
q=1 wp,lwq,ldE(Xp, Yq)
It can be found easily that the b(i) in Silhouette also takes into account one
more factor than the b(i)
′ in Simpliﬁed Silhouette - the sum of all the pairwise
distances within the corresponding cluster with a weight
Complexity Analysis
Finally, we can analyse the complexity of the computation of these measures.
From , the overall complexity of the computation of Silhouette is estimated
as O(mn2), while that of Simpliﬁed Silhouette is estimated as O(kmn). When k
is much smaller than n, Silhouette is much more computationally expensive than
Simpliﬁed Silhouette. In addition, during the process of k-means clustering, the
distance of each data point to its cluster centroid has already been calculated in
each iteration, which greatly reduces the calculation of both the Cost Function
and Simpliﬁed Silhouette. Therefore, the Cost Function and Simpliﬁed Silhouette
are much more eﬃcient in the evaluation of k-means clustering validity.
Conclusions of Theoretical Analysis
In summary, from the theoretical comparison, we can conclude that Simpliﬁed
Silhouette is an internal measure with features related with both the k-means
Cost Function and the original Silhouette:
1 It considers more than the k-means Cost Function by additionally bringing in
the distance of each data point to its closest neighbouring cluster;
2 It also simpliﬁes Silhouette by ignoring within-cluster pairwise distances.
Therefore, we can consider Simpliﬁed Silhouette as a variant of Silhouette for
k-means clustering. In the experimental analysis, we will compare the time consumed by diﬀerent measures, and most importantly, verify the performance of
Simpliﬁed Silhouette compared with k-means Cost Function and the original Silhouette so that to ﬁnd out if these mathematical diﬀerences lead to performance
diﬀerences.
Experimental Design
Research Targets
The experimental analysis is designed to evaluate the performances of these three
internal measures, the k-means Cost Function, Silhouette and Simpliﬁed Silhouette, in the evaluation of k-means clustering validity and to answer speciﬁcally
the two research questions proposed at the end of Sect. 2.
For the evaluation of the validity of clustering with the same k value, we
take the k-means Cost Function as the default measure, and aim to ﬁnd out if
Silhouette or Simpliﬁed Silhouette can perform as well as the Cost Function. On
the other hand, for the evaluation of the validity of clustering with diﬀerent k
values, we evaluate Silhouette and Simpliﬁed Silhouette to ﬁnd out if Simpliﬁed
Silhouette has comparative performances to the original Silhouette so that it can
be used safely instead of the original Silhouette.
This experiment adopts four real world datasets and four synthetic datasets.
The real world datasets are all famous numeric datasets from the UC Irvine
Machine Learning Repository ( Iris, Glass,
Wine and Yeast. The labels in these datasets are subjectively labelled only for
some speciﬁc purposes, so they cannot reﬂect exactly the intrinsic structure inside the data or the ground-truth k value. Therefore, we ignore the labels of
these four datasets in the experiment. The other four datasets are generated
artiﬁcially for clustering, and hence the labels in them can be used in the evaluation. The ﬁrst two synthetic datasets are the Dim032 and Dim064 datasets from
 with 32 dimensions and 64 dimensions respectively. The other two synthetic
datasets are the S1 and S3 datasets from , which have only two dimensions but
many more instances. The clusters in S1 are separated widely from each other,
while those in S3 are more compact. We select these diﬀerent datasets in order
to evaluate the internal measures in diﬀerent situations. Detailed information
about the datasets is summarised in Table 1. As discussed above, we only know
the desired k values of the four synthetic datasets.
Table 1: Experiment Datasets
#Instances
#Dimensions
Experimental Process
As introduced in Sect. 1, the common way to implement k-means is to run it
multiple times with diﬀerent parameter conﬁgurations and select the best result.
In this paper, for each dataset we run k-means with the k values ranging from
2 to 30, and for each k value, we run it 30 times with the initial centroids randomly selected from the dataset5. As each run of k-means usually takes multiple
iterations to process, we keep records of all the clustering labels and the cluster
centroids of each iteration, and consider the clustering labels of each iteration in
each k-means run as a clustering result. Then we calculate the internal measures
of all these clustering results. In this way, these measures are based on not only
good clustering results after the convergence of the Cost Function, but also the
clustering results during the k-means process that are not very good. Based on
these diﬀerent clustering results, the evaluation of our three measures are more
comprehensive and reasonable.
In the experimental process, there are some detailed features that are worth
mentioning. Firstly, all the data is normalised to z-score before input into kmeans clustering to keep the balance among features with diﬀerent magnitudes.
Secondly, we use a diﬀerent method to deal with empty clusters in the k-means
process. The common way to deal with empty clusters is to re-run the k-means by
re-selecting the initial centroids. In order to generate diﬀerent clustering results
for the evaluation, the way we adopt in this work is to ﬁnd the closest data point
to the centroid of each empty cluster, and assign the closest data point to the
corresponding empty cluster to form a non-empty cluster.
Based on the total inventory of results accumulated, we then make the following four evaluations:
1 An evaluation of the measures in each iteration of each run of k-means;
2 An evaluation of the measures in each run of k-means;
3 An evaluation of the measures in the selection of the best result across all the
30 clustering results with each ﬁxed value of k;
4 An evaluation of the measures in the selection of the overall best result from
the best results selected for all the 29 k values.
Experimental Results
In this section we detail the results of the four evaluations outlined in the last
section, and analyse the performances of the three measures - the k-means Cost
Function (CF), Silhouette (Sil) and Simpliﬁed Silhouette (SS).
Evaluation in Each Iteration
Firstly, we look at the performances of the three internal measures in each iteration. As discussed in Sect. 2, the Cost Function of k-means is deﬁned as
5 In preparing our experiments we tested two diﬀerent initialisation methods for kmeans, a random initialisation and a well-known algorithm k-means++. However,
we found that the initialisation method made no diﬀerence in our results so in this
paper we just report the results using the random initialisation.
the default measure for k-means and it decreases monotonically during the kmeans process. Therefore, the Cost Function value in the next iteration cannot
be larger than that in the previous iteration. However, both Silhouette and Simpliﬁed Silhouette are designed for general clustering, so they may not represent
the validity of k-means exactly. Table 2 shows the number of iterations in which
the k-means Cost Function increases of all the iterations for each dataset, and
that in which Silhouette or Simpliﬁed Silhouette decreases. Note that a smaller
value of the k-means Cost Function indicates a better clustering result, while a
bigger value of Silhouette or Simpliﬁed Silhouette indicates a better clustering
result. The percentages with the parentheses around indicate the proportions of
these kinds of iterations in corresponding total iteration numbers.
Table 2: Evaluation of Iterations
#Iterations
#Iterations with
Increasing CF
#Iterations with
Decreasing Sil
#Iterations with
Decreasing SS
303 (5.33%)
473 (8.32%)
776 (10.28%)
709 (9.39%)
248 (4.44%)
278 (4.97%)
5211 (21.78%)
3888 (16.25%)
119 (3.33%)
93 (2.61%)
70 (2.09%)
21 (0.63%)
5832 (33.80%)
6457 (37.42%)
7585 (27.75%)
8234 (30.13%)
From Table 2, we can see the Cost Function decreases monotonically as expected, but neither Silhouette nor Simpliﬁed Silhouette increases monotonically
(although both of them increase in most cases). Based on the deﬁnition, the clustering result always gets better along iterations of each run of k-means. Therefore
the evaluations of k-means clustering validity with both Silhouette and Simpli-
ﬁed Silhouette are inaccurate in some iterations, so we can see neither Silhouette
nor Simpliﬁed Silhouette performs as well as the Cost Function.
Meanwhile, also from Table 2 we see that there is not much diﬀerence between
the numbers of iterations with decreasing Silhouette and Simpliﬁed Silhouette
values, which indicates these two measures perform similarly in the evaluation
in iterations.
Evaluation in Each Run of k-means
As stated in Sect. 5.1, Silhouette and Simpliﬁed Silhouette may be inaccurate in
the evaluation of clustering validity in individual iterations. Therefore, for Silhouette and Simpliﬁed Silhouette the k-means process may be not a monotonically
converging process, and in the last iteration of k-means where the minimum of
the Cost Function is always found, the Silhouette or Simpliﬁed Silhouette value
may be not the best value in the k-means process. We get the results just as we
expect: for all datasets, there are always clustering with the last Silhouette or
Simpliﬁed Silhouette smaller than the best value (due to the limitation of space,
the details are not included in the paper). Similarly, we can see that neither
Silhouette nor Simpliﬁed Silhouette performs as well as the Cost Function.
Even though it may not result in the best Silhouette or Simpliﬁed Silhouette
value, the last iteration is always taken as the end of a k-means clustering based
on its deﬁnition. Therefore, the result in the last iteration is always taken as the
ﬁnal clustering result of the k-means clustering in further steps of the experiment.
Evaluation in the Selection of the Best Result from Clustering
with Each Fixed Value of k
For each ﬁxed value of k, we compare 30 k-means clustering results and select the
best one among them based on our three internal measures. Table 3 shows the
number of k values with which the same best result is selected from clustering,
based on every pair of two measures or all three measures.
Table 3: Evaluation of the Selection of the Best Result from Clustering with
Each Fixed Value of k
#k Values -
Sil and SS
#k Values -
Sil and CF
#k Values -
#k Values -
All Measures
Silhouette and Simpliﬁed Silhouette can select the same best result for most
k values, but only for a small number of k values, they can select the same
best result as the Cost Function. Similarly, we can see that neither of them
can perform as well as the Cost Function. Although Silhouette performs a little
better than Simpliﬁed Silhouette in this case, there is not much diﬀerence.
Based on these results as well as the results in above sections, we can conclude
that the k-means Cost Function is the only one among these three internal
measures that can accurately evaluate k-means clustering validity. Therefore,
the best clustering result for each k value is selected based on the k-means Cost
Function in further steps of the experiment.
Evaluation in the Selection of the Overall Best Result
The selection of the overall best result from all the best results selected for
each k value is the last step of the experiment. Table 4 shows the k values
corresponding to the overall best results selected based on each internal measure
for each dataset. It is shown
that the k-means Cost Function is problematic
in the evaluation of the validity of k-means clustering with diﬀerent k values,
and tends to select the result with the largest k value as the overall best result,
therefore as we discussed, it is not suitable for this case.
Table 4: Evaluation of the Selection of the Overall Best Result from the Best
Clustering Results Selected for Diﬀerent k Values Based on Diﬀerent Measures
Corresponding k
Corresponding k
Corresponding k
On the other hand, Silhouette and Simpliﬁed Silhouette select the same overall best result for almost all datasets. For three of the four synthetic datasets
that are designed for clustering, both measures can select the results with the
desired k values. For the dataset Dim064, they also select the result with the
same value. It is common to select results with the non-desired k value based on
conditions like this because the initial centroids are randomly selected to generate a variety of clustering results6. From this perspective, we can conclude that
Simpliﬁed Silhouette has competitive performance to Silhouette in the selection
of the overall best result.
Evaluation of Correlations between Internal Measures
We also evaluate the Pearson correlations between Silhouette and Simpliﬁed
Silhouette. For each dataset and each k value, the distinct pairs of these two
measures are extracted from the results. From Fig. 1 and Fig. 2, it is shown that
there is highly positive correlation between Silhouette and Simpliﬁed Silhouette
in an overwhelming majority of situations.
6 If other methods like k-means++ are used for selecting the initial centroids, it is
very likely to get all the desired k values for all the synthetic datasets.
Fig. 1: Correlations between Sil and SS Fig. 2: P-value for Correlation Testing
between Sil and SS
Evaluation of Time Consumed
Finally, we compare the time consumed in the calculation of each internal measure. Figure 3 shows the time consumed (with ms as unit) for the datasets S1,
which is the dataset with the most instances. It is shown that the time consumed
by Silhouette is much more than that by the Cost Function or Simpliﬁed Silhouette, and the diﬀerences can be orders of magnitude in size. Similar results
are found for other datasets. The rough time consumed in calculation may not
reﬂect the genuine eﬃciency of algorithms exactly, but from the commercial perspective, it is meaningful to notice that the implementation of the Cost Function
and Simpliﬁed Silhouette is generally much faster than Silhouette.
Conclusion
In this paper we have analysed the application of Simpliﬁed Silhouette to the
evaluation of k-means clustering validity, and compared it with two other internal
measures: the k-means Cost Function and the original Silhouette from both
theoretical and empirical perspectives.
Theoretically, Simpliﬁed Silhouette has a mathematical relationship with
both the k-means Cost Function and the original Silhouette. It brings in additionally the distance of each data point to its closest neighbouring cluster to
the k-means Cost Function, but simpliﬁes Silhouette by ignoring within-cluster
pairwise distances.
Empirically, we can make the following conclusions:
Fig. 3: Time Consumed - S1
1 Neither Simpliﬁed Silhouette nor the original Silhouette can perform as well
as the k-means Cost Function in the evaluation of the validity of k-means
clustering with the same k value but diﬀerent initial centroids;
2 Simpliﬁed Silhouette has competitive performances to the original Silhouette
in the evaluation of k-means validity and is much faster in the calculation;
Therefore, the most suitable method to automate the selection of the best
k-means result is using the k-means Cost Function ﬁrstly to select the best result
for each k value and then using Simpliﬁed Silhouette to select the overall best
result from the best results for diﬀerent k values.
Due to the limitation of time and resources, Simpliﬁed Silhouette has not been
fully explored in this paper, e.g. the actual industrial datasets are not available.
On the other hand, this is an attempt to evaluate the internal measures for a
speciﬁc clustering algorithm. Speciﬁc methods should be evaluated, selected and
even designed for speciﬁc algorithms or conditions, rather than always a same
set of general methods for all the situations.
Acknowledgement. The authors wish to acknowledge the support of Enterprise Ireland through the Innovation Partnership Programme SmartSeg 2. The
authors also wish to acknowledge the support of the ADAPT Research Centre.
The ADAPT Centre for Digital Content Technology is funded under the SFI
Research Centres Programme (Grant 13/RC/2106) and is co-funded under the
European Regional Development Funds.