Noname manuscript No.
(will be inserted by the editor)
Lipschitz Constrained GANs via Boundedness and
Continuity
Kanglin Liu · Guoping Qiu
Received: date / Accepted: date
Abstract One of the challenges in the study of Generative Adversarial Networks
(GANs) is the difﬁculty of its performance control. Lipschitz constraint is essential in guaranteeing training stability for GANs. Although heuristic methods such as
weight clipping, gradient penalty and spectral normalization have been proposed to
enforce Lipschitz constraint, it is still difﬁcult to achieve a solution that is both practically effective and theoretically provably satisfying a Lipschitz constraint. In this
paper, we introduce the boundedness and continuity (BC) conditions to enforce the
Lipschitz constraint on the discriminator functions of GANs. We prove theoretically
that GANs with discriminators meeting the BC conditions satisfy the Lipschitz constraint. We present a practically very effective implementation of a GAN based on a
convolutional neural network (CNN) by forcing the CNN to satisfy the BC conditions (BC-GAN). We show that as compared to recent techniques including gradient
penalty and spectral normalization, BC-GANs not only have better performances but
also lower computational complexity.
Keywords Generative Adversarial Networks · Lipschitz constraint · Boundedness ·
Continuity
1 Introduction
Generative Adversarial Networks (GANs) is hailed as one of the most signiﬁcant
developments in machine learning research of the past decade. Since its ﬁrst introduction, GANs have been applied to a wide range of problems and numerous papers have
Kanglin Liu1,2,3
E-mail: 
Guoping Qiu1,2,3,4
E-mail: 
1.Shenzhen University, Shenzhen, China
2.Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen, China
3.Shenzhen Institute of Artiﬁcial Intelligence and Robotics for Society, Shenzhen, China
4.University of Nottingham, Nottingham, United Kingdom
 
Kanglin Liu, Guoping Qiu
been published. In a nutshell, GANs are constructed around two functions : the
generator G, which maps a sample z to the data distribution, and the discriminator D,
which is trained to distinguish real samples of a dataset from fake samples produced
by the generator. With the goal of reducing the difference between the distributions
of fake and real samples, a GAN training algorithm trains G and D in tandem.
A major challenge of GANs is that controlling the performance of the discriminator is particularly difﬁcult. Kellback-Leibler (KL) divergence was originally used as
the loss function of the discriminator to determine the difference between the model
and target distributions . However, KL divergence is potentially non-continuous
with respect to the parameters of G, leading to the difﬁculty in training . Specifically, when the support of the model distribution and the support of the target distribution are disjoint, there exists a discriminator that can perfectly distinguish the
model distribution from that of the target. Once such a discriminator is found, zero
gradients would be back propagated to G and the training of G would come to a complete stop before obtaining the optimal results. Such a phenomena is referred to as
the vanishing gradient problem.
The conventional form of Lipschitz constraint is given by: ||f(x1) −f(x2)|| ≤
k · ||x1 −x2||. It is obvious that Lipschitz constraint requires the continuity of the
constrained function and guarantees the boundedness of the gradient norm. Besides,
it has been found that enforcing Lipschitz constraint can provide provable robustness against adversarial examples , improve generalization bounds , enable
Wasserstein distance estimation , and also alleviate the training difﬁculty in GANs.
Thus, a number of works have advocated the Lipschitz constraint. To be speciﬁc,
weight clipping was ﬁrst introduced to enforce the Lipschitz constraint . However,
it has been found that weight clipping may lead to the capacity underuse problem
where training favors a discriminator that uses only a few features . To overcome
the weakness of weight clipping, regularization terms like gradient penalty are added
to the loss function to enforce Lipschitz constraint on D . More recently,
Miyato et al. introduce spectral normalization to control the Lipschitz constraint
of D by normalizing the weight matrix of the layers, which is regarded as an improvement on orthonormal regularization . Using gradient penalty or spectral
normalization can stabilize the training and gain improved performance. However,
it has been found that gradient penalty suffers from the problem of not being able to
regularize the function at the points outside of the support of the current generative
distribution . In addition, spectral normalization has been found to suffer from
the problem of gradient norm attenuation , i.e., a layer with a Lipschitz bound
of 1 can reduce the norm of the gradient during backpropagation, and each step of
backprop gradually attenuates the gradient norm, resulting in a much smaller Jacobian for the network’s function than is theoretically allowed. Also as we will show
in Section 3 and Section 4.3, these new methods have the capacity underuse problem (see Proposition 1 and Figure 1 ). Therefore, despite recent progress, it remains
challenging to achieve practical success as well as provably satisfying a Lipschitz
constraint.
In this paper, we introduce the boundedness and continuity (BC) conditions
to enforce the Lipschitz constraint, and introduce a CNN based implementation of
Lipschitz Constrained GANs via Boundedness and Continuity
GANs with discriminators satisfying the BC conditions. We make the following contributions:
(a) We prove that SN-GANs, one of the latest GAN training algorithms that use
spectral normalization, will prevent the discriminator functions from obtaining the
optimal solution when applying Wasserstein distance as the loss metric even though
the Lipschitz constraint is satisﬁed.
(b) We present BC conditions to enforce the Lipschitz constraint for the GANs’
discriminator functions, and introduce a CNN based implementation of GANs by
enforcing the BC conditions (BC-GANs). We show that the performances of BC-
GANs are competitive to state of the art algorithms such as SN-GAN and WGAN-GP
but having lower computational complexity.
2 Related Work
2.1 Generative Adversarial Networks (GANs)
Generative adversarial networks (GANs) is a special generative model to learn a generator G to capture the data distribution via an adversarial process. Speciﬁcally, a
discriminator D is introduced to distinguish the generated images from the real ones,
while the generator G is updated to confuse the discriminator. The adversarial process
is formulated as a minimax game as:
D V (G, D)
where min and max of G and D are taken over the set of the generator and discriminator functions respectively. V (G, D) is to evaluate the difference in the two
distributions of qx and qg, where qx is the data distribution, and qg is the generated
distribution. The conventional form of V (G, D) is given by Kellback-Leibler (KL)
divergence: Ex∼qx[logD(x)] + Ex′∼qg[log(1 −D(x′))] .
2.2 Methods to Enforce Lipschitz Constraint
Applying KL divergence as the implementation of V (G, D) could lead to the training difﬁculty, e.g., the vanishing gradient problem. Thus, numerous methods have
been introduced to solve this problem by enforcing the Lipschitz constraint, including weight clipping , gradient penalty and spectral normalization .
Weight clipping was introduced by Wasserstein GAN (WGAN) , which used
Wasserstein distance to measure the differences between real and fake distributions
instead of KL divergence.
W(Pr, Pg) =
where W(Pr, Pg) represents the Wasserstein distance, Pr and Pg are the real and
fake distributions, respectively. Weight clipping enforces the Lipschitz constraint by
Kanglin Liu, Guoping Qiu
truncating each element of the weight matrices. Wasserstein distance shows superiority over KL divergence, because it can effectively avoid the vanishing gradient
problem brought by KL divergence. In contrast to weight clipping, gradient penalty
 penalizes the gradient at sample points to enforce Lipschitz constraint:
LD = E[f(G(z))] −E[f(x)]+ αE[(||∇f(x)|| −1)2]
gradient penalty
where LD is the loss objective for the discriminator, and α is a hyperparameter.
Spectral normalization is a weight normalization method, which controls the Lipschitz constraint of the discriminator function by literally constraining the spectral
norm of each layer. The implementation of the spectral normalization can be expressed as:
WSN(W) := W/σ(W)
where W represents the weight matrix in each network layer, σ(W) is the spectral
norm of matrix W, which equals to the largest singular value of the matrix W, and
WSN(W) represents the normalized weight matrix. To a certain extent, spectral normalization have succeeded in facilitating stable training and improving performance.
3 Existing Problems
Although heuristic methods have been proposed to enforce Lipschitz constraint, it
is still difﬁcult to achieve a solution that is both practically effective and theoretically provably satisfying the Lipschitz constraint. To be speciﬁc, weight clipping was
proven to be unsatisfactory in , and it can lead to the capacity underuse problem
where training favors a discriminator that uses only a few features . In addition,
gradient penalty suffers from the obvious problem of not being able to regularize the
function at the points outside of the support of the current generative distribution.
In fact, the generative distribution and its support gradually changes in the course of
the training, and this can destabilize the effect of the regularization itself . Moreover, it has been found that spectral normalization suffers from the gradient norm
attenuation problem . Furthermore, we have found that applying spectral normalization prevents the discriminator functions from obtaining the optimal solutions
when using Wasserstein distance as the loss metric. To provide an explanation to this
problem, we present Proposition 1.
Let Pr and Pg be the distributions of real images and generated images in X, a
compact metric space. The discriminator function f is constructed based on a neural
network of the following form with input x:
f(x, θ) = W L+1aL(W L(aL−1(· · · a1(W 1x)))))
where θ := {W 1, W 2, ..., W L+1} is the learning parameter set, and al is an elementwise non-linear activation function. Spectral normalization is applied on f to guarantee the Lipschitz constraint.
Proposition 1 When using Wasserstein distance as the loss metric of f, the optimal
solution to f is unreachable.
Lipschitz Constrained GANs via Boundedness and Continuity
4 Enforcing Boundedness and Continuity in CNN based GANs
Finding a proper way to enforce the Lipschitz constraint remains an open problem.
Motivated by this, we search for a better way to enforce the Lipschitz constraint.
4.1 BC Conditions
The purpose is to ﬁnd the discriminator from the set of k-Lipschitz continuous functions , which obeys the following condition:
||f(x1) −f(x2)|| ≤k||x1 −x2||
Equation (6) is referred to as the Lipschitz continuity or Lipschitz constraint. If
the discriminator function f satisﬁes following conditions, it is guaranteed to meet
the condition of Equation (6) :
(a) Boundedness: f is a bounded function.
(b) Continuity: f is a continuous function, and the number of points where f is
continuous but not differentiable is ﬁnite. Besides, if f is differentiable at point x, its
derivative is ﬁnite.
Conditions (a) and (b) are referred to as the boundedness and continuity (BC)
conditions. A discriminator satisfying the BC conditions is referred as a Bounded
Discriminator, and a GAN model with BC conditions enforced is referred to as BC-
GAN. Following Theorem 1 and Theorem 2 guarantee that meeting the BC conditions is sufﬁcient to enforce the Lipschitz constraint of Equation (6). (see proofs in
Theorem 1. Let Ψ be the set of all f : X →R, where f is a continuous function. In
addition, the number of points where f is continuous but not differentiable is ﬁnite.
Besides, if f is differentiable at point x, its derivative is ﬁnite. Then, f in Ψ satisﬁes
Lipschitz constraint.
Theorem 2. Let Pr and Pg be the distributions of real images and generated images
in X, a compact metric space. Let Ωbe the set of all f : X →R, where f is a
continuous and bounded function. And, the number of points where f is continuous
but not differentiable is ﬁnite. Besides, if f is differentiable at point x, its derivative
is ﬁnite. The set Ωcan be expressed as:
Ω: {f|||f(x)|| ≤m, if ∂f(x)
exists,||∂f(x)
where m represents the bound. Then, there must exist a k, and we have a computable
k · W(Pr, Pg):
k · W(Pr, Pg) = sup
where W(Pr, Pg) represents the Wasserstein distance between Pr and Pg .
Kanglin Liu, Guoping Qiu
According to Theorem 1 and Theorem 2 , it is obvious that the BC conditions are
sufﬁcient to enforce the Lipschitz constraint. Furthermore, k · W(Pr, Pg) is bounded
and computable, and can be obtained as:
k · W(Pr, Pg) = max
Then, k · W(Pr, Pg) can be applied as a new loss metric to guide the training of
D. Logically, the new objective for D is:
f∈ΩEz∼p(z)[f(G(z))] −Ex∼Pr[f(x)]
Theorem 3 in tells us that,
∇θkW(Pr, Pg)= −Ez∼p(z)[∇θf(G(z))]
where θ is the parameters of G. Equation (11) indicates that using gradient descent to
update the parameters in G is a principled method to train the network of G. Finally,
the new objective for G can be obtained:
−Ez∼p(z)[f(G(z))]
4.2 Implementation of BC Conditions
In this paper, we introduce a simple but efﬁcient implementation of BC conditions.
When applying the BC conditions to D, the training of D can be equivalently regarded as a conditional (constrained) optimization process. Then, Equation (10) can
be updated as:
f∈Ω{Ez∼p(z)[f(G(z))] −Ex∼Pr[f(x)]}
s.t.||f(x)|| ≤m, if ∂f(x)
exists,||∂f(x)
In this paper, the discriminator function f is implemented by a deep neural network, which applies a series of convolutional and non-linear operations. Both convolutional and non-linear functions are continuous, which means that D is a continuous
function. Moreover, the gradients of the output of D with respect to the input are
always ﬁnite. As a result, condition (b) is satisﬁed naturally. To guarantee condition
(a), the Lagrange Multiplier Method can be applied here, then the objective of D can
be written as the following equation:
f {Ez∼p(z)[f(G(z))] −Ex∼Pr[f(x)]}
+ β · max(||[f(x)]|| −m, 0)
where β is the hyperparameter and m represents the bound. The term max(∥f(x)∥−
m, 0) plays the role of forcing D to be a bounded function, while Ez∼p(z) [f(G(z))]−
Ex∼p(x) [f(x)] is used to determine k·W(Pr, Pg). The procedure of training the BC-
GAN is described in Algorithm 1.
Lipschitz Constrained GANs via Boundedness and Continuity
Algorithm 1: BC-GAN
the number of D iteration per G iteration ncritic,
the batch size n, the bound m,
initial critic parameter w0,
initial generator parameters θ0
1: while θ has not converged do
Sample {x(i)}n
Sample {z(i)}n
for t=1,2,...,ncritic do
i=1 f(xi)→Lr
i=1 f(g(zi))→Lg
[Lg −Lr + β · max(∥f(x)∥−m, 0)]→LD
Adam(▽wLD)→w
Adam(∇θ[−1
i=1 f(g(zi))])→θ
11: end while
4.3 Validity
In order to verify the validity of proposed BC conditions, we use synthetic datasets
as those presented in to test discriminator’s performance. Speciﬁcally, discriminators are trained to distinguish the fake distribution from the real one. The toy distributions hold the fake distribution Pg as the real distribution Pr plus unit-variance
Gaussian noise. Theoretically, discriminator with good performance is more likely
to learn the high moments of the data distributions and model the real distribution.
Figure 1 illustrates the value surfaces of the discriminator. It is clearly seen that discriminator enforced by BC conditions have a good performance on discriminating
the real samples from the fake ones, demonstrating the validity of proposed method.
4.4 Comparison with Spectral Normalization and Gradient Penalty
Gradient penalty, spectral normalization as well as our proposed method are inspired
by different motivations to enforce the Lipschitz constraint on D. Therefore, they
differ in the way of implementation and in principle. The ﬁrst difference is the way
of implementation. Gradient penalty and our method operate on the loss function
directly, while spectral normalization constrains the weight matrix instead of the loss
Secondly, they differ in principle. For BC-GAN, k·W(Pr, Pg) is applied to evaluate the difference between the fake and real distributions instead of W(Pr, Pg), which
is used in WGAN-GP and WGAN. Moreover, WGAN-GP and SN-GAN strictly constrain the Lipschitz constant to be 1 or a known constant. While BC-GAN eases the
restriction on the Lipschitz constant, and k is an unknown scalar parameter which
will have no inﬂuence on the training of the network. Therefore, k · W(Pr, Pg) can
be employed as a new loss metric to guide the training of D.
To visualize the differences, we still use the synthetic datasets to test discriminators’ performance. Figure 1 illustrates the value surfaces of the discriminators. It
Kanglin Liu, Guoping Qiu
Fig. 1: Value surface of the discriminators trained to optimality on toy datasets. The
yellow dots are data points, the lines are the value surfaces of the discriminators. Left
column: Spectral Normalization. Middle column: Gradient Penalty. Right column:
The proposed method. The upper, middle and lower rows are trained on 8-Gaussian,
25-Gaussian and the Swiss roll distributions, respectively. The generator is held ﬁxed
at real data plus unit-variance Gaussian noise. It is seen that discriminators trained
with gradient penalty as well as spectral normalization have failed to capture the high
moments of the data distribution.
is obvious that discriminators trained with gradient penalty as well as spectral normalization have pathological value surfaces even when optimization has completed,
and they have failed to capture the high moments of the data distributions and instead
model very simple approximations to the optimal functions. In contrast, BC-GANs
have successfully learned the higher moments of the data distributions, and the discriminator can distinguish the real distribution from the fake one much better.
4.5 Convergence Measure
One advantage of using Wasserstein distance as the metric over KL divergence is the
meaningful loss. The Wasserstein distance W(Pr, Pg) shows the property of convergence . If it stops decreasing, then the training of the network can be terminated.
This property is useful as one does not have to stare at the generated samples to ﬁgure
out the failure modes. To obtain the convergence measure in the proposed BC-GAN,
a corresponding indicator of the training stage is introduced:
||∇xf(x)||2
Lipschitz Constrained GANs via Boundedness and Continuity
To prove that proposed indicator IGD is capable of convergence measure, Theorem 3 is introduced.
Theorem 3. Let Pr and Pg be the distributions of real and generated images, x is the
image located in Pr and Pg, and f is the discriminator function, bounded by the BC
Conditions. IGD in Equation 15 is proportional to W(Pr, Pg).
5 Experiments
5.1 Experiment setup
In order to assess the performance of BC-GAN, image generation experiments are
conducted on CIFAR-10 , STL-10 and CELEBA datasets. Two widelyused GAN architectures, including the standard CNN and ResNet based CNN , are
applied for image generation task. For the architecture details, please see Appendix.
Equations (14) and (12) are used as the loss metric of D and G, respectively. IGD in
Equation (15) acts as the role of measuring convergence. m and β in Equation (14)
are set as 0.5 and 2, respectively. For optimization, the Adam is utilized in all the
experiments with α=0.0002, β1 = 0, β2 = 0.9. D updates 5 times per G update.
To keep it identical to previous GANs, we set the batch size as 64. Inception Score
 and Fr´echet Inception Distance are utilized for quantitative assessment of
generated examples.
Although Inception Score and Fr´echet Inception Distance are widely used as an
evaluation metric for GANs, Barratt suggests that it should be more systematic
and careful when evaluating and comparing generative models. Because inception
score may not correlate well with the image quality strictly. Recently, Catherine 
proposes a new method to evaluate the generative models, called skill rating. Skill
rating evaluates models by carrying out tournaments between the discriminators and
generators. For better evaluation, results assessed by skill rating is also presented.
5.2 Results on Image Generation
Image generation tasks are carried out on the CIFAR-10 and STL-10 datasets. Based
on the ResNet based CNN architecture, we obtain the average inception score of 8.40
and 9.15 for image generation on CIFAR-10 and STL-10, respectively. We compare
our algorithm against multiple benchmark methods. In Table 1, we show the Inception
Score and Fr´echet Inception Distance of different methods with their corresponding
optimal settings on CIFAR-10 and STL-10 datasets. As illustrated in Table 1, BC-
GAN has comparable performances with the state-of-the-art GANs. We also conduct
image generation on CELEBA dataset. Examples of generated images are shown
in Figure 2 and 3.
Skill rating is recently introduced to judge the GAN model by matches between G and D. To determine the outcome of a match between G and D, D judges
two batches: one batch of samples from G, and one batch of real data. Every sample
x that is not judged correctly by D (e.g. D(x) >0.5 for the generated data or D(x)
Kanglin Liu, Guoping Qiu
-Standard CNN-
LR-GAN 
Orthonormal 
Table 1: IS and FID of unsupervised image generation on CIFAR-10 and STL-10. IS
is the Inception Score, and FID represents Fr´echet Inception Distance. For IS, higher
is better, while lower is better for FID.
(a) SN-GAN
(b) WGAN-GP
(c) BC-GAN
Fig. 2: Image generation on CIFAR-10 dataset using (a) SN-GAN, (b) WGAN-GP
and (c) BC-GAN.
(a) SN-GAN
(b) WGAN-GP
(c) BC-GAN
Fig. 3: Image generation on CELEBA dataset using (a) SN-GAN, (b) WGAN-GP
and (c) BC-GAN.
Lipschitz Constrained GANs via Boundedness and Continuity
Fig. 4: Matches between D and G. Wasserstein distance is utilized to indicate the
results instead of the win rate. With larger value of the Wassserstein distance, D is
more likely to distinguish the real images from the fake ones. Lower value of the
Wasserstein distance indicates that G is more likely to fool D
<0.5 for the real data) counts as a win for G and is used to compute its win rate. Win
rate tests the performance between D and G dynamically in the training process and
judges whether D or G dominates, while the other stops updating. If D dominates
and G stops updating, win rate for G decreases dramatically. We make some modi-
ﬁcations, because we use Wasserstein distance to determine the difference between
fake and real data instead of probability. As a result, we show the loss of D instead of
the win rate in Figure 4. When D in the latter iteration is used to distinguish the generated images in the early iteration from real images, it outputs a large loss, meaning
that D can easily distinguish the generated images (fake images) from real images.
And the images generated in the latter iteration can also easily fool D in the early
iteration. Therefore, there is a healthy training, and the performance of D and G is
continuously improved in the training process.
When applying KL divergence as the loss metric of D, the training of GANs
suffers from the vaninshing gradient problem, i.e., zero gradient would back propagate to G, and the training would completely stop. As a comparsion, Figure 4 shows
a healthy training during the entire iterations, further indicating the effectiveness of
6 Analysis
6.1 Bound m
The parameter m in Equation (14) represents the bound of D, and it actually controls the gradient ∂LD/∂x, where LD is the loss of D, x is the image and ∂LD/∂x
is the gradient backpropagated from D to G, which indeed affects the training of G,
and further inﬂuences the model performance. Explanation is as followed. The discriminator f is a bounded function. Given enough iterations, fx∼Pr(x) would always
Kanglin Liu, Guoping Qiu
converge to m and fx∼Pg(x) would converge to −m. And considering that f satisﬁes
k-Lipschitz constraint, the following condition is satisﬁed:
||fxr∼Pr(xr) −fxg∼Pg (xg)|| ≈2m ≤k||xr −xg||
||xr −xg|| ≤k
k determines the upper bound of the gradient backpropagated from D to G, and
is directly proportional to D. Increasing m enhances the upper bound of the gradients ∂LD/∂x. This is veriﬁed by the experiment shown in Figure 5 (a). Moreover, the
gradients are used to guide the training of the generator, and naturally affect the performance of the model. Increasing m from 0.5 to 2 leads to decreased performance
(Inception score drops from 8.40 to 7.56). Therefore, properly controlling the gradient is important for improving the performance of GAN models. And the bound
m provides such a mechanism for controlling the gradient. m is recommended to be
taken as 0.5 for image generation task on CIFAR-10. One possible explanation why
a smaller m (hence smaller gradients back-propagated) in the training leads to better
performances is that the error surfaces are highly nonlinear, the backpropagation is
a gradient descent and greedy algorithm, small gradients may help the optimization
lead to a deeper local minimum or indeed the global minimum of the error surface.
Fig. 5: (a) variation of the gradient ∂LD/∂x with iterations in BC-GAN. Larger m
leads to higher gradients. (b) variation of the gradient with iterations in WGAN-
GP. (c) comparison of the gradient variation of SN-GAN and BC-GAN, where SN
represents SN-GAN, and BC is BC-GAN.
We also monitor the variation of the gradient on WGAN-GP and SN-GAN. It’s
found that the behaviour of the gadient variation varys on different models. The gradient penalty term in WGAN-GP forces the gradient of the output of D with respect
to the input to be a ﬁxed number. Therefore, as shown in Figure 5 (b), the gradient is
around 1 in the whole training process. For SN-GAN and our BC-GAN in Figure 5
(c), the variation of the gradient is similar. With training process going on, the gradient tends to increase until convergence is reached. The difference is that the amplitude of the gradient in SN-GAN is larger than that in BC-GAN. As mentioned above,
the amplitude of the gradient indeed affects the training of the generator. However,
SN-GAN provides no mechanism for controlling the gradient. While the bound m in
BC-GAN acts as the role of controlling the gradient. Thus, at least in this perspective,
BC-GAN has a better performance control over SN-GAN.
Lipschitz Constrained GANs via Boundedness and Continuity
6.2 Meaningful Training Stage Indicator IGD
We introduce a new indicator IGD for monitoring the training stage. Figure 6 (a)
shows the correlation of−IGD with inception score during the training process. Because IGD decreases with the iteration, we use −IGD instead. As we can see, −IGD
has a positive correlation with the inception score. As it is easier to visualize the
correlation between IGD and image quality in higher resultion images, we perform
image generation task on CELEBA dataset and show the variation of IGD with
iterations in Figure 6 (b) . It’s clearly seen that IGD correlates well with image quality
during the training process.
Fig. 6: (a) correlation of -IGD with inception score on CIFAR10. (b) variation of IGD
with iteration for the training on CELEBA database. IGD correlates well with the
image quality, indicating that IGD can be regarded as the indicator of the training
6.3 Training Time
It is worth noting that BC-GAN is computationally efﬁcient. We list the computational time for 100 generator updates in Figure 7. WGAN-GP requires more compu-
Fig. 7: Computation time for 100 generator updates. GP for WGAN-GP and SN
for SN-GAN. We use Standard CNN as the architecture. Tests are based on Nvidia
Kanglin Liu, Guoping Qiu
tational time because it needs to calculate the gradient of the gradient norm ∥▽xD∥2,
which needs one whole round of forward and backward propagation. And spectral
normalization needs to calculate the largest singular value of the matrices in each
layer. What is worse, for gradient penalty and spectral normalization, the extra computational costs increase with the increase of layers. As for BC-GAN, there is no
matrix operation or gradient calculation in the backpropagation. As a result, it has
lower computational cost.
7 Concluding Remarks
In this paper, we have introduced a new generative adversarial network training technique called BC-GAN which utilizes bounded discriminator to enforce Lipschitz constraint. In addition to provide theoretical background, we have also presented practical implementation procedures for training BC-GAN. Experiments on synthetical
as well as real data show that the new BC-GAN performs better and has lower computational complexity than recent techniques such as spectral normalization GAN
(SN-GAN) and Wasserstein GAN with gradient penalty (WGAN-GP). We have also
introduced a new training convergence measure which correlates directly with the image quality of the generator output and can be conveniently used to monitor training
progress and to decide when training is completed.
Conﬂict of Interest
The authors declare that they have no conﬂict of interest. We declare that we do not
have any commercial or associative interest that represents a conﬂict of interest in
connection with the work submitted