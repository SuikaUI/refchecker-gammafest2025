Sandia National Laboratories is a multi-program laboratory managed and operated by Sandia Corporation,!
wholly owned subsidiary of Lockheed Martin Corporation, for the U.S. Department of Energyʼs!
National Nuclear Security Administration under contract DE-AC04-94AL85000.!
Introduction to Optimization
Cynthia Phillips
Sandia National Laboratories
 
March 15, 2011
SAND2011-1736C
(Combinatorial) Optimization
Find the best solution out of a (finite) set of feasible solutions.
Begins with an English description
Solution: What decisions can you make? What decisions are implied
by the actual decisions?
Feasible: What constraints must a solution satisfy?
Best: How do we compare two solutions? Is there a score?
Formal Modeling
• Variables
–  Decision variables
–  Helper variables
• Objective Function: How good is a solution?
–  Multiple objectives
• Constraints
–  Requirements for feasibility
–  Can include goals
• Input parameters
–  Data, for evaluating a solution, determining feasibility
• Can take considerable effort
• Tradeoff: model fidelity vs tractability
• Solution difficulty hierarchy
–  Black box
–  Has derivatives
–  Nonlinear constraints and/or objective
–  Convexity
–  Linear constraints and objective
• Can have integer variables (MILP)
• All continuous variables (LP)
–  Specific tractable problems: network flow, matching, matroids
• As structure becomes more restricted
–  Closer to optimal
• Even within the same “class” formulation matters
“Solving” an Optimization Problem
Solution strategy and measure of “success” depend on
• How fast the computation must run
–  Platform
• Development time
• Special structure of data
• Required degree of optimality
–  feasible? better? (near) optimal?
–  How important is each run?
–  Irrevocable? Recourse?
–  How good is the data?
–  How good is the model?
Confidence in Solutions
• Proof of (near) optimality
–  Mathematical
–  Computational
• Benchmarks
–  Verification: Am I solving the problem right?
–  Validation: Am I solving the right problem?
–  What is ground truth?
• Simulation
• Experiments
• Do not optimize past the confidence in the model and data
Multiple Solutions
• Exploring the space of near optimal solutions
–  When objective pressure is heuristic or stochastic
• Evolution
–  Unexpressed goals
• Not easily express mathematically
• Maybe don’t know yet
• Diversity
• Robust/stable point
Computation for insight
Options When a Problem is Hard
For intelligent search (almost all solvers have in some form):
• Search harder
–  Parallelization
• Search smarter
–  Understand/recognize/use (sub)-structure
–  Customize the solver
• Lower expectations
–  Approximations
Example 1: Sequence Alignment (Naor, Brutlag)
• Edit distance score
–  Match score (wa), positive
–  mismatch score (wab), negative (depends on similarity)
–  Gap score, negative
• Evolutionary justification, but not “correct”
-- A C C T G C
G A -- C A G --
g wA g wC wTA wG g
Graph Representation
• Node for each pair (i,j): ith element first sequence, jth from
• Each node has 3 outgoing edges
–  Diagonal for a (mis)match
–  Horizontal/vertical for a gap insertion
Graph Representation
• An alignment is now a path from s to t in a 2D grid
• Goal: maximize path in a directed acyclic graph (tractable)
• Exponential number of s-t paths, though not all are high-score
Compute Efficiently
• Dynamic Programming
• D(i,j) is score of best alignment through i elements of first string
and j elements of second.
• Compute each element when ancestors done
• Can compute near optimal by doing the same in reverse t to s.
D(0,0) = 0
D(i, j) = max D(i "1, j) + g, D i "1, j "1
) + wij, D i, j "1
Compact Representation of near-optimal paths
• Include only edges on at least 1 path with score within Δ of optimal
• Δ>0 necessary to capture biology in general
Example: 2 Leucine zippers:
Compact Representation
• Shows regions conserved in all near-optimal alignments.
• Example: heavy and light chain of human immunoglobulin (23%
match, but similar structure when folded): Δ=2
Other Nice Analytical Features
• Enumerate paths in score order (with weight transformation)
• Count number of near-optimal alignments
• Set of canonical paths
–  Polynomial number (mn, usually much less) for length-n and
length-m strings
–  Covers the compact representation
Graph Algorithms
All these graph algorithms have efficient (polynomial-time) solutions
• Shortest paths
• Minimum cut/Maximum flow
• Minimum-weight spanning tree
• Random spanning tree
• (Strongly) connected components
• Biconnected components
• Planarity testing
• Matching
• Euler Circuit
(wikipedia)
(wikipedia)
Example 2: Protein-Peptide Docking (Hart,Roe)
Motivation
Protein-protein interactions are essential to virtually all cellular
–  Proteins are macro-molecules composed of a linear chain of
amino acid residues
–  Proteins folds into well-defined 3D structures that determine
their role in cellular processes
Protein-protein interactions provide insight into protein function
Phage-Display
Phage-display libraries: an experimental technique used to probe
protein-protein binding interactions
–  Libraries are typically of size 4-12 residues in length
–  Libraries generate a consensus binding sequence
• Describe potential binding
• Find the sequence specificities
of these binding interactions
Impact: With binding sequences
can search the genome for
binding partners
Computational Phage Display
Idea: study protein-protein interactions through protein-peptide
Many protein-protein interactions are
mediated by modular domains
–  PDZ, SH3, SH2, WW, PTB, FHA
These domains often bind to a linear
stretch of the binding partner
–  Provide the same type of information as
experimental methods
–  Minimize experimental costs by designing
reduced “focused” phage-display libraries
Assumptions
1.  Side-chain structures can be well-captured by rotamer libraries
Rotamer libraries taken from trusted data sources (e.g. PDB)
Discretize the structure prediction
2. The peptide backbone is well-constrained
We assume that it’s fixed
If there is flexibility, then we could consider a (small) set of
alternative backbone conformations
Peptide Structure Prediction
Goal: structure prediction for a given peptide
Variables: rotamer choices:
Peptide structures are evaluated with an empirical energy model:
–  Amber scoring function
–  Generalized Born continuum solvation calculation
• Energy parameters:
–  Eir = energy from having rotamer r in sidechain i
–  Airjs = interaction energy from rotamer r in sidechain i and
rotamter j in sidechain s
if rotamer is assigned to sidechain
Mixed Integer programming (IP)
Subject to:
• Can also have inequalities in either direction (slack variables):
• Integer variables represent decisions (1 = yes, 0 = no)
• Surprisingly expressive
• Many good commercial and free IP solvers
Tx ! bi " ai
T x + si = bi , si # 0
x = (xI,xC)
xI # Z n (integer values)
n (rational values)
Naturally an Integer Quadratic Program (IQP)
Note: many of the energies are negative, so this IQP is not convex
Note: this is a quadratic semi-assignment problem
An Integer Programming Formulation
Note: this model can be refined to exploit data sparsity
Note: similar models have been derived by several other authors…
Airjswirjs
=!ir " i,r,j
=!js " i,j,s
Finding Consensus Sequences
–  Empirical energies provide only a rough estimate of rotamerrotamer or rotamer-protein interactions
–  The discretization imposed by a rotamer library can create
artificial infeasible interactions
Enumerate solutions:
• Within a certain percentage of the optimal objective value, or
• Better than some fixed cutoff value, or
• Among the n best solutions (ties broken arbitrarily)
Compute consensus matrix of amino acid frequency at each position
Using Consensus Information
Limit the scope of phage-display experiments
Only include amino acids at sites where they appear in near
optimal solutions
Identify peptide docking candidates
Use a consensus matrix to score peptide sequences with an
expected frequency
Can be use to scan the genome for binding partners
A similar approach has been taken using Boltzman energies
to predict binding affinities
We expect that consensus information will prove more stable
and predictive
Peptide Design
Same basic formulation
• The rotamer library at each site can include rotamers for all amino
• Optimizer implicitly selects an amino acid when selecting a rotamer
• ILPs for peptide design problems are much more difficult
–  Forrester and Greenberg describe better MILP models
• Teaser for Friday: Create a custom solver based on ILP search
Some Thoughts at This Point
The “answer” provided by an optimization solver is not
simply the optimal solution!
Analysis of optimization results
“The purpose of computing is insight, not numbers.”
R. W. Hamming
Is this solution relevant for a practical application?
–  What is the fidelity of the computational model near this point?
–  How sensitive is the model to perturbations?
–  Do my input data accurately reflect real-world scenarios?
Why is this the optimal solution?
–  Is this a global optimum?
–  How distinct is the global solution?
–  Why is this solution different?
–  How do other solutions compare with respect to other design
–  What is the global structure of the objective and constraints?
Challenges
Can we couple optimization with informatics strategies to provide
insight into applications?
–  How should we archive data generated during optimization?
• branching decisions, local minima found, etc.
–  What type of data analysis or visualization strategies can be
used to interrogate these data sets?
How do we tailor optimizers to facilitate post-solution analysis?
–  Is this more than simply printing more optimization data?
–  How do we manage expensive data analysis computations?
Can we objectively critique this type of optimization research?
–  We need more than ‘horse race’ comparisons
–  How do we quantify ‘insight’?
Decisions Given Uncertain Future
• Sometimes can express uncertainty with variable ranges or
distributions
• Scenarios
–  Sample of possible futures
–  General technique when uncertainty is complex
• Simulation-based
• Truly stochastic
–  Weather
–  Congressional budgets at presidential discretization
–  Can improve answer as sampling improves
The Sensor Placement Problem
Issue: Contamination released in a
municipal water network
Goal: develop early warning system
–  Protect human populations
–  Limit network remediation
Place sensors on
–  Utility-owned infrastructure
–  Schools
–  hospitals
•  Sensors are expensive
–  Cost of sensors
–  Cost of installation
Contaminant Transport Modeling
Water movement (direction, velocity in each pipe) determined by
• Demand (consumption)
• Sources/tanks
Current (most trusted) simulator
• EPANET code computes hydraulic equations to determine flows
• Discrete-event simulation for contaminant movement
Sensor Placement Modeling
• Data uncertainty
–  Aleatory uncertainty (inherent, uncontrollable)
• Demand (drives water movement)
• Population distribution
–  Epistemic (lack of knowledge)
• Damage(costs, morbidity statistics)
• Simulator fidelity
• sensor performance
• attack distribution
–  Nature of contamination
• When? Where? What? How much?
Modeling Assumptions
• Sensors are perfect
• Sensors raise a general alarm
–  Can model a response delay
• Fixed set of demand patterns for “typical” day
–  Seasonal variations
–  Special events
–  Weekday/weekend
Modeling Events
• Given: Set of events = (location, time) pairs
• Simulate the evolution of a contaminant plume
• For each event determine
–  Where/when event can be observed
–  Amount of damage prior to that observation
• Measures of damage/impact:
–  Population exposed
–  # deaths
–  Volume of contaminant release
–  Total pipe length contaminated
–  Time to detection
–  # failed detections
Witnessing an Event
Simulator gives ordered list of nodes where a sensor
could witness contamination
Witnesses:
This example has two (green) sensors.
Perfect sensor model: first sensor in list
detects the event.
Evaluating a Sensor Placement
• Impact in red
= dummy node (represents failure to detect)
Evaluating a Sensor Placement
• Impact in red
= dummy node (represents failure to detect)
Choose sensors 2 and 3 (black)
Mixed Integer programming (IP)
Subject to:
• Can also have inequalities in either direction (slack variables):
• Integer variables represent decisions (1 = yes, 0 = no)
Tx ! bi " ai
T x + si = bi , si # 0
x = (xI,xC)
xI # Z n (integer values)
n (rational values)
One Sensor Placement IP for Water Networks
Variables:
Extreme points will have integer values for xij if the yi are integral.
Each event has a dummy location to mark failure to detect
yi = 1 if we place a sensor at location i " L,
0 Otherwise
xij = 1 if location i raises the alarm (witnesses) event j
0 Otherwise
Objective function
Compromise across all “likely” event scenarios to minimize expected damage.
wij " the total damage from event j if detected at location i # L j
" j # the weight of event j = (i, t)
xij "1 if location i raises alarm (witnesses) event j, 0 otherwise.
Sensor Placement Mixed Integer Program
%j # A (every event witnessed)
xij & yi %j # A,i # L j (need sensor to witness)
& p (sensor count limit)
0 & xij &1
Sensor Placement = p-median
p-median problem:
–  n possible facility locations
–  m customers
–  dij = distance from customer j to location i
• Pick p locations and assign each customer to an open location to
minimize the total distance.
Sensor placement as a p-median problem:
• Sensors = Facilities
• Network locations = potential facility locations
• Events = Customers to be “served” (witnessed)
• “Distance” from an event j to a node i = impact if a sensor at node i
witnesses event j.
Formulation is really important in practice
In Unconstrained facility location (pick facilities to build and serve
customers)
Part of formulation 1 is
Formulation 2 is the same except we sum these constraints over i:
IPs are equivalent at optimality
But, (from Linderoth), for 40 customers, 40 facilities, random costs
• First formulation solves in 2 seconds
• Second formulation solves in 53,121 seconds (14.75 hours)
• Adding redundant constraints (even a lot) can be very helpful
computationally
yij " xi #i, j
Model/Simulator Interaction
• Model requires only a list of witnesses and impacts for each event
• Model is stable as simulator improves
• EPANET has some known issues
–  Perfect mixing assumption
–  Numerical issues/scaling
• Same basic model works in other settings
–  Airborne contaminants
–  Blog watching
The p-median Problem
• Open p facilities and assign each customer to an open facility to
minimize the total customer->facility distance.
• NP-complete
• Well Studied
–  Operations Research heuristics
–  Approximation algorithms for metric p-median
• Water problem not metric
–  Doesn’t satisfy triangle inequality
• For bipartite graphs: weight of edge at most weight of path
between endpoints
a1 inject here
a2 inject here
Imperfect Sensors
• Sensor a location i detects with fixed probability pi
–  Assume independence (well spaced geographically)
• In practice, base on water quality zones
• False positives important
–  For this formulation handle by tuning (offline)
• Witness an event if all sensors that see it first fail, and you succeed
Raw success probability pi
Witness probability if
All 4 locations have sensors
Imperfect Sensors formulation (non-linear)
• xai = probability location i witnesses event a
• si = 1 if put sensor on location i
• dai = impact if location i witnesses event a
• pi = success probability for a sensor at location i
One-Imperfect Witness Approximation
• Sensor a location i detects with fixed probability pi
• Only consider the best sensor for each event
–  No “back up”
• Adjusted impact: dʹ′ai → pidai + (1 - pi)Da,
where Da = dummy impact for event a
Raw success probability pi
One-imperfect-witness impact dʹ′
Methods we considered for solving impSP
• Ignore imperfection
• Exact linear integer program based on zones
• Nonlinear solver (fractional)
• Local search with imperfect-sensor objective
• Random Sampling
• One-imperfect witness
11,575 nodes
9705 events
40 sensors
Robust Scenario Coverage
• Robust (tail) measures typically harder than mean
• New method (for some cases) to find TCE using iterated mean
Value at Risk
95th Percentile
Conditional
Expectation
Multiple Objectives - Pareto Front
• Example: sensor network
–  # exposed/sickened/killed, mass released, pipe-feet
contaminated, robust measures
• Represent each solution with a vector of objectives
• A solution dominates another if it’s as least as good on all objectives:
• A solution is Pareto optimal if no other solution dominates it
• Exploring Pareto front avoids value judgments
• Open research: Present decision maker with “small” set with
–  Objective diversity
–  Structural diversity
Multiple Objectives – Pareto Front
• Could consider using weights on multiple objectives:
αw1 + (1-α)w2
• Can be difficult to solve, and doesn’t always expose pareto-optimal
solutions (convex hull)
• Goal constraints: bound one objective and optimize the other
Multiobjective Example: Sensor Placement
Mean/CVaR (≈TCE) trade-off for Network B (3500 nodes)
Expected Impact
Battle of the Water Sensor Networks
• Not a great example of experimentation but…
Partnership: Optimizers and Domain Experts
• Optimizers
–  Model for performance
–  Have a “bag of tricks”
–  Generally know software availability or can roll own quickly
• Domain Experts
–  Model to solve a real problem
–  Want insight/understanding
–  Work with optimizers to ensure critical constraints are kept