HAL Id: inria-00544230
 
Submitted on 7 Dec 2010
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of scientific research documents, whether they are published or not.
The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
Performance measurement in blind audio source
separation
Emmanuel Vincent, Rémi Gribonval, Cédric Févotte
To cite this version:
Emmanuel Vincent, Rémi Gribonval, Cédric Févotte. Performance measurement in blind audio source
separation. IEEE Transactions on Audio, Speech and Language Processing, 2006, 14 (4), pp.1462–
1469. ￿inria-00544230￿
Performance Measurement in
Blind Audio Source Separation
Emmanuel Vincent⋆, R´emi Gribonval and C´edric F´evotte
Abstract— In this article, we discuss the evaluation of Blind
Audio Source Separation (BASS) algorithms. Depending on the
exact application, different distortions can be allowed between an
estimated source and the wanted true source. We consider four
different sets of such allowed distortions, from time-invariant
gains to time-varying ﬁlters. In each case we decompose the
estimated source into a true source part plus error terms
corresponding to interferences, additive noise and algorithmic
artifacts. Then we derive a global performance measure using
an energy ratio, plus a separate performance measure for each
error term. These measures are computed and discussed on the
results of several BASS problems with various difﬁculty levels.
Index Terms— Audio source separation, performance, quality,
evaluation, measure.
I. INTRODUCTION
LIND Audio Source Separation (BASS) has been a topic
of intense work during the last years. Several successful
models have emerged, such as Independent Component Analysis (ICA) , Sparse Decompositions (SD) and Computational Auditory Scene Analysis (CASA) . However, it
is still hard to evaluate an algorithm or to compare several
algorithms because of the lack of appropriate performance
measures and common test sounds, even in the very simple
case of linear instantaneous mixtures. In this article we design
new numerical performance criteria that can help evaluate and
compare algorithms when applied on usual BASS problems.
Before we present these, let us ﬁrst describe the problems
considered and discuss the existing performance measures and
their drawbacks.
A. BASS general notations
The BASS problem arises when one or several microphones
record a sound that is the mixture of sounds coming from
several sources. For simplicity, we consider here only linear
time-invariant mixing systems. If we denote by sj(t) the signal
emitted by the j-th source (1 ≤j ≤n), xi(t) the signal
recorded by the i-th microphone (1 ≤i ≤m) and aij(τ)
the (causal) source-to-microphone ﬁlters, we have xi(t) =
τ=0 aij(τ)sj(t −τ) + ni(t), where ni(t) is some
Submitted to IEEE Transactions on Speech and Audio Processing on June
9th 2004. Revised on February 1st 2005. Accepted on May 3rd 2005.
Emmanuel Vincent is with Queen Mary, University of London, Electronic Engineering Department, Mile End Road, London E1 4NS (United
Kingdom) (Phone: +44 20 7882 5528, Fax: +44 20 7882 7997, Email:
 ). R´emi Gribonval is with IRISA, Campus
de Beaulieu, F-35042 Rennes Cedex (France) (Phone: +33 2 9984 2506,
Fax: +33 2 9984 7171, Email: ). C´edric F´evotte is
with Cambridge University Engineering Department, Trumpington Street,
Cambridge CB2 1PZ (United Kingdom) (Phone: +44 12 2376 5582, Fax:
+44 12 2333 2662, Email: )
additive sensor noise. This m × n mixture is expressed more
conveniently using the matrix of ﬁlters formalism as
x = A ⋆s + n.
where ⋆denotes convolution. In the following, variables
without time index will denote batch sequences, e.g. x =
[x(0), . . . , x(T −1)]. Bold letters will be used for multichannel
variables, such as the vector of observations x, the vector
of sources s, or the mixing system A, and plain letters for
monochannel variables, such as the j-th source sj.
B. BASS applications and difﬁculty levels
BASS covers many applications , and the criteria used
to assess the performance of an algorithm depend on the
application. Sometimes the goal is to extract source signals
that are listened to, straight after separation or after some
post-processing audio treatment. Sometimes, it is to retrieve
source features and/or mixing parameters to describe complex
audio scenes in a way related to human hearing. In this
paper, we focus on the most common task addressed by BASS
algorithms: Source Extraction.
Source Extraction consists in extracting from a mixture
one or several mono source signals sj. Examples include
the denoising and dereverberation of speech for auditory
protheses and the extraction of interesting sounds in musical
excerpts for electronic music creation. Without speciﬁc prior
information about the sources s or the mixing system A this
problem suffers from well-known theoretical indeterminacies
 , . Generally the sources can only be recovered up to
a permutation and arbitrary gains, but further indeterminacies
may exist in convolutive mixtures (e.g. up to a ﬁlter).
Source Extraction can be addressed at various difﬁculty
levels depending on the structure of the mixing system ,
 . A ﬁrst difﬁculty criterion is the respective number of
sources and sensors. In noiseless determined instantaneous
mixtures (i.e. when m = n) there exists a time-invariant
linear demixing system W = A−1. After W has been
estimated, the sources can be simply recovered as s = Wx. In
noiseless under-determined mixtures (i.e. when m < n), this
is not possible anymore since the equation x = As has an
afﬁne set of solutions. This non trivial indeterminacy can be
removed using knowledge about the sources, such as sparse
priors . A second difﬁculty criterion is the length of the
mixing ﬁlters. Many algorithms for instantaneous noiseless
determined mixtures provide near perfect results , , .
But convolutive mixtures still raise challenging theoretical
issues such as the identiﬁability of the sources up to gain and
technical difﬁculties like the estimation of long mixing ﬁlters
in short duration mixtures.
C. Existing performance measures and their limitations
Some performance measures for Source Extraction have
already been deﬁned in the literature. A ﬁrst kind of measure
assumes that the estimated sources bs have been recovered
by applying a time-invariant linear demixing system W to
the observations x. The global system B = W ⋆A veriﬁes
bs = B ⋆s. The quality of bsj is then measured by the row
Inter-Symbol Interference 
j′,τ |Bjj′(τ)|2 −maxj′,τ |Bjj′(τ)|2
maxj′,τ |Bjj′(τ)|2
ISIj is always positive and equal to zero only when bsj is
equal to the true source sj′ up to a gain and a delay τ
with (j′, τ) = arg maxj′,τ |Bjj′(τ)|2. This criterion and other
similar ones are relevant, but cannot be applied to underdetermined BASS problems because a perfect time-invariant
demixing system W does not exist generally. Moreover even
in determined BASS it is possible to use other separation
schemes than time-invariant linear demixing. A second kind
of measure consists in comparing directly bsj and sj, paying
attention to the indeterminacies of the task. The gain indeterminacy can be handled by comparing L2-normalized versions
of the sources with the relative square distance , , 
∥bsj∥−ϵ sj
This measure is also relevant since it is always positive and
equal to zero only when bsj equals sj up to a gain. However
D takes at most the value D = 2, even in the worst case
where the permutation indeterminacy has been badly solved
and where bsj equals another source sj′ orthogonal to sj. One
would then desire a distortion D = +∞. More generally D
evaluates bad results rather coarsely. For example bsj = sj′
and bsj = sj′/∥sj′∥+ 0.02 sj/∥sj∥lead to similar measures
D = 2 and D ≈1.96 but are perceived quite differently.
These performance measures suffer from further limitations.
Both consider only the case where bsj has to be recovered
up to a permutation and a gain. But in some applications
it may be relevant to allow more or less distortions, not
necessarily related to the theoretical indeterminacies of the
problem. For example in hi-ﬁmusical applications it may be
important to recover the sources up to a simple gain since
arbitrary ﬁltering modiﬁes the timbre of musical instruments.
On the contrary in speech applications some ﬁltering distortion
may be allowed because low-pass ﬁltered speech is generally
still intelligible. Moreover both measures provide a single
performance criterion containing all estimation errors. But
in audio applications it is important to measure separately
the amount of interferences from non-wanted sources, the
amount or remaining sensor noise and the amount of “burbling” artifacts (also termed “musical noise”). Such artifacts
are often considered as a more annoying kind of error than
interferences, that are themselves more annoying than sensor
noise. Many separation methods for under-determined BASS
problems produce few interferences but many artifacts ,
 , , and this cannot be described by a single criterion.
D. Overview of our proposals
The goal of this article is to design new performance criteria
that can be applied on all usual BASS problems and overcome
the limitations above. The only assumptions we make is that
• the true source signals and noise signals (if any) are
• the user chooses a family of allowed distortions F
according to the application (but independently of the
kind of mixture or the algorithm used).
The mixing system and the demixing technique do not need
to be known.
Separate performance measures are computed for each
estimated source bsj by comparing it to a given true source
sj. Note that the measures do not take into account the
permutation indeterminacy of BASS. If necessary, bsj may
be compared with all the sources (sj′)1≤j′≤n and the “true
source” may be selected as the one that gives the best results.
The computation of the criteria involves two successive
steps. In a ﬁrst step, we decompose bsj as
bsj = starget + einterf + enoise + eartif,
where starget = f(sj) is a version of sj modiﬁed by an
allowed distortion f
∈F, and where einterf, enoise and
eartif are respectively the interferences, noise and artifacts
error terms. These four terms should represent the part of bsj
perceived as coming from the wanted source sj, from other
unwanted sources (sj′)j′̸=j, from sensor noises (ni)1≤i≤m,
and from other causes (like forbidden distortions of the sources
and/or “burbling” artifacts). In a second step, we compute
energy ratios to evaluate the relative amount of each of these
four terms either on the whole signal duration or on local
E. Structure of the article
The rest of the article has the following structure. In
Section II we show how to decompose bsj and compute the performance measures when F is the set of time-invariant gains
distortions (this covers our preliminary proposals introduced
in ). In Section III we extend these results to the case
where F contains time-varying and/or ﬁltering distortions. In
Section IV we test the measures on several BASS problems. In
Section V we discuss their relevance for algorithm evaluation
and comment their correlation with subjective performance on
informal listening tests. Finally we conclude in Section VI by
pointing out further perspectives about BASS evaluation and
introducing our on-line evaluation database BASS-dB .
II. PERFORMANCE CRITERIA FOR TIME-INVARIANT GAINS
ALLOWED DISTORTIONS
We propose in this section performance criteria for the most
usual case when the only allowed distortions on bsj are timeinvariant gains. We ﬁrst show how to decompose bsj into four
terms as in (4) and then we deﬁne relevant energy ratios
between these terms.
Let us denote in the following ⟨a, b⟩:= PT −1
t=0 a(t)b(t) the
inner product between two possibly complex-valued1 signals
a and b of length T, where b is the complex conjugate of b,
and ∥a∥2 := ⟨a, a⟩the energy of a.
A. Estimated source decomposition by orthogonal projections
When A is a time-invariant instantaneous matrix and when
the mixture is separated by applying a time-invariant instantaneous matrix W, bsj can be decomposed as
bsj = (WA)jjsj +
(WA)jj′sj′ +
Since (WA)jj is a time-invariant gain, it seems natural to
identify the three terms of this sum with starget, einterf and
enoise respectively (eartif = 0 here). However (5) cannot be
used as a deﬁnition of starget, einterf, enoise and eartif since
the mixing and demixing systems are unknown. Also the two
ﬁrst terms of (5) may not be perceived as separate sound
objects when a nonwanted source sj′ is highly correlated
with the wanted source sj.
Instead, the decomposition we propose is based on orthogonal projections. Let us denote Π{y1, . . . , yk} the orthogonal
projector onto the subspace spanned by the vectors y1, . . . , yk.
The projector is a T ×T matrix, where T is the length of these
vectors. We consider the three orthogonal projectors
Psj := Π{sj},
Ps := Π{(sj′)1≤j′≤n},
Ps,n := Π{(sj′)1≤j′≤n, (ni)1≤i≤m}.
And we decompose bsj as the sum of the four terms
starget := Psjbsj,
einterf := Psbsj −Psjbsj,
enoise := Ps,nbsj −Psbsj,
eartif := bsj −Ps,nbsj.
The computation of starget is straightforward since it involves only a simple inner product: starget = ⟨bsj, sj⟩sj/∥sj∥2.
The computation of einterf
is a bit more complex. If
orthogonal,
j′̸=j⟨bsj, sj′⟩sj′/∥sj′∥2. Otherwise, if we use a vector c
of coefﬁcients such that Psbsj
j′=1 cj′sj′
(where (·)H denotes Hermitian transposition), then c
ss [⟨bsj, s1⟩, . . . , ⟨bsj, sn⟩]H, where Rss is the Gram matrix of
the sources deﬁned by (Rss)jj′ = ⟨sj, sj′⟩. The computation
of Ps,n proceeds in a similar fashion, however most of the
time we can make the assumption that the noise signals are
mutually orthogonal and orthogonal to each source, so that
Ps,nbsj ≈Psbsj + Pm
i=1⟨bsj, ni⟩ni/∥ni∥2.
1Audio signals are real-valued, but it is costless to express our performance
criteria in the slightly more general complex setting which might be useful
for other types of signals.
B. From estimated source decomposition to global performance measures
Starting from the decomposition of bsj in (6-12), we now
deﬁne numerical performance criteria by computing energy
ratios expressed in decibels (dB). We deﬁne the Source to
Distortion Ratio
SDR := 10 log10
∥starget∥2
∥einterf + enoise + eartif∥2 ,
the Source to Interferences Ratio
SIR := 10 log10
∥starget∥2
∥einterf∥2 ,
the Sources to Noise Ratio
SNR := 10 log10
∥starget + einterf∥2
and the Sources to Artifacts Ratio
SAR := 10 log10
∥starget + einterf + enoise∥2
These four measures are inspired by the usual deﬁnition
of the SNR, with a few modiﬁcations. For instance the
deﬁnition of the SNR involving the term starget + einterf at
the numerator aims at making it independent of the SIR.
Indeed consider the case of an instantaneous noisy 2 × 2
mixture where bs1 = ϵ s1 + s2 + enoise with ∥ϵ s1∥≪∥s2∥
and ∥enoise∥≈∥ϵ s1∥. Then bs1 is perceived as dominated
by the interfering signal, with the noise energy making an
insigniﬁcant contribution. This is consistent with SIR ≈−∞
and SNR ≈+∞using our deﬁnitions. A SNR deﬁned by
10 log10(∥starget∥2/∥enoise∥2) would give SNR ≈0 instead.
Similarly, the SAR is independent of the SIR and the SNR
since the numerator in (16) includes the interferences and noise
terms as well.
Note that the numerical precision of the measures is lower
for high performance values than for low ones. For example a
high SDR means that the denominator in (13) is very small, so
that small constant-amplitude errors in starget (due to signal
quantization) result in large SDR deviations. In particular,
when the signals correspond to sound ﬁles, the precision of
the results depends on the number of bits per sample.
C. Local performance measures
When the powers of starget, einterf, enoise and eartif vary
across time, the perceived separation quality also varies accordingly. We take this into account by deﬁning local numerical performance measures in the following way.
First we compute starget, einterf, enoise and eartif as in (6-
12). Then, denoting w a ﬁnite length centered window, we
compute the windowed signals sr
target, er
interf, er
noise and er
centered in r, where sr
target(t) = w(t −r)starget(t) and so
on. Finally, for each r we compute the local measures SDRr,
SIRr, SNRr and SARr as in (13-16) but replacing the original
terms by the windowed terms centered in r.
SDRr, SIRr, SNRr and SARr thus measure the separation
performance on the time frame centered in r. All these values
can be visualized more globally by plotting them against r or
by summarizing them into cumulative histograms . Global
performance measures can also be deﬁned in the spirit of
segmental SNR . The shape of the window w has not
much importance generally, only its duration is relevant. Thus
a rectangular window may be used for simplicity.
D. Comparison with existing performance measures
The new performance measures solve most of the problems
encountered with existing measures discussed in Section I-C.
First the computation does not rely on the assumption that
a particular type of demixing system or algorithm is used.
The only assumption is that bsj has to be recovered up to a
time-invariant gain. Measures for other allowed distortions are
proposed in Section III.
Secondly the SDR has better properties than D. Simple
calculus shows that both measures are identical up to a oneto-one mapping 10−SDR/10 = D(4 −D)/(2 −D)2. However,
contrary to −10 log10 D, the SDR is not lower-bounded:
SDR = −∞when starget = 0 and evaluation of bad results
is less coarse .
Thirdly four criteria are proposed instead of a single one.
The SIR, SNR and SAR allow to distinguish between estimation errors that are mostly dominated by interferences, noise
or artifacts. This is veriﬁed on test mixtures in Section IV.
III. PERFORMANCE CRITERIA FOR OTHER ALLOWED
DISTORTIONS
A. Which equations have to be modiﬁed ?
After having deﬁned performance measures for timeinvariant gains allowed distortions, we consider now similar
measures for other allowed distortions. Much of the work
done in the previous section is still relevant here and only
the deﬁnitions of the orthogonal projectors in (6-8) have to be
Indeed the two steps consisting in decomposing bsj in four
terms and in computing energy ratios between these terms do
not depend on each other. Since the kind of allowed distortion
is not used in the second step, the performance measures are
always deﬁned by (13-16), whatever the allowed distortion is.
Moreover the decomposition of bsj can also often be deﬁned
by (9-12), but using other orthogonal projectors depending
on the allowed distortions. In the following we present successively the projectors used to decompose bsj when ﬁltering
and/or time-varying distortions are allowed.
B. Time-invariant ﬁlters allowed distortions
When time-invariant ﬁlters are allowed, starget is not a
scaled version of sj anymore, but a ﬁltered version expressed
as starget(t) = PL−1
τ=0 h(τ) × sj(t −τ). If we express this
in terms of subspaces, starget does not generally belong to
the subspace spanned by sj but to the subspace spanned by
delayed versions of sj. So we can deﬁne starget by projecting
bsj on this new subspace.
We denote by sτ
i the source signal sj and the noise
signal ni delayed by τ, so that sτ
j (t) = sj(t−τ) and nτ
ni(t−τ). To avoid multiple deﬁnitions due to boundary effects,
we consider the support of all signals to be [0, T +L−2] where
[0, T −1] is the original support of the signals and L−1 is the
maximum delay allowed. We deﬁne the decomposition using
the three projectors
Psj := Π{(sτ
j )0≤τ≤L−1},
Ps := Π{(sτ
j′)1≤j′≤n,0≤τ≤L−1},
Ps,n := Π{{(sτ
j′)1≤j′≤n, (nτ
i )1≤i≤m}0≤τ≤L−1},
The computation of the projections again involves inversion
of Gram matrices. The Gram matrix corresponding to Psj
is the empirical auto-correlation matrix of sj deﬁned by
(Rsjsj)ττ ′ = ⟨sτ
j ⟩. The Gram matrix associated with Ps
has a symmetric block-Toeplitz structure, where the blocks
on the τ-th diagonal are the empirical auto-correlation matrix
of the sources at lag τ deﬁned by (Rss(τ))jj′ = ⟨sj, sτ
C. Time-varying gains allowed distortions
When time-varying gains distortions are allowed, starget
is equal to sj multiplied by a slowly time-varying gain. We
parameterize this gain as g(t) = PU−1
u=0 αuv(t −uT ′), where
v is a positive kernel (i.e. a window) of length L′ and T ′
the hopsize in samples between two successive “breakpoints”.
When v is a rectangular window and L′ = T ′, this parameterization yields piecewise constant gains with breakpoints at uT ′,
but choosing a smoother kernel makes it possible to get more
smoothly varying gains. This gives starget(t) = g(t)sj(t) =
u=0 αu × v(t −uT ′)sj(t). Thus starget belongs to the
subspace spanned by versions of sj windowed by the kernel
v. Note that this use of windowed source signals has no link
with the the computation of local performance measures from
windowed decomposed signals in Section II-C. We emphasize
again that the decomposition of bsj and the computation of
energy ratios are separate steps.
We deﬁne the windowed source signals (su
j )0≤u≤U−1 and
the windowed noise signals (nu
i )0≤u≤U−1 of support [0, T −1]
j (t) = v(t−uT ′)sj(t) and nu
i (t) = v(t−uT ′)ni(t). The
projectors for decomposition are given by
Psj := Π{(su
j )0≤u≤U−1},
Ps := Π{(su
j′)1≤j′≤n,0≤u≤U−1},
Ps,n := Π{{(su
j′)1≤j′≤n, (nu
i )1≤i≤m}0≤u≤U−1}.
In order to guarantee the natural property Psjsj
(i.e. SDR = +∞as expected in the particular case where
bsj = sj), we enforce the condition that PU−1
u=0 v(t −uT ′)
is a constant for all t. When this is veriﬁed, sj belongs
to the subspace spanned by (su
j )0≤u≤U−1 because sj
u=0 v(t−uT ′). This condition always holds true
when T ′ = 1, but other values of T ′ may work depending on
the kernel v. For example if v is a triangular window and L′
is a multiple of 2, then T ′ = L′/2 also works.
D. Time-varying ﬁlters allowed distortions
Finally, when time-varying ﬁlters distortions are allowed,
the decomposition of bsj is made by combining the ideas of
the two previous subsections. The estimated source starget is
expressed as a version of sj “convolved” by a slowly timevarying ﬁlter. Using the notations of the previous subsections, this results in starget(t) = PL−1
τ=0 h(τ, t)sj(t −τ) =
u=0 ατu ×v(t−uT ′)sj(t−τ). Thus starget belongs
to the subspace spanned by delayed versions of sj windowed
by the kernel v.
j )0≤τ≤L−1,0≤u≤U−1 and the windowed delayed noise
signals (nτu
i )0≤τ≤L−1,0≤u≤U−1 of support [0, T + L −2]
by windowing delayed signals: sτu
j (t) = v(t −uT ′)sτ
i (t) = v(t −uT ′)nτ
i (t). Note that the reverse order
computation (passing windowed signals through delay lines)
is not equivalent and results in other projections generally. We
deﬁne the decomposition by the projectors
Psj := Π{(sτu
j )0≤τ≤L−1,0≤u≤U−1},
Ps := Π{(sτu
j′ )1≤j′≤n,0≤τ≤L−1,0≤u≤U−1},
Ps,n := Π{{(sτu
j′ )1≤j′≤n, (nτu
i )1≤i≤m}0≤τ≤L−1,0≤u≤U−1}.
IV. EVALUATION EXAMPLES
In order to assess the relevance of our performance measures, we made tests on a few usual BASS problems. The
separated sources were either simulated from a known decomposition or extracted from the mixtures with existing BASS
algorithms.
In this section we present the results of performance measurement on three noiseless mixtures of three musical sources.
The sources are 16 bits sound ﬁles of 2.4 s, sampled at 8 KHz
(T = 19200) and normalized. s1 is cello, s2 drums and s3
piano. The three mixtures are 16 bits sound ﬁles containing
an instantaneous 2×2 mixture, a convolutive 2×2 mixture and
an instantaneous 2 × 3 mixture. These mixtures were chosen
because they have very different difﬁculty levels and they act
as typical mixtures within the large amount of usual audio
mixtures. We also chose some typical existing algorithms to
separate these mixtures to show that the performance measures
are relevant on “real life” data.
For each mixture and each algorithm the (non quantized)
estimated sources are decomposed using different allowed
distortions and the performance measures are computed. The
results are summarized in Tables II, III and IV. The different
kinds of allowed distortions and corresponding decompositions
are denoted TI Gain, TI Filt, TV Gain and TV Filt respectively.
The values of the decomposition parameters are listed in
Table I. Their choice is discussed in Section V based on
informal listening tests.
The sound ﬁles corresponding to these examples are available for listening on 
demos/bssperf/. This demo web page provides the sound
ﬁles of the mixture x, the sources s, the ﬁrst estimated source
bs1, and also the sound ﬁles of starget, einterf, enoise and eartif
from the decomposition of bs1. Sound ﬁles of bs2, bs3 and their
decompositions are not provided for the sake of legibility. We
emphasize that listening to these sounds and comparing with
the related performance ﬁgures is the best way to evaluate the
meaningfulness of our proposals.
PARAMETER VALUES USED FOR DECOMPOSITION (8 KHZ SAMPLE RATE).
Time frames
distortion
A. Instantaneous 2 × 2 mixture
Our ﬁrst example is a stereo instantaneous mixture of s1
and s2, obtained with the mixing matrix
We solve this problem by estimating a demixing matrix
with two different ICA methods : by using non Gaussian
distributions and mutual independence of the sources with
JADE , and by ﬁnding zones in the time-frequency plane
where only one source is present with TFBSS (used with
64 time frames and 1024 frequency bins as input parameters).
The performance measures are shown in Table II for TI
Gain decompositions. Results with other decompositions
differ from less than 2 dB. Since the global mixing-unmixing
system WA is known, we also compute for comparison the
System SIR (SSIR) which is the power ratio between the two
ﬁrst terms of (5).
As expected with sources estimated by time-invariant linear
demixing, no artifacts come into play: SAR ≈+∞up to
numerical precision. The estimation error is dominated by
interferences and SDR ≈SIR. Moreover, the SIR is higher for
TFBSS than for JADE. This result is corroborated by the fact
that the demixing matrix estimated with TFBSS is closer to the
true demixing matrix than with JADE. Also, as expected the
SSIR is very close to the SIR, because the correlation between
the sources ⟨s1, s2⟩= −0.0055 is small.
EVALUATION OF AN INSTANTANEOUS 2 × 2 MIXTURE.
distortion
B. Convolutive 2 × 2 mixture
Our second example is a convolutive mixture of s1 and
s2 made with 256 tap ﬁlters. The problem is solved by a
frequential domain ICA method using 256 sub-bands and
separating the mixture with JADE in each sub-band.
The usual “permutation problem” is encountered when
building estimated sources from extraction results in each
sub-band. We test two methods to address this problem:
the method outlined in and an oracle (i.e. choice of
the optimal permutations knowing the true sources). The
corresponding algorithms are named Frequential ICA (FICA)
or Oracle Frequential ICA (OFICA). Both methods do not
aim at recovering the sources s1 and s2 but their images on
the ﬁrst channel a11 ⋆s1 and a12 ⋆s2. Thus the estimated
sources may be at best ﬁltered versions of the true sources.
The performance measures are shown in Table III for three
different decompositions. We compute again the SSIR from
(5), with WA now containing ﬁlters instead of gains.
Different conclusions arise depending on the decomposition.
The TI Gain decomposition results in low SDRs for both
methods and SDR ≈SAR. Many artifacts arise due to
forbidden (ﬁlter) distortions of the sources. On the contrary
the TI Filt decomposition outputs a high SDR for OFICA
and a medium SDR for FICA with SDR ≈SIR. Artifacts are
smaller because ﬁlter distortions are allowed, and interferences
are larger for FICA than for OFICA because the use of oracle
information in OFICA prevents bad pairing of sub-bands. The
TV Filt decomposition leads to intermediate results. Short (64tap) ﬁlter distortions are allowed, but longer ﬁlter distortions
are not, thus some of the ﬁlter distortions on the estimated
sources are counted towards artifacts. Again the SSIR is very
close the SIR computed using the TI Filt decomposition,
because the correlation between delayed versions of different
sources is also small.
It is also interesting to study the evolution of the performance measures across time. For example Fig. 1 plots the
local SIR for bs1 (estimated with FICA) using TI Filt. We see
that the actual performance measure varies a lot, which cannot
be explained by a single global SIR.
EVALUATION OF A CONVOLUTIVE 2 × 2 MIXTURE.
Method Allowed
distortion
C. Instantaneous 2 × 3 mixture
Our third example is an instantaneous mixture of s1, s2 and
s3 computed with the mixing matrix
To solve this problem, we represent the two mixture channels
in a domain where the sources exhibit a sparse behavior,
and then the mixing matrix and the sources are estimated
by (nonlinear) clustering of the ratios of the representation
coefﬁcients between the channels. Two algorithms are tested:
a clustering of the Short Time Fourier Transform (STFT)
called DUET (using a 256 sample Hanning window and
a 192 sample hopsize for STFT computation) and a Matching
Local SIR for bs1 estimated by FICA and TI Filt decomposition
in the 2 × 2 convolutive mixture. Hanning windows of length 100 ms and
overlapping 75 ms are used. The SIR is plotted against time in the upper plot
and summarized in a cumulative histogram in the lower plot.
Pursuit Clustering (MPC) (using 10 000 Gabor atoms
with truncated Gaussian envelope). The performance measures
are shown in Table IV for two different decompositions.
Unlike in the previous experiments, it does not seem possible
to display any sort of “System SIR” for the MPC algorithm,
since the result of the separation is not a linear function of the
input sources. In a sense, this perfectly illustrates a situation
where it is necessary to have at hand performance measures
such as the ones we deﬁne, that is to say measures which
do not rely on a particular type of separation algorithm, but
simply try to compare the estimated signals with the target
This time the choice of the decomposition has less inﬂuence
on the results. Both methods estimate the sources essentially
without ﬁlter distortions but with “burbling” artifacts due to
source overlap in the representation domain. Thus SDRs are
low for both methods and SDR ≈SAR. Note that MPC
leads to better performance than DUET, particularly for bs3.
Indeed the use of an overcomplete dictionary in MPC makes
the source representations sparser and limits source overlap.
EVALUATION OF AN INSTANTANEOUS 2 × 3 MIXTURE.
Method Allowed
distortion
V. DISCUSSION
Before we conclude, let us summarize in this section the
results of the evaluation examples. We discuss the relevance of
the proposed performance measures for algorithm evaluation
and comparison. Then we describe how they could possibly
be modiﬁed to explain subjective auditory assessments.
A. Relevance for algorithm evaluation and comparison
The main result of the previous section is that the SDR,
SIR, SNR and SAR were found to be relevant for the
evaluation of an algorithm and the comparison of several
algorithms. Indeed, given a family of allowed distortions, the
SIR and SAR were shown to be valid performance measures
regarding two separate goals: rejection of the interferences
and absence of forbidden distortions and “burbling” artifacts.
Other experiments proved that the SNR was also valid for a
third goal: rejection of the sensor noise. Finally the SDR was
shown to be valid as a global performance measure in case
these three goals are equally important.
Another important result is that the measures were found
to depend a lot on the number of delays and time frames
chosen for decomposition. Experimentally the more distortions
are allowed the higher the SDRs are. More rigorously, when
F and F′ are two families with F ⊂F ′, the SDR of a given
estimated source bsj is higher allowing distortions in F ′ than in
F. Indeed the projection subspaces verify {f(sj), f ∈F} ⊂
{f(sj), f ∈F′} and thus ∥bsj −Psjbsj∥is smaller allowing
distortions in F′ than in F.
This conﬁrms our main postulate that the evaluation of
the performance of an algorithm only makes sense given a
family of allowed distortions. This can be seen as a nice
property if the distortions allowed for the desired application
correspond to one of the families presented in sections II and
III with a precisely known number of frequency sub-bands
and time frames. But this is annoying when one has no
idea about which distortions to allow. In that case, we
cannot “recommend” a family of allowed distortions more
than another one: the “best” choice really depends on the
application.
Finally an interesting result is that in the previous section
the results of algorithm classiﬁcation according to mean SDR
were always the same whatever decomposition was used. We
make the hypothesis that this is not a coincidence and that
the classiﬁcation order is rather independent of the family of
allowed distortions. Of course this hypothesis is based on very
few experiments actually, but we think it would be interesting
to validate or inﬁrm it using more data. If it was true then
algorithm classiﬁcation would be greatly simpliﬁed. Indeed
it would be unnecessary to test many families of allowed
distortions before providing a global result: a single one would
B. Relevance towards subjective performance measures
Another interesting question is to study the relationship
between the proposed measures and subjective auditory
performance assessments. In theory this should be done
using carefully calibrated psycho-acoustical listening tests.
We could ﬁrst ask the listeners how they describe the results
with their own words, and check whether they use synonyms
of “interferences” and “artifacts” or not. Then we could go
on with more constrained tests, such as broadcasting pairs
of results and asking listeners if they hear more or less
“interferences” and “artifacts” in the ﬁrst sound of each pair.
Because performing these listening tests is not a trivial task,
we give here only a few remarks based on our own listening
experience.
If we admit that the ear splits estimated sources into the
same four components than our analytical decomposition, we
may deﬁne interferences, noise and artifacts as “what I hear
coming from the other sources”, “what I hear coming from
sensor noise” and “what I hear to be burbling artifacts”. With
this deﬁnition of auditory performance measures, we remark
that the SIR, SNR and SAR seem to be better related to the auditory notion of interferences, noise and artifacts using the TV
Filt decomposition. Indeed decompositions using very few delays and time frames are not always able to extract all the perceived interferences inside einterf but split them between einterf
and eartif. On the contrary decompositions with too many delays and/or time frames sometimes put “burbling” artifacts into
einterf and nothing into eartif. The parameters we chose for the
TV Filt decomposition (F = 64 and L′ = 200 ms) appear to
be a good compromise in many experiments. When the TI Filt
decomposition is used, a higher number of delays (L = 256)
seems preferable. Of course these choices cannot be proved
using physical or mathematical arguments, but readers may
check this partially by listening to the previous examples on
 
If we also admit that the ear associates energy prioritarily to
the true source rather than to interferences in the case where
some sources are similar, then the components starget, einterf,
enoise and eartif estimated by the “greedy” decomposition of
(9-12) should be closer to the perceptual components than
those estimated by the simultaneous decomposition of (5).
Indeed the “greedy” decomposition scheme takes into account
similarity between sources as measured by correlation. We
think that this measures part of the perceptual similarity
between sources, but not all. For instance two white noises
sound the same even when they are orthogonal.
Some other auditory properties cannot be explained by
the proposed measures. First the high values of SIR, SNR
and SAR have limited auditory signiﬁcation. For example
the two instantaneous mixtures of Section IV-A have very
different SIRs but can hardly be distinguished. Also the SDR
does not measure the total perceived distortion. In the case
where bsj is a slightly low-pass ﬁltered version of sj, then
SDR ≈+∞using TV Filt decomposition but low-pass
ﬁltering is perceived as timbre distortion. This fourth kind
of error (besides interferences, noise and “burbling” artifacts)
could be dealt with using an additional performance measure,
such as Itakura-Saito distance or cepstral distortion .
An interesting idea to mimic the auditory treatments would
be to pass the sources and noises through an auditory ﬁlter
bank. Then each estimated source could be decomposed on
subspaces spanned by the auditory sub-bands by handling
differently sinusoidal and noise-like zones and by taking into
account auditory masking phenomena. Similar performance
measures already exist in the ﬁelds of denoising and compression , .
VI. CONCLUSION AND PERSPECTIVES
In this article we discussed the question of performance
measurement in BASS. Given a set of allowed distortions,
we evaluated the quality of an estimated source by four
measures called SDR, SIR, SNR and SAR. Experiments
involving typical mixtures and existing algorithms showed
that these measures were relevant for algorithm evaluation
and comparison. With respect to other existing performance
measures, the main improvement is that we do not assume a
particular separation algorithm nor a limited set of allowed
distortions. Moreover we evaluate separately the amount of
interferences, remaining sensor noise and artifacts, which is
a crucial point for evaluation in under-determined mixtures.
Our performance measures are implemented within a
MATLAB toolbox named BSS EVAL distributed online under
the GNU Public License .
The main application of this work is to rank existing BASS
algorithms according to their performance on the same test
data. To help this we built a web database called BASSdB that classiﬁes the test mixtures according to the
Source Extraction subtasks . These subtasks corresponds
to different structures of the mixing system deﬁned by the
number of sources and sensors (2×2, 2×5, 5×5, 7×5, etc)
and the kind of mixing ﬁlters (gain, delay, gain+delay, liverecorded room impulse responses). BASS-dB already provides
some test mixtures and performance results, but we encourage
people to feed it with their own mixtures and results.
We hope the BASS community will consider this issue,
so that BASS methods can be compared within a shared
framework. Among the results, the best BASS methods
could be identiﬁed and selected for further improvement.
Or objective difﬁculty criteria could be deﬁned to determine
for example whether the difﬁculty in an under-determined
convolutive
convolution
from under-determination. Our hypothesis that algorithm
classiﬁcation
independent
distortions could also be validated or inﬁrmed.
Among the possible generalizations to this work, we are
currently studying the derivation of psycho-acoustical performance measures and performance measures for the similar
BASS tasks of Source Spatial Image Extraction and Remixing
 , that also involve listening to the extracted sources.
ACKNOWLEDGMENTS
This work was part of the Junior Researchers Project
“Resources for Audio Signal Separation” funded by GdR
ISIS (CNRS) and was mainly performed when Emmanuel
Vincent was with IRCAM, Paris (France). C´edric F´evotte
acknowledges support of the European Commission funded
Research Training Network HASSIP .
The authors would like to thank Laurent Benaroya, Fr´ed´eric
Bimbot, Xavier Rodet, Axel R¨obel and ´Eric Le Carpentier for
their helpful comments.