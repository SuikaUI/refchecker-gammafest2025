INFORMATION
COMPUTATION
82, 93-133 
Approximate
Generation
and Rapidly
SINCLAIR AND MARK JERRUM
Department
of Computer
University
of Edinburgh,
The paper studies effective approximate solutions to combinatorial
counting and
uniform generation problems. Using a technique based on the simulation of ergodic
Markov chains, it is shown that, for self-reducible structures, almost uniform
generation
is possible in polynomial
time provided
only that randomised
approximate
counting to within some arbitrary polynomial
factor is possible in
polynomial
time. It follows that, for self-reducible structures, polynomial
randomised algorithms for counting to within factors of the form (1 +n-@)
available either for all fl E R or for no fi E R. A substantial part of the paper is
devoted to investigating the rate of convergence of finite ergodic Markov chains,
and a simple but powerful characterisation of rapid convergence for a broad class
of chains based on a structural property of the underlying graph is established.
Finally, the general techniques of the paper are used to derive an almost uniform
generation procedure for labelled graphs with a given degree sequence which is
valid over a much wider range of degrees than previous methods: this in turn leads
to randomised approximate counting algorithms for these graphs with very good
asymptotic behaviour.
1989 Academic
Press, Inc.
1, INTRODUCTION
This paper is concerned with two classes of problems involving
set of combinatorial
structures:
and generating
at random.
Combinatorial
counting problems have a long and distinguished
Apart from their intrinsic
interest, they arise naturally
from investigations
in numerous
other branches of mathematics
and the natural sciences and
have given rise to a rich
and beautiful
generation
are less well studied
but have a number
of computational
applications.
For example, they can be seen as a way of exploring
set of structures and constructing
typical representatives of it. These may
* An extended abstract of this paper appeared in the “Proceedings of the 13th International
Workshop on Graph-Theoretic
Concepts in Computer Science, Staffelstein, June/July 1987”;
published by Springer-Verlag
as Lecture Notes in Computer Science Vol. 314.
0890-5401/89 53.00
1989 by Academic
Press. Inc.
All rights
of reproduction
in any form reserved.
be used to formulate
conjectures about the set, or perhaps as test data for
the empirical
analysis of some heuristic algorithm
which takes inputs from
The study of counting problems as a class from a computational
tive was initiated
by Valiant
 . A parallel
approach to generation
was proposed more recently by Jerrum,
and Vazirani
 . In this paper, we improve
and extend some results of the latter
concerning
the relationship
between counting
and generation
and in particular
the existence of efficient
approximation
algorithms
for their solution.
Typically,
the sets of structures we encounter are defined implicitly
some other combinatorial
entity drawn from a family of problem instances,
together with a relation R which associates with each instance x a finite set
R(x) of solutions, as in the following examples:
1. Problem
instances: Boolean formulae B in disjunctive normal form
set R(B): all satisfying assignments of B.
instances: undirected
graphs G. Solution
set R(G): ail
l-factors (perfect matchings)
3. Problem
instances:
n. Solution
partitions
Thus we can talk about the counting
and (uniform)
generation
associated with a relation R: given as input a problem
instance x, count or
generate the elements of the solution
Many naturally
occurring relations of this kind exhibit a self-reducibility
first studied by Schnorr . Informally,
this means that the
in R(x) have a simple inductive
construction
from the solution
sets of a few smaller instances of the same problem.
(For precise definitions
of terms in this Introduction,
the reader is referred to the next section.) All
of the above examples are self-reducible:
in 1, for instance, there is an
obvious (l-l
)-correspondence between the satisfying assignments of B and
those of the reduced formulae
BT and B,, which are obtained from B by
substituting
for one of its variables the values true and false respectively.
For self-reducible relations, an efficient (i.e., polynomial
time) algorithm
for the counting
immediately
yields a polynomial
time uniform
generation
procedure.
has been used extensively
literature
to generate particular
combinatorial
structures, such as 3 above,
for which counting information
is readily available, typically in the form of
a recurrence relation
 .
Efficient exact solutions
to counting
are, however, relatively
indeed there are many natural
relations, among them 1 and 2
APPROXIMATE
above, whose counting
is #P-complete
and hence apparently
intractable
1979a, 1979b), but whose construction problem
solved in polynomial
time. (Given a problem
instance x, the construction
asks for a solution
y E R(x) if one exists, and the answer “no”
otherwise.) In some cases, such as 1 above, the structures can also be
generated efficiently. Note that generation
seems to be harder in general
than construction
since it requires that all solutions be “equally accessible.”
In circumstances where exact methods are elusive, it is natural to seek
procedures
structures
approximately
appropriate
sense. Following
Stockmeyer
 and Karp
 , we allow our counting
algorithms
to flip coins, and demand that
they produce an answer which approximates
within some specified
factor with high probability.
self-reducible
relations,
approximate
and almost
generation,
in which a small
bias in the output distribution
over R(x) is allowed, are closely related. (An
will generally
be as useful in practice
one and may be effectively indistinguishable
from it.) Specifically,
and Vazirani
 show how the standard reduction
from generation
to exact counting can be modified so as to yield an almost
given only approximate
estimates, provided
these are within a factor of 1 + 0(1x1 pkR) of the correct values, where 1x1 is
size and k,>O
is a constant
on R. Conversely,
approximate
to within any factor of the form 1 + 1x1 -p, with
j? E R, is polynomial
time reducible to almost uniform generation. They also
locate these two problems for general NP relations within the second level
of the (probabilistic)
polynomial
time hierarchy (Stockmeyer,
In this paper, we present an improved
polynomial
time reduction
generation
to approximate
for self-reducible
relations,
in which the counting
estimates need only be within a factor of
1 + O( 1x1”) of the exact values, for an arbitrary
real constant ~1. Thus a very
crude counting procedure (to within a constant factor, say) can be used to
generate solutions almost uniformly,
and so can in turn be bootstrapped
polynomial
time to a counting procedure which approximates
within a fac-
tor of 1+ E for any specified E > 0. Moreover,
the runtime
of the improved
procedure depends only polynomially
on E- *. (Such an algorithm
called a fully
polynomial
randomised
approximation
A remarkable
consequence of this result is that the concept of approximate
within factors of the form 1 + U( 1x1 -p), for fi E R, is robust
with respect to
polynomial
time computation
for the large class of self-reducible relations.
The novel reduction
is accomplished
by stochastic simulation
ergodic Markov
chain whose structure mirrors
the self-reducibility
in question.
The states of the chain include
the solutions
interest, and as the chain evolves it converges to a stationary
distribution
which is uniform
over these states. Therefore, provided
the convergence is
rapid enough, a modest number
of simulation
steps will ensure that the
final state is almost uniformly
distributed
over the solution
set. A similar
approach, based on a rather different type of Markov
chain, can be used to
generate in more direct fashion various structures such as matchings
graphs. This is the subject of another paper on eigenvalues and expander graphs, appears
to be quite generally
applicable
and we believe it to be of independent
interest. Further examples of its use appear in . Very recently, a similar characterisation
for Markov
was discovered independently
by Lawler and Sokal .
as a concrete example of these ideas in action we consider the
of generating labelled graphs with specified vertex degrees and a
specified excluded
a result of McKay
 which
provides analytic counting
estimates for these graphs, we show that it is
possible to generate them in polynomial
time from a distribution
very close to uniform
only that the maximum
degree grows no
faster than O(HZ”~), where m is the number of edges. Although
the problem
is apparently
not self-reducible
under this restriction,
our techniques can
still be applied with a little extra work. This result represents a considerable
improvement
on hitherto
 XE C* the corresponding
solution set
with respect to R is
R(x)= {~EC*:
(x, y)eR}.
We shall always assume that these sets are finite. Note that we make no
distinction
between strings which do not encode a “valid” problem instance
and those which encode a problem
instance with empty solution
the formal counterpart
of Example
1 of the Introduction
R = { (x, y ): x E Z* encodes a Boolean formula
y E C* encodes a satisfying assignment of B}.
Throughout
we shall move freely between the formal and informal problem
descriptions,
“reasonable”
in the sense of Garey and Johnson .
The counting problem for a relation
R over C involves computing
#R: Z* + N defined
As indicated
Introduction,
we shall be concerned with effective approximate
solutions to
this problem
which estimate the value of the function
within a specified
factor. This notion of approximation,
which is familiar
from combinatorial
optimisation
and asymptotic
analysis, has also been applied
to counting
in computer
science by Stockmeyer
 and Karp and Luby
(A less conventional
severe definition
approximate
is studied by Cai and Hemachandra,
If a, li, and r are non-negative
real numbers with r 2 1, we say that ri
approximates a within ratio r if cir-’ < a < 6r. Let R be a relation
and p a real-valued function of the natural number n such that p(n) > 1 for
all n E N. A randomised approximate counter for R within ratio p is a
probabilistic
V whose output on input x E ,5’* is a non-negative
real-valued
variable g(x) satisfying
Pr(V?(x) approximates
#R(x) within ratio p( 1x1)) B 1,
If % is in fact deterministic
then it is an approximate counter for R within
ratio p. In either case, %? is polynomial/y time-bounded if it runs within time
p( [xl) for some polynomial
p and all inputs XE C*.
The significance of the lower bound of $ in the above definition
lies in the
fact that it allows the counter to be “powered” so that the probability
a bad estimate
becomes very small in polynomial
time. (This
would still hold if a were replaced by any fixed constant greater than t.)
More precisely, we have
If there exists a polynomially
time-bounded
randomised
approximate
counter V for R within ratio p, then there exists a probabilistic
W which on inputs (x, S > EC* x R + runs in time polynomial
1x1 and lg 6-‘,
and whose output is a random variable %“(x, 6) satisfying
Pr((e’(x, 6) approximates
within ratio p( Ix])) > 1 - 6.
The required
W’ makes p(lg 6-l)
calls to %, with
input x, for a suitable polynomial
p and returns the median of the values
obtained. For the details, see Lemma 6.1 of .
In the (uniform) generation problem
for a relation
R G C* x C*, we are
given an input x EC* and asked to select an element of R(x) at random in
such a way that each solution
has equal a priori
probability
chosen. In practice,
the strict uniformity
requirement
can generally
weakened slightly, and we say that a probabilistic
93 is an almost
for R if its output
on ‘inputs
(x, E) EC* x R + is a
random variable $3(x, E) satisfying
Y(x, E) takes values in the set R(x) u {?} with ? # C, and
R(x) # @ + Pr(g(x,
E) = ?) < 4.
There exists a function
4: C* x R+ -+ (0, 1 ] such that, for all
y 4 R(x) == Pr(%(x, E) = y) = 0
y~R(x)=>(l+~)-‘&x,~)<Pr(%(x,~)=y)d(l+~)~(x,~).
Thus E represents the pointwise bias tolerated
in the output
distribution.
is fuZiy polynomial
(Ep.) if it runs in time
bounded by a polynomial
in 1x1 and lg E ~ ’ : in this case, the generator may
be regarded
as effectively
indistinguishable
polynomial
time statistical tests. Note that as a matter of convenience we
the generator
(i.e., output
the special symbol
probability
64. This can always be made to decay exponentially
fast using
if the construction
is solvable
polynomial
time, as is often the case for the relations we consider, then we
can force the generator never to fail when R(x) is non-empty.
APPROXIMATE
In the above definitions
we have not been precise about our
model of randomised
computation.
For deliniteness, we take this to be the
probabilistic
 , in which the only source of
randomness is a fair coin. However, we shall feel free to express algorithms
in terms of much more general branching
probabilities
of two previously
integers.. This
can always be
by a fair coin to a high degree of accuracy at negligible
particular,
the notions
of polynomial
approximation
presented here are robust with respect to such changes in the
model of computation.
we formalise
the concept
of self-reducibility
Introduction.
A relation
R EC* x C* is (polynomial
time) self-reducible, in
the sense of Schnorr , if
exists a polynomial
computable
I,: C* + N such that lR(x) = 0( I.#“)
for some constant k, > 0, and
Y E R(x) * IYI = ER(x)
vx, y E P.
For all XE Z* with ZR(x) = 0, the predicate
,4 E R(x) can be
tested in polynomial
time. (A denotes the empty string over C.)
exist polynomial
computable
and 0: C* + N satisfying
4x) = mIxI)
f,(x) > 0 - o(x) > 0
Ill/k w)l d I.4
~AII/(x, ~1) = max{I,(x) - 14, O}
and such that each solution
set can be expressed in the form
R(x) = u {WY:
Y E WV%, w,,>
(iii) provides an inductive construction
of the solution sets as
follows: if the solution
length lR(x) is greater than zero, R(x) can be par-
into classes according to the small initial
segment w of length a(x),
and each class can then be expressed as the solution set of another instance
$(x, w), concatenated with w. The partitioning
of satisfying assignments of
in the Introduction
is easily seen to be of the
required form, under some natural encoding. An atom is an instance x E .Z*
with solution
length I,(x) = 0: in the above example, these would include
(encodings of) the constants true and false, viewed as DNF formulae. Con-
(ii) says that, for atoms x, we can test in polynomial
time whether
or R(x) = {A}.
that this, together
with condition
implies that we can test whether a candidate solution y E C* belongs to any
set R(x) in time polynomial
in 1x1 + Jyl. In view of condition
the existence problem associated with R is therefore in NP. It appears that the vast majority
occurring relations can be formulated
so as to be self-reducible.
It is conceptually
to capture
the inductive
construction
solutions of a self-reducible relation explicitly
in a tree structure. For each
with R(x) # 0,
the tree of derkations
is a rooted tree in
which each vertex v bears both a problem instance label inst(v) E C* and a
solution label sol(v) E .Z*, defined inductively
as follows:
The root u has labels inst(u) = x and sol(u) = A.
For any vertex v in TR(x), if the problem
instance z = inst(u) is
an atom then u is a leaf. Otherwise, define
W(u) = (w E .F’(“:
R(ll/(z, w)) # 0).
(Note that W(v) is non-empty.)
Then v has a child v, for each w E W(v),
with labels inst( v,) = ll/(z, w) and sol( v,.) = sol(u) . w.
Note that the labels sol(v) are distinct, while the inst(v) are in general not.
It should be clear that the labels sol(v) for leaves v are precisely the
elements of R(x),
so there is a (Ill)-correspondence
between leaves and
solutions.
generally,
for any vertex v of Z’,(x)
there is a (l-l)-
correspondence
between the solution
set R(inst(v))
and the leaves of the
subtree rooted at v. The bounds on (T and + in the definition
of self-reducibility
ensure that
is bounded
lR(x) = O((xlk”),
and that the number
of children
of any vertex is also
polynomially
In order to infer the structure of the tree of derivations,
it is clearly
necessary to solve the existence problem
for the relation in question. Since
we will not always be able to do this with certainty, it is useful to define
self-reducibility
except that
the restriction
R(@(z, w)) # 0
in the definition
of W(v) is removed.
contains TR(x) as a subgraph and their labels agree. All solutions in R(x)
still occur precisely once as labels of leaves of p,(x),
but there may be
other leaves whose partial solution
labels are not in R(x).
The depth and
vertex degree of FR(x) remain polynomially
bounded as before.
Most known uniform generation
algorithms
for combinatorial
structures
 may be viewed as instances of the
generic reduction
to the corresponding
APPROXIMATE
that the structures are described by a self-reducible
relation R, select a
random path from the root of the tree of derivations
to a leaf (solution),
each stage choosing the next edge with probability
proportional
number of solutions
in the maximal
subtree rooted at its lower end. This
information
may be obtained from a counter which evaluates the function
#R for appropriate
instance labels in the tree. By appending
correction
process based on the a posteriori
probability
of the path, this
procedure can be made to work even if the counter is slightly inaccurate,
specifically
if it is within
1 + O(nekR), where k, > 0 is a constant
satisfying iR(x) = O(lxlk”)
 .
Furthermore,
if the counter
is randomised
then a Ep. almost uniform
generator is still obtained.
(In the latter case we have to work with the self-
reducibility
tree rather than the tree of derivations.)
Since a f.p. almost
can itself be used to construct
a polynomially
randomised
approximate
counter within
1 -t K@ for any
desired p E R, counters within
the threshold
1 + O(n -““)
bootstrapped
to achieve arbitrarily
good asymptotic
al., 1986).
cruder counting
information
is available
(to within
constant factor, say) the above “one-pass” technique breaks down owing to
the accumulation
of errors which are too large to be corrected. We will
self-correcting
in which a
process moves dynamically
the tree, with backtracking
allowed. The generator we will construct in Section 4 views the vertices of
the tree of derivations
as the states of a Markov
chain ,&Y?(x) in which
there is a non-zero transition
probability
between two states iff they are
adjacent in the tree. The transition
probabilities
themselves are computed
with the aid of the crude approximate
counter. Clearly
all states com-
so that, leaving aside questions of periodicity,
if the chain is
allowed to evolve for t steps from any initial
state the distribution
final state approaches
stationary
distribution
as t + co. Now
suppose that this distribution
is uniform over the leaves of the tree. Then
we get an almost uniform generator by simulating
the chain for sufficiently
steps starting
at (say) the root and, if the final state is a leaf,
outputting
the corresponding
The efficiency of this procedure will of course depend crucially
rate of convergence of the chain. In particular,
since the size of the tree is in
general exponential
in 1x1, we require
the chain to be very close to
stationarity
after visiting only a small fraction of its states. There appear to
be no quantitative
results in the literature
which would readily provide
useful analytic bounds on the rate of approach to stationarity
in this case.
Accordingly,
in the next section we develop a characterisation
convergence,
in a suitably
defined sense, for a broad class of Markov
SINCLAIR AND JERRUM
chains. This will enable us to show in Section 4 that the almost uniform
generation
procedure sketched above is in fact fully polynomial.
The Markov
chain approach
generation
also points to a fundamentally
different strategy which appeals neither to
self-reducibility
nor to counting.
Here transitions
are made more or less
between solutions
by means of local perturbations,
in a manner
suggested by Broder
 and familiar
from Monte
Carlo studies in
statistical physics . We can also consider generating solutions
from more general distributions
appropriate
adjustments
stationary
distribution
of the chain. The machinery
developed in the next
section can be used to analyse Markov
chains of this kind as well: for
applications,
the reader is referred to . First, we establish some’ terminology
and quote some
basic facts.
Let the sequence of random
variables (X,),““_, be a time-homogeneous
chain on a finite state space [N] = (0, 1, . . . . N-
1 }, NB 1, with
transition
P = (pii)&\.
(All Markov
chains in this paper will be
assumed to be of this form.) Thus for any ordered pair i, j of states the
quantity pij = Pr(X, + , = j ( X, = i) is the transition probability
from state i to
state j and is independent
of t. The matrix P is non-negative
and stochastic,
i.e., its row sums are all unity. For SEN,
the s-step transition
simply the power P” = (PC)); thus p$) = Pr(X, + s = j 1 X, = i), independent
t. We denote the distribution
of X, by the row vector rc(‘)‘= (rc~~))~&‘, so
rr!‘) = Pr(X
II (O)’ denotes
the initial
distribution,
II(‘)’ = kCo)‘Pr for all t E N. Usually
we will have rrj”) = 1 for some iE [IV]
(and 0 elsewhere); i is then called the initial
The chain is ergodic if there exists a distribution
R’ = (n,) > 0 over [ZV]
lim p!?) = 71.
Vi, jE [IV].
In this case, we have that R(‘)’ = aco”P’ -+ II’ pointwise as t + co, and the
is independent
(O)’ The stationary
distribution
II’ is the unique
vector satisfying a’P=
tr’, Ci rri = 1, i.e., the unique normalised
left eigen-
vector of P with eigenvalue
1. Necessary and sufftcient conditions
ergodicity
are that the chain should be (a) irreducible, i.e., for each pair of
APPROXIMATE
states i, Jo [N],
there is an s EN such that p:) > 0 (j can be reached from i
in a finite number of steps); and (b) aperiodic, i.e., gcd(s: p!) > 0} = 1 for
all i, jE [N].
Suppose now that we wish to sample elements
of the state space,
assumed very large, according
to the stationary
distribution
arises frequently
in the mathematical
of physical
systems, where states correspond
to configurations
of the system and
appropriate
functions of the stationary
process to physical constants or
parameters
fundamental
stochastic
optimisation
techniques such as simulated
 . In the applications
we have in mind here, some of the
states can be identified
with certain combinatorial
structures of interest and
rr’ is uniform
over these states. However, our approach will address the
general problem.
The desired distribution
can be realised by picking
an arbitrary
state and simulating
the transitions
of the Markov
chain according to the
probabilities
pii, which we assume can be computed locally as required. As
the number t of simulation
steps increases, the distribution
of the random
X, will approach
rc’. Clearly, for this process to be effective it is
necessary to know a priori how many steps are required to achieve a dis-
sufficiently close to R’ for our purposes, or in other words to have
some bound on the rate of convergence of the chain. As a time-dependent
of deviation
the limit,
we define the relative pointwise
distance (r.p.d.) over a non-empty
subset US [N]
after t steps by
Thus d U (t) gives the largest relative difference between rr(‘)’ and rr’ at any
state Jo U, maximised
over all possible initial
states iE ZJ.’ The inclusion
the parameter
U merely allows us to specify that certain portions
state space are not relevant in the sampling
process, as will prove helpful
later. The aim of this section is to obtain a useful upper bound on A, as a
function of t. In particular,
we want to investigate conditions
under which
convergence is rapid in the sense that A CN3(t) becomes very close to 0 while
t 4 N: this is sometimes referred to as the “rapid mixing”
property has been chosen by analogy with our definition of almost uniform
generation in Section 2. We could alternatively have used a measure based on the variation
namely d;(r)
= maxiE u x,Ipt’
- nj[jl. F or most interesting chains, this choice makes
no essential difference to the rapid convergence criterion.
chains have recently been proposed by other authors. Methods
based on coupling
1981) and stopping
1986) are attractive
and yield tight bounds for simple chains,
such as random walks on hypercubes and various card-shuflhng
processes.
However, the analysis involved
appears to become extremely
complex in
more interesting cases where the chain lacks a highly symmetrical
structure.
The approach used here based on the eigenvalues of the transition
more classical, but seems hitherto to have been of little practical value. Our
contribution
is to develop from it a simple yet powerful tool for obtaining
good analytic bounds for a broad class of chains. Crucially,
we will be able
to apply this tool to chains which have not proved amenable to analysis by
other means.
An ergodic Markov
chain is said to be time-reversible
if either (and
hence both) of the following equivalent
conditions
For all i, jE [TV], pii~i=pjjnj.
The matrix
is symmetric,
where D’12 is the diagonal
matrix diag(7chi2, . . . . 7crp i) and D- ‘I2 is its inverse.
(i) says that in the stationary distribution
the expected numbers
of transitions
per unit time from state i to state j and from state j to state i
are equal, and is usually called the “detailed
balance” property. As we shall
see, time-reversible
chains are particularly
susceptible to detailed analysis,
and for this reason play a major
role in applications
where a rigorous
quantitative
is necessary (see, e.g., Keilson,
It is illuminating
to identify
an ergodic time-reversible
chain with a
weighted undirected
graph containing
self-loops as follows. The vertex set
of the graph is the state space [NJ of the chain, and for each pair of states
i, j (which need not be distinct) the edge (i, j) has weight wii= nipii=
By detailed balance this definition
is consistent. Thus there is an edge of
non-zero weight between i and j iff pii > 0. We call this graph the underlying
graph of the chain. It should be clear that such a chain is uniquely specified
by its underlying
As already stated, the stationary
distribution
rr’ of an ergodic chain is a
left eigenvector
of P with eigenvalue 1, = 1. Let { &: 1 < i < N-
Ai E C, be the remaining
eigenvalues (not necessarily distinct) of P. By stan-
dard Perron-Frobenius
theory for non-negative
matrices (Seneta, 198 I),
these satisfy (Ai1 < 1 for 1 < i< N-
1. Furthermore,
the transient behaviour
of the chain, and hence its rate of convergence,
is governed
of the eigenvalues 2;. In the time-reversible
case, condition
of the definition
that the eigenvalues of P are just those of the
- ‘I’, and so are all real. This fact leads to
a clean formulation
of the above dependence.
APPROXIMATECOUNTING
PROPOSITION
Let P be the transition
of an ergodic time-
reversible Markov
chain, 11’ its stationary distribution
and (Ai: 0 6 i 6 N - 1 }
its (necessarily real) eigenvalues, with A,, = 1. Then for any non-empty subset
and all t E N, the relative pointwise distance A,(t)
mini, U rcj’
where A,,,, =max{l&(:
Let D ‘I* and D ~ ‘I2 be as in the definition
of time-reversibility,
that the matrix
A = D”*PD-
‘I* is symmetric
with the same eigenvalues as
these are real. Hence
we can select an orthonormal
(e”“:O<i<N-l)
for RN consisting
of left eigenvectors
of A, where
e(j)’ = (ej!‘)) has associated eigenvalue Izi and e,!‘) = rc,!/* for Jo [N].
1979) A has the spectral representation
where EC’) = e”‘e”)’ is a dyad (i.e., has rank 1) with E(‘)E(j) = 0 for i # j, and
ECi)* = EC’). It follows that, for any t E N, A’ = xi A: EC’), and hence
p’= D-l/*A’D’/*
l/*e(‘))(e(‘)‘D”*)
= 1 No’ + c
~f(D~1/2e(i))(e(i)‘D1’2),
where 1 N is the N-vector all of whose entries are 1; in component
By definition,
the r.p.d. A,(t)
is therefore given by
where the second inequality
follows from the Cauchy-Schwarz
inequality
SINCLAIR AND JERRUM
 and
the orthonormality
Proposition
3.1 says that a time-reversible
chain will be rapidly
mixing in the sense indicated earlier provided that a’ is not extremely small
in any state of interest and that A,,.,,, is bounded away from 1. The first of
these conditions
can be checked immediately
from our knowledge of n’ and
is rarely violated
in practice. We therefore focus our attention
second condition,
which is not so easily handled.
(Note that P is a large
evaluation
of the eigenvalues
feasible.)
Suppose the eigenvalues
of P are ordered so that 1 = 1, > I, >
A,- i > - 1. Then the value of A,,, is governed by 1, and A,-, , the latter
being significant
only if some of the eigenvalues are negative. Negative
eigenvalues
correspond
to oscillatory,
or “near-periodic”
cannot occur if each state is equipped
with a sufficiently
large self-loop
probability.
Specifically, it is enough to have min, P,~ B +. To see this, let I,
denote the Nx N identity
and consider the non-negative
2P - IN, whose eigenvalues are pi = 2A; - 1. By Perron-Frobenius,
for all iE [N],
which implies that A,,-, > 0.
In fact, negative eigenvalues never present an essential obstacle to rapid
because any chain can be modified
in a simple way so that the
above condition
holds without risk of slowing down the convergence too
PROPOSITION
Let P be the transition
of an ergodic time-
reversible Markov
chain, and 1 = & > 1, > . . > 1, _ , > - 1 its eigenvalues.
Then the modified chain with transition matrix P’ = +(I, + P) is also ergodic
and time-reversible
with the same stationary distribution,
and its eigenvalues
{A:}, similarly
ordered, satisfy Ah_, > 0 and Ai,, = A’, = $(l + A,).
From the above discussion, it is sufficient for rapid mixing
to bound the
second eigenvalue A, away from 1. We shall do this by relating A1 to a more
accessible structural
property of the underlying
Intuitively,
we would expect an ergodic chain to converge rapidly if it is
to “get stuck” in any subset S of the state space whose total
stationary
probability
is fairly small. We can formalise
this idea by con-
sidering the cut edges which separate S from the rest of the space in the
underlying
graph, and stipulating
that these must be capable of supporting
a sufficiently large “flow” in the graph, viewed as a network. With this in
mind, for any non-empty
subset S of states with non-empty
complement
we define the quantity
Gs= Fs/Cs, where
APPROXIMATE
the capacity of S;
the ergodicflow out of S.
0 <F, < C, < 1. Qs may
be visualised
as the conditional
probability
that the stationary
process crosses the cut from S to S in a
single step, given that it starts in S. Finally,
we define the global conduc-
tance of the chain by
It is easy to see that F,= Fs for all such sets S. This implies
Gs= GsCs( 1 - C,)-‘,
so we may equivalently
Now suppose that the chain is time-reversible,
and let G be its under-
lying graph. Then for all S as above we have
a function of the edge weights of G. The conductance @ E Q(G) may then
be viewed as a structural property of the weighted graph G. In view of the
above remarks, we might hope that Q(G), which in some sense measures
the minimum
relative connection
strength between “small”
subsets S and
the rest of the space, has some bearing on the rate of convergence of the
relationship
is manifested
via a bound
on the second
eigenvalue 1 i .
3.3. For an ergodic time-reversible Markov chain with underlying
graph G, the second eigenvalue I, of the transition matrix satisfies
Let e’ = (ei)y=Wo’ be an eigenvector
of P with associated eigen-
value ?, < 1, and define the matrix
Q = IN - P (the “Laplace
associated with P). Then clearly
e’Q = (1 - A)e’.
Define the subset of states S= {in [NJ: ei > O}. It is easy to check that,
since P is stochastic and A< 1, xi ei = 0. Hence 0 < 1 SI < N, and we may
assume without loss of generality that C, = xi, s ni d 4. Now let 6’ = (Ci) be
the vector defined by
otherwise.
Renumbering
states as necessary, we shall assume that to 2 t, 2 . . >
t, _ I, which implies also that S = (0, 1, . . . . r ) for some r with 0 < r < N - 1.
the scalar product of (1) with 6’ gives
(e’Q, 2’) = (1 - A)(e’, e’).
The right-hand
side of (2) is just
Note that if Q= (qv) then qii= -pii for i#j,
and qii= 1 -pii=cj+ipii,
we can expand the left-hand side of (2) as
w,i(ci-eTj)2,
where the inequality
follows from the fact that all contributions
are positive. Using (3) and (4), Eq. (2) therefore yields
wij(ci-gj)2
Now consider the sum
c wi,(c+~j)2,<2
c w,(f?f+$)<2
APPROXIMATE
this with (5) gives
1-A,Zi<jwij(ei-6j)’
~~i<jwij(‘i+~j)*
2 CiE s I@;
~i<jwij(E:-~;)
CiES7tie^f
where we have used the Cauchy-Schwarz
inequality.
To complete
proof, we need to relate the quotient
in (6) to the quantity
Q(G). To do
this, consider
the increasing
sequence (S,); =0 of subsets of S with
Sk = { 0, . . . . k}. The numerator
of the quotient
in (6) may be expressed in
terms of ergodic flows across the boundaries
between successive sets Sk as
= k;. (3 - 3 + 1) *x.sk wii
Now the capacities of the Sk satisfy C, d Cs < f for 0 6 k < r, and hence by
definition
of 0, F, 2 Q(G) Csk. We therefore get from (7)
This inequality
ensures that the quotient
in (6) is bounded below by D(G),
so that finally
as required.
SINCLAIR AND JERRUM
Propositions
3.1 and 3.2 and Lemma
3.3 we arrive at the
main result of this section, which says that the number of steps required for
an ergodic time-reversible
chain to lose its memory
stationarity)
is 0(@(G)-2
lg(l/n ,,,)),
where G is its underlying
nmin the minimum
stationary
probability
of any state. Thus, under mild
assumptions about the stationary distribution,
convergence is rapid if Q(G)
is not too small.
THEOREM 3.4. Let G be the underlying graph of an ergodic time-rever-
sible Markov chain, modified iSnecessary as in Proposition 3.2 to ensure that
min, pii > 4, and A’ its stationary distribution. Then for any non-empty subset
U c [N] and all t E N, the relative pointwise distance A,(t)
< (1 - @(G)*P)
Remarks. (a)
3.4 has a converse which states that, under the
same assumptions,
> (1 - 20(G))’
 . Hence we effec-
tively have a characterisation of rapid mixing for time-reversible
terms of the graph-theoretic
@. (Note however that this does not
cover cases in which rci is extremely
small for some i. Such chains may
exhibit a range of convergence behaviour
regardless of the value of @b(G).)
In the interest of simplicity,
we have appealed to the rather crude
device of Proposition
3.2 for eliminating
negative eigenvalues: the effect of
this operation
on the conductance is to reduce it by a factor of t. In prac-
tice it may often be possible to reason about negative eigenvalues on an ad
hoc basis for the chain at hand. Proposition
3.1 and Lemma
3.3 may then
be used directly to get a bound on A,(t).
3.3 and its proof parallel an earlier continuous
Cheeger for Riemannian
manifolds.
In the discrete setting,
lemma and its converse are closely related to recent work of Alon 
and Milman
 in which a
relationship
between a similar
structural
of simple,
unweighted
graphs and the second eigenvalue
of the adjacency matrix
is established.
This property, called the magnification, measures the minimum
vertices adjacent
to a small
subset S as a fraction
of ISI, and is a
generalisation
of the widely studied
concept of expansion for bipartite
graphs. Our conductance @ is a weighted edge analogue of magnification,
and is the natural
to study in the present application.
significance of Alon’s result as a sufficient condition
for rapid mixing
certain Markov
chains has been noted by several authors; in particular,
Aldous states a restricted form of Theorem
3.4 for random walks on
APPROXIMATE
regular graphs. Our characterisation
based on the conductance
provide a cleaner and more natural
formulation
of this connection.
recently, Lawler and Sokal have independently
discovered results
to those presented in this section but in a rather more general
3.4 allows us to investigate
the rate of convergence of a time-
reversible chain by examining
the structure of its underlying
graph. For
this will typically
of the form
@P(G) = Q((lg N))k)
as the number N of states increases, for some constant
k. The exciting
feature of this characterisation
is that, with a bit more
work, suitable conductance bounds may actually be derived analytically
a number of interesting chains. In this way we are able for the first time to
establish the rapid mixing property for chains which lack a high degree of
and which have not proved amenable
to analysis by other
methods. In the next section, we show how this can be done for the chain
based on the tree of derivations
at the end of the last section.
applications
may be found in Jerrum
and Sinclair
 and
Sinclair .
4. REDUCTIONS
We return now to the main theme of this paper, namely the construction
of an efficient almost uniform
generator for a self-reducible relation
only very approximate
information.
Let R SC* x C* be self-reducible,
and x E Z* a problem
instance with
R(x) # a. As advertised in Section 2, our aim is to set up an ergodic
whose states are the vertices of the tree of
derivations
TR(x) and whose stationary
distribution
is uniform
leaves of the tree.
The chain is based on an elaboration
of the standard reduction
uniform generation to exact counting indicated at the end of Section 2. We
may view the counter in this reduction as assigning to each edge of the tree
of derivations
an integer weight equal to the number of leaves in the sub-
tree rooted at its lower end; the process is then a transient Markov
which the transition
probabilities
from any vertex (state) to its children are
proportional
to the corresponding
edge weights. Suppose now that the
process is no longer
constrained
but may also
from any vertex to its parent, the transition
probabilities
adjacent vertices being proportional
to the edge weights: thus from any
vertex upward and downward movements
are equally likely. To
periodicity,
we add to each state a self-loop probability
643/82/l-8
Viewing this process as a symmetric
random walk with reflecting barriers
on the levels of the tree, it is easy to see that it converges rapidly
(essentially in time polynomial
in the depth of the tree) to a stationary
distribution
which is uniform
over levels and also uniform
over leaves.
Hence a short simulation
of the chain generates leaves almost uniformly,
and the probability
of failure can be made small by repeated trials. Now
suppose that we have available only an approximate
counter for R, so that
the edge weights in the tree are no longer accurate. Then we have grounds
for optimism
that this procedure might
still work efficiently:
the hope is
that, since each edge weight influences transitions
in both directions,
process will actually be self-correcting.
polynomially
time-bounded
approximate
counter G9 for R within ratio p(n) = 1 + O(n’) for some c1 E R.
Thus the error ratio in %?’ need not even be constant,
but may increase
polynomially
with the problem
size. Note
first that,
since R is self-
reducible, %’ can always be modified
so as to give an exact answer (which
will be either 0 or 1) when its input is an atom; also, its output may always
be rounded up to the nearest integer at the cost of adding at most 1 to p.
We shah assume throughout
this section
%’ incorporates
modifications.
We may also assume without
loss of generality
monotonically
increasing. To begin with, we shall consider the case where
@ is deterministic;
the additional
technical problems posed by randomised
counters will be dealt with later.
For a problem
instance x as above, let V, E be the vertex and edge sets
respectively of TR(x), and set rn = IR(x), r = p( 1x1). Note that both m and r
are polynomially
bounded in 1x1, and that the depth of the tree is at most
m. For each edge (u, v) E: E define the quantity
if u is the parent of u;
otherwise.
(Recall that inst( .) gives the problem
instance associated with any vertex of
the tree.) Since 59 is deterministic,
f: E + N + is a well-defined function
E. The crucial property
to bear in mind is that for any edge P E E, f(e)
approximates
within ratio
r the number of leaves in the maximal
Next we define for each vertex u G V a degree
u:(u.c)r E
Note that d(u) 2 1 for all 21 E V, and that 4 v) = 1 if v is a leaf because %? is
APPROXIMATE
exact for atoms.
For each ordered
pair u, u of vertices, the transition
probability
p,, from v to u is then defined to be
f(u, ovwv),
(24, v)EE;
otherwise.
Thus there is a non-zero transition
probability
between two states iff they
are adjacent in the tree. The self-loop probability
f ensures that the chain is
aperiodic. It is clearly also irreducible,
and hence ergodic, and it is a simple
matter to verify that the stationary distribution
rc’ = (E,),~ &, is proportional
to the degrees, i.e.,
where D = C,, ,, d(u).
Let us first check that sampling
from V according to the distribution
does in fact give us an efficient generation
procedure for R, so that the
of the previous section applies. Since leaves of the tree corre-
spond to solutions,
while other vertices must necessarily correspond
failure of the generator, we have to verify that I’ is uniform and sufficiently
large over the leaves. (Recall that an almost uniform
generator must have
bounded failure probability.)
Uniformity
follows directly from the fact that
d(u) = 1 for all leaves u, so x, = l/D.
this is not too small
consequence of the following
In the stationary distribution of A%?(x), the probability of
being at a leaf is at least 1/2rm.
Observe that the degree sum D over the tree T,(x)
D= 1 d(u)=2
Now consider the collection
of edges at some fixed level of the tree. By (8)
the weight of each such edge approximates
within ratio r the number
leaves in the maximal
subtree rooted at its lower end. Since these subtrees
are disjoint,
the aggregated weight of all edges at this level is at most
r #R(x). Summing
over all levels of the tree yields the bound
D = 2 1 f(e) d 2rm #R(x).
SINCLAIR AND JERRUM
Since 71, = l/D for each leaf u, the stationary
probability
of being at a leaf is
as claimed.
Recall that m and r are each polynomially
bounded in 1x1, so the failure
probability
can be reduced to $ by repeating the entire experiment
polynomially
many times.
We now adress the trickier
question of the rate of convergence of the
for the moment
an efficient
simulation
from some initial
state can be performed.
It is easy to see that
the chain is time-reversible
by virtue of detailed balance.2 We will therefore
try to estimate the conductance 0 of its underlying
graph, as defined in the
previous section, and appeal to Theorem
4.2. Let G be the underlying graph of the Markov chain A?‘%(x)
defined above. Then the conductance of G satisfies
Q(G) > (4r2m)-‘.
(u, u) E E
v)/20, while the loop at u has weight d(u)/2D and all other edges
have weight zero. In what follows, we will identify subsets of V with the
subgraphs of TR(x) which they induce. If Ss V is a subtree (connected
of TR(x), we let root(S)
denote the vertex of S at minimum
distance from root(V),
the root of T,(x).
In order to bound the conductance
of G, we claim that it suflices to
consider flows out of all subtrees S with root(S) # root(V).
(Informally,
process will converge fast because it is quite likely to emerge from any such
subtree, travelling
upwards, within a small number of steps.) To see this,
note first that Q(G) 3min
Qs, where the minimisation
is over all non-
empty subsets SE V with root( V) # S. But we may write any such S as the
union TO u . . . u T, of disjoint
subtrees no pair of which is connected by an
edge in 7’,Jx), and we have
~ss~-~i FTt
>min-=min@T,.
Hence it is clear that Q(G) 2 min Qs, where the minimisation
is now over
all subtrees S of T,Jx) with root(S) #root(V),
as claimed.
* This is actually
also an immediate
of the fact that
is a free process,
the edges corresponding
to non-zero
transition
probabilities
APPROXIMATE
A lower bound on Gs for such subtrees is readily obtained.
assume without loss of generality that S is maximal.
Then the flow out of S
is just Fs =f(cut(S))/20,
where cut(S) is the cut edge connecting
rest of the tree. But sincef(cut(S))
approximates
the number of leaves L(S)
in S within ratio r, the flow is bounded below by
On the other hand, summing
edge weights in the subtree S as in the proof
of Lemma 4.1, we may easily derive the bound
“Fs d(u) =.f(cut(S)) + 2 1
f(e) G 2rmWh
where E( 5’) is the set of edges in S. Since Cs = C,, s d(u)/D, putting
and (14) together yields
which completes the proof of the lemma.
Since both m and r are at most polynomial
in the problem
size 1x1, the
bound in Lemma
4.2 is sufficient to ensure that the chains .,&Z(x)
rapidly mixing.
More precisely, for each x E C* with R(x) # 121, let d’“‘(t)
denote the r.p.d. of J@%(X) over the whole state space V after t steps. Then
4.3. There exists a function q: C* x R+ + N such that q(x, E) is
polynomially bounded in 1x1 and lg EC’,
and for each XE Z* with R(x) # a,
d’“‘(t)6~/2
for all t>q(x,E).
For each such x, the chain &V(x)
satisfies the conditions
3.4. Furthermore,
we have seen that min,,
y rry = l/D, which by
(12) is bounded below by (2rmlZI”))‘.
(Note that solutions are strings of
length m over the alphabet
C, so #R(x) < ICI”.)
and using the bound on Q(G) obtained in Lemma
4.2, we get
d’“)(t) < 2rmlCI” (1 - (32r4m2)-I)‘.
The function q defined by
q(x, s) = 32r4m2(ln(2rm)
+ m 1nlZI + ln(2/.s))
then clearly satisfies the requirements
of the lemma.
SINCLAIR AND JERRUM
We are now in a position
to state the first major result of this section.
4.4. Let R GZ* x C* be self-reducible. If there exists a
polynomially time-bounded (deterministic) approximate counter for R within
ratio 1 + O(n’) for some tl E R, then there exists a fully polynomial almost
uniform generator ,for R.
Let V be the approximate
counter for R as specified above. We
proceed to construct an almost uniform
generator 9 for R which uses % as
an oracle.
On inputs (x, E) E C* x R +, 9 initially
calls % with input x and halts
with output
? if %(x)=0,
which is the case if and only if R(x)= 0.
Otherwise, 9 simulates
the Markov
chain J%?(x) defined above, starting
at the root
definition
the transition
probabilities
from any state can be computed
by appropriate
calls to V
since we may easily keep track of the problem
instance labels of the ver-
tices. (Note that we are also inferring the structure of the tree locally in the
process.) The simulation
halts after q(x, E) steps, where q is the function
specified in Lemma
4.3, outputting
the corresponding
if the final
state is a leaf and ? otherwise. Since the degree of the tree is bounded by a
polynomial
in 1x1 and all problem
instance labels have size at most 1x1,
each step can be simulated
in polynomial
time. Together with the bound
on q from Lemma 4.3, this ensures that Y always halts in time bounded by
a polynomial
in 1x1 and lg E ‘.
Now let 9(x, E) be the output
variable of Y on inputs (x, a).
$9 only ever outputs
solutions,
so Pr(Y(x, E) = y) = 0 if
since the chain
has been allowed
to evolve for
sufficiently many steps, we may deduce from Lemma 4.3 that
for any solution
y E R(x), where D depends only on x and is defined at
(11). Assuming as we may that E < 1, this ensures that the bias is within the
required bound E. Finally,
if R(x) # 0 Lemma 4.1 implies that
a) = ?) d (1 - 1/2rm)( 1 + s/2).
further that
E < l/rm, this bound can be reduced to l/e < l/2
using only (2rm)2 iterations
of the procedure 9.
If the approximate
counter in Theorem
4.4 is randomised as defined in
Section 2, so that it may occasionally
produce arbitrarily
bad results, the
reduction still goes through but at the cost of some tiresome technicalities.
We summarise
the proof in this case.
APPROXIMATE
4.5. The result of Theorem 4.4 still holds even if the
approximate counter for R is randomised.
Proof (sketch).
Let x be a problem
instance for which R(x) # Qr. As
before, assume p is monotonic
and set m = I,(x),
r = p( 1x1). We begin by
considering
the intermediate
case where the counter 9? is randomised
always produces estimates which are within ratio r of their correct values.
We again define a Markov
chain J%?(x) on the tree TR(x), whose tran-
probabilities
are determined
as follows, Suppose the process is
at vertex v, and let U be the set of children
of v. For each
UE Uu (v}, make a call %?(inst(u)) to the counter and denote the result
c(u); then make a further inde~ndent
set of calls ~(inst(~))
for the same
vertices u and denote their sum d(v). Finally,
make a transition
adjacent vertex u with probability
c(u)/4r2d(~),
if u is a chiid of u;
c(v)Pr*d(u),
if u is the parent of v,
and remain at u otherwise. (Note that the factor 1/4r* ensures that these
transitions
are always well defined, and that there is a self-loop probability
of at least 4 in each state; we have used a rather than 4 for consistency with
the second part of the proof.) Clearly, if %? is deterministic
this reduces
(except for a uniform
factor of 1/2r*) to the original
chain. In the ran-
domised case, it is easy to see that the transition
probability
puu from v to u
is actually the expectation
where the random variablef(u,
v) is defined as in (8) and is independent
d(v). The stationary
distribution
R’ therefore satisfies
rr, cc l/E(d(v) -‘)
and the fact that %? is exact for atoms implies that d(v) = 1 with probability
1 for leaves v. The chain is clearly still time-reversible,
and the rest of the
proof goes through
essentially as in the deterministic
case, with d(u) and
f(u, u) replaced by l/E(d(v)-‘)
and E(f(u, Y)) respectively.
Now suppose that the counter may in addition
produce arbitrarily
results with some small probability
6: by Lemma
2.1 we may assume that
6 < 2-P(IXi) for all problem
instances in the tree, where p is any desired
polynomial.
Since we are no longer able to infer the structure of TR(x) with
certainty,
we must now work in the larger self-reducibility
tree TT,(x) (cf.
Section 2). We let V, P denote the vertex sets of TR(x) and T,(x)
tively. Note that p\V consists of a union of disjoint
subtrees of
modifications
transition
probabilities
necessary. At vertex u E v, we compute
values c(u), for u E U u (u}, and
d(v) as before, where now U is the set of children of u in ?,Jx). If d(u) = 0
then we make a transition
to the parent of u (if it exists) with probability
probability
a. Otherwise,
we test whether
C,c(z4)>4r2d(u):
i so, we remain at o; if not, we make a transition
neighbouring
vertex with probabilities
as in (15). (Note that the self-loop
probability
in each state is at least t.) Once again, the leaves of T,(x)
treated as a special case.
This chain is clearly ergodic on some subset of v containing
those states which communicate
with the root. Henceforth we redefine v to
include only such states. The chain is also still time-reversible
because it is
a tree process. Let us first observe that the new vertices in P\V
negligible
effect. All transitions
from V to v\V
occur with at most tiny
probability
6, so if started in V the process is unlikely
to leave V during the
course of the simulation.
Should it enter a subtree in v\V,
however, the
d(u) at the root vertex u will take the value 0 with
probability
very close to 1, thus causing the chain to leave the subtree
rapidly. In fact, it is not hard to see that thestationary
probability
vertex u E 8\ V is at most O(@), where k is the distance of u from V in
FR(x). As a result, the total weight of r\V
in the stationary
distribution
Furthermore,
the large exit probability
subtrees SG v\V
ensures a lower bound on Qs similar to that in the proof of Lemma 4.2.
Examination
of the transition
probabilities
within V reveals that we can
view this portion
as a chain of the restricted kind described in the first part
of the proof whose transition
probabilities
have been perturbed by a factor
in the range (1 f 6’), where 6’ depends on 6 and can be made exponentially
small, It is then easy to see that the stationary
probabilities
of states in I’
undergo similarly
small perturbations
in the range (1 f d’),. As a result, a
lower bound as in the proof of Lemma 4.2 also holds for subtrees S with
root(S) E V, and so for all subtrees, which again implies
that the conduc-
tance Q(G) is suitably bounded below. Assuming that the simulation
at the root, we therefore get rapid convergence over the subset V of the
state space,3 which is sufficient since V includes all leaves of TR(x). A test
applied to leaf labels ensures that no non-solutions
are output.
There is actually a simpler way to prove Theorem 4.5, though
the resulting algorithm
is less natural and the process is no longer strictly a
chain. Note
that the simulation
of Theorem 4.4 can still
precisely,
as defined
in Section
3.4 implies
a sufficient
to this measure
APPROXIMATE
using a randomised
if we arrange to remember the
of the counter on all previous calls so that each edge weight is
at most once. Provided
all values returned by the counter are
accurate within
the given ratio,
we are effectively in the situation
4.4 and our earlier analysis applies. By powering the counter, we
can ensure that this condition
fails to hold with very small probability,
the effect on the overall process will be negligible.
Theorem 4.5 has an interesting consequence for counting problems. First
let us generalise our notion
of approximate
to allow the error
ratio in the estimate to be specified as part of the input. If R is a relation
over C, then a randomised approximation scheme for #R is a probabilistic
V whose output
(x, E) E Z* x R+ is a non-negative
real-valued
random variable 3(.x, E) satisfying
Pr(%(x, E) approximates
#R(x) within ratio 1 + E) > t.
59 is a fzdly polynomial randomised
approximation
scheme (fpras) if it runs
in time bounded by a polynomial
in 1x1 and E- ’ for all inputs (x, E). Note
that the definition
of fully polynomial
here differs from that for almost
generators in the absence of a logarithm.
Jerrum, Valiant,
and Vazirani
 show how to construct a fpras for
#R for a self-reducible relation
R given a Ep. almost uniform
generator for
R. In view of Theorem
4.5, this means that we can bootstrap
a very crude
counter for R to one with arbitrarily
good asymptotic
behaviour as follows.
polynomially
time-bounded
randomised
approximate
counter for R within ratio 1 + O(n’) for some real CI (which
we may think of as large). Then by Theorem 4.5 there exists a Ep. almost
generator for R, and hence by the above result of Jerrum et al. a
fpras for #R. (Recall that Jerrum et al. establish this only for c1< -k,,
small threshold
value as defined in Section 2.) We have therefore proved
our next result.
THEOREM 4.6. Let R E C* x Z’* be self-reducible. If there exists a
polynomially time-bounded randomised approximate counter for R within
ratio 1 + O(n’) for some CI E R, then there exists a fully polynomial ran-
domised approximation scheme for #R.
The chief significance of Theorem 4.6 is that it establishes a notion
approximate
which is robust with respect to polynomial
computation,
at least for the large class of self-reducible
relations:
randomised
approximate
I+ O(n’) can always be
to one within ratio 1 + n pb for any desired real /I with at most a
polynomial
increase in runtime.
Thus we are justified
in classifying the
SINCLAIR AND JERRUM
counting problem for a self-reducible relation R as tractable if there exists a
polynomial
randomised
which with
probability
approximates
to within some factor of the form 1 + 0( 1x1”), with
aER. We suggest that this notion will be useful in the future classification
of hard counting
as studied, e.g., by Stockmeyer
 and
Karp and Luby .
The bootstrapping
described in Theorem ,4.6 actually
holds for a rather trivial reason if the relation
R has a property which we
might call self-embeddability.
Informally,
R is self-embeddable
if there exists
an efficiently computable
function [ which takes a pair x,, x2 of problem
instances and embeds them in an instance 5(x,, x,), whose size is at most
linear in lx,1 and 1~~1 and whose solution
set is in (1-1)-correspondence
with the product
set R(x,) x R(x,).
An example
is the relation
associates with a directed graph G its set of (directed) Hamiltonian
the required embedding
function 5 takes a pair G,, G2 of graphs and adds
a new vertex u, together with edges from u to all vertices of G, and from all
vertices of G2 to u. To bootstrap
a counter for a self-embeddable
given a problem instance x we apply the embedding
construction
an instance z with #R(z) = #R(x) p(‘.“) for some suitable polynomial
then use the counter to approximate
#R(z) and take the p( Ixl)th
the result, which yields an improved
natural relations turn out to be self-embeddable,
there seem to be a number
of significant
exceptions
self-reducible
relations,
satisfiability
and natural
restricted versions of familiar
relations,
Hamiltonian
paths in planar graphs. Moreover,
the Markov
chain reduc-
tion technique presented here can sometimes be applied even in the absence
of self-reducibility.
Evidence for this is provided
by the relation
discussed in the next section, which is apparently
neither self-embeddable
nor self-reducible under the degree restrictions
imposed there.
4.5 can also be used to derive a surprising
bootstrap-
ping result for generators. Specifically, given a polynomially
time-bounded
generator for a self-reducible relation
R which is almost uniform
U( 1x1 PkR), where k, is a constant as above, it is possible to construct a f.p.
for R . The new generator
course achieves exponentially
small bias in polynomial
5. GRAPHS WITH SPECIFIED DEGREES
Given a sequence g = (g,, . . . . g, _ ,) of non-negative
integers, is it possible
to efficiently
generate labelled
graphs with vertex set . A generation
procedure would provide a
means of examining
graphs with a given number
vertices and given degree and investigating
their properties, about many of
which little
Furthermore,
it has recently
been shown by
 that generation
techniques
for labelled
graphs with a
given degree sequence can be used in the uniform
generation
of isomor-
phism classes of regular graphs.
 gives efficient
algorithms
for uniformly
generating
labelled cubic and degree-4 graphs on n vertices. However, these are based
on specific recurrence relations
and do not generalise easily to higher
degrees. A simpler
discussed in , and already
in the work of Bollob&
 , uniformly
generates labelled
regular graphs of arbitrary
degree k, but the probability
of failure remains
polynomially
only if k = @(log n)1’2). When the degree is per-
to increase more rapidly
with n, it seems difficult to generate the
graphs with anything
approaching
equal probabilities:
in the approach
 , for example,
the probabilities
associated with different
graphs may vary widely. Our method,
which relies on the reduction
developed in the previous section, requires only that k = O(~Z’/~)
and achieves a distribution
over the graphs which is asymptotically
close to uniform.
In keeping with our general approach, we begin by defining a relation
which describes the graphs of interest. For the sake of clarity, we shall not
refer in this section to an encoding scheme: it should however be clear how
to translate everything into the formal framework of Section 2. A (la&/led)
[n] = (0, . . . . n - 1 }
...> g, ~ ,) of non-negative
integers such that xi gi = 2e(g) is even,
and a graph on g is a graph with vertex set [n] in which vertex i has degree
gi, 0 < id n - 1. (All graphs here are assumed to be simple and undirected.)
SINCLAIR AND JERRUM
If the vertex set is understood,
we shall identify a graph with its edge set. It
is actually convenient to generalise the above problem
by allowing a set of
forbidden edges to be specified. Accordingly,
we define the relation
which associates with each problem instance of the form (g, X), where g is
a degree sequence on [n] and X is a labelled graph with vertex set [n], the
GRAPHs(g, X) = {G: G is a graph on g having no edge in common
We refer to X as an excluded graph for g. Although
this relation
as it stands, we get a more symmetrical
R defined by
{ (G, cu ): G E GRAPHS&,
X) and w is an edge-ordering
Clearly, we can move freely between these relations since any solution
e(g) ! ordered
of each element
GRAPHS(g, x).
Next we specify a self-reducibility
on R by defining the tree of derivations
T,(g, X), assuming that R(g, X) # 0. In this tree, the object (G, o)
be derived by successively adding the edges of G in the order determined
precisely, the partial
labels of the tree are in (l-l)-
correspondence
with pairs (H, w), in which Z7 is a graph with vertex set
[n] which can be extended to at least one graph in ciRAPr-rs(g, X), and o is
an edge-ordering
of fl. The root has label (0,
while the children
the vertex with label
have labels of the form
w + (i, j))
for some edge (i, j), where o + (i, j) denotes the extension of w
in which (i, j) is the largest element. The problem instance label of a vertex
u is determined
by its partial
w) as follows.
E = (I$, . . . . En- i) be the degree sequence of R, and define h = g - h, where
the subtraction
is pointwise. Also, let Y be the subgraph of Xv Z7 obtained
by deleting
all edges (i, j) for which either fii =gi
instance label of u is (h, Y).
that the deletion
of redundant
constraints
from Xu R is not
necessary for the consistency of the tree, but it will prove useful later-in
the proof of Lemma
Y represents only the essential excluded
graph. From
now on, we will in fact assume that all problem
(g, X> have had redundant
constraints removed. In particular,
this means
that the problem
instance label of the root of the tree is just (g, X). It also
justifies our use of e(g) as a measure of input size for this problem
stating approximation
results below.
Now that we have a tree of derivations
for R, Theorem 4.4 will give us
an efficient
for R, and hence for GRAPHS,
we can count
these structures
with sufficient
accuracy. The
APPROXIMATE
for GRAPHS has received much attention
over a number
of years, where the aim
has chiefly been to extend
the validity
asymptotic
estimates to a wider range of degrees . The best result available
to date is due to McKay,
quote this below.
a degree sequence g on [In] and an excluded graph X for g,
. . . . x,-r)
yk, X) = max{ sL,,, gmaxxmax >, where g,,, = maXi gi and x,,, = maXi xi.
We shall use y to express bounds on the degrees involved
in the problem.
Furthermore,
if g,,, > 0 set
1;: gi(gi-
,a, m = - 2eig) ,.zxgigj.
5.1 (McKay,
There exists Q positive constant r0 with
the property that, for any problem instance (g, X)
with g,,, > 0 and
y(g, X) < e(g)/lO, the quantity
e(g)! 2e(g) nl:d
g,! exp( - W
- 4g)* - Ag9 X)1
approximates #GRAPHS(g,
X) within ratio exp(r,y(g, X)2/e(g)).
Remarks. (a)
result is slightly stronger than this:
we have stated it in a simplified
form which is adequate for our purposes.
The estimate
in Theorem
5.1 immediately
leads to a simple
suggested by Wormald
 and implicit
in the earlier work of
 for generating graphs whose degrees grow slowly with the
number of edges: make gi copies of vertex i for each i, generate a pairing
(i.e., a perfect matching
in the complete graph on these vertices) uniformly
at random,
and then collapse the copies to a single vertex again. The result
will be a multigraph
on g, and the distribution
over caAPHs(g, X) is
but the procedure may fail since not all the graphs generated in
this way will be simple or avoid X. The exponential
factor in (16) can be
interpreted
as approximating
the probability
a randomly
yields an element
of GRAPHS(g, X). It is then clear from
definitions
of 1 and p that, provided y(g, X) = O(log e(g)), this probability
is polynomially
below, so that the method
is effective in this
range. For regular graphs, this implies a degree bound of 0( (log n)“‘).
Let us now restate Theorem
5.1 in a more convenient form.
5.2. Let Q, B be fixed
real numbers with Q > 0 and
B 2 100Q4. Then for all problem instances (g, X) for which either e(g) < B
or Yk, J3 6 Q*e(g)“*,
the quantity
can be approximated
polynomial
time within a constant ratio.
We have already observed that #R(g,
X) = e(g)! #GRAPHs(g,
SO we need only approximate
the latter. Note that when e(g) > B the bound
on y ensures also that y(g, X) < e(g)/lO, so we may appeal to Theorem
The expression in (16) can clearly be evaluated
in polynomial
yields an approximation
within the constant ratio exp(r,,Q4) in all relevant
cases, except when g,,, = 0 or possibly when e(g) < B. The first case is
to handle the second, observe that for fixed B there are only a
constant number of instances, up to relabelling
of the vertices, for which
e(g) d B, so all counting
in this range may be done exactly by explicit
enumeration.
(Alternatively,
in practice
any convenient
approximation
method may be used, subject to the proviso that it yields the answer 0 iff
# GRAPHS(g,
X) = 0: this property
can be tested in polynomial
time using
techniques.)
Now let us see whether Corollary
5.2 is powerful enough to allow us to
construct a generation algorithm
for GRAPHS
via the reduction
to counting
in Theorem
4.4. Ideally,
we might hope to handle instances for
as Q(e(g)“*).
immediately
since the relation
R is no longer self-reducible when restricted
in this way. In other words, even if g,,,
are suitably bounded, the
tree T,(g, X) will in general contain
vertices whose problem
(h, Y) are unbalanced in the sense that the degrees are rather large com-
pared to the number of edges e(h), so that we cannot guarantee reasonable
counting estimates over the whole tree. We will overcome this problem
naively pruning the tree in such a way as to leave only problem
which do fall within the bounds of Corollary
5.2, though we will have to
do a little work to check that the effects of this are not too drastic.
For any pair Q, B of real numbers
with Q > 0 and B b 100Q4, we
call a problem
(Q, B)-balanced
e(g) < B or
y(g, X) < Q?e(g)“*.
If (g, X) is (Q, B)-balanced
and R(g, X) # 0, then the
pruned tree Tkp.B)(g, X) with respect to Q, B is obtained
by deleting from
T,(g, X) each vertex whose problem instance label is not (Q, B)-balanced,
together with the entire subtree rooted at the vertex.
Now consider defining a time-reversible
chain &%‘(g, X) on the
tree in precisely the same manner
as in Section 4, using the
counting estimates of Corollary
5.2. Our first claim is that the conductance
bound of Lemma 4.2 still holds, so that .&‘$?(g, X) is rapidly mixing. To see
this, imagine a corresponding
chain on the complete tree T,(g, X) in which
all counting
are within
the constant
of Corollary
clearly, in this case the conductance
is bounded
as in Lemma
JP&?(g, X) is obtained
from this chain simply by deieting
some subtrees
APPROXIMATE
and, as the reader may readily verify, the removal of extremal portions of a
chain cannot
decrease its conductance.
Hence the bound
Lemma 4.2 applies to .NU(g, X) also.
We turn now to the effect of the pruning operation
on the stationary dis-
tribution.
As before, the distribution
will be proportional
to the “degrees”
d(u) defined as in (9) and can be made uniform
over leaves by counting
exactly at this level. (When we speak of “leaves” of the pruned tree, we
shall always mean those vertices which are also leaves of the original
T,(g, X).) However, since we have lost some leaves by pruning, it is by
means obvious that the induced distribution
on GRAPHs(g, X) obtained
forgetting
the edge orderings is even close to uniform,
or that the failure
probability
is still bounded. Both these facts will follow from the lemma
below, which says that in the pruning process we lose at most a small frac-
tion of the leaves corresponding
to any graph in GRAPHs(g, X) provided
that the constants Q, B are suitably chosen.
be a family
of problem
(g, X> satisfying
max 1 g,,, t xmax > = O(e(g)“4)
and /3 a real constant.
Then there exists
a pair of real numbers
Q, B as above (which
depend on 9
and /I) such
each GE GRAPHS(g, X),
the pruned
Tkp,B’(g, X)
e(g)!( 1 - e(g)-8/4)
leaues with solution label G.
We postpone
the rather technical
proof of this lemma
its consequences, which constitute
the central results of this
real b’, there exists
a polynomial
which generates elements of GRAPHS(g,
X) almost untformly
bias at most e(g))B,
that the degrees involved are bounded as
= W4g)“4).
We assume without
loss of generality
fl >/O and that
e(g) > 0. Let Q, B be real numbers satisfying the conditions
for the given value of /?. Assuming that
chain &%?(g, X) as defined above. By the discussion preceding
5.3, the chain
is rapidly
so a polynomially
simulation
suffices to ensure a r.p.d. of at
5.3, the stationary
distribution
of the chain induces a distribution
over GRAPHs(g, X) which is almost
with bias at most e(g))8/4,
since e(g) 2 1 and fl> 0. The overall
bias is then at most e(g))“,
required. Finally,
again by Lemma 5.3, the stationary
probability
at a leaf is bounded below as in Lemma 4.1 except for an additional
due to pruning
of (1 - e(g))B/4) 2 t.
SINCLAIR AND JERRUM
5.5. For any fixed real /3, there exists a polynomial time
algorithm which generates labelled k-regular graphs on n vertices almost
uniformly with bias at most nB, provided that the degree is bounded as
k = O(n113).
We could of course allow the bias in the above algorithm
to be specified
as part of the input.
there is no reason to suppose that the
generator would be fully polynomial
since we can say nothing
useful about
the behaviour
of the counter in Corollary
5.2 for “small”
instances as Q and B vary. Thus the polynomial
bias claimed
apparently
the best we can achieve in polynomial
time. Note
source of the bias is essentially just the pruning
on the tree: the
effect of the truncation
of the Markov
chain is exponentially
small as in
Theorem 4.4, and thus negligible
by comparison.
It remains
now for us to prove Lemma
5.3. For this we require
preliminary
technical result.
PROPOSITION
5.6. Let Z be a random variable denoting the number of
green objects in a random sample (without replacement) of size s > 0 from a
population of size m 2 2s made up of g green and b = m -g blue objects, and
let p = E(Z) = sgfm. Then for any real a > 0,
Pr(Z>ap)<s
Z is distributed
hypergeometrically
E(Z) = p as claimed. Now set r = au. If r < sg/(m -s) then the right-hand
side of the above inequality
is greater than 1 and there is nothing
Assume therefore that r > sg/(m - s). For each i, 1 < i< s, the probability
that the ith choice yields a green object, conditional
on the preceding
choices, certainly
cannot exceed g/(m -s),
since there are always at least
elements remaining
in the pool. Thus for any r’ EN with r’> r we
But we have also
=r'!(s-r')!
by Stirling’s
approximation,
APPROXIMATE
Now the function f(x) = (c/x)-‘, with c E R+, is monotonically
decreasing
for c/x < e; hence, since I’ > r > sg/(m -s), we have the bound
and consequently
Pr(Z=r’)<s
as required.
Proof of Lemma 5.3.
By virtue of the asymptotic
bounds on g,,,
we may choose Q > 0 such that max{ g,,,,
< (Q/4) e(g)‘/” for
zl?%stances
in the family. This implies
a lower bound on B of 100Q4:
further constraints on B will be introduced
below. Note that all instances in
the family are certainly
(Q, B)-balanced.
For problem
instances with e(g) < B there is nothing
to prove as no
pruning takes place in the tree T,(g, X). So let (g, X) be an instance in the
family with m = e(g) > B, and G be any graph in GRAPr-rs(g, X), assumed
non-empty.
In order to estimate the proportion
of all m ! derivations
present in the pruned tree T p*“)(g, X), we estimate the probability
chosen derivation
of G is present. More
precisely, consider the
process (8(1))yz 0, where R(O) = @ and, for t > 1, t7(‘) is a sub-
graph of G having precisely t edges which is obtained
from R(‘-‘)
adding a single edge, all unused edges of G being equiprobable.
If we iden-
tify B(‘) with a problem instance label (h (‘) Y(‘)) in the tree of derivations
as before, then a random derivation
is still present after pruning
is (Q, B)-balanced
for 0 d t 6 m. The proportion
of all m !
derivations
of G which are present after pruning is therefore just
(I), Y(l)) is (Q, B)-balanced)
We proceed to obtain a lower bound on (17) by showing that, for each t
separately, (h (1) Y(l)) is almost surely (Q, B)-balanced,
provided we make
B large enough. Clearly,
this is just the event that the problem
corresponding
to a randomly
chosen t-edge subgraph
of G is (Q, B)-
The proof divides into four stages, corresponding
to various
ranges of values of t.
If O<t <m/2,
then Pr((h (‘) Ycr))
is (Q, B)-balanced)
always have hk& <g,,,
so that y(h(‘), Ycf)) <
2y(g, X). Furthermore,
for all t in this range, e(h”)) 2 e(g)/2. From our
choice of Q, we conclude that (h (I’ Yet)) is (Q, B)-balanced
If m/2 < t d m - m5”, then Pr( (h(l), Y”‘)
is (Q, B)-balanced)
1 - mpB-‘/4.
Recall that i!!(‘) can be viewed as a randomly
chosen t-edge
subgraph of G, or equivalently,
its complement
H(‘) in G as a randomly
chosen s-edge subgraph of G, where s = m - t. Now we have
Ycr)) = max{hL&
y,$&, /$,gX2}
d h”) Qe(g)“4.
Qe(h(1))1/2
(Q, B)-balanced
, i.e., if the maximum
vertex degree h!$g, of the random
s-edge subgraph
H (‘) does not exceed Qs”‘m -l/4
We can estimate the
probability
of this event using Proposition
5.6 as follows: let i E [n] be any
vertex with gj > 0. Then if we colour green all gj edges of G adjacent to j,
and all other edges of G blue, the random variable hj”) is distributed
of green edges in a random
sample (without
replacement)
edges of G. We are therefore in the situation
of Proposition
Z = hj’), g = gj, and tail value clp = Qs”2m-‘/4,
where p = sgjfm is the mean
of hj’). The factor c( is quite large, viz.,
a-Qm”42viZQm”4>4\/i
where we have used the facts that s < m/2 and g,,, d (Q/4)m”4.
value itself satisfies
> Qm I/16,
since also s B m5j8. Proposition
5.6 therefore yields
Pr(h!” > CI~) < s
where c = (2 fi/e)Q
> 1. Thus the probability
that any vertex degree h/(‘)
exceeds the bound is at most m2cpm”“,
which is less than m-P-‘/4
m > B provided B is chosen large enough.
‘I8 < t < m - B, then Pr( (h(‘), YCt)) is (Q, B)-balanced)
> 1 - mpB-‘/4.
As in (ii) above, let s = m - t and view H(‘) as a randomly
chosen s-edge subgraph of G. In view of (i), we may assume that s<m/2.
By definition
of y, (h ,
(I) Y(l)) will be (Q, B)-balanced
if hga, and yg’,, are
each bounded
above by Qe(h(‘))‘/4. In the case of hgh, we proceed via
APPROXIMATE
Proposition
5.6 precisely as in (ii), only this time with tail value a~ = Qs”“.
We find that
since now s<m
‘I* Further, a~ = Q.r ‘I4 3 QB114, so we get the tail estimate
Pr(h!‘) > LX~) < s
Thus the probability
that any vertex degree A,!‘) exceeds Qs”~ is at most
m2(cm)-8’,
where c > 0 is fixed and /?’ can be made arbitrarily
suitable choice of B. By setting B appropriately,
we can clearly make this
less than rne8-l/8
for all m > B.
A similar argument
can be used to handle y!& : for a vertex i E [n] with
gj > 0, let r(j)
be the set of vertices adjacent to j in G. At this point we
make use of the fact (refer to the definition
of problem
instance labels in
the tree) that Y(‘) includes only essentid excluded edges, i.e., edges (i, k) for
which both hj’) > 0 and hp) > 0. From this it is clear that
I{iEr(j):hj’)>O}l.
Now colour green all edges of G with an endpoint
and the remain-
der blue, and again view H(‘) as a random sample of size s from the edge
set of G. Each time a green edge is selected, it contributes
at most two to
the right-hand
side of (18). Thus yj’) < 22, where the random variable 2 is
the number
of green edges in the sample, so the required tail probability
may be estimated
from Proposition
5.6 with g = xi, r(jI gi < g:,,,
CL~ = Qs”~/~. The bounds on s in this range imply
Qm > S m'132,
2s3'4d,ax Q
and crp 3 QB”“/2,
Pr( y!‘) > 2ap) < Pr(Z > CI,U) < s
Exactly as above, this ensures that the probability
that any vertex degree
y!‘) exceeds Qs114 is at most m -p-‘/8
for all m > B, provided
lirge enough. Combining
the bounds for I$!,& and y!&,
we arrive at (iii).
then Pr((h”‘,
Y(‘) ) is (Q, B)-balanced) = 1. This is
true by definition,
since e(h”‘) = m - t < B.
SINCLAIR AND JERRUM
In view of (i)-(iv),
the probability
of the conjunction
in (17) is now
easily seen to be bounded
below by 1 -me8/4,
as claimed
We conclude our discussion of graphs with specified degrees with some
remarks on the counting
The reduction
in 
from approximate
counting to almost uniform
generation mentioned
of Section 4 may
as a means
approximating
the number
of leaves in a rooted tree T given an almost
generator for the leaves in the maximal
subtree rooted at any ver-
tex. For any such subtree S, let L(S) denote the number of leaves in S. The
idea is to generate leaves of T almost uniformly
and compute the fraction s
of the sample which belong to the subtree S rooted at some suitably chosen
child of root(T):
this will be a reliable estimate of the true fraction if the
latter is not too small and the sample is large enough. An estimate of L(T)
is then obtained
by recursively estimating
L(S) and multiplying
the result
of the sample
sizes required
to achieve an
approximation
of L(T) within ratio 1 + E with high probability
is bounded
by a polynomial
function of c-’ and the depth m and maximum
T, assuming the generators have bias at most about E/m.
Now consider the situation
of Theorem
5.4: can we apply the above
technique to estimate the number of leaves in the pruned tree TkQ,“)(g, X)?
Note first that an almost uniform
generator for the leaves in any maximal
subtree S is available
since we may simulate
just this portion
chain .@Z(g, X), transitions
out of S being censored. Moreover,
the reduced chain
will be efficient provided
only that the subtree has sufficiently
many leaves. It is not hard to see that, by modifying
slightly the method in
 for selecting a subtree for the recursion,
we can ensure that this condition
always holds with high probability.
E = mP8/4 for some PER,
we therefore get a randomised
approximate
counter which estimates the number of leaves in Tkpg”)(g, X)
within ratio 1 + m -“/4 in polynomial
time. But by Lemma 5.3 this number
itself approximates
m! #GRAPHS(g,
x) within ratio 1 + m-‘/2, so we are in
approximate
#GRAPHS(~,
1 + m --’ in
polynomial
time for any desired p E R. We summarise this discussion in our
final theorem.
THEOREM 5.7. For any fixed real & there exists a polynomially time-
bounded randomised approximate
counter for
1 + e(g) -B, provided that the degrees are bounded as max( g,,, , x,,, } =
APPROXIMATE
5.7 implies
the existence of a polynomial
algorithmic
method for computing
the number of labelled graphs with specified degrees
that these are not too large) with a relative
error which is
smaller than any desired power of the number
of edges. The asymptotic
of such a counter thus compares very favourably with available
estimates,
such as Theorem
5.1. While
this is a remarkable
theoretical
we suspect that
the various
powers and constants
accumulated
in the reductions will render the method impractical
degree of accuracy is required.
observe that the counting
for GRAPHS is
apparently hard to solve exacfly even under the degree restrictions imposed
in this section,
so that the approximation
justified.
precisely,
we can say that the problem
of evaluating
max 1 gmax y ha, } = O(e(g)li4)
is #P- complete. To see this, note first that
there is a simple reduction from the well-known
#P-complete
counting perfect matchings
in a graph G, under which the excluded graph
X is the complement
of G and the degree sequence is (1, 1, . . . . 1). The
#P-completeness
of the restricted version follows from the fact that the
#P-complete
even for very dense graphs G,
specifically
when G has minimum
vertex degree n - O(n’14),
shown using a reduction of Broder .
ACKNOWLEDGMENT
The concept
of self-embeddability
in Section
in discussions