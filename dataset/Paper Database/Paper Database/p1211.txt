Person Re-Identiﬁcation
Using Kernel-Based Metric Learning Methods⋆
Fei Xiong, Mengran Gou, Octavia Camps, and Mario Sznaier
Dept. of Electrical and Computer Engineering,
Northeastern University, Boston, MA 02115
{fxiong,mengran,camps,msznaier}@coe.neu.edu
 
Abstract. Re-identiﬁcation of individuals across camera networks with
limited or no overlapping ﬁelds of view remains challenging in spite
of signiﬁcant research eﬀorts. In this paper, we propose the use, and
extensively evaluate the performance, of four alternatives for re-ID classiﬁcation: regularized Pairwise Constrained Component Analysis, kernel Local Fisher Discriminant Analysis, Marginal Fisher Analysis and a
ranking ensemble voting scheme, used in conjunction with diﬀerent sizes
of sets of histogram-based features and linear, χ2 and RBF-χ2 kernels.
Comparisons against the state-of-art show signiﬁcant improvements in
performance measured both in terms of Cumulative Match Characteristic curves (CMC) and Proportion of Uncertainty Removed (PUR) scores
on the challenging VIPeR, iLIDS, CAVIAR and 3DPeS datasets.
Introduction
Surveillance systems for large public spaces (i.e. airport terminals, train stations,
etc.) use networks of cameras to maximize their coverage area. However, due to
economical and infrastructural reasons, these cameras often have very little or
no overlapping ﬁeld of view. Thus, recognizing individuals across cameras is a
critical component when tracking in the network.
The task of re-identiﬁcation (re-ID) can be formalized as the problem of
matching a given probe image against a gallery of candidate images. As illustrated in Figure 1(a), this is a very challenging task since images of the same
individual can be very diﬀerent due to variations in pose, viewpoint, and illumination. Moreover, due to the (relatively low) resolution and the placement of the
cameras, diﬀerent individuals may appear very similar and with little or none visible faces, preventing the use of biometric and soft-biometric approaches .
A good overview of existing re-ID methods can be found in 
and references therein. The three most important aspects in re-ID are i) the
features used, ii) the matching procedure, and iii) the performance evaluation.
⋆Electronic supplementary material -Supplementary material is available in the online version of this chapter at 
Videos can also be accessed at 
319-10583-3
D. Fleet et al. (Eds.): ECCV 2014, Part VII, LNCS 8695, pp. 1–16, 2014.
⃝Springer International Publishing Switzerland 2014
F. Xiong et al.
Fig. 1. The re-ID problem. (a) Challenges (left to right): low resolution, occlusion,
viewpoint, pose, and illumination variations and similar appearance of diﬀerent people.
(b) Projecting the data improves classiﬁcation performance.
Most re-ID approaches use appearance-based features that are viewpoint quasiinvariant such as color and texture descriptors. However, the
number and support of features used varies greatly across approaches making it
diﬃcult to compare their impact on performance. Using standard metrics such
as Euclidean distance to match images based on this type of features results
in poor performance due to the large variations in pose and illumination and
limited training data. Thus, recent approaches design classiﬁers
to learn specialized metrics (see Figure 1(b)), that enforce features from the same
individual to be closer than features from diﬀerent individuals. Yet, state-of-theart performance remains low, slightly above 30% for the best match. Performance
is often reported on standard datasets that bring in diﬀerent biases. Moreover,
the number of datasets and the experimental evaluation protocols used vary
greatly across approaches, making diﬃcult to compare them.
This paper focuses on all aspects of the problem, feature extraction, distance
learning for re-ID classiﬁcation, and performance evaluation. In particular:
– We explore the eﬀect of the size and location of support regions for commonly
used histogram-based feature vectors may have on classiﬁcation performance.
– We propose four kernel-based distance learning approaches to improve re-ID
classiﬁcation accuracy when the data space is under-sampled: regularized
Pairwise Constrained Component Analysis (rPCCA), kernel Local Fisher
Discriminant Classiﬁer (kLFDA), Marginal Fisher Analysis (MFA) , and
a ranking ensemble voting (REV) scheme.
– We provide a comprehensive performance evaluation using four sets of features, three kernels (linear, χ2 and RBF-χ2) and four challenging re-ID
datasets: VIPeR , CAVIAR , 3DPeS and iLIDS . Using this
protocol, we compare the proposed methods against four state-of-the-art
methods: Pairwise Constrained Component Analysis (PCCA) , Local
Fisher Discriminant Analysis (LDFA) , SVMML and KISSME .
Our experiments not only allow us to compare previously published classiﬁcation
techniques using a common set of features and datasets (an experiment that to
Person Re-Identiﬁcation Using Kernel-Based Metric Learning Methods
the best of our knowledge has not been reported so far) but also show that
the classiﬁcation methods proposed here result in a signiﬁcant improvement in
performance over the state-of-the-art.
Related Work
Re-ID data samples consist of images of individuals, cropped such that the target
occupies most of the image. The most commonly used features are inspired on a
“bag-of-words” approach and are histograms based using local support regions
within the target’s bounding box . Yet, the number of support regions and
the dimension of the feature vector can vary widely. For example, Mignon and
Jurie use feature vectors of dimension 2,676 while use feature vectors
of dimension 22,506. In our experiments we evaluate the eﬀect of these choices
on re-ID accuracy performance. As shown in our experiments, using too many
of these features can decrease performance.
Most re-ID approaches can be formalized as a supervised metric/distance
learning algorithm where a projection matrix P is sought so that the projected
Mahalanobis-like distance DM(xik, xjk) = (xi −xj)T M(xi −xj), where M =
PT P, is small when feature vectors xik and xjk represent the same person and
large otherwise.
The best reported performance on the VIPeR dataset was achieved using
an adaptive boundary approach that jointly learns the distance metric and an
adaptive thresholding rule. However, a drawback of this approach is that it scales
poorly since its computational complexity is O(d2) where d is the dimension of
the feature vector xik. An alternative approach is to use a logistic function to
approximate the hinge loss so that the global optimum still can be achieved
by iteratively gradient search along P as in Pairwise Constrained Component
Analysis (PCCA) and in (PRDC) . However, these methods are prone to
over ﬁtting. We propose to address this problem by introducing a regularization
term that uses the additional degrees of freedom available in the problem to
maximize the inter-class margin.
The state-of-the-art performance on the CAVIAR and the 3DPeS datasets was
achieved by using a Local Fisher Discriminant Classiﬁer (LFDA) as proposed by
Pedagadi et al. . While this approach has a closed form solution for the Mahalanobis matrix, it requires an eigenanalysis of a d×d scatter matrix. For large
d, proposed to ﬁrst reduce the dimensionality of the data using principal
component analysis (PCA). However, PCA can eliminate discriminant features
defeating the beneﬁts of LFDA. We propose instead to use a kernel approach to
preserve discriminant features while reducing the dimension of the problem to a
N × N eigendecomposition, where N << d is the number of images.
For the sake of clarity, we list the notation used in this paper here. xi ∈Rd is a
feature vector representing the ith image. li ∈{1, · · · , c} is the identity label for
the ith image. A pair of samples (xik, xjk) has associated a class label yk = 1 if
F. Xiong et al.
li = lj and yk = −1, otherwise. N << d, Nc and N ′ ≤N 2 represent the total
number of samples, the number of images with label c, and the number of pairs
of images used, respectively1. φ(x) is a mapping from feature to Kernel space.
Proposed Methods
In this section we propose four possible approaches towards increasing accuracy
performance. The ﬁrst approach, rPCCA, is a new iterative procedure that introduces a regularization term to maximize the inter-class margin to the hinge loss
PCCA approach. The second approach, kLDFA, is a new closed-form method that
uses a kernel trick to handle large dimensional feature vectors while maximizing
a Fischer optimization criteria. The third approach is to use the Marginal Fisher
Analysis method introduced in which to best of our knowledge has not been
used for re-ID before. Finally, we also propose a new ensemble approach where the
results of multiple classiﬁers are combined to exploit their individual strengths.
Regularized PCCA (rPCCA)
In Mignon and Jurie proposed to use PCCA with an approximation to
the hinge loss to learn the projected metric. Their motivation was that the
projected distances between samples from the same class should be smaller than
a given threshold T while the distances between inter-class samples should be
larger than T . To this eﬀect, without loss of generality, they set T = 1 and
then approximated the hinge loss with the generalized logistic loss function 
β log(1 + eβx) to form the objective function:
P(xik, xjk) −1))
where P is a d′ × d matrix (d′ < d) that is found using a gradient descentbased method. Additionally, it is possible to use a “kernel trick” to improve
classiﬁcation when the data is not linearly separable. In this case, a projection
d′×N matrix Q is applied to the feature vectors in the kernel space P = QφT (X)
and the objective function becomes:
ℓβ[yk((eik −ejk)T KQT QK(eik −ejk) −1)]
where K = φ(X)T φ(X) is the N × N kernel matrix and ei is the ith vector of
the canonical basis in RN – i.e. a unit vector with 1 at position i. Using trace,
ℓβyktrace[QK(eik −ejk)(eik −ejk)T KQT ] −1
and the gradient of the new objective function E(Q) is:
1 We will use all possible positive pairs but only a fraction of the negative ones.
Person Re-Identiﬁcation Using Kernel-Based Metric Learning Methods
ykσβ(yk(D2
P(xik, xjk) −1))KCkK
where σβ(x) = (1 + e−βx)−1 for β = 1 and Ck = (eik −ejk)(eik −ejk)T .
The matrix K is full rank since φ(X) is D × N and D > d >> N. Then, one
can multiply the gradient with a preconditioner K−1 and iteratively solve the
problem by updating Q using the expression
Qt+1 = Qt(I −2η
ykσβ(yk(D2
P(xik, xjk) −1)) at time t. It can be easily shown that the eﬀect
of this preconditioning step is that using changes in direction of Q results in the
desired optimal change in direction of P. Furthermore, it should be noted that
updating Q uses K but does not require to compute its inverse.
PCCA can result in poor classiﬁcation performance due to large variations
among samples and limited training data. We propose to address this problem
by using the additional degrees of freedom available in the problem to maximize
the inter-class margin. To this eﬀect, motivated by the objective functions used
on SVMs, we propose the regularized PCCA (rPCCA) objective function with a
regularization term penalizing the Frobenius norm of P:
P(xik, xjk) −1)) + λ||P||2
where λ is the regularization parameter. Brieﬂy, the intuition behind this new
objective function is to treat each of the rows pi of P as the separating hyperplane in an SVM and use the fact that the classiﬁcation margin is precisely
given by (∥pi∥2)−1. Substituting P with QφT (X), the derivative of the regularized objective function with respect to Q becomes:
kKCk + λI)K
Similarly to PCCA, the global optimum can be achieved by multiplying the
gradient with the preconditioner K−1 and iteratively updating the matrix Q.
Kernel LFDA (kLDFA)
A drawback of using LFDA is that it requires solving a generalized eigenvalue
problem of very large scatter d × d matrices. For example, in the authors
use feature vectors with d = 22506 features. To circumvent this problem, 
proposed to exploit the redundancy among the features by performing a preprocessing step where principal component analysis (PCA) is used to reduce the
dimensionality of the data. However, a potential diﬃculty here is that this unsupervised dimensionality reduction step, when applied to relatively small datasets,
F. Xiong et al.
can result in an undesirable compression of the most discriminative features.
To avoid this problem, we propose to use a kernel approach, based on the method
introduced in in the context of supervised dimensionality reduction. The
beneﬁts of this approach are twofold: it avoids performing an eigenvalue decomposition of the large scatter matrices and it can exploit the ﬂexibility in choosing
the kernel to improve the classiﬁcation accuracy.
The proposed kernel LDFA (kLDFA) method ﬁnds a projection matrix P ∈
Rd′×d to maximize the ‘between-class’ scatter while minimizing the ‘within-class’
scatter for similar samples using the Fisher discriminant objective:
P (PSwP)−1PT SbP
where the within and between scatter matrices are Sw = 1
2φ(X)˜Swφ(X)T and
2φ(X)˜Sbφ(X)T where ˜Sw = N
i,j(ei −ej)(ei −ej)T and ˜Sb =
i,j(ei −ej)(ei −ej)T . Then, representing the projection matrix with
the data samples in the kernel space P = QφT (X), the kLFDA problem is
formulated as:
Q (QK˜SwKQ)−1QK˜SbKQ
Since the within class scatter matrix ˜Sw is usually rank deﬁcient, a regularized
ˆSw deﬁned below is used instead:
ˆSw = (1 −α)˜Sw + α
N trace(˜Sw)I
Marginal Fisher Analysis(MFA)
Marginal Fisher Analysis (MFA) was proposed in as yet another graph
embedding dimension reduction method. Similarly to kLDFA and LDFA, it has
a closed form solution given by a general eigenvalue decomposition. However,
in contrast to LDFA, its special discriminant objective allows to maximize the
marginal discriminant even when the assumption of a Gaussian distribution for
each class is not true. Moreover, the results in showed that the learned
discriminant components have larger margin between classes, similar to a SVM.
The scatter matrices for MFA are deﬁned as:
˜Sw = (Dw −Ww) and ˜Sb = (Db −Wb)
where Dbii = 
j Wbij, Dwii = 
j Wwij as well as the sparse matrices Ww
and Wb are deﬁned as: Ww
ij = 1 if and only if xi or xj is the kw nearest within
class neighbor of other; and Wb
ij = 1 if and only if xi or xj is the kb nearest
between class neighbor of other.
Ranking Ensemble Voting
Classiﬁcation accuracy is aﬀected by the method used to learn the projected
metric, the kernel used and the features used to represent the data. Thus, it
Person Re-Identiﬁcation Using Kernel-Based Metric Learning Methods
is possible to design an ensemble of classiﬁers that use diﬀerent kernels and
sets of features. Then, given a test image and a gallery of candidate matches,
each of these classiﬁers will produce, in principle, a diﬀerent ranking among the
candidates which, in turn, could be combined to produce a single and better
ranking. That is, instead of tuning for the best set of parameters through crossvalidation, one could independently run diﬀerent ranking classiﬁers and merge
the results. In this paper, we will consider two alternative ways on how to combine the results from the individual rankings into a ranking ensemble voting
(REV) scheme; “Ensemble 1”: adding the rankings in a simple voting scheme;
or “Ensemble 2”: assuming that the output of a ranking algorithm represents
the probability of the rth closest reference image is the correct match, given the
ranking algorithm Rm, p(r|Rm); m = 1, . . . , Nr, for each of the Nr algorithms.
Then, assuming conditional independence among the diﬀerent algorithms we
have p(r) = Nr
i=1 p(r|Ri).
Experiments
In this section we describe the set of experiments used to evaluate the proposed
methods as well as the choice of features and kernels. In particular, we compared
the performance of rPCCA, kLFDA, MFA and REV, against the current stateof-art PCCA, LFDA, SVMML and KISSME, using four diﬀerent sets of features,
three diﬀerent kernels, and four diﬀerent datasets, as described below.
(c) CAVIAR
Fig. 2. Best CMC curves for each method on four datasets
Datasets and Experimental Protocol
All the algorithms were evaluated using the four most challenging and commonly
used throughout the literature datasets. The VIPeR dataset is composed of
1264 images of 632 individuals, with 2 images of 128 × 48 pixels per individual.
The images are taken from horizontal viewpoints but in widely diﬀerent directions. The iLIDS dataset has 476 images of 119 pedestrians. The number
of images for each individual varies from 2 to 8. Since this dataset was collected
at an airport, the images often have severe occlusions caused by people and luggage. The CAVIAR dataset contains 1220 images of 72 individuals from 2
cameras in a shopping mall. Each person has 10 to 20 images. The image sizes
F. Xiong et al.
Table 1. CMC at r = 1, 5, 10, 20 and PUR scores on VIPeR with p = 316 test individuals (highest scores in red)
LFDA SVMML KISSME
14.3 16.7 19.6
19.1 19.9 22.0 20.6 28.1 32.3 21.1 28.4 32.2
40.5 46.0 51.5
48.3 50.6 54.8 46.2 60.0 65.8 48.7 60.1 66.0
57.5 62.6 68.2
64.9 67.8 71.0 60.8 75.0 79.7 63.9 74.8 79.7
74.7 79.6 82.9
80.9 83.2 85.3 75.9 87.8 90.9 78.9 87.7 90.6
PUR 36.1 39.6 42.9
41.0 42.7 44.8 37.5 48.4 52.5 39.9 48.3 52.4
15.0 17.0 19.7
19.3 19.7 21.1 21.2 28.9 31.8 20.9 28.7 32.2
41.5 46.1 50.7
47.8 49.6 52.9 47.1 60.4 64.8 49.3 59.7 65.5
58.2 63.1 67.2
64.5 65.9 69.2 61.3 74.7 79.1 63.9 74.4 79.0
75.9 79.2 82.5
80.6 81.5 83.6 76.2 87.1 90.3 78.2 86.6 90.3
PUR 36.8 39.5 42.2
40.7 41.8 43.5 38.0 48.3 51.9 39.8 47.9 52.0
18.3 18.4 16.4
21.1 20.5 20.5 23.3 30.3 30.9 23.6 29.6 31.1
46.9 46.4 45.0
51.1 50.5 51.3 52.8 63.5 64.4 52.1 63.0 65.2
63.7 63.4 61.4
67.5 67.4 67.7 68.3 77.9 79.3 67.4 77.3 79.6
80.2 79.3 77.0
82.9 82.4 82.3 82.4 89.8 90.6 81.5 88.9 90.6
PUR 40.1 39.9 37.9
42.7 42.5 42.6 43.2 51.0 51.9 42.6 50.3 52.0
16.2 15.2 11.8
19.2 19.0 16.8 23.6 27.0 24.5 22.7 27.3 24.8
43.5 41.5 35.5
49.4 48.4 45.1 54.4 60.1 56.0 53.8 60.2 56.9
59.0 57.0 51.1
65.5 64.7 60.9 70.1 75.3 72.1 69.1 75.2 72.3
75.6 73.3 68.4
80.8 80.3 77.2 84.0 88.6 86.8 83.3 88.2 86.3
PUR 37.2 35.7 32.0
41.3 40.9 38.6 44.4 48.9 46.7 43.9 48.8 46.7
of this dataset vary signiﬁcantly (from 141 × 72 to 39 × 17). Finally, the 3DPeS
dataset includes 1011 images of 192 individuals captured from 8 outdoor
cameras with signiﬁcantly diﬀerent viewpoints. In this dataset each person has
2 to 26 images. Except for VIPeR, the size of the images from the other three
datasets is not constant so they were scaled to 128 × 48 for our experiments.
In our experiments, we adopted a Single-Shot experiment setting. All the
datasets were randomly divided into two subsets so that the test set contains
p individuals. This partition was repeated 10 times. Under each partition, one
image for each individual in the test set was randomly selected as the reference
image set and the rest of the images were used as query images. This process
was repeated 10 times, as well, and it can be seen as the recall at each rank.
The rank of the correct match was recorded and accumulated to generate the
match characteristic M(r).
For easy comparison with other algorithms, we report the widely used accumulated M(r), Cumulative Match Characteristic (CMC) performance curves,
averaged across the experiments. In addition, we also report the proportion of
uncertainty removed (PUR) scores:
PUR = log(N) + N
r=1 M(r) log(M(r))
where N is the size of the gallery set. This score compares the uncertainty under
random selection among a gallery of images and the uncertainty after using
a ranking method. Finally, since the ﬁrst few retrieved images can be quickly
inspected by a human, higher scores at rank r ≥1 are preferred.
Person Re-Identiﬁcation Using Kernel-Based Metric Learning Methods
Table 2. CMC at r = 1, 5, 10, 20 and PUR scores on iLIDS with p = 60 test individuals
(highest scores shown in red)
LFDA SVMML KISSME
21.7 23.0 24.1
25.5 26.6 28.0 32.3 36.5 36.9 30.5 32.6 32.1
49.7 51.1 53.3
53.8 54.3 56.5 57.2 64.1 65.3 53.9 58.5 58.8
65.0 67.0 69.2
68.4 69.7 71.8 70.0 76.5 78.3 66.3 71.5 72.2
81.4 83.3 84.8
83.0 84.5 85.9 83.9 88.5 89.4 80.4 84.8 85.9
PUR 21.3 22.8 24.4
24.2 25.4 27.0 27.9 33.7 34.9 24.8 28.8 29.1
23.9 24.5 25.7
27.8 28.0 29.6 33.3 37.8 37.4 30.7 34.2 33.7
53.0 53.2 54.0
55.3 56.0 57.3 57.5 64.8 64.8 54.0 58.9 59.5
68.3 68.8 69.6
70.2 70.4 71.7 70.1 76.6 77.3 66.2 71.1 72.0
83.9 84.9 84.4
84.6 85.3 85.9 83.5 88.6 89.1 80.7 85.3 86.0
PUR 23.9 24.5 25.1
26.1 26.6 27.8 28.3 34.7 34.8 25.1 29.9 30.0
24.0 23.8 24.0
28.4 28.9 29.2 34.1 38.0 36.2 30.3 33.7 32.1
53.6 52.9 51.7
57.0 57.1 57.2 60.4 65.1 63.5 56.2 59.3 57.4
69.1 68.6 67.1
71.4 71.4 71.1 73.5 77.4 76.1 68.9 71.7 70.5
84.4 84.1 82.8
85.8 85.7 85.4 86.5 89.2 89.2 83.6 86.5 85.9
PUR 24.4 24.2 23.4
27.3 27.6 27.6 30.8 35.4 33.9 26.7 30.3 28.9
21.4 21.4 20.2
26.0 26.6 25.9 32.2 34.2 30.5 29.2 30.2 26.8
49.1 48.5 45.1
53.3 53.4 52.5 59.9 61.5 57.3 55.1 55.3 50.3
65.5 64.9 61.1
68.9 68.7 67.7 73.8 74.8 71.8 69.3 69.3 64.8
82.1 81.3 78.4
84.5 84.3 83.0 86.5 87.7 85.6 83.8 84.3 82.1
PUR 21.5 21.1 18.7
24.7 25.0 24.1 30.2 31.8 28.4 26.3 27.0 23.4
Features, Kernels and Implementation Details
In , PCCA was applied to feature vectors made of 16-bins histograms from
the RGB, YUV and HSV color channels, as well as texture histograms based on
Local Binary Patterns extracted from 6 non-overlapping horizontal bands2. In
the sequel we will refer to these features as the band features.
On the other hand, the authors in applied LDFA to a set of feature vectors
consisting of 8-bins histograms and 3 moments extracted from 6 color channels
(RGB and HSV) over a set of 341 dense overlapping 8 × 8 pixel regions, deﬁned
every 4 pixels in both the horizontal and vertical directions, resulting in 11,253
dimensional vectors. These vectors were then compressed into 100 dimensional
vectors using PCA before applying LDFA. In the sequel, we will refer to these
features as the block features.
Even though the authors of and reported performance analysis using
the same datasets, they used diﬀerent sets of features to characterize the sample
images. Thus, it is diﬃcult to conclude whether the diﬀerences on the reported
performances are due to the classiﬁcation methods or to the feature selection.
Therefore, in order to fairly evaluate the beneﬁts of each algorithm and the eﬀect
of the choice of features, in our experiments we tested each of the algorithms
using the same set of features. Moreover, while both band and block features
are extracted within rectangular or square regions, their size and location are
very diﬀerent. Thus, to evaluate how these regions aﬀect the re-identiﬁcation
accuracy, we run experiments varying their size and position. In addition to the
2 Since the parameters for the LBP histogram and horizontal bands were not given
in , we found values that provide even better matching accuracy than in .
F. Xiong et al.
Table 3. CMC at r = 1, 5, 10, 20 and PUR scores on CAVIAR with p = 36 test
individuals (highest scores shown in red)
LFDA SVMML KISSME
25.7 29.1 33.4
28.8 30.4 34.0 31.5 36.2 35.9 33.8 37.7 38.4
57.9 62.5 67.2
61.3 63.6 67.5 55.4 64.0 63.6 62.0 67.2 69.0
75.8 79.7 83.1
78.0 80.4 83.4 69.5 78.7 77.9 77.2 82.1 83.6
92.0 94.2 95.7
93.2 94.5 95.8 86.1 92.2 91.2 92.1 94.6 95.1
PUR 21.5 25.5 29.8
24.3 26.5 30.3 20.2 27.5 26.9 25.6 30.7 32.0
28.8 30.7 33.9
30.6 31.8 34.6 33.6 38.5 37.9 35.3 39.0 38.9
62.3 64.8 67.8
64.0 65.9 68.5 59.1 66.7 67.0 63.8 68.6 69.7
79.1 81.4 83.5
80.4 82.1 83.9 73.1 80.7 81.0 78.6 83.0 83.7
94.0 94.9 95.6
94.5 95.0 95.8 88.5 93.3 92.7 92.8 94.8 94.9
PUR 25.2 27.5 30.3
26.7 28.4 31.0 23.1 30.1 29.7 27.3 32.0 32.5
31.9 32.9 33.2
33.0 34.1 35.1 35.7 39.1 39.1 36.6 40.2 39.4
65.2 66.3 65.9
66.0 67.1 67.2 62.6 66.8 68.4 65.5 70.2 69.7
81.6 82.4 81.9
82.0 82.9 83.1 77.0 80.9 82.4 80.2 83.9 83.7
95.3 95.5 95.2
95.4 95.5 95.6 91.4 93.4 94.3 93.3 95.1 95.0
PUR 28.2 29.1 28.8
29.0 29.9 30.4 26.4 30.5 31.6 28.8 33.4 32.7
30.8 31.3 30.4
32.5 33.0 33.4 34.7 37.7 36.4 34.9 37.8 36.3
63.5 64.1 62.2
64.9 65.3 64.4 62.0 65.9 65.6 64.5 67.9 66.4
80.2 80.5 79.1
81.2 81.6 80.6 76.6 80.5 80.6 79.7 82.4 81.6
94.6 94.7 93.6
94.9 95.0 94.3 91.2 93.6 93.6 93.3 94.6 94.2
PUR 26.7 27.1 25.4
28.0 28.4 27.8 25.7 29.6 29.0 27.7 31.1 29.5
band and block features described above, we used a set of features extracted
from 16 × 16 and 32 × 32 pixels overlapping square regions, similar to the ones
used in the block features, but deﬁned with a step half of the width/height of the
square regions in both directions. Thus, a total of 75 and 14 regions were selected
in these two feature sets. The feature vectors were made of 16-bins histogram of
8 color channels extracted on these image patches. To represented the texture
patterns, 8-neighbors of radius 1 and 16-neighbors of radius 2 uniform LBP
histograms were also computed for each region. Finally, the histograms were
normalized with the ℓ1 norm in each channel and concatenated to form the
feature for each image.
The projected feature space dimensionality was set to d′ = 40 for the PCCA
algorithm. To be fair, we also used d′ = 40 with rPCCA. The parameter in the
generalized logistic loss function was set to 3 for both PCCA and rPCCA. Since
we could not reproduce the reported results of LFDA using their parameters
setting, we set the projected feature space as 40 and the regularizing weight β as
0.15 for LFDA3. In kLFDA, we used the same d′ and set the regularizing weight
to 0.01. For MFA, we used all positives pairs of each person for the within class
sets and set kb to 12, β = 0.01, and d′ = 30. Since SVMML in used diﬀerent
features, we also tuned the parameters to achieve results as good as possible. The
two regularized parameters of A and B were set to 10−8 and 10−6, respectively.
Since KISSME is very sensitive to the PCA dimensions, we chose the dimension
for each dataset that gives best PUR and rank 1 CMC score, which are 77, 45,
65 and 70 for VIPeR, iLIDS, CAVIAR and 3DPeS, respectively. In the training
3 It was set as 0.5 in . However, we could not reproduce their reported results with
this parameter.
Person Re-Identiﬁcation Using Kernel-Based Metric Learning Methods
Table 4. CMC at r = 1, 5, 10, 20 and PUR scores on 3DPeS with p = 95 test individuals
(highest scores shown in red)
LFDA SVMML KISSME
33.4 36.4 39.7
39.2 40.4 43.5 38.8 48.4 48.7 35.9 42.3 41.8
63.5 66.3 68.4
68.3 69.5 71.6 62.0 72.5 73.7 58.5 65.3 65.5
75.8 78.1 79.6
79.7 80.5 81.8 72.6 82.1 83.1 69.3 75.2 75.7
86.9 88.6 89.5
89.3 90.0 91.0 82.7 89.9 90.7 79.9 84.8 85.2
PUR 37.7 40.4 42.7
42.5 43.6 46.0 36.7 47.6 48.5 33.2 40.0 40.1
37.3 39.8 42.2
41.9 44.0 46.2 44.1 51.9 52.2 40.0 45.6 45.0
67.4 69.6 71.1
71.3 72.6 74.7 66.5 75.1 75.9 62.6 69.0 68.3
79.4 80.9 82.1
82.2 82.9 84.2 75.8 83.6 84.6 72.9 78.4 78.1
89.3 89.8 90.5
90.6 91.0 91.5 84.7 90.9 91.5 82.9 87.1 86.9
PUR 41.4 43.4 45.1
45.2 46.6 48.7 41.3 50.5 51.3 37.4 43.7 43.2
40.7 41.6 40.2
46.9 47.3 47.6 47.6 54.0 52.4 42.4 48.4 46.3
70.3 70.5 68.4
74.5 75.0 74.6 71.8 77.7 77.1 66.8 72.4 70.5
81.5 81.3 79.6
84.4 84.5 84.1 81.1 85.9 85.7 76.5 81.5 80.0
90.7 90.4 89.3
91.8 91.9 91.7 88.8 92.4 92.4 86.0 89.8 89.1
PUR 44.5 44.6 42.7
49.1 49.3 49.1 46.4 53.5 52.5 41.2 47.6 45.6
37.9 38.4 33.8
45.2 45.2 43.8 46.8 51.6 48.2 41.8 46.0 42.0
67.2 66.9 61.8
72.8 72.6 70.5 72.5 76.4 73.9 66.6 70.6 66.5
79.0 78.5 74.2
82.5 82.4 80.8 81.8 84.9 83.1 76.8 80.1 77.1
89.1 88.5 85.4
90.8 90.6 89.5 89.5 92.0 91.0 86.2 89.0 86.3
PUR 41.5 41.1 36.2
47.0 46.9 44.7 46.8 51.7 48.6 41.0 45.6 41.4
process for PCCA, rPCCA and KISSME, the number of negative pairs was set
to 10 times the number of positive pairs. Finally, we tested three kernels with
each algorithm and feature set: a linear, a χ2 and a RBF −χ2 kernel which are
denoted with L, χ2 and Rχ2, respectively.
Performance Analysis
For both, the VIPeR and iLIDS datasets, the test sets were randomly selected
using half of the available individuals. Speciﬁcally, there are p = 316, p = 60,
p = 36, and p = 95 individuals in each of the test sets for the VIPeR, iLIDS,
CAVIAR, and 3DPeS datasets, respectively. Figure 2 shows the best CMC curves
for each algorithm on the four datasets. The results are also summarized in
Tables 1 to 4, along with the PUR scores for all the experiments. The experiments
show that the VIPeR dataset is more diﬃcult than the iLIDS dataset. This can be
explained by observing that VIPeR has only two images per individual, resulting
in much lower r = 1 CMC scores. On the other hand, the overall PUR score is
higher for the VIPeR set, probably because the iLIDS set has less than half of
the images than VIPeR has.
The highest CMC and PUR scores in every experiment at every ranking were
highlighted in red in the given table. The highest CMC and PUR scores were
achieved using the proposed methods with either a χ2 or a Rχ2 kernel. The
proposed approaches achieve as much as 19.6% at r = 1 and a 10.3% PUR
score improvement on the VIPeR dataset, 14.6% at r = 1 and a 31.2% PUR
score improvement on the iLIDS dataset, 15.0% at r = 1 and a 7.4% PUR score
improvement on the CAVIAR dataset and 22.7% at r = 1 and a 13.6% PUR
score improvement on the 3DPeS dataset, when using band features (6 bands).
F. Xiong et al.
Table 5. The best reported CMC scores in the existing literature
SVMML kLFDA PRDC kLFDA LFDA MFA LFDA kLFDA
In general, rPCCA performed better than LFDA which, in turn, performed
better than PCCA. The better performance of rPCCA over PCCA and LFDA
shows that the regularizer term ∥P∥F plays a signiﬁcant role in preventing over-
ﬁtting of noisy data. However, the best performance is achieved by kLFDA
because this approach does a better job at selecting the features by avoiding
the PCA pre-processing step while taking advantage of the locally scaled aﬃnity
It should be noted that using 6, 14, 75 and 341 regions results in similar
performance, but using 341 results in slightly lower PUR scores. Moreover, the
RBF-χ2 kernel does not help improving the matching accuracy when the regions
are small. It was observed in our experiments that the χ2 distance of the positive
and negative pairs were distributed within a small range around 1 and that the
kernel mapping of these values were hard to distinguish. A possible explanation
for this eﬀect, is that the histograms are noisier and sparser when the base
regions are small.
For sake of completeness, we also compared the best performance for the
proposed algorithms against the best results as reported in the existing literature
(even though as pointed above, the values reported elsewhere do not use the same
set of features or experimental protocol) in Table 5.
Our algorithm matches the best reported results for the VIPeR and iLIDS
datasets, even though the reported PRDC ranking was obtained under easier experiment settings4. Note that both SVMML5 and PRDC require an
iterative optimization which is very expensive on both computation and memory.
In comparison, computing the closed-form solution for the proposed kLFDA and
MFA algorithms is much cheaper. When using a 3.8Hz Intel quad-core computer
with 16GB RAM, the average training times for VIPeR, using 6 patches with a
linear kernel are 0.24s, 0.22s and 155.86s for kLFDA, MFA and SVMML, respectively. While average training times for the iLIDS are 0.07s, 0.04s and 155.6s for
kLFDA, MFA and PRDC, respectively. In the experiments on the CAVIAR and
3DPeS datasets, our ranking is more accurate than LFDA algorithm6.
4 Only 50 individuals were selected as test, while our test set is composed of 60 individuals. Thus, the ranking accuracy is computed in an easier experiment setting.
5 The ranking accuracy was read from the ﬁgure.
6 The CAVIAR ranking reported in was obtained by using the mean of the features
from the sample person in the test set as the reference feature. We believe this is
equivalent to knowing the ground truth before ranking. Hence we report the result
in Table 5 via following our protocol but using the same features as in .
Person Re-Identiﬁcation Using Kernel-Based Metric Learning Methods
Finally, Table 6 shows the results for ranking ensembles voting using diﬀerent
learning algorithms, feature sets, kernels, and aggregating methods. Since the
features extracted from 8 × 8 pixels regions provided the worst performance for
almost all the algorithms, we do not use this set of features in the ensemble.
Therefore, for each metric learning algorithm, we created an ensemble with 9
ranking algorithms, combining 3 kernels (if applicable) and 3 feature sets, which
were used to vote for a ﬁnal ranking. The best performances of the individual
ranking case for each of the metric learning methods from Tables 1 to 4 are also
shown (with a gray background) for easy comparison. The experimental results
show that the ensemble methods produced diﬀerent level of improvements for
each dataset and in general “Ensemble 1” results in larger gains. For single ensemble metric learning algorithm, the performance of ensemble rPCCA improved
from 1.56% to 7.91% across all four datasets whereas the ensemble kLFDA bene-
ﬁted much less. The performance on iLIDS datasets improved on all experiments
whereas the ones on 3DPeS decreased for ensemble kLFDA and MFA. Since the
images in the iLIDS dataset have severe occlusions, using an ensemble of diﬀerent feature sets is beneﬁcial with this dataset. The highest improvement is all
algorithms ensemble on CAVIAR dataset, the rank1 score increased 4.73% and
the PUR score increased 8.08% These results suggest that combining diﬀerent
feature grids can improve the performance.
Table 6. CMC scores of ensembles of rPCCA, kLFDA, MFA on all four datasets. The
columns with gray background show the performance of the best ranking algorithm in
this category (highest scores shown in red).
Ensb 1 Ensb 2
Ensb 1 Ensb 2
Ensb 1 Ensb 2
Ensb 1 Ensb 2
F. Xiong et al.
Fig. 3. The kLFDA projection weight map
for 3DPeS, CAVIAR, iLIDS and VIPeR
Fig. 4. View point variation in 3DPeS
Dataset Analysis
Figure 3 shows a heat map illustrating the projection weight map for each of
the datasets when using kLDFA with 341 patches and a linear kernel. There,
it is seen that the upper body features are the most discriminant ones in all
four datasets. This is expected since the bounding-boxes of the samples are
reasonably accurate and the torsos are relatively well aligned. On the other
hand, the feature projection weights at the bottom of the sample are diﬀerent
across the four datasets. This can be explained by the fact that the viewpoint
variations in the 3DPeS dataset are the most severe among all the datasets. As
shown in Figure 4, when looking from a top view the legs for the pedestrians
occupy fewer pixels and their locations change more than when seen from an
horizontal viewpoint as is the case for the VIPeR samples.
Moreover, the projection weights for the VIPeR dataset are larger for patches
in the background than for the other three datasets. This reﬂects the fact that
the VIPeR samples were taken in three diﬀerent scenes, walk way through a
garden, play ground and street side way with distinctive backgrounds and that
the two images for each person were always taken in the same scene.
Conclusion
We proposed and evaluated the performance of four alternatives for re-ID classiﬁcation: rPCCA, kLFDA, MFA and two ranking ensemble voting (REV) schema,
used in conjunction with sets of histogram-based features and linear, χ2 and
RBF-χ2 kernels. Comparison against four state-of-the-art approaches (PCCA,
LDFA, SVMML and KISSME) showed consistently better performance and up
to a 19.6%, 14.6%, 15.0% and 22.7% accuracy improvements at rank 1 and
10.3%, 31.2%, 7.4% and 13.6% PUR scores improvements, on the VIPeR, iLIDS,
CAVIAR and 3DPeS datasets, respectively, when using 6 bands as support regions for the extracted features and using an RBF-χ2 kernel with the kLFDA
and MFA approaches. With the Ensemble 1 voting schema, we can further increase accuracy by 8.7%, 4.7%, 4.7% at rank 1 and by 2.7%, 1.4%, 8.1% at PUR
on the VIPeR, iLIDS, CAVIAR datasets, respectively.
Person Re-Identiﬁcation Using Kernel-Based Metric Learning Methods