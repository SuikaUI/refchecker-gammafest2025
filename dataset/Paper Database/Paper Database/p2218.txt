Shone, N, Tran Nguyen, N, Vu Dinh, P and Shi, Q
A Deep Learning Approach to Network Intrusion Detection
 
LJMU has developed LJMU Research Online for users to access the research output of the
University more effectively. Copyright © and Moral Rights for the papers on this site are retained by
the individual authors and/or other copyright owners. Users may download and/or print one copy of
any article(s) in LJMU Research Online to facilitate their private study or for non-commercial research.
You may not engage in further distribution of the material or use it for any profit-making activities or
any commercial gain.
The version presented here may differ from the published version or from the version of the record.
Please see the repository URL above for details on accessing the published version and note that
access may require a subscription.
For more information please contact 
 
Citation (please note it is advisable to refer to the publisher’s version if you
intend to cite from this work)
Shone, N, Tran Nguyen, N, Vu Dinh, P and Shi, Q A Deep Learning
Approach to Network Intrusion Detection. IEEE Transactions on Emerging
Topics in Computational Intelligence, 2 (1). ISSN 2471-285X
LJMU Research Online
IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE, NOVEMBER 2017
A Deep Learning Approach to Network Intrusion
Nathan Shone, Tran Nguyen Ngoc, Vu Dinh Phai, Qi Shi
Abstract—Network Intrusion Detection Systems (NIDSs) play a crucial role in defending computer networks. However, there are
concerns regarding the feasibility and sustainability of current approaches when faced with the demands of modern networks. More
speciﬁcally, these concerns relate to the increasing levels of required human interaction and the decreasing levels of detection
accuracy. This paper presents a novel deep learning technique for intrusion detection, which addresses these concerns. We detail our
proposed non-symmetric deep auto-encoder (NDAE) for unsupervised feature learning. Furthermore, we also propose our novel deep
learning classiﬁcation model constructed using stacked NDAEs. Our proposed classiﬁer has been implemented in GPU-enabled
TensorFlow and evaluated using the benchmark KDD Cup ’99 and NSL-KDD datasets. Promising results have been obtained from our
model thus far, demonstrating improvements over existing approaches and the strong potential for use in modern NIDSs.
Index Terms—deep learning, anomaly detection, auto-encoders, KDD, network security.
INTRODUCTION
NE of the major challenges in network security is the
provision of a robust and effective Network Intrusion
Detection System (NIDS). Despite the signiﬁcant advances
in NIDS technology, the majority of solutions still operate
using less-capable signature-based techniques, as opposed
to anomaly detection techniques. There are several reasons
for this reluctance to switch, including the high false error
rate (and associated costs), difﬁculty in obtaining reliable
training data, longevity of training data and behavioural
dynamics of the system. The current situation will reach a
point whereby reliance on such techniques leads to ineffective and inaccurate detection. The speciﬁcs of this challenge
are to create a widely-accepted anomaly detection technique
capable of overcoming limitations induced by the ongoing
changes occurring in modern networks.
We are concerned with three main limitations, which
contribute to this network security challenge. The ﬁrst is
the drastic growth in the volume of network data, which is set
to continue. This growth can be predominantly attributed
to increasing levels of connectivity, the popularity of the
Internet of Things and the extensive adoption of cloudbased services. Dealing with these volumes requires techniques that can analyse data in an increasingly rapid, efﬁcient and effective manner. The second cause is the in-depth
monitoring and granularity required to improve effectiveness
and accuracy. NIDS analysis needs to be more detailed and
contextually-aware, which means shifting away from abstract and high-level observations. For example, behavioural
changes need to be easily attributable to speciﬁc elements of
a network, e.g. individual users, operating system versions
or protocols. The ﬁnal cause is the number of different
N. Shone and Q. Shi are with the Department of Computer Science at
Liverpool John Moores University, Liverpool, UK.
E-mail: {n.shone/q.shi}@ljmu.ac.uk
T. Ngoc and V. Phai are with Department of Information Security at Le
Quy Don Technical University, Hanoi, Vietnam.
Email: , 
Manuscript submitted 30 June 2017.
protocols and the diversity of data traversing through modern
networks. This is possibly the most signiﬁcant challenge and
introduces high-levels of difﬁculty and complexity when
attempting to differentiate between normal and abnormal
behaviour. It increases the difﬁculty in establishing an accurate norm and widens the scope for potential exploitation or
zero-day attacks.
In recent years, one of the main focuses within NIDS
research has been the application of machine learning and
shallow learning techniques such as Naive Bayes, Decision
Trees and Support Vector Machines (SVM) . By enlarge,
the application of these techniques has offered improvements in detection accuracy. However, there are limitations
with these techniques, such as the comparatively high level
of human expert interaction required; expert knowledge
is needed to process data e.g. identifying useful data and
patterns. Not only is this a labour intensive and expensive
process but it is also error prone . Similarly, a vast
quantity of training data is required for operation (with
associated time overheads), which can become challenging
in a heterogeneous and dynamic environment.
To address the above limitations, a research area currently receiving substantial interest across multiple domains
is that of deep learning. This is an advanced subset of machine learning, which can overcome some of the limitations
of shallow learning. Thus far, initial deep learning research
has demonstrated that its superior layer-wise feature learning can better or at least match the performance of shallow
learning techniques . It is capable of facilitating a deeper
analysis of network data and faster identiﬁcation of any
anomalies.
In this paper, we propose a novel deep learning model to
enable NIDS operation within modern networks. The model
we propose is a combination of deep and shallow learning,
capable of correctly analysing a wide-range of network
trafﬁc. More speciﬁcally, we combine the power of stacking
our proposed non-symmetric deep auto-encoder (NDAE)
(deep-learning) and the accuracy and speed of Random
IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE, NOVEMBER 2017
Forest (RF)(shallow learning). We have practically evaluated
our model using GPU-enabled TensorFlow and obtained
promising results from analysing the KDD Cup ’99 and
NSL-KDD datasets. We are aware of the limitations of these
datasets but they remain widely-used benchmarks amongst
similar works, enabling us to draw direct comparisons.
This paper offers the following novel contributions:
A new NDAE technique for unsupervised feature
learning, which unlike typical auto-encoder approaches provides non-symmetric data dimensionality reduction. Hence, our technique is able to facilitate improved classiﬁcation results when compared
with leading methods such as Deep Belief Networks
A novel classiﬁer model that utilises stacked NDAEs
and the RF classiﬁcation algorithm. By combining
both deep and shallow learning techniques to exploit
their respective strengths and reduce analytical overheads. We are able to better or at least match results
from similar research, whilst signiﬁcantly reducing
the training time.
The remainder of this paper is structured as follows.
Section 2 presents relevant background information. Section
3 examines existing research. Section 4 speciﬁes our proposed solution, which is subsequently evaluated in Section
5. Section 6 discusses our ﬁndings from the evaluation.
Finally the paper concludes in Section 7.
BACKGROUND
In this section, we will provide background information
necessary to understand our motivations and the concepts
behind the model proposed in this paper.
NIDS challenges
Network monitoring has been used extensively for the
purposes of security, forensics and anomaly detection. However, recent advances have created many new obstacles for
NIDSs. Some of the most pertinent issues include:
Volume - The volume of data both stored and passing through networks continues to increase. It is
forecast that by 2020, the amount of data in existence
will top 44ZB . As such, the trafﬁc capacity of
modern networks has drastically increased to facilitate the volume of trafﬁc observed. Many modern
backbone links are now operating at wirespeeds of
100Gbps or more. To contextualise this, a 100Gbps
link is capable of handling 148,809,524 packets per
second . Hence, to operate at wirespeed, a NIDS
would need to be capable of completing the analysis
of a packet within 6.72ns. Providing NIDS at such a
speed is difﬁcult and ensuring satisfactory levels of
accuracy, effectiveness and efﬁciency also presents a
signiﬁcant challenge.
Accuracy - To maintain the aforementioned levels of
accuracy, existing techniques cannot be relied upon.
Therefore, greater levels of granularity, depth and
contextual understanding are required to provide
a more holistic and accurate view. Unfortunately,
this comes with various ﬁnancial, computational and
time costs.
Diversity - Recent years have seen an increase in
the number of new or customised protocols being
utilised in modern networks. This can be partially
attributed to the number of devices with network
and/or Internet connectivity. As a result, it is becoming increasingly difﬁcult to differentiate between
normal and abnormal trafﬁc and/or behaviours.
Dynamics - Given the diversity and ﬂexibility of
modern networks, the behaviour is dynamic and
difﬁcult to predict. In turn, this leads to difﬁculty
in establishing a reliable behavioural norm. It also
raises concerns as to the lifespan of learning models.
Low-frequency attacks - These types of attacks have
often thwarted previous anomaly detection techniques, including artiﬁcial intelligence approaches.
The problem stems from imbalances in the training
dataset, meaning that NIDS offer weaker detection
precision when faced with these types of low frequency attacks.
Adaptability - Modern networks have adopted
many new technologies to reduce their reliance on
static technologies and management styles. Therefore, there is more widespread usage of dynamic
technologies such as containerisation, virtualisation
and Software Deﬁned Networks. NIDSs will need to
be able to adapt to the usage of such technologies
and the side effects they bring about.
Deep Learning
Deep learning is an advanced sub-ﬁeld of machine learning,
which advances Machine Learning closer to Artiﬁcial Intelligence. It facilitates the modelling of complex relationships
and concepts using multiple levels of representation. Supervised and unsupervised learning algorithms are used to
construct successively higher levels of abstraction, deﬁned
using the output features from lower levels .
Auto-encoder
A popular technique currently utilised within deep learning
research is auto-encoders, which is utilised by our proposed
solution (detailed in Section 4). An auto-encoder is an unsupervised neural network-based feature extraction algorithm,
which learns the best parameters required to reconstruct its
output as close to its input as possible. One of it desirable
characteristics is the capability to provide more a powerful
and non-linear generalisation than Principle Component
Analysis (PCA).
This is achieved by applying backpropagation and setting the target values to be equal to the inputs. In other
words, it is trying to learn an approximation to the identity
function. An auto-encoder typically has an input layer, output layer (with the same dimension as the input layer) and
a hidden layer. This hidden layer normally has a smaller dimension than that of the input (known as an undercomplete
or sparse auto-encoder). An example of an auto-encoder is
shown in Fig. 1.
Most researchers , , use auto-encoders as a nonlinear transformation to discover interesting data structures,
IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE, NOVEMBER 2017
by imposing other constraints on the network, and compare
the results with those of PCA (linear transformation). These
methods are based on the encoder-decoder paradigm. The
input is ﬁrst transformed into a typically lower-dimensional
space (encoder), and then expanded to reproduce the initial
data (decoder). Once a layer is trained, its code is fed to the
next, to better model highly non-linear dependencies in the
input. This paradigm focuses on reducing the dimensionality of input data. To achieve this, there is a special layer
- the code layer , at the centre of the deep auto-encoder
structure. This code layer is used as a compressed feature
vector for classiﬁcation or for combination within a stacked
auto-encoder .
Fig. 1. An example of a single auto-encoder
The hidden layer is used to create a lower dimensionality
version of high dimensionality data (known as encoding).
By reducing the dimensionality, the auto-encoder is forced
to capture the most prominent features of the data distribution. In an ideal scenario, the data features generated by the
auto-encoder will provide a better representation of the data
points than the raw data itself.
The aim of the auto-encoder is to try and learn the
function shown in equation 1.
hW,b(x) ≈x
Here, h is a non-linear hypothesis using the parameters
W (weighting) and b (bias), which can ﬁt the given data (x).
Simply, it tries to learn an approximation to the identity
of a function, where x′ is most similar to x. The learning
process is described as a reconstruction error minimisation
function, as shown in equation 2.
L(x, d(f(x)))
Here, L is a loss function penalising d(f(x)) for being
dissimilar to x, d is a decoding function and f is an encoding
Stacked auto-encoder
Unlike a simple auto-encoder, a deep auto-encoder is composed of two symmetrical deep-belief networks, which typically have four or ﬁve shallow layers for encoding, and a
second set of four or ﬁve layers for decoding. The work by
Hinton and Salacukhudinov has produced promising results by implementing a deep learning algorithm to convert
high dimensional data to low dimensional data by utilising
a deep auto-encoder.
Deep learning can be applied to auto-encoders, whereby
the hidden layers are the simple concepts and multiple
hidden layers are used to provide depth, in a technique
known as a stacked auto-encoder. This increased depth can
reduce computational costs and the amount of required
training data, as well as yielding greater degrees of accuracy
 . The output from each hidden layer is used as the input
for a progressively higher level. Hence, the ﬁrst layer of a
stacked auto-encoder usually learns ﬁrst-order features in
raw input. The second layer usually learns second-order
features relating to patterns in the appearance of the ﬁrstorder features. Subsequent higher layers learn higher-order
features. An illustrative example of a stacked auto-encoder
is shown in Fig. 2. Here, the superscript numbers refer to
the hidden layer identity and the subscript numbers signify
the dimension for that layer.
Classifier
Auto-encoder 1
Hidden Layers
Auto-encoder 2
Hidden Layers
Fig. 2. An example of a stacked auto-encoder
EXISTING WORK
Deep learning is garnering signiﬁcant interest and its application is being investigated within many research domains,
such as: healthcare , ; automotive design , ;
manufacturing and law enforcement , .
There are also several existing works within the domain
of NIDS. In this section, we will discuss the most current
notable works.
Dong and Wang undertook a literary and experimental
comparison between the use of speciﬁc traditional NIDS
techniques and deep learning methods . The authors
concluded that the deep learning-based methods offered
improved detection accuracy across a range of sample sizes
and trafﬁc anomaly types. The authors also demonstrated
that problems associated with imbalanced datasets can be
overcome by using oversampling for which, they used the
Synthetic Minority Oversampling Technique (SMOTE).
Zhao et al. presented a state-of-the-art survey of deep
learning applications within machine health monitoring.
IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE, NOVEMBER 2017
They experimentally compared conventional machine learning methods against four common deep learning methods
(auto-encoders, Restricted Boltzmann Machine (RBM), Convolutional Neural Network (CNN) and Recurrent Neural
Network (RNN). Their work concluded that deep learning
methods offer better accuracy than conventional methods.
Our literature review identiﬁed several proposed deep
learning methods speciﬁcally for NIDSs.
Alrawashdeh and Purdy proposed using a RBM
with one hidden layer to perform unsupervised feature reduction. The weights are passed to another RBM to produce
a DBN. The pre-trained weights are passed into a ﬁne tuning
layer consisting of a Logistic Regression classiﬁer (trained
with 10 epochs) with multi-class soft-max. The proposed
solution was evaluated using the KDD Cup ’99 dataset.
The authors claimed a detection rate of 97.90% and a false
negative rate of 2.47%. This is an improvement over results
claimed by authors of similar papers.
The work by Kim et al. aspired to speciﬁcally target
advanced persistent threats. They propose a Deep Neural
Network (DNN) using 100 hidden units, combined with the
Rectiﬁed Linear Unit activation function and the ADAM
optimiser. Their approach was implemented on a GPU
using TensorFlow, and evaluated using the KDD data set.
The authors claimed an average accuracy rate of 99%, and
summarised that both RNN and Long Short-Term Memory
(LSTM) models are needed for improving future defences.
Javaid et al. propose a deep learning based approach
to building an effective and ﬂexible NIDS. Their method
is referred to as self-taught learning (STL), which combines a sparse auto-encoder with softmax regression. They
have implemented their solution and evaluated it against
the benchmark NSL-KDD dataset. The authors claim some
promising levels of classiﬁcation accuracy in both binary
and 5-class classiﬁcation. Their results show that their 5class classiﬁcation achieved an average f-score of 75.76%.
Potluri and Diedrich propose a method using 41
features and their DNN has 3 hidden layers (2 auto-encoders
and 1 soft-max). The results obtained were mixed, those
focusing on fewer classes were more accurate than those
with more classes. The authors attributed this to insufﬁcient
training data for some classes.
Cordero et al. proposed an unsupervised method
to learn models of normal network ﬂows. They use RNN,
auto-encoder and the dropout concepts of deep learning.
The exact accuracy of their proposed method evaluated is
not fully disclosed.
Similarly, Tang et al. also propose a method to
monitor network ﬂow data. The paper lacked details about
its exact algorithms but does present an evaluation using
the NSL-KDD dataset, which the authors claim gave an
accuracy of 75.75% using six basic features.
Kang and Kang proposed the use of an unsupervised DBN to train parameters to initialise the DNN, which
yielded improved classiﬁcation results (exact details of the
approach are not clear). Their evaluation shows improved
performance in terms of classiﬁcation errors.
Hodo et al. have produced a comprehensive taxonomy and survey on notable NIDSs approaches that utilise
deep and shallow learning. They have also aggregated some
of the most pertinent results from these works.
In addition, there is other relevant work, including the
DDoS detection system proposed by Niyaz et al. . They
propose a deep learning-based DDoS detection system for
a software deﬁned network (SDN). Evaluation is performed
using custom generated trafﬁc traces. The authors claim to
have achieved binary classiﬁcation accuracy of 99.82% and
8-class classiﬁcation accuracy of 95.65%. However, we feel
that drawing comparisons with this paper would be unfair
due to the contextual difference of the dataset. Speciﬁcally,
benchmark KDD datasets cover different distinct categories
of attack, whereas the dataset used in this paper focuses on
subcategories of the same attack.
You et al. propose an automatic security auditing
tool for short messages (SMS). Their method is based upon
the RNN model. The authors claimed that their evaluations
resulted in an accuracy rate of 92.7%, thus improving existing classiﬁcation methods (e.g. SVM and Naive Bayes).
Wang et al. propose an approach for detecting
malicious JavaScript. Their method uses a 3 layer SdA with
linear regression. It was evaluated against other classiﬁer
techniques, showing that it had the highest true positive
rate but the second best false positive rate.
The work by Hou et al. outlines their commercial
Android malware detection framework, Deep4MalDroid.
Their method involves the use of stacked auto-encoders
with best accuracy resulting from 3 layers. The 10-fold
cross validation was used, showing that in comparison to
shallow learning, their approach offers improved detection
performance.
Lee et al. propose a deep-learning approach to fault
monitoring in semiconductor manufacturing. They use a
Stacked de-noising Auto-encoder (SdA) approach to provide an unsupervised learning solution. A comparison with
conventional methods has demonstrated that throughout
different use cases the approach increases accuracy by up to
14%. in different use cases. They also concluded that among
the SdAs analysed (1-4 layers) those with 4 layers produced
the best results.
The ﬁndings from our literature review have shown that
despite the high detection accuracies being achieved, there
is still room for improvement. Such weaknesses include the
reliance on human operators, long training times, inconsistent or average accuracy levels and the heavy modiﬁcation
of datasets (e.g. balancing or proﬁling). The area is still in
an infantile stage, with most researchers still experimenting
on combining various algorithms (e.g. training, optimisation, activation and classiﬁcation) and layering approaches
to produce the most accurate and efﬁcient solution for a
speciﬁc dataset. Hence, we believe the model and work presented in this paper will be able to make a valid contribution
to the current pool of knowledge.
PROPOSED METHODOLOGY
Non-symmetric deep auto-encoder
Decreasing the reliance on human operators is a crucial
requirement for future-prooﬁng NIDSs. Hence, our aim is
to devise a technique capable of providing reliable unsupervised feature learning, which can improve upon the
performance and accuracy of existing techniques.
IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE, NOVEMBER 2017
This paper introduces our NDAE, which is an autoencoder featuring non-symmetrical multiple hidden layers.
Fundamentally, this involves the proposed shift from the
encoder-decoder paradigm (symmetric) and towards utilising just the encoder phase (non-symmetric). The reasoning
behind this is that given the correct learning structure,
it is be possible to reduce both computational and time
overheads, with minimal impact on accuracy and efﬁciency.
NDAE can be used as a hierarchical unsupervised feature
extractor that scales well to accommodate high-dimensional
inputs. It learns non-trivial features using a similar training
strategy to that of a typical auto-encoder. An illustrated
example of this is presented in Fig. 3.
Typical auto-encoder
Non-symmetric deep auto-encoder
Fig. 3. Comparison of a typical auto-encoder and a NDAE
The proposed NDAE takes an input vector x ∈Rd and
step-by-step maps it to the latent representations hi ∈Rdi
(here d represents the dimension of the vector) using a
deterministic function shown in equation (3) below:
hi = σ(Wi.hi−1 + bi); i = 1, n,
Here, h0 = x, σ is an activation function (in this work
we use sigmoid function σ(t) = 1/(1 + e−t)) and n is the
number of hidden layers.
Unlike a conventional auto-encoder and deep autoencoder, the proposed NDAE does not contain a decoder
and its output vector is calculated by a similar formula to
equation (4) as the latent representation.
y = σ(Wn+1.hn + bn+1)
The estimator of the model θ = (Wi, bi) can be obtained
by minimising the square reconstruction error over m training samples (x(i), y(i))m
i=1, as shown in equation (5).
(x(i) −y(i))2
Stacked non-symmetric deep auto-encoders
In this subsection, we detail the novel deep learning classiﬁcation model we have created to address the problems
identiﬁed with current NIDSs.
Fundamentally, our model is based upon using our
NDAE technique (outlined in Section 4.1) for deep learning.
This is achieved by stacking our NDAEs to create a deep
learning hierarchy. Stacking the NDAEs offers a layer-wise
unsupervised representation learning algorithm, which will
allow our model to learn the complex relationships between
different features. It also has feature extraction capabilities,
so it is able to reﬁne the model by prioritising the most
descriptive features.
Due to the data that we envisage this model using,
we have designed the model to handle large and complex
datasets (further details on this are provided in 6). Despite
the 42 features present in the KDD Cup ’99 and NSL-KDD
datasets being comparatively small, we maintain that it provides a benchmark indication as to the model’s capability.
However, the classiﬁcation power of stacked autoencoders with a typical soft-max layer is relatively weak
compared to other discriminative models including RF,
KNN and SVM. Hence, we have combined the deep learning power of our stacked NDAEs with a shallow learning classiﬁer. For our shallow learning classifer, we have
decided upon using Random Forest. Current comparative
research such as that by Choudhury and Bhowal , and
Anbar et al. shows that RF is one of the best algorithms for intrusion detection. These are ﬁndings that were
replicated by our own initial tests. Additionally, there are
many examples of current intrusion detection research also
utilising RF such as and .
RF is basically an ensemble learning method, the principle of which is to group ‘weak learners’ to form a ‘strong
learner’ . In this instance, numerous individual decision
trees (the weak learners) are combined to form a forest.
RF can be considered as the bagging (records are selected
at random with replacement from the original data) of
these un-pruned decision trees, with a random selection of
features at each split. It boasts advantages such as low levels
of bias, robustness to outliers and overﬁtting correction, all
of which would be useful in a NIDS scenario.
In our model, we train the RF classiﬁer using the encoded representations learned by the stacked NDAEs to
classify network trafﬁc into normal data and known attacks.
In deep learning research, the exact structure of a model
dictates its success. Currently, researchers are unable to explain what makes a successful deep learning structure. The
exact structure of our model has resulted from experimented
with numerous structural compositions to achieve the best
results. The ﬁnal structure of our proposed model is shown
in Fig. 4.
Hidden Layer 1
Hidden Layer 2
Hidden Layer 3
Hidden Layer 1
Hidden Layer 2
Hidden Layer 3
Classifier
Fig. 4. Stacked NDAE Classiﬁcation Model
As per Fig. 4, our model uses two NDAEs arranged in a
stack, and is combined with the RF algorithm. Each NDAE
has 3 hidden layers, with each hidden layer using the same
IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE, NOVEMBER 2017
number of neurons as that of features (indicated by the
numbering in the diagram). These exact parameters were
determined by cross-validating numerous combinations (i.e.
numbers of neurons and hidden layers), until the most
effective was identiﬁed. This allows for performance evaluation without the risk of overﬁtting. For our experiments,
we used the 10-fold cross-validation approach on the NSL-
KDD dataset using Scikit Learn. The result for our ﬁnal
model structure was 0.995999 +/- 0.000556, which is a very
promising result.
EVALUATION & RESULTS
Similar to most existing deep learning research, our proposed classiﬁcation model (Section 4.2) was implemented
using TensorFlow. All of our evaluations were performed
using GPU-enabled TensorFlow running on a 64-bit Ubuntu
16.04 LTS PC with an Intel Xeon 3.60GHz processor, 16 GB
RAM and an NVIDIA GTX 750 GPU.
To perform our evaluations, we have used the KDD Cup
’99 and NSL-KDD datasets. Both of these datasets are considered as benchmarks within NIDS research. Furthermore,
using these datasets assists in drawing comparisons with
existing methods and research.
Throughout this section, we will be using the metrics
deﬁned below:
True Positive (TP) - Attack data that is correctly classiﬁed as an attack.
False Positive (FP) - Normal data that is incorrectly
classiﬁed as an attack.
True Negative (TN) - Normal data that is correctly
classiﬁed as normal.
False Negative (FN) - Attack data that is incorrectly
classiﬁed as normal.
We will be using the following measures to evaluate the
performance of our proposed solution:
Accuracy =
TP + TN + FP + FN
The accuracy measures the proportion of the total number
of correct classiﬁcations.
Precision =
The precision measures the number of correct classiﬁcations
penalised by the number of incorrect classiﬁcations.
The recall measures the number of correct classiﬁcations
penalised by the number of missed entries.
False Alarm =
The false alarm measures the proportion of benign events
incorrectly classiﬁed as malicious.
F-score = 2 · Precision · Recall
Precision + Recall
The F-score measures the harmonic mean of precision and
recall, which serves as a derived effectiveness measurement.
This paper utilises the KDD Cup ’99 and NSL-KDD benchmark datasets. Both of which have been used extensively
in IDS research involving trafﬁc with both normal and
abnormal connections.
KDD Cup ’99
The KDD Cup ’99 dataset was used in DARPA’s IDS evaluation program . The data consists of 4 gigabytes-worth
of compressed tcpdump data resulting from 7 weeks of
network trafﬁc. This can be processed into about 5 million
connection records, each with about 100 bytes. It consists of
approximately 4,900,000 single connection vectors each of
which contains 41 features. These include Basic features (e.g.
protocol type, packet size), Domain knowledge features (e.g.
number of failed logins) and timed observation features (e.g.
% of connections with SYN errors). Each vector is labelled as
either normal or as an attack (of which there are 22 speciﬁc
attack types, as outlined in Table 1).
It is common practice to use 10% of the full size dataset,
as this provides a suitable representation with reduced computational requirements. This 10% subset is produced and
disseminated alongside the original dataset. In this paper,
we use the 10% (herein referred to as KDD Cup ’99) subset,
which contains 494,021 training records and 311,029 testing
records. The exact composition is shown in Table 1.
The KDD Cup ’99 dataset needs pre-processing to be successfully utilised with our proposed stacked NDAE model.
This is because our model operates using only numeric
values but one record in the dataset has a mixture of
numeric and symbolic values, so a data transformation was
needed to convert them. In addition integer values also need
normalisation as they were mixed with ﬂoating point values
between 0 and 1, which would make learning difﬁcult.
The newer NSL-KDD dataset, which was produced by
Tavallaee et al. to overcome the inherent problems of the
KDD ’99 data set, which are discussed in . Although,
this new version of the dataset still suffers from some of
the problems discussed by McHugh in and may not
be a perfect representation of existing real networks. Most
current NIDS research still uses this dataset, so we believe it
remains an effective benchmark to help researchers compare
different methods.
The NSL-KDD dataset is fundamentally the same structure as the KDD Cup ’99 dataset (i.e. it has 22 attack patterns
or normal trafﬁc, and ﬁelds for 41 features). We will be
using the whole NSL-KDD dataset for our evaluations, the
composition of which is also shown in Table 1.
In Table 1, some of the attack patterns have been highlighted. This indicates attack patterns that contain less than
20 occurrences in the dataset. 20 is the minimum threshold
required for accurate levels of training and evaluation. So,
for this paper these attacks have been omitted.
One of the most prominent techniques currently used
within deep learning research is DBNs , , . One
notable publication on the technique is by Alrawashdeh
and Purdy , where the authors propose the use of a
DBN model for NIDSs. Hence, for our evaluation we draw
IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE, NOVEMBER 2017
Composition of Datasets
10% KDD ’99
Attack Type
’teardrop’
’portsweep’
’ftp write’
’guess password’
’multihop’
’warezclient’
’warezmaster’
’loadmodule’
’buffer overﬂow’
a direct comparison between the results obtained from our
proposed model and the DBN model. We will also compare the results of our model against those published by
Alrawashdeh and Purdy.
KDD Cup ’99
In this section, we evaluate the 5-class classiﬁcation performance of our proposed classiﬁcation model against the DBN
model published in , using the KDD Cup ’99 dataset as
outlined in the previous subsection.
The results obtained from the 5-class analysis of the KDD
Cup ’99 dataset by both the DBN model in and our
stacked NDAE model are presented in Table 2. By comparing the results of both models, we can see that overall our
stacked NDAE model the effectiveness and accuracy of our
results are better than, or comparable with those achieved
by the model in . However, notable exceptions to this
are the “U2R” and “R2L” classes, which will be discussed in
Section 6.
Time efﬁciency is an important consideration for our
model, particularly when applied within a NIDS. Hence, we
have measured the training time required by our stacked
NDAE model and a DBN model to analyse the KDD ’99
dataset. However, it would not be a fair to draw comparisons with in this respect, due to differences in the hardware and software used. Therefore, we have implemented
a DBN model in TensorFlow, and the results obtained are
presented in Table 3.
As Table 3 shows, the non-symmetric approach of our
model is able to accomplish a signiﬁcant reduction in
required training time, offering an average reduction of
97.72%. Hence, it is promising that our model can maintain
the high levels of accuracy, whilst drastically reducing the
required training time.
KDD ’99 Training Time
No. Neurons
in Hidden Layers
Training Time (s)
Saving (%)
Unfortunately, the paper does not provide evaluations
using the NSL-KDD dataset. Thus we will be using the
previously-discussed TensorFlow DBN model for comparisons. To maximise comparability we have undertaken two
separate evaluations based on (a) 5-class classiﬁcation as used
in KDD Cup ’99, and (b) 13-class classiﬁcation from NSL-KDD
(this selection is explained in Section 5.1).
5-Class Classiﬁcation
By using the same 5 generic class labels as used in the KDD
Cup ’99 dataset, we can compare the performance of the two
models between the two datasets. It also aids comparability
against similar works adopting this strategy. The performance results are presented in Table 4 and illustrated by the
Receiver Operating Characteristic (ROC) curve in Figure 5.
Fig. 5. ROC Curve for NSL-KDD 5-Class
From the table, it is evident that our model offers increased accuracy, precision, recall, effectiveness (F-score)
and the false alarm rate, when compared to the DBN approach.
13-Class Classiﬁcation
As discussed previously, our model is designed to work
with larger and complex datasets. Therefore, we evaluate
our model’s classiﬁcation capabilities on a 13-class dataset.
These 13 labels are those with more than the minimum
20 entries. The purpose of this analysis is to compare the
stability of our model when the number of attack classes increases. Therefore, we do not compare these results against
another model. The corresponding performance analysis is
presented in Table 5. It is evident when these results are
compared to those in Table 4 (the 5-class performance) that
overall it performs better, with the average accuracy increasing from 85.42% to 89.22%. One of our initial goals was
to support the granularity required by modern networks.
IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE, NOVEMBER 2017
KDD Cup ’99 Performance
Accuracy (%)
Precision (%)
Recall (%)
F-Score (%)
False Alarm (%)
NSL-KDD 5-class Performance
Accuracy (%)
Precision (%)
Recall (%)
F-Score (%)
False Alarm (%)
Therefore, these results are a promising indication that our
model can perform better when faced with more detailed
and granular datasets.
Timeliness is critical in modern NIDS, thus we also evaluate the training time required for the NSL-KDD dataset.
The results of this comparison are shown in Table 6.
NSL-KDD Time Comparison
No. Neurons
in Hidden Layers
Training Time (s)
Saving (%)
From these results, we can see that through the different
hidden layer compositions, our model is able to consistently
reduce the required training time compared with DBN.
DISCUSSION
Our evaluations show that our proposed stacked NDAE
model has produced a promising set of results.
5-Class KDD Cup ’99 Classiﬁcation
With regards to the KDD Cup ’99 dataset evaluation, the
results show that our model is able to offer an average
accuracy of 97.85%. more speciﬁcally, the results show that
our accuracy is better than or comparable with the work in
 , in 3 out of 5 classes. It is also a signiﬁcant improvement
on other deep learning methods such as . However, it is
noted that the results for “R2L” and “U2L” attack classes
are anomalous. The stacked NDAE model requires greater
amounts of data to learn from. Unfortunately, due to the
smaller number of training datum available, the results
achieved are less stable. Despite this, it is evident from the
performance analysis that our model can offer improved
precision, recall and F-score, especially for larger classes.
Furthermore, our model managed to produce these comparable performance results, whilst consistently reducing
the required training time by an average of 97.72%.
5-Class NSL-KDD Classiﬁcation
With regards to the NSL-KDD dataset, we can see from the
results that throughout all of the measures our model yields
superior level of performance in 3 of the 5 classes. Notably,
the model offered a total accuracy rate of 85.42%, which
improves upon the DBN model by just under 5%. It also
offered a 4.84% reduction in the false alarm rate. The results
also re-emphasise the point made, that our model doesn’t
handle smaller classes (“R2L” and “U2R”) as well.
Another important factor is that the time required to
train our model is drastically reduced, yielding an average
time saving of 78.19% against DBN. This is of critical importance particularly for application in a NIDS.
13-Class NSL-KDD Classiﬁcation
The results from the 13-Class classiﬁcation evaluate demonstrate that our model was able to offer a 3.8% improvement
on its own accuracy simply by using a more granular
dataset. This supports our claim that the model is able to
work more effectively with larger and complex datasets.
Furthermore, the larger dataset gives a better insight
into the weakness in our model. As it can be seen from
the results, there is a direct correlation between the size of
the training datasets for each label and the accuracy/error
rates. This supports our observation that the smaller classes
(in this case “back”, “guess password”, “tear drop” and
“warez client”) yield lower levels of accuracy using our
However, it must also be noted that the larger classes
yielded consistently high rates throughout all of the performance measures.
Comparison With Related Works
We have also compared the results from our stacked
NDAE model against the results obtained from similar deep
learning-based NIDSs.
In , the authors claim their 5-class classiﬁcation of
the NSL-KDD dataset produced an f-score of 75.76%. Their
IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE, NOVEMBER 2017
NSL-KDD 13-class Performance
No. Training
No. Attack
Accuracy (%)
Precision (%)
Recall (%)
F-score (%)
False Alarm (%)
’buffer overﬂow’
’guess password’
’portsweep’
’teardrop’
’warezclient’
recall and precision results are not listed but the bar charts
show them to be around 69% and 83% respectively. Our
model has produced superior results by offering f-score of
87.37%, recall of 85.42% and precision of 100.00%.
Tang et al. claim that their Deep Neural Network
(DNN) approach achieved an accuracy of 75.75% when
performing a 5-class classiﬁcation of the NSL-KDD dataset.
This is result is lower than our achieved accuracy of 85.42%.
Whilst classifying the KDD Cup ’99 dataset, Kim et al.
 claim they have achieved an accuracy of accuracy of
96.93%. Also Gao et al. claim their deep learning DBN
model achieved an accuracy of 93.49%. Both of these results
are less than the 97.85% accomplished by our model.
These comparisons show that our model’s results are
very promising when compared to other current deep
learning-based methods.
CONCLUSION & FUTURE WORK
In this paper, we have discussed the problems faced by
existing NIDS techniques. In response to this we have
proposed our novel NDAE method for unsupervised feature
learning. We have then built upon this by proposing a novel
classiﬁcation model constructed from stacked NDAEs and
the RF classiﬁcation algorithm.
We have implemented our proposed model in Tensor-
Flow and performed extensive evaluations on its capabilities. For our evaluations we have utilised the benchmark
KDD Cup ’99 and NSL-KDD datasets and achieved very
promising results.
Our results have demonstrated that our approach offers
high levels of accuracy, precision and recall together with
reduced training time. Most notably, we have compared
our stacked NDAE model against the mainstream DBN
technique. These comparisons have demonstrated that our
model offers up to a 5% improvement in accuracy and training time reduction of up to 98.81%. Unlike most previous
work, we have evaluated the capabilities of our model based
on both benchmark datasets, revealing a consistent level of
classiﬁcation accuracy.
Although our model has achieved the above promising
results, we acknowledge that it is not perfect and there is
further room for improvement.
In our future work, the ﬁrst avenue of exploration for
improvement will be to assess and extend the capability of
our model to handle zero-day attacks. We will then look
to expand upon our existing evaluations by utilising realworld backbone network trafﬁc to demonstrate the merits
of the extended model.
ACKNOWLEDGEMENTS
The authors would like to thank the Royal Academy of
Engineering for their support provided through the Newton
Research Collaboration Programme.