Perception & Psychophysics
2001, 63 (7), 1171-1182
Perceptual groupingis the process whereby individual
items in the visual image are aggregated into larger structures. Grouping is known to influence many low-level visual computations, such as the perception of lightness
 , the perception of motion , and visual search . Yet the process by which a grouping interpretation is chosen, often described in terms of somewhat
vagueand poorly understoodGestalt principles,has proven
difficult to characterize precisely. Perhaps the main obstacle has been the difficulty in specifying in a mathematically rigorous way the various candidate interpretations
from which the visual system unconsciouslychooses, and
the function determining subjective preference among
these interpretations.Thispaper attemptsto develop such a
theory in the specific case of contourintegration—that is,
the aggregation of a sequence of visual items into a virtual curve—and then to test the predictionsof this model
against the judgments of human observers.
Bayesian Approaches to Perception
A natural candidate for a rigorous model is Bayesian
probability theory, which has often been advocated as an
optimal method for making decisions under conditionsof
uncertainty and has recently attracted a
great deal of interest among investigatorsof human vision
 . Bayesian or quasi-
Bayesian models have been brought to bear on the interpretation of motion and surfaces
 ,
recognitionof objects , classification of shapes , and combinationof
distinctcue sources . The application of Bayesian theory to grouping
may be more difficult than in these other cases, because,in
grouping, the target inference—the “best grouping”—is
difficult to describe formally and, arguably, might not
admit an objective definition (this issue is discussed
below). A fully realized Bayesian theory of human perceptual grouping would need to spell out the observer’s subjective model of what alternative grouping hypotheses are
possible, how they might give rise to possible image configurations, and with what likelihoods.
In Bayesian theory, the degree of belief in a perceptual
hypothesisH0 (henceforth called the target hypothesisor
target interpretation) given image I is expressed by the
posterior probability:
where H0, H1, .. . are candidateinterpretations,p(Hi) is the
prior probability of hypothesis Hi, and p(I|Hi), called a
likelihoodterm, is the probabilitythat the observed image
I would be generated by the hypothesisHi. The likelihood
term is a measure of fit between the hypothesis under
consideration and the image configuration. The prospect
Copyright 2001 Psychonomic Society, Inc.
This work was supported by National Science Foundation Grant
SBR-9875175.I am grateful to G. John Andersen and two anonymous
reviewers for helpful comments on the manuscript and to Henry Chi for
assistance in data collection. Address correspondence to J. Feldman, Department of Psychology,Center for CognitiveScience, Rutgers University, Busch Campus, New Brunswick, NJ 08903 (e-mail: jacob@ruccs.
rutgers.edu).
Bayesian contour integration
JACOB FELDMAN
Rutgers University, New Brunswick, New Jersey
The process by which the human visual system parses an image into contours, surfaces, and objects—perceptual grouping—has proven difficult to capture in a rigorous and generaltheory. A natural
candidate for such a theory is Bayesian probability theory, which provides optimal interpretations of
data under conditions of uncertainty. But the fit of Bayesian theory to human grouping judgments has
never been tested, in part because methods for expressing grouping hypotheses probabilistically have
not been available. This paper presents such methods for the case of contour integration—that is, the
aggregationof a sequence of visualitems into a “virtual curve.”Two experiments are reported in which
human subjects were asked to group ambiguous configurations of dots (in Experiment 1, a sequence
of five dots could be judged to contain a “corner” or not; in Experiment 2, an arrangement of six dots
could be judged to fall into two disjoint contours or one smooth contour). The Bayesian theory accounts extremely well for subjects’ judgments, explaining more than 75% of the variance in both tasks.
The theory thus provides a far more quantitativelyprecise account of human contour integration than
has been previously possible, allowing a very precise calculation of the subjective goodness of a virtual chain of dots. BecauseBayesiantheory is inferentiallyoptimal, this finding suggestsa “rational justification,” and hence possibly an evolutionary rationale, for some of the rules of perceptual grouping.
of formulating a Bayesian model of grouping hinges on
the construction of suitable likelihood terms for grouping hypotheses.
We focus on the case of grouping individual visual
items (dots, edge fragments, etc.) into smooth contours,
a process known to occur early and to be essential in the
construction of visual representations . The visual system’s tendency to
extract approximately collinear patterns from the image
has been investigatedin some detail .Yet, there is still
no quantitativemodel that will predict both (1) the subjective coherence of a dot pattern as a function of its geometry and (2) the particular grouping interpretation that a
human observer will perceive in an ambiguousconfiguration (e.g., the particular assignment of dots to distinct virtual curves. Moreover, what is known about the quantitative properties of curve grouping does not afford any
convenientmathematical generalization to other types of
groupingproblems, such as groupinginto surfaces and objects. Such a generalizationmight be providedby Bayesian
theory, which is in principle completelygeneral in its application.
A major obstacle is the lack of a model for how the system combines the many local estimates of collinearity
(e.g., theoutputsof local orientation-tunedcells) into a single global judgment of curve coherence, a problem sometimes referred to as cooperativity .It is believedthat
raw judgments of collinearity propagate laterally in visual
cortex , but the mathematical
form of the combinationrule is unknown.Arguments from
differential geometry suggest that along a smooth curve,
sampled at intervals to produce visible points, successive
angles between points should tend to be collinear, and the
implicit curve should be well approximated by the local
tangent . But such arguments do
not specify exactly how much deviation from collinearity
should suppress the impression of a subjective curve, nor
how successive angles should interact (i.e., the combination rule). These lacunae need to be repaired in order to
construct suitable subjective likelihood functions.
A Bayesian Model of Smooth Curves
Earlier studies have suggested
a mathematical form for the likelihood function correspondingto subjectivelysmooth curvilinearpatterns.The
simplest case is three visual items, parameterized by an
angle a1 measuring the deviation from perfect collinearity (0º) (see Figure 1). Human judgments of apparent
curvilinearity are consistent with a model in which,
under the hypothesis of a smooth curve, the expected
distributionof angle a1 is proportionalto a Gaussian distribution centered at 0º. That is, the likelihood function
for the smooth hypothesis, p(a1|smooth), is given by
where a3 is the standard deviation of the Gaussian distribution,and h3 is a proportionality constant. In the case of
four visual items, there are now two successiveangles,a1
and a2, and the joint distribution p(a1, a2 | smooth) is
where s4is the standard deviationof each of the two marginal distributions, r is the correlation coefficient, and h4
is a proportionality constant (Figure 2). Empirical estimates of correlationr have shown it to be nonzerobetween
successiveangles—that is, successive angles along a subjectivelysmooth curve are not independentlydistributed—
but, approximately zero between nonsuccessive angles
 . This means that by Bayes’ rule, the likelihood function for the general case of n items is the productof successiveiterationsof the function L4 (Equation 4).
Equation 4 represents a “moving four-item window”
operating on successive angle pairs, each of which contributes independently to the overall perception of a
smooth curve (Figure 3). In the spectrumof Bayesianmodels, the assumption of correlation between successive angles but independence between nonsuccessive angles
Figure 1. Notation of angles along a curvilinear pattern of dots.
BAYESIAN CONTOUR INTEGRATION
places this model somewhere between weak fusion (all
cues are assumed to be independent)and strong fusion (all
jointdensitiesare computed) ,approximately in the style of modified weak fusion .
The two “atomic” likelihood functions L3 and L4 together can be used to construct probabilistic models of
arbitrarily long smooth curves (L3 is needed only when a
curve contains only three items; the exact procedure is
detailed below), and, moreover, to build complete scene
representations consisting only of piece-wise smooth
contours. Hence, the resulting composite probabilistic
functions providerigorous numerical models of how well
candidate grouping interpretations fit the observed configuration, allowing the visual system to in effect select
the probabilisticallyoptimal groupinginterpretation. It is
worth noting that, notwithstanding their superficially
complex mathematical form, these functions may easily
be computed by simple arrangements of neural hardware
 .
The experimentsreported below investigatehuman subjects’ subjectivegroupingof dot configurationsinto piecewise smooth virtual curves. It is to be emphasized that the
Bayesian models presented below as accounts of subjects’ data are constructed entirely out of the atomic
functionsL3 and L4 and contain no unmotivatedor ad hoc
components.
Experiments
Two types of tasks were employed.In the corners task,
displays contained five dots parameterized by three angles, a1, a2, and a3 (Figure 4, top). In the corners task, the
angles used were 0º, ±15º, ±30º, and ±45º (a1, a3), and
0º, ±10º, ±20º, ±30º, ±40º, ±50º, and ±60º (a2), all fully
crossed, for a total of 7 ´ 13 ´ 7 = 637 combinations. As
illustrated in Figure 4, these parameters allow for a wide
variety of configurations,ranging from some that clearly
appear to have a corner, to some that appear to be quite
smooth. In the two-contours task, angles were 0º, ±15º,
±30º, and ±45º (a1, a3), and 0º, ±10º, ±20º, ±40º, and ±60º
(a2), all fully crossed, for a total of 7 ´ 7 ´ 7 = 343 combinations. Again, these parameters allow for a wide
range of configurations (Figure 4), including some that
appear to spontaneously “break” into two contours, eliciting a two contour response, as well as some that suggest
a single smooth contour.
Dots were dark circular patches(subtending0.11º of visualanglein thecorners task, and0.055ºor 0.11ºin the twop(a1,a2|smooth)
p(a1|smooth)
Figure 2. The atomic functions L3 and L4, used in the construction of Bayesian models. The functions give the expected
distribution of angles along a subjectively smooth virtual curve.
Figure 3. L4 is computed in parallel on groups of four dots lying
successively along a chain of dots.
contours task) on a uniform white background displayed
at high contrast in a darkened room at a 60-cm viewing
distance, with observers’ heads fixed by a chinrest.
In the corners task, each configuration was displayed
in a randomly chosen orientation. In the two-contours
task, configurationswere presenteduprightas in Figure 4.
(That is, each figure was displayed so that the second
and third dots were at the same height as each other, and
likewise the fourth and fifth dots.) Nineteen naive subjects were asked to judge, on a 1–5 scale, whether the dots
traced out a corner or a single smooth curve (1 = definitely a smooth curve, 5 = definitelya corner). In the twocontours task, displays contained six dots again parameterized by three angles, a1, a2, and a3 (Figure 4, bottom).
(In addition, two stimulus sizes were employed, but no
scale effects were found, and henceforth the data are presented collapsed across scale.) Seventeen naive subjects,
none of whom had participatedin the corners experiment,
were asked to rate whether the display containedtwo distinct smooth contours or one long smooth contour, again
on a 1–5 scale (1 = definitely one smooth contour, 5 =
definitely two smooth contours). Subjects’ mean ratings
of each condition,after normalizationto the interval(0,1),
were taken to represent the subjects’ a posteriori belief
that the stimulus configuration belonged to the target interpretation.
The two tasks were chosen in order to reflect two fundamental modes of contour extraction: Dots can be assigned to two completely disjoint contours, or they can be
assigned to two distinct sections of the same contour that
are separated by a perceived tangent discontinuity . One of the advantagesof a Bayesian approach is the possibility of treating these two modes of
grouping in a theoretically uniform manner, and, in fact,
both Bayesian models described below (one for each task)
draw on the same probabilistic vocabulary—namely, the
functions L3 and L4.
Bayesian Models of the Two Tasks
In each task, several groupinginterpretationsare possible, some leading to the target interpretation (corner or
two contours, respectively), others leading to the perception of a single smooth contour. One immediate complication is that in each task, there are several different perceptually distinct interpretations that all lead to the target
response. Consider first the corners task. In this task, one
may perceive a corner at the central dot; denote this interpretation by Hc. Alternatively, one may perceive a corner
at either the second or the fourth dot, again leading to a
corner response; denote these interpretations by Hc¢ and
Hc². Counterposedto these is the smooth interpretationHs.
All hypothesesunderconsiderationare depictedschematically in Figures 5 (corners) and 6 (two-contours).
For any hypothesis Hi, denote by Pi the product
p(Hi)p(I | Hi) of its prior and its likelihood. By Bayes’
rule, the probability of the target response (corner, regardless of where the corner is perceived) is
where h is a free scaling factor relating this expression to
the subjects’numeric ratings. Likelihoodfunctionsp(I|Hi)
were constructed for each interpretation in the following
manner. Three dotsat an angle,a1, are assigned likelihood
L3(a1). Four or more dots with angles a1, a2, . . . are assigned likelihoodby concatenations of the function L4 as
Figure 4. The two tasks employed, showing sample stimuli (left, with likely responses; stimuli not drawn to scale)
and illustration of the experimental variables a1, a2, and a3 (right).
BAYESIAN CONTOUR INTEGRATION
in Equation 4. One- or two-dot groups are each perfectly
consistent with a straight line and hence have likelihood
unity; they drop out of the resulting formulae. The full
Bayesian model for the corners task is then provided by
Equation 5, substituting p(Hi)p(I | Hi) for each Pi, and
then using Figure 5 to provide expressions for each likelihood term p(I |Hi).
The free parametersof theBayesianmodel includethree
parameters,s3, s4, and r, of the atomic functionsL3 and L4,
the overall scaling parameter h, and the priors. Although
there are four separate scalar priors in Equation5 (one for
each hypothesis),there are in fact really only two degrees
of freedom among the priors, after one assumes p(Hc¢) =
p(Hc²) (by symmetry) and further expresses all the priors
relative to one standard prior chosen arbitrarily. [In the
analysis, p(Hs) is omitted, implicitly representing p(Hc)
and p(Hc¢) as proportionsof it.] Boiling this all down, the
Bayesian model for the corners task contains six free parameters: s3, s4, r, p(Hc), p(Hc¢)[=p(Hc²)], and h. The first
three are the parameters of the atomic likelihood functions L3 and L 4; the next two are the free priors, and the
last is the overall scaling factor. The free parameters are
admittedly more numerous than in some previous contour integrationtheories, but all are motivated directly by
Bayesian theory and readily admit meaningful interpretation.In the analysisbelow, these six variablesare treated
as free parameters in a nonlinear regression fitting the
Bayesian model to subjects’ ratings.
An extremely similar analysis applies to the twocontourstasks,with hypothesesH2, H2¢, and H2² associated
with the response two contours, and Hs associated with
one contour (Figure 6; note that here Hs has a different
mathematical form than in the corners task due to the
different stimulusgeometry). Figures 5 and 6 give explicit
expressions for the likelihood of each hypothesis under
consideration in both tasks.
First, for both tasks, the effects and interactions of all
three angularvariables,a1, a2, and a3, were submittedto an
analysisof variance(ANOVA). In bothtasks, all three main
effects, all 3 two-way interactions,and thethree-way interaction were significant at p < .0001 (statistical details are
givenin Table 1). Figures7 (corners) and 8 (two-contours)
show the main effects of a1, a2, and a3 (along with the
Bayesian model, discussed below), and Figures 9 and 10
show the 3 two-way interactions a1 ´ a2, a1 ´ a3, and a2 ´
a3. The most salient main effects were that, in both tasks,
target interpretations (1) increased markedly as angle a2
increased and (2) decreased as a1 and a2 increased, except at the tails, where target interpretations again increased. The effect of a2 was much larger in magnitude
than that of a1 and a3.
The significant interactions suggest a nonlinear decision surface, and, indeed, the plots of the 3 two-way interactions (Figures 9 and 10) show highly curved surfaces.
As remarked by Jaynes , “Bayes’ theorem automatically generates the exact nonlinear function called for by
the problem” (p. 268), and hence it might be hoped that
Bayesian theory would provide a quantitative account of
Figure 5. Candidate hypotheses in the corners task, showing illustration
(left) and mathematical form (right).
the shapes of these surfaces. Hence, in the next analysis,
the Bayesian model derived above was fit to the full fourdimensional decision surface (probability as a function of
a1, a2, and a3).
Figures 7 and 8 show the best-fit Bayesian model (chosen by Levenburg–Marquardt, using least-squared error)
superimposed on the subjects’ data. For ease of viewing,
the Bayesian model is shown superimposed on the marginal means (main effects) only, but note that the model
shown reflects a fit not just to this relatively small number of data points, but rather to the full 4-D response surface, comprising 637 independent data points in the corners task, and 343 in the two-contours task, while using
only six degrees of freedom in each model. The fit is extremely good [corners, R2 = .8443; F(6,631) = 88.78, p <
.000001; two-contours, R2 = .7686; F(6,337) = 43.17307,
p < .000001],althoughin the two-contours data, the subjects’ responses seem slightly more peaked than in the
model. The good fit of the models to relatively subtle effects (e.g., the rising tails in a1 and a3) reflects the power
of Bayesian machinery to make quantitative predictions
beyond what is intuitively obvious. In particular, the
Bayesian model makes an accurate prediction about exactly how various angularcues are combined—the problem of cooperativitythat is rarely successfully addressed
in conventional theories.
Estimated parameters of the Bayesian models are
given in Table 2. All six parameters in each model made
significantcontributionsto the fit, as determinedby comparing fits with versus without each parameter (details
are given in Table 2). The parameters s3, s4, and r controlling the atomic functions L3 and L4 are very similar in
the two tasks (see the first three rows in Table 2). This result is especially crucial because it supports the hypothesis that, notwithstanding the difference between the two
tasks, subjects’ judgments were constructedfrom a fixed
and stable probabilistic lexicon. It is worth noting, however, that these estimates differ from earlier estimates
 . These differences may be attributable
to the difference in tasks (judging the smoothness of a
single dot pattern vs. grouping an entire configuration
into separate smooth components), although this is admittedly speculative. Such context-drivenmodulation of
parameters may be related to the neurophysiological
finding of rapid modulationof lateral connectionswithin
visual cortex and, in Bayesian theory, to the
mathematical notion of competitive priors .
Figure 6. Candidate hypotheses in the two-contours task, showing illustration (left) and mathematical
form (right).
Details of the Analyses of Variance
Corners zTask
Two-Contours Task
a1 ´ a2 ´ a3
BAYESIAN CONTOUR INTEGRATION
Figure 7. Subjects’ data and the Bayesian model in the corners task, showing proportion corners judgment as a function of a1 (top), a2 (middle), and a3
(bottom). Error bars are standard errors.
Figure 8. Subjects’ data and the Bayesian model in the two-contours task,
showing proportion two contours judgments as a function of a1 (top), a2 (middle), and a3 (bottom). Data shown are collapsed over scale. Error bars are standard errors.
BAYESIAN CONTOUR INTEGRATION
Conclusions
The very close fit of the Bayesian model compares favorably with the results from existing theories in other
grouping domains. By comparison, only a few years ago,
numerical theories of proximity grouping were judged to
be empirically successful simply when they agreed with
human judgments more often than chance , althoughmore recently, standards of empirical successin that area—but not in collinearitygrouping—
have improved .
This good fit means that with the aid of Bayesian calculations, the subjectivegoodness of a virtual curve of dots
can be calculated with about an order of magnitude more
precise than with conventional treatments. (In most current treatments, curves are classified simply as curved
[angles generated at random from, e.g., ±30º] or straight
[angles near 0º]; this means that subjective goodness is
treated as if it depended only on the mean angle over the
entire curve, a far coarser measure than the combinations
of L4 used here.)
Some of the goodness of fit could be due to the choice
of Gaussian likelihood functions and the use of pooled
data, because sums of independent distributions tend toward normality (the central limit theorem). However, statistical analysisof individualsubject’s data in earlier studies showed that the model fit is reduced
only slightly, and visual inspectionof individualsubjects’
data in the present experiments suggests the same. In any
Figure 9. Two-way interactions in the corners task: a1 ´ a2 (top), a1 ´ a3 (middle), and a2 ´
a3 (bottom).
case, the use of Gaussian likelihoodfunctionsis well motivated by Bayesian theory. The Gaussian distribution is
the maximum-entropy distribution given a fixed mean
and variance .In the presentcase,
this means that, given an assumption that curves tend to
continuesmoothly,with a certain expectations of spread
about the expected direction,a Gaussian likelihoodfunction encodes this assumption with the absolute minimum
of additionalassumptions or information .
This makes the choice of Gaussians a very reasonable one
for a visual system in which contours are expected to be
curvilinear but in which any more specific knowledge of
the geometry of contoursin its environment is lacking. Ultimately, the close fits reported
abovesuggest that whatever their rationale,Gaussians are
the visual system’s choice, or very nearly so.
Traditionally,within psychology,perceptual grouping
has often been treated as a “subjective”task—that is, one
without a definitely correct or incorrect answer. Indeed,
the “goodness” of a grouping interpretation has sometimes been treated by Gestalt writers as if it were virtually an aesthetic attribute. Conversely, it is possible to
view grouping as the solution to a definite problem—
namely, the identification of visual elements in the image
Figure 10. Two-way interactions in the two-contours task: a1 ´ a2 (top), a1 ´ a3 (middle),
and a2 ´ a3 (bottom).
BAYESIAN CONTOUR INTEGRATION
that arose from the same physical source in the scene—
for example, the same object edge or surface. This view
is attractive from a computational point of view, in that
it provides the beginnings of a rationale for the selection
of algorithms: Prefer those algorithms that tend to solve
that problem successfully. Clearly, this is the assumption
implicit in the Bayesian theory proposed above, in which
the observer explicitly chooses between the hypothesis
that a given element arises from one curve and the hypothesis that it arises from another. Nevertheless, some care
must be taken to avoid circularity here, because the question of which elements in the scene are “truly” part of
the same object does not bear a completely objective answer and would normally be answered by appealing perceptual grouping(perhaps from anotherview of the same
scene, at a different viewing angle, or at a different time).
Still, one can certainly imagine that some grouping interpretations would be more successful than others in
terms of their consistencywith the later actions of the observer, such as manipulation of the objects observed in
the scene.
In the case of Bayesian grouping, this raises a puzzle:
If Bayesian theory tends to yield the “correct” answer,
what exactlyis correct aboutit in the case of grouping?An
argument drawn from the historicaldebate overBayesianism providesone possible answer. The Bayesiangrouping
interpretationis not necessarily an objectivelyoptimal interpretation of the world, but it does represent a provably
optimal use of the observer’s prior knowledge and beliefs
 : in this case, the
visualsystem’s beliefsaboutthe geometricform of smooth
curves, as here embodied by the likelihood functions L3
and L4. That is, Bayesian theory yields grouping percepts
that parse the world in a way most harmonious with the
visual system’s implicit mental model of smooth curves.
That this tends to lead to successful percepts reflects both
the aptness of the subjective priors and the optimality of
Bayesian theory’s use of them.
In this sense, Bayesian groupingtheory is not truly normative, because the priors and likelihood functions are
motivated by extra-Bayesian considerations and, in some surprising respects, even run counter
to mathematically correct statistical reasoning . Nevertheless, these functions are apparently manipulated by neural machinery in an almost strictly
Bayesian fashion. This realizationsheds new light on the
Gestalt principle of good continuation, which, along
with otherGestalt principles,is conventionallyheld up as a
cornerstone of human perceptual grouping. As has often
been pointed out, such principles really describe a particular behavioral tendency, rather than explain or justify it.
The link to Bayes’ rule demonstrated here suggests that
the principle of good continuation, and, given the theoretically universal range of applicability of Bayesian reasoning, perhaps other Gestalt principles, can indeed be
regarded as a rational strategy for perception. The significance of this point, in the context of the recent debate
over the evolutionary adaptiveness of human mental
strategies and heuristics, is obvious. Indeed, the natural
next step is to extend the mathematics presented above to
other types of perceptual grouping (e.g., region grouping, amodal completion, etc.), with the hope that the
close fit to human judgments found here can be duplicated outside the narrow case of contour integration.