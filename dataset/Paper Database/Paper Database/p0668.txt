Moment Matching for Multi-Source Domain Adaptation
Xingchao Peng
Boston University
 
Qinxun Bai
Horizon Robotics
 
Boston University
 
Zijun Huang
Columbia University
 
Kate Saenko
Boston University
 
Vector Institute & Peter Munk Cardiac Center
 
Conventional unsupervised domain adaptation (UDA)
assumes that training data are sampled from a single domain.
This neglects the more practical scenario where
training data are collected from multiple sources, requiring multi-source domain adaptation. We make three major contributions towards addressing this problem. First,
we collect and annotate by far the largest UDA dataset,
called DomainNet, which contains six domains and about
0.6 million images distributed among 345 categories, addressing the gap in data availability for multi-source UDA
Second, we propose a new deep learning approach, Moment Matching for Multi-Source Domain Adaptation (M3SDA), which aims to transfer knowledge learned
from multiple labeled source domains to an unlabeled target
domain by dynamically aligning moments of their feature
distributions. Third, we provide new theoretical insights
speciﬁcally for moment matching approaches in both single and multiple source domain adaptation. Extensive experiments are conducted to demonstrate the power of our
new dataset in benchmarking state-of-the-art multi-source
domain adaptation methods, as well as the advantage of
our proposed model. Dataset and Code are available at
 
1. Introduction
Generalizing models learned on one visual domain to
novel domains has been a major obstacle in the quest
for universal object recognition. The performance of the
learned models degrades signiﬁcantly when testing on novel
domains due to the presence of domain shift .
Recently, transfer learning and domain adaptation methods have been proposed to mitigate the domain gap. For
example, several UDA methods incorporate
Maximum Mean Discrepancy loss into a neural network to
diminish the domain discrepancy; other models introduce
different learning schema to align the source and target domains, including aligning second order correlation ,
real quickdraw painting infograph clipart
bicycle bird strawberry flower pizza butterfly
Figure 1. We address Multi-Source Domain Adaptation where
source images come from multiple domains. We collect a large
scale dataset, DomainNet, with six domains, 345 categories, and
∼0.6 million images and propose a model (M3SDA) to transfer
knowledge from multiple source domains to an unlabeled target
moment matching , adversarial domain confusion and GAN-based alignment . However,
most of current UDA methods assume that source samples
are collected from a single domain. This assumption neglects the more practical scenarios where labeled images
are typically collected from multiple domains. For example, the training images can be taken under different weather
or lighting conditions, share different visual cues, and even
have different modalities (as shown in Figure 1).
In this paper, we consider multi-source domain adaptation (MSDA), a more difﬁcult but practical problem of
knowledge transfer from multiple distinct domains to one
unlabeled target domain. The main challenges in the research of MSDA are that: (1) the source data has multiple
domains, which hampers the effectiveness of mainstream
single UDA method; (2) source domains also possess domain shift with each other; (3) the lack of large-scale multidomain dataset hinders the development of MSDA models.
In the context of MSDA, some theoretical analysis has been proposed for multi-source domain
 
Classes Domains Description
Digit-Five
Ofﬁce 
Ofﬁce-Caltech 2012
CAD-Pascal 
animal,vehicle
Ofﬁce-Home 
ofﬁce, home
animal, stuff
Open MIC 
Syn2Real 
2018 280,157
animal,vehicle
DomainNet (Ours)
see Appendix
Table 1. A collection of most notable datasets to evaluate domain
adaptation methods. Speciﬁcally, “Digit-Five” dataset indicates
ﬁve most popular digit datasets (MNIST , MNIST-M , Synthetic Digits , SVHN, and USPS) which are widely used to evaluate domain adaptation models. Our dataset is challenging as it
contains more images, categories, and domains than other datasets.
(see Table 10, Table 11, and Table 12 in Appendix for detailed
categories.)
adaptation (MSDA). Ben-David et al pioneer this direction by introducing an H∆H-divergence between the
weighted combination of source domains and target domain. More applied works use an adversarial discriminator to align the multi-source domains with the target domain. However, these works focus only on aligning the source domains with the target, neglecting the domain shift between the source domains. Moreover, H∆Hdivergence based analysis does not directly correspond to
moment matching approaches.
In terms of data, research has been hampered due to the
lack of large-scale domain adaptation datasets, as state-ofthe-art datasets contain only a few images or have a limited number of classes. Many domain adaptation models
exhibit saturation when evaluated on these datasets. For example, many methods achieve ∼90 accuracy on the popular
Ofﬁce dataset; Self-Ensembling reports ∼99% accuracy on the “Digit-Five” dataset and ∼92% accuracy on
Syn2Real dataset.
In this paper, we ﬁrst collect and label a new multidomain dataset called DomainNet, aiming to overcome
benchmark saturation.
Our dataset consists of six distinct domains, 345 categories and ∼0.6 million images. A
comparison of DomainNet and several existing datasets is
shown in Table 1, and example images are illustrated in
We evaluate several state-of-the-art single domain adaptation methods on our dataset, leading to surprising ﬁndings (see Section 5). We also extensively evaluate
our model on existing datasets and on DomainNet and show
that it outperforms the existing single- and multi-source approaches.
Secondly, we propose a novel approach called M3SDA
to tackle MSDA task by aligning the source domains with
the target domain, and aligning the source domains with
each other simultaneously. We dispose multiple complex
adversarial training procedures presented in , but directly align the moments of their deep feature distributions,
leading to a more robust and effective MSDA model. To our
best knowledge, we are the ﬁrst to empirically demonstrate
that aligning the source domains is beneﬁcial for MSDA
Finally, we extend existing theoretical analysis to the case of moment-based divergence between source
and target domains, which provides new theoretical insight
speciﬁcally for moment matching approaches in domain
adaptation, including our approach and many others.
2. Related Work
Domain Adaptation Datasets Several notable datasets that
can be utilized to evaluate domain adaptation approaches
are summarized in Table 1. The Ofﬁce dataset is a
popular benchmark for ofﬁce environment objects. It contains 31 categories captured in three domains: ofﬁce environment images taken with a high quality camera (DSLR),
ofﬁce environment images taken with a low quality camera
(Webcam), and images from an online merchandising website (Amazon). The ofﬁce dataset and its extension, Ofﬁce-
Caltech10 , have been used in numerous domain adaptation papers , and the adaptation performance has reached ∼90% accuracy. More recent benchmarks are proposed to evaluate the effectiveness of domain adaptation models. However, these datasets
are small-scale and limited by their speciﬁc environments,
such as ofﬁce, home, and museum. Our dataset contains
about 600k images, distributed in 345 categories and 6 distinct domains. We capture various object divisions, ranging
from furniture, cloth, electronic to mammal, building, etc.
Single-source UDA Over the past decades, various singlesource UDA methods have been proposed. These methods
can be taxonomically divided into three categories. The ﬁrst
category is the discrepancy-based DA approach, which utilizes different metric learning schemas to diminish the domain shift between source and target domains. Inspired by
the kernel two-sample test , Maximum Mean Discrepancy (MMD) is applied to reduce distribution shift in various methods . Other commonly used methods
include correlation alignment , Kullback-Leibler
(KL) divergence , and H divergence . The second
category is the adversarial-based approach . A domain discriminator is leveraged to encourage the domain
confusion by an adversarial objective. Among these approaches, generative adversarial networks are widely used
to learn domain-invariant features as well to generate fake
source or target data. Other frameworks utilize only adversarial loss to bridge two domains. The third category
is reconstruction-based, which assumes the data reconstruction helps the DA models to learn domain-invariant
features. The reconstruction is obtained via an encodertree
spreadsheet
strawberry
watermelon
sea turtle
streetlight
lighthouse
helicopter
hot air balloon
wine glass
teddy-bear
wristwatch
toothbrush
animal migration
skateboard
washing machine
wine bottle
coffee cup
house plant
school bus
cruise ship
toothpaste
eyeglasses
rhinoceros
television
flashlight
waterslide
rollerskates
soccer ball
sleeping bag
binoculars
pickup truck
screwdriver
police car
microphone
tennis racquet
traffic light
flip flops
flying saucer
The Great Wall
garden hose
diving board
hockey puck
fire hydrant
blackberry
frying pan
basketball
paper clip
alarm clock
baseball bat
paintbrush
smiley face
remote control
The Mona Lisa
string bean
picture frame
floor lamp
dishwasher
chandelier
aircraft carrier
calculator
camouflage
ceiling fan
Number of Instances
streetlight
wine glass
toothbrush
toothpaste
sleeping bag
picture frame
floor lamp
chandelier
ceiling fan
rhinoceros
stethoscope
skateboard
screwdriver
wristwatch
eyeglasses
rollerskates
flip flops
camouflage
spreadsheet
headphones
washing machine
light bulb
television
flashlight
microphone
power outlet
remote control
cell phone
dishwasher
calculator
lighthouse
The Eiffel Tower
skyscraper
waterslide
The Great Wall
garden hose
diving board
coffee cup
binoculars
paper clip
alarm clock
paintbrush
smiley face
school bus
pickup truck
police car
roller coaster
birthday cake
sea turtle
teddy-bear
animal migration
traffic light
fire hydrant
The Mona Lisa
strawberry
watermelon
blackberry
soccer ball
hockey stick
tennis racquet
flying saucer
hockey puck
basketball
baseball bat
house plant
string bean
wine bottle
frying pan
cruise ship
aircraft carrier
helicopter
hot air balloon
Number of Instances
furniture (9.93%)
mammal (8.22%)
tool (7.33%)
cloth (6.48%)
electricity (6.45%)
building (6.39%)
office (5.76%)
human body (5.52%)
road transport (4.64%)
food (4.04%)
nature (3.93%)
cold blooded (3.92%)
other (3.60%)
music (2.80%)
fruit (2.79%)
sport (2.66%)
tree (2.54%)
bird (2.40%)
vegetable (2.31%)
shape (2.04%)
kitchen (1.97%)
water transport (1.88%)
sky transport (1.21%)
insect (1.15%)
Figure 2. Statistics for our DomainNet dataset. The two plots show object classes sorted by the total number of instances. The top
ﬁgure shows the percentages each domain takes in the dataset. The bottom ﬁgure shows the number of instances grouped by 24 different
divisions. Detailed numbers are shown in Table 10, Table 11 and Table 12 in Appendix. (Zoom in to see the exact class names!)
decoder or a GAN discriminator, such as dual-
GAN , cycle-GAN , disco-GAN , and Cy-
CADA .
Though these methods make progress on
UDA, few of them consider the practical scenario where
training data are collected from multiple sources. Our paper
proposes a model to tackle multi-source domain adaptation,
which is a more general and challenging scenario.
Multi-Source Domain Adaptation Compared with single
source UDA, multi-source domain adaptation assumes that
training data from multiple sources are available. Originated from the early theoretical analysis , MSDA
has many practical applications . Ben-David et al 
introduce an H∆H-divergence between the weighted combination of source domains and target domain. Crammer
et al establish a general bound on the expected loss of
the model by minimizing the empirical loss on the nearest
k sources. Mansour et al claim that the target hypothesis can be represented by a weighted combination of source
hypotheses. In the more applied works, Deep Cocktail Network (DCTN) proposes a k-way domain discriminator
and category classiﬁer for digit classiﬁcation and real-world
object recognition. Hoffman et al propose normalized
solutions with theoretical guarantees for cross-entropy loss,
aiming to provide a solution for the MSDA problem with
very practical beneﬁts. Duan et al propose Domain Selection Machine for event recognition in consumer videos
by leveraging a large number of loosely labeled web images from different sources. Different from these methods,
our model directly matches all the distributions by matching the moments. Moreover, we provide a concrete proof of
why matching the moments of multiple distributions works
for multi-source domain adaptation.
Moment Matching The moments of distributions have
been studied by the machine learning community for a long
In order to diminish the domain discrepancy between two domains, different moment matching schemes
have been proposed. For example, MMD matches the ﬁrst
moments of two distributions. Sun et al propose an approach that matches the second moments. Zhang et al 
propose to align inﬁnte-dimensional covariance matrices in
RKHS. Zellinger et al introduce a moment matching
regularizer to match high moments. As the generative adversarial network (GAN) becomes popular, many GANbased moment matching approaches have been proposed.
McGAN utilizes a GAN to match the mean and covariance of feature distributions. GMMN and MMD
GAN are proposed for aligning distribution moments
with generative neural networks. Compared to these methods, our work focuses on matching distribution moments
for multiple domains and more importantly, we demonstrate
that this is crucial for multi-source domain adaptation.
3. The DomainNet dataset
It is well-known that deep models require massive
amounts of training data. Unfortunately, existing datasets
for visual domain adaptation are either small-scale or limited in the number of categories.
We collect by far the
largest domain adaptation dataset to date, DomainNet . The
DomainNet contains six domains, with each domain containing 345 categories of common objects, as listed in Table 10, Table 11, and Table 12 (see Appendix). The domains include Clipart (clp, see Appendix, Figure 9): collection of clipart images; Infograph (inf, see Figure 10):
infographic images with speciﬁc object; Painting (pnt, see
Figure 11): artistic depictions of objects in the form of
paintings; Quickdraw (qdr, see Figure 12): drawings of
the worldwide players of game “Quick Draw!”1; Real (rel,
see Figure 13): photos and real world images; and Sketch
1 
Share Weights
Share Weights
classifier
classifier
Final Prediction
Source Domains
Feature Extractor
Moment Matching Component
Classifiers Trained
on Source Domains
i-th source domain
j-th source domain
target domain
Dotted lines appear in test phase
Figure 3. The framework of Moment Matching for Multi-source Domain Adaptation (M3SDA). Our model consists of three components: i) feature extractor, ii) moment matching component, and iii) classiﬁers. Our model takes multi-source annotated training data as
input and transfers the learned knowledge to classify the unlabeled target samples. Without loss of generality, we show the i-th domain and
j-th domain as an example. The feature extractor maps the source domains into a common feature space. The moment matching component
attempts to match the i-th and j-th domains with the target domain, as well as matching the i-th domain with the j-th domain. The ﬁnal
predictions of target samples are based on the weighted outputs of the i-th and j-th classiﬁers. (Best viewed in color!)
(skt, see Figure 14): sketches of speciﬁc objects.
The images from clipart, infograph, painting, real, and
sketch domains are collected by searching a category name
combined with a domain name (e.g. “aeroplane painting”)
in different image search engines. One of the main challenges is that the downloaded data contain a large portion
of outliers. To clean the dataset, we hire 20 annotators to
manually ﬁlter out the outliers. This process took around
2,500 hours (more than 2 weeks) in total. To control the
annotation quality, we assign two annotators to each image,
and only take the images agreed by both annotators. After the ﬁltering process, we keep 423.5k images from the
1.2 million images crawled from the web. The dataset has
an average of around 150 images per category for clipart
and infograph domain, around 220 per category for painting and sketch domain, and around 510 for real domain. A
statistical overview of the dataset is shown in Figure 2.
The quickdraw domain is downloaded directly from
 The raw
data are presented as a series of discrete points with temporal information. We use the B-spline algorithm to connect all the points in each strike to get a complete drawing.
We choose 500 images for each category to form the quickdraw domain, which contains 172.5k images in total.
4. Moment Matching for Multi-Source DA
Given DS = {D1, D2, ..., DN} the collection of labeled
source domains and DT the unlabeled target domain, where
all domains are deﬁned by bounded rational measures on
input space X, the multi-source domain adaptation problem
aims to ﬁnd a hypothesis in the given hypothesis space H,
which minimizes the testing target error on DT .
Deﬁnition 1. Assume X1, X2 , ..., XN, XT are collections
of i.i.d. samples from D1, D2, ..., DN, DT respectively, then
the Moment Distance between DS and DT is deﬁned as
MD2(DS, DT ) =
M3SDA We propose a moment-matching model for MSDA
based on deep neural networks.
As shown in Figure 3,
our model comprises of a feature extractor G, a momentmatching component, and a set of N classiﬁers C
{C1, C2, ..., CN}. The feature extractor G maps DS, DT
to a common latent feature space. The moment matching
component minimizes the moment-related distance deﬁned
in Equation 1. The N classiﬁers are trained on the annotated source domains with cross-entropy loss. The overall
objective function is:
LDi + λ min
G MD2(DS, DT ),
where LDi is the softmax cross entropy loss for the classi-
ﬁer Ci on domain Di, and λ is the trade-off parameter.
M3SDA assumes that p(y|x) will be aligned automatically when aligning p(x), which might not hold in practice.
To mitigate this limitation, we further propose M3SDA-β.
M3SDA-β In order to align p(y|x) and p(x) at the
same time, we follow the training paradigm proposed
In particular,
we leverage two classiﬁers
per domain to form N
pairs of classiﬁers C′
{(C1, C1′), (C2, C2′), ..., (CN, CN ′)}. The training procedure includes three steps. i). We train G and C′ to classify
the multi-source samples correctly. The objective is similar
to Equation 2. ii). We then train the classiﬁer pairs for a
ﬁxed G. The goal is to make the discrepancy of each pair
of classiﬁers as large as possible on the target domain. For
example, the outputs of C1 and C1′ should possess a large
discrepancy. Following , we deﬁne the discrepancy of
two classiﬁers as the L1-distance between the outputs of the
two classiﬁers. The objective is:
|PCi(DT ) −PCi′(DT )|,
where PCi(DT ), PCi′(DT ) denote the outputs of Ci, Ci′
respectively on the target domain. iii). Finally, we ﬁx C′ and
train G to minimize the discrepancy of each classiﬁer pair
on the target domain. The objective function is as follows:
|PCi(DT ) −PCi′(DT )|,
These three training steps are performed periodically until
the whole network converges.
Ensemble Schema In the testing phase, testing data from
the target domain are forwarded through the feature generator and the N classiﬁers. We propose two schemas to
combine the outputs of the classiﬁers:
• average the outputs of the classiﬁers, marked as
• Derive a weight vector W
(w1, . . . , wN−1)
i=1 wi = 1, assuming N-th domain is the target).
The ﬁnal prediction is the weighted average of the outputs.
To this end, how to derive the weight vector becomes a
critical problem. The main philosophy of the weight vector is to make it represent the intrinsic closeness between
the target domain and source domains.
In our setting,
the weighted vector is derived by the source-only accuracy between the i-th domain and the N-th domain, i.e.
wi = acci/PN−1
4.1. Theoretical Insight
Following , we introduce a rigorous model of multisource domain adaptation for binary classiﬁcation. A domain D = (µ, f) is deﬁned by a probability measure (distribution) µ on the input space X and a labeling function f :
X →{0, 1}. A hypothesis is a function h : X →{0, 1}.
The probability that h disagrees with the domain labeling
function f under the domain distribution µ is deﬁned as:
ϵD(h) = ϵD(h, f) = Eµ[|h(x) −f(x)|].
For a source domain DS and a target domain DT , we
refer to the source error and the target error of a hypothesis h as ϵS(h) = ϵDS(h) and ϵT (h) = ϵDT (h) respectively. When the expectation in Equation 5 is computed
with respect to an empirical distribution, we denote the corresponding empirical error by ˆϵD(h), such as ˆϵS(h) and
In particular, we examine algorithms that minimize convex combinations of source errors, i.e., given a
weight vector α = (α1, . . . , αN) with PN
j=1 αj = 1, we
deﬁne the α-weighted source error of a hypothesis h as
ϵα(h) = PN
j=1 αjϵj(h), where ϵj(h) is the shorthand of
ϵDj(h). The empirical α-weighted source error can be de-
ﬁned analogously and denoted by ˆϵα(h).
Previous theoretical bounds on the target error are based on the H∆H-divergence between the source
and target domains. While providing theoretical insights
for general multi-source domain adaptation, these H∆Hdivergence based bounds do not directly motivate momentbased approaches.
In order to provide a speciﬁc insight
for moment-based approaches, we introduce the k-th order cross-moment divergence between domains, denoted
by dCM k(·, ·), and extend the analysis in to derive the
following moment-based bound for multi-source domain
adaptation. See Appendix for the deﬁnition of the crossmoment divergence and the proof of the theorem.
Theorem 1. Let H be a hypothesis space of V C dimension
d. Let m be the size of labeled samples from all sources
{D1, D2, ..., DN}, Sj be the labeled sample set of size βjm
j βj = 1) drawn from µj and labeled by the groundtruth
labeling function fj. If ˆh ∈H is the empirical minimizer of
ˆϵα(h) for a ﬁxed weight vector α and h∗
T = minh∈H ϵT (h)
is the target error minimizer, then for any δ ∈(0, 1) and
any ϵ > 0, there exist N integers {nj
j=1 and N constants
j=1, such that with probability at least 1 −δ,
ϵT (ˆh) ≤ϵT (h∗
T ) + ηα,β,m,δ + ϵ
dCM k(Dj, DT )
where ηα,β,m,δ = 4
βj )( 2d(log( 2m
d )+1)+2 log( 4
and λj = minh∈H{ϵT (h) + ϵj(h)}.
Theorem 1 shows that the upper bound on the target error
of the learned hypothesis depends on the pairwise moment
divergence dCM k(DS, DT ) between the target domain and
each source domain.2
This provides a direct motivation
for moment matching approaches beyond ours. In particular, it motivates our multi-source domain adaptation approach to align the moments between each target-source
pair. Moreover, it is obvious that the last term of the bound,
k dCM k(Dj, DT ), is lower bounded by the pairwise divergences between source domains. To see this, consider
2Note that single source is just a special case when N = 1.
mt,up,sv,sy
mm,up,sv,sy
mm,mt,sv,sy
mm,mt,up,sy
mm,mt,up,sv
Source Only
63.70±0.83
92.30±0.91
90.71±0.54
71.51±0.75
83.44±0.79
80.33±0.76
67.87±0.75
97.50± 0.62
93.49±0.85
67.80±0.84
86.93±0.93
82.72± 0.79
70.81±0.94
97.90±0.83
93.47±0.79
68.50±0.85
87.37±0.68
83.61±0.82
Source Only
63.37±0.74
90.50±0.83
88.71±0.89
63.54±0.93
82.44±0.65
77.71±0.81
63.78±0.71
96.31±0.54
94.24±0.87
62.45±0.72
85.43±0.77
80.44±0.72
CORAL 
62.53±0.69
97.21±0.83
93.45±0.82
64.40±0.72
82.77±0.69
80.07±0.75
71.30±0.56
97.60±0.75
92.33±0.85
63.48±0.79
85.34±0.84
82.01±0.76
65.88±0.68
97.21±0.73
95.42±0.77
75.27±0.71
86.55±0.64
84.07±0.71
71.57± 0.52
97.89±0.84
92.83±0.74
75.48±0.48
86.45±0.62
84.84±0.64
70.53±1.24
96.23±0.82
92.81±0.27
77.61±0.41
86.77±0.78
84.79±0.72
71.31±0.75
96.47±0.78
97.01±0.82
78.45±0.77
84.62±0.79
85.60± 0.78
72.50±0.67
96.21±0.81
95.33±0.74
78.89±0.78
87.47±0.65
86.10±0.73
M3SDA (ours)
69.76±0.86
98.58±0.47
95.23±0.79
78.56±0.95
87.56±0.53
86.13±0.64
M3SDA-β (ours)
72.82±1.13
98.43±0.68
96.14±0.81
81.32±0.86
89.58±0.56
87.65± 0.75
Digits Classiﬁcation Results. mt, up, sv, sy, mm are abbreviations for MNIST, USPS, SVHN, Synthetic Digits, MNIST-M,
respectively. Our model M3SDA and M3SDA-β achieve 86.13% and 87.65% accuracy, outperforming other baselines by a large margin.
the toy example consisting of two sources D1, D2, and a
target DT , since dCM k(·, ·) is a metric, triangle inequality
implies the following lower bound:
dCM k(D1, DT ) + dCM k(D2, DT ) ≥dCM k(D1, D2).
This motivates our algorithm to also align the moments between each pair of source domains. Intuitively, it is not possible to perfectly align the target domain with every source
domain, if the source domains are not aligned themselves.
Further discussions of Theorem 1 and its relationship with
our algorithm are provided in the Appendix.
5. Experiments
We perform an extensive evaluation on the following
tasks: digit classiﬁcation (MNIST, SVHN, USPS, MNIST-M,
Sythetic Digits), and image recognition (Ofﬁce-Caltech10,
DomainNet dataset). In total, we conduct 714 experiments.
The experiments are run on a GPU-cluster with 24 GPUs
and the total running time is more than 21,440 GPU-hours.
Due to space limitations, we only report major results; more
implementation details are provided in the supplementary
material. Throughout the experiments, we set the trade-off
parameter λ in Equation 2 as 0.5. In terms of the parameter
sensitivity, we have observed that the performance variation
is not signiﬁcant if λ is between 0.1∼1. All of our experiments are implemented in the PyTorch3 platform.
5.1. Experiments on Digit Recognition
Five digit datasets are sampled from ﬁve different
sources, namely MNIST , Synthetic Digits , MNIST-
M , SVHN, and USPS. Following DCTN , we sample
25000 images from training subset and 9000 from testing
subset in MNIST, MINST-M, SVHN, and Synthetic Digits.
USPS dataset contains only 9298 images in total, so we take
3 
the entire dataset as a domain. In all of our experiments, we
take turns to set one domain as the target domain and the
rest as the source domains.
We take four state-of-the-art discrepancy-based approaches: Deep Adaptation Network (DAN), Joint
Adaptation Network (JAN), Manifold Embedded Distribution Alignment (MEDA), and Correlation Alignment 
(CORAL), and four adversarial-based approaches: Domain Adversarial Neural Network (DANN), Adversarial Discriminative Domain Adaptation (ADDA), Maximum Classiﬁer Discrepancy (MCD) and Deep Cocktail
Network (DCTN) as our baselines. In the source combine setting, all the source domains are combined to a single domain, and the baseline experiments are conducted in
a traditional single domain adaptation manner.
The results are shown in Table 2. Our model M3SDA
achieves an 86.13% average accuracy, and M3SDA-β
boosts the performance to 87.65%, outperforming other
baselines by a large margin. One interesting observation
is that the results on MNIST-M dataset is lower. This phenomenon is probably due to the presence of negative transfer .
For a fair comparison, all the experiments are
based on the same network architecture. For each experiment, we run the same setting for ﬁve times and report the
mean and standard deviation. (See Appendix for detailed
experiment settings and analyses.)
5.2. Experiments on Ofﬁce-Caltech10
The Ofﬁce-Caltech10 dataset is extended from the
standard Ofﬁce31 dataset. It consists of the same 10
object categories from 4 different domains: Amazon, Caltech, DSLR, and Webcam.
The experimental results on Ofﬁce-Caltech10 dataset are
shown in Table 4. Our model M3SDA gets a 96.1% average accuracy on this dataset, and M3SDA-β further boosts
the performance to 96.4%. All the experiments are based
on ResNet-101 pre-trained on ImageNet.
As far as we
AlexNet clp
pnt qdr rel
pnt qdr rel
pnt qdr rel
skt Avg. DANN clp
pnt qdr rel
65.5 8.2 21.4 10.5 36.1 10.8 17.4
N/A 9.1 23.4 16.2 37.9 29.7 23.2
N/A 7.8 24.5 14.3 38.1 25.7 22.1
N/A 9.1 23.2 13.7 37.6 28.6 22.4
32.9 27.7 23.8 2.2 26.4 13.7 19.8
17.2 N/A 15.6 4.4 24.8 13.5 15.1
17.6 N/A 18.7 8.7 28.1 15.3 17.7
17.9 N/A 16.4 2.1 27.8 13.3 15.5
28.1 7.5 57.6 2.6 41.6 20.8 20.1
29.9 8.9 N/A 7.9 42.1 26.1 23.0
27.5 8.2 N/A 7.1 43.1 23.9 22.0
29.1 8.6 N/A 5.1 41.5 24.7 21.8
13.4 1.2 2.5 68.0 5.5 7.1
14.2 1.6 4.4 N/A 8.5 10.1 7.8
qdr 17.8 2.2 7.4 N/A 8.1 10.9 9.3
16.8 1.8 4.8 N/A 9.3 10.2 8.6
36.9 10.2 33.9 4.9 72.8 23.1 21.8
37.4 11.5 33.3 10.1 N/A 26.4 23.7
33.5 9.1 32.5 7.5 N/A 21.9 20.9
36.5 11.4 33.9 5.9 N/A 24.5 22.4
35.5 7.1 21.9 11.8 30.8 56.3 21.4
39.1 8.8 28.2 13.9 36.2 N/A 25.2
35.3 8.2 27.7 13.3 36.8 N/A 24.3
37.9 8.2 26.3 12.2 35.3 N/A 24.0
29.4 6.8 20.7 6.4 28.1 15.1 17.8
Avg. 27.6 8.0 21.0 10.5 29.9 21.2 19.7
Avg. 26.3 7.1 22.2 10.2 30.8 19.5 19.4
Avg. 27.6 7.8 20.9 7.8 30.3 20.3 19.1
pnt qdr rel
skt Avg. ADDA clp
pnt qdr rel
skt Avg. MCD clp
pnt qdr rel
pnt qdr rel
N/A 8.1 21.1 13.1 36.1 26.5 21.0
N/A 11.2 24.1 3.2 41.9 30.7 22.2
N/A 14.2 26.1 1.6 45.0 33.8 24.1
N/A 9.7 12.2 2.2 33.4 23.1 16.1
15.6 N/A 15.3 3.4 25.1 12.8 14.4
19.1 N/A 16.4 3.2 26.9 14.6 16.0
23.6 N/A 21.2 1.5 36.7 18.0 20.2
10.3 N/A 9.6 1.2 13.1 6.9
26.8 8.1 N/A 5.2 40.6 22.6 20.7
31.2 9.5 N/A 8.4 39.1 25.4 22.7
34.4 14.8 N/A 1.9 50.5 28.4 26.0
17.1 9.4 N/A 2.1 28.4 15.9 14.6
15.1 1.8 4.5 N/A 8.5 8.9
15.7 2.6 5.4 N/A 9.9 11.9 9.1
qdr 15.0 3.0 7.0 N/A 11.5 10.2 9.3
13.6 3.9 11.6 N/A 16.4 11.5 11.4
35.3 10.7 31.7 7.5 N/A 22.9 21.6
39.5 14.5 29.1 12.1 N/A 25.7 24.2
42.6 19.6 42.6 2.2 N/A 29.3 27.2
31.7 12.9 19.9 3.7 N/A 26.3 18.9
34.1 7.4 23.3 12.6 32.1 N/A 21.9
35.3 8.9 25.2 14.9 37.6 N/A 25.4
41.2 13.7 27.6 3.8 34.8 N/A 24.2
18.7 7.8 12.2 7.7 28.9 N/A 15.1
25.4 7.2 19.2 8.4 28.4 18.7 17.9
Avg. 28.2 9.3 20.1 8.4 31.1 21.7 19.8
Avg. 31.4 13.1 24.9 2.2 35.7 23.9 21.9
Avg. 18.3 8.7 13.1 3.4 24.1 16.7 14.1
Table 3. Single-source baselines on the DomainNet dataset. Several single-source adaptation baselines are evaluated on the DomainNet
dataset, including AlexNet , DAN , JAN , DANN , RTN , ADDA , MCD , SE . In each sub-table, the
column-wise domains are selected as the source domain and the row-wise domains are selected as the target domain. The green numbers
represent the average performance of each column or row. The red numbers denote the average accuracy for all the 30 (source, target)
combinations.
Source only
Source only
M3SDA (ours)
M3SDA-β (ours)
Table 4. Results on Ofﬁce-Caltech10 dataset. A,C,W and D represent Amazon, Caltech, Webcam and DSLR, respectively. All the
experiments are based on ResNet-101 pre-trained on ImageNet.
know, our models achieve the best performance among all
the results ever reported on this dataset. We have also tried
AlexNet, but it did not work as well as ResNet-101.
5.3. Experiments on DomainNet
Single-Source Adaptation To demonstrate the intrinsic
difﬁculty of DomainNet, we evaluate multiple state-ofthe-art algorithms for single-source adaptation:
Alignment Network (DAN) , Joint Adaptation Network (JAN) , Domain Adversarial Neural Network
(DANN) , Residual Transfer Network (RTN) , Adversarial Deep Domain Adaptation (ADDA) , Maximum Classiﬁer Discrepancy (MCD) ,
Ensembling (SE) . As the DomainNet dataset contains 6
domains, experiments for 30 different (sources, target) combinations are performed for each baseline. For each domain,
we follow a 70%/30% split scheme to participate our dataset
into training and testing trunk. The detailed statistics can be
viewed in Table 8 (see Appendix). All other experimental settings (neural network, learning rate, stepsize, etc.) are
kept the same as in the original papers. Speciﬁcally, DAN,
JAN, DANN, and RTN are based on AlexNet , ADDA
and MCD are based on ResNet-101 , and SE is based
on ResNet-152 . Table 3 shows all the source-only and
experimental results. (Source-only results for ResNet-101
Number of Categories
Figure 4. Accuracy vs. Number of categories. This plot shows
the painting→real scenario. More plots with similar trend can be
accessed in Figure 5 (see Appendix).
and ResNet-152 are in Appendix, Table 7). The results
show that our dataset is challenging, especially for the infograph and quickdraw domain. We argue that the difﬁculty
is mainly introduced by the large number of categories in
our dataset.
Multi-Source Domain Adaptation DomainNet contains
six domains. Inspired by Xu et al , we introduce two
MSDA standards: (1) single best, reporting the single bestperforming source transfer result on the test set, and (2)
source combine, combining the source domains to a single domain and performing traditional single-source adaptation. The ﬁrst standard evaluates whether MSDA can improve the best single source UDA results; the second testify
whether MSDA is necessary to exploit.
Baselines For both single best and source combine experiment setting, we take the following state-of-the-art methods
as our baselines: Deep Alignment Network (DAN) ,
Joint Adaptation Network (JAN) , Domain Adversarial Neural Network (DANN) , Residual Transfer
Network (RTN) , Adversarial Deep Domain Adaptation (ADDA) , Maximum Classiﬁer Discrepancy
(MCD) , and Self-Ensembling (SE) .
For multisource domain adaptation, we take Deep Cocktail Network
(DCTN) as our baseline.
Results The experimental results of multi-source domain
inf,pnt,qdr,
rel,skt→clp
clp,pnt,qdr,
rel,skt→inf
clp,inf,qdr,
rel,skt→pnt
clp,inf,pnt,
rel,skt→qdr
clp,inf,pnt,
qdr,skt →rel
clp,inf,pnt,
qdr,rel →skt
Source Only
33.9 ± 0.62
11.8 ± 0.69
41.6 ± 0.84
26.4 ± 0.70
Source Only
M3SDA∗(ours)
40.8± 0.52
M3SDA (ours)
M3SDA-β (ours)
26.0± 0.89
68.1 ± 0.49
Multi-source domain adaptation results on the DomainNet dataset. Our model M3SDA and M3SDA-β achieves 41.5%
and 42.6% accuracy, signiﬁcantly outperforming all other baselines. M3SDA∗indicates the normal average of all the classiﬁers. When
the target domain is quickdraw, the multi-source methods perform worse than single-source and source only baselines, which indicates
negative transfer occurs in this case. (clp: clipart, inf: infograph, pnt: painting, qdr: quickdraw, rel: real, skt: sketch.)
adaptation are shown in Table 5. We report the results of
the two different weighting schemas and all the baseline results in Table 5. Our model M3SDA achieves an average
accuracy of 41.5%, and M3SDA-β boosts the performance
The results demonstrate that our models designed for MSDA outperform the single best UDA results,
the source combine results, and the multi-source baseline.
From the experimental results, we make three interesting
observations. (1)The performance of M3SDA∗is 40.8%.
After applying the weight vector W, M3SDAimproves the
mean accuracy by 0.7 percent. (2) In clp,inf,pnt,rel,skt→qdr
setting, the performances of our models are worse than
source-only baseline, which indicates that negative transfer occurs. (3) In the source combine setting, the performances of DAN , RTN , JAN , DANN 
are lower than the source only baseline, indicating the negative transfer happens when the training data are from multiple source domains.
Effect of Category Number To show how the number of
categories affects the performance of state-of-the-art domain adaptation methods, we choose the painting→real setting in DomainNet and gradually increase the number of
category from 20 to 345. The results are in Figure 4. An interesting observation is that when the number of categories
is small (which is exactly the case in most domain adaptation benchmarks), all methods tend to perform well. However, their performances drop at different rates when the
number of categories increases. For example, SE performs the best when there is a limit number of categories,
but worst when the number of categories is larger than 150.
6. Conclusion
In this paper, we have collected, annotated and evaluated by far the largest domain adaptation dataset named DomainNet. The dataset is challenging due to the presence
of notable domain gaps and a large number of categories.
We hope it will be beneﬁcial to evaluate future single- and
multi-source UDA methods.
We have also proposed M3SDA to align multiple source
domains with the target domain. We derive a meaningful
error bound for our method under the framework of crossmoment divergence. Further, we incorporate the moment
matching component into deep neural network and train the
model in an end-to-end fashion. Extensive experiments on
multi-source domain adaptation benchmarks demonstrate
that our model outperforms all the multi-source baselines as
well as the best single-source domain adaptation method.
7. Acknowledgements
We thank Ruiqi Gao, Yizhe Zhu, Saito Kuniaki, Ben Usman, Ping Hu for their useful discussions and suggestions.
We thank anonymous annotators for their hard work to label the data. This work was partially supported by NSF and
Honda Research Institute. The authors also acknowledge
support from CIFAR AI Chairs Program.