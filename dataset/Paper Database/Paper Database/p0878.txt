IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 46, NO. 4, APRIL 2008
An Active Learning Approach to Hyperspectral
Data Classiﬁcation
Suju Rajan, Joydeep Ghosh, Fellow, IEEE, and Melba M. Crawford, Fellow, IEEE
Abstract—Obtaining training data for land cover classiﬁcation
using remotely sensed data is time consuming and expensive especially for relatively inaccessible locations. Therefore, designing
classiﬁers that use as few labeled data points as possible is highly
desirable. Existing approaches typically make use of small-sample
techniques and semisupervision to deal with the lack of labeled
data. In this paper, we propose an active learning technique
that efﬁciently updates existing classiﬁers by using fewer labeled
data points than semisupervised methods. Further, unlike semisupervised methods, our proposed technique is well suited for
learning or adapting classiﬁers when there is substantial change
in the spectral signatures between labeled and unlabeled data.
Thus, our active learning approach is also useful for classifying a series of spatially/temporally related images, wherein the
spectral signatures vary across the images. Our interleaved semisupervised active learning method was tested on both single and
spatially/temporally related hyperspectral data sets. We present
empirical results that establish the superior performance of our
proposed approach versus other active learning and semisupervised methods.
Index Terms—Active learning, hierarchical classiﬁer, multitemporal data, semisupervised classiﬁers, spatially separate data.
I. INTRODUCTION
ECENT advances in remote sensing technology have
made hyperspectral data with hundreds of narrow contiguous bands more widely available. The hyperspectral data
can therefore reveal subtle differences in the spectral signatures
of land cover classes that appear similar when viewed by
multispectral sensors . If successfully exploited, the hyperspectral data can yield higher classiﬁcation accuracies and more
detailed class taxonomies. However, the task of classifying
hyperspectral data also has unique challenges.
Supervised statistical methods require labeled training data
to estimate parameters. It is expensive and time consuming to
obtain labeled data, but the very high dimensionality of the
hyperspectral data makes it difﬁcult to design classiﬁers using
only a few labeled data points.
The task of classifying hyperspectral images obtained over
different geographic locations or multiple times proportionately
Manuscript received November 9, 2006; revised April 9, 2007. This work
was supported by the National Science Foundation under Grant IIS-0312471.
S. Rajan and J. Ghosh are with the Department of Electrical and Computer
Engineering, The University of Texas at Austin, Austin, TX 78712 USA
(e-mail: ; ).
M. M. Crawford is with the Schools of Civil and Electrical and Computer
Engineering, Purdue University, West Lafayette, IN 47907 USA (e-mail:
 ).
Color versions of one or more of the ﬁgures in this paper are available online
at 
Digital Object Identiﬁer 10.1109/TGRS.2007.910220
becomes more complex as factors such as atmospheric and
light conditions, topographic variations, etc., alter the spectral
signatures corresponding to the same land cover type across
different images. Rather than acquiring labeled data from each
of the spatially/temporally related images, it would be very
desirable to acquire labeled data from a single image and
exploit that knowledge for constructing a new classiﬁer for a
new but related image. We refer to this concept of exploiting
labeled data from related images as the knowledge transfer
scenario .
The focus of this paper is on hyperspectral image classiﬁcation using very few labeled data points. Two popular
machine learning approaches for dealing with this problem are
semisupervised learning and active learning. Semisupervised
algorithms incorporate the unlabeled data into the classiﬁer
training phase to obtain better decision boundaries. Some of
the more popular semisupervised classiﬁcation algorithms are
techniques based on Expectation Maximization (EM) and
transductive support vector machines . An overview of the
semisupervised classiﬁcation techniques can be found in .
In contrast, active learning assumes the existence of a
rudimentary learner trained with a small amount of labeled
data. The learner has access to both the unlabeled data and
a “teacher.” The learner then selects an unlabeled data point
and obtains its label from the teacher. The goal of the active
learner is to select the most “informative” data points so as to
accurately learn from the fewest such additionally labeled data
points. Several active learning algorithms have been proposed,
which differ in the way the unlabeled data points are chosen.
In this paper, we explore the efﬁcacy of combining semisupervision with a new active learning technique in building
hyperspectral classiﬁers using very little labeled data. Our technique is applicable to both tasks of single-image classiﬁcation
and knowledge transfer. For single-image classiﬁcation, we
assume that we have very little labeled data from the image.
We then use active learning to select unlabeled data points from
the same image for retraining the classiﬁer. In the knowledge
transfer scenario, we assume that we have several temporally
or spatially related images. The labeled data from one such
image are used to build the initial classiﬁer. The unlabeled
data points are then selected from the temporally or spatially
separate image to efﬁciently update the existing classiﬁer for
this separate image.
Our proposed method works with any generative classiﬁer.
In this paper, we evaluate our technique using two such classiﬁers, namely the Maximum-Likelihood (ML) classiﬁer and
the Binary Hierarchical Classiﬁer (BHC). We present results on
several isolated and spatially/temporally related hyperspectral
0196-2892/$25.00 © 2008 IEEE
IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 46, NO. 4, APRIL 2008
images. In all cases, our method of incorporating semisupervision with active learning is found to perform better than other
active learning approaches (also interleaved with semisupervision) and classical semisupervised methods.
II. RELATED WORK
The classiﬁcation of hyperspectral data using labeled data,
including specialized techniques for dealing with small sample
sizes , , has been well studied in the remote sensing
community, so we do not review this literature but refer to the
special issue . Rather, since the focus of this paper is on
learning classiﬁers when only a portion of the data is labeled,
we focus on the existing literature on semisupervised learning
and knowledge transfer for remotely sensed data. To our knowledge, there has been very little work in using active learning for
the classiﬁcation of remotely sensed data. Hence, our review of
active learning concentrates on the general theoretical frameworks developed in the machine learning community.
A. Semisupervised Learning for Single-Image Classiﬁcation
Given a mixture of labeled and unlabeled data, semisupervised classiﬁcation algorithms try to improve the classiﬁcation accuracy by making use of the unlabeled data to obtain
better classiﬁcation boundaries. Semisupervised methods that
make use of EM have had considerable success in a number
of domains, especially that of text data analysis and remote
The advantages of using unlabeled data to aid the classiﬁcation process in the domain of remote sensing data were ﬁrst
identiﬁed and exploited in . In this paper, the authors made
use of unlabeled data via EM to obtain better estimates of the
class-speciﬁc parameters. It was shown that using unlabeled
data enhanced the performance of the maximum a posteriori
probability classiﬁers, especially when the dimensionality of
the data approached the number of training samples. Subsequent extensions to the EM approach include using “semilabeled” data in the EM iterations , . In these methods,
the available labeled data are ﬁrst used to train a supervised
classiﬁer to obtain tentative labels for the unlabeled data. The
semilabeled data thus obtained are then used to retrain the
existing classiﬁer, and the process is iterated until convergence.
In addition to the typical semisupervised setting, unlabeled
data have also been utilized for “partially supervised classiﬁcation” , . In partially supervised classiﬁcation problems,
training samples are provided only for a speciﬁc class of interest, and the classiﬁer must determine whether the unlabeled
data belong to the class of interest. While Mantero et al. 
attempt to model the distribution of the class of interest and
automatically determine a suitable “acceptance probability,”
Jeon and Landgrebe make use of the unlabeled data while
learning an ML classiﬁer to determine whether a data point is
of interest or not.
B. Semisupervised Learning for Multi-Image Classiﬁcation
The possibility that the class label of a pixel could change
with time was ﬁrst explored in . In this paper, the joint
probabilities of all the possible combinations of classes between the multitemporal images were estimated and used in
the classiﬁcation rule. However, the proposed “multitemporal
cascade classiﬁer” requires labeled data from all the images
of interest. More recently, unsupervised algorithms have been
proposed whereby changes in the label of a particular pixel
in a multitemporal sequence are automatically detected .
Supervised methods that automatically try to model the class
transitions in multitemporal images have also been investigated
 . Another supervised approach involves building a local
classiﬁer for each image in the sequence and combining the
decisions, either via a joint-likelihood-based rule or a weighted
majority decision rule based on the reliabilities of the data sets
and that of the individual classes, to yield a “global” decision
rule for the unlabeled data . Still other spatial–temporal
methods utilize the temporal correlation of the classes between
images to help improve the classiﬁcation accuracy , .
It is important to note that the standard formulation for
semisupervised classiﬁcation techniques assumes that both
labeled and unlabeled data have the same class-conditional
distributions. This assumption is violated for the knowledge
transfer scenario considered in this paper. While applying a
classiﬁer learned on a particular image to a spatially/temporally
separated image, it is likely that the statistics of the data from
the new images signiﬁcantly differ from the original image. The
standard semisupervised approach may not be the best option.
C. Knowledge Transfer for Classiﬁcation of Related Images
A pioneering attempt at unsupervised knowledge transfer
for multitemporal remote sensing images was made in .
In this paper, the authors consider a ﬁxed set of land cover
classes whose spectral signatures vary over time. Given an
image t1 of a certain land area with a labeled training set, the
problem is to classify pixels of another image t2 of the same
land area obtained at a different time. An ML classiﬁer is ﬁrst
trained on the labeled data from t1 assuming that the classconditional density functions are Gaussian. The mean vector
and the covariance matrix of the classes from t1 are used
as initial approximations to the parameter values of the same
classes from t2. These initial estimates to the classes from t2 are
then improved via EM using the corresponding unlabeled data.
A recent work exploited the “contextual” properties of a
classiﬁer trained using data acquired from one area to help
classify the data obtained from spatially and temporally different areas . A multiclassiﬁer system called the BHC 
was used for this purpose. The BHC automatically derives a
hierarchy of the target classes based on their mutual afﬁnities.
This hierarchy, along with the features extracted at each node
of the BHC tree, is used to transfer the knowledge from an
existing classiﬁcation task to another related task. The available
unlabeled data are then used to update the existing BHC via
semisupervised learning techniques to better reﬂect the statistics of the data from new areas. It was shown that exploiting
contextual information yielded better classiﬁcation accuracies
than other powerful multiclassiﬁer systems, such as the errorcorrecting output code , for the purposes of knowledge
transfer in hyperspectral data.
RAJAN et al.: ACTIVE LEARNING APPROACH TO HYPERSPECTRAL DATA CLASSIFICATION
D. Active Learning
In a typical active learning setting, a classiﬁer is ﬁrst trained
from a small amount of labeled data. The classiﬁer also has
access to the set of unlabeled data as well as a “teacher.” The
classiﬁer then selects a data point from the set of unlabeled data
points and obtains the corresponding label from the teacher.
The goal of the algorithm is to choose data points such that
a more accurate classiﬁcation boundary is learned using as few
additional labeled data points as possible. Stated formally, let
X ∈ℜ(n×m) be a random vector following a certain probability
distribution, for example, PX. Assume that the learner has
access to a set of random instances D = {xi}n
i=1 drawn from
PX. Let DL ⊂D be the subset for which the true target value
i=1 has been provided to train a classiﬁer. Active learning
algorithms then select ˆx from DUL = D\DL and retrain the
classiﬁer with the appended training set D+
L = DL ∪(ˆx, ˆy).
Note that the learner does not have access to the label ˆy prior
to committing to a speciﬁc ˆx. The process of identifying ˆx
and adding it to DL is repeated for a user-speciﬁed number of
iterations. The different active learning methods differ in the
criteria used to select ˆx.
The only work that applies active learning for the classiﬁcation of remotely sensed data that we are aware of at this time
is that of Mitra et al. , which restricts itself to multispectral
images. In , Mitra et al. make use of active learning while
training support vector machines, and identify ˆx from DUL
based on the distance of the unlabeled data points from the
existing hyperplane. The dependence of the selection criterion
for ˆx on the hyperplane limits the approach to Support Vector
Machine (SVM) type classiﬁers.
A statistical approach to active learning for regression problems was proposed by Cohn et al. , where bias-variance
decomposition of the squared error function is used to select
ˆx. Assuming an unbiased learner, ˆx is selected such that the
resulting D+
L minimizes the expected variance in the output of
the learner measured over X, where the expectation is taken
over P(Y |ˆx).
In a related work, MacKay proposed an informationbased objective function for active learning. In this setting,
the true target function is characterized by a parameter vector
w over which a probability distribution P(W|D) is deﬁned.
Deﬁning S as the entropy of P(W|DL) and S+ as the entropy
with P(W|D+
L), the goal is to select ˆx such that the expected
change in entropy of the distribution (S −S+) is maximum.
The authors also show that maximizing the expected change in
entropy is the same as maximizing the Kullback–Leibler (KL)
divergence between P(W|D+
L) and P(W|DL) . Under the
regression setting, it is shown that choosing ˆx as the point for
which the estimated target value (based on w) has the maximum
variance causes the maximum increase in mutual information
of the parameter vector. The authors also present a closedform solution in the regression setting for identifying ˆx with
the maximum information gain.
An active learning approach that makes use of the
a posteriori probability density function (pdf) (P(Y |X)) was
proposed in . Assuming there exists a true probability
distribution (Ptrue(Y |X)), a user-deﬁned loss function L, and
the a posteriori probability distribution estimated from the
training set (PDL(Y |X)), the expected loss of the learner is
L (Ptrue(Y |x), PDL(Y |x)) P(x)dx.
Active learning proceeds by selecting a data point such that the
expected error using the appended training set D+
L is the least
over all the possible ˆx ∈DUL. However, since Ptrue(Y |X) is
unknown, the authors propose using PDL(Y |X) itself as an
estimate for the unknown true distribution. This substitution
renders the expected loss function meaningless when L is chosen to be the Euclidean distance. When using the KL divergence
as the loss function, the equation reduces to the negative entropy
of PDL(Y |X) .
Given a probabilistic binary classiﬁer, the uncertainty sampling technique proposed by Lewis and Gale chooses the
data point whose a posteriori estimates PDL(y|ˆx) are closest
to 0.5. Since the method focuses on examples closer to the
decision boundaries, it is not clear whether this method will be
of much use for data sets with considerable overlap between
classes as data points close to the decision boundary will
always be chosen for labeling, which results in skewed classconditional probability estimates.
Committee-based learners comprise another popular class of
“multihypothesis” active learning algorithms. Of these methods, the “query by committee” (QBC) approach in is a
general active learning algorithm that has theoretical guarantees
on the reduction in prediction error with the number of queries.
Given an inﬁnite stream of unlabeled examples, the QBC picks
the data point on which instances of the Gibbs algorithm, which
are drawn according to a probability distribution deﬁned over
the version space, disagree. However, the algorithm assumes
the existence of a Gibbs algorithm and noise-free data. Several
variations of the original QBC algorithm have been proposed,
such as the Query by Bagging and Query by Boosting algorithms and the adaptive resampling approach .
Saar-Tsechansky and Provost apply active learning principles
to obtain better class (a posteriori) probability estimates .
Given a probabilistic classiﬁer, the Bootstrap-LV attempts to
select ˆx with the highest “local variance” assuming that the
example that has a high variance in its class probability estimate
is more difﬁcult to learn and hence should be queried. An
extension of the Bootstrap-LV algorithm to the multiclass case
 makes use of the Jensen–Shannon divergence to measure
the uncertainty in the class probability estimates.
McCallum and Nigam combine EM and active learning for text classiﬁcation. Based on the QBC approach, the
“density-weighted pool-based sampling” uses the average KL
divergence between the a posteriori class distribution of each
classiﬁer and the mean a posteriori class distribution (i.e.,
the Jensen–Shannon divergence with equal weights) to assign
a disagreement score to each x in DUL. The disagreement
measure is then combined with a density metric that ensures
that the algorithm chooses an ˆx that is similar to many other
data points in D. Thus, each ˆx is not only representative of other
IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 46, NO. 4, APRIL 2008
data points but also causes signiﬁcant disagreement among the
committee members.
Active learning has also been applied in the multiview setting
 . In the multiview problem, the features are partitioned into
subsets, each of which is sufﬁcient for learning an estimate
of the target function. In the co-testing family of algorithms,
classiﬁers are constructed for each view of the data. Provided the views are “compatible” and “uncorrelated,” the data
points on which the classiﬁers disagree are likely to be most
informative.
III. PROPOSED APPROACH
We propose a new active learning technique that can be used
in conjunction with any classiﬁer that determines the decision
boundary via (an estimate of) a posteriori class probabilities,
i.e., classiﬁers that are probabilistic/generative rather than discriminative .
Our approach strikes a middle ground between the methods
proposed in and that in . As in , we make use
of the a posteriori probability distribution function P(Y |X)
to guide our active learning process. The loss function we
propose is similar to that in in that we attempt to increase
the information gain between PD+
L (Y |X) and PDL(Y |X), i.e.,
the a posteriori pdfs estimated from D+
L and DL, respectively.
Maximizing the expected information gain between P +
and PDL(Y |X) is equivalent to selecting the data point ˆx
from DUL such that the expected KL divergence between
DL(Y |X) and PDL(Y |X) is maximized. That is, we try to
select those data points that change the current belief in the
posterior probability distribution the most.
Since the true label of ˆx is initially unknown, we follow the
methodology in and and estimate the expected KL
distance between P +
DL(Y |X) and PDL(Y |X) by ﬁrst selecting
˜x ∈DUL and assuming ˜y to be its label. Let D+
UL = DUL\˜x,
L = DL ∪(˜x, ˜y), and |D+
UL| be the number of data points
in the set D+
UL. Estimating via sampling, the proposed KLmax
function can be written in terms of (˜x, ˜y) as
L (˜x, ˜y)=
DL(Y |x)∥PDL(Y |x)
The KL divergence between the two probability distributions is
DL(Y |x)∥PDL(Y |x)
DL(Y |x) log
Note that simply assigning a wrong class label to ˜y for ˜x can
result in a large value of the corresponding KLmax
L . Hence,
as in and , we use the expected KL distance from
DL(Y |x) and PDL(Y |x), with the expectation estimated over
PDL(Y |x), and then select the ˆx that maximizes this distance as
ˆx = argmax
L (˜x, ˜y)PDL(˜y|˜x).
The efﬁcacy of our method strongly depends on the correctness of the posterior probability estimates. The very high
dimensionality (>100 features) of the hyperspectral data coupled with the lack of sufﬁcient quantities of labeled data could
result in skewed estimates of the parameters of the probability
distributions. The dimensionality of the data is reduced via
feature selection/extraction techniques , and the EM algorithm is utilized with the active learning process to improve the
estimates.
The following subsections describe our method in more detail for the two different application scenarios, i.e., classifying
a single hyperspectral image and knowledge transfer between
multiple temporally/spatially related images. We use an ML
classiﬁer and our own BHC, in which each class is modeled
by a multivariate Gaussian. However, it should be clear that
our technique can be used with any classiﬁer that can produce
estimates of a posteriori class probabilities.
A. Active Learning for Classifying a Single Image
Let us assume that we have a small amount of labeled
data from the hyperspectral image to be classiﬁed. The highdimensional data are ﬁrst projected into a reduced space using
feature selection/extraction techniques. We choose the Fisher-m
feature extractor for the following reasons: 1) the Fisher
extractor produces a feature space that is most suitable for
discriminating the different land cover classes; and 2) the Fisher
discriminant makes use of the estimates of the class distributions to determine the reduced space and can be continually
updated to reﬂect the changes in the estimates as the learning
When using the ML classiﬁer with multivariate Gaussians
to model the class-conditional probability distributions, the
initial parameters of the Gaussians are estimated using the
available labeled data. The E-step of the algorithm determines
the posterior probabilities of the unlabeled data based on the
Gaussians. The probabilities thus estimated are then used to
update the parameters of the Gaussians (M-step). EM iterations are performed until the average change in the posterior
probabilities between two iterations is smaller than a speciﬁed
threshold . A new Fisher feature extractor is computed for
each EM iteration based on the statistics of the classes at that
iteration. The updated extractor can then be used to project the
data into the corresponding Fisher space prior to the estimation
of the class-conditional pdfs.
Setting PDL(Y |X) as the posterior probability of the unlabeled data DUL, which is obtained at the end of the EM iterations, (ˆx, ˆy) is selected from DUL such that the expected KL
divergence between P +
DL(Y |X) and PDL(Y |X) is maximized,
L = DUL ∪(ˆx, ˆy). For reasons of computational ef-
ﬁciency, (ˆx, ˆy) is selected from a randomly sampled subset of
DUL. A data point ˜x is selected from the subset of DUL, and
RAJAN et al.: ACTIVE LEARNING APPROACH TO HYPERSPECTRAL DATA CLASSIFICATION
the label ˜y is assigned to it. This new data point (˜x, ˜y) is then
used to update the existing class parameter estimates, and a new
posterior probability distribution P +
DL(Y |X) is obtained. Using
(2) and (4), the expected value of KLmax
L (˜x, ˜y) is computed
UL = DUL\˜x for all possible ˜y. The data point (ˆx, ˆy)
from DUL with the maximum expected KL divergence is then
added to the set of labeled data points, where ˆy is hereafter
assumed to be the true label of ˆx.
For the next iteration of active learning, the EM process is
repeated but with two differences: 1) the Gaussian parameter
estimates from the previous iteration are used to initialize the
EM process, and 2) constrained EM is employed, wherein the
E-step only updates the posterior probabilities for the unlabeled
data while ﬁxing the memberships of the labeled instances
according to the known class assignments.
B. Active Learning for Knowledge Transfer
Assume that the hyperspectral data are available from two
spatially (or temporally) different areas, i.e., Areas 1 and 2, and
that there is an adequate amount of labeled data from Area 1 to
build a supervised classiﬁer. The Fisher-m feature extractor is
computed from the Area 1 data to determine a low-dimensional
discriminatory feature space.
The one difference between active learning for the singleimage case and that of the knowledge transfer scenario is
that in the latter the unlabeled data are drawn from spatially/
temporally removed data. While the labeled data from Area 1
are only used to initialize the very ﬁrst EM iteration, subsequent
EM iterations are guided by the posterior probabilities assigned
to the unlabeled Area 2 data. Active learning proceeds as
before with the posterior probability distributions of the Area 2
data determining PDL(Y |X) and guiding the active learning
process. Thus, we ensure that we select “informative” Area 2
data points that change the existing belief in the distributions of
the Area 2 classes the most. Selecting such data points should
result in better learning curves than if the data are selected
at random. Constrained EM is then performed between active
learning iterations by using the estimates from the previous EM
iteration for initialization and holding the known memberships
of the Area 2 data points as ﬁxed.
IV. EXPERIMENTAL EVALUATION
Results were obtained to investigate the performance of our
proposed method. We compared the learning rates with those of
other classiﬁers that select data points either at random or via
another related active learning method.
A. Data Sets
The active learning approaches described above were tested
on hyperspectral data sets obtained from two sites: the John F.
Kennedy Space Center (KSC), National Aeronautics and Space
Administration (NASA), Florida , and the Okavango Delta,
Botswana . The images of the data sets along with the
CLASS NAMES AND NUMBER OF DATA POINTS FOR THE KSC DATA SET
spatial regions from which the labeled data were obtained are
shown in .
1) KSC: The NASA Airborne Visible/Infrared Imaging
Spectrometer acquired data at 18-m spatial resolution over the
KSC on March 23, 1996. The bands that were noisy or impacted
by water absorption were removed, which leaves 176 candidate
features for the study. The training data were selected using
land cover maps derived by the KSC staff from color infrared
photography, Landsat Thematic Mapper (TM) imagery, and
ﬁeld checks. The discrimination of land cover types for this
environment is difﬁcult due to the similarity of the spectral
signatures for certain vegetation types and the existence of
mixed classes. The 512 × 614 spatially removed data set is
located on a different portion of the ﬂight line and exhibits
somewhat different characteristics . While the number of
classes in the two regions differs, we restrict the study to those
classes that are present in both regions. Details of the ten land
cover classes considered in the KSC area are shown in Table I.
2) Botswana: Hyperion data were acquired over a 1476 ×
256 pixel study area located in the Okavango Delta, Botswana.
Fourteen different land cover types consisting of seasonal
swamps, occasional swamps, and drier woodlands located in
the distal portion of the delta were identiﬁed for the study,
which focused on the impact of ﬂooding on vegetation. Uncalibrated and noisy bands that cover water absorption features
were removed, which results in 145 features. The training
data were manually selected using a combination of vegetation surveys located by the Global Positioning System, aerial
photography from the Aquarap project, and a 2.6-m resolution IKONOS multispectral imagery. The spatially removed
test data for the May 31, 2001 acquisition were sampled from
spatially contiguous clusters of pixels that were within the same
scene but disjoint from those used for the training data .
Table II contains a list of classes and the number of classspeciﬁc labeled data.
Multitemporal data: To test the efﬁcacy of the knowledge
transfer framework for multitemporal images, data were also
obtained from the Okavango region in June and July 2001. The
May data are characterized by the onset of the annual ﬂooding
cycle and some newly burned areas. The ﬂood progressed in
June and July, and the burned vegetation recovered. It should
also be noted that only nine classes were identiﬁed in the June
and July images as the data were acquired over a slightly different area due to a change in the satellite pointing. Additionally,
some classes identiﬁed in the May 2001 image were excessively
ﬁne grained for this sequence, so the data in some classes were
IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 46, NO. 4, APRIL 2008
CLASS NAMES AND NUMBER OF DATA POINTS
FOR THE BOTSWANA DATA SET
CLASS NAMES AND NUMBER OF DATA POINTS FOR
THE MULTITEMPORAL BOTSWANA DATA SET
aggregated. The classes representing the various land cover
types that occur in this environment are listed in Table III.
B. Experimental Methodology
For the single-image scenario, the initial labeled data (ten
randomly chosen data points from each class) and the unlabeled
data were extracted from the same image. For the knowledge
transfer case, the labeled data are selected from a particular
image subset (referred to as Area 1), and the unlabeled data are
chosen from spatially or temporally distinct image data
(referred to as Area 2). In this case, 75% of the Area 1 data
were used for building the initial classiﬁer, and the remaining
25% were used as the validation set. All the experiments were
repeated over ﬁve different samplings of the initial labeled set.
Prior to active learning, the dimensionality of the input data
was reduced using a best bases feature extractor, which reduces
the feature space by recursively combining highly correlated
adjacent bands. The method has been shown to be better suited
for feature extraction in hyperspectral data than other methods such as Segmented Principal Components Transformation
(SPCT) . For the single-image scenario, the number of best
bases was ﬁxed such that there are at least ﬁve times as many
initial labeled samples as the number of extracted features. In
the knowledge transfer scenario, because of the availability of
sufﬁcient quantities of labeled data, from Area 1, the number
of best bases was determined using a validation set. The best
bases method was used as a preprocessing technique as our
experiments showed this method to be less sensitive to the
effect of ill-conditioned covariance matrices than the Fisher-m
extractor. As detailed in Section III, the Fisher-m feature extractor was then used to obtain a discriminatory feature space
from the more “stable” feature set produced by the best bases
The proposed active learning technique can be implemented
with any classiﬁer that makes use of estimates of a posteriori
class probabilities for determining the decision boundaries. In
our experiments, we used the ML classiﬁer and the BHC. The
ML classiﬁer was implemented as detailed in Section III. The
BHC is a multiclassiﬁer system that was primarily developed
to deal with multiclass hyperspectral data . It recursively
decomposes a multiclass (C-classes) problem into (C −1)
binary metaclass problems, which results in (C −1) classiﬁers
arranged as a binary tree. The partitioning of a parent set of
classes into metaclasses is obtained through a deterministic
annealing process that encourages similar classes to remain in
the same partition. The metaclasses at each node of the BHC
are modeled using mixtures of Gaussians, with the number of
Gaussians corresponding to the number of classes at that node.
Each node also has a corresponding Fisher feature extractor.
The proposed active learning method (KL-Max) detailed
in Section III was implemented. Our approach was evaluated
against two baseline methods, i.e., Random and Entropy. The
ﬁrst method chooses the data points at random, one at a time,
from the unlabeled set and uses constrained EM to update the
estimates of the class parameters. The entropy-based active
learning approach of Roy and McCallum is one of the more
popular methods of active learning that make use of a posteriori
class probabilities. As mentioned in Section II-D, this entropybased method chooses the data points that result in an increase
in the future expected entropy. Following the notation from (2)
and (4), ˆx is selected using the following equations:
L (˜x, ˜y)=
L (y|x) log PD+
The ˆx ∈DUL with the lowest expected loss is then selected for
querying and is added to DL as
ˆx = argmin
L (˜x, ˜y)PDL(˜y|˜x).
To have a fair comparison, as in our proposed method, semisupervised EM was used to estimate the parameters of the classconditional pdfs. For reasons of computational efﬁciency, the
new data point ˆx was chosen from a randomly chosen subset
(30 data points) of the unlabeled data for both the KL-Max and
the entropy method.
V. RESULTS AND DISCUSSION
Figs. 1–4 show the learning rates of the different active
learning methods. Each point on the x-axis represents the
number of additional labeled samples used to train the classiﬁer,
while the y-axis represents the classiﬁcation accuracies. The
RAJAN et al.: ACTIVE LEARNING APPROACH TO HYPERSPECTRAL DATA CLASSIFICATION
Classiﬁcation accuracy versus active learning iterations on a single image with the ML + EM classiﬁer. (a) KSC. (b) Botswana. (c) May. (d) June.
Classiﬁcation accuracy versus active learning iterations on a single image with the BHC + EM classiﬁer. (a) KSC. (b) Botswana. (c) May. (d) June.
error bars for classiﬁcation accuracies were obtained using the
ﬁve different samplings of the initial labeled data set, as detailed
in Section IV-B.
A. Single-Image Classiﬁcation
Figs. 1 and 2 show the learning rate curves for single-image
classiﬁcation over 100 active learning iterations for the different
IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 46, NO. 4, APRIL 2008
Classiﬁcation accuracy versus active learning iterations on spatially/temporally separate images with the ML + EM classiﬁer. (a) Spatial KSC. (b) Spatial
Botswana. (c) May to June. (d) May to July. (e) June to July. (f) May + June to July.
Classiﬁcation accuracy versus active learning iterations on spatially/temporally separate images with the BHC + EM classiﬁer. (a) Spatial KSC.
(b) Spatial Botswana. (c) May to June. (d) May to July. (e) June to July. (f) May + June to July.
data sets using the ML and BHC methods, respectively. All the
active learning methods, for single-image classiﬁcation, make
use of an initial classiﬁer trained using ten randomly chosen
data points from each class. Thus, the x-axis for the KSC data
starts at 100, the Botswana at 140, and the remaining data sets
at 90. For the ML classiﬁer, the proposed KL-Max method
performs much better than the other methods on the KSC and
Botswana data sets, whereas the learning rates are comparable
RAJAN et al.: ACTIVE LEARNING APPROACH TO HYPERSPECTRAL DATA CLASSIFICATION
Likelihood of classes being chosen by the active learning methods for the May-to-June knowledge transfer problem. (a) Per-class confusion.
(b) ML entropy. (c) BHC entropy. (d) ML KL-Max. (e) BHC KL-Max.
to those of the entropy-based approach on the May, June, and
July data sets. On data sets with a larger number of classes,
the entropy-based method performs worse than even random
selection. The poor performance of the entropy-based method
could be attributed to the fact that focusing on data points that
increase the future expected entropy results in skewed estimates
of the class distributions.
Similar trends can be observed for the BHC method. When
the proposed active learning approach was applied, both BHC
and ML classiﬁers exhibited comparable learning behavior.
However, the entropy-based method performed even worse with
the BHC technique for these data sets. A possible reason for
this behavior is the greater dependence of the BHC on the
adequacy of the estimated class distributions. Each node in the
BHC hierarchy makes use of class distribution estimates for
determining the corresponding Fisher-m extractor and learning
decision boundaries. Hence, skewed class distribution estimates
would have an increasingly adverse effect on classiﬁcation
accuracies while traversing down the tree, which results in poor
overall classiﬁcation accuracies.
B. Knowledge Transfer
The proposed approach seems to be particularly well suited
to the problem of knowledge transfer. Fig. 3 shows the learning rates for the spatially/temporally separated data sets over
the active learning iterations. Note that unlike the single-image
case, the x-axis for all the data sets in this case starts at
zero. The KL-Max method yields higher overall classiﬁcation accuracies than the other approaches. The results for the
IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 46, NO. 4, APRIL 2008
CONFUSION MATRIX FOR THE MAY-TO-JUNE KNOWLEDGE TRANSFER PROBLEM USING SEMISUPERVISED BHC
CONFUSION MATRIX FOR THE MAY-TO-JUNE KNOWLEDGE TRANSFER PROBLEM USING BHC KL-MAX AFTER 180 ACTIVE LEARNING ITERATIONS
entropy-based method are similar to those of the single-image
A comparison of the classiﬁcation accuracies between the
BHC using KL-Max for the single image and the knowledge
transfer scenario shows that for the same amounts of available
labeled data, the knowledge transfer method has higher classi-
ﬁcation accuracies than learning a classiﬁer from scratch on the
new image. For example, consider the July data set. Fig. 2(e)
shows the classiﬁcation accuracy when both the initial labeled
data set and the unlabeled data are drawn from these data.
Fig. 4(d)–(f) shows the classiﬁcation accuracies for the same
data set when the initial labeled data are selected from related
multitemporal images, namely May and June. Fig. 2(e) shows
that using 140 labeled data points from the July data results
in a classiﬁcation accuracy of approximately 94%. In comparison, using the knowledge in the existing June and May +
June classiﬁers achieves the same accuracy with only about 50
data points [Fig. 4(e) and (f)]. However, classifying the July
data set using the classiﬁer trained on May data [Fig. 4(d)]
requires about 120 labeled data points from the July data set
to obtain the same accuracy. This is because the July data
represent changes that have occurred over a two-month interval.
Additionally, training data for some classes were necessarily
extracted from different geographic locations in June and July
due to the change in pointing angle and the advance of the
A better understanding of the efﬁcacy of the KL-Max
method, for knowledge transfer, compared to the entropy-based
approach, can be obtained by comparing the likelihood of the
class labels chosen by these methods to the per-class confusion.
In the following analysis, we measure the per-class confusion
by two quantities, namely (1-precision) and (1-recall) . A
class with unit precision and recall values has no confusion.
Hence, in our analysis, classes with high values of (1-precision)
and/or (1-recall) exhibit substantial confusion, and active learning methods should be able to focus on such classes.
In the following discussion, we make use of the May-to-June
knowledge transfer scenario as an illustrative example. This
data set combination is representative of the remaining data sets
as it exhibits the spatial and temporal variations between the
May and June images. Fig. 5(a) shows the per-class confusion
in classifying the June data, via semisupervision, using a BHC
classiﬁer trained on the May data. Note that this is the very ﬁrst
step of the active learning process. The classiﬁer was trained
using ﬁve different samplings of the May data, and the obtained
results were averaged. The actual averaged confusion matrix
is shown in Table IV. It can be seen that the two woodland
classes, i.e., Riparian (Class 3) and Woodlands (Class 6),
exhibit signiﬁcant confusion. The Primary Floodplain (Class 2)
class is sometimes classiﬁed as either the Island Interior
(Class 5) or the Exposed Soils (Class 9) class. The Savanna
(Class 7) and Exposed Soils (Class 9) land cover types also
show some confusion.
Fig. 5(b)–(e) shows the lift in selecting 180 data points from
each class. For each class, the lift is measured as the ratio of the
number of data points chosen by the active learning method to
the number of data points that would have been chosen from
it by random selection. Those classes with a higher lift are
more likely to have data points chosen than classes with a lower
value of lift. Thus, a good active learning method should have
a strong correlation between the per-class lift and the per-class
confusion. It can be seen that the KL-Max method [Fig. 5(d)
and (e)] has a better correlation with the per-class confusion
than the entropy-based method [Fig. 5(b) and (c)]. Note that
the overall best correlation is obtained with the BHC KL-Max
method [Fig. 5(e)].
In addition to showing that the proposed method not only
identiﬁes the “correct” problem classes, we also show that it
RAJAN et al.: ACTIVE LEARNING APPROACH TO HYPERSPECTRAL DATA CLASSIFICATION
Number of data points chosen from each class at different active
learning iterations for the May-to-June knowledge transfer problem.
selects the most informative data points from these classes.
Table V shows the averaged confusion matrix obtained by the
BHC KL-Max method after 180 active learning iterations. The
KL-Max method eliminates the confusion among all classes except that of Riparian (Class 3) and Woodlands (Class 6), which
are both tree classes. Fig. 5(e) shows that while the KL-Max
method is more likely to select data points from classes 3 and
6, the two classes continue to exhibit some confusion. To understand this behavior, consider Fig. 6 showing the distribution
of class labels selected after 33, 66, and 100 iterations of a
single active learning run. Note that for classes 2 and 7, the
increase in the number of additional labeled data points, i.e.,
between 33 and 100 iterations, is far less than that of classes 3
and 6. Thus, one may conclude that for classes 2 and 7, the
most informative data points are chosen early on in the active
learning process, which probably is the case for classes 3 and
6 as well. However, as we force active learning to proceed,
regardless of whether the estimates of class distributions change
across subsequent iterations, the algorithm continues to select
data points from the “more confusing” classes 3 and 6.
VI. CONCLUSION
We have proposed a new active learning approach for ef-
ﬁciently updating classiﬁers built from small quantities of
labeled data. The principle of selecting data points that mostly
change the existing belief in class distributions seems to be
particularly well suited to the scenario in which the distributions
of the classes show spatial (or temporal) variations. The proposed method is empirically shown to have better learning rates
than choosing data points at random and an entropy-based active learning method regardless of the underlying probabilistic
classiﬁer. This paper can be expanded when more hyperspectral
data are available, especially to determine the effectiveness of
the active learning-based knowledge transfer framework when
the spatial/temporal separation of the data sets is systematically
increased.
ACKNOWLEDGMENT
The authors would like to thank A. Neunschwander and
Y. Chen for help in preprocessing the Hyperion data.