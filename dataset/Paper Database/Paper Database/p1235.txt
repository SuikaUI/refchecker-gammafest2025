Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 2134–2143,
Berlin, Germany, August 7-12, 2016. c⃝2016 Association for Computational Linguistics
Leveraging FrameNet to Improve Automatic Event Detection
Shulin Liu, Yubo Chen, Shizhu He, Kang Liu and Jun Zhao
National Laboratory of Pattern Recognition
Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China
{shulin.liu, yubo.chen, shizhu.he, kliu, jzhao}@nlpr.ia.ac.cn
Frames deﬁned in FrameNet (FN) share
highly similar structures with events in
ACE event extraction program. An event in ACE is composed of an event trigger and a set of arguments. Analogously,
a frame in FN is composed of a lexical unit and a set of frame elements, which play
similar roles as triggers and arguments of
ACE events respectively. Besides having
similar structures, many frames in FN actually express certain types of events. The
above observations motivate us to explore
whether there exists a good mapping from
frames to event-types and if it is possible
to improve event detection by using FN.
In this paper, we propose a global inference approach to detect events in FN. Further, based on the detected results, we analyze possible mappings from frames to
event-types. Finally, we improve the performance of event detection and achieve
a new state-of-the-art result by using the
events automatically detected from FN.
Introduction
In the ACE (Automatic Context Extraction) event extraction program, an event is represented as a
structure consisting of an event trigger and a set of
arguments. This paper tackles with the event detection (ED) task, which is a crucial component in
the overall task of event extraction. The goal of ED
is to identify event triggers and their corresponding event types from the given documents.
FrameNet (FN) is a linguistic resource storing considerable information about lexical and predicateargument semantics. In FN, a frame is deﬁned as
a composition of a Lexical Unit (LU) and a set
of Frame Elements (FE). Most frames contain a
set of exemplars with annotated LUs and FEs (see
Figure 2 and Section 2.2 for details).
From the above deﬁnitions of events and
frames, it is not hard to ﬁnd that the frames deﬁned
in FN share highly similar structures as the events
deﬁned in ACE. Firstly, the LU of a Frame plays
a similar role as the trigger of an event. ACE de-
ﬁnes the trigger of an event as the word or phrase
which most clearly expresses an event occurrence.
For example, the following sentence “He died in
the hospital.” expresses a Die event, whose trigger is the word died. Analogously, the LU of a
frame is also the word or phrase which is capable of indicating the occurrence of the expressed
semantic frame. For example, the sentence “Aeroplanes bombed London.” expresses an Attack1
frame, whose LU is the word bombed. Secondly,
the FEs of a frame also play similar roles as arguments of an event. Both of them indicate the participants involved in the corresponding frame or
event. For example, in the ﬁrst sentence, He and
hospital are the arguments, and in the second sentence, Aeroplanes and London are the FEs.
Besides having similar structure as events,
many frames in FN actually express certain types of events deﬁned in ACE. Table 1 shows some
examples of frames which also express events.
Sample in FN
Aeroplanes bombed London.
Hitler invaded Austria .
The court ﬁned her $40.
He was executed yesterday.
Table 1: Examples of frames expressing events.
The aforementioned observations motivate us to
1The notation of frames distinguishes from that of events
by the italic decoration.
explore: (1) whether there exists a good mapping
from frames to event-types, and (2) whether it is
possible to improve ED by using FN.
Figure 1: Our framework for detecting events in
FN (including training and detecting processes).
For the ﬁrst issue, we investigate whether a
frame could be mapped to an event-type based on
events expressed by exemplars annotated for that
frame. Therefore the key is to detect events from
the given exemplar sentences in FN. To achieve
this goal, we propose a global inference approach
(see ﬁgure 1). We ﬁrstly learn a basic ED model
based on the ACE labeled corpus and employ it to
yield initial judgements for each sentence in FN.
Then, we apply a set of soft constraints for global
inference based on the following hypotheses: 1).
Sentences belonging to the same LU tend to express events of the same type; 2). Sentences belonging to related frames tend to express events of
the same type; 3). Sentences belonging to the same
frame tend to express events of the same type. All
of the above constraints and initial judgments are
formalized as ﬁrst-order logic formulas and modeled by Probabilistic Soft Logic (PSL) . Finally, we obtain
the ﬁnal results via PSL-based global inference.
We conduct both manual and automatic evaluations for the detected results.
For the second issue, ED generally suffers from data sparseness due to lack of labeled
samples. Some types, such as Nominate and
Extradite, contain even less than 10 labeled
samples. Apparently, from such a small scale of
training data is difﬁcult to yield a satisfying performance. We notice that ACE corpus only contains
about 6,000 labeled instances, while FN contains
more than 150,000 exemplars. Thus, a straightforward solution to alleviate the data sparseness problem is to expand the ACE training data by using
events detected from FN. The experimental results show that events from FN signiﬁcantly improve
the performance of the event detection task.
Figure 2: The hierarchy of FN corpus, where each
Sk under a LU is a exemplar annotated for that
LU. Inheritance is a semantic relation between the
frames Invading and Attack.
To sum up, our main contributions are: (1) To
our knowledge, this is the ﬁrst work performing event detection over ACE and FN to explore
the relationships between frames and events. (2)
We propose a global inference approach to detect
events in FN, which is demonstrated very effective
by our experiments. Moreover, based on the detected results, we analyze possible mappings from
frames to event-types (all the detecting and mapping results are released for further use by the NLP
community2). (3) We improve the performance of
event detection signiﬁcantly and achieve a new
state-of-the-art result by using events automatically detected from FN as extra training data.
Background
ACE Event Extraction
In ACE evaluations, an event is deﬁned as a specific occurrence involving several participants. ACE
event evaluation includes 8 types of events, with
33 subtypes. Following previous work, we treat
them simply as 33 separate event types and ignore
the hierarchical structure among them. In this paper, we use the ACE 2005 corpus3 in our experiments. It contains 599 documents, which include
about 6,000 labeled events.
The FrameNet is a taxonomy of manually identi-
ﬁed semantic frames for English4. Figure 2 shows
2Available at 
3 
4We use the latest released version, FrameNet 1.5 in this
work ( 
the hierarchy of FN corpus. Listed in the FN
with each frame are a set of lemmas with part of
speech (i.e “invade.v”) that can evoke the frame,
which are called lexical units (LUs). Accompanying most LUs in the FN is a set of exemplars annotated for them. Moreover, there are a set of labeled
relations between frames, such as Inheritance.
FN contains more than 1,000 various frames
and 10,000 LUs with 150,000 annotated exemplars. Eight relations are deﬁned between frames
in FN, but in this paper we only use the following
three of them because the others do not satisfy our
hypotheses (see section 4.2):
Inheritance: A inherited from B indicates that A
must correspond to an equally or more speciﬁc
fact about B. It is a directional relation.
See also: A and B connected by this relation indicates that they are similar frames.
Perspective on: A and B connected by this relation
means that they are different points-of-view about
the same fact (i.e. Receiving vs. Transfer).
Related Work
Event extraction is an increasingly hot and challenging research topic in NLP. Many approaches
have been proposed for this task. Nearly all the existing methods on ACE event task use supervised
paradigm. We further divide them into featurebased methods and representation-based methods.
In feature-based methods, a diverse set of strategies has been exploited to convert classiﬁcation clues into feature vectors. Ahn uses the lexical features(e.g., full word), syntactic
features (e.g., dependency features) and externalknowledge features ) to
extract the event. Inspired by the hypothesis of
One Sense Per Discourse , Ji
and Grishman combined global evidence
from related documents with local decisions for
the event extraction. To capture more clues from
the texts, Gupta and Ji , Liao and Grishman
 and Hong et al. proposed the crossevent and cross-entity inference for the ACE event task. Li et al. proposed a joint model to
capture the combinational features of triggers and
arguments. Liu et al. proposed a global inference approach to employ both latent local and
global information for event detection.
representation-based
event mentions are represented by embedding,
which typically are fed into neural networks. Two similarly related work has been proposed on
event detection . Nguyen and Grishman employed Convolutional Neural Networks (CNNs) to
automatically extract sentence-level features for
event detection. Chen et al. proposed dynamic multi-pooling operation on CNNs to capture better sentence-level features.
FrameNet is a typical resource for framesemantic parsing, which consists of the resolution
of predicate sense into a frame, and the analysis of the frame’s participants . Other tasks which have
been studied based on FN include question answering , textual entailment and paraphrase recognition . This is the ﬁrst work to explore the
application of FN to event detection.
Basic Event Detection Model
Alike to existing work, we model event detection
(ED) as a word classiﬁcation task. In the ED task,
each word in the given sentence is treated as a candidate trigger and the goal is to classify each of
these candidates into one of 34 classes (33 event
types plus a NA class). However, in this work, as
we assumed that the LU of a frame is analogical to
the trigger of an event, we only treat the LU annotated in the given sentence as a trigger candidate.
Each sentence in FN only contains one candidate
trigger, thus “the candidate” denotes both the candidate trigger of a sentence and the sentence itself
for FN in the remainder of this paper. Another notable difference is that we train the detection model on one corpus (ACE) but apply it on another
(FN). That means our task is also a cross-domain
problem. To tackle with it, our basic ED approach
follows representation-based paradigm, which has
been demonstrated effective in the cross-domain
situation .
We employ a simple three-layer (a input layer, a
hidden layer and a soft-max output layer) Artiﬁcial
Neural Networks (ANNs) to
model the ED task. In our model, adjacent layers
are fully connected.
Word embeddings learned from large amount of
unlabeled data have been shown to be able to capture the meaningful semantic regularities of words
 . This paper uses unsupervised learned word embeddings
as the source of base features. We use the Skipgram model to learn word
embeddings on the NYT corpus5.
Given a sentence, we concatenate the embedding vector of the candidate trigger and the average embedding vector of the words in the sentence
as the input to our model. We train the model using
a simple optimization technique called stochastic
gradient descent (SGD) over shufﬂed mini-batches
with the Adadelta update rule . Regularization is implemented by a dropout . The experiments show
that this simple model is surprisingly effective for
event detection.
Event Detection in FrameNet
To detect events in FN, we ﬁrst learned the basic
ED model based on ACE labeled corpus and then
employ it to generate initial judgements (possible
event types with conﬁdence values) for each sentence in FN. Then, we apply a set of constraints
for global inference based on the PSL model.
Probabilistic Soft Logic
PSL is a framework for collective, probabilistic
reasoning in relational domains . Similar to Markov Logic Networks (MLNs) , it uses weighted ﬁrst-order logic formulas
to compactly encode complex undirected probabilistic graphical models. However, PSL brings two remarkable advantages compared with MLNs.
First, PSL relaxes the boolean truth values of
MLNs to continuous, soft truth values. This allows
for easy integration of continuous values, such as
similarity scores. Second, PSL restricts the syntax
of ﬁrst order formulas to that of rules with conjunctive bodies. Together with the soft truth values
constraint, the inference in PSL is a convex optimization problem in continuous space and thus
can be solved using efﬁcient inference approaches. For further details, see the references .
Global Constraints
Our global inference approach is based on the
following three hypotheses.
5 
H1: Same Frame Same Event
This hypothesis indicates that sentences under the
same frame tend to express events of the same
type. For example, all exemplars annotated for the
frame Rape express events of type Attack, and
all sentences under the frame Clothing express
NA (none) events. With this hypothesis, sentences
annotated for the same frame help each other to
infer their event types during global inference.
H2: Related Frame Same Event
This hypothesis is an extension of H1, which
relaxes “the same frame” constraint to “related
frames”. In this paper, frames are considered to
be related if and only if they are connected by
one of the following three relations: Inheritance,
See also and Perspective on (see section 2.2).
For example, the frame Invading is inherited
from Attack, and they actually express the same
type of event, Attack. With this hypothesis,
sentences under related frames help each other to
infer their event types during global inference.
The previous two hypotheses are basically true
for most frames but not perfect. For example, for
the frame Dead or alive, only a few of the
sentences under it express Die events while the
remainder do not. To amend the this ﬂaw, we introduce the third hypothesis.
H3: Same LU Same Event
This hypothesis indicates that sentences under the
same LU tend to express events of the same type
(as a remind, LUs are under frames). It is looser than the previous two hypotheses thus holds true in more situations. For example, H3 holds
true for the frame Dead or alive which violates H1 and H2. In FN, LUs annotated for that
frame are alive.a, dead.a, deceased.a, lifeless.a,
living.n, undead.a and undead.n. All exemplars
under dead.a, deceased.a and lifeless.a express
Die events. Therefore, this hypothesis amends the
ﬂaws of the former two hypotheses.
On the other hand, the ﬁrst two hypotheses also help H3 in some cases. For example, most of
the sentences belonging to the LU suit.n under the
frame Clothing are misidentiﬁed as Sue events
due to the ambiguity of the word “suit”. However,
in this situation, H1 can help to rectify it because
the majority of LUs under Clothing are not ambiguous words. Thus, under the ﬁrst hypothesis,
the misidentiﬁed results are expected to be corrected by the the results of other exemplars belonging
to Clothing.
To model the above hypotheses as logic formulas
in PSL, we introduce a set of predicates (see Table 2), which are grouped into two categories: observed predicates and target predicates. Observed
predicates are used to encode evidences, which are
always assumed to be known during the inference,
while target predicates are unknown and thus need
to be predicted.
CandEvt(c, t)
introduced
represent conf(c, t), which is the conﬁdence value generated by the basic ED model for classifying the candidate c as an event of the type t. SameFr(c1, c2)
indicates whether the candidates c1 and c2 belong
to the same frame. It is initialized by the indicator
function Isf(c1, c2), which is deﬁned as follows:
Isf(c1, c2) =
c1, c2 from the same frame
SameLU(c1, c2) is similar, but applies for candidates under the same LU. The last three observed
predicates in Table 2 are used to encode the aforementioned semantic relations between frames. For
example, Inherit(c1, c2) indicates whether the
frame of c1 is inherited from that of c2, and it
is initialized by the indicator function Iih(c1, c2),
which is set to 1 if and only if the frame of c1 is
inherited from that of c2, otherwise 0. Evt(c, t) is
the only target predicate, which indicates that the
candidate c triggers an event of type t.
Assignment
CandEvt(c, t)
conf(c, t)
SameFr(c1, c2)
Isf(c1, c2)
SameLU(c1, c2)
Isl(c1, c2)
Inherit(c1, c2)
Iih(c1, c2)
SeeAlso(c1, c2)
Isa(c1, c2)
Perspect(c1, c2)
Ipe(c1, c2)
Table 2: Predicates and their initial assignments.
Putting all the predicates together, we design a
set of formulas to apply the aforementioned hypotheses in PSL (see Table 3). Formula f1 connects the target predicate with the initial judgements from the basic ED model. Formulas f2 and
f3 respectively encode H1 and H3. Finally, the remaining formulas are designed for various relations between frames in H2. We tune the formulas’s weights via grid search (see Section 5.4). The
inference results provide us with the most likely
CandEvt(c, t) →Evt(c, t)
SameFr(c1, c2) ∧Evt(c1, t) →Evt(c2, t)
SameLU(c1, c2) ∧Evt(c1, t) →Evt(c2, t)
Inherit(c1, c2) ∧Evt(c1, t) →Evt(c2, t)
SeeAlso(c1, c2) ∧Evt(c1, t) →Evt(c2, t)
Perspect(c1, c2) ∧Evt(c1, t) →Evt(c2, t)
Table 3: Formulas in the PSL model
interpretation, that is, the soft-truth values of the
predicate Evt. The ﬁnal detected event type t of
candidate c is decided by the the equation:
t = argmax
Evt(c, t′)
Evaluations
In this section, we present the experiments and
the results achieved. We ﬁrst manually evaluate
our novel PSL-based ED model on the FN corpus.
Then, we also conduct automatic evaluations for
the events detected from FN based on ACE corpus. Finally, we analyze possible mappings from
frames/LUs to event types.
We learned the basic ED model on ACE2005
dataset. In order to evaluate the learned model, we
followed the evaluation of : randomly selected 30 articles from different genres
as the development set, and we subsequently conducted a test on a separate set of 40 ACE 2005
newswire documents. We used the remaining 529
articles as the training data set.
We apply our proposed PSL-based approach
to detect events in FrameNet. Via collecting all exemplars annotated in FN, we totally obtain
154,484 sentences for detection.
Setup and Performance of Basic Model
We have presented the basic ED model in Section
3. Hyperparameters were tuned by grid search on
the development data set. In our experiments, we
set the size of the hidden layer to 300, the size of
word embedding to 200, the batch size to 100 and
the dropout rate to 0.5.
Table 4 shows the experimental results, from
which we can see that the three-layer ANN model
is surprisingly effective for event detection, which
even yields competitive results compared with Nguyen’s CNN and Chen’s DMCNN. We believe the
reason is that, compared with CNN and DMCNN,
Nguyen’s CNN 
Chen’s DMCNN 
Liu’s Approach 
ANN (ours)
ANN-Random (ours)
Table 4: Performance of the basic ED model. AN-
N uses pre-trained word embeddings while ANN-
Random uses randomly initialized embeddings.
ANN focuses on capturing lexical features which
have been proved much more important than sentence features for the ED task by . Moreover, our basic model achieves much
higher precision than state-of-the-art approaches
(79.5% vs. 75.6%).
We also investigate the performance of the basic
ED model without pre-trained word embeddings6
(denoted by ANN-Random). The result shows that
randomly initialized word embeddings decrease
the F1 score by 7.3 (61.5 vs. 68.8). The main
reasons are: 1). ACE corpus only contains 599
articles, which are far insufﬁcient to train good
embeddings. 2). Words only existing in the test
dataset always retain random embeddings.
For comparison, we designed four baseline systems that utilize different hypotheses to detect events in FN.
(1) ANN is the ﬁrst baseline, which directly uses
a basic ED model learned on ACE training corpus
to detect events in FN. This system does not apply
any hypotheses between frames and events.
(2) SameFrame (SF) is the second baseline system, which applies H1 over the results from AN-
N. For each frame, we introduce a score function
φ(f, t) to estimate the probability that the frame f
could be mapped to the event type t as follows:
where Sf is the set of sentences under the frame
f; I(c, t) is an indicator function which is true if
and only if ANN predicts the candidate c as an
event of type t. Then for each frame f satisfying
φ(f, t) > α, we mapped it to event type t, where
α is a hyperparameter. Finally, all sentences under
mapped frames are labeled as events. Note that,
6We thank the anonymous reviewer for this suggestion.
unlike the PSL-based approach which applies constraints as soft rules, this system utilizes H1 as a
hard constraint.
(3) RelatedFrame (RF) is the third baseline system, which applies H2 over the results from AN-
N. For each frame f, we merge it and its related
frames into a super frame, f
′. Similar with SF,
a score function ζ(f
′, t), which shares the same
expression to equation 3, is introduced. For the
merged frame satisfying ζ(f
′, t) > β, we mapped
it to the event type t. Finally, all sentences under
′ are labeled as events.
(4) SameLU (SL) is the last baseline, which applies the hypothesis H3 over the results from ANN.
Also, a score function ψ(l, t) is introduced:
where Sl is the set of sentences under the LU l. For
each LU satisfying ψ(l, t) > γ, we mapped it to
the event type t. Finally, all sentences under l are
labeled as events.
Manual Evaluations
In this section, we manually evaluate the precision
of the baseline systems and our proposed PSLbased approach. For fair comparison, we set α, β
and γ to 0.32, 0.29 and 0.42 respectively to ensure they yield approximately the same amount of
events as the ﬁrst baseline system ANN. We tune
the weights of formulas in PSL via grid search
by using ACE development dataset. In details, we
ﬁrstly detect events in FN under different conﬁgurations of formulas’ weights and add them to
ACE training dataset, respectively. Consequently, we obtain several different expanded training
datasets. Then, we separately train a set of basic
ED models based on each of these training datasets and evaluate them over the development corpus.
Finally, the best weights are selected according
to their performances on the development dataset.
The weights of f1 :f5 used in this work are 100,
10, 100, 5, 5 and 1, respectively.
Manual Annotations
Firstly, we randomly select 200 samples from the
results of each system. Each selected sample is a
sentence with a highlighted trigger and a predicted
event type. Figure 3 illustrates three samples. The
ﬁrst line of each sample is a sentence labeled with
the trigger. The next line is the predicted event
type of that sentence. Annotators are asked to assign one of two labels to each sample (annotating
in the third line):
Y: the word highlighted in the given sentence
indeed triggers an event of the predicted type.
N: the word highlighted in the given sentence
does not trigger any event of the predicted type.
We can see that, it is very easy to annotate a sample for annotators, thus the annotated results are
expected to be of high quality.
Figure 3: Examples of manual annotations.
To make the annotation more credible, each
sample is independently annotated by three annotators7 (including one of the authors and two of
our colleagues who are familiar with ACE event
task) and the ﬁnal decision is made by voting.
Table 5 shows the results of manual evaluations.
Through the comparison of ANN and SF, we can
see that the application of H1 caused a loss of 5.5
point. It happens mainly because the performance
of SF is very sensitive to the wrongly mapped
frames. That is, if a frame is mismapped, then all
sentences under it would be mislabeled as events.
Thus, even a single mismapped frame could signiﬁcantly hurt the performance. This result also
proves that H1 is inappropriate to be used as a hard
constraint. As H2 is only an extension of H1, RF
performs similarly with SF. Moreover, SL obtains
a gain of 2.0% improvement compared with ANN,
which demonstrates that the ”same LU” hypothesis is very useful. Finally, with all the hypotheses, the PSL-based approach achieves the best performance, which demonstrates that our hypotheses
are useful and it is an effective way to jointly utilize them as soft constraints through PSL for event
detection in FN.
Automatic Evaluations
To prepare for automatic evaluations, we respectively add the events detected from FN by each
of the aforementioned ﬁve systems to ACE training corpus. Consequently, we obtain ﬁve ex-
7The inter-agreement rate is 86.1%
Precision (%)
PSL-based Approach
Table 5: Results of manual evaluations.
panded training datasets: ACE-ANN-FN, ACE-SF-
FN, ACE-RF-FN, ACE-SL-FN and ACE-PSL-FN.
Then, we separately train ﬁve basic ED models on
each of these corpus and evaluate them on the ACE
testing data set. This experiment is an indirect evaluation of the events detected from FN, which is
based on the intuition that events with higher accuracy are expected to bring more improvements
to the basic model.
Training Corpus
ACE-ANN-FN
ACE-PSL-FN
Table 6: Automatic evaluations of events from FN.
Table 6 presents the results where we measure
precision, recall and F1. Compared with ACE-
ANN-FN, events from SF and RF hurt the performance. As analyzed in previous section, SF and R-
F yield quite a few false events, which dramatically hurt the accuracy. Moreover, ACE-SL-FN obtains a score of 70.3% in F1 measure, which outperforms ACE-ANN-FN. This result illustrates the
effectiveness of our “same LU” hypothesis. Finally and most importantly, consistent with the results
of manual evaluations, ACE-PSL-FN performs the
best, which further proves the effectiveness of our
proposed approach for event detection in FN.
Improving Event Detection Using FN
Event detection generally suffers from data sparseness due to lack of labeled samples. In this section,
we investigate the effects of alleviating the aforementioned problem by using the events detected
from FN as extra training data. Our investigation
is conducted by the comparison of two basic ED
models, ANN and ANN-FN: the former is trained
on ACE training corpus and the latter is trained on
the new training corpus ACE-PSL-FN (introduced
in the previous section), which contains 3,816 extra events detected from FN.
Nguyen’s CNN 
Chen’s DMCNN 
Liu’s Approach 
ANN (Ours)
ANN-FN (Ours)
Table 7: Effects of expanding training data using
events automatically detected from FN.
Table 7 presents the experimental results. Compared with ANN, ANN-FN achieves a signiﬁcant
improvement of 1.9% in F1 measure. It happens
mainly because that the high accurate extra training data makes the model obtain a higher recall
(from 60.7% to 65.2%) with less decrease of precision (from 79.5% to 77.6%). The result demonstrates the effectiveness of alleviating the data sparseness problem of ED by using events detected from FN. Moreover, compared with state-ofthe-art methods, ANN-FN outperforms all of them
with remarkable improvements (more than 1.3%).
Analysis of Frame-Event Mapping
In this section, we illustrate the details of mappings from frames to event types. The mapping
pairs are obtained by computing the function φ
(see Section 5.3) for each (frame, event-type) pair
(f, t) based on the events detected by the PSLbased approach. Table 8 presents the top 10 mappings. We manually evaluate their quality by investigating: (1) whether the deﬁnition of each
frame is compatible with its mapped event type;
(2) whether exemplars annotated for each frame
actually express events of its mapped event type.
For the ﬁrst issue, we manually compare
the deﬁnitions of each mapped pair. Except Relational nat features8, deﬁnitions of
all the mapped pairs are compatible. For the second issue, we randomly sample 20 exemplars (if
possible) from each frame and manually annotate
them. Except the above frame and Invading,
exemplars of the remaining frames all express the
right events. The only exemplar of Invading
failing to express its mapped event is as follows:
“The invasion of China by western culture has had
a number of far-reaching effects on Confucianism.” ACE requires an Attack event to be a physical act, while the invasion of culture is unphysical. Thus, the above sentence does not express an
8The full name is Relational natural relations in FN.
Hit target
Relational
nat features
Being born
Sentencing
End-Position
Notiﬁcation
of charges
Charge-Indict
Table 8: Top 10 mappings from frames to event types. Ne is the number of exemplars detected
as events; ||Sf|| and φ hold the same meanings as
mentioned in Section 5.3.
Attack event. To sum up, the quality of our mappings is good, which demonstrates that the hypothesis H1 is basically true.
Analysis of LU-Event Mapping
This section illustrates the details of mappings
from LUs to event types. The mapping pairs are
obtained by computing the function ψ (see Section
5.3). Table 9 presents the top 10 mappings. In FN,
each LU belongs to a frame. In table 9, we omit the
frame of each LU because of space limitation9.
decapitation.n
Trial-Hearing
Arrest-Jail
Table 9: Top 10 mappings from LUs to event types. Ne is the number of exemplars detected
as events; ||Sl|| and ψ hold the same meanings as
mentioned in Section 5.3.
To investigate the mapping quality, we manu-
separately
Hostile encounter,
Cause harm, Forming relationships, Killing, Trial, Attack,
Quarreling, Arrest, Forming relationships and Hit target.
ally annotate the exemplars under these LUs. The
result shows that all exemplars are rightly mapped.
These mappings are quite good. We believe the
reason is that an LU is hardly ambiguous due to
its high speciﬁcity, which is not only speciﬁed by
a lemma but also by a frame and a part of speech
tag. Table 9 only presents the top 10 mappings. In
fact, we obtain 54 mappings in total with ψ = 1.0.
We released all the detected events and mapping
results for further use by the NLP community.
Conclusions and Future Work
Motivated by the high similarity between frames
and events, we conduct this work to study their
relations. The key of this research is to detect events in FN. To solve this problem, we proposed
a PSL-based global inference approach based on
three hypotheses between frames and events. For
evaluation, we ﬁrst conduct manual evaluations on
events detected from FN. The results reveal that
our hypotheses are very useful and it is an effective
way to jointly utilize them as soft rules through P-
SL. In addition, we also perform automatic evaluations. The results further demonstrate the effectiveness of our proposed approach for detecting
events in FN. Furthermore, based on the detected
results, we analyze the mappings from frames/LUs
to event types. Finally, we alleviate the data sparseness problem of ED by using events detected
from FN as extra training data. Consequently, we
obtain a remarkable improvement and achieve a
new state-of-the-art result for the ED task.
Event detection is only a component of the overall task of event extraction, which also includes
event role detection. In the future, we will extend this work to the complete event extraction
task. Furthermore, event schemas in ACE are quite
coarse. For example, all kinds of violent acts, such
as street ﬁghts and wars, are treated as a single
event type Attack. We plan to reﬁne the event
schemas by the ﬁner-grained frames deﬁned in FN
(i.e. Attack may be divided into Terrorism,
Invading, etc.).
Acknowledgements
This work was supported by the Natural Science Foundation of China (No. 61533018), the
National Basic Research Program of China (No.
2014CB340503) and the National Natural Science
Foundation of China (No. 61272332). And this
work was also supported by Google through focused research awards program.