DeepPap: Deep Convolutional Networks for
Cervical Cell Classiﬁcation
Ling Zhang, Le Lu, Senior Member, IEEE, Isabella Nogues, Ronald M. Summers, Shaoxiong Liu,
and Jianhua Yao
Abstract—Automation-assisted cervical screening via Pap smear or
liquid-based cytology (LBC) is a highly effective cell imaging based
cancer detection tool, where cells are partitioned into ”abnormal” and
”normal” categories. However, the success of most traditional classiﬁcation methods relies on the presence of accurate cell segmentations.
Despite sixty years of research in this ﬁeld, accurate segmentation
remains a challenge in the presence of cell clusters and pathologies.
Moreover, previous classiﬁcation methods are only built upon the extraction of hand-crafted features, such as morphology and texture. This
paper addresses these limitations by proposing a method to directly
classify cervical cells – without prior segmentation – based on deep
features, using convolutional neural networks (ConvNets). First, the
ConvNet is pre-trained on a natural image dataset. It is subsequently
ﬁne-tuned on a cervical cell dataset consisting of adaptively re-sampled
image patches coarsely centered on the nuclei. In the testing phase,
aggregation is used to average the prediction scores of a similar set of
image patches. The proposed method is evaluated on both Pap smear
and LBC datasets. Results show that our method outperforms previous
algorithms in classiﬁcation accuracy (98.3%), area under the curve
(AUC) (0.99) values, and especially speciﬁcity (98.3%), when applied to
the Herlev benchmark Pap smear dataset and evaluated using ﬁve-fold
cross-validation. Similar superior performances are also achieved on the
HEMLBC (H&E stained manual LBC) dataset. Our method is promising
for the development of automation-assisted reading systems in primary
cervical screening.
Index Terms—Cell classiﬁcation, Deep learning, Neural networks, Pap
smear, Cervical cytology.
INTRODUCTION
ERVICAL cytology (conventional Pap smear or liquid-based
cytology) , the most popular screening test for prevention
and early detection of cervical cancer, has been widely used in
developed countries and has signiﬁcantly reduced its incidence
and number of deaths . However, population-wide screening is
still unavailable in underdeveloped countries , partly due to the
complexity and tedious nature of manually screening abnormal
L. Zhang, L. Lu, R. Summers, and J. Yao are with the Imaging Biomarkers
and Computer-Aided Diagnosis Laboratory and also with the Clinical Image
Processing Service, Radiology and Imaging Sciences Department, National
Institutes of Health Clinical Center, Bethesda, MD 20892 USA e-mail:
( ; ).
I. Nogues is with the Imaging Biomarkers and Computer-Aided Diagnosis
Laboratory, Radiology and Imaging Sciences Department, National Institutes
of Health Clinical Center, Bethesda, MD 20892 USA.
S. Liu is with the Department of Pathology, Peoples Hospital of Nanshan
District, Shenzhen 518052 China.
cells from a cervical cytology specimen . While automationassisted reading techniques can boost efﬁciency, their current
performance is not adequate for inclusion in primary cervical
screening .
During the past few decades, extensive research has been
devoted to the creation of computer-assisted reading systems based
on automated image analysis methods , , . Such systems
automatically select potentially abnormal cells in a given cervical
cytology specimen, from which the cytoscreener/cytopathologist
completes the classiﬁcation. This task comprises three steps: cell
(cytoplasm and nuclei) segmentation, feature extraction/selection,
and cell classiﬁcation.
Accurate cell segmentation is crucial to the success of a
reading system. However, despite recent signiﬁcant progress in
this area – , the presence of cell clusters (which is even
more problematic in Pap smear than in liquid-based cytology),
as well as the large shape and appearance variations between
abnormal and normal nuclei, remains a major obstacle to the
accurate segmentation of individual cytoplasms and nuclei. On
the Herlev benchmark dataset , , the attained nucleus
segmentation accuracy ranging between 0.85 and 0.92 .
On an overlapping cervical cell dataset , the cytoplasm segmentation accuracy ranges from 0.87 to 0.89 . On the other
hand, most cell classiﬁcation studies assume that accurate segmentations of individual cytoplasms and nuclei are already available
 – . By optimizing features derived from the segmented
cytoplasm and nucleus, high classiﬁcation accuracies (e.g., 96.8%)
are achieved on the Herlev dataset, using 5-fold cross validation
(CV) , . However, these high values would decrease, once
the automated segmentation error (deriving mainly from the errorprone abnormal nucleus segmentation , ), were taken into
Several strategies to remove this dependence on segmentation
have been investigated. Classiﬁcation based only on nucleus features (excluding cytoplasm features) is proposed , , .
Comparable results on the Herlev dataset is obtained by using
a non-linear dimensionality reduction algorithm and supervised
learning . Another idea is to classify image patches containing
full cervical cells – . However, extraction of such patches
still requires automated cell detection and segmentation. To avoid
the pre-segmentation step, pixel-level classiﬁcation method is designed to directly screen abnormal nuclei with no prior cytoplasm
and nucleus segmentation , but reports limited validation
results. Alternatively, a technique which classiﬁes the cropped
blocks from cell images is proposed . However, arbitrary
 
Convolutional
Neural Network
Cervical Cell
Preprocessing
Preprocessing
Convolutional
Neural Network
Aggregation
Overview of the proposed method using convolutional neural
networks and transfer learning for classifying cervical cell images.
cropping could potentially separate a full cell into distinct patches.
Current cervical screening systems are hindered by limitations
in the feature design and selection components. At present, extracted features fall under the following categories: handcrafted
features describing morphology and chromatin characteristics
 , – in accordance with “The Bethesda System (TBS)”
rules , engineered features representing texture distribution
 , , according to previous computer-aided-diagnosis
experiences, or both combined , , . The resulting features
are then organized, using a feature selection or dimensionality
reduction algorithm, for classiﬁcation. Handcrafted features are
compromised by the current limited understanding of cervical
cytology. Engineered features are obtained in an unsupervised
manner, and thus often encode redundant information. The feature selection process potentially ignores signiﬁcant clues and
removes complementary information. Moreover, considering that
the detection of some abnormal cervical cells is challenging even
for human experts , , , the hand-crafted features
used in previous studies may not be able to represent complex
discriminative information. In fact, information describing cell
abnormality may potentially lie in latent higher level features of
cervical cell images, but this has not yet been investigated.
Representation learning refers to a set of methods designed to
automatically learn and discover intricate discriminative information from raw data . Recently, representation learning has been
popularized by deep learning methods . In particular, deep
convolutional neural networks (ConvNets) have achieved
unprecedented results in the 2012 ImageNet Large Scale Visual
Recognition Challenge, which consisted in classifying natural
images in the ImageNet dataset into 1000 ﬁne-grained categories
 . They have also signiﬁcantly improved performance in a
variety of medical imaging applications , , such as classiﬁcation of lung diseases and lymph nodes in CT images ,
 , segmentation (pixel classiﬁcation) of brain tissues in
MRI, vessel segmentation in fundus images, and detecting
cervical intraepithelial neoplasia (CIN, particularly CIN2+) at
patient level based on Cervigram images or multimodal
data . Additionally, ConvNets have demonstrated superior
performance in the classiﬁcation of cell images, such as pleural
cancer and human epithelial-2 cell images .
Large datasets are crucial to the high performance of Conv-
Nets. However, there exists a very limited amount of labeled data
for cervical cells, as high expertise is required for quality annotation. For instance, the Herlev benchmark dataset only contains
917 cells (675 abnormal and 242 normal). Transfer learning –
 is an effective method to overcome this problem. Since the
features in the ﬁrst few ConvNet layers are more generic, they
can be appended to various sets of subsequent layers speciﬁc to
different tasks . For instance, ConvNets trained on large-scale
natural image datasets (e.g., ImageNet ) can be transferred
to various medical imaging datasets, such as CT , ultrasound
 and X-ray , datasets, and can subsequently reduce
overﬁtting on small datasets while boosting performance through
ﬁne-tuning.
In this paper, we apply ConvNets to the classiﬁcation of
cervical cells in cytology images. Our approach directly operates
on raw RGB channels sampled from a set of square image patches
coarsely centered on each nucleus. A ConvNet pre-trained on
ImageNet is ﬁne-tuned to discriminate between patches containing
abnormal and normal cells based on deep hierarchical features.
For an unseen cell, a set of image patches coarsely centered on the
nucleus are classiﬁed by the ﬁne-tuned ConvNet. Its classiﬁcation
results are then aggregated to generate the ﬁnal cell category.
Our approach is tested on two cervical cell image datasets: the
Herlev dataset consisting of Pap smear images ; the HEMLBC
(H&E stained manual liquid-based cytology) dataset being used
to develop automation-assisted cervical screening system . In
our experiments (conducted using ﬁve-fold cross-validation(CV)),
the ﬁne-tuned ConvNet obtains classiﬁcation accuracies of 98.3%
on Herlev dataset and 98.6% on HEMLBC dataset, surpass the
previous best accuracies of 96.8% and 94.3% on the two datasets,
respectively.
Our contributions are summarized as follows. 1) To the best
of our knowledge, this is the ﬁrst application of deep learning
and transfer learning methods to cervical cell classiﬁcation. 2)
Unlike the previous methods, which rely on cytoplasm/nucleus
segmentation and hand-crafted features, our method automatically
extracts deep hierarchical features embedded in the cell image
patch for classiﬁcation, as long as a coarse nucleus center is
provided. As a result, the classiﬁcation does not suffer from any
accuracy loss caused by inaccurate segmentation, and does not
explicitly utilize prior medical knowledge of cervical cytology. 3)
Our method generates the highest performances on both the Herlev
Pap smear and the HEMLBC datasets, and has the potential to
improve the performance of automation-assisted cervical cancer
screening systems.
The proposed method includes a training and a testing stage, as
shown in Fig. 1. In the training stage, a ConvNet is ﬁrst pre-trained
on the ImageNet dataset, and data preprocessing is applied on the
cervical cell dataset. Next, transfer learning is applied, whereby
the pre-trained network parameters are used to initialize a new
ConvNet. This ConvNet is then ﬁne-tuned on the preprocessed
training samples. In the testing stage, the preprocessed testing
images are fed into the ﬁne-tuned ConvNet. The abnormality score
is obtained by aggregating the ConvNet’s output values. Further
details are described below.
Data Preprocessing
Patch extraction
Unlike previous patch based cell classiﬁcation methods – ,
 , , our method does not directly operate on images containing full cells (like the images in the Herlev dataset), for practical
Translations
Translations
Fig. 2. Two set of image patches are generated from (a) an abnormal and (b) a normal cervical cell image by rotations and translations. The
centroids of translated image patches are shown as yellow, indicating the potentially inaccurate detection of nucleus centers.
reasons. In particular, obtaining an individual cell requires cell presegmentation (at least cytoplasm segmentation), which remains an
unsolved, challenging problem . As mentioned in the TBS
rules , different cervical cytology abnormalities are associated
with different nucleus abnormalities. Hence, nucleus features in
themselves already include substantial discriminative information.
We thus extract image patches of size m × m centered on the
nucleus centroid. This strategy allows for embedding not only the
nucleus scale/size information (an important discriminative feature
between abnormal and normal cells), but also the contextual clues
(e.g., the cytoplasm appearance) in the extracted patches. We
acknowledge that automated methods for extracting a nucleus
patch, e.g., Laplacian-of-Gaussian (LoG) , selective search
 , or ConvNets exist. However, in this paper, we choose
to focus on the classiﬁcation task. We adopt a simple method of
directly translating the centroid of the ground-truth nucleus mask
to extract a set of image patches as described below.
Data Augmentation
Data augmentation improves the accuracy of ConvNets and reduces overﬁtting . Since cervical cells are rotationally invariant, we perform Nr rotations (with a step size of θ degrees) on
each cell image, and thus increase our number of image samples.
Nr patches (one per rotated image) of size m × m centered at the
rotated nucleus centers are extracted as the training samples, as
shown in the middle (blue) panel in Fig. 2. Note that rotating
a cell image may slightly degrade its high frequency contents
(could be considered as a lower imaging quality), but should
not change its abnormality/normality for most cells. Actually the
augmentation step based on image rotation is crucial to the success
of the ConvNet , and has been demonstrated to be important
for improving accuracy of ConvNet-based cell image classiﬁcation
problem , given the limited number of images in the Herlev
and HEMLBC dataset. Zero padding is used to void regions that
lie outside of the image boundary.
Considering that the detected nucleus center may be inaccurate
in practice, we randomly translate (by up to d pixels) each nucleus
centroid Nt times to obtain Nt points as the coarse nucleus
centers. Accordingly, Nt patches of size m × m centered at these
locations are extracted as training samples, as shown in the right
(green) panel in Fig. 2. These patches not only simulate inaccurate
nucleus center detection, but also increase the amount of training
samples for ConvNets. Other data augmentation approaches such
as scale and color transformations are not used, as both the size
and intensity of the nucleus are essential features to distinguish
abnormal cervical cells from normal ones.
There are ∼3 times more abnormal cell images than normal
cell images in the Herlev dataset. Classiﬁers tend to exhibit bias
towards the majority class (abnormal cells). Although achieving
a high sensitivity rate (correct classiﬁcation of abnormal cells)
is ideal from a medical point of view , a high false positive
rate (mis-classiﬁcation of normal cells as abnormal) is not desirable from a practical standpoint . A common solution to this
dilemma is to balance the proportions of positive and negative
training samples . Doing so also improves the accuracy and
convergence rate of ConvNets in training , . Hence, we
create a balanced training set by sampling a higher proportion of
normal than abnormal patches.
Convolutional Neural Networks
A convolutional neural network (ConvNet) , is a deep
learning model comprising multiple consecutive stages, namely
convolutional (conv), non-linearity and pooling (pool) layers,
followed by more conv and fully connected (fc) layers. The input
of the ConvNet is the raw pixel intensity image (in our case, the
image obtained by subtracting the mean image over the training
set from the original image ). The output layer is composed of
several neurons each corresponding to one class. The weights (W)
in the ConvNet are optimized by minimizing the classiﬁcation
error on the training set using the backpropagation algorithm .
Fig. 3 shows two ConvNets. The upper network is trained on the
ImageNet dataset, and the lower network is trained on the cervical
cell dataset.
Convolutional layer
The conv layer takes local rectangular patches across (with offset
by stride and with/without spatial preservation by padding) the
input image (for the ﬁrst layer) or feature maps (for the subsequent layers) as input, on which 2D convolution with a ﬁlter
is performed. The sum x of the resulting convolutions is fed
into a non-linearity function, speciﬁcally a rectiﬁed linear unit
(ReLU) f(x) = max(0, x) , in order to increased the speed
of training. In a given layer, the same ﬁlter is shared in a feature
map, while different ﬁlters are used for different feature maps.
This property of ﬁlter sharing in conv layer allows for detecting
the same pattern in different locations of the feature map.
conv & pool
conv & pool
conv & pool
Image patch extraction
Input image (RGB)
Feature maps
Feature maps
Feature maps
ImageNet dataset
Parameter Transfer
Fine-Tuning
Pre-Training
Fig. 3. A ConvNet is ﬁne-tuned on the cervical cell dataset with parameters transferred from another ConvNet pre-trained on the ImageNet dataset.
In this example, the parameters (W1, W2, ... Wk) in the purple region in the pre-trained model (upper panel) are transferred to the same locations
in another model (lower panel) for ﬁne-tuning on cervical cell dataset.
Pooling layer
The pooling operation down-samples the feature map by summarizing feature responses in each non-overlapping local patch,
often by computing the maximum activations (max-pooling). This
yields features invariant to minor translations in the data.
Fully connected layer
conv and pool generate feature maps of smaller dimensions than
the input image, which are then passed through several fc layers.
The ﬁrst few fc layers fuse these feature maps into a feature
vector. The last fc layer contains two neurons which compute the
classiﬁcation probability for each class using softmax regression.
To reduce overﬁtting, “dropout” is used to constrain the fullyconnected layers.
Network training
The weights W in ConvNets are initialized with values from the
Gaussian distribution. During training, these weights are iteratively updated with the gradients of the loss function, computed
via stochastic gradient descent (SGD) over a mini-batch (size of
256) of training samples. The initial learning rate is decreased after
certain epochs. As in Ref. , momentum and weight decay are
used to speed up the learning and reduce overﬁtting. The training
process is terminated after a pre-determined number of epochs.
The model with the lowest validation loss value is selected as the
ﬁnal network.
Transfer Learning
Transfer learning refers to the ﬁne-tuning of deep learning models
that are pre-trained on other large-scale image datasets. In this
study, the ﬁrst few conv and pool layers of a ConvNet pre-trained
on the ImageNet classiﬁcation dataset (ILSVRC2012) (purple
region in the upper part in Fig. 3) are used as the base of our
network, on top of which several task-speciﬁc fc layers with
random initialized weights are attached. In order to facilitate the
transfer of features, the same network layers (conv and pool) with
the BVLC CaffeNet are transferred to the same locations
in our model (purple regions in Fig. 3). Like our network, the
CaffeNet also takes RGB channels as input. All of these layers are
jointly trained (ﬁne-tuned) on our cervical cell dataset, for which
a learning rate 10 times smaller than the original CaffeNet value
is used to ﬁne-tune the transferred layers, and the original learning
rate is used to train the fc layers from scratch.
To classify an unseen image, we combine random-view aggregation and multiple crop testing to produce the ﬁnal
prediction score. In particular, our data augmentation method
generates Nv image patches (rotations and translations about the
nucleus centroid). From each of these patches, Nc sub-patches
are cropped (including its corner, center and mirrored patches).
Hence, for each test cervical cell image, Nv × Nc sub-patches are
fed into the ConvNet. The ﬁnal prediction score is obtained by
averaging the scores of these Nv × Nc predictions.
The 917 cells (242 normal and 675 abnormal) from Herlev dataset.
Superﬁcial squamous epithelial
Intermediate squamous epithelial
Columnar epithelial
Mild squamous non-keratinizing dysplasia
Moderate squamous non-keratinizing dysplasia
Severe squamous non-keratinizing dysplasia
Squamous cell carcinoma in situ intermediate
EXPERIMENTAL METHODS
The cell data used to train and test the ConvNets comes from
two datasets with two types of cervical cytology images, which
were acquired by different slide preparation, staining methods,
and imaging conditions.
Herlev Dataset
The ﬁrst one is from a publicly available dataset ( collected at the Herlev University Hospital by a digital camera and microscope . The image resolution is 0.201 µm per pixel . The specimens are prepared
via conventional Pap smear and Pap staining. The Herlev dataset
consists of 917 images – each containing one cervical cell – with
ground truth segmentation and classiﬁcation. There are a total of
seven different classes – diagnosed by two cyto-technicians and
a doctor, in order to maximize certainty of the diagnosis. These
seven classes belong to two categories: class 1-3 are normal, and
class 4-7 are abnormal, as shown in Table 1. Examples of some
cells are provided in Fig. 4(a). As can be seen, most abnormal
cells have larger nucleus size than normal cells. However, the
normal columnar nucleus may have similar size (also maybe
similar chromatin distribution) as severe and/or carcinoma nuclei,
which makes the classiﬁcation challenging.
For each abnormal cell image in the Herlev dataset, Nr = 10
rotations (θ = 36◦) and Nt = 10 translations (up to 10 pixels)
are performed. For each normal cell, we use Nr = 20 (θ =
18◦) and Nt = 14, resulting in 100 and 280 image patches for
each abnormal and normal cell image, respectively. This yields
a relatively balanced data distribution. Note that such different
steps of rotation/translation for abnormal and normal cells are
only for training not testing set. The image patch size is set to
m = 128 pixels to cover some cytoplasm region for most cells,
and to contain most of the full nucleus region for the largest one.
These image patches are then up-sampled to a size of 256 × 256
× 3 pixels via bi-linear interpolation, in order to facilitate the
transfer of pre-trained ConvNet model .
HEMLBC Dataset
The second one is from our own dataset collected at the People’s
Hospital of Nanshan District by using our previously developed
autofocusing system (Olympus BX41 microscope with 20× objective, Jenoptik ProgRes CF Color 1.4 Megapixel Camera, and
MS300 motorized stage) . Each pixel has a size of 0.208 µm2.
The specimens are prepared by manual liquid-based cytology with
H&E staining. The dataset used in this paper is a subset used to
train the abnormal/normal nucleus classiﬁer for our automationassisted cervical screening system . There are totally 989
abnormal cells from 8 biopsy-conﬁrmed CIN slides and 1381
normal cells from another 8 NILM (negative for intraepithelial
lesion and malignancy) slide available. To create a balanced
data distribution, 989 normal cells are randomly selected. The
abnormal cells are diagnosed by two experienced pathologists.
Most of them are segmented by an automated algorithm and
the ill-segmented ones are manually segmented by a pathologist.
The normal cells are formed by two subsets: the ﬁrst subset
is collected by a pathologist with automated segmentation; the
second subset is some false positive cells (e.g., cells with large
nuclei, atrophic cells, etc.) collected during bootstrap process from
validation images with manual segmentation for the ill-segmented
ones by an engineer. More details are described in . Examples
of some cells are shown in Fig. 4(b).
For both abnormal and normal cell image in the HEMLBC
dataset, Nr = 10 rotations (θ = 36◦) and Nt = 10 translations
(up to 10 pixels) are performed, resulting in 100 image patches
for each cell image. The image patch size is also set to m = 128
pixels and then up-sampled to a size of 256 × 256 × 3 pixels as
in Herlev dataset.
Network Architectures and Implementation
Fig. 3 illustrates our network architecture. The base ConvNet (denote as ConvNet-B) is pre-trained on the ImageNet classiﬁcation
dataset. ConvNet-B contains ﬁve conv layers (conv1 −conv5),
three pool layers (pool1, pool2, pool5), and three fc layers
(fc6 −fc8). Layers from conv1 to pool5 are transferred to
the same locations in our model (denote as ConvNet-T). In other
word, the ﬁrst 5 weight layers (conv1 to pool5) of ConvNet-T are
copied from the pre-trained ConvNet-B, and fc6 −fc8 layers of
ConvNet-T are initialized with random Gaussian distributions. The
detailed conﬁgurations of our ConvNet-T are listed in Table. 2.
Local response normalization is used for conv1 and conv2 layers
using the same setting as , and all hidden layers are equipped
with the ReLU activation function. Note that the ConvNet-B
and ConvNet-T share the same network structure from conv1
to pool5, but the number of neurons of the three fc layers in
ConvNet-B and ConvNet-T are 4096-4096-1000 and 1024-256-2,
respectively. The 1024 and 256 are set based on our empirical
evaluation, and 2 is to accommodate the new object categories
in our 2-class (abnormal/normal) classiﬁcation problem. Actually,
setting the number of neurons of fc6 and fc7 layers in the range
of 1024∼256 will result in similar accuracy, while more number
of neurons (e.g., 4096-4096) tend to have slightly lower accuracy
(1%-2% lower) on our data, which is more compact and speciﬁc
compared to ImageNet. ConvNet-T is run on the Caffe platform
 , using a Nvidia GeForce GTX TITAN Z GPU with 12 GB of
Training and Testing Protocols
From each 256 × 256 training image patch or its mirrored version,
a 227 × 227 sub-patch is randomly cropped, from which the mean
image over the training set is then subtracted. Stochastic Gradient
Descent (SGD), with a mini-batch size of 256, is used to train the
ConvNet-T for 30 epochs. The learning rates of layers conv1 −
pool5 and layers fc6−fc8 start from 0.001 and 0.01, respectively,
and are decreased by a factor of 10 at every tenth epoch. Weight
decay and momentum are set to 0.0005 and 0.9. A dropout ratio
of 0.5 is used to constrain the fc6 and fc7 layers.
superficial
intermediate
(a) Herlev
(b) HEMLBC
Fig. 4. Example images of normal and abnormal cervical cells from the (a) Herlev and (b) HEMLBC dataset. All these examples keep their originally
relative scales for better illustrating the different characteristics (mainly nucleus size) between normal and abnormal cells.
ConvNet-T architectures for cervical cell classiﬁcation.
Filter size
In testing, we obtain the ﬁnal score by averaging the scores of
the fc8 output on 1000 patches (Nv = 100 augmentations each
with Nc = 10 sub-crops).
Evaluation Methods
We evaluate the cervical cell classiﬁcation using ﬁve-fold CV on
both Herlev and HEMLBC datasets, to facilitate comparison with
most previously reported results. In each of the 5 iterations of the
ConvNet, 4 of 5 folds are used as training data, and the remaining
one as validation. It’s worth mentioning that data augmentation
is after the training/validation splitting of cell population. We
obtain the model’s ﬁnal performance values by averaging results
from the 5 validation sets. The performance evaluation metrics
include sensitivity (Sens), speciﬁcity (Spec), accuracy (Acc),
harmonic mean (H-mean), F-measure, and area under the ROC
curve (AUC), where Sens measures the proportion of correctly
identiﬁed abnormal cells, and Spec the proportion of correctly
identiﬁed normal cells; Acc is the global percentage of correctly
classiﬁed cells; H-mean = 2 × Sens×Spec
Sens+Spec, used in , takes
into account the imbalanced data distribution; F-measure, the
harmonic mean of precision and recall, is used in . The ROC
curve is computed by varying thresholds on the ﬁnal classiﬁcation
scores (each ﬁnal score is the average score of 1000 predictions).
To test the robustness of our method against localization error of
nucleus center, we randomly translate the ground truth centers of
the test cells up to 5 or 10 pixels in both x and y directions, and the
resulting performances on Herlev dataset are reported. In addition,
the numbers of correct classiﬁcation (normal vs. abnormal) and the
distribution (shown by box plots) of the predicted abnormal scores
of all cells for each of the seven cell classes (listed in Table 1)
are reported. Finally, we further consider the 7-class classiﬁcation
problem by simply modifying the number of neurons in the last
fc layer from 2 to 7, and report the overall error (OE)% as in ,
ConvNet Learning Results
Fig. 5 illustrates a ﬁne-tuning process of ConvNet-T during 30
training epochs on the Herlev dataset. As shown in the ﬁgure, after
6 epochs, the validation loss reaches its minimum value (0.119),
with a corresponding validation accuracy of 0.972. Fig. 6 shows
the learned ﬁlters of the ﬁrst convolutional layer of ConvNet-
T trained on the Herlev Pap smear dataset. These automatically
learned ﬁlters mainly consist of gradients of different frequencies
and orientations and blobs of color, which are necessary for the
cervical cell classiﬁcation task. Along with these learned ﬁlters,
the activations (feature maps) of an example cell at different
pooling layers (pool1, pool2, and pool5) are provided in Fig.
7. One can observe that the pooling operation summarizes the
input cell image or previous feature maps by highlighting the activated spatial locations, and that the features become increasingly
abstract in deeper layers of the ConvNet.
(a) Training and validation loss, and (b) validation accuracy
versus number of training epochs.
Fig. 6. Visualization of the 96 ﬁlters with size of 11 × 11 × 3 in the ﬁrst
convolutional layer of ConvNet-T ﬁne-tuned on Pap smear dataset.
Qualitative Results
Fig. 8 and Fig. 9 contain examples of correctly classiﬁed abnormal and normal cell patches from the validation Herlev dataset,
respectively. Fig. 10 provides examples of misclassiﬁed cervical
cells from both Herlev and HEMLBC datasets, including both
false negatives and false positives. The ﬁrst two false negatives
are instances of carcinoma, and the third one is an example of
severe dysplasia. All false positives are columnar epithelial cells.
Quantitative Results on Herlev Dataset
Table 3 shows the classiﬁcation performance (Sens, Spec,
Acc, H-mean, F-measure, and AUC) of our method in comparison with previous methods , – , , on the
Herlev dataset. The mean values of Sens, Spec, Acc, H-mean,
F-measure, and AUC from our method (ConvNet-T) are 98.2%,
98.3%, 98.3%, 98.3%, 98.8%, and 0.998, respectively. We thus
outperform previous methods in all metrics but Sens, which is
slightly below others. Among these metrics, our Spec (98.3%)
substantially surpasses the previous highest result (92.2%). Also
note that certain degree of localization error (up to 10 pixels) of
nucleus center only results in a small reduction of performances
of our method (e.g., Acc from 98.3% to 97.8%).
Table 4 provides the numbers (and corresponding percentages)
of correct classiﬁcation for each of the seven cell classes. Our
method shows perfect performance on two types of normal cell
(superﬁcial and intermediate squamous epithelial), as well as one
type of abnormal cell (mild dysplasia). While the performances
are relatively lower for columnar epithelial and severe squamous
non-keratinizing dysplasia (both are 95.9%). The distribution of
the abnormal scores of all cells for the seven cell classes are
shown as box plots in Fig. 11. The proposed method returns
abnormality-scores close to 0 or 1 for most normal and abnormal
cells, respectively. The few misclassiﬁcations mainly occur to
normal columnar and severe squamous cells, given the probability
threshold at 0.5.
Finally, for the 7-class problem, an overall error (OE) of 1.6%
is achieved on average. Such an error is lower than errors of
previous methods, such as 7.9% and 3.9% .
Quantitative Results on HEMLBC Dataset
Table 5 compares the classiﬁcation performance between
the proposed deep ConvNet-based method and our previous
MLP (multilayer perceptron)-based method on the HEMLBC
dataset. Although the dataset used in this paper is a subset slightly
smaller than that used in , an obvious trend of performance
improvement can be observed.
Computational Speed
The average training time of a ConvNet-T running over up
to 30 epochs is about 4 hours. Using the Nv × Nc = 1000
classiﬁcation strategy, the testing time for one cervical cell is 3.5
seconds on average.
DISCUSSION
Comparison With Previous Methods
The methods in – follow the traditional cell classiﬁcation pipeline – with features derived from manually segmented
cytoplasms/nuclei. The techniques presented in , perform
direct texture classiﬁcation of the input image. In contrast, our
method automatically learns from the input image patch, and
thus is not limited by the shortcomings of cell segmentation or
feature design. The Sens values of previous methods are slightly
higher than those from our method (99.0% vs. 98.2% under 5fold CV). Such high Sens results mainly from the imbalanced
data distribution – number of abnormal cells ∼3 X higher than
the number of normal cells – which induces the classiﬁer to
predict more cells as abnormal. High Sens even at the expense
of fairly low Spec is required for specimen level diagnosis, as
all positives will be reexamined by human experts. However,
considering the abundance of normal cells (up to 300,000) in a
Pap smear slide, the resulting lower Spec will generate many false
positives in clinical practice. For example, a 92% speciﬁcity ,
 will result in about 24,000 false positive cells. As a result,
extensive and tedious targeted reading from a human observer
will be necessary to reﬁne the accuracy of the screening. Our
approach substantially decreases the number of false positives.
Although there are still about 1.7% false positives, they only
come from columnar epithelial cells (Table 4). Actually, the differentiation between some columnar epithelial cells and (severe)
abnormal cells are also challenging for experienced pathologists.
Our method perfectly eliminates the majority types of normal
cells (superﬁcial and intermediate epithelial) in a specimen, and
thus alleviates the labor burden of targeted reading and potentially
reduces screening errors. Compared to our previous MLP method
 on HEMLBC dataset, the deep ConvNet method achieves both
higher Sens and Spec at cell level. Actually, the automationassisted screening system built upon the MLP method has a
satisfyingly high Sens=88% and a perfect Spec=100% at slide
level by pathologist’s targeted reading. Therefore, our new method
has a high potential to further improve the Sens of screening
system while reducing the labor burden of targeted reading.
Input image
(3@227×227)
pool1 feature maps
(96@27×27)
pool2 feature maps
(256@13×13)
pool5 feature maps
Fig. 7. Visualization of the activations (feature maps) of three pooling layers, pool1, pool2, and pool5 for an input cervical cell image.
Performance comparison of our method with previous methods on the Herlev dataset. PSO-1nn: particle swarm optimization for feature selection
and 1-nearest neighbor as the classiﬁer. GEN-1nn: genetic algorithm for feature selection and 1-nearest neighbor as the classiﬁer. ANN: artiﬁcial
neural networks. K-PCA: kernel principal component analysis for dimensional reduction. Ensemble: majority voting of three classiﬁers. ENS:
ensemble classiﬁers based on Local Binary Pattern (LBP) with different conﬁgurations. dis(S + M): discriminative LBP with concatenated sign
and magnitude components. In the H-mean (%) column, numbers in () indicate that no such result is present in the literature, so approximate
results are calculated based on the corresponding Sens and Spec to enable comparison. ∗: The method in uses leave-one-out cross
validation (LOOCV) and excludes the columnar cells, which is not directly comparable to 10-fold (Refs. , ) or 5-fold CV (Refs. , ,
 – and our proposed method) that involve all types of cells. ∆d: randomly translate the ground truth nucleus center up to d pixels in both x
and y directions. Bold indicates the highest value in each column.
H-mean (%)
Benchmark 
(88.0±NA )
PSO-1nn 
(95.2±NA )
GEN-1nn 
(95.2±NA )
(98.2±NA )
K-PCA + SVM 
Ensemble 
dis(S + M) 
ConvNet-T∆5
ConvNet-T∆10
Abnormal Score = 0.99 Abnormal Score = 0.97 Abnormal Score = 0.99 Abnormal Score = 0.98
Abnormal Score = 0.96 Abnormal Score = 0.93 Abnormal Score = 0.89 Abnormal Score = 0.79
Examples of correctly classiﬁed abnormal cervical cells from
Herlev dataset. Column 1 to column 4 are mild dysplasia, moderate
dysplasia, severe dysplasia and carcinoma, respectively. Score = 1
corresponds to a 100% probability of representing an abnormal cell.
Advantages of the Proposed Method
1) The proposed method is designed for robust automated screening applications, since it only requires a coarse nucleus centroid
as input (no cytoplasm/nucleus segmentation is needed). Our
experiments indicate that the proposed image patch based cell
Abnormal Score = 0.00 Abnormal Score = 0.01 Abnormal Score = 0.01
Abnormal Score = 0.00 Abnormal Score = 0.12 Abnormal Score = 0.21
Fig. 9. Examples of correctly classiﬁed normal cervical cells from Herlev
dataset. Column 1 to column 3 are superﬁcial, intermediate and columnar epithelial, respectively. Score = 1 corresponds to a 100% probability
of representing an abnormal cell.
classiﬁcation is robust to inaccurate detection of nucleus centroid
(refer to ConvNet-T∆5 and ∆10 in Table 3). Some examples can
be seen in Fig. 8 and Fig. 9, where most of the image patches
are not centered on the exact nucleus centroids, but are still
assigned reasonable abnormal scores by our method. 2) Moreover,
(a) Herlev
(b) HEMLBC
Abnormal misclassified as normal
Normal misclassified as abnormal
Abnormal misclassified as normal
Normal misclassified as abnormal
Fig. 10. Examples of misclassiﬁed cervical cells from (a) Herlev dataset;
(b) HEMLBC dataset. All images are shown at their original scales.
Numbers (and percentages) of correct classiﬁcation (normal vs.
abnormal) for each of the seven cell classes in Herlev dataset.
Correct classiﬁcation
Superﬁcial squamous epithelial
Intermediate squamous epithelial
Columnar epithelial
94 (95.9%)
Mild squamous non-keratinizing dysplasia
182 (100%)
Moderate squamous non-keratinizing dysplasia
145 (99.3%)
Severe squamous non-keratinizing dysplasia
189 (95.9%)
Squamous cell carcinoma in situ intermediate
147 (98.0%)
Fig. 11. Box plots shown the distribution of abnormal scores of all cells
in the seven classes from Herlev dataset. Blue and red backgrounds
indicate normal and abnormal cell categories, respectively. Black dash
line is the score threshold 0.5.
Performance comparison of our method with a previous method on the
HEMLBC dataset. ConvNet-T∗— It’s worth mention that the 989/989
abnormal/normal cells used in this paper is a subset of 1,126/1,126
abnormal/normal cells used in due to data missing of some
abnormal cells.
ConvNet-T∗
our method is able to distinguish the abnormal and normal cells
even for some “difﬁcult” cases. For example, the two columnar
epithelial cells in the third column in Fig. 9 appear to exhibit a
far greater level of abnormality than a severe dysplasia cell (lower
one in the third column in Fig. 8), as these columnar cells have
much larger nuclei or nonuniform chromatin distributions. Unlike traditional morphology/texture based classiﬁcation methods,
which simply classify both cells as abnormal, our method provides
a much higher abnormal score (0.89) for the severe dysplasia
cell than the two columnar cells (0.01 and 0.21). This indicates
that the ConvNet-T captures some latent but essential features
embedded in the cell images. 3) Finally, the deep learning based
method has high Sens and especially high Spec, and produces
the highest performances on a Pap-stained Pap smear (Herlev) and
a H&E stained liquid-based cytology (HEMLBC) datasets. Such
a strong performance has the potential to boost the development
of automation-assisted reading systems in primary cervical cancer
screening.
Limitations
Despite its high performance, our method demonstrates a few
limitations hindering its inclusion in existing cervical screening
systems. 1) Classiﬁcation of a single patch requires 3.5 seconds,
which is far too slow in a clinical setting. One could address
this issue by eliminating the image patch augmentation step (100
variants per patch) from the testing phase, thus reducing speed
to 0.035 seconds while compromising accuracy by only ∼1%.
2) Despite high classiﬁcation accuracy on the Herlev dataset, our
method misclassify a few severe dysplasia (4.1%) and carcinoma
(2%) cells as normal (Table 4 and Fig. 11). As shown in Fig.
10(a), two dark stained carcinoma nuclei and a very large severe
dysplasia nucleus are incorrectly classiﬁed as normal. An ideal
screening system should not miss such severe abnormalities. To
better handle such mis-classiﬁcations, cytoplasm/nucleus segmentation based features could be integrated into the system, either via
deep learning or via “TBS” rules. Furthermore, both Herlev and
HEMLBC are mainly consisted of expert-selected “typical” cells.
The real life situation is more complex so more investigations are
needed before transferring the results of this study to practice. For
example, refer to the last two false positive cells in Fig. 10(b), they
are from NILM slides, but it’s hard to tell whether: the ﬁrst one
is an abnormal or normal cell due to poor imaging quality, and
the second one is a normal atrophic cell or an abnormal cell. 3) A
nucleus center is pre-required for applying our method, and is obtained from the ground truth segmentation in this paper. However,
screening of abnormal cells within a given ﬁeld-of-view requires
automated detection of nucleus centers. Our ongoing study shows
that this may easily be achieved using the fully convolutional
networks (FCN) , for semantic segmentation of cervical
cells. And we already show that our method is robust to certain
amount of inaccurate nucleus center detection. 4) The current
experiments are conducted on a majority of images with individual
cells. The effect of overlapping nuclei, cell clumps and artifacts
on classiﬁcation accuracy needs to be analyzed more extensively
in the future investigation, since a screening system is expected to
able to avoid misclassifying such objects as abnormal cells. Taskspeciﬁc classiﬁers (mostly likely relying on deep learning) may be
needed to handle these problems , , .
CONCLUSION
This paper proposes a convolutional neural network-based method
to classify cervical cells. Unlike previous methods, which rely
on cytoplasm/nucleus segmentation and hand-crafted features,
our method automatically extracts deep features embedded in
the cell image patch for classiﬁcation. It consists in extracting
image patches coarsely centered on the nucleus as network input,
transferring features from another pre-trained model into a new
ConvNet for ﬁne-tuning on the cell image patches, and aggregating
multiple predictions to form the ﬁnal network output. The proposed method yields the highest performance on both the Herlev
Pap smear and the HEMLBC liquid-based cytology datasets,
compared to previous methods. We anticipate that a segmentationfree, highly accurate cervical cell classiﬁcation system of this type
is promising for the development of automation-assisted reading
systems for primary cervical screening.
ACKNOWLEDGMENTS
This work was supported in part by the Intramural Research
Program at the NIH Clinical Center, and the National Natural
Science Foundation of China (81501545). The authors thank
Nvidia for the TITAN Z GPU donation.