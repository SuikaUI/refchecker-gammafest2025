Meta-Learning with Differentiable Convex Optimization
Kwonjoon Lee2
Subhransu Maji1,3
Avinash Ravichandran1
Stefano Soatto1,4
1Amazon Web Services
2UC San Diego
3UMass Amherst
 
{smmaji,ravinash,soattos}@amazon.com
Many meta-learning approaches for few-shot learning
rely on simple base learners such as nearest-neighbor classiﬁers. However, even in the few-shot regime, discriminatively trained linear predictors can offer better generalization. We propose to use these predictors as base learners to
learn representations for few-shot learning and show they
offer better tradeoffs between feature size and performance
across a range of few-shot recognition benchmarks. Our
objective is to learn feature embeddings that generalize well
under a linear classiﬁcation rule for novel categories. To
efﬁciently solve the objective, we exploit two properties of
linear classiﬁers: implicit differentiation of the optimality
conditions of the convex problem and the dual formulation
of the optimization problem. This allows us to use highdimensional embeddings with improved generalization at a
modest increase in computational overhead. Our approach,
named MetaOptNet, achieves state-of-the-art performance
on miniImageNet, tieredImageNet, CIFAR-FS, and FC100
few-shot learning benchmarks. Our code is available online1.
1. Introduction
The ability to learn from a few examples is a hallmark
of human intelligence, yet it remains a challenge for modern machine learning systems. This problem has received
signiﬁcant attention from the machine learning community
recently where few-shot learning is cast as a meta-learning
problem (e.g., ). The goal is to minimize generalization error across a distribution of tasks with few training examples. Typically, these approaches are composed of
an embedding model that maps the input domain into a feature space and a base learner that maps the feature space
to task variables. The meta-learning objective is to learn
an embedding model such that the base learner generalizes
well across tasks.
While many choices for base learners exist, nearestneighbor classiﬁers and their variants (e.g., ) are
1 
popular as the classiﬁcation rule is simple and the approach
scales well in the low-data regime. However, discriminatively trained linear classiﬁers often outperform nearestneighbor classiﬁers (e.g., ) in the low-data regime
as they can exploit the negative examples which are often
more abundant to learn better class boundaries. Moreover,
they can effectively use high dimensional feature embeddings as model capacity can be controlled by appropriate
regularization such as weight sparsity or norm.
Hence, in this paper, we investigate linear classiﬁers as
the base learner for a meta-learning based approach for fewshot learning. The approach is illustrated in Figure 1 where
a linear support vector machine (SVM) is used to learn a
classiﬁer given a set of labeled training examples and the
generalization error is computed on a novel set of examples
from the same task. The key challenge is computational
since the meta-learning objective of minimizing the generalization error across tasks requires training a linear classi-
ﬁer in the inner loop of optimization (see Section 3). However, the objective of linear models is convex and can be
solved efﬁciently. We observe that two additional properties
arising from the convex nature that allows efﬁcient metalearning: implicit differentiation of the optimization 
and the low-rank nature of the classiﬁer in the few-shot setting. The ﬁrst property allows the use of off-the-shelf convex optimizers to estimate the optima and implicitly differentiate the optimality or Karush-Kuhn-Tucker (KKT) conditions to train embedding model.
The second property
means that the number of optimization variables in the dual
formation is far smaller than the feature dimension for fewshot learning.
To this end, we have incorporated a differentiable
quadratic programming (QP) solver which allows endto-end learning of the embedding model with various linear
classiﬁers, e.g., multiclass support vector machines (SVMs)
 or linear regression, for few-shot classiﬁcation tasks.
Making use of these properties, we show that our method
is practical and offers substantial gains over nearest neighbor classiﬁers at a modest increase in computational costs
(see Table 3). Our method achieves state-of-the-art performance on 5-way 1-shot and 5-shot classiﬁcation for popuarXiv:1904.03758v2 [cs.CV] 23 Apr 2019
Embeddings of
Training Examples
Weights of
Linear Classifier
Score (logit)
for Each Class
Training Examples
Test Examples
Figure 1. Overview of our approach. Schematic illustration of our method MetaOptNet on an 1-shot 3-way classiﬁcation task. The
meta-training objective is to learn the parameters φ of a feature embedding model fφ that generalizes well across tasks when used with
regularized linear classiﬁers (e.g., SVMs). A task is a tuple of a few-shot training set and a test set (see Section 3 for details).
lar few-shot benchmarks including miniImageNet ,
tieredImageNet , CIFAR-FS , and FC100 .
2. Related Work
Meta-learning studies what aspects of the learner (commonly referred to as bias or prior) effect generalization
across a distribution of tasks . Meta-learning approaches for few-shot learning can be broadly categorized
these approaches into three groups. Gradient-based methods use gradient descent to adapt the embedding
model parameters (e.g., all layers of a deep network) given
training examples. Nearest-neighbor methods learn
a distance-based prediction rule over the embeddings. For
example, prototypical networks represent each class by
the mean embedding of the examples, and the classiﬁcation
rule is based on the distance to the nearest class mean. Another example is matching networks that learns a kernel density estimate of the class densities using the embeddings over training data (the model can also be interpreted
as a form of attention over training examples). Model-based
methods learn a parameterized predictor to estimate
model parameters, e.g., a recurrent network that predicts parameters analogous to a few steps of gradient descent in parameter space. While gradient-based methods are general,
they are prone to overﬁtting as the embedding dimension
grows . Nearest-neighbor approaches offer simplicity and scale well in the few-shot setting. However, nearestneighbor methods have no mechanisms for feature selection
and are not very robust to noisy features.
Our work is related to techniques for backpropagation
though optimization procedures. Domke presented a
generic method based on unrolling gradient-descent for a
ﬁxed number of steps and automatic differentiation to compute gradients. However, the trace of the optimizer (i.e.,
the intermediate values) needs to be stored in order to compute the gradients which can be prohibitive for large problems. The storage overhead issue was considered in more
detail by Maclaurin et al. where they studied low precision representations of the optimization trace of deep networks. If the argmin of the optimization can be found analytically, such as in unconstrained quadratic minimization
problems, then it is also possible to compute the gradients
analytically. This has been applied for learning in low-level
vision problems . A concurrent and closely related
work uses this idea to learn few-shot models using ridgeregression base learners which have closed-form solutions.
We refer readers to Gould et al. which provides an excellent survey of techniques for differentiating argmin and
argmax problems.
Our approach advocates the use of linear classiﬁers
which can be formulated as convex learning problems. In
particular, the objective is a quadratic program (QP) which
can be efﬁciently solved to obtain its global optima using
gradient-based techniques. Moreover, the solution to convex problems can be characterized by their Karush-Kuhn-
Tucker (KKT) conditions which allow us to backpropagate
through the learner using the implicit function theorem .
Speciﬁcally, we use the formulation of Amos and Kolter 
which provides efﬁcient GPU routines for computing solutions to QPs and their gradients. While they applied this
framework to learn representations for constraint satisfaction problems, it is also well-suited for few-shot learning as
the problem sizes that arise are typically small.
While our experiments focus on linear classiﬁers with
hinge loss and ℓ2 regularization, our framework can be used
with other loss functions and non-linear kernels. For example, the ridge regression learner used in can be implemented within our framework allowing a direct comparison.
3. Meta-learning with Convex Base Learners
We ﬁrst derive the meta-learning framework for few-shot
learning following prior work (e.g., ) and then
discuss how convex base learners, such as linear SVMs, can
be incorporated.
3.1. Problem formulation
Given the training set Dtrain = {(xt, yt)}T
t=1, the goal
of the base learner A is to estimate parameters θ of the predictor y = f(x; θ) so that it generalizes well to the unseen
test set Dtest = {(xt, yt)}Q
t=1. It is often assumed that the
training and test set are sampled from the same distribution
and the domain is mapped to a feature space using an embedding model fφ parameterized by φ. For optimizationbased learners, the parameters are obtained by minimizing
the empirical loss over training data along with a regularization that encourages simpler models. This can be written
θ = A(Dtrain; φ) = arg min
Lbase(Dtrain; θ, φ) + R(θ)
where Lbase is a loss function, such as the negative loglikelihood of labels, and R(θ) is a regularization term. Regularization plays an important role in generalization when
training data is limited.
Meta-learning approaches for few-shot learning aim to
minimize the generalization error across a distribution of
tasks sampled from a task distribution.
Concretely, this
can be thought of as learning over a collection of tasks:
= {(Dtrain
i=1, often referred to as a metatraining set. The tuple (Dtrain
) describes a training
and a test dataset, or a task. The objective is to learn an
embedding model φ that minimizes generalization (or test)
error across tasks given a base learner A. Formally, the
learning objective is:
Lmeta(Dtest; θ, φ), where θ = A(Dtrain; φ)
Figure 1 illustrates the training and testing for a single
task. Once the embedding model fφ is learned, its generalization is estimated on a set of held-out tasks (often referred
to as a meta-test set) S = {(Dtrain
j=1 computed
Lmeta(Dtest; θ, φ), where θ = A(Dtrain; φ)
Following prior work , we call the stages of estimating the expectation in Equation 2 and 3 as meta-training and
meta-testing respectively. During meta-training, we keep an
additional held-out meta-validation set to choose the hyperparameters of the meta-learner and pick the best embedding
3.2. Episodic sampling of tasks
Standard few-shot learning benchmarks such as miniImageNet evaluate models in K-way, N-shot classiﬁcation tasks. Here K denotes the number of classes, and N
denotes the number of training examples per class. Fewshot learning techniques are evaluated for small values of
N, typically N ∈{1, 5}. In practice, these datasets do not
explicitly contain tuples (Dtrain
), but each task for
meta-learning is constructed “on the ﬂy” during the metatraining stage, commonly described as an episode.
For example, in prior work , a task (or episode)
Ti = (Dtrain
) is sampled as follows. The overall
set of categories is Ctrain. For each episode, categories Ci
containing K categories from the Ctrain are ﬁrst sampled
(with replacement); then training (support) set Dtrain
{(xn, yn) | n = 1, . . . , N × K, yn ∈Ci} consisting of N
images per category is sampled; and ﬁnally, the test (query)
= {(xn, yn) | n = 1, . . . , Q × K, yn ∈Ci}
consisting of Q images per category is sampled.
We emphasize that we need to sample without replacement, i.e., Dtrain
= Ø, to optimize the generalization error.
In the same manner, meta-validation set
and meta-test set are constructed on the ﬂy from Cval and
Ctest, respectively.
In order to measure the embedding
model’s generalization to unseen categories, Ctrain, Cval,
and Ctest are chosen to be mutually disjoint.
3.3. Convex base learners
The choice of the base learner A has a signiﬁcant impact on Equation 2. The base learner that computes θ =
A(Dtrain; φ) has to be efﬁcient since the expectation has to
be computed over a distribution of tasks. Moreover, to estimate parameters φ of the embedding model the gradients of
the task test error Lmeta(Dtest; θ, φ) with respect to φ have
to be efﬁciently computed. This has motivated simple base
learners such as nearest class mean for which the parameters of the base learner θ are easy to compute and the
objective is differentiable.
We consider base learners based on multi-class linear
classiﬁers (e.g., support vector machines (SVMs) ,
logistic regression, and ridge regression) where the baselearner’s objective is convex. For example, a K-class linear
SVM can be written as θ = {wk}K
k=1. The Crammer and
Singer formulation of the multi-class SVM is:
θ = A(Dtrain; φ) = arg min
subject to
wyn · fφ(xn) −wk · fφ(xn) ≥1 −δyn,k −ξn, ∀n, k
where Dtrain = {(xn, yn)}, C is the regularization parameter and δ·,· is the Kronecker delta function.
Gradients of the SVM objective.
From Figure 1, we see
that in order to make our system end-to-end trainable, we
require that the solution of the SVM solver should be differentiable with respect to its input, i.e., we should be able
to compute {
∂fφ(xn)}N×K
n=1 . The objective of SVM is convex and has a unique optimum. This allows for the use of
implicit function theorem (e.g., ) on the optimality
(KKT) conditions to obtain the necessary gradients. For the
sake of completeness, we derive the form of the theorem for
convex optimization problems as stated in . Consider the
following convex optimization problem:
subject to
f(θ, z) ⪯0
h(θ, z) = 0.
where the vector θ ∈Rd is the optimization variable of the
problem, the vector z ∈Re is the input parameter of the
optimization problem, which is {fφ(xn)} in our case. We
can optimize the objective by solving for the saddle point
(˜θ, ˜λ, ˜ν) of the following Lagrangian:
L(θ, λ, ν, z) = f0(θ, z) + λT f(θ, z) + νT h(θ, z).
In other words, we can obtain the optimum of the objective
function by solving g(˜θ, ˜λ, ˜ν, z) = 0 where
g(θ, λ, ν, z) =
∇θL(θ, λ, ν, z)
diag(λ)f(θ, z)
Given a function f(x) : Rn →Rm, denote Dxf(x) as
its Jacobian ∈Rm×n.
Theorem 1 (From Barratt ) Suppose g(˜θ, ˜λ, ˜ν, z) = 0.
Then, when all derivatives exist,
Dz ˜θ = −Dθg(˜θ, ˜λ, ˜ν, z)−1Dzg(˜θ, ˜λ, ˜ν, z).
This result is obtained by applying the implicit function
theorem to the KKT conditions. Thus, once we compute the
optimal solution ˜θ, we can obtain a closed-form expression
for the gradient of ˜θ with respect to the input data. This
obviates the need for backpropagating through the entire
optimization trajectory since the solution does not depend
on the trajectory or initialization due to its uniqueness. This
also saves memory, an advantage that convex problems have
over generic optimization problems.
Time complexity.
The forward pass (i.e., computation of
Equation 4) using our approach requires the solution to the
QP solver whose complexity scales as O(d3) where d is
the number of optimization variables. This time is dominated by factorizing the KKT matrix required for primaldual interior point method. Backward pass requires the solution to Equation 8 in Theorem 1, whose complexity is
O(d2) given the factorization already computed in the forward pass. Both forward pass and backward pass can be
expensive when the dimension of embedding fφ is large.
Dual formulation.
The dual formulation of the objective
in Equation 4 allows us to address the poor dependence on
the embedding dimension and can be written as follows. Let
We can instead optimize in the dual space:
||wk(αk)||2
subject to
This results in a quadratic program (QP) over the dual
variables {αk}K
k=1. We note that the size of the optimization variable is the number of training examples times the
number of classes. This is often much smaller than the size
of the feature dimension for few-shot learning. We solve
the dual QP of Equation 10 using which implements a
differentiable GPU-based QP solver. In practice (as seen
in Table 3) the time taken by the QP solver is comparable
to the time taken to compute features using the ResNet-12
architectures so the overall speed per iteration is not significantly different from those based on simple base learners
such as nearest class prototype (mean) used in Prototypical
Networks .
Concurrent to our work, Bertinetto et al. employed
ridge regression as the base learner which has a closed-form
solution. Although ridge regression may not be best suited
for classiﬁcation problems, their work showed that training
models by minimizing squared error with respect to one-hot
labels works well in practice. The resulting optimization for
ridge regression is also a QP and can be implemented within
our framework as:
||wk(αk)||2
where wk is deﬁned as Equation 9. A comparison of linear SVM and ridge regression in Section 4 shows a slight
advantage of the linear SVM formation.
3.4. Meta-learning objective
To measure the performance of the model we evaluate
the negative log-likelihood of the test data sampled from
the same task. Hence, we can re-express the meta-learning
objective of Equation 2 as:
Lmeta(Dtest; θ, φ, γ) =
(x,y)∈Dtest
[−γwy · fφ(x) + log
exp(γwk · fφ(x))]
where θ = A(Dtrain; φ) = {wk}K
k=1 and γ is a learnable
scale parameter. Prior work in few-shot learning 
suggest that adjusting the prediction score by a learnable
scale parameter γ provides better performance under nearest class mean and ridge regression base learners.
We empirically ﬁnd that inserting γ is beneﬁcial for the
meta-learning with SVM base learner as well. While other
choices of test loss, such as hinge loss, are possible, loglikelihood worked the best in our experiments.
4. Experiments
We ﬁrst describe the network architecture and optimization details used in our experiments (Section 4.1). We then
present results on standard few-shot classiﬁcation benchmarks including derivatives of ImageNet (Section 4.2) and
CIFAR (Section 4.3), followed by a detailed analysis of the
impact of various base learners on accuracy and speed using the same embedding network and training setup (Section 4.4-4.6).
4.1. Implementation details
Meta-learning setup. We use a ResNet-12 network following in our experiments. Let Rk denote a residual
block that consists of three {3×3 convolution with k ﬁlters,
batch normalization, Leaky ReLU(0.1)}; let MP denote a
2×2 max pooling. We use DropBlock regularization ,
a form of structured Dropout.
Let DB(k, b) denote
a DropBlock layer with keep rate=k and block size=b.
The network architecture for ImageNet derivatives is:
R64-MP-DB(0.9,1)-R160-MP-DB(0.9,1)-R320-
MP-DB(0.9,5)-R640-MP-DB(0.9,5),
network architecture used for CIFAR derivatives is:
R64-MP-DB(0.9,1)-R160-MP-DB(0.9,1)-R320-
MP-DB(0.9,2)-R640-MP-DB(0.9,2).
apply a global average pooling after the last residual block.
As an optimizer, we use SGD with Nesterov momentum of 0.9 and weight decay of 0.0005. Each mini-batch
consists of 8 episodes. The model was meta-trained for 60
epochs, with each epoch consisting of 1000 episodes. The
learning rate was initially set to 0.1, and then changed to
0.006, 0.0012, and 0.00024 at epochs 20, 40 and 50, respectively, following the practice of .
During meta-training, we adopt horizontal ﬂip, random
crop, and color (brightness, contrast, and saturation) jitter
data augmentation as in . For experiments on mini-
ImageNet with ResNet-12, we use label smoothing with
ϵ = 0.1. Unlike where they used higher way classiﬁcation for meta-training than meta-testing, we use a 5way classiﬁcation in both stages following recent works
 . Each class contains 6 test (query) samples during meta-training and 15 test samples during meta-testing.
Our meta-trained model was chosen based on 5-way 5-shot
test accuracy on the meta-validation set.
Meta-training shot. For prototypical networks, we match
the meta-training shot to meta-testing shot following the
usual practice . For SVM and ridge regression, we
observe that keeping meta-training shot higher than metatesting shot leads to better test accuracies as shown in Figure 2. Hence, during meta-training, we set training shot to
15 for miniImageNet with ResNet-12; 5 for miniImageNet
with 4-layer CNN (in Table 3); 10 for tieredImageNet; 5 for
CIFAR-FS; and 15 for FC100.
Base-learner setup. For linear classiﬁer training, we use
the quadratic programming (QP) solver OptNet . Regularization parameter C of SVM was set to 0.1. Regularization parameter λ of ridge regression was set to 50.0. For the
nearest class mean (prototypical networks), we use squared
Euclidean distance normalized with respect to the feature
dimension.
Early stopping. Although we can run the optimizer until convergence, in practice we found that running the QP
solver for a ﬁxed number of iterations (just three) works
well in practice. Early stopping acts an additional regularizer and even leads to a slightly better performance.
4.2. Experiments on ImageNet derivatives
The miniImageNet dataset is a standard benchmark
for few-shot image classiﬁcation benchmark, consisting of
100 randomly chosen classes from ILSVRC-2012 .
These classes are randomly split into 64, 16 and 20 classes
for meta-training, meta-validation, and meta-testing respectively. Each class contains 600 images of size 84×84. Since
the class splits were not released in the original publication , we use the commonly-used split proposed in .
The tieredImageNet benchmark is a larger subset
of ILSVRC-2012 , composed of 608 classes grouped
into 34 high-level categories. These are divided into 20 categories for meta-training, 6 categories for meta-validation,
and 8 categories for meta-testing. This corresponds to 351,
97 and 160 classes for meta-training, meta-validation, and
meta-testing respectively. This dataset aims to minimize the
semantic similarity between the splits. All images are of
size 84 × 84.
Results. Table 1 summarizes the results on the 5-way mini-
ImageNet and tieredImageNet. Our method achieves stateof-the-art performance on 5-way miniImageNet and tiered-
ImageNet benchmarks. Note that LEO make use of
encoder and relation network in addition to the WRN-28-10
backbone network to produce sample-dependent initializa-
Table 1. Comparison to prior work on miniImageNet and tieredImageNet. Average few-shot classiﬁcation accuracies (%) with 95%
conﬁdence intervals on miniImageNet and tieredImageNet meta-test splits. a-b-c-d denotes a 4-layer convolutional network with a, b, c,
and d ﬁlters in each layer. ∗Results from . †Used the union of meta-training set and meta-validation set to meta-train the meta-learner.
“RR” stands for ridge regression.
miniImageNet 5-way
tieredImageNet 5-way
Meta-Learning LSTM∗ 
64-64-64-64
43.44 ± 0.77
60.60 ± 0.71
Matching Networks∗ 
64-64-64-64
43.56 ± 0.84
55.31 ± 0.73
32-32-32-32
48.70 ± 1.84
63.11 ± 0.92
51.67 ± 1.81
70.30 ± 1.75
Prototypical Networks∗† 
64-64-64-64
49.42 ± 0.78
68.20 ± 0.66
53.31 ± 0.89
72.69 ± 0.74
Relation Networks∗ 
64-96-128-256
50.44 ± 0.82
65.32 ± 0.70
54.48 ± 0.93
71.32 ± 0.78
96-192-384-512
51.2 ± 0.6
68.8 ± 0.1
Transductive Prop Nets 
64-64-64-64
55.51 ± 0.86
69.86 ± 0.65
59.91 ± 0.94
73.30 ± 0.75
SNAIL 
55.71 ± 0.99
68.88 ± 0.92
Dynamic Few-shot 
64-64-128-128
56.20 ± 0.86
73.00 ± 0.64
AdaResNet 
56.88 ± 0.62
71.94 ± 0.57
TADAM 
58.50 ± 0.30
76.70 ± 0.30
Activation to Parameter† 
59.60 ± 0.41
73.74 ± 0.19
61.76 ± 0.08
77.59 ± 0.12
66.33 ± 0.05
81.44 ± 0.09
MetaOptNet-RR (ours)
61.41 ± 0.61
77.88 ± 0.46
65.36 ± 0.71
81.34 ± 0.52
MetaOptNet-SVM (ours)
62.64 ± 0.61
78.63 ± 0.46
65.99 ± 0.72
81.56 ± 0.53
MetaOptNet-SVM-trainval (ours)†
64.09 ± 0.62
80.00 ± 0.45
65.81 ± 0.74
81.75 ± 0.53
tion of gradient descent. TADAM employs a task embedding network (TEN) block for each convolutional layer
– which predicts element-wise scale and shift vectors.
We also note that pretrain the WRN-28-10 feature extractor to jointly classify all 64 classes in mini-
ImageNet meta-training set; then freeze the network during
the meta-training. make use of a similar strategy of
using standard classiﬁcation: they co-train the feature embedding on few-shot classiﬁcation task (5-way) and standard classiﬁcation task (64-way). In contrast, our system is
meta-trained end-to-end, explicitly training the feature extractor to work well on few-shot learning tasks with regularized linear classiﬁers. This strategy allows us to clearly see
the effect of meta-learning. Our method is arguably simpler
and achieves strong performance.
4.3. Experiments on CIFAR derivatives
The CIFAR-FS dataset is a recently proposed fewshot image classiﬁcation benchmark, consisting of all 100
classes from CIFAR-100 . The classes are randomly
split into 64, 16 and 20 for meta-training, meta-validation,
and meta-testing respectively. Each class contains 600 images of size 32 × 32.
The FC100 dataset is another dataset derived from
CIFAR-100 , containing 100 classes which are grouped
into 20 superclasses. These classes are partitioned into 60
classes from 12 superclasses for meta-training, 20 classes
from 4 superclasses for meta-validation, and 20 classes
from 4 superclasses for meta-testing. The goal is to minimize semantic overlap between classes similar to the goal
Meta-training shot
Accuracy (%)
miniImageNet 5-way
MetaOptNet­SVM­1­shot
MetaOptNet­SVM­5­shot
Prototypical Networks­1­shot
Prototypical Networks­5­shot
Meta-training shot
Accuracy (%)
tieredImageNet 5-way
Meta-training shot
Accuracy (%)
CIFAR-FS 5-way
Meta-training shot
Accuracy (%)
FC100 5-way
Figure 2. Test accuracies (%) on meta-test sets with varying
meta-training shot. Shaded region denotes 95% conﬁdence interval. In general, the performance of MetaOptNet-SVM on both
1-shot and 5-shot regimes increases with increasing meta-training
of tieredImageNet. Each class contains 600 images of size
Table 2 summarizes the results on the 5-way
classiﬁcation tasks where our method MetaOptNet-SVM
achieves the state-of-the-art performance. On the harder
FC100 dataset, the gap between various base learners is
more signiﬁcant, which highlights the advantage of complex base learners in the few-shot learning setting.
Table 2. Comparison to prior work on CIFAR-FS and FC100. Average few-shot classiﬁcation accuracies (%) with 95% conﬁdence
intervals on CIFAR-FS and FC100. a-b-c-d denotes a 4-layer convolutional network with a, b, c, and d ﬁlters in each layer. ∗CIFAR-FS
results from . †FC100 result from . ¶Used the union of meta-training set and meta-validation set to meta-train the meta-learner.
“RR” stands for ridge regression.
CIFAR-FS 5-way
FC100 5-way
32-32-32-32
58.9 ± 1.9
71.5 ± 1.0
Prototypical Networks∗† 
64-64-64-64
55.5 ± 0.7
72.0 ± 0.6
35.3 ± 0.6
48.6 ± 0.6
Relation Networks∗ 
64-96-128-256
55.0 ± 1.0
69.3 ± 0.8
96-192-384-512
65.3 ± 0.2
79.4 ± 0.1
TADAM 
40.1 ± 0.4
56.1 ± 0.4
ProtoNets (our backbone) 
72.2 ± 0.7
83.5 ± 0.5
37.5 ± 0.6
52.5 ± 0.6
MetaOptNet-RR (ours)
72.6 ± 0.7
84.3 ± 0.5
40.5 ± 0.6
55.3 ± 0.6
MetaOptNet-SVM (ours)
72.0 ± 0.7
84.2 ± 0.5
41.1 ± 0.6
55.5 ± 0.6
MetaOptNet-SVM-trainval (ours)¶
72.8 ± 0.7
85.0 ± 0.5
47.2 ± 0.6
62.5 ± 0.6
Table 3. Effect of the base learner and embedding network architecture. Average few-shot classiﬁcation accuracy (%) and forward
inference time (ms) per episode on miniImageNet and tieredImageNet with varying base learner and backbone architecture. The former
group of results used the standard 4-layer convolutional network with 64 ﬁlters per layer used in , whereas the latter used a 12-layer
ResNet without the global average pooling. “RR” stands for ridge regression.
miniImageNet 5-way
tieredImageNet 5-way
acc. (%) time (ms) acc. (%) time (ms)
acc. (%) time (ms) acc. (%) time (ms)
4-layer conv (feature dimension=1600)
Prototypical Networks 
53.47±0.63
70.68±0.49
54.28±0.67
71.42±0.61
MetaOptNet-RR (ours)
53.23±0.59
69.51±0.48
54.63±0.67
72.11±0.59
MetaOptNet-SVM (ours)
52.87±0.57
68.76±0.48
54.71±0.67
71.79±0.59
ResNet-12 (feature dimension=16000)
Prototypical Networks 
59.25±0.64
75.60±0.48
61.74±0.77
80.00±0.55
MetaOptNet-RR (ours)
61.41±0.61
77.88±0.46
65.36±0.71
81.34±0.52
MetaOptNet-SVM (ours)
62.64±0.61
78.63±0.46
65.99±0.72
81.56±0.53
4.4. Comparisons between base learners
Table 3 shows the results where we vary the base learner
for two different embedding architectures. When we use
a standard 4-layer convolutional network where the feature
dimension is low (1600), we do not observe a substantial
beneﬁt of adopting discriminative classiﬁers for few-shot
learning. Indeed, nearest class mean classiﬁer is proven
to work well under a low-dimensional feature as shown
in Prototypical Networks .
However, when the embedding dimensional is much higher (16000), SVMs yield
better few-shot accuracy than other base learners. Thus,
regularized linear classiﬁers provide robustness when highdimensional features are available.
The added beneﬁts come at a modest increase in computational cost. For ResNet-12, compared to nearest class
mean classiﬁer, the additional overhead is around 13% for
the ridge regression base learner and around 30-50% for
the SVM base learner. As seen in from Figure 2, the performance of our model on both 1-shot and 5-shot regimes
generally increases with increasing meta-training shot. This
makes the approach more practical as we can meta-train the
embedding once with a high shot for all meta-testing shots.
As noted in the FC100 experiment, SVM base learner
seems to be beneﬁcial when the semantic overlap between
test and train is smaller. We hypothesize that the class embeddings are more signiﬁcantly more compact for training
data than test data (e.g., see ); hence ﬂexibility in the
base learner allows robustness to noisy embeddings and improves generalization.
Iterations
Accuracy (%)
miniImageNet 5-way 1-shot
MetaOptNet­SVM
MetaOptNet­RR
Iterations
Accuracy (%)
miniImageNet 5-way 5-shot
MetaOptNet­SVM
MetaOptNet­RR
Figure 3. Test accuracies (%) on miniImageNet meta-test set
with varying iterations of QP solver. The error bar denotes 95%
conﬁdence interval. Ridge regression base learner (MetaOptNet-
RR) converges in 1 iteration; SVM base learner (MetaOptNet-
SVM) was run for 3 iterations.
4.5. Reducing meta-overﬁtting
Augmenting meta-training set. Despite sampling tasks, at
the end of meta-training MetaOptNet-SVM with ResNet-
12 achieves nearly 100% test accuracy on all the metatraining datasets except the tieredImageNet. To alleviate
overﬁtting, similarly to , we use the union of the
meta-training and meta-validation sets to meta-train the embedding, keeping the hyperparameters, such as the number
of epochs, identical to the previous setting. In particular,
we terminate the meta-training after 21 epochs for mini-
ImageNet, 52 epochs for tieredImageNet, 21 epochs for
CIFAR-FS, and 21 epochs for FC100. Tables 1 and 2 show
the results with the augmented meta-training sets, denoted
as MetaOptNet-SVM-trainval. On minImageNet, CIFAR-
FS, and FC100 datasets, we observe improvements in test
accuracies.
On tieredImageNet dataset, the difference is
negligible. We suspect that this is because our system has
not yet entered the regime of overﬁtting (In fact, we observe ∼94% test accuracy on tieredImageNet meta-training
set). Our results suggest that meta-learning embedding with
more meta-training “classes” helps reduce overﬁtting to the
meta-training set.
Various regularization techniques. Table 4 shows the effect of regularization methods on MetaOptNet-SVM with
ResNet-12. We note that early works on few-shot learning
 did not employ any of these techniques. We observe
that without the use of regularization, the performance of
ResNet-12 reduces to the one of the 4-layer convolutional
network with 64 ﬁlters per layer shown in Table 3. This
shows the importance of regularization for meta-learners.
We expect that performances of few-shot learning systems
would be further improved by introducing novel regularization methods.
4.6. Efﬁciency of dual optimization
To see whether the dual optimization is indeed effective
and efﬁcient, we measure accuracies on meta-test set with
varying iteration of the QP solver. Each iteration of QP
solver involves computing updates for primal and dual
variables via LU decomposition of KKT matrix. The results
1-shot 5-shot
Table 4. Ablation study.
Various regularization techniques
improves test accuracy regularization techniques improves test
accuracy (%) on 5-way miniImageNet benchmark.
MetaOptNet-SVM with ResNet-12 for results. ‘Data Aug.’, ‘Label Smt.’, and ‘Larger Data’ stand for data augmentation, label
smoothing on the meta-learning objective, and merged dataset of
meta-training split and meta-test split, respectively.
are shown in Figure 3. The QP solver reaches the optima of
ridge regression objective in just one iteration. Alternatively
one can use its closed-form solution as used in . Also, we
observe that for 1-shot tasks, the QP SVM solver reaches
optimal accuracies in 1 iteration, although we observed that
the KKT conditions are not exactly satisﬁed yet. For 5-shot
tasks, even if we run QP SVM solver for 1 iteration, we
achieve better accuracies than other base learners. When the
iteration of SVM solver is limited to 1 iteration, 1 episode
takes 69 ± 17 ms for an 1-shot task, and 80 ± 17 ms for a 5shot task, which is on par with the computational cost of the
ridge regression solver (Table 3). These experiments show
that solving dual objectives for SVM and ridge regression
is very effective under few-shot settings.
5. Conclusion
In this paper, we presented a meta-learning approach
with convex base learners for few-shot learning. The dual
formulation and KKT conditions can be exploited to enable computational and memory efﬁcient meta-learning that
is especially well-suited for few-shot learning problems.
Linear classiﬁers offer better generalization than nearestneighbor classiﬁers at a modest increase in computational
costs (as seen in Table 3). Our experiments suggest that
regularized linear models allow signiﬁcantly higher embedding dimensions with reduced overﬁtting. For future work,
we aim to explore other convex base-learners such as kernel
SVMs. This would allow the ability to incrementally increase model capacity as more training data becomes available for a task.
Acknowledgements. The authors thank Yifan Xu, Jimmy
Yan, Weijian Xu, Justin Lazarow, and Vijay Mahadevan for
valuable discussions. Also, we appreciate the anonymous
reviewers for their helpful and constructive comments and
suggestions. Finally, we would like to thank Chuyi Sun for
help with Figure 1.