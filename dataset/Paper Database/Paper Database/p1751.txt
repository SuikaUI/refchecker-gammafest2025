ANI-1: an extensible neural network potential with
DFT accuracy at force ﬁeld computational cost†
J. S. Smith,a O. Isayev*b and A. E. Roitberg*a
Deep learning is revolutionizing many areas of science and technology, especially image, text, and speech
recognition. In this paper, we demonstrate how a deep neural network (NN) trained on quantum
mechanical (QM) DFT calculations can learn an accurate and transferable potential for organic
molecules. We introduce ANAKIN-ME (Accurate NeurAl networK engINe for Molecular Energies) or ANI
for short. ANI is a new method designed with the intent of developing transferable neural network
potentials that utilize a highly-modiﬁed version of the Behler and Parrinello symmetry functions to build
single-atom atomic environment vectors (AEV) as a molecular representation. AEVs provide the ability to
train neural networks to data that spans both conﬁgurational and conformational space, a feat not
previously accomplished on this scale. We utilized ANI to build a potential called ANI-1, which was
trained on a subset of the GDB databases with up to 8 heavy atoms in order to predict total energies for
organic molecules containing four atom types: H, C, N, and O. To obtain an accelerated but physically
relevant sampling of molecular potential surfaces, we also proposed a Normal Mode Sampling (NMS)
method for generating molecular conformations. Through a series of case studies, we show that ANI-1 is
chemically accurate compared to reference DFT calculations on much larger molecular systems (up to
54 atoms) than those included in the training data set.
Introduction
Understanding the energetics of large molecules plays a central
role in the study of chemical and biological systems. However,
because of extreme computational cost, theoretical studies
of these complex systems are oen limited to the use of approximate methods, compromising accuracy in exchange for
a speedup in the calculations. One of the grand challenges in
modern theoretical chemistry is designing and implementing
approximations that expedite ab initio methods without loss of
accuracy. Popular strategies include partition of the system of
interest into fragments,1,2 linear scaling,3 semi-empirical4–6 (SE)
methods or the construction of empirical potentials that have
been parameterized to reproduce experimental or accurate ab
initio data.
In SE methods, some of the computationally expensive
integrals are replaced with empirically determined parameters.
This results in a very large speed up. However, the accuracy is
also substantially degraded compared to high level ab initio
methods due to the imposed approximations.7 Also, the
computational cost of SE methods is still very high compared to
classical force elds (FFs), potentially limiting the system size
that can be studied.
Classical force elds or empirical interatomic potentials
(EPs) simplify the description of interatomic interactions even
further by summing components of the bonded, angular,
dihedral, and non-bonded contributions tted to a simple
analytical form. EPs can be used in large-scale atomistic simulations with signicantly reduced computational cost. More
accurate EPs have been long sought aer to improve statistical
sampling and accuracy of molecular dynamics (MD) and Monte-
Carlo (MC) simulations. However, EPs are generally reliable
only near equilibrium. These, typically nonreactive empirical
potentials, are widely used for drug design, condensed matter
and polymer research.8–11 Thus, such potentials are usually not
applicable for investigations of chemical reactions and transition states. One exception to this is the ReaxFF force eld,12
which is capable of studying chemical reactions and transition
states. However, ReaxFF, like most reactive force elds, must
generally be reparameterized from system to system and
therefore lacks an “out-of-the-box” level of transferability.
Furthermore, each application of FF and EP needs to be carefully pondered, as their accuracy varies among diﬀerent
systems. In fact, performing benchmarks to determine the
optimal FF combination for the problem at hand is usually
unavoidable. Unfortunately, there are no systematic ways for
improving or estimating the transferability of EPs.
aUniversity of Florida, Department of Chemistry, PO Box 117200, Gainesville, FL, USA
32611-7200. E-mail: roitberg@u.edu
bUniversity of North Carolina at Chapel Hill, Division of Chemical Biology and
Medicinal Chemistry, UNC Eshelman School of Pharmacy, Chapel Hill, NC, USA
27599. E-mail: 
† Electronic
supplementary
information
available.
10.1039/c6sc05720a
Cite this: Chem. Sci., 2017, 8, 3192
Received 31st December 2016
Accepted 7th February 2017
DOI: 10.1039/c6sc05720a
rsc.li/chemical-science
3192 | Chem. Sci., 2017, 8, 3192–3203
This journal is © The Royal Society of Chemistry 2017
EDGE ARTICLE
Open Access Article. Published on 08 February 2017. Downloaded on 3/26/2025 6:23:41 PM.
This article is licensed under a Creative Commons Attribution-NonCommercial 3.0 Unported Licence.
View Article Online
View Journal | View Issue
Machine learning (ML) is emerging as a powerful approach
to construct various forms of transferable13–15 and non-transferable16,17 atomistic potentials utilizing regression algorithms.
ML methods have been successfully applied in a variety of
applications in chemistry, including the prediction of reaction
pathways,18 QM excited state energies,19 formation energies,20
atomic forces, nuclear magnetic resonance chemical shis,21
and assisting in the search of novel materials.22 ML potentials
have shown promise in predicting molecular energies with QM
accuracy with a speed up of as much as 5 orders of magnitude.
The key to transferable methods is nding a correct molecular
representation that allows and improves learning in the chosen
ML method. As discussed by Behler,23 there are three criteria
that such representations must adhere to in order to ensure
energy conservation and be useful for ML models: they must be
rotationally and translationally invariant, the exchange of two
identical atoms must yield the same result, and given a set of
atomic positions and types the representation must describe
a molecule's conformation in a unique way. Several such
representations have been developed,24–27 but true transferability and extensibility to complex chemical environments,
i.e. all degrees of freedom for arbitrary organic molecules, with
chemical accuracy has yet to be accomplished.
In 2007, Behler and Parrinello (BP) developed an approximate molecular representation, called symmetry functions
(SFs), that take advantage of chemical locality in order to make
neural network potentials25 (NNPs) transferable. These SFs have
been successfully applied to chemical reaction studies for
a single chemical system or the study of bulk systems such as
water. Bart´ok et al. also suggested an alternative representation
called smooth overlap of atomic positions (SOAP), where the
similarity between two neighborhood environments is directly
dened.28 Very recent work, that introduced a new method
known as deep tensor neural networks (DTNNs),15 provides
further evidence that NNPs can model a general QM molecular
potential when trained to a diverse set of molecular energies. So
far, the DTNN model was only trained to small test data sets to
show the model could predict molecular energies in specic
cases, i.e. equilibrium geometries of organic molecules or the
energy along the path of short QM molecular dynamics trajectories. In our experience, training to trajectories can bias the
tness of a model to the specic trajectory used for training,
especially along short trajectories. Also, DTNN potentials were
not shown to predict energies for larger systems than those
included in the training set.
Since the introduction of BP SFs, they have been employed in
numerous studies where neural network potentials (NNPs) are
trained to molecular total energies sampled from MD data to
produce a function that can predict total energies of molecular
conformations outside of the training set. In general, the NNPs
developed in these studies are non-transferable, aside from bulk
materials25,29 and water cases.30 None of the studies that utilize
the SFs of Behler and Parrinello have presented a NNP that is
truly transferable between complex chemical environments, such
as those found in organic molecules, aside from one limited case
of all trans-alkanes31 where non-equilibrium structures and
potential surface smoothness are not considered. We suggest two
reasons for the lack of transferability of the SFs. Firstly, as originally dened, SFs lack the functional form to create recognizable
features (spatial arrangements of atoms found in common
organic molecules, e.g. a benzene ring, alkenes, functional
groups) in the molecular representation, a problem that can
prevent a neural network from learning interactions in one
molecule and then transferring its knowledge to another molecule upon prediction. Secondly, the SFs have limited atomic
number diﬀerentiation, which empirically hinders training in
complex chemical environments. In general, the combination of
these reasons limits the original SFs to studies of either chemically symmetric systems with one or two atom types or very small
single molecule data sets.
In this work, we present a transferable deep learning32,33
potential that is applicable to complex and diverse molecular systems well beyond the training data set. We introduce
ANAKIN-ME (Accurate NeurAl networK engINe for Molecular
Energies) or ANI for short. ANI is a new method for developing
NNPs that utilizes a modied version of the original SFs to build
single-atom atomic environment vectors (AEVs) as a molecular
representation. AEVs solve the transferability problems that
hindered the original Behler and Parrinello SFs in complex
chemical environments. With AEVs, the next goal of ANI
becomes to sample a statistically diverse set of molecular
interactions, within a domain of interest, during the training of
an ANI class “potential” to produce a transferable NNP. This
requires a very large data set that spans molecular conformational and congurational space, simultaneously. An ANI
potential trained in this way is well suited to predict energies for
molecules within the desired training set domain (organic
molecules in this paper), which is shown to be extensible to
larger molecules than those included in the training set.
ANI uses an inherently parallel computational algorithm. It
is implemented in an in-house soware package, called NeuroChem, which takes advantage of the computational power of
graphics processing units (GPU) to accelerate the training,
testing, and prediction of molecular total energies via an ANI
potential. Finally, we show the accuracy of ANI-1 compared to
its reference DFT level of theory and, for context, three popular
semi-empirical QM methods, AM1, PM6, and DFTB, through
four case studies. All case studies only consider larger organic
molecules than ANI-1 was trained to predict energies for,
providing strong evidence of the transferability of ANI-1.
Theory and neural network
potential design
Neural network potentials
Deep learning33 is a machine learning model that uses
a network of computational neurons, which are organized in
layers. Specically, ANI uses a fully-connected neural network
(NN) model in this work. NNs are highly exible, non-linear
functions with optimizable parameters, called weights, which
are updated through the computation of analytic derivatives of
a cost function with respect to each weight. The data set used to
optimize the weights of a NN is called a training set and consists
This journal is © The Royal Society of Chemistry 2017
Chem. Sci., 2017, 8, 3192–3203 | 3193
Edge Article
Chemical Science
Open Access Article. Published on 08 February 2017. Downloaded on 3/26/2025 6:23:41 PM.
This article is licensed under a Creative Commons Attribution-NonCommercial 3.0 Unported Licence.
View Article Online
of inputs and a label, or reference value, for each input. Multilayered NNs are known as universal function approximators34
because of their ability to t to arbitrary functions. A neural
network potential35,36 (NNP) utilizes the regression capabilities
of NNs to predict molecular potential surfaces, given only
information about the structure and composition of a molecule.
Standard NNPs suﬀer from many problems that need to be
solved before any generalized model can be built. Firstly,
training neural networks to molecules with many degrees of
freedom (DOF) is diﬃcult because the data requirements grow
with each DOF to obtain a good statistical sampling of the
potential energy surface. Also, the typical inputs, such as
internal coordinates or coulomb matrices, lack transferability to
diﬀerent molecules since the input size to a neural network
must remain constant. Finally, the exchange of two identical
atoms in a molecule must lead to the same result.
The ANAKIN-ME model
Heavily modied Behler and Parrinello symmetry functions25
(BPSFs) and their high-dimensional neural network potential
model, depicted in Fig. 1, form a base for our ANAKIN-ME (ANI)
model. The original BPSFs are used to compute an atomic
environment vector (AEV), ~Gi
X ¼ {G1, G2, G3,.,GM}, composed
of elements, GM, which probe specic regions of an individual
atom's radial and angular chemical environment. Each ~Gi
the ith atom of a molecule with atomic number X is then used as
input into a single NNP. The total energy of a molecule, ET, is
computed from the outputs, Ei, of the atomic number specic
NNPs using:
In this way, ET has the form of a sum over all i “atomic
contributions” to the total energy. Aside from transferability, an
added advantage of this simple summation is that it allows for
a near linear scaling in computational complexity with added
cores or GPUs, up to the number of atoms in the system of
X vectors are key to allowing this functional form of the
total energy to be utilized. For an atom i, ~Gi
X is designed to give
a numerical representation, accounting for both radial and
angular features, of i's local chemical environment. The local
atomic environment approximation is achieved with a piecewise cutoﬀfunction:
for Rij # RC
for Rij . RC
here, Rij is the distance between atoms i and j, while Rc is
a cutoﬀradius. As written, fC(Rij) is a continuous function with
continuous rst derivatives.
To probe the local radial environment for an atom i, the
following radial symmetry function, introduced by Behler and
Parrinello, produces radial elements, GR
ehðRijRsÞ
The index m is over a set of h and Rs parameters. The
parameter h is used to change the width of the Gaussian
distribution while the purpose of Rs is to shithe center of the
peak. In an ANI potential, only a single h is used to produce thin
Gaussian peaks and multiple Rs are used to probe outward from
the atomic center. The reasoning behind this specic use of
parameters is two-fold: rstly, when probing with many small
h parameters, vector elements can grow to very large values,
which are detrimental to the training of NNPs. Secondly, using
Rs in this manner allows the probing of very specic regions of
the radial environment, which helps with transferability. GR
a set of M ¼ {m1, m2, m3,.} ¼ {(h1, Rs1), (h2, Rs2), (h3, Rs3),.}
parameters, is plotted in Fig. 2A. M consist of a constant h for all
m and multiple Rs parameters to show a visualization of how
each vector element probes its own distinct region of an atom's
radial environment.
We made two modications to the original version of Behler
and Parrinello's angular symmetry function to produce one
better suited to probing the local angular environment of
complex chemical systems. The rst addition is qs, which allows
an arbitrary number of shis in the angular environment, and
the second is a modied exponential factor that allows an Rs
parameter to be added. The Rs addition allows the angular
environment to be considered within radial shells based on the
average of the distance from the neighboring atoms. The eﬀect
of these two changes is that AEV elements are generally smaller
because they overlap atoms in diﬀerent angular regions less and
they provide a distinctive image of various molecular features,
a property that assists neural networks in learning the energetics of specic bonding patterns, ring patterns, functional
groups, or other molecular features.
Given atoms i, j, and k, an angle qijk, centered on atom i, is
computed along with two distances Rij and Rik. A single element,
X, to probe the angular environment of atom i, takes
the form of a sum over all j and k neighboring atom pairs, of the
product of a radial and an angular factor,
Rij þ Rik
The Gaussian factor combined with the cutoﬀfunctions, like
the radial symmetry functions, allows chemical locality to be
exploited in the angular symmetry functions. In this case, the
index m is over four separate parameters: z, qs, h, and Rs. h and
Rs serve a similar purpose as in eqn (3). Applying a qs parameter
allows probing of specic regions of the angular environment in
a similar way as is accomplished with Rs in the radial part. Also,
z changes the width of the peaks in the angular environment.
for several m are plotted in Fig. 2B while the original
3194 | Chem. Sci., 2017, 8, 3192–3203
This journal is © The Royal Society of Chemistry 2017
Chemical Science
Edge Article
Open Access Article. Published on 08 February 2017. Downloaded on 3/26/2025 6:23:41 PM.
This article is licensed under a Creative Commons Attribution-NonCommercial 3.0 Unported Licence.
View Article Online
Behler and Parrinello's HDNN or HD-atomic NNP model. (A) A scheme showing the algorithmic structure of an atomic number speciﬁc
neural network potential (NNP). The input molecular coordinates, ~q, are used to generate the atomic environment vector, ~Gi
X, for atom i with
atomic number X. ~Gi
X is then fed into a neural network potential (NNP) trained speciﬁcally to predict atomic contributions, Ei
X, to the total energy,
ET. Each lk represents a hidden layer of the neural network and is composed of nodes denoted aj
k where j indexes the node. (B) The highdimensional atomic NNP (HD-atomic NNP) model for a water molecule. ~Gi
X is computed for each atom in the molecule then input into their
respective NNP (X) to produce each atom's Ei
X, which are summed to give ET.
Examples of the symmetry functions with diﬀerent parameter sets. (A) Radial symmetry functions, (B) modiﬁed angular symmetry
functions and (C) the original Behler and Parrinello angular symmetry functions. These ﬁgures all depict the use of multiple shifting parameters for
each function, while keeping the other parameters constant.
This journal is © The Royal Society of Chemistry 2017
Chem. Sci., 2017, 8, 3192–3203 | 3195
Edge Article
Chemical Science
Open Access Article. Published on 08 February 2017. Downloaded on 3/26/2025 6:23:41 PM.
This article is licensed under a Creative Commons Attribution-NonCommercial 3.0 Unported Licence.
View Article Online
angular function is plotted in Fig. 2C. With the original Behler
and Parrinello angular function, only two shiing values were
possible in the angular environment, 0 and p. The modied
angular function allows an arbitrary number to be chosen,
allowing for better resolution of the angular environment. As
with its radial analog, this helps to keep the elements of ~Gi
small for better NNP performance and allows probing of
specic regions of the angular chemical environment.
Log–log plots of the training, validation, testing, and a random
GDB-10 (molecules with 10 heavy atoms from the GDB-11 database)
extensibility testing set of total energy errors vs. increasing number of
data points in the training set. The sets of points converge to the ﬁnal
ANI-1 potential presented in this paper, trained on the full ANI-1 data
Relative energy comparisons from random conformations of a random sampling of 134 molecules from GDB-11 all with 10 heavy atoms.
There is an average of 62 conformations, and therefore energies, per molecule. Each set of energies for each molecule is shifted such that the
lowest energy is at 0. None of the molecules from this set are included in any of the ANI training sets. (A–D) Correlation plots between DFT
energies, Eref, and computed energies, Ecmp, for ANI-1 and popular semi-empirical QM methods. Each individual molecule's set of energies is
shifted such that the lowest energy is at zero. (E) RMS error (kcal mol1) of various ANI potentials, compared to DFT, trained to an increasing data
set size. The x-axis represents the maximum size of GDB molecules included in the training set. For example, 4 represents an ANI potential
trained to a data set built from the subset of GDB-11 containing all molecules up to 4 heavy atoms.
The total energies, shifted such that the lowest is zero, calculated for various C10H20 isomers, are compared between DFT with the
uB97X functional and 6-31G(d) basis set, the ANI-1 potential, AM1
semi-empirical, and PM6 semi-empirical methods.
3196 | Chem. Sci., 2017, 8, 3192–3203
This journal is © The Royal Society of Chemistry 2017
Chemical Science
Edge Article
Open Access Article. Published on 08 February 2017. Downloaded on 3/26/2025 6:23:41 PM.
This article is licensed under a Creative Commons Attribution-NonCommercial 3.0 Unported Licence.
View Article Online
Atomic number diﬀerentiated atomic environment
vector. In this work, we diﬀerentiate between atomic numbers
in the AEV by supplying a radial part for each atomic number
and an angular part for each atomic number pair in the local
chemical environment. The original BPSFs treat all atoms
identically in the summation over all atoms, and thus individual atomic number specic NNPs are unable to distinguish between a carbon, hydrogen, or any other atom type at
some distance. Through empirical evidence, provided in
Table S4 of the ESI,† we have found that discriminating
between atomic numbers allows for training to much lower
error on diverse multi-molecule training sets and permits
better transferability.
For AEVs built from N atom types, this leads to N radial sub-
AEVs and N(N + 1)/2 angular sub-AEVs. ESI Fig. S1† gives an
example of an atomic number diﬀerentiated AEV for the carbon
atom in formic acid with only 8 radial symmetry functions and
8 angular symmetry functions. The gure shows an overlay of
two AEVs each representing a diﬀerent C–O–H angle with the
rest of the structure frozen. From this gure, it is easy to identify
the diﬀerent features which represent formic acid and it also
provides clear information on the conformation of the molecule. It is this clearly dened “ngerprint” that allows the
modied symmetry functions to perform well in such diverse
chemical environments.
Normal mode sampling
The ANI method requires many training and testing data
points, (~q, ET), where ~q is some energy minimized or nonminimized molecular coordinates, a conformation, from
a diverse set of molecules and ET is the single point energy
calculated at a desired QM level of theory. To obtain an
accelerated but physically relevant sampling of molecular
potential surfaces, we propose the Normal Mode Sampling
(NMS) method to generate structures for which single point
energies can be computed. A method akin to our version of
normal mode sampling has successfully been employed in
generating non-equilibrium structures in order to obtain
a data set of atomic forces for training a ML model.37 The end
goal of NMS is to generate a set of data points on the
potential surface, or a window, around a minima energy
structure of a molecule out to some maximum energy. Using
the proposed NMS gives some condence that interactions to
a specic temperature are accounted for in a trained ANI
potential.
To carry out normal mode sampling on an energy minimized
molecule of Na atoms, rst a set of Nf normal mode coordinates,
Q ¼ {q1, q2, q3,.qNf}, is computed at the desired ab initio
level of theory, where Nf ¼ 3Na  5 for linear molecules and
Nf ¼ 3Na  6 for all others. The corresponding force constants,
(A–C) These three triangle plots, which are on the same scale shown to the right, show energy diﬀerences, DE, between random energy
minimized conformers of the molecule retinol. The structural diﬀerences between these conformers include many dihedral rotations. (A) shows
the conformers DE calculated with DFT, (B) ANI-1, and (C) DFTB. (D) shows the absolute value of the diﬀerence between (A) and (B), |DDE|, while
(E) shows the same between (A) and (C). DE and |DDE| have their own scale shown to the right of the plots. All plots of a speciﬁc type use the same
color scaling for easy comparison.
This journal is © The Royal Society of Chemistry 2017
Chem. Sci., 2017, 8, 3192–3203 | 3197
Edge Article
Chemical Science
Open Access Article. Published on 08 February 2017. Downloaded on 3/26/2025 6:23:41 PM.
This article is licensed under a Creative Commons Attribution-NonCommercial 3.0 Unported Licence.
View Article Online
K ¼ {K1, K2, K3,.,KNf}, are obtained alongside Q. Then a set of Nf
uniformly distributed pseudo-random numbers, ci, are generated such that
ci is in the range . Next, a displacement,
Ri, for each normal mode coordinate is computed by setting
a harmonic potential equal to the ci scaled average energy of the
system of particles at some temperature, T. Solving for the
displacement gives:
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
where kb is Boltzmann's constant. The sign of Ri is determined
randomly from a Bernoulli distribution where p ¼ 0.5 to ensure
that both sides of the harmonic potential are sampled equally.
The displacement is then used to scale each normalized normal
mode coordinate by qR
i ¼ Riqi. Next, a new conformation of the
molecule is generated by displacing the energy minimized
coordinates by QR, the superposition of all qR
i . Finally, a single
point energy at the desired level of theory is calculated using the
newly displaced coordinates as input.
The choice of temperature is dependent on the intended use
of the ANI potential being trained. However, it should be noted
that this method of sampling the potential surface of a molecule
is simply an approximation for generating structures. In practice, NMS works best when generating windows of the potential
surface of many molecules to be used in the training of the
same ANI potential. The reasoning behind this is as follows: if
any interactions are missed or not sampled well by NMS, it is
possible that other molecules in the data set contain the same
or similar interactions. Therefore, the accuracy of using such
a sampling method is dependent on not only the number of
points per window but also the number of distinct molecules
included in the data set.
Each subplot shows a one-dimensional potential surface scan generated from DFT, the ANI-1 potential, and two popular semi-empirical
methods, DFTB and PM6. The atoms used to produce the scan coordinate are labeled in the images of the molecules in every sub-plot. Each
ﬁgure also lists the RMSE, in the legend, for each method compared to the DFT potential surface.
3198 | Chem. Sci., 2017, 8, 3192–3203
This journal is © The Royal Society of Chemistry 2017
Chemical Science
Edge Article
Open Access Article. Published on 08 February 2017. Downloaded on 3/26/2025 6:23:41 PM.
This article is licensed under a Creative Commons Attribution-NonCommercial 3.0 Unported Licence.
View Article Online
Data selection
The accuracy of any empirical potential, especially an ANI
potential, is highly dependent on the amount, quality of, and
types of interactions included in the data used to train the
model. For instance, a data set generated from high level
CCSD(T) ab initio theory, for every possible combination of all
atom types and a full sampling of congurations in threedimensional space would be ideal for training an ANI potential.
However, this is not possible due to time and other practicality
considerations. Therefore, we limit the scope of this study to
a specic class of systems, namely organic molecules with four
atom types: H, C, N, and O. We also restrict our data set to near
equilibrium conformations, since a full sampling of each
structure's potential surface increases the number of data
points required for training to a near intractable level. Data sets
have been developed38 with a similar search of chemical space,
however, these data sets only cover congurational space and
not conformational space, which is a requirement for training
an ANI class potential. In this work, we choose uB97X,39 the
hybrid meta-GGA DFT functional, with the 6-31G(d) basis set as
reference QM data. The uB97X functional provides excellent
accuracy for molecular structures, stability, bond energies and
reaction barriers. Everything described in this article can be
repeated at any other level of QM theory if wanted.
The GDB-11 database
A good starting point to build a training data set for organic
molecules is the GDB-11 database.40,41 The GDB-11 database is
built from all possible molecules containing up to 11 atoms of
the atomic numbers C, N, O, and F and is ltered by chemical
stability and synthetic feasibility considerations, as well as
simple valency rules. Molecules in GDB-11 are supplied in the
form of SMILES strings,42 which we converted to 3D structures
using the RDKit soware package.43
The ANI-1 data set employed in this work, was generated
from a subset of the GDB-11 database containing molecules
without the uorine atom. This leaves only molecules with H, C,
N, and O aer hydrogens are added with RDKit. Also, given the
sheer number of molecules (40.3 million) in the GDB-11 database, as of the time of this article, only reference data for
molecules up to 8 atoms of C, N, and O have been computed. In
total, 57 951 molecules are included in our current data set, the
ANI-1 data set. A breakdown of how many molecules are
included from each GDB-11 subset is given in ESI Table S1.† All
energies are computed with neutral molecules in the singlet
spin state.
ANI-1 data set generation
From a proper database of molecules within a chemical domain
of interest, a data set must be generated that includes sampling
of each molecule's potential surface around its equilibrium
structure. We do this in the spirit of work carried out by many
others16,35,36,44 who tted neural networks to single molecule
potential surfaces. Given simple physical considerations, the
sampling of the potential surface can be limited to a window of
relevant energies. Sampling can be carried out using quantum
mechanical (QM) molecular dynamics (MD) simulation as
suggested by others.45 However, QM MD is ineﬃcient for
producing a small data set from sampling of a large window of
a potential surface, which is desirable for the ANI method. The
reason for this is that congurationally diverse data sets overlap
interactions throughout the data set, so larger molecules
require far less data points (200) than smaller ones. Because of
this, utilizing MD would follow a well-dened trajectory along
the potential surface and would lead to sampling biased to the
specic trajectory. Thus, a very long trajectory is required to
overcome this bias. It is for this reason that sampling of a more
stochastic nature is required for the ANI method.
In this work, we propose a Normal Mode Sampling (NMS)
method that works by calculating the normal modes of a molecule, then randomly perturbing the equilibrium structure along
these normal modes out to a maximum energy (see Section 2.3
for details on NMS). The ANI-1 data set was generated by
applying NMS to every molecule with 8 or less heavy atoms in
the GDB-11 database. Using the wB97X39 DFT functional with
the 6-31G(d) basis set in the Gaussian 09 electronic structure
package,46 the following steps are followed to generate the data
(1) Convert SMILES strings to 3D structures and add hydrogens to ll valence orbitals.
(2) Optimize each molecule in the database using tight
convergence criteria.
(3) Generate normal modes for each optimized molecule
with an ultra-ne DFT grid.
(4) Use the NMS method to generate K structures for each
molecule in the database. The exact number of structures per
molecule is determined using K ¼ S(3N  6). S is an empirically
determined value dependent on the number of heavy atoms in
the molecule and N is the total number of atoms in the molecule, including hydrogens.
(5) Calculate single point energies for each of the generated
structures.
Using this procedure to generate the ANI-1 data set results in
molecular energies for a total of 17.2 million conformations
generated from 58k small molecules. For each molecule's
individual set of random conformations, 80% is used for
training, while 10% is used for each validation and testing of
the ANI-1 model.
For practical considerations, the value S from step 3 is large
(about 500) for very small molecules and is gradually reduced as
the number of heavy atoms, and molecule diversity, grows.
Table S1 in the ESI† shows the parameters used in the
production of the ANI-1 data set, including the S values used for
each GDB-11 database subset as well as the per atom test set
RMSE of an ANI potential vs. DFT for each subset.
Training the ANI-1 potential
All ANI potential training, validating, and predicting is done with
an in-house C/C++ and CUDA GPU accelerated soware package
that we call NeuroChem (C++ interface) and pyNeuroChem
This journal is © The Royal Society of Chemistry 2017
Chem. Sci., 2017, 8, 3192–3203 | 3199
Edge Article
Chemical Science
Open Access Article. Published on 08 February 2017. Downloaded on 3/26/2025 6:23:41 PM.
This article is licensed under a Creative Commons Attribution-NonCommercial 3.0 Unported Licence.
View Article Online
(Python interface). Where applicable, the neural network algorithm is encoded as either matrix–matrix, matrix–vector, or
vector–vector operations using CUBLAS.47 The atomic environment vectors are computed through a separate in-house built
library called AEVLib, which is also GPU accelerated.
Finding a good set of atomic environment vector (~G)
parameters to compute molecular representations plays a major
role in how well the ANI-1 potential trains and performs. Too
many ~G parameters will lead to networks that are very large, and
thus hard to train. Too few parameters result in low resolution
of the local chemical environment, which is detrimental to
transferability and training in general. For the ANI-1 potential,
32 evenly spaced radial shiing parameters are used for the
radial part of ~G and a total of 8 radial and 8 angular shiing
parameters are used for the angular part. The specic AEV
parameters were chosen with a few goals in mind: to minimize
the size of the AEV, to maximize the resolution of the local
atomic environments, and to cover all space within the cutoﬀ
radius provided. Keeping these goals in mind the choice of
parameters can be automated to simply chose multiple Rs and
qs parameters equally spaced and setting the h and z parameters
such that one function overlaps with its neighboring function
slightly, as shown in Fig. 2A and B. With four atom types, this
leads to a total of 768 elements in ~G. The cutoﬀradii of 4.6 ˚A for
the radial and 3.1 ˚A for the angular symmetry functions were
chosen based on the distribution of atomic distances and an
assumption that angular environments are less sampled in the
ANI-1 data set, empirical testing veried this to be the case.
The choice of network architecture also plays a major role in
how well a potential performs. Too small of a network reduces
the exibility of the function which can hinder performance
and too large can lead to bad generalization across structures
due to overtraining, especially on small data sets. With larger
data sets, a bigger and more exible network can be used to
yield better results. We empirically tested many network architectures. Generally, 3 to 4 hidden layer networks with between
32 and 128 nodes per layer performed the best. The best ANI
potential (ANI-1), employed in this work, was trained to 80% of
the 17 + M data points, and has the following pyramidal
architecture: 768 : 128 : 128 : 64 : 1. That is, 768 input values
followed by a 128-node hidden layer followed by another hidden
layer with 128 nodes, a 64-node hidden layer, and nally a single
output node for a total of 124 033 optimizable parameters per
each individual atomic number neural network potential. All
hidden layer nodes use a Gaussian activation function48 while
the output node uses a linear activation function. The weights
are randomly initialized from a normal distribution in the range
(1/d, 1/d), where d is the number of inputs into the node. The
neural network bias parameters are all initialized to zero.
To train the weights, the program randomly samples structures from the training set in a mini-batch of 1024 molecules.
Next a cost derivative w.r.t. each weight is calculated through
back-propagation from the exponential cost function:49
~EANI is a vector of the energy outputs, EANI
, from the ANI
network for the jth set of coordinates. EDFT
is the corresponding
DFT reference energy. The parameter s is set to 0.5 for best
performance. This cost function was chosen because of its
robustness in handling outliers in data sets, a property that
achieves 2 to 4 times lower error upon training an ANI potential.
The network weights are optimized via the ADAM update
method.50 An initial learning rate of 0.001 is used with the other
ADAM parameters set to b1 ¼ 0.9, b2 ¼ 0.999, and 3 ¼ 1.0  108,
as recommended by the ADAM authors. To avoid node saturation the incoming weight vector to each node in the network
is constrained by the max norm regularization method51 to
a maximum length of 3.0. The mini-batch update is repeated
over the full training set until a training epoch is completed.
Training epochs are iterated until the validation set stops
improving in accuracy for 100 epochs. The optimization process
is carried out 6 times using an order of magnitude smaller
learning rate each time. The nal tness of the training, validation, and test sets in the case of the ANI-1 potential are 1.2,
1.3, and 1.3 root mean squared error (RMSE) in kcal mol1,
respectively.
Results and discussion
The nal ANI potential for the domain of organic molecules
containing the atoms H, C, N, and O, is trained on a data set
containing over 80% of the 17.2 million data points in the ANI-1
data set. This data set, produced by applying normal mode
sampling (NMS, developed in the present work) to more than
56k distinct small molecules from the GDB-8 database, spans
the congurational as well as conformational space of organic
molecules. Such vast data is required to ensure the sampling of
relevant interactions needed to produce a very high dimensional potential surface. Fig. 3 stands as evidence to the
necessity of this vast amount of training data. More important
than the low errors to the training, validation, and test sets, it
shows that the extensibility of ANI potentials increase with data
set size, and does not plateau up to the current data set size.
We performed extensive benchmark and case studies to
estimate the accuracy of the ANI-1 potential compared to DFT
reference calculations. As baselines, in the rst test case we
compare ANI-1 to a sorted coulomb matrix13 (CM) molecular
representation with a multilayer perceptron (MLP) neural
network model, baseline 1, and to an ANI type neural network
model trained where the AEVs are not type diﬀerentiated,
baseline 2. MLP's were chosen in baseline 1 because of their
ability to train to very large data sets via batched learning. Table
S4 in the ESI† provides details of these baselines for comparison
to the ANI method.
To highlight the true transferability of the ANI-1 potential, all
molecules considered in the following test cases contain greater
than eight heavy atoms. The atom counts for these test systems
range from 10 to 24 heavy atoms up to a total of 53 atoms.
Firstly, we analyzed ANI-1's overall performance, goodness of t,
and transferability to non-minimized structures with a total of
8245 conformations generated using NMS on 134 randomly
selected molecules from GDB-11, each with 10 heavy atoms. In
3200 | Chem. Sci., 2017, 8, 3192–3203
This journal is © The Royal Society of Chemistry 2017
Chemical Science
Edge Article
Open Access Article. Published on 08 February 2017. Downloaded on 3/26/2025 6:23:41 PM.
This article is licensed under a Creative Commons Attribution-NonCommercial 3.0 Unported Licence.
View Article Online
the second case study, we look at the accuracy of ANI-1 in predicting the relative energies of DFT energy minimized C10H20
isomers with respect to the lowest energy isomer. Thirdly,
energy diﬀerences are compared for energy minimized conformers of the drug molecule retinol. And nally, four rigid
scans, a bond stretch, an angle bend, and two dihedral rotations
on relatively large drug molecules are carried out on ANI-1 and
compared with reference DFT results. For comparison, we also
show the performance of popular DFTB, PM6, and AM1 semiempirical methods in all the test cases presented.
Statistical tness
To show the overall accuracy and transferability of the ANI-1
potential, Fig. 4 plots the energy correlation of relative energies
for a subset of molecules from the GDB-11 database. Specically, the sampling includes 8245 total NMS generated conformations and their respective energies from 134 randomly
selected molecules with 10 heavy atoms. This gives a set of 62
conformations, on average, per molecule. Each molecule's test
set is shied such that the lowest energy is zero in order to
compare relative energies. An absolute energy comparison of
this test set, between ANI-1 and DFT, is provided in ESI Table
Fig. 4A is a correlation plot of the computed ANI-1 energies,
Ecmp, vs. the DFT reference energies, Eref. The ANI-1 potential
achieves an RMSE of only 1.8 kcal mol1 over the entire random
sampling. Fig. 4B–D provides the same comparison but for
popular semi-empirical methods to the DFT reference energies.
If only relative energies within 30.0 kcal mol1 of the minimum
energy are considered, the ANI-1, DFTB, PM6, and AM1
methods obtain an RMSE of 0.6, 2.4, 3.6, and 4.2 kcal mol1,
respectively. ESI Table S3† lists the total energy and relative
energy error of the ANI-1 potential as an energy cap, Ecap, is
lowered until nally only minimum energy structures are
considered.
Fig. 4E shows how the RMSE of an ANI potential to reference
DFT decreases as the number of distinct molecules grows in the
training set. From this plot, it is clear that the addition of more
data leads to better ts, with the largest and most diverse data
set achieving an RMSE of just 1.8 kcal mol1. Inclusion of
molecules with 7 heavy atoms, mostly mono-substituted
aromatic compounds, yields a dramatic reduction of the RMSE.
This gure, along with Fig. 3, stands as evidence that increasing
the size and diversity of an ANI training set leads to better
tness and transferability, meaning future parameterization
will yield even better results.
The total energies produced by ANI-1, baseline 1, and baseline 2 for the GDB-10 test set are also compared. ANI-1, when
trained on the full ANI-1 training set, achieves a total energy
RMSE of 1.9 kcal mol1 while baseline 1 and baseline 2 achieve
a RMSE of 493.7 kcal mol1 and 6.6 kcal mol1, respectively.
While the baselines perform better on the ANI-1 test set, as seen
in ESI Fig. S4,† their performance on the GDB-10 test set shows
that both suﬀer from an inability to extend their learned
interactions to larger molecules. For baseline 1, this is caused
a constant zero throughout training, yet when a larger molecule
is tested on it, those elements have non-zero values. These
non-zero values are then fed into untrained network parameters, which yields arbitrary results. For baseline 2, the problem
comes from the fact that the AEVs have an inability to diﬀerentiate between atom types, creating confusion during the
learning process.
Structural and geometric isomers
This case study looks at relative stabilities of structural and
geometric isomers with the empirical formula C10H20. All
isomers were optimized at the chosen DFT level of theory.
Structures of all isomers included in this case study are shown
in ESI Fig. S2.† Fig. 5 gives a visual comparison of the ANI-1
potential and diﬀerent semi-empirical methods to DFT calculated energies of the isomers. The energies are ordered from the
lowest to the highest for clarity. The x-axis shows the isomer
index number, which matches to the molecule index in ESI
Fig. 5 shows that the ANI-1 potential properly predicts the
minimum energy structure and continues to match the energies
of the ring containing structures, indices 1–4 on the x-axis, with
a very low error and with proper ordering. Also, when moving
from the ringed structures to the linear alkenes, index 4 to 5, the
approximates
between these two classes of molecules very well. The linear
alkanes, indices 5–13, t very well to the DFT energies. Overall
the ANI-1 potential achieves an RMSE of 0.2 kcal mol1. In
contrast, both DFTB and PM6 methods incorrectly predict
the relative stability of ring containing structures. Energies
of isomers 5–13 are systematically underestimated by about
6–7 kcal mol1.
Conformers of retinol
Eight conformers of the molecule retinol were generated using
the RDKit package and then optimized to their respective DFT
energy minima. In this case study, Fig. 6, the energy diﬀerence,
DE, and |DDE| are plotted to show how well the ANI-1 potential
performs at predicting energy diﬀerences when large conformational changes, i.e. many dihedral rotations over the entire
molecule occur. The |DDE| plots represent the absolute value of
the diﬀerences between the elements of the DFT plot and the
elements of the other method's DE plots. All DE plots are on the
same scale, shown to the right of the gures, and the same is
true for the |DDE| plots.
Fig. 6A shows DE between each retinol conformer for DFT
while B shows the same for ANI-1 and C for DFTB. Aside from
some minor shading diﬀerences, the comparison of A and B
clearly shows how well the ANI-1 energy diﬀerences match that
of the DFT calculations. Fig. 6D and E contain |DDE| plots
corresponding to A vs. B and A vs. C, respectively, and shows
that the ANI-1 potential can predict DFT energy diﬀerences of
these large structural changes to a very low error. In total, ANI-1
and DFTB achieve a RMSE to the DFT DE of 0.6 kcal mol1 and
1.2 kcal mol1, respectively. However, DFTB severely over estimates energies of conformers 2 and 7.
This journal is © The Royal Society of Chemistry 2017
Chem. Sci., 2017, 8, 3192–3203 | 3201
Edge Article
Chemical Science
Open Access Article. Published on 08 February 2017. Downloaded on 3/26/2025 6:23:41 PM.
This article is licensed under a Creative Commons Attribution-NonCommercial 3.0 Unported Licence.
View Article Online
Potential surface accuracy
So far, all test cases have only considered large structural
changes or unordered NMS generated structures. However, to
be useful in molecular dynamics simulations, the ANI-1
potential must not only have a low error, but must also produce
a very smooth physically meaningful surface. To provide
evidence that ANI-1 satises these requirements, unrelaxed
scans were conducted on diﬀerent drug molecules and are
plotted in Fig. 7.
Fig. 7A shows a bond stretch, from 1.2 ˚A to 1.8 ˚A, of the N–C
bond (labeled 1 and 2) in the analgesic drug molecule fentanyl.52 The bond equilibrium distance was calculated separately for each method and was found to be 1.3 ˚A for DFT, 1.4 ˚A
for ANI-1, 1.4 ˚A for DFTB, and 1.4 ˚A for PM6. Fig. 7B presents an
angle bend, from 90.0 to 135.0, for the C–C–C angle labeled
1–2–3 in the structure of fentanyl included within the plot. As
with the bond stretch, the ANI-1 potential produces an angle
bend potential surface with a very low RMSE of only 0.4 kcal
mol1 while maintaining a very smooth curvature for accurate
force calculations. ANI-1 produces an angle bend potential with
an equilibrium angle 1.0 from the DFT equilibrium. PM6 and
DFTB produce equilibrium structures at 1.1 and 0.8,
respectively, from the DFT calculation.
Finally, Fig. 7C and D depict rotations of the dihedral angles
labeled in the two gures. Fig. 7C shows a C–C–C–C dihedral
rotation potential in the molecule 4-cyclohexyl-1-butanol, while
Fig. 7D is for an N–C–C–C dihedral angle in the drug molecule
called lisdexamfetamine.53 The ANI-1 potential manages to
capture all minima to within 3.0 of the DFT potentials for both
plots, which is better or comparable to the semi-empirical
methods. As expected both semi-empirical methods severely
underestimate dihedral rotation barriers, and in the case of
lisdexamfetamine give an unrealistic shape of potential surface.
Again, both gures not only t well to the potential surface but
model it very well by reproducing the shape and smoothness of
the surface. This fact shows that the ANI-1 potential does produce
a smooth potential, one that could provide forces, for use in
molecular dynamics simulations or optimization problems.
Conclusions
In this work we present the rst truly transferable neural
network potential (NNP) for organic molecules based on a deep
learning architecture and with heavy modications to the
HDNN method of Behler and Parrinello.25 Our NNP, presented
as the ANI-1 potential, was trained on a data set, which spans
conformational and congurational space, built from small
organic molecules of up to 8 heavy atoms. We show its applicability to much larger systems of 10–24 heavy atoms including well known drug molecules and a random selection of
134 molecules from the GDB-11 database containing 10 heavy
atoms. ANI-1 shows exceptional predictive power on the
10-heavy atom test set, with RMSE versus DFT relative energies
as low as 0.6 kcal mol1 when only considering molecular
conformations that are within 30.0 kcal mol1 of the energy
minimum for each molecule. While the ANI-1 potential
specically targets organic molecules with the atoms H, C, N,
and O, the ANI method can be used to build potentials for other
classes of molecules and even crystals. ANI-1 was specically
trained to DFT energies, but could be extended to high level ab
initio QM methods and larger basis sets given enough computational resources.
As the results clearly show, the ANI method is a potential
game-changer for molecular simulation. Even the current
version, ANI-1, is more accurate vs. the reference DFT level of
theory in the provided test cases than DFTB, and PM6, two of
the most widely used semi-empirical QM methods. Besides
being accurate, a single point energy, and eventually forces, can
be calculated as many as six orders of magnitude faster than
through DFT. Empirical evidence shows the computational
scaling per atom of the method is roughly equivalent to a classical force eld for very large molecules.
The accuracy of the ANI method is heavily dependent on the
data used during training. Thus, continuing to augment the ANI-1
data set with new molecules and including more atomic numbers
will improve the accuracy of the trained ANI potential further as
well as extend the method to new chemical environments.
Acknowledgements
J. S. S. acknowledges the University of Florida for funding
through the Graduate School Fellowship (GSF). A. E. R. thanks
NIH award GM110077. O. I. acknowledges support from
DOD-ONR (N00014-16-1-2311) and the Eshelman Institute for
Innovation award. Part of this research was performed while
O. I. was visiting the Institute for Pure and Applied Mathematics (IPAM), which is supported by the National Science
Foundation (NSF). The authors acknowledge the Extreme
Science and Engineering Discovery Environment (XSEDE)
award DMR110088, which is supported by National Science
Foundation
ACI-1053575.
gratefully
acknowledge the support of the U.S. Department of Energy
through the LANL/LDRD Program for this work. We gratefully
acknowledge the support and hardware donation of NVIDIA
Corporation and personally Mark Berger.
Notes and references
1 K. Kitaura, E. Ikeo, T. Asada, T. Nakano and M. Uebayasi,
Chem. Phys. Lett., 1999, 313, 701–706.
2 D. G. Fedorov, T. Nagata and K. Kitaura, Phys. Chem. Chem.
Phys., 2012, 14, 7562.
3 C. Ochsenfeld, J. Kussmann and D. S. Lambrecht, in Reviews
in Computational Chemistry, John Wiley & Sons, Inc., 2007,
4 M. Elstner, Theor. Chem. Acc., 2006, 116, 316–325.
5 J. J. P. Stewart, J. Mol. Model., 2009, 15, 765–805.
6 M. J. S. Dewar, J. Am. Chem. Soc., 1985, 107, 3902.
7 W. Thiel, Perspectives on Semiempirical Molecular Orbital
Theory, John Wiley & Sons, Inc., 2007.
8 T. A. Halgren, J. Comput. Chem., 1996, 17, 490–519.
9 H. Sun, J. Phys. Chem. B, 1998, 102, 7338–7364.
3202 | Chem. Sci., 2017, 8, 3192–3203
This journal is © The Royal Society of Chemistry 2017
Chemical Science
Edge Article
Open Access Article. Published on 08 February 2017. Downloaded on 3/26/2025 6:23:41 PM.
This article is licensed under a Creative Commons Attribution-NonCommercial 3.0 Unported Licence.
View Article Online
10 V. Hornak, R. Abel, A. Okur, B. Strockbine, A. Roitberg and
C. Simmerling, Proteins: Struct., Funct., Genet., 2006, 65,
11 J. A. Maier, C. Martinez, K. Kasavajhala, L. Wickstrom,
K. E. Hauser and C. Simmerling, J. Chem. Theory Comput.,
2015, 11, 3696–3713.
12 A. C. T. van Duin, S. Dasgupta, F. Lorant and W. A. Goddard
III, J. Phys. Chem. A, 2001, 105, 9396–9409.
13 M. Rupp, A. Tkatchenko, K.-R. Muller and O. A. von
Lilienfeld, Phys. Rev. Lett., 2012, 108, 58301.
14 S. Manzhos and T. Carrington, J. Chem. Phys., 2006, 125, 84109.
15 K. T. Sch¨utt, F. Arbabzadah, S. Chmiela, K. R. M¨uller and
A. Tkatchenko, 2016, arXiv.org:1609.08259.
16 T. H. Ho, N.-N. Pham-Tran, Y. Kawazoe and H. M. Le, J. Phys.
Chem. A, 2016, 120, 346–355.
17 B. Kolb, B. Zhao, J. Li, B. Jiang and H. Guo, J. Chem. Phys.,
2016, 144, 224103.
18 B. Jiang, J. Li and H. Guo, Int. Rev. Phys. Chem., 2016, 35,
19 F. H¨ase, S. Valleau, E. Pyzer-Knapp and A. Aspuru-Guzik,
Chem. Sci., 2016, 7, 5139–5147.
Lilienfeld
R. Armiento, Phys. Rev. Lett., 2016, 117, 135502.
21 M. Rupp, R. Ramakrishnan and O. A. von Lilienfeld, J. Phys.
Chem. Lett., 2015, 6, 1–5.
22 O. Isayev, C. Oses, S. Curtarolo and A. Tropsha, 2016, 1–12.
23 J. Behler, Int. J. Quantum Chem., 2015, 115, 1032–1050.
Jasrasaria,
Pyzer-Knapp,
A. Aspuru-Guzik, 2016, arXiv: 1608.05747.
25 J. Behler and M. Parrinello, Phys. Rev. Lett., 2007, 98, 146401.
26 O. A. Von Lilienfeld, R. Ramakrishnan, M. Rupp and
A. Knoll, Int. J. Quantum Chem., 2015, 115, 1084–1093.
27 S. Manzhos, R. Dawes and T. Carrington, Int. J. Quantum
Chem., 2015, 115, 1012–1020.
28 A. P. Bart´ok, R. Kondor and G. Cs´anyi, Phys. Rev. B: Condens.
Matter Mater. Phys., 2013, 87, 184115.
29 W. J. Szlachta, A. P. Bart´ok and G. Cs´anyi, Phys. Rev. B:
Condens. Matter Mater. Phys., 2014, 90, 104108.
30 T. Morawietz, A. Singraber, C. Dellago and J. Behler, Proc.
Natl. Acad. Sci. U. S. A., 2016, 113, 8368–8373.
31 M. Gastegger, C. Kauﬀmann, J. Behler and P. Marquetand, J.
Chem. Phys., 2016, 144, 194110.
32 Y. LeCun, Y. Bengio and G. Hinton, Nature, 2015, 521, 436–
33 J. Schmidhuber, Neural Networks, 2015, 61, 85–117.
34 K. Hornik, M. Stinchcombe and H. White, Neural Networks,
1989, 2, 359–366.
35 H. Gassner, M. Probst, A. Lauenstein and K. Hermansson,
J. Phys., 1998, 102, 4596–4605.
36 C. M. Handley and P. L. A. Popelier, J. Phys. Chem. A, 2010,
114, 3371–3383.
37 M. Rupp, R. Ramakrishnan and O. A. von Lilienfeld,
 
38 R. Ramakrishnan, P. O. Dral, M. Rupp and O. A. von
Lilienfeld, Sci. Data, 2014, 1, 140022.
39 J. Da Chai and M. Head-Gordon, J. Chem. Phys., 2008, 128,
40 T. Fink and J. L. Raymond, J. Chem. Inf. Model., 2007, 47,
41 T. Fink, H. Bruggesser and J. L. Reymond, Angew. Chem., Int.
Ed., 2005, 44, 1504–1508.
42 
43 G. Landrum, 
44 J. Behler, Phys. Chem. Chem. Phys., 2011, 13, 17930.
M. G. Rockley and R. Komanduri, J. Chem. Phys., 2005,
122, 84104.
46 G. M. J. Frisch, W. Trucks, H. B. Schlegel, G. E. Scuseria,
M. A. Robb, J. R. Cheeseman, G. Scalmani, V. Barone,
B. Mennucci, G. A. Petersson, H. Nakatsuji, M. Caricato,
X. Li, H. P. Hratchian, A. F. Izmaylov, J. Bloino, G. Zheng
and J. L. Sonnenberg, Gaussian, Inc., Wallingford, CT, 2009.
47 
48 T. Poggio and F. Girosi, Science, 1990, 24–7, 978–982.
49 T. Amaral, L. M. Silva, L. A. Alexandre, C. Kandaswamy,
J. M. Santos and J. M. S. De, in Proceedings - 2013 12th
Mexican International Conference on Articial Intelligence,
MICAI 2013, IEEE, 2013, pp. 114–120.
50 D. Kingma and J. Ba, arXiv:1412.6980 [cs.LG], 2014, 1–15.
51 N. Srivastava, G. E. Hinton, A. Krizhevsky, I. Sutskever and
R. Salakhutdinov, J. Mach. Learn. Res., 2014, 15, 1929–1958.
52 T. H. Stanley, J. Pain Symptom Manage., 1992, 7, S3–S7.
53 D. J. Heal, S. L. Smith, J. Gosden and D. J. Nutt,
J. Psychopharmacol., 2013, 27, 479–496.
This journal is © The Royal Society of Chemistry 2017
Chem. Sci., 2017, 8, 3192–3203 | 3203
Edge Article
Chemical Science
Open Access Article. Published on 08 February 2017. Downloaded on 3/26/2025 6:23:41 PM.
This article is licensed under a Creative Commons Attribution-NonCommercial 3.0 Unported Licence.
View Article Online