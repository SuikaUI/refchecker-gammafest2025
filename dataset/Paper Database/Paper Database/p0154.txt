Unsupervised Transfer Learning via Multi-Scale Convolutional
Sparse Coding for Biomedical Applications
Hang Chang⋆ [Member, IEEE], Ju Han [Member, IEEE], Cheng Zhong [Member, IEEE],
Antoine M. Snijders, and Jian-Hua Mao
Hang Chang and Ju Han and Cheng Zhong and Antoine M. Snijders and Jian-Hua Mao are with
Berkeley Biomedical Data Science Center (BBDS: Biological Systems and
Engineering Division, Lawrence Berkeley National Laboratory, Berkeley, California, U.S.A
The capabilities of (I) learning transferable knowledge across domains; and (II) fine-tuning the
pre-learned base knowledge towards tasks with considerably smaller data scale are extremely
important. Many of the existing transfer learning techniques are supervised approaches, among
which deep learning has the demonstrated power of learning domain transferrable knowledge with
large scale network trained on massive amounts of labeled data. However, in many biomedical
tasks, both the data and the corresponding label can be very limited, where the unsupervised
transfer learning capability is urgently needed. In this paper, we proposed a novel multi-scale
convolutional sparse coding (MSCSC) method, that (I) automatically learns filter banks at
different scales in a joint fashion with enforced scale-specificity of learned patterns; and (II)
provides an unsupervised solution for learning transferable base knowledge and fine-tuning it
towards target tasks. Extensive experimental evaluation of MSCSC demonstrates the effectiveness
of the proposed MSCSC in both regular and transfer learning tasks in various biomedical domains.
Index Terms
Transfer Learning; Sharable Information; Convolutional Sparse Coding; Deep Learning;
Biomedical Application; Brain Tumors; Low Dose Ionizing Radiation (LDIR); Mouse Model;
Breast Cancer Subtypes
⋆Correspondence should be addressed to Hang Chang ( ).
All related resources have been released for public consumption at BMIHub - 
Disclaimer
This document was prepared as an account of work sponsored by the United States Government. While this document is believed to
contain correct information, neither the United States Government nor any agency thereof, nor the Regents of the University of
California, nor any of their employees, makes any warranty, express or implied, or assumes any legal responsibility for the accuracy,
completeness, or usefulness of any information, apparatus, product, or process disclosed, or represents that its use would not infringe
privately owned rights. Reference herein to any specific commercial product, process, or service by its trade name, trademark,
manufacturer, or otherwise, does not necessarily constitute or imply its endorsement, recommendation, or favoring by the United
States Government or any agency thereof, or the Regents of the University of California. The views and opinions of authors expressed
herein do not necessarily state or reflect those of the United States Government or any agency thereof or the Regents of the University
of California.
HHS Public Access
Author manuscript
IEEE Trans Pattern Anal Mach Intell. Author manuscript; available in PMC 2018 May 01.
 
IEEE Trans Pattern Anal Mach Intell. 2018 May ; 40(5): 1182–1194. doi:10.1109/TPAMI.2017.2656884.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
1 Introduction
Recent neuroscience findings , have identified the complex hierarchy in the neocortex
for the representation of observations. Motivated by these findings, one branch of the
machine learning community has attempted to build information representations, through
computational modules, which share similar properties with those in the neocortex. For the
past decade, deep learning has gained momentum as a result of its demonstrated capability
of improved performance for various automation tasks and its potential for future research.
Among different deep learning approaches, Convolutional Neural Networks (CNNs) – 
and Deep Belief Networks (DBNs) , are the most well-established techniques.
Along with the development of modern deep neural networks, one curious phenomenon
exhibits that, regardless of natural image dataset or even training objectives – , the
first layer of the deep neural network always captures standard features that resemble either
Gabor filters or color blobs. The common appearance of filters learned from the first few
layers provides the domain adaptive/transferrable base knowledge, which can serve as the
basis for transfer learning – . During transfer learning with deep neural networks, a
base deep neural network is first trained on a base dataset and task, and the learned
knowledge (e.g., features, representation) is then transferred to a target network to be trained
on a target dataset and task. Typically, the first n layers of the target deep neural network is
initialized as the first n layers of the base deep neural network; while with the remaining
layers randomly initialized and trained towards the target dataset and task. Depending on the
size of the target dataset and the size of the network (i.e., the number of parameters), the first
n layers of the target deep neural network can either be frozen (i.e., remain unchanged
during training on the new task), or be fine-tuned based on backpropagation strategy towards
the new task, which is a balance between specificity and generality of derived knowledge.
Although deep neural networks have been successfully applied in various biomedical tasks,
the training of such large scale networks typically requires massive amounts of labeled data,
which can be very limited in many biomedical tasks.
In this paper, we proposed a novel method, namely Multi-Scale Convolutional Sparse
Coding (MSCSC), which automatically learns filter banks at different scales in a joint
fashion with enforced scale-specificity, and therefore not only improves the classification
performance on many biomedical tasks, but also provides an unsupervised solution for
transfer learning.
The rest of this paper is organization as follows: Section 2 briefly reviews related studies.
Section 3 describes the details of proposed MSCSC model. Section 4 and Section 5
elaborate the experimental design, followed by detailed discussion on the evaluation results.
Lastly, section 6 concludes the paper.
2 Related Work
In recent years, convolutional sparse coding has received increasing research interest in
computer vision and machine learning communities – , due mainly to its capability
of learning shift-invariant filters with complex patterns.
Chang et al.
IEEE Trans Pattern Anal Mach Intell. Author manuscript; available in PMC 2018 May 01.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
Meanwhile, in the field of transfer learning via deep neural networks, recent studies –
 have shown that, given a target dataset which is significantly smaller than the base one,
transfer learning can be a powerful tool to enable training a large target network to obtain
state-of-the-art results in various tasks without over-fitting, which suggests that the first few
layers of a deep neural network, trained on a large scale base dataset, can capture domain
adaptive/transferable knowledge, which is fairly general at least in the natural image domain.
Although deep neural networks have been successfully applied in various biomedical tasks,
the training of such large scale networks typically requires massive amounts of labeled data,
which can be very limited in many biomedical tasks.
3 Multi-Scale Convolutional Sparse Coding
In this section, we describe the proposed multi-scale convolutional sparse coding model.
Without the loss of generality, we demonstrate MSCSC with 2D images as input. Let
X = {xi}i = 1
be a training set containing N images with dimension m × n. Let
D = {ds, k}s = 1, k = 1
be the 2D multiscale convolutional filter bank with S different scales,
and K filters per scale, where each ds,k is an hs × hs convolutional kernel. Define
Z = {Zi}i = 1
as the set of sparse feature maps, where Zi = {zs, k
}s = 1, k = 1
consists of S × K
feature maps for the reconstruction of image xi. MSCSC aims to decompose each training
image xi as the sum of a series of sparse feature maps zs, k
∈Zi convolved with kernels ds,k
from the filter bank D, by solving the following objective function:
ds, k * zs, k
s.t.‖ds, k‖2
2 = 1, ∀k = 1, …, K; ∀s = 1, …, S
where the first and the second term represent the reconstruction error and the ℓ1-norm
penalty, respectively; α is a regularization parameter; * is the 2D discrete convolution
operator; and the filters are constrained to have unit energy to avoid trivial solutions. The
construction of D is a balance between the reconstruction error and the ℓ1-norm penalty.
Note that the objective of Eq. (1) is not jointly convex with respect to D and Z, but is convex
with respect to either one of them with the other fixed . We thus solve Eq. (1) by
optimizing D and Z in an alternative fashion, i.e., iteratively performing the two steps that
first compute Z and then updating D. Specifically, we use the Iterative Shrinkage
Thresholding Algorithm (ISTA) to solve for the sparse feature maps Z; and use the
stochastic gradient descent for updating the convolutional dictionary D. Alternative
methods for updating the dictionary can be found in , , , and the proposed
optimization procedure is sketched in Algorithm 1. It is clear that the proposed optimization
procedure utilizes the standard ISTA strategy with indices over the different scales.
Chang et al.
IEEE Trans Pattern Anal Mach Intell. Author manuscript; available in PMC 2018 May 01.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
Algorithm 1 MSCSC Algorithm
Input: Training set X = {xi}i = 1
Output: Convolutional filter bank D = {ds, k}s = 1, k = 1
Initialize: D ~
(0, 1), Z ← 0
for i = 1 to N do
Normalize each kernel in D to unit energy
Fixing D, compute sparse feature maps Zi by solving
ds, k * zs, k
Fixing Z, update D as
D ← D − μ ΔDℒ (D,Z)
until Convergence (maximum iterations reached or objective function ≤ threshold)
4 Evaluation of MSCSC on Regular Classification Tasks
This section provides experimental evaluation of MSCSC on tissue histology classification
and the classification of breast cancer subtypes, followed by detailed discussion on the
experimental results.
4.1 Evaluation of MSCSC on Tissue Histology Classification
In this section, we present detailed experimental design and evaluation of MSCSC on the
task of tissue histology classification. The corresponding classification pipeline, namely
Multi-Scale-CSCSPM, was built upon MSCSC and SPM, and applied on two distinct tumor
datasets, curated from The Cancer Genome Atlas (TCGA), namely (i) Glioblastoma
Multiforme (GBM) and (ii) Kidney Renal Clear Cell Carcinoma (KIRC), which are publicly
available from the NIH (National Institute of Health) repository.
4.1.1 Multi-Scale Multi-Spectral Feature Extraction for Tissue Histology
Classification—As suggested in , different spectra of biomedical images usually
capture distinct targets of interests, and applying CSC to each spectrum separately enables
learning of biological-component-specific feature detectors, which helps improve the
classification performance. Therefore, we adopt the same configuration as in , and apply
the proposed MSCSC to two separate spectra produced through color decomposition ,
which characterize the nuclear chromatin and the extracellular matrix, respectively.
Without the loss of generality, we assume that the number of filters for each spectrum
(channel) is K per scale, the number of scales is S, and the number of spectra (channels) is
Chang et al.
IEEE Trans Pattern Anal Mach Intell. Author manuscript; available in PMC 2018 May 01.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
W after decomposition; the 2D feature map ys, k
ω is then defined as: ys, k
ω * xω, for 1 ≤ s
≤ S, 1 ≤ k ≤ K and 1 ≤ ω ≤ W, where x̂ω is the ω-th spectrum component of input image x
∈Dω is the k-th convolutional kernel at scale s in filter bank Dω learned over
spectrum with index ω.
The architecture for multi-scale multi-spectral tissue histology feature extraction is
illustrated in Figure 2, which consists steps as follows,
Color decomposition (CoD). An input image is first decomposed and divided
into two separate spectrum , corresponding to the nuclear chromatin and the
extracellular matrix, respectively.
Multi-scale convolution. Each decomposed spectra is convolved with spectrumspecific multi-scale filters learnt via MSCSC.
Element-wise absolute value rectification (Abs). The Abs layer computes
absolute value element-wisely in each feature map, ys, k
ω , to avoid the cancelation
effect in sequential operations.
Local contrast normalization (LCN). The LCN layer aims to enhance the
stronger feature responses and suppress weaker ones across feature maps,
ω }s = 1, k = 1
, in each spectrum (ω), by performing local subtractive and
divisive operations , .
Max-pooling (MP). The MP layer partitions each feature map into nonoverlapping windows and extracts the maximum response from each of the
pooling window. It allows local invariance to translation .
Concatenation of features from each spectrum to form the multi-scale multispectral tissue features.
After extraction, the multi-scale multi-spectral tissue features, with dimensionality SKW, are
fed into SPM frame-work for summarization and classification as described in the following
4.1.2 Feature Summarization via SPM—We adopt SPM to construct tissue
morphometric context , – as the final representation for tissue classification. Let
V = [v1, …, vT] ∊ ℝSKW×T be the feature set of T feature vectors with dimension SKW. The
final representation of the tissue image is constructed as follows,
Construct a dictionary B = [b1, …, bP] ∊ ℝSKW×P with P tissue morphometric
types, by solving:
‖vi −Bci‖2s . t . card(ci) = 1, ‖ci‖1 = 1, ci ≥0, ∀i
Chang et al.
IEEE Trans Pattern Anal Mach Intell. Author manuscript; available in PMC 2018 May 01.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
where C = [c1, …, cT] ∊ ℝP×T is a set of codes for reconstructing V, cardinality
constraint card(ci) enforces ci to have only one nonzero element, ci ≥ 0 is a nonnegative constraint on all vector elements. Eq. (2) is optimized by alternating
between the two variables. After training, the query signal set V is encoded via
Vector Quantization (VQ) based on dictionary Bi.e., assigning each vi to its
closest tissue morphometric type in B.
Construct the spatial histogram for SPM . This is done by dividing an image
into increasingly finer subregions and computing local histograms of different
tissue morphometric types falling into each of the subregions. The spatial
histogram, H, is then formed by concatenating the appropriately weighted
histograms of tissue morphometric types at all resolutions, i.e.,
), 1 ≤l ≤L
2L −l + 1Hl, …, 1
where (·) is the vector concatenation operator, l ∊ {0, …, L} is the resolution
level of the image pyramid, and Hl represents the concatenation of histograms for
all image subregions at pyramid level l. Note, the formulation of spatial
histogram, H, is derived from the work in , and please refer to Equation 1
and Equation 3 in for details.
For the final classification, the spatial histograms are transformed via homogeneous kernel
map for improved scalability with the adoption of linear SVM .
4.1.3 Experimental Setup—We have compared the proposed approach with six other
approaches on both GBM and KIRC datasets. Implementation details of all approaches are
summarized in Table 1. On the implementation of nonlinear kernel SPM , we used the
standard K-means clustering for constructing the dictionary and set the level of pyramid to
be 3. During evaluation, We repeated all experiments 10 times with random splits of training
and test set, and reported the final results as the mean and standard deviation of the
classification rates on the following two distinct tumor types:
GBM Dataset. It contains 3 classes: Tumor, Necrosis, and Transition to Necrosis,
which were curated from whole slide images (WSI) scanned with a 20X
objective (0.502 micron/pixel). Examples can be found in Figure 3. The number
of images per category are 628, 428 and 324, respectively. Most images are 1000
× 1000 pixels. In this experiment, we trained on 80 and 160 images per category
and tested on the remaining images, with three different dictionary sizes: 256,
512 and 1024. Detailed comparisons are shown in Table 2.
KIRC Dataset. It contains 3 classes: Tumor, Normal, and Stromal, which were
curated WSI scanned with a 40X objective (0.252 micron/pixel). Examples can
Chang et al.
IEEE Trans Pattern Anal Mach Intell. Author manuscript; available in PMC 2018 May 01.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
be found in Figure 3. The number of images per category are 568, 796 and 784,
respectively. Most images are 1000 × 1000 pixels. In this experiment, we trained
on 140 and 280 images per category and tested on the remaining images, with
three different dictionary sizes: 256, 512 and 1024. Detailed comparisons are
shown in Table 3.
4.1.4 Discussion
Joint learning (MSCSC) vs. Separate learning (CSC) for the construction of
multi-scale filters. To better understand the difference between joint learning and
separate learning in terms of multi-scale filter construction and its impact on
classification performance, we designed the comparison between Multi-Scale-
CSCSPM and PSEUDO-Multi-Scale-CSCSPM, where the only difference is that
the multi-scale filters in Multi-Scale- CSCSPM were jointly learnt through
MSCSC, while the multi-scale filters in PSEUDO-Multi-Scale-CSCSPM were
separately learnt at each scale via CSC and concatenated afterwards. Figure 1(a)
shows some examples of multi-scale filters jointly/separately learnt from each
individual spectrum. It is clear that, through joint learning via MSCSC, the filters
at smaller scale (i.e., 13 × 13) mainly captures lower-level features (e.g., edges),
while the filters at larger scale (i.e., 27 × 27) are more responsible for higherlevel features (e.g., complex pattern in extracellular matrix). However, filters
learnt separately via CSC do not have such scale-specificity, and present a
mixture of both low-level and high-level features at both scales, which might
lead to feature redundancy across scales. The difference in scale-specificity
becomes more distinct for filters learnt from extracellular matrix, since compared
with nuclear chromatin, extracellular matrix sees much more complex patterns,
which CSC fails to capture. As a result (shown in Table 2 and Table 3), Multi-
Scale-CSCSPM outperforms PSEUDO-Multi-Scale-CSCSPM on both datasets.
And we suggest that MSCSC intrinsically allows trainable collaboration of filters
across different scales, which potentially leads to filters with improved scalespecificity, and as a result, less feature redundancy across scales.
Multi-Scale filters vs. single scale filters. Biological events often express
themselves at different scales due to the inherent heterogeneity (e.g., cell type,
cell state and the micro-environment). Therefore, the capability to capture and
characterize biological events at different scales is very much demanded. For fair
comparison, in our experiments, Multi-Scale-CSCSPM, PSEUDO-Multi-Scale-
CSCSPM and MCSCSPM were configured to learn the same number of filters,
which are 300 and 600 filters for GBM and KIRC datasets, respectively.
Experimental results, as summarized in Table 2 and Table 3, show that, for both
GBM and KIRC datasets, Multi-Scale-CSCSPM outperforms PSEUDO-Multi-
Scale-CSCSPM and yields the best performance. However, PSEUDO-Multi-
Scale-CSCSPM only outperforms MCSCSPM on GBM; while becomes less
favorable compared to MCSCSPM on KIRC. These observations suggest that,
Classification system built on multi-scale filters learnt via MSCSC is
more preferable compared to the one built on filters at single scale;
Chang et al.
IEEE Trans Pattern Anal Mach Intell. Author manuscript; available in PMC 2018 May 01.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
Joint multi-scale filter learning (MSCSC) ensures the scale-specificity
of filters, and thereafter the consistency of performance for system (i.e.,
Multi-Scale-CSCSPM) built upon features extracted via such filters.
The inconsistency of classification system (PSEUDO-Multi-Scale-
CSCSPM), built on PSEUDO-multi-scale filters, attributes to the lack
of scale-specificity of such filters, which can potentially leads to feature
redundancy across scales, and as a result, less favorable performance
even compared with system (i.e., MCSCSPM) built on filters at single
Multi-Scale filter learning vs. Multi-Stage filter learning. Compared to the most
recently proposed multi-stage unsupervised feature learning system (PSDnSPM)
 , Multi-Scale-CSCSPM consistently achieves better performance over two
distinct tumor types, with significantly less number of filters (i.e., 300 vs. 1024
on GBM; and 600 vs. 1024 on KIRC). These advantages, we suggest, are results
of i) scale specificity enforced by the proposed multi-scale filter learning
strategy; and ii) convolutional filter learning, which, compared to patch-based
learning, leads to much more compact filter bank that are translation-invariant.
Multi-Scale filter learning v.s. biological meaningful prior knowledge. System
built upon biological meaningful prior knowledge (i.e., SMLSPM ) can be
very effective for the task of tissue histology classification. However, biological
meaningful prior knowledge might not always be available straightforwardly
(i.e., cellular morphometric properties, as used in SMLSPM, might be difficult to
extract), which, as a result, potentially limits the generalization ability of such
system to different applications. The results, as shown in Table 2 and Table 3,
indicate that the proposed system, Multi-Scale-CSCSPM, is superior to the
system built upon biological meaningful prior knowledge (i.e., SMLSPM ),
without imposing additional requirements (e.g., nuclei are segmentable), which
is a better alternative for analyzing large cohorts of distinct tumor types with
substantial technical variations and biological heterogeneities.
4.1.5 Experimental Revisit
Color Decomposition: to investigate the benefit of color decomposition in the
proposed tissue histology classification pipeline, we have further evaluated
Multi- Scale-CSCSPM with two more variations: Multi-Scale- CSCSPM-RGB
and Multi-Scale-CSCSPM-Gray. For Multi-Scale-CSCSPM-RGB, convolutional
filter banks were learned from/applied to R, G, and B channels separately, where
the number of filters were set to be 50 and 100 per channel per scale for GBM
and KIRC, respectively. For Multi-Scale-CSCSPM-Gray, convolutional filter
banks were learned from / applied to the grayscale image, where the number of
filters were set to be 150 and 300 per scale for GBM and KIRC, respectively.
The number of filters were set to ensure the comparability among the variations,
and all other experimental setup remains the same as for Multi-Scale-CSCSPM.
The best performances on GBM and KIRC datasets with 160 training images and
280 training images per category, respectively, were illustrated in Figure 4. It is
Chang et al.
IEEE Trans Pattern Anal Mach Intell. Author manuscript; available in PMC 2018 May 01.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
clear that color decomposition is beneficial to tissue histology classification,
which is due to the capturing of biological-component-specific information and,
therefore, improve the classification performance .
Max-pooling: to investigate the benefit of max-pooling in the proposed tissue
histology classification pipeline, we have further evaluated Multi-Scale-
CSCSPM with two more variations: Multi-Scale-CSCSPM-Mean Pooling and
Multi-Scale-CSCSPM-NoPooling. All other experimental setup remains the
same as for Multi-Scale-CSCSPM, and the best performances on GBM and
KIRC datasets with 160 training images and 280 training images per category,
respectively, were illustrated in Figure 5. It is clear that max-pooling strategy
outperforms the other options, probably due to its robustness to local
translations.
Absolute value rectification: to investigate the benefit of absolute value
rectification in the tissue histology classification pipeline, we have further
evaluated Multi-Scale-CSCSPM without absolute value rectification: Multi-
Scale-CSCSPM-noAbs. All other experimental setup remains the same as for
Multi-Scale-CSCSPM, and the best performances on GBM and KIRC datasets
with 160 training images and 280 training images per category, respectively,
were illustrated in Figure 6. It is clear that absolute value rectification is
desirable for the task of tissue histology classification.
4.1.6 Further Comparison with Other Related Work—Existing multi-scale computer
vision applications typically concatenate filters from multiple learning layers for multi-scale
feature extraction, or use hierarchical pooling to construct the multi-scale features based on
single scale filter responses. For the comparison with the former case, Multi-Scale
PSD2SPM was implemented with filters concatenated from both the first and the second
layers; and for the comparison with the later case, Yang’s model was adopted with
implementation based on multi-spectral single-scale (27×27) filters, for fair comparison,
followed by 3 max-pooling layers in hierarchy (in our experiments, mean-pooling results in
~5% performance drop for both datasets).
Furthermore, it is also very interesting to compare with the Convolutional Neural Networks
(CNN) , due to its demonstrated success in many different computer vision
applications – , . Here, we adopted AlexNet and VGGNet , which are two
of the most successful deep convolutional neural network architectures. During evaluation,
we followed the suggestions in with different level of transfer learning settings on both
GBM and KIRC datasets using aggressive data augmentation strategies (e.g., flipping,
rotation and changing of illumination), among which, we found that the direct application of
the pre-train networks (bvlc_alexnet and VGG_ILSVRC_19_layers ) produced the
best performance. Specifically, for both AlexNet and VGGNet, features were extracted on
224×224 patches with step-size (45) followed by SPM as used for all other approaches.
The best performances on GBM and KIRC datasets were reported with 160 and 280 training
images per category, respectively, as shown in Figure 7. It is clear that our proposed method
outperforms the pre-trained AlextNet on both GBM and KIRC datasets, while produces
Chang et al.
IEEE Trans Pattern Anal Mach Intell. Author manuscript; available in PMC 2018 May 01.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
highly competitive results compared with the pre-trained VGGNet, where, specifically, it
outperforms the pre-trained VGGNet on GBM dataset and underperforms the pre-trained
VGGNet on KIRC dataset. The experimental results suggest that the pre-trained deep neural
networks from natural domain (e.g., from ImageNet ) encode sharable information that
is potentially applicable to biomedical domains. Furthermore, given the significant smaller
model structure and the unique unsupervised learning capability of the proposed work,
compared with deep neural networks, our proposed work provides a highly competitive
solution for the learning and application of sharable information with improved
computational efficiency and reduced label dependency, which is especially beneficial and
desirable to biomedical domains.
4.2 Further Evaluation of MSCSC on Classification of Breast Cancer Subtypes
As a further validation, we have also applied the classification pipeline (MultiScale-
CSCSPM) for the classification of subtypes in breast cancer. The dataset for evaluation
contains 3 classes: DCIS model, ERBB2+, and Triple Negative, which were collected from
22 breast cancer cell line, and scanned by phase contrast microscope with a 10X objective.
Examples can be found in Figure 8. The number of images per category are 36, 40 and 40,
respectively. Most images are 1024 × 768 pixels. In this experiment, we trained 18 images
per category and tested on the remaining images, with fixed dictionary size: 1024. All
experimental protocols and parameter settings were identical to those described in Section
4.1.3, except that no color decomposition was involved (gray-scale image). The final results
(see Figure 9) show superior performance of our approach, which confirms the effectiveness
and applicability of the proposed multi-scale convolutional sparse coding model to various
different tasks.
5 Evaluation of Transfer Learning Capability of MSCSC
The multi-scale joint learning characteristics of MSCSC as well as its capability in capturing
scale-specific patterns not only help improve the performances of various regular
classification tasks as demonstrated in Section 3, but also provide an unsupervised solution
for (I) learning sharable knowledge from a base dataset; and (II) applying/fine-tuning the
base knowledge towards the target datasets. This section provides perceptual validation of
the sharable knowledge derived by MSCSC across domains, followed by extensive
evaluation and discussion on the perceptual insights.
5.1 Perceptual Evaluation
As a perceptual evaluation, we visualized the multi-scale filter banks jointly learned by
MSCSC from different domains in Figure 10, which indicates that: (I) filter banks with
smaller scale(s) always capture general features regardless of the training domain; (II) the
specificity of features captured by filter banks with larger scale(s) trained on various
domains, is an increasing function with respect to the dissimilarity among domains; and (III)
interestingly, the generality of knowledge, captured by the filter banks with larger scale(s) of
MSCSC within different cancer-related domains, still maintains to a large degree, which
suggests that the adaptive/transferable knowledge in cancer-related domain(s) is derivable
Chang et al.
IEEE Trans Pattern Anal Mach Intell. Author manuscript; available in PMC 2018 May 01.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
through MSCSC in an unsupervised fashion. These insights are further justified
quantitatively as follows.
5.2 Quantitative Evaluation of Sharable Knowledge Across Tumor Types in Tissue
Histology from Human Patients
Figure 10 suggests that features learned from histology domain are transferable/sharable
across tumor types from human patients. As a quantitative evaluation, we directly applied (I)
the pre-trained model from GBM to the classification task in KIRC dataset; and (II) the pretrained model from KIRC dataset to to the classification task in GBM dataset. All the
experimental protocols were identical to the ones described in Section 4.1, and the best
performances on GBM and KIRC datasets with 160 training images and 280 training images
per category, respectively, were shown in Figure 11.
5.3 Quantitative Evaluation of Sharable Knowledge from Human to Mouse in Tissue
In this experiment, we were interested to know whether MSCSC trained on human tissue
histology can capture sharable information which is applicable to animal models.
Specifically, we directly utilized the MSCSC (pre-trained on GBM dataset) for the
differentiation of mouse breast tumor morphology between radiation-induced cancer and
spontaneous cancer. The dataset contains 2 classes: Sham (control) and LDIR (low dose
ionizing radiation at 10 cGy), which were curated from a cohort that was generated for the
study of the genetic control of stromal mediation of mammary tumor susceptibility to LDIR
 . Each category contained 200 images, which were scanned by light microscope with a
40X objective and a fixed size of 2048 × 1536 pixels. During evaluation, we randomly
selected 100 images per category for training and tested on the remaining images with 10
iterations and fixed dictionary size: 1024. All experimental protocols and parameter settings
were identical to those described in Section 4.1.3. The final results, as the mean and standard
deviation of the classification rates, was illustrated in Figure 12.
5.4 Fine-Tuning Pre-Trained Model from GBM towards Breast Cancer Subtype
Classification
With the increase of domain difference, an urgent need is to fine tune the pre-trained model
towards new tasks, which can be easily achieved by fixing the first few filter banks with
smaller scales and re-training the rest (filter banks with larger scales) due to the multi-scale
joint learning characteristics of MSCSC. As a further justification, we applied the pretrained model from GBM dataset (see Section 4.1) to the task of Breast Cancer Subtype
Classification (see Section 4.2) with different levels of knowledge transfer and tuning
settings, and the corresponding performance was illustrated in Figure 13.
5.5 Discussion
Our experimental evaluations above suggest that,
The pre-trained multi-scale filter banks by MSCSC may capture sharable
knowledge/information across domains, and therefore may be directly applicable
to related domain(s). As demonstrated in Figure 10, filter banks at each
Chang et al.
IEEE Trans Pattern Anal Mach Intell. Author manuscript; available in PMC 2018 May 01.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
individual scale all capture similar patterns across different cancer domains,
which can serve as the sharable information for tasks across those domains. This
insight was further confirmed by the quantitative evaluation of (I) the direct
application of pre-trained model from GBM to the tasks in KIRC, Breast Cancer
dataset and mouse LDIR dataset, as shown in Figure 11, Figure 13 and Figure
12, respectively; and (II) the direct application of pre-trained model from KIRC
to the task in GBM dataset, as shown in Figure 11;
The pre-trained multi-scale filter banks by MSCSC can be fine-tuned effectively
towards the target dataset in an unsupervised fashion, which is performed by
fixing the pre-trained filter bank(s) at smaller scale(s) while re-training the rest
(filter bank(s) at larger scale(s)). As shown in Figure 13, the partially-tuned filter
banks pre-trained from GBM dataset (GBMTransfer-Multiscale-CSCSPM-ft2nd)
saw a steady increase of performance on the classification of breast cancer
subtypes along filter learning iterations, and both the entirely-tuned filter banks
(GBMTransfer-Multiscale-CSCSPM-ft1st2nd) and the filter banks learned
directly from breast cancer dataset (Multiscale-CSCSPM) experienced the
decrease of performance along filter learning iterations. All the phenomenons are
suggested to be tightly related to the scale of target dataset (breast cancer
dataset), which, in our case, is significantly smaller compared to the based
dataset (GBM dataset).
6 CONCLUSION
In this paper, we proposed a Multi-Scale Convolutional Sparse Coding model (MSCSC) for
unsupervised joint learning of filters at multi-scales with trainable collaboration among
them, which, compared to CSC, leads to filters with improved scale-specificity and,
subsequently, features with reduced redundancy across scales. Furthermore, such an joint
learning strategy also provides an unsupervised solution for transfer learning, which is
extremely helpful when the scale of labeled data is very limited. Experimental results, in
various biomedical domains, demonstrate the effectiveness of MSCSC on both regular
classification tasks as well as its capability in learning sharable base knowledge and finetuning it towards new tasks.
Our future work will focus on (I) applying the sharable information learned from GBM/
KIRC dataset to a large cohort of tissue histology sections for tumor grading and the
association with clinical outcome; and (II) further validating the MSCSC algorithm on
various tasks on natural image datasets.
Acknowledgments
This work was supported by NIH R01 CA184476 carried out at Lawrence Berkeley National Laboratory.