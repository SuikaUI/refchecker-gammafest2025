HAL Id: hal-04144056
 
Submitted on 28 Jun 2023
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of scientific research documents, whether they are published or not.
The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
Robust Bayesian Learning for Reliable Wireless AI:
Framework and Applications
Matteo Zecchin, Sangwoo Park, Osvaldo Simeone, Marios Kountouris, David
To cite this version:
Matteo Zecchin, Sangwoo Park, Osvaldo Simeone, Marios Kountouris, David Gesbert.
Bayesian Learning for Reliable Wireless AI: Framework and Applications. IEEE Transactions on Cognitive Communications and Networking, 2022, pp.1-1. ￿10.1109/TCCN.2023.3261300￿. ￿hal-04144056￿
Robust Bayesian Learning for Reliable Wireless AI:
Framework and Applications
Matteo Zecchin, Student Member, IEEE, Sangwoo Park, Member, IEEE, Osvaldo Simeone, Fellow, IEEE, Marios
Kountouris, Fellow, IEEE, David Gesbert, Fellow, IEEE
Abstract—This work takes a critical look at the application
of conventional machine learning methods to wireless communication problems through the lens of reliability and robustness.
Deep learning techniques adopt a frequentist framework, and
are known to provide poorly calibrated decisions that do not
reproduce the true uncertainty caused by limitations in the
size of the training data. Bayesian learning, while in principle
capable of addressing this shortcoming, is in practice impaired
by model misspeciﬁcation and by the presence of outliers. Both
problems are pervasive in wireless communication settings, in
which the capacity of machine learning models is subject to
resource constraints and training data is affected by noise
and interference. In this context, we explore the application
of the framework of robust Bayesian learning. After a tutorialstyle introduction to robust Bayesian learning, we showcase the
merits of robust Bayesian learning on several important wireless
communication problems in terms of accuracy, calibration, and
robustness to outliers and misspeciﬁcation.
Index Terms—Bayesian learning, robustness, localization, modulation classiﬁcation, channel modeling
I. INTRODUCTION
Artiﬁcial intelligence (AI) is widely viewed as a key enabler
of 6G wireless systems. Research on this topic has mostly
focused on identifying use cases and on mapping techniques
from the vast literature on machine learning to given problems
 – . At a more fundamental level, there have been efforts
to integrate well-established communication modules, e.g.,
for channel encoding and decoding, with data-driven designs,
notably via tools such as model unrolling , . All these
efforts have largely relied on deep learning libraries and tools.
The present paper takes a critical look at the use of this
conventional methodology through the lens of reliability and
robustness . To this end, we explore the potential beneﬁts of
the alternative design framework of robust Bayesian learning
The work of M. Zecchin and D.Gesbert is funded by the Marie Curie action
WINDMILL (grant No. 813999), while O. Simeone and S. Park have received
funding from the European Research Council (ERC) under the European
Union’s Horizon 2020 Research and Innovation Programme (Grant Agreement
No. 725731). M. Kountouris has received funding from the European Research
Council (ERC) under the European Union’s Horizon 2020 Research and
Innovation Programme (Grant agreement No. 101003431).
Matteo Zecchin, Marios Kountouris and David Gesbert are with the
Communication Systems Department, EURECOM, Sophia-Antipolis, France
(e-mail: ; ; ).
Sangwoo Park and Osvaldo Simeone are with the King’s Communications, Learning & Information Processing (KCLIP) lab, Department of
Engineering, King’s College London, London WC2R 2LS, U.K. (e-mail:
 ; ).
The second author has contributed to the problem deﬁnitions and to the
experiments. The third author has had an active role in deﬁning the problems,
as well as in writing the text, while the last two authors have had a supervisory
by focusing on several key wireless communication applications, namely modulation classiﬁcation, indoor and outdoor
localization, and channel modeling and simulation.
A. Frequentist vs. Bayesian Learning
In frequentist learning, the output of the training process is
a single model – typically, a single vector of weights for a
neural network – obtained by minimizing the training loss.
This approach is justiﬁed by the use of the training loss
as an estimate of the population loss, whose computation
would require averaging over the true, unknown distribution
of the data. This estimate is only accurate in the presence of
sufﬁciently large data sets. While abundant data is common
in the benchmark tasks studied in the computers science
literature, the reality of many engineering applications is
that data are often scarce. In wireless communications, the
problem is particularly pronounced at the physical layer, in
which fading dynamics imply short stationary intervals for data
collection and training – .
The practical upshot of the reliance on frequentist learning
is that, in the presence of limited data, decisions made by AI
models (such as neural networks) tend to be poorly calibrated,
providing conﬁdence scores that do not match their true
accuracy , . As a result, an AI model may output a
decision and a large estimate of its correctness, say 95%, while
the accuracy of its prediction is signiﬁcantly lower. This is
an issue problem in many engineering applications, including
emerging communication networks (e.g., 5G and beyond), in
which a more or less conﬁdent decision should be treated
differently by the end user .
The framework of Bayesian learning addresses the outlined
shortcomings of frequentist learning , . At its core,
Bayesian learning optimizes over a distribution over the model
parameter space. This way, if several models ﬁt the data almost
equally well, Bayesian learning does not merely select one of
the models, disregarding uncertainty; rather it assigns similar
distribution values to all such models . As a result, decisions produced by AI models trained via Bayesian learning can
account for the “opinions” of multiple models by averaging
their predictions using the optimized distribution , .
Assuming that the model is well speciﬁed, the uncertainty
quantiﬁcation produced by Bayesian learning can hence be
much more accurate than for frequentist learning. Bayesian
learning has recently been applied in by focusing on the
problem of demodulation over fading channels; as well as in
 for detection over multiple-antenna channels.
B. Robust Bayesian Learning
Like frequentist learning, Bayesian learning assumes that
the distribution underlying training data generation is the same
as that producing test data. Furthermore, Bayesian learning
implicitly assumes that the posited model – namely likelihood
and prior distribution – is sufﬁciently close to the true,
unknown data-generating distribution to justify the use of the
posterior distribution as the optimized distribution in the model
parameter space. As a result, the beneﬁt of Bayesian learning
is degraded when data is affected by outliers , and/or
when the model is misspeciﬁed – .
Recent work has addressed both of these limitations, introducing a generalized framework that we will refer to as
robust Bayesian learning. Robust Bayesian learning aims at
providing well-calibrated, and hence reliable, decisions even
in the presence of model misspeciﬁcation and of discrepancies
between training and testing conditions.
Model misspeciﬁcation has been addressed in , .
These papers start from two observations. The ﬁrst is that
Bayesian learning can be formulated as the minimization
of a free energy metric, which involves the average of the
training loss, as well as an information-theoretic regularizing
term dependent on a prior distribution. The conventional free
energy metric can be formally derived as an upper bound
on the population loss within the theoretical framework of
PAC Bayes theory – . The second observation is that,
in the presence of model misspeciﬁcation, model ensembling
can be useful in combining the decisions of different models
that may be specialized to distinct parts of the problem space.
Using these two observations, references , introduced
alternative free energy criteria that are based on a tighter bound
of the population loss for ensemble predictors.
To address the problem of outliers (see e.g. ), different free energy criteria have been introduced, which are
less sensitive to the presence of outliers. These metrics are
based alternative scoring rules, such as the Brier score ,
and divergences, such as β-divergences , and γdivergence , , which generalize the Kullback-Leibler
(KL) divergence underlying the standard free energy metric.
Finally, a uniﬁed framework has been introduced in 
that generalizes the free energy metrics introduced in ,
 . The approach is robust to misspeciﬁcation, while also
addressing the presence of outliers.
C. Main Contributions
In this paper, we explore the application of robust Bayesian
learning to wireless communication systems. Our main purpose is twofold. On the one hand, we present a tutorialstyle review of robust Bayesian learning in order to introduce
the framework for an audience of communication engineers.
On the other hand, we detail applications of robust Bayesian
learning to communication systems, focusing on automated
modulation classiﬁcation (AMC), received signal strength indicator (RSSI)-based localization, as well as channel modeling
and simulation. These applications have been selected in
order to highlight the importance of considering uncertainty
quantiﬁcation, in addition to accuracy, while also emphasizing
the problems of model misspeciﬁcation and outliers in wireless
communications – .
Our speciﬁc contributions are as follows.
• We give a self-contained introduction to Bayesian and
robust Bayesian learning by describing conceptual underpinnings and practical implications.
• We detail a series of applications of robust Bayesian
learning to popular wireless communication problems,
which are characterized by model misspeciﬁcation and
for which training must contend with data sets corrupted
by outliers.
• As a ﬁrst application, we focus on the AMC problem
for intelligent spectrum sensing . In this setting, the
necessity of deploying lightweight models that satisfy
the strict computational requirements of network edge
devices can give rise to model misspeciﬁcation. At the
same time, the training data sets often contain noninformative outliers due to interfering transmissions from
other devices. We demonstrate that robust Bayesian learning yields classiﬁers with good calibration performance
despite model misspeciﬁcation and the presence of outliers.
• As a second application, we study node localization based
on crowdsourced RSSI data sets . Such data sets
typically contain inaccurately reported location measurements due to imprecise or malicious devices. Furthermore, owing to the complex relation between RSSI measurements and device locations, learning often happens
using misspeciﬁed model classes. In this context, we
demonstrate that robust Bayesian is able to properly estimate residual uncertainty about the transmitters’ locations
in spite of the presence of outliers and misspeciﬁed model
• Finally, we apply robust Bayesian learning to the problem of channel modeling and simulation. We show via
experiments that robust Bayesian learning produces accurate and well-calibrated generative models even in the
presence of outlying data points.
D. Organization
This paper contains two main parts. In the ﬁrst part,
consisting of Sections II and III, we provide a tutorial-style
review of robust Bayesian learning, along with the necessary
background. The second part of the paper elaborates on the
application discussed in the previous subsection.
We start the ﬁrst part in Section II, where we deﬁne the
learning setup and we provide a tutorial-style comparison
between frequentist and Bayesian learning frameworks. In
Section III-A, we introduce the concept of model misspeciﬁcation and we review the m-free energy criterion as a tool
to mitigate the effect of misspeciﬁed model classes. In Section
III-B, we deﬁne outliers and illustrate the role of robust losses
to reduce the inﬂuence of outlying data samples. Finally, in
Section III-C, we describe the robust Bayesian framework and
review the robust m-free energy learning objective . This
approach simultaneously addresses model misspeciﬁcation and
Channel Gain [dB]
p(x|θfreq) and p(x|q)
Target distribution samples
Target distribution
Frequentist
Bayesian β = 1
Bayesian β = 0.1
(10, 1)-Robust Bayesian
Target distribution samples
Frequentist
Bayesian β = 1
Bayesian β = 0.1
(10, 1)-Robust Bayesian
Fig. 1: Estimated distribution over a scalar channel gain
(top panel) and corresponding posterior distribution q(θ) over
the model parameter θ (bottom panel) for frequentist learning, Bayesian learning with β ∈{1, 0.1} and (m, 1)-robust
Bayesian learning with m = 10. The training data set,
represented as crosses, is sampled from the target distribution
In the second part of this paper, we turn to a series of
applications of robust Bayesian learning to important wireless
communication problems. In Section IV, we consider the
AMC task; Section V studies the problem of robust RSSIbased localization; and Section VI focuses on channel modeling and simulation. Finally, Section VII concludes the paper.
simulation
 
II. FREQUENTIST VS. BAYESIAN LEARNING
Throughout this paper we consider a standard learning setup in which the learner has access to a data set D of n
data points {zi}n
i=1 sampled in an independent and identically
distributed (i.i.d.) fashion from a sampling distribution νs(z).
As we will see, owing to the presence of outliers, the sampling
distribution may differ from the target distribution ν(z). The
general goal of learning is that of optimizing models that
perform well on average with respect to the target distribution
ν(z). In this section, we assume that the sampling distribution
νs(z) equals the target distribution ν(z), and we will address
the problem of outliers – which arises when νs(z) ̸= ν(z) –
in the next section.
We will consider both supervised learning problems and
the unsupervised learning problem of density estimation with
applications to wireless communications. In supervised learning, a data sample z ∈Z corresponds to a pair z = (x, y)
that comprises a feature vector x ∈X and a label y ∈Y.
In contrast, for density estimation, each data point z ∈Z
corresponds to a feature vector z = x ∈X.
Supervised learning is formulated as an optimization over
a family of discriminative models deﬁned by a parameterized
conditional distribution p(y|x, θ) of target y given input x. The
conditional distribution, or model, p(y|x, θ) is parameterized
by vector θ ∈Θ in some domain Θ. In contrast, density
estimation amounts to an optimization over a model deﬁned
by parameterized densities p(x|θ). In both cases, optimization
targets a real-valued loss function, which is used to score the
model θ when tested on a data point z.
A. Frequentist Learning
The goal of frequentist learning consists in ﬁnding the
model parameter vector θ that minimizes the training loss
evaluated on the data set D, i.e.,
ˆL(θ, D) =
where ℓ(θ, z) is the loss of model θ evaluated at z. This
optimization follows the empirical risk minimization (ERM)
principle. Accordingly, the frequentist solution is a single
model parameter θfreq ∈Θ that minimizes the training loss,
θfreq = arg min
To simplify the discussion, we assume that the solution to
the ERM problem is unique, although this does not affect the
generality of the presentation.
ERM is motivated by the fact that the training loss (1) is a
ﬁnite-sample approximation of the true, unknown, population
L(θ) = Eν(z)[ℓ(θ, z)],
which averages the loss over the target, and here also sampling,
distribution ν(z). The discrepancy between the population loss
and its approximation given by the training loss introduces
uncertainty regarding the optimal model parameter
θ∗= arg min
which is also assumed to be unique to simplify the discussion.
The error between the optimal solution θ∗and the frequentist
solution θfreq is a form of epistemic uncertainty; namely, uncertainty about the optimal model’s parameter due to the limited
amount of data. The epistemic uncertainty can therefore be
reduced by increasing the size of the data set D .
In practice, the short stationarity intervals of the datagenerating distributions associated with wireless communications often limit the size of training data sets. In this
scarce data regime, epistemic uncertainty may be signiﬁcant.
By selecting a single model, frequentist learning neglects
epistemic uncertainty as it discards information about other
plausible models that ﬁt training data almost as well as the
ERM solution (2). As a result, frequentist learning is known
to lead to poorly calibrated decision , , resulting in
over- or under-conﬁdent predictions that may cause important
reliability issues. More speciﬁcally, a model is said to be overconﬁdent whenever its predictions are complemented by a
correctness likelihood estimates that are larger than the ground
truth values, and it is said to be under-conﬁdent when the
opposite is true .
B. Bayesian Learning
Bayesian learning adopts a probabilistic reasoning framework by scoring all members in the model class by means of a
distribution q(θ) over the model parameter space Θ. Bayesian
learning encodes in the distribution q(θ) the information
obtained from data D, as well as prior knowledge about the
problem, e.g., about the norm of the optimal model parameter
vector θ∗or about sparsity patterns in θ∗ .
Mathematically, given a prior distribution p(θ) on the model
parameter space, Bayesian learning can be formulated as the
minimization of the free energy criterion
J (q) = Eq(θ)[ ˆL(θ, D)] + 1
β KL(q(θ)||p(θ)),
where KL(q(θ)||p(θ)) denotes the KL divergence between the
posterior distribution q(θ) and a prior distribution p(θ), i.e.
KL(q(θ)||p(θ)) = Eq(θ)
while β > 0 is a constant, also known as inverse temperature.
Accordingly, through problem
Bayesian learning minimizes a weighted sum of the average
training loss and of the discrepancy with respect to the prior
distribution p(θ).
The KL term in the free energy (5) plays an essential role
in differentiating between Bayesian learning and frequentist
learning for small data set sizes. In fact, the KL divergence
term acts as a regularizer, whose inﬂuence on the solution
of problem (7) is inversely proportional to the data set size n.
When the regularizer is removed, i.e., when we set β →∞, the
solution of the problem (7) reduces to the frequentist solution
(2). More precisely, the distribution q(θ) that solves problem
(7) reduces to a point distribution concentrated at θfreq.
The optimization (7) of the free energy criterion (5) can be
theoretically justiﬁed through the PAC Bayes generalization
framework , . In it, the KL term is proved to quantify
an upper bound on the discrepancy between training loss and
population loss on average with respect to the random draws
of the model parameter vector θ ∼q(θ). Mathematically,
the free energy provides an upper bound on the average
population loss (when neglecting constants that are inessential
for optimization), i.e.,
Eq(θ) [L(θ)] ≤ˆ
J (q) + const.
As we have discussed in the previous subsection, epistemic
uncertainty is caused by the difference between training and
population losses, and hence between the corresponding minimizers (4) and (2). By incorporating a bound on this error,
the free energy criterion (5) unlike the frequentist training
loss (1), provides a way to account for epistemic uncertainty.
Speciﬁcally, the posterior distribution solving (7) scores multiple (possibly inﬁnite) models that are compatible with the
evidence provided by training data set D.
Specializing the problem (7) to the log-loss
ℓ(x, y, θ) = −log p(y|x, θ)
for supervised learning, and
ℓ(x, θ) = −log p(x|θ)
for density estimation, the minimization of the free energy in
(7) leads to the β-tempered posterior distribution
qBayes(θ|D) ∝
p(θ)p(y|x, θ)β
for supervised learning. A similar expression applies to unsupervised learning for density estimation replacing in (11)
the discriminative model p(y|x, θ) by the density model
p(x|θ).The distribution (11) reduces to the standard posterior distribution when β = 1. In practice, computing the
posterior distribution, or more generally solving problem (7),
are computationally prohibitive tasks that requires to compute
intractable integrals . A common approach to address this
issue is through variational inference (VI) . VI limits the
scope of the optimization over a tractable set of distributions
q(θ), such as jointly Gaussian variables with free mean and
covariance parameters.
Let us now assume that we have obtained a distribution q(θ)
as a, generally approximate, solution of problem (7). We focus
ﬁrst on supervised learning. Given a test input x, the ensemble
predictor obtained from distribution q(θ) is given by
p(y|x, q) = Eq(θ)[p(y|x, θ)].
The average in (12) is in practice approximated by drawing
multiple, say m, samples θ ∼q(θ) from distribution q(θ),
obtaining the m-sample predictor
p(y|x, θ1, ..., θm) = 1
p(y|x, θi),
where samples θi are generated i.i.d. from distribution q(θ)
for i = 1, ..., m, which we write as θ1, ..., θm ∼q(θ)⊗m.
In the case of density estimation, the ensemble density
p(x|q) is similarly deﬁned as
p(x|q) = Eq(θ)[p(x|θ)],
which can be approximated as
p(x|θ1, ..., θm) = 1
with θ1, ..., θm ∼q(θ)⊗m. Henceforth, when detailing expressions for supervised learning, it will be implied that the
corresponding formulas for density estimation apply by replacing p(y|x, θ) with p(x|θ) as done above to deﬁne ensemble
predictors.
Given a distribution q(θ), we deﬁne the m-sample log-loss
ℓ(x, y, θ1, ..., θm) = −log(p(y|x, θ1, ..., θm)),
which measures the log-loss of the m-sample predictor (13).
Example 1: To illustrate the difference between the frequentist and Bayesian learning paradigms, in Figure 1, we
consider the problem of estimating the probability distribution
of the channel gain of a scalar wireless channel. This is
an example of unsupervised learning for density estimation.
Let us assume that the channel gain density follows a true,
unknown, target distribution given by the mixture of two
Gaussians ν(x) = 0.7N(x|0.5, 0.05) + 0.3N(x|0.8, 0.02).
This is shown in the top part of Figure 1 as a dashed green
line. The two components may correspond to line-of-sight
(LOS) and non-line-of-sight (NLOS) propagation conditions
 . We ﬁx a Gaussian model class p(x|θ) = N(x|θ, 0.25)
and a prior distribution p(θ) = N(θ| −5, 5). Therefore the
model class is misspeciﬁed since there does not exists a value
θ such that p(x|θ) = ν(x); on the other hand, a Gaussian
mixture model would be well speciﬁed in this scenario. Given
the 5 data points represented as crosses in the top part of
Figure 1, the estimated distribution obtained by frequentist
learning is reported as a dash-dotted black curve in the top
panel. In contrast, Bayesian learning returns the posterior
distribution (11), which in turn yields the ensemble density
(12). The distributions are shown in the top and bottom parts of
the Figure 1, respectively for inverse temperature parameters
β = {1, 0.1}. The Bayesian predictive distribution is still
unimodal but it has a larger variance, which results from the
combination of multiple Gaussian models according to the
Bayesian posterior that does not reduce to a point distribution
in virtue of the KL regularization term whose inﬂuence is
controlled by β.
III. ROBUST BAYESIAN LEARNING
As we have seen in the previous section, Bayesian learning
optimizes the free energy by tackling problem (7). By (8),
the free energy provides a bound on the population loss
as a function of the training loss when averaging over the
distribution q(θ) in the model parameter space . This
approach has two important limitations:
• Model misspeciﬁcation: The bound (8) provided by the
free energy is known to be loose in the presence of model
misspeciﬁcation. Model misspeciﬁcation occurs when the
assumed probabilistic model p(y|x, θ) cannot express the
conditional target distribution ν(y|x) = ν(x, y)/ν(x),
where ν(x) =
ν(x, y)dy. This causes the β-tempered
posterior distribution to be generally suboptimal when the
model is misspeciﬁed . There exist several techniques
to mitigate the effect of misspeciﬁcation, for example by
using tighter approximations of the ensemble risk ,
 , using pseudo-likelihoods or modeling aleatoric
uncertainty .
• Discrepancy between sampling and target distributions:
The sampling distribution νs(z) that underlies the generation of the training data set D may not match the
target distribution ν(x) used to test the trained model. A
common model for this mismatch assumes the presence
of outliers in the training data . This discrepancy is
not accounted for in the derivation of the free energy
criterion, causing Bayesian learning to be suboptimal in
the presence of outliers . For this reason, alternative
scoring rules, such as the Brier score , and divergences, such as β-divergences , and γ-divergence
 , have been considered to mitigate the presence
of anomalous training data points.
We observe that the two causes of suboptimality outlined in the
previous paragraph are distinct. In fact, model misspeciﬁcation
may reﬂect the ignorance of the learner concerning the data
generation process, or it may be caused by constraint on
the computational resources of the device implementing the
model. In contrast, the presence of outliers amounts to an
inherent source of distortion in the data, which cannot be
removed even if the learner acquired more information about
the data generation process or more computing power. In this
section, we review robust Bayesian learning solutions that
address these two issues.
We emphasize that robustness is a multifaceted property
that may refer to aspects other than model misspeciﬁcation
and outliers, such as covariate shift , adversarial attacks
at inference time , or poisoning attacks in distributed
learning settings – . In this paper, we focus solely on
model misspeciﬁcation and outliers, given the importance of
these aspects for applications in communication engineering.
Therefore, when referring to robust Bayesian learning we will
implicitly consider only robustness with respect to these two
impairments.
A. (m, 1)-Robust Bayesian Learning Against Model Misspeciﬁcation
In this subsection, we describe a recently proposed method
that makes Bayesian learning robust against model misspeciﬁcation . We start by providing a formal deﬁnition of
misspeciﬁcation. Recall that we are focusing on supervised
learning, but the presentation also applies to density estimation by replacing the discriminative model p(x|y, θ) with the
density model p(x|θ).
(Misspeciﬁcation).
{p(y|x, θ) : θ ∈Θ} is said to be misspeciﬁed with respect
to the target distribution ν(x, y) whenever there is no model
parameter vector θ ∈Θ such that ν(y|x) = p(y|x, θ), where
ν(y|x) is the conditional target distribution obtained from the
joint target distribution ν(x, y).
Under model misspeciﬁcation, the free energy criterion has
been shown to yield a loose bound (8) on the population loss
obtained by the ensemble predictor (12) .
To address this problem, the m-sample free energy criterion
was introduced in , whose minimization yields (m, 1)robust learning. The reason for the notation “(m, 1)” will be
made clear in the next two subsections. The key observation
underlying this approach is that the training loss ˆL(θ, D) in
the standard free energy (5) does not properly account for the
performance of ensemble predictors. In fact, the log-loss of an
m-sample ensemble predictor is given by ℓ(x, y, θ1, . . . , θm)
in (16), and not by the log-loss ℓ(x, y, θ) in (9). This is
not an issue when the model is well speciﬁed, since, in
this case, the minimization of the free energy (5) yields the
posterior distribution (11), which is the optimal solution to
the learning problem when one trusts the model to match the
data generation distribution . In contrast, in the presence
of model misspeciﬁcation, the optimal solution is generally
not given by the posterior distribution (11), and better predictive performance can be obtained by directly minimizing
the prediction loss ℓ(x, y, θ1, . . . , θm) in (16) accrued by the
ensemble predictor (13). To account for this performance
metric in the formulation of Bayesian learning, reference 
introduced the m-sample free energy, in which the training loss
ˆL(θ, D) in the free energy (5) is replaced by the m-sample
training loss
ˆL(θ1, . . . , θm, D) =
ℓ(x, y, θ1, ..., θm)
p(y|x, θi)
Furthermore, the m-sample free energy is deﬁned as
J m(q) = Eq(θ)⊗m[ ˆL(θ1, . . . , θm, D)] + m
β KL(q(θ)||p(θ)),
in which the m-sample training loss is averaged over the
distribution of the m samples θ1, ..., θm ∼q(θ)⊗m used in
the ensemble predictor (13). We note that the m-sample free
energy has an additional parameter m and it coincides with
the standard free energy (5) for m = 1.
Finally, the (m, 1)-robust Bayesian learning problem is
deﬁned by the optimization
Intuitively, according to the discussion above, the solution of
problem (19) yields an ensemble predictor (15) that is more
robust to model misspeciﬁcation since it directly accounts
for the performance of the ensemble predictor. This way, the
ensemble predictor can compensate for a model mismatch
by averaging over the predictions of several models via the
optimized distribution q(θ). This key point is illustrated with
the next example.
Example 1 (continued): Let us return to Example 1 of
Figure 1. The problem is characterized by model misspeciﬁcation since the target distribution ν(x) is a mixture of
two Gaussian components, while the model class comprises
only unimodal Gaussian models p(x|θ). In contrast to standard
Bayesian learning, the ensemble density (13) obtained with the
distribution q(θ) returned by (m, 1)-robust Bayesian learning
for m = 10 (red curve in the top panel) is able to take
advantage of ensembling to approximate both the NLOS and
LOS components of the target distribution.
−logt(p(y|x))
t = 1 (log-loss)
Increasing t
Fig. 2: t-log-loss −logt(p(y|x) as a function of the predictive
probability p(y|x) for different values of t. For t = 1, the
t-log-loss coincides with the conventional log-loss. A sample
(x, y) with a low predictive probability p(y|x) →0 is assigned
an unbounded log-loss value. In contrast, for t < 1, the t-logloss is bounded by (1−t)−1, limiting the inﬂuence of outliers.
B. (1, t)-Robust Bayesian Learning Against Outliers
We now turn to methods that make Bayesian learning robust
against discrepancies between training and testing conditions.
Speciﬁcally, we adopt the standard model introduced in the
classical paper , which accounts for the mismatch between
the distributions of the training data and of the test data
via an additive error that can be interpreted in terms of
the presence of outliers in the training set. Accordingly, we
assume that the training data is generated from a sampling
distribution νs(x, y) that is given by the weighted sum of the
target, testing, distribution ν(x, y) and of an out-of-distribution
(OOD) distribution ξ(x, y). The OOD component models the
said mismatch between training and testing distributions. A
formal deﬁnition follows.
Assumption 1 (Outliers). The sampling distribution is given
νs(x, y) = (1 −ϵ)ν(x, y) + ϵξ(x, y)
where ν(x, y) is the target distribution; ξ(x, y) is the OOD
distribution; and ϵ ∈ denotes the mismatch error.
According to model (20), the training data set can be interpreted as containing, on average, a fraction ϵ of outliers, which
are drawn from the distribution ξ(x, y). In contrast, testing is
done based on data from the target distribution ν(x, y). In
this regard, in order for model (20) to be meaningful, one
typically assumes that the OOD measure ξ(x, y) is large for
pairs of (x, y) at which the target measure ν(x, y) is small.
This ensures that outlying data points (x, y) ∼ξ(x, y) tend to
be in part of the domain that is not covered by the target
distribution. Therefore, the model (20) can be equivalently
stated as assuming that the training data contains a fraction ϵ of
training points that are sampled from low-probability regions
of the testing distribution.
The performance of both frequentist and Bayesian learning
is known to be sensitive to outliers when the log-loss is
adopted to evaluate the training loss. This sensitivity is caused
by the unbounded value of the log-loss (9) when evaluated
on anomalous data points to which the model assigns low
probabilities p(y|x, θ). This is illustrated in Figure 2 for a
general conditional distribution p(y|x). A number of papers
have proposed to mitigate the effect of outliers by replacing
the log-loss in favor of more robust losses – , .
A well-explored solution is to adopt the t-log-loss. For for
a model p(y|x, θ), the t-log-loss is deﬁned as
−logt(p(y|x, θ)) := −
 p(y|x, θ)1−t −1
for p > 0,
where t ∈[0, 1) ∪(1, ∞); and
−log1(p(y|x, θ)) := −log(p(y|x, θ)) for p > 0.
By (22) the standard log-loss is obtained with t = 1, while for
t < 1 the associated loss function is bounded by (1 −t)−1, as
shown in Figure 2.
Using the t-log-loss in lieu of the standard log-loss in the
training loss (1) we obtain the t-training loss
ˆLt(θ, D) = −
logt (p(y|x, θ)) ,
which leads to the corresponding t-free energy
Jt(q) = Eq(θ)[ ˆLt(θ, D)] + 1
β KL(q(θ)||p(θ)).
Accordingly, (1, t)-robust Bayesian learning is deﬁned by the
minimization 
The solution of problem (25) becomes more robust to outliers
as t is reduced below 1 towards 0. In fact, with a t value
close to 1, if a few, outlying, training points are assigned
an incorrect probability by the model, the overall training
loss tends to be large (see Figure 2), causing conventional
Bayesian learning to be sensitive to outliers. In contrast, as t
decreases, the t-log-loss does not penalize as much models that
do not properly “cover” outlying training points, enhancing
robustness to outliers.
Example 2: To highlight the effect of outliers, in Figure
3, we consider the same channel gain estimation problem
described in Example 1, but we now assume that the original
training data set (black crosses) is contaminated by an outlying
data point (red cross). The (m, 1)-robust Bayesian learning
solution (red curve with m = 10) is based on the standard
log-loss and is observed to be signiﬁcantly affected by the
presence of the outliers. As a result, the estimated distribution
for the (m, 1)-robust Bayesian learning concentrates a relevant
fraction of its mass around the outlier. In contrast, the (1, t)robust Bayesian solution (gray curve) with t = 0.4 is less
inﬂuenced by the outlying data point. However, like Bayesian
learning, it is not able to take advantage of ensembling and
to approximate both LOS and NLOS components. This observation justiﬁes the (m, t)-robust Bayesian learning approach
described next.
Channel Gain [dB]
p(x|θfreq) and p(x|q)
Target distribution samples
Target distribution
(10, 1)-Robust Bayesian
(1, 0.4)-Robust Bayesian
(10, 0.4)-Robust Bayesian
Target distribution samples
(10, 1)-Robust Bayesian
(1, 0.4)-Robust Bayesian
(10, 0.4)-Robust Bayesian
Fig. 3: Estimated distribution over channel gains (top panel)
and posterior distribution over the model parameter θ (bottom
panel) of a density model trained following (m, 1)-robust
Bayesian learning, the (1, t)-robust Bayesian learning and
the (m, t)-robust Bayesian learning. The training data set,
represented as crosses, comprises samples from the sampling
distribution ν(x) (black) and an outlier (red).
C. (m, t)-Robust Bayesian Learning Against Model Misspeciﬁcation and Outliers
To concurrently address model misspeciﬁcation and the
presence of outliers, reference formally introduced (m, t)robust Bayesian learning, which minimizes a free energy
metric integrating both m-sample predictors and the t-log-loss.
To describe it, let us ﬁrst deﬁne the (m, t)-training loss
ˆLt(θ1, . . . , θm, D) = −
p(y|x, θi)
which is obtained from the m-sample training loss (17) by
replacing the log-loss with the t-log-loss. The (m, t)-free
energy is accordingly deﬁned as
t (q) = Eq(θ)⊗m[ ˆLt(θ1, . . . , θm, D)] + m
β KL(q(θ)||p(θ)),
and (m, t)-robust Bayesian learning amounts to the minimization
Note that (m, t)-robust Bayesian learning recovers standard
Bayesian learning by setting t = 1 and m = 1, as well as
(m, 1)-robust Bayesian learning with t = 1 and the (1, t)robust Bayesian learning for m = 1.
Example 2 (continued): Returning to Example 2, we now
consider the performance of (m, t)-robust Bayesian learning
for m = 10 and t = 0.4. The resulting distribution (blue
line) with m = 10 and t = 0.4 seems to be able to better
to approximate the target distribution by reducing the effect
of the outliers, while also taking advantage of ensembling to
combat misspeciﬁcation.
IV. ROBUST AND CALIBRATED AUTOMATIC MODULATION
CLASSIFICATION
As a ﬁrst application of robust Bayesian learning we
consider the AMC problem. This is the task of classifying
received baseband signals in terms of the modulation scheme
underlying their generation. The relation between the received
signal and the chosen modulation scheme is often mediated by
complex propagation phenomena, as well as hardware nonidealities at both the receiver and the transmitter side. As a
result, model-based AMC methods often turn out to be inaccurate because of the overly simplistic nature of the assumed
models . In contrast, machine learning based AMC has
been shown to be extremely effective in correctly classifying
received signals based on signal features autonomously extracted from data . We refer to and references therein
for a comprehensive overview.
All prior works on learning-based AMC, reviewed in ,
have adopted frequentist learning. In this section, we consider
the practical setting in which AMC must be implemented
on resource-constrained devices, entailing the use of small,
and hence mismatched, models; and the training data sets are
characterized by the presence of outliers due to interference.
A. Problem Deﬁnition and Performance Metrics
The AMC problem can be framed as an instance of supervised classiﬁcation, with the training data set D comprising
pairs (x, y) of discrete-time received baseband signal x and
modulation label y, with Y being the set of possible modulation schemes. Each training data point (x, y) ∈D is obtained
by transmitting a signal with a known modulation y ∈Y over
the wireless channel, and then recording the received discretetime vector x at the receiver end. The outlined procedure
determines the unknown sampling distribution νs(x, y).
We evaluate the performance of AMC on a testing data
set Dte in terms of accuracy and calibration. To describe
calibration performance metrics, let us consider a predictive
distribution p(y|x), which may be the frequentist distribution
p(y|x, θfreq), or the ensemble distribution (13) in the cases
of Bayesian learning and robust Bayesian learning. A hard
prediction ˆy is obtained as the maximum-probability solution
ˆy = arg max
The corresponding conﬁdence score assigned by the predictor
p(y|x) is the probability p(ˆy|x) ∈ . The calibration
of a classiﬁer measures the degree to which the conﬁdence
score p(ˆy|x) ∈ reﬂects the true probability of correct
classiﬁcation P[ˆy = y|x] conditioned on the input x.
We adopt the standard reliability diagrams and the
expected calibration error as diagnostic tools for the calibration
(4, t)-Robust Bayesian
(1, t)-Robust Bayesian
Frequentist
Frequentist
(4, t)-Robust Bayesian
(1, t)-Robust Bayesian
Fig. 4: Average test accuracy and ECE for AMC over the
DeepSIG: RadioML 2016.10A data set for frequentist and
(m, t)-robust Bayesian learning as a function of the parameter
t. The test set is free from interference, while the training set
is subject to interference (ϵ = 0.5).
performance . Both metrics require binning the output of
the classiﬁer conﬁdence score p(ˆy|x) into M intervals of equal
size, and then grouping the testing data points (x, y) ∈Dte
based on the index of the bin for the conﬁdence score p(ˆy|x).
For each bin Bm, the within-bin accuracy is deﬁned as
1{ˆy = y},
which measures the fraction of test samples within the bin that
are correctly classiﬁed; and the within-bin conﬁdence as
Conf(Bm) =
which is the average conﬁdence level for the test samples
within the bin.
The reliability diagram plots within-bin accuracy and
within-bin conﬁdence as a function of the bin index m.
As a result, a reliability diagram visualizes the relation between conﬁdence and accuracy of a predictor, establishing
whether a classiﬁer is over-conﬁdent (Conf(Bm) > Acc(Bm)),
under-conﬁdent (Conf(Bm) < Acc(Bm)) or well-calibrated
(Conf(Bm) ≈Acc(Bm)).
The expected calibration error (ECE) summarizes the calibration performance of a classiﬁer as a single number obtained
as the weighted sum of the absolute difference between withinbin accuracy and within-bin conﬁdence, namely
|Conf(Bm) −Acc(Bm)| .
By this deﬁnition, one can generally conclude that a lower
ECE indicates a better calibrated predictor.
B. Data Set
We adopt the DeepSIG: RadioML 2016.10A data set .
This is a synthetic data set that contains 220K vectors of I/Q
samples of signals comprising 8 digital modulation schemes
(BPSK, QPSK, 8PSK, 16QAM, 64QAM, BFSK, CPFSK) and
3 analog modulations (WB-FM, AM-SSB, AM-DSB). We
focus on the problem of classifying the 8 digital modulation
schemes using received signals recorded at different SNR
levels ranging from 0 dB to 18 dB. To account for a mismatch
between training and testing conditions under model (20), we
focus on a scenario in which an additional transmitter is occasionally active during training data collection, and it is later
removed or deactivated when testing takes place. This way, the
training data set comprises informative training examples, not
affected by interference, and uninformative training examples,
for which it is impossible to assign an unambiguous label
given the simultaneous presence of multiple signals.
Formally, we model the presence of interference during
training by generating an ϵ-“contaminated” version of the
original data set. In it, with probability ϵ ∈[0, 1), the original
training sample x is summed to an interfering signal x′
picked uniformly at random from the data set. Note that the
interfering signal can be possibly generated from a different
modulation scheme. According to the contamination model of
Assumption 1, the samples affected by interference represent
outliers distributed according to ξ(y, x), since no interference
is assumed during testing.
With regards to the adopted scenario, we emphasize that
the model (20) is not limited to situations in which deviations
between testing and training distributions are characterized by
additional interference. In particular, it may be that interference affects the testing phase (as described by distribution
ν(x, y)) and not the training phase (as described by distribution νs(x, y)), or that the training phase is occasionally
affected by a different type of interference.
We consider 30% of the available samples for training;
20% of the samples for validation; and the remaining 50%
for testing. The use of a small training data set is intentional,
as we wish to focus on a regime characterized by data scarcity.
C. Implementation
We consider a probabilistic model p(y|x, θ) represented by
a lightweight convolutional neural network (CNN) architecture
comprising of two convolutional layers followed by two linear
layers with 30 neurons each. The ﬁrst convolutional layer has
16 ﬁlters of size 2 × 3, and the second layer has 4 ﬁlters
of size 1 × 2. We adopt the Exponential Linear Unit (ELU)
activation with parameter α = 1. The lightweight nature of
the architecture is motivated by the strict computational and
memory requirements at network edge devices. As a result, the
CNN model is generally misspeciﬁed, in the sense that, following Deﬁnition 1, the complex relation between received signal
and chosen modulation scheme cannot be exactly represented
using the model. In fact, the probabilistic model p(y|x, θ) is
obtained here by composing the output of a CNN model fθ(x)
with the softmax function. When the CNN model fθ(x) is
capacity constrained, this class of predictive distribution may
well not contain the ground-truth distribution p(y|x) relating
the received signal x and the modulation scheme y, as the latter
may be more complex due to noise, transmitter and receiver
circuit non-idealities, and propagation phenomena.
Perfect Calibration
(a) Frequentist Learning
Perfect Calibration
(b) Robust Bayesian Learning
Fig. 5: Reliability diagrams for frequentist (left) and (m, t)robust Bayesian learning for m = 4 and t = 0.7 (right) for
AMC over the DeepSIG: RadioML 2016.10A data set .
In the training data set, half of the samples are affected by
interference, i.e., ϵ = 0.5. For Bayesian learning, we adopt
a Gaussian variational distribution q(θ) = N(θ|µ, Σ) over
the CNN model parameter vector θ, which has dimension
16404 and it includes all the weights of the neural network.
Accordingly, the mean µ and diagonal covariance matrix Σ
are optimized, while we ﬁx the prior p(θ) = N(θ|0, I).
Optimization for both frequentist and Bayesian methods is
carried out via Adam with a learning rate η = 0.001, and the
reparametrization trick is implemented for Bayesian learning
 . In our experiments we set β = 0.01. The number
of samples used to evaluate the ensemble prediction (13) is
m = 10. Note that this may differ from the value of m used
to deﬁne the training criterion.
D. Results
In Figure 4 we report the average test accuracy and ECE
for frequentist and (m, t)-robust Bayesian as a function of
t for m = 1 and m = 4. These two values are chosen
to highlight the difference between (1, t)-robust Bayesian
learning (m = 1) and (m, t)-robust Bayesian learning for
m > 1. Furthermore, when estimating the m-sample training
loss we set m = 4 as we do not appreciate performance
gains for larger values. The main observation is that, with
suitably chosen parameters (m, t), robust Bayesian learning
can outperform standard frequentist learning both in terms
of accuracy and calibration for t < 1. The smallest ECE is
obtained by robust Bayesian learning for t = 0.7, and it is ﬁve
times smaller compared to the one obtained using conventional
Bayesian learning (t = 1). Overall, (m, t)-robust Bayesian
paradigm is able to improve the ﬁnal accuracy by 5% and to
reduce the ECE by ﬁve times via suitable choice of parameters
To further elaborate on the calibration performance, in
Figure 5 we compare the reliability diagrams obtained via
frequentist and (m, t)-robust Bayesian learning for m = 4 and
t = 0.7. While frequentist learning provides under-conﬁdent
predictions, robust Bayesian learning offers well-calibrated
predictions that consistently offer a small discrepancy between
accuracy and conﬁdence levels.
TABLE I: Test negative log-likelihood for RSSI localization
(34) with t = 1 and no outliers (ϵ = 0). The case m = 1
corresponds to conventional Bayesian learning.
SigfoxRural
1.70 ± 1.03
−0.43 ± 0.61
−1.59 ± 0.36
4.33 ± 2.32
2.25 ± 1.69
2.17 ± 1.76
4.86 ± 1.02
2.74 ± 0.46
1.44 ± 0.33
(a) Bayesian Learning
(b) Robust Bayesian Learning
Fig. 6: Predictive distribution p(y|x) as a function of the
estimated position of the transmitter y, where x is the RSSI
vector associated to the true location shown as a green cross.
The black dots correspond to the locations recorded in the
SigfoxRural data set. The left panel shows the predictive
distribution for Bayesian learning, while the right panel depicts
the predictive distribution for (m, t)-robust Bayesian learning
with m = 10 and t = 1. No outliers are considered in the
training set, i.e., ϵ = 0.
V. ROBUST AND CALIBRATED RSSI-BASED
LOCALIZATION
In this section, we turn to the problem of localization.
In outdoor environments, accurate localization information
of a wireless device can be obtained leveraging the global
navigation satellite system (GNSS). However, the performance
of satellite-based positioning is severely degraded in indoor
environments , and its power requirements are not compatible with Internet-of-Things (IoT) application characterized
by ultra-low power consumption . For this reason, alternative techniques have been investigated that rely on so-called
channel ﬁngerprints, i.e., feature extracted from the received
wireless signals .
Among such methods, the use of received signal strength
indicators (RSSI) measured at multiple wireless access points
has been shown to provide an accessible, yet informative,
vector of features. Owing to the complexity of deﬁning
explicit models relating the device location y ∈Y with the
RSSI-measurements vector x ∈X, data-driven RSSI-based
localization techniques have been recently explored , .
The outlined prior work in this area has focused on machine
learning models trained using the conventional frequentist
In this section, we study a setting in which the training data
set is collected using noisy, e.g., crowd-sourced, ﬁngerprints.
As such, the training set contains outliers. Furthermore, we
aim at developing strategies, based on robust Bayesian learning, which can offer accurate localization, while also properly
quantifying residual uncertainty.
A. Problem Deﬁnition and Performance Metrics
The RSSI-based localization problem is a supervised regression task. In it, a training sample (x, y) is obtained
by measuring the RSSI ﬁngerprint y corresponding to the
transmission of a reference signal at a device located at a
known position x. The general goal is to train a machine
learning model p(y|x) to predict the location y associated to
a RSSI vector x so as to optimize accuracy and uncertainty
quantiﬁcation.
Given a test data set Dte and assuming that the predictive
location is the mean of the predictive distribution, i.e. ¯y =
Ep(y|x)[y], we adopt the mean squared error (MSE) metric
MSE(Dte, p) =
as a measure of accuracy. Furthermore, in order to estimate
the residual uncertainty about y predicted by the model, we
adopt the negative test log-likelihood 
NLL(Dte, p) = −
log(p(y|x)).
Note that the negative log-likelihood is large if the model
assigns a small probability density p(y|x) to the correct output
B. Data Sets
We experiment on different publicly available RSSI ﬁngerprint data sets, encompassing both outdoor and indoor
conditions:
• The SigfoxRural data set comprises 25, 638 Sigfox
messages measured at 137 base stations and emitted from
vehicles roaming around a large rural area (1068 km2)
between Antwerp and Gent.
• The UTSIndoorLoc data set contains 9494 WiFi
ﬁngerprints sampled from 589 access points inside the
FEIT Building at the University of Technology of Sydney,
covering an area of 44, 000 m2.
• The UJIIndoorLoc data set contains 21, 049 WiFi
ﬁngerprints measured at 520 access points and collected
from 3 building of the Jaume I University, spanning a
total area of 108, 703 m2.
To model the presence of outliers, we modify the training data
sets described above, producing ϵ-contaminated data sets D as
per Deﬁnition 2. This is done by replacing the target variable y
for a fraction ϵ of the data points (x, y) ∈D with a uniformly
random location y within the deployment area.
C. Implementation
We consider a model class speciﬁed by a Gaussian likelihood p(y|x, θ) = N(y|fθ(x), 0.01), where the mean fθ(x)
is the output of a fully connected neural network with two
hidden layers, each with 50 neurons with ELU activations
and a total of 19004 parameters. Despite the expressive power
of the neural network model, each model p(y|x, θ) in this
class can only account for unimodal, Gaussian distributed,
residual uncertainties around the estimated position fθ(x).
Therefore, whenever the residual uncertainty about the receiver
location is multimodal, the model class is misspeciﬁed by
Deﬁnition 1. We emphasize that this situation is distinct
from that studied in the previous section, in which model
misspeciﬁcation was caused by model capacity limitations. In
fact, here, misspeciﬁcation holds irrespective of the capacity
of the neural network model fθ(x). As we will see, given the
complex relation between RSSI vector and location, particularly when the number of RSSI measurements is sufﬁciently
small, residual uncertainty tends to be multimodal, making this
an important problem. Training for frequentist and Bayesian
learning is carried out as described in the previous section,
and ensembling uses m = 50 samples during testing time.
D. Results
We start by considering the case in which there are no
outliers, i.e., ϵ = 0, thus focusing solely on the problem of
misspeciﬁcation. In Figure 6, we plot the predictive distribution obtained via Bayesian learning (m = 1, left panel)
and robust Bayesian learning with m = 10 and t = 1
(right panel) for a testing sample x corresponding to the
position shown as a green cross. The black dots correspond
to the positions covered by the training set in the SigfoxRural
data set. The resulting predictive distribution for conventional
Bayesian learning provides a poor estimation of the true device
position, and is unable to properly quantify uncertainty. In
contrast, robust Bayesian learning is able to counteract model
misspeciﬁcation, producing a more informative predictive distribution. The distribution correctly suggests that the receiver
can be in two possible areas, one of which indeed containing
the true node location.
To further elaborate on the capacity of robust Bayesian
learning for uncertainty quantiﬁcation, in Table I we report
the negative log-likelihood (34) attained by Bayesian learning
(m = 1), as well as by robust Bayesian learning with t = 1
and m = 2 or m = 10 on the three data sets. Increasing
the value of m is seen to yield lower negative log-likelihood
scores, conﬁrming that robust Bayesian learning provides a
more precise quantiﬁcation of uncertainty.
We now introduce outliers by carrying out training on
contaminated data sets with different levels of contamination
ϵ. Recall that the trained models are tested on a uncorrupted
(ϵ = 0) test data set Dte. In Figure 7, we plot the test MSE (33)
of frequentist learning, robust frequentist learning based on the
minimization of the t-log-loss (21) with t = 0.99 and (m, t)robust Bayesian learning with m = 10 and t ∈{1, 0.96} as a
function of ϵ. For the robust learners, the parameter t is tuned
by choosing the best performing value in the range (1, 0.95].
The MSE of frequentist learning and (10, 1)-robust Bayesian
learning are seen to degrade signiﬁcantly for increasing values
of ϵ. The performance loss is particularly severe for (m, 1)robust Bayesian learning. This is due to the mass-covering
behavior entailed by the use of m-sample training loss, which
in this case becomes detrimental due to the presence of
outliers. In contrast, both robust frequentist with t = 0.99 and
robust Bayesian learning with t = 0.96 are able to counteract
the effect of outliers, retaining good predictive performance
even in case of largely corrupted data sets.
VI. ROBUST AND CALIBRATED CHANNEL SIMULATION
The design of communication systems has traditionally
relied on analytical channel models obtained via measurements
campaigns. Due to the complexity of multipath propagation
scenarios, in recent years generative machine learning models
have introduced as an alternative to analytical models. Generative models can be trained to produce samples that mimic
hard-to-model channel conditions. Applications of deep generative models in the form of variational autoencoders (VAEs)
 and generative adversarial networks (GANs) were
speciﬁcally reported in the context of end-to-end simulation
of wireless systems in , and for channel modeling in
 – for earlier applications to satellite communications.
The outlined prior work has focused on frequentist methods
and has assumed the availability of uncorrupted data sets that
are free from outliers. In this section, we explore the use
of robust Bayesian learning to account for both outliers and
model misspeciﬁcation.
A. Problem Deﬁnition and Performance Metrics
Generative models are trained in an unsupervised manner
by assuming the availability of a training set D of examples
x corresponding to channel impulse responses. We focus on
VAEs, i.e., on generative models with latent variables. VAEs
comprise a parameterized encoder q(h|x, θe), mapping an
input x ∈X into a lower-dimensional latent vector h ∈H; as
well as a parameterized decoder p(x|h, θd) that reconstructs
the input sample x ∈X from the latent representation h ∈H.
Note that the vector of model parameters encompasses both
encoding and decoding parameters as θ = (θe, θd).
Let us deﬁne as p(h) a ﬁxed prior distribution on the
latent variables h. Once training is complete, samples x of
channel responses can be generated from the model as follows.
For frequentist learning, given the trained model θfreq, one
generates a sample h ∼p(h) for the latent vector, and then
produces a channel sample x ∼p(x|h, θfreq). For Bayesian
learning, given the optimized distribution q(θ), we produce a
random sample θ ∼q(θ) and then generate channel sample
x ∼p(x|h, θd). The role of the encoder q(h|x, θe) will be
made clear in Section VI-C when discussing the training
According to the discussion in the previous paragraph, the
channel distribution implemented by the model is given by
p(x) = Ep(h)[p(x|h, θfreq
Mean Squared Error
(10, 1)-Robust
(0.99)-Robust Frequentist
Frequentist
(10, 0.96)-Robust
(a) SigfoxRural
(10, 1)-Robust
Frequentist
(0.99)-Robust Frequentist
(10, 0.96)-Robust
(b) UTSIndoor
(10, 1)-Robust
Frequentist
(0.99)-Robust Frequentist
(10, 0.96)-Robust
(c) UJIIndoor
Fig. 7: Test mean squared error (33) as a function of the corruption level ϵ of the standard frequentist solution based on the
log-loss, the robust frequentist solution based on the t-log-loss with t = 0.99, and the (m, t)-robust Bayesian learning with
m = 10 and t = {1, 0.96}. As ϵ increases, the training data sets are increasingly affected by outliers.
for frequentist learning; and by
p(x) = Ep(h)q(θd)[p(x|h, θd)]
for Bayesian learning. Note that the average is taken only
over the latent vector h ∼p(h) for frequentist learning; while
in Bayesian learning the expectation is also taken over the
optimized distribution q(θd) for the decoder’s parameters θd.
To evaluate the performance of the generative model, we
consider two different metrics accounting for accuracy and
uncertainty quantiﬁcation. Accuracy is measured by the “distance” between the target distribution ν(x) and the distribution
p(x) produced by the model. We measure the “distance”
between ν(x) and p(x) via the maximum-mean discrepancy
(MMD) , which is deﬁned as
MMD(p, ν) =Ex,x′∼p(x)[k(x, x′)] + Ex,x′∼ν(x)[k(x, x′)]
−2Ex∼ν(x),x′∼p(x)[k(x, x′)]
where k(x, x′) is a positive deﬁnite kernel function. In the
experiments reported below, we have approximated the MMD
based on empirical averages. These are evaluated using samples from distribution p(x), which are generated as explained
above, as well as samples from the sampling distribution ν(x),
i.e., examples from the training set D. Moreover, we use the
Gaussian kernel k(x, x′) = N(∥x −x′∥|0, 1).
To evaluate the performance in terms of uncertainty quantiﬁcation, we focus on the problem of out-of-distribution (OOD)
detection (see, e.g., ). A well-calibrated model p(x), when
fed with an input x, should return a small value if x is an
OOD sample, that is, if it has a low target distribution ν(x).
To obtain a quantitative measure, we consider the task of
distinguishing between samples drawn from the target distribution ν(x) and from the OOD distribution ξ(x). Speciﬁcally,
we adopt the model probability distribution p(x) as the test
statistic, classifying x as in-distribution (ID) if p(x) is larger
than some threshold γ and as OOD otherwise. As in ( ),
we take the area under the receiver operating characteristic
curve (AUROC) score for this test as a measure of how
distinguishable the two samples are. The AUROC metric is
obtained by integrating the ROC traced by probability of
detection versus probability of false alarm as the threshold γ
is varied. A larger AUROC indicates that the model provides a
better quantiﬁcation of uncertainty, as reﬂected in its capacity
to detect OOD samples against ID samples.
B. Data Set
We consider the simulation of the magnitudes of a
frequency-selective channel response x ∈R128 that mimics the
target distribution ν(x) deﬁned by the 3GPP TDL-A channel
model distribution with a delay spread of τ = 100
ns. In particular we generate 1000 TDL-A channel responses
using Matlab’s 5G Toolbox . Outliers are accounted for by
constructing an ϵ-contaminated training set D that contains a
fraction ϵ = 0.2 of samples distributed according to the same
channel model but with a larger delay spread τ = 300 ns (see
the top row in Fig. 8).
C. Implementation
For models with latent variables, the direct adoption of
the log-loss generally yields intractable optimization problems
(see, e.g., ). To address this problem, training of VAEs
replaces the training loss (1) with the variational lower bound
ˆLV AE(θ, D) =
Ep(h|x,θe)[log(p(x|h, θd)]
KL(p(h|x, θd)||p(h)),
which involves the use of the encoder model p(h|x, θe).
Accordingly, the frequentist training objective is modiﬁed as
ˆLV AE(θ, D),
(a) TDL-A τ = 100ns
(b) TDL-A τ = 300ns
(c) Frequentist Learning
(d) (4, 0.7)-Robust Bayesian Learning
Fig. 8: The top row shows a sample of the magnitude for the TDL-A channel response given a delay spread τ = 100ns in
panel (a), while an outlier sample corresponding to the larger delay spread τ = 300 ns is depicted in panel (b). The bottom
row reports a sample from the trained model for frequentist learning in panel (c) and for (4, 0.7)-robust Bayesian learning in
panel (d).
while Bayesian learning addresses the problem
ˆLV AE(θe, θd, D)
β KL(q(θ)||p(θ)).
The robust free energy metrics are obtained in a similar
manner, yielding the following formulation for (m, t)-robust
Bayesian learning
(θ1, ..., θm, D)=
Ep(h|x,θe) logt
p(x|h, θd,i)
KL(p(h|x, θd)||p(h)).
The prior latent variable distribution is p(h) = N(h|0, I5).
We implement both the encoder and the decoder by using
fully connected neural networks with a single hidden layer
with 10 units, for a total of 6438 parameters. Speciﬁcally, the
encoder distribution p(h|x, θe) = N(h|µθe(x), Σθe(x)) has
mean vector µθe(x) ∈R5 and diagonal covariance matrix
Σθe(x) ∈R5×5 obtained from the output of the neural
network. The decoder p(x|h, θd) = N(ˆx|µθd(h), σI128) has
mean vector µθd(h) obtained as the output of the neural
network with a ﬁxed variance value σ = 0.1. For Bayesian
learning, we optimize distribution q(θd) as in the previous
sections, while we consider a distribution q(θe) concentrated
at a single vector θe. Ensembling during testing time is carried
out with m = 50 samples.
D. Results
To start, in Figure 8 we illustrate a sample of the magnitude
for the TDL-A channel response given a delay spread τ = 100
ns in panel (a), while an outlier sample corresponding to the
larger delay spread τ = 300 ns is depicted in panel (b). The
bottom row of Figure 8 reports a sample from the trained
model for frequentist learning in panel (c) and for (4, 0.7)robust Bayesian learning in panel (d). Visual inspection of the
last two panels conﬁrms that (m, t)-robust Bayesian learning
can mitigate the effect of outliers as it reduces the spurious
multipath components associated with larger delays.
For a numerical comparison, Figure 9 compares frequentist
and (4, t)-robust Bayesian learning in terms of both accuracy
– as measured by the MMD – and uncertainty quantiﬁcation
– as evaluated via the AUROC. For t < 0.85 robust Bayesian
learning is conﬁrmed to have the capacity to mitigate the effect
of the outlying component, almost halving the MMD obtained
Frequentist
(4, t)-Robust Bayesian
Frequentist
(4, t)-Robust Bayesian
Fig. 9: Maximum mean discrepancy (MMD) and area under
receiving operating curve (AUROC) for frequentist learning
and (4, t)-robust Bayesian learning. Both models are trained
on a corrupted data set with (ϵ = 0.2).
by frequentist learning. Furthermore, robust Bayesian learning
has a superior uncertainty quantiﬁcation performance, with
gain increasing for decreasing values of t.
VII. CONCLUSION
This work has focused on the problem of ensuring that AI
models trained for wireless communications satisfy reliability
and robustness requirements. We have speciﬁcally addressed
two important problems: model misspeciﬁcation, arising from
limitations on the available knowledge about the problem and
on the complexity of the AI models that can be implemented
on network devices; and outliers, which cause a mismatch
between training and testing conditions. We have argued that
standard frequentist learning, as well as Bayesian learning,
are not designed to address these requirements, and we have
explored the application of robust Bayesian learning to achieve
robustness to model misspeciﬁcation and to the presence of
outliers in the training data set. Robust Bayesian learning
has been shown to consistently provide better accuracy and
uncertainty estimation capabilities in a range of important
wireless communication problems. These results motivate a
range of extension of robust Bayesian learning and applications. For instance, the integration of robust Bayesian learning
to the meta-learning framework, in order to enable robust and
sample effective learning, or the application of robust Bayesian
learning to higher layers of the protocol stack as a tool to
empower semantic communication.