Analysis of KITTI Data for Stereo Analysis
with Stereo Conﬁdence Measures
Ralf Haeusler and Reinhard Klette
The University of Auckland
Computer Science Department
Tamaki Campus
Abstract. The recently published KITTI stereo dataset provides a new
quality of stereo imagery with partial ground truth for benchmarking
stereo matchers. Our aim is to test the value of stereo conﬁdence measures (e.g. a left-right consistency check of disparity maps, or an analysis
of the slope of a local interpolation of the cost function at the taken
minimum) when applied to recorded datasets, such as published with
KITTI. We choose popular measures as available in the stereo-analysis
literature, and discuss a naive combination of these. Evaluations are carried out using a sparsiﬁcation strategy. While the best single conﬁdence
measure proved to be the right-left consistency check for high disparity
map densities, the best overall performance is achieved with the proposed naive measure combination. We argue that there is still demand
for more challenging datasets and more comprehensive ground truth.
Introduction
Computational stereo vision is in general an ill-posed problem, and solutions are
approximate in some sense. Situations with no unique solutions are commonly
found in recorded stereo images. Also with strong assumptions imposed to resulting disparity maps, such as piecewise smoothness, no stereo matcher can
guarantee correct results.
Widely used test datasets often use input data of limited complexity .
On these, recently developed stereo matchers deliver dense results of satisfactory quality. However, in practice, recorded real-world data are considerably
more challenging; see, e.g., . There may be no satisfactory solution to the
stereo problem in many situations displayed in these datasets. For treating unmatchable regions in disparity maps, there are some attempts to identify these
using so-called conﬁdence measures.
To evaluate quality of stereo matching results and accuracy of detected mismatches by means of conﬁdence measures, availability of accurate ground truth
is necessary. However, real-world stereo data in are provided without ground
truth. Recently published stereo-vision test data , in the paper brieﬂy called
KITTI data, show real-world scenes and come with ground truth provided by a
laser range-scanner. In this paper, we try to rate the challenge given by KITTI
data and quantify the value of conﬁdence measures in dealing with such datasets.
A. Fusiello et al. (Eds.): ECCV 2012 Ws/Demos, Part II, LNCS 7584, pp. 158–167, 2012.
⃝Springer-Verlag Berlin Heidelberg 2012
Analysis of KITTI Data with Stereo Conﬁdence Measures
Conﬁdence measures can be used in stereo processing to remove spurious disparity matches and interpolate these locations with surrounding disparity values.
The left-right consistency check is the most prominent example. Various conﬁdence measures have been proposed for stereo analysis; see . Experimental
studies of quantitative evaluations of conﬁdence measures have been conducted
(on very limited datasets) in . By using the KITTI data, we also discuss
conﬁdence measures on a larger set of real-world data.
Many conﬁdence measures are derived from the graph of cost functions. For
example, consider a parabola ﬁt of the cost function at the taken minimum and
its neighbourhood. The minimum of this parabola can be used to interpolate
disparity with subpixel accuracy. Parameter a deﬁnes the curvature of such a
parabola ax2 + bx + c, and this value is often considered to be a conﬁdence
measure. In it is applied with the intention to improve results for scene ﬂow
computations. An equivalent conﬁdence measure can be deﬁned using the slope
of an Okutomi ﬁt , and this may be more appropriate, depending on the stereo
matching cost function used.
However, a conﬁdence measure that only operates locally on the cost function
cannot assign, for example, low conﬁdence to ambiguous matches within repetitive textures of the source image. Improved results can be expected when the
costs of all disparity values are taken into account. This was demonstrated by 
for the 3D reconstruction of large outdoor scenes where conﬁdence is high if the
cost function has a single well-deﬁned minimum, and low if the cost function is
ﬂat or has multiple strong local minima. It is an open question which conﬁdence
measure has the best performance in a particular matching situation.
Very little has been published on improving the accuracy of conﬁdence measures by combining diﬀerent measures. For example, see for conﬁdence measures in optical ﬂow computations, using a supervised learning process of Gaussian mixture models with classiﬁcation criteria being the magnitude of the end
point error in optic ﬂow. However, it remained open whether this conﬁdence
measure (obtained as a result of classiﬁcation in feature space) could actually
improve accuracy. In , ﬂow data is assigned to algorithms found most suitable by classiﬁcation, based on a combination of ﬂow conﬁdence features such as
photo consistency and texture properties. used similar features for detecting
diﬃcult to match ﬂow regions in order to test whether these regions are occluded.
In both, classiﬁcation results are obtained using random decision forests.
In this paper we include a naive approach for conﬁdence measure combinations for stereo, which seems to be useful in increasing accuracy, i.e. is reducing
numbers of false positives. Also, we deﬁne a simple bound for limits of potential
accuracy improvements by measure combinations. We apply this measure and a
number of popular stereo conﬁdence measures to the recently published KITTI
dataset , and evaluate them using a similar sparsiﬁcation strategy as used in
Section 2 contains the deﬁnitions of conﬁdence measures used in this paper,
including a multiplicative combination and an upper bound for accuracy improvements. Section 3 presents the evaluation method for the performance of
R. Haeusler and R. Klette
measures and provides details about experiments conducted. Section 4 presents
results. Section 5 discusses limitations of conﬁdence measures and of the used
KITTI dataset. Section 6 concludes.
Conﬁdence Measures for Stereo Analysis
For our experiments, we use semi-global matching (SGM) for stereo analysis 
due to its best overall performance on synthetic and recorded outdoor data in
terms of quality and computational costs. The data term in the original version
of SGM stereo is derived from a mutual information measure . However, 
concludes that the census cost function leads to the best overall performance.
Conﬁdence measures used in this study are not deﬁned on census costs directly,
but on census costs aggregated using SGM with penalty parameters p1 = 20 and
p2 = 100. In the following, we denote these aggregated cost A.
A compilation of diﬀerent conﬁdence measures can be found in . We
selected measures which appear to be pairwise “fairly diﬀerent” by their definitions, with an intention to obtain the best possible performance boost by
combining “orthogonal measures”. This is, of course, possible only to a limited
extent. All conﬁdence measures presented here are deﬁned pixelwise. No dependency from neighbouring pixels is introduced, except the dependency deﬁned by
cost aggregation. Contrary to the common practice, we scale values such that
lower values indicate a smaller likelihood of an erroneous disparity estimate (i.e.
a higher conﬁdence).This facilitates the comparison to actual disparity errors.
We deﬁne and use the following measures, with d0 representing the estimated
disparities D(x, y):
– Curvature. Curvature derived from parabola ﬁtting is a very popular stereo
conﬁdence measure. It is the only conﬁdence measure in the source code of
 . We are using the inverse of the opening parameter for scaling:
Γ0(x, y) =
−2A(x,y)(d0) + A(x,y)(d0 −1) + A(x,y)(d0 + 1)
– Perturbation. The perturbation measure, introduced in , computes the
deviation from an ideal cost function that has a single minimum at location
d0 and is very large everywhere else. Nonlinear scaling is applied:
Γ1(x, y) =
e−(A(x,y)(d0)−A(x,y)(d))
The parameter ς should be chosen such that no numerical underﬂows appear.
A good choice depends on the range of possible valid cost values.
– Peak ratio. The peak ratio indicates low conﬁdence if there are two candidates with similar matching score. It is deﬁned as
Γ2(x, y) = A(x,y)(d0)/A(x,y)(d1)
Analysis of KITTI Data with Stereo Conﬁdence Measures
where d1 is the second smallest local minimum, i.e. A(x,y)(d1−1) > A(x,y)(d1)
and A(x,y)(d1 + 1) > A(x,y)(d1). Not requiring a local minimum but only the
second smallest cost value yields a measure similar to parabola curvature.
– Entropy. Entropy deﬁned on the disparity space was used in steering a diffusion process for cost aggregation in stereo matching . It can be used
as a conﬁdence measure itself. Cost values are normalized for computing the
entropy. Here, p indicates that cost values are converted into a probability
distribution function:
Γ3(x, y) = −
p(d) log p(d)
e−A(x,y)(d)
d′ e−A(x,y)(d′)
Similar to the perturbation measure Γ1, cost values for all disparities in-
ﬂuence the result. All cost values undergo nonlinear scaling, making these
measures computationally rather expensive.
– Right-left consistency check. Right-left consistency compares the disparities
of the left and right view, denoted by D and D(r):
Γ4(x, y) =
D(x,y) −D(r)
Large discrepancies, intuitively, should indicate a higher likelihood of an
incorrect match. We are also interested in ﬁnding out whether there is conﬁdence information extractable from disparities given with subpixel precision,
D(x,y) −D(r)
– Combination of measures. We deﬁne a measure combination Γ by multiplying all ﬁve measures deﬁned above:
Γ(x, y) = Γ0(x, y)Γ1(x, y)Γ2(x, y)Γ3(x, y)Γ4(x, y)
Note that this is not justiﬁed in the sense of joint probabilities. Measures
are not pairwise independent. Correlation is quite strong as their deﬁnition
is derived from same cost values A.
– Accuracy. Ideally conﬁdence measures exactly predict the magnitude of the
error in disparity estimation, so as to discard largest errors ﬁrst. For comparison with Γ0, . . . , Γ4 and Γ we include this ideal measure, given by the
absolute diﬀerence Δ between disparity estimate D and ground truth G:
D(x,y) −G(x,y)
In practise, ﬁnding such a conﬁdence measure was equivalent to the stereo
problem being solved.
Thus, it is more realistic to compare a combination of conﬁdence measures rather
against a measure that identiﬁes an error if at least one of the contributing
conﬁdence measures can detect it. The amount of remaining errors s is then
the cardinality of the union set of all undetected erroneous pixels for a speciﬁc
sparsiﬁcation φ of the disparity map D:
s(φ) = card
D(x,y)|(x, y) ∈Ω ∧Δ(x, y) > 3 ∧∀i (Γi(x, y) ≤γi(φ))
R. Haeusler and R. Klette
Here, γi(φ) is the value of the conﬁdence measure Γi which induces a sparsiﬁcation φ. Note, that values from this deﬁnition cannot be derived without ground
truth. It merely gives a lower limit of remaining disparity errors. The bad-pixel
criterion is deviation of estimated disparities from ground truth being larger
than 3. This is in accordance with the default in and due to limited accuracy
of laser range ﬁnder measurements.
Evaluation of Conﬁdence Measures
We test SGM stereo and derived conﬁdence measures on a small subset of the
recently introduced KITTI Dataset . We choose stereo frames which expose
some interesting behaviour, e.g. the ones challenging for SGM stereo. Challenging
are considered the frames which produce most errors in comparison to ground
truth. We also include two frames where only few errors between SGM results
and ground truth can be observed.
For comparisons, we use raw disparities D, i.e. do not attempt to improve
results by consistency checks, interpolation, median ﬁltering, or any other kind of
postprocessing. Any such steps may introduce some bias to ﬁndings. However, we
exclude such disparities from evaluation, which have been found to be occluded
according to the method described in . It may be beneﬁcial, to use occlusion
ground truth instead, if such was available with .
Furthermore, we restrict the evaluation to pixels where:
– Ground truth is available. In KITTI data there is no ground truth for upper
parts of images, areas usually depicting sky in road vehicle based recordings.
– The cost function contains valid values for all possible disparities. This excludes the left image border in the left view with its width equalling the
number of disparities, the reason being scaling issues in the presense of unknown cost values in the deﬁnition of conﬁdence measures based on the entire
cost function.
– Disparity estimates are supported by data term values, i.e. we do not rely on
extrapolation introduced by SGM. This excludes a narrow band along the
image border (e.g. 3 pixels for a 7 × 7 cost matching window).
A sparsiﬁcation function is computed by summing the remaining errors of matching results when a certain percentile of the disparity map is ﬁltered according to
the locations having least conﬁdence assigned. Locations with lowest conﬁdence
are removed ﬁrst.
Measure comparisons often refer to the area under the sparsiﬁcation curve.
However, errors for very sparse maps are of little interest and should not bias a
comparison of conﬁdence measures. Thus, we do not compare the areas under
the sparsiﬁcation curves. We are merely interested in measure performance for
disparity map densities in a range corresponding to proportions of good disparity
pixels, typically between 70 % and 95 % when using the SGM stereo algorithm
without postprocessing disparities on the KITTI dataset (see intersection of
ground truth optimum with x-axis in Figures 2 and 3).
Analysis of KITTI Data with Stereo Conﬁdence Measures
000008.png
000043.png
000071.png
000082.png
000087.png
000094.png
000120.png
000122.png
000128.png
000180.png
Fig. 1. Visualization of stereo results without postprocessing (left column) and laser
range ﬁnder ground truth (right column) of frames included in this study. Close objects
are red, distant objects green.
R. Haeusler and R. Klette



!"#
$%&$
*+
-&(.##
#
#
 !"#


 !"


 !"#





!"#
$
*+
-&(.##
#
#
 !"


 !"


 !"


Fig. 2. Sparsiﬁcation plots for selected frames of KITTI data with high amount of bad
pixels in the evaluation domain excluding locations detected as being occluded by the
stereo matcher. Numbers of remaining bad pixels are plotted against disparity map
Recall that Frames 8 and 128 were selected due to their apparent amenability
to the stereo problem. The illustration in Fig. 1, however, reveals that low error
rates are only a result of missing ground truth in locations where stereo solutions
Analysis of KITTI Data with Stereo Conﬁdence Measures




" #$"
()
+$&,!!



!"#!
 

Fig. 3. Sparsiﬁcation plots for selected frames of KITTI data with low amount of bad
pixels in the evaluation domain excluding locations detected as being occluded by the
stereo matcher. Numbers of remaining bad pixels are plotted against disparity map
are not accurate. Nevertheless, this may not corrupt an evaluation of conﬁdence
measures, as these areas are ignored.
Sparsiﬁcation plots in Figures 2 and 3 show that the curvature conﬁdence
measure Γ0 in general identiﬁes disparity errors much less accurately than other
conﬁdence measures included in this study. In Frame 43 the selection of bad
pixels appears to be almost random (straight line). However on Frame 43, depicting some vegetation in close proximity, other conﬁdence measures also do
not seem to work well. Useful accuracy of Γ0, according to our experiments, can
be observed in Frames 8 and 122.
The remainder of conﬁdence measures, regarding accuracy, is almost on a
par at low sparsiﬁcations. From the measures Γ1 to Γ4, the entropy conﬁdence
measure Γ3 is most often the worst one. The left-right consistency check is not
helpful within higher sparsiﬁcations, especially not if Γ4 < 1.
For most frames, the naive combination Γ of conﬁdence measures outperforms
single conﬁdence measures at a sparsiﬁcation determined by numbers of bad
pixels. However, the left-right consistency check Γ4 can be on a par at this
sparsiﬁcation level.
Regarding the proposed bound for combined conﬁdence measures it can be
found that at the level of sparsiﬁcation necessary to remove all bad pixels, there
is usually a remainder of half the amount of bad pixels found by the proposed
combination Γ, which cannot be identiﬁed by any conﬁdence measure.
Discussion
In the following, we discuss accuracy of conﬁdence measures on the frames included in this study and try, where possible, to link their behaviour to scene
structure and quality of ground truth and stereo results.
The curvature conﬁdence measure, although widely used, is not much better than randomly removing pixels. Reasons may include limited sharpness of
R. Haeusler and R. Klette
recorded images. This measure only performs rather well on Frames 8 and 122.
This ﬁnding may not be signiﬁcant for Frame 8, due to low numbers of bad
pixels involved. The reason for apparently improved accuracy of curvature on
Frame 122 may be the detection of homogeneously textured areas on road surfaces, which are wrongly estimated by SGM stereo. For detection of textureless
areas, however, there may exist better indicators, such as the structural tensor
That, in all frames, the consistency check Γ4 does not perform well at higher
sparsiﬁcations is not surprising, as subpixel estimation only is based on interpolated cost function values and therefore compromised by so-called pixel locking.
However, the consistency check is also not successful in detecting errors resulting
from surface over-extension or foreground fattening , as these occur likewise
in left-right and right-left matching.
Frame 87 visually does not seem to contain 20 percent bad pixels showing
in Fig. 2. Also, conﬁdence measures do not detect these bad pixels well. Such
results pose the question whether a ﬁxed tolerance of 3 pixel for disparity errors
is appropriate. In particular, in practise, it may be advantageous to deﬁne error
tolerance based on physical distance and with a lower limit in disparity space.
Another problem of the KITTI dataset is missing ground truth in large image
areas. It is most often absent where image regions are challenging for stereo. This
is, e.g., the case on fences (Frames 94 and 128) and car windows (Frames 82,
120 and 180). However, it should be noted that there is no agreement or even no
approach regarding evaluation strategies for such image regions exposing stereo
matchers to semi-transparencies.
Conclusion
Compared to previous benchmark data which was recorded under controlled
lighting conditions, some frames of KITTI data are more challenging for computational stereo due to outdoor scenes with suboptimal lighting conditions.
However, extremely diﬃcult recordings of road scenarios are absent. To our experience, these include tunnels, back-light, night scenes with street lights and
lights of other traﬃc participants, wet road surfaces and precipitation.
Missing ground truth at locations challenging for stereo vision reduces the
signiﬁcance of our ﬁndings and makes it hard to draw comprehensive conclusions.
A comprehensive analysis, however, can be conducted if suﬃciently diversiﬁed
datasets with ground truth are available. Apart from the low coverage with
ground truth at interesting image locations, another shortcoming of the KITTI
dataset is the low dynamic range and luminance resolution of the imagery. Being
eight bit only, preventable stereo problems are introduced, which may disguise
more interesting problems. We conclude that a suﬃciently challenging and rich
dataset for stereo benchmarking with ground truth is not yet available.
Analysis of KITTI Data with Stereo Conﬁdence Measures