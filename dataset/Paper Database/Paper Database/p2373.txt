Active Learning of Uniformly Accurate Inter-atomic Potentials for Materials
Simulation
Linfeng Zhang
Program in Applied and Computational Mathematics,
Princeton University, Princeton, NJ 08544, USA
Institute of Applied Physics and Computational Mathematics,
Huayuan Road 6, Beijing 100088, P.R. China and
CAEP Software Center for High Performance Numerical Simulation, Huayuan Road 6, Beijing 100088, P.R. China
Laboratory of Computational Physics, Institute of Applied Physics and
Computational Mathematics, Huayuan Road 6, Beijing 100088, P.R. China
Roberto Car
Department of Chemistry, Department of Physics,
Program in Applied and Computational Mathematics,
Princeton Institute for the Science and Technology of Materials,
Princeton University, Princeton, NJ 08544, USA
Department of Mathematics and Program in Applied and Computational Mathematics,
Princeton University, Princeton, NJ 08544, USA and
Beijing Institute of Big Data Research, Beijing, 100871, P.R. China
An active learning procedure called Deep Potential Generator (DP-GEN) is proposed for the
construction of accurate and transferable machine learning-based models of the potential energy
surface (PES) for the molecular modeling of materials.
This procedure consists of three main
components: exploration, generation of accurate reference data, and training. Application to the
sample systems of Al, Mg and Al-Mg alloys demonstrates that DP-GEN can produce uniformly
accurate PES models with a minimal number of reference data.
INTRODUCTION
The inter-atomic potential energy surface (PES) plays
a central role in the molecular modeling of materials.
Obtaining an accurate and eﬃcient representation of the
PES is a central issue in molecular simulation. In this
context, one faces the dilemma that ab initio methods
are accurate but highly ineﬃcient, while empirical force
ﬁelds (FFs) are eﬃcient, but there is a limited guarantee
for their accuracy. Thus, there is a great demand for an
eﬃcient and uniformly accurate PES model that can be
used to compute a broad range of atomistic properties
for most material compounds of practical interest.
Developing empirical FFs has been challenging due to
the high dimensionality and many-body character of the
PES. Usually, empirical FFs parameterize the PES by
assuming an analytical functional form in terms of relatively simple functions based on physical/chemical intuition, and by ﬁtting the model parameters against a bundle of experimental properties and/or microscopic quantities from ab initio calculations. Some popular examples
are the Lennard-Jones potential , the Stillinger-Weber
potential , the embedded-atom method (EAM) potential , the CHARMM /AMBER FFs, the reactive
FFs , etc. Representability and transferability are two
main issues faced by empirical FFs. By representability,
we mean the ability of the assumed functional form to
reproduce accurately the target properties. By transferability, we mean the ability of a PES model to describe
properties that do not belong to the set of ﬁtting targets. Due to the physical/chemical knowledge encoded
in the functional form, we expect the empirical FFs to be
qualitatively transferable to a moderate range of thermodynamic conditions beyond those adopted for the ﬁtting.
However, as a consequence of assuming relatively simple functional forms, empirical FFs usually face a severe
representability problem. Moreover, a substantial human
eﬀort in tuning the model parameters is often required to
achieve the best balance in ﬁtting the target properties.
Recent progress with machine learning (ML) methods
is changing the outlook . ML models, being capable
of learning complex and highly nonlinear functional dependence, are excellent in their representability. It is now
possible, using modern ML approaches, to parametrize
 
the PES using data from ab initio calculations to obtain models that have ab initio accuracy and are, at the
same time, competitive regarding eﬃciency against empirical FFs. In spite of the remarkable success of these
ML methods, there is no guarantee for the quality of ML
models when they are used to predict the properties of
a conﬁguration that is far from the training dataset .
In addition, since the training data is usually generated
with expensive ﬁrst-principle calculations, one would like
to obtain good ML models without having to rely on very
large ab initio datasets. These questions arise not only
for PES modeling, but in many other contexts when ML
methods are applied to problems involving physical models.
To address this issue, we get inspiration from active
learning , an area of supervised learning whose
aim is to learn general purpose models with a minimal
number of training data. A training data point involves
an input and an output. For example, in an image recognition task whose goal is to judge whether a cat is in an
image or not, the input is an array of digits that represents the image, and the output is a boolean proposition. Usually the output is called a label and the term
labeling is used to denote the creation of a label. In the
context of active learning, one typically faces a situation
in which unlabeled data are abundant, but labeling is expensive. Therefore, an interactive algorithm is required
to eﬃciently explore unlabeled data, collect feedbacks onthe-ﬂy, and actively query the teacher for labels on data
points with negative feedbacks. Along this line of thinking, at an abstract level, one can formulate an active
learning procedure for PES modeling that involves three
steps: exploration, labeling, and training.
1. Exploration requires an eﬃcient sampler and an informative indicator. The sampler uses the current
PES model to quickly explore the conﬁguration
space. The indicator monitors on-the-ﬂy the con-
ﬁgurations explored by the sampler, selects those
with low prediction accuracy, and sends them to
the labeling step.
2. Labeling means generating reference ab initio energies and forces for the selected conﬁgurations. Labeling can be done by a code that implements highlevel quantum chemistry, quantum Monte Carlo, or
density functional theory (DFT) methods. The labeled conﬁgurations are then added to the existing
dataset and used in the new iteration for training.
3. Training requires a good model, or PES representation, which can ﬁt the ever-increasing dataset with
satisfactory accuracy. Such a representation should
be eﬃcient and should satisfy certain physical constraints like the extensive and symmetry-preserving
properties of the PES.
The whole scheme falls into a closed loop: One starts with
a relatively poor approximation of the PES and uses it
to explore diﬀerent conﬁgurations. Then a selected set of
new conﬁgurations is labeled, and a new approximation
of the PES is obtained by training. These three steps are
repeated until convergence is achieved, i.e., the conﬁguration space has been explored suﬃciently, and a minimal
set of data points have been accurately labeled. At the
end of this procedure, a uniformly accurate PES model
is generated.
In this work, our ﬁrst goal is to translate the general
proposal described above into a practical scheme for modeling the PES. In this scheme, for the PES representation,
we use an advanced version of the Deep Potential (DP)
model , which has shown great promise in learning
the PES of a broad range of systems, such as insulators,
molecular crystals, and a 5-component high entropy alloy, etc. See, e.g., Fig. 1 of Ref. . For the sampler, we
use molecular dynamics (MD) based on the DP model.
Thereafter DP based MD will be referred to as DPMD.
At the same time, we introduce an indicator that we call
the model deviation. This is done as follows. We train an
ensemble of DP models using the same dataset but different initialization of the DP parameters. For each new
conﬁguration that is explored by DPMD, these models
generate an ensemble of predictions. For each conﬁguration, the model deviation is deﬁned as the maximum
standard deviation of the predicted atomic forces. A high
model deviation indicates low quality in the model prediction and is proposed for labeling. In this work, we use
in the labeling stage DFT within the generalized gradient approximation , which works well in the chosen testing examples. We will see that sampling is much
cheaper than labeling, and only a very small fraction of
the explored conﬁgurations is selected for labeling. We
call the methodology introduced here the Deep Potential
Generator, abbreviated DP-GEN.
Our second goal is to demonstrate the uniform accuracy of a PES model obtained in this way.
end, we consider the example of Al, Mg, as well as Al-
Mg alloys. Using DP-GEN, we construct a model that
can accurately describe these systems at diﬀerent compositions and thermodynamic conditions. The resulting
PES model is evaluated from the point of view of a material scientist.
We calculate several statical, dynamical, and mechanical properties, such as radial distribution functions (RDF), phonon spectra, elastic constants,
etc. Some of these properties are compared with DFT
results. We also compare DP calculated properties directly with experimental results when these are available. To further test the quality of the PES model, we
introduce an automatic procedure based on the Materials Project (MP) database . In this procedure, one
searches the database by entering a material composition, such as Al-Mg in the present case. The database
will then return a large number of locally stable struc-
tures, including many structures of potential practical
interest. Based on these structures, we evaluate several
equilibrium properties and compare the DFT predictions
with those of the PES model. In addition, for each one
of these structures, we automatically generate unrelaxed
vacancy and interstitial defects as well as the set of surfaces corresponding to a range of Miller indices . We
then compare the relaxed formation energies of the defects and the unrelaxed formation energies of the surfaces
predicted by DFT and by the PES model. We stress that
these structures, i.e., crystals, defects, and surfaces, were
not explicitly included in the training data. We ﬁnd that
our PES model can achieve uniform accuracy in the prediction of all of these structural properties.
We notice that there is a diﬀerence between active
learning in conventional ML problems and the active
learning we pursue here.
This diﬀerence lies in exploration or sampling. Conventional active learning problems in ML typically deal with an existing unlabeled
Here our dataset is generated on the ﬂy via
sampling. This means that we need to have an eﬃcient
sampling method.
We should mention that related work can be found in
the literature . In particular, Smith et al utilized an active learning scheme to model the PES of organic molecules based on an existing large database .
Moreover, Bartok et al constructed a kernel based
general purpose PES model for pure silicon, wherein they
exhaustively enumerated possible structures for labeling.
Finally, the principle of active learning was also used in
the reinforced dynamics scheme for enhanced sampling and free energy calculation.
METHODOLOGY
In this section, we introduce the three essential components of the DP-GEN scheme: the model, the sampler,
and the indicator. Fig. 1 shows a schematics of DP-GEN.
To initialize the procedure, we label a small set of initial
structures introduced in Fig. 1(a) and train an ensemble
of preliminary DP models. More details on the simulation protocol and the iterative process are reported in the
supplementary materials (SM).
Model. The DP scheme assumes that the potential energy E can be written as a sum of atomic energies, i.e.,
Each atomic energy Ei is a function of
Ri, the local environment of atom i in terms of the relative coordinates of its neighbors within a cut-oﬀradius
rc. The dependence of Ei on Ri embodies the nonlinear and many-body character of the inter-atomic interactions. Therefore, we use a deep neural network function
(DNN) to parameterize it, i.e., Ei = Ewαi(Ri). Here
αi indicates the chemical species of the i-th atom; wαi
denotes the parameters of the DNN we call network parameters, that are determined by the training procedure.
Schematic plot of one iteration of the DP-GEN
scheme, taking the Al-Mg system as an example. (a) Exploration with DPMD. (a.1) Preparation of initial structures. I.
For bulk structures: start from stable crystalline structures
of pure Al and Mg. In this work, we use face-centered-cubic
(FCC), hexagonal-closed-packed (HCP), simple cubic (SC),
and diamond structures. II. Compress and dilate the stable
structures uniformly to allow for a larger range of number densities. We use α to denote the scale factor of the compression
and dilation operations. Here α ranges in the interval 0.96-
1.04. III. Randomly perturb the atomic positions and cell vectors of all the initial crystalline structures. The magnitude of
perturbations on the atomic coordinates is σa = 0.01˚A. The
magnitude of perturbation on each cell vector is σc = 0.03
times the length of the cell vector. IV. Generate random alloy structures: starting from all the structures prepared for
pure systems, randomly place Al or Mg at diﬀerent sites. V.
Generate structures with rigid displacement: starting from
stable FCC and HCP structures, rigidly displace two crystalline halves along speciﬁc crystallographic directions. We
only use (100), (110), (111), and (0001), (10¯10), (11¯20), respectively, for FCC and HCP, as the displacement directions.
The magnitudes d of the displacements range in the interval
0.2-10.0˚A. Based on all the displaced structures, perform dilation α and perturbation σa and σc, and generate random
alloy structures. (a.2) Canonical simulation at a given temperature.
The temperature increases with the iteration index within the range 50-2000 K. (b) Labeling with electronic
structure calculations. (c) Training with the DP model.
A vital component of the DP model is a general proce-
dure that encodes Ri into the so-called feature matrix
Di. This procedure guarantees the conservation of the
translational, rotational, and permutational symmetries
of the system, without losing coordinate information in
the local environment. Derivatives of the energy with respect to the atomic positions give the forces. During the
training process, the network parameters evolve in order
to minimize the loss function, a measure of the error in
the energies and the forces predicted by DP relative to
the labels, i.e., the corresponding DFT predictions .
Upon convergence, the model can match the labels within
a small error tolerance. The details of the architecture
of the DP model and the training process are given in
Ref. .
The goal of the sampler is to explore the
conﬁguration space in a range of thermodynamic variables, say temperature and pressure. Ideally one should
develop an automatic/adaptive procedure for this purpose. However, since exploration is relatively cheap compared to labeling, we adopt a more heuristic approach
in which the exploration is done through: (1) carefully
selecting the initial conﬁgurations, and (2) exploring the
volume-temperature space. We use a variety of crystal
structures as our initial conﬁguration, as in the procedure illustrated in Fig. 1(a).
To explore the volumetemperature phase space, we adopt a temperature increasing scheme, in which the temperature of the DPMD
simulations is increased systematically with the iteration
index in the range 50-2000 K. We notice that many structures constructed in this way are far from equilibrium
structures so that the subsequent DPMD simulations in
the 50-2000K temperature range produce a large sample
of conﬁgurations that may diﬀer substantially from the
initial structure. More details on the initial structures
and the thermodynamic conditions in each iteration are
summarized in Tables S1–S4.
Indicator. It is well-known that neural network models are highly nonlinear functions of the network parameters wαi.
The loss function, as a function of wαi, is
highly non-convex, i.e., several local minima exist in the
landscape of the loss function. In the current work, we
initialize the wαi randomly according to the standard
normal distribution. As a result, diﬀerent initializations
often lead to diﬀerent minimizers of the loss function.
These minimizers ﬁt well the training data, so in the
conﬁgurational region belonging to the neighborhood of
the training data, they generate equally accurate energies and forces and show small deviations in their predictions. However, for snapshots “far” from the training
data, these minimizers usually predict inaccurate values
that show signiﬁcantly larger deviation. This property
of neural network models motivates us to deﬁne the indicator as the deviation of the predictions generated by
an ensemble of DP models trained with the same dataset
but with diﬀerent parameter initializations. In practice,
we deﬁne the model deviation, denoted as E, as the maximum standard deviation of the predictions for the atomic
forces, i.e.:
∥fi −¯fi∥2
where i runs through the atomic indices in a conﬁguration, and the ensemble average ⟨· · · ⟩is taken over the
ensemble of models. We ﬁnd that using the predicted
forces to evaluate the model deviation is generally better
than using the predicted energies. The force is an atomic
property and is sensitive to a failure in local predictions,
while the energy is a global quantity and does not seem
to provide suﬃcient resolution in this regard. Moreover,
we ﬁnd that a failure in local predictions can be better
signaled by using the maximum over i in Eqn. 1, instead
of the average over i ( 1
As examples,
we report the results of the DP-
GEN scheme for Al, Mg and their alloys. At the end of
the DP-GEN scheme, we collect a set of labeled data and
obtain a DP model for the Al-Mg system. As shown in
Table S4, about 650 million conﬁgurations were explored
by DPMD, but only 0.0044% of them were selected for
labeling. To get an idea of the usefulness of the resulting
DP model for materials science applications, we compare
the accuracy of the DP model in predicting important
material properties with a state-of-the-art empirical FF
like the modiﬁed embedded atom method (MEAM) .
MEAM adopts a more general deﬁnition of embedding
than EAM in order to improve the description of directional bonding and of alloy systems. In this work, we
compare our method with a very recent version of the
Al-Mg MEAM potential that is available in the literature . We used DeePMD-kit in the training step,
LAMMPS in the exploration step, and VASP 
in the labeling step.
Pure Al and Mg
The equilibrium properties of pure Al are presented in
Table I, including the atomization energy and equilibrium volume per atom, defect formation energies, elastic
constants and moduli, stacking fault energies, melting
point, enthalpy of fusion, and diﬀusion coeﬃcient. The
defect formation energy is deﬁned as Edf = Ed(Nd) −
NdE0, d = v(i) indicating vacancy (interstitial) defects.
Ed denotes the relaxed energy of a defective structure
with Nd atoms and E0 denotes the energy per atom of
the corresponding ideal crystal at T = 0 K. To compute the defect formation energies, we use a supercell in
which we replicate 7×7×7 times the primitive FCC cell.
FIG. 2: The phonon dispersion relations of Al at T = 80K
and P = 1bar. Here q denotes the wave number and ν the
frequency. The experimental data is taken from .
We estimate the melting temperature (Tm) by simulating with DPMD coexisting crystal and liquid phases in
a supercell containing 8000 atoms within the isothermalisobaric ensemble at standard pressure. To estimate the
liquid diﬀusion coeﬃcient (D), we perform DPMD simulations on large supercells (6912 atoms) for which ﬁnite
size eﬀects are negligible. For all the properties in Table I, the DP predictions are in satisfactory agreement
with DFT and/or experiment. Notice that MEAM reproduces quite accurately the solid state properties in Table I, particularly when compared to experiment, which
is not surprising since the basic experimental solid state
properties have been used to tune the parameters of this
FF. However, the vibrational properties at short wavelength, particularly the zone boundary phonons, are not
reproduced well by MEAM in contrast to DP, as shown
in Fig. 2. MEAM fails even more dramatically in predicting the properties of the liquid: the MEAM liquid is
largely overstructured (see Fig. 3). Its diﬀusion coeﬃcient is one order of magnitude smaller than in experiment or DP, and its enthalpy of fusion is also signiﬁcantly
smaller than in experiment or DP (see Table I).
DFT, DP, and MEAM predictions for the equation of
state (EOS) of Al are reported in Fig. 4. DP reproduces
well the DFT results for all the crystalline structures considered here, i.e., FCC, HCP, double-hexagonal-closedpacked (DHCP), body-centered-cubic (BCC), SC and diamond. Interestingly, the range of DP accuracy extends
well beyond the volume interval that was included in the
training data, which is indicated by the yellow shaded
area in the ﬁgure. As shown in the inset of Fig. 4, the
energy diﬀerence between FCC and DHCP, and the one
between DHCP and HCP is small, only 12 meV/atom
and 19 meV/atom, respectively, yet DP reproduces accurately the relative stabilities.
The MEAM potential
performs well for FCC, HCP, DHCP, and SC, but shows
signiﬁcant deviations from DFT for diamond and BCC.
DP and MEAM predictions for the phonon dispersion relations are compared with experimental results in Fig. 2.
DP results agree very well with experiment.
The promise of ML potential models is to retain the
accuracy of ab initio molecular dynamics (AIMD) at the
TABLE I: Equilibrium properties of Al: atomization energy
Eam, equilibrium volume per atom V0, vacancy formation energy Evf, interstitial formation energies Eif for octahedral interstitial (oh) and tetrahedral interstitial (th). independent
elastic constants C11, C12, and C44, Bulk modulus BV (Voigt),
shear modulus GV (Voigt), stacking fault energy γsf, twin
stacking fault energy γtsf, melting point Tm, enthalpy of fusion ∆Hf, and diﬀusion coeﬃcient D at T = 1000K.
Eam [eV/atom]
V0 [˚A3/atom]c
Eif (oh) [eV]
Eif (th) [eV]
γsf [J/m2]
0.11–0.21h
γtsf [J/m2]
918(±5) 898(±5)
∆Hf[kJ/mol]
10.7(±0.2)l
D [10−9m2/s]
aThe DFT results, unless speciﬁed with a reference, are computed by the authors.
We notice that a K-mesh spacing equal
to 0.06 ˚A−1 was used to obtain more converged DFT results in
this table. However, in the labeling stage, we used a K-mesh spacing equal to 0.08 ˚A−1, which gives converged values for most of
the properties except for elastic constants and moduli. Using Kmesh spacing equal to 0.08 ˚A−1 gives C11 = 129.3 GPa, C12 =
52.8 GPa, C44 = 37.4 GPa, BV = 78.3 GPa, and GV = 37.7 GPa.
bRef. .
cExperiment values obtained at T = 298K; DFT, DP,
and MEAM results obtained at T = 0K. dRef. . eRefs. .
fRef. .
gRef. .
hRefs. .
iRef. .
jRef. .
kRef. .
lRef. .
mRef. , D = 7.2 × 10−9m2/s at 980K
and 7.9 × 10−9m2/s at 1020K.
FIG. 3: The RDFs g(r) of liquid Al at P = 1 bar and temperatures T = 943 K. The DP and MEAM predictions are
compared with the experimental data taken from . The
inserted plot is the zoom-in of RDFs in range 3.5˚A≤r ≤7˚A.
cost of FF simulations. Therefore, ML potential models
can be used to simulate much larger systems for much
longer times than possible with AIMD. This is illustrated
by our calculations for the diﬀusion coeﬃcient and the radial distribution function (RDF) of the liquid, which were
performed on large cells with 4000 atoms with very modest computational resources when using DP. Thus, the
V [Å3/atom]
FIG. 4: The EOS’s of Al. Solid lines, dashed lines, and cross
points denote DP, MEAM, and DFT results, respectively.
The energies of MEAM are shifted so that the MEAM energy
of a stable FCC structure equals to that given by DFT. DFT
based relaxations fail in some HCP and DHCP structures with
a volume per atom larger 30 ˚A3, thus the corresponding DFT
predictions are not shown. Yellow bars denote volume ranges
in the training data. The BCC and DHCP structures were
not explicitly added to the training data.
Surface formation energy by DP/MEAM [J/m2]
Surface formation energy by DFT [J/m2]
DP: FCC Al
DP: HCP Mg
MEAM: FCC Al
MEAM: HCP Mg
FIG. 5: Surface formation energies of Al and Mg.
non-equivalent surfaces with Miller index values smaller than
4 and 3 are investigated for Al and Mg, respectively.
DP model opens opportunities for extending the power
of ab initio methods.
The DP method gives similarly good results for the
corresponding properties of pure Mg, which are reported
in the SM.
Finally, we examine the surface formation energy
Esf((lmn)), which describes the energy needed to create
a surface with Miller indices (lmn) for a given crystal,
and is deﬁned by Esf((lmn)) =
2A(Es((lmn)) −NsE0).
Here Es((lmn)) and Ns denote the energy and number
of atoms of the relaxed surface structure with Miller indices (lmn). A denotes the surface area. We enumerate
all the non-equivalent surfaces corresponding to Miller
index values smaller than 4 for Al, and smaller than 3
for Mg. As shown in Fig. 5, the surfaces formation energies predicted by DP are close to DFT , and those
predicted by MEAM are worse in all cases. We report in
detail the values of surface formation energies for Al and
Mg in Tables S6 and S7, respectively.
Mg-Al Alloys
For alloy systems, we adopted the testing scheme introduced in Section I, ﬁnding 28 crystalline (ordered) Mg-Al
alloy structures in the MP database , corresponding
to relative Mg concentrations (cMg) ranging from 25% to
94%. Most of these structures were found initially from
experiment and were recorded in the inorganic crystal
structure database (ICSD) . When recorded in the
MP database they were further relaxed with DFT. In
Figs. 6 (a-f), we compare predictions of DFT, DP, and
MEAM for the 28 alloy structures. The 6 panels in Fig. 6
report (a) the formation energies, (b) the equilibrium
volumes per atom,(c) the elastic constants, (d) the relaxed vacancy formation energies, (e) the total energies
per atom along interstitial relaxation pathways, and (f)
the unrelaxed surface formation energies.
Notice that
only the elastic constants from DP are compared with
DFT in Fig. 6 (c).
The corresponding MEAM elastic
constants are compared with DFT in Fig.S3.
The formation energy of an Mg-Al alloy system is de-
Eaf = E0(cMg) −cMgE0
Mg −(1 −cMg)E0
where E0(cMg) denotes the equilibrium energy (0 K) per
atom of the Mg-Al alloy structure with Mg concentration equal to cMg, and E0
Al denote the equilibrium energies per atom of the corresponding stable
crystals of pure Mg and Al at 0 K. The precise values
of the formation energies and equilibrium volumes per
atom are reported in Table S9. To generate the vacancy
and interstitial structures, we used supercells that are
periodic copies of the MP structures.
The size of the
supercell for each MP structure is reported in Table S5.
We further notice that the interstitial structures are automatically generated based on 12 MP structures 
that are the most stable ones at the corresponding concentrations. Since most of the interstitial structures are
energetically highly unstable, their relaxation likely ends
up with structures that do not represent locally relaxed
interstitial point defects, as shown in Fig. S4. In this case,
the end structures depend very sensitively on the details
of the relaxation. Therefore, instead of performing independent relaxations within DFT, DP, and MEAM, we
compare the predictions of these models for conﬁgurations along the DFT relaxation pathways (excluding the
initial high energy conﬁgurations).
DP/MEAM [eV/atom]
DFT [eV/atom]
(a) Formation energy
Distribution
of Error (%)
DP/MEAM [Å3/atom]
DFT [Å3/atom]
(b) Equilibrium volumn
Distribution
of Error (%)
100 120 140
(c) Elastic constant
0 2 4 6 8 10 12 14
Distribution
of Error (%)
DP/MEAM [eV]
(d) Relaxed vacancy formation energy
Distribution
of Error (%)
DP/MEAM [eV/atom]
DFT [eV/atom]
(e) Energy along interstitial relaxation path
Distribution
of Error (%)
DP/MEAM [J/m2]
DFT [J/m2]
(f) Unrelaxed surface energy
Distribution
of Error (%)
FIG. 6: Comparisons of Al-Mg alloy properties predicted by DFT, DP, and MEAM, based on 28 structures in the MP database.
(a) 28 formation energies. (b) 28 equilibrium volumes per atom. (c) 225 elastic constants. Three structures, mp-1039192, mp-
1094664, and mp-12766, are excluded because they resulted unstable under small displacements within DFT. (d) 125 relaxed
vacancy formation energies. Three structures, mp-1039192, mp-1094664, and mp-1038818, are excluded because they resulted
unstable under vacancy relaxations within DFT. Two DP predictions and three MEAM predictions are outside the range of the
plot due to large errors. (e) 86,199 energies per atom along the interstitial relaxation pathways within DFT. (f) 903 unrelaxed
surface energies.
In almost all tested cases, we observe an overall satisfactory agreement between DP predictions and DFT reference results. The accuracy of DP is signiﬁcantly better
than that of MEAM. We stress that the DP-GEN procedure is blind to the alloy structures used to compute the
properties reported in Fig. 6, because these structures
were not explicitly included in the training data. The
number of atoms in the unit cell of 6 MP structures is
larger than 32, which was the maximum number of atoms
in the unit cell of the structures belonging to the training dataset. This suggests that in the case of Mg-Al alloys the DP model trained with relatively small periodic
structures can, to some extent, be used to predict the
properties of larger structures. Some structures tested
have little in common with the initial training data. Yet
the DP model produced satisfactory results, suggesting
that it could work for a broader range of materials.
SUMMARY AND OUTLOOK
The DP-GEN scheme is general, practical, and fairly
automatic. To generate the DP model for the Al-Mg system, we did not use any existing DFT database (the MP
database was only used for testing), nor did we use an exhaustive list of possible structures based on physical and
chemical considerations. Instead, we explored the space
of conﬁgurations using computationally eﬃcient DPMD
simulations. DFT calculations were only performed on
a small subset of the conﬁgurations that showed large
model deviation. This made possible to progressively improve the DP model.
The DP-GEN scheme is quite ﬂexible. The three components, training, exploration, and labeling, are highly
modularized and can be implemented separately and
then recombined. This makes it easy to incorporate additional functionalities. For example, enhanced sampling
techniques or genetic algorithms can be incorporated with minimal eﬀort in the exploration module.
We expect that the modular structure of DP-GEN should
make possible to use this method to generate models for a
variety of important problems, such as ﬁnding transition
pathways for structural transformations and chemical reactions. The outcome of DP-GEN include the model and
the accumulated data, which could be used for further applications. For example, if a rare-earth species is added
to the Al-Mg system, one does not need to start the DP-
GEN scheme from scratch. Instead, one could restart the
DP-GEN scheme with the current model and data, and
continue with the exploration of the conﬁguration space
involving the new species.
Besides alloys dominated by metallic bonding, it would
be interesting to use the DP-GEN scheme to study other
materials, such as ceramics, polymers, etc., which include
diﬀerent types of bond interactions. This should be possible because the applicability of DP-GEN relies on three
main points: the representability of the model, the validity of the indicator, and the capability of the sampler.
Several investigations suggest that the ﬁrst two issues
should be relatively independent of the details of the microscopic interactions. Indeed, our earlier studies 
indicate that the DP model can represent equally well the
PES of systems that diﬀer signiﬁcantly in their bonding
character, such as organic molecules, molecular crystals,
hydrogen bonded systems, semiconductors and semimetals.
In addition, extensive observations by our group
show that the DP-GEN indicator, which derives from
the variance of the predictions within an ensemble of
DNN models, works equally well for diﬀerent applications . These observations are further supported
by recent work by other groups who used closely related
indicators in applications to a variety of diﬀerent systems . We are left with the sampler, which may
require case speciﬁc strategies. We are currently investigating this issue in a range of materials, ﬁnding that
in all cases the search for optimal sampling strategies is
facilitated by the modular structure of DP-GEN. We will
present speciﬁc examples in future work.
Last but not least, one should be aware that DP-GEN
scheme may fail in some circumstances. We think that
this should occur most likely when the sampler and/or
the indicator fail. For example, the sampler could fail
when the conﬁguration space has high dimensionality and
large free energy barriers prevent exploring important
conﬁgurations. In these situations, speciﬁcally designed
good reaction coordinates might be necessary. Additional
diﬃculties may be due to the indicator. To the best of
the authors’ knowledge, a rigorous mathematical theory
of the indicator is missing. A large value of the proposed
indicator is only a suﬃcient, not a necessary, condition
for poor performance of a DP model. There may be situations in which the physics is poorly described by a model,
yet the corresponding ensemble of predictions has small
variance. We did not face these diﬃculties in the present
investigation but the reader should be aware that systematic validation tests should always be performed before
using a DP model to explore new physics.
The work of L.Z. and W.E is supported in part by
Major Program of NNSFC under grant 91130005, ONR
grant N00014-13-1-0338 and NSFC grant U1430237. The
work of L.Z. and R.C. is supported in part by the
DOE with Award Number de-sc0019394.
of H.W. is supported by the National Science Foundation of China under Grants 11501039, 11871110 and
91530322, and the National Key Research and Development Program of China under Grants 2016YFB0201200
2016YFB0201203.
H.W. is supported by the Science Challenge Project
No. JCKY2016212A502. We are grateful for computing
time provided in part by the National Energy Research
Scientiﬁc Computing Center (NERSC), the Terascale Infrastructure for Groundbreaking Research in Science and
Engineering (TIGRESS) High Performance Computing
Center and Visualization Laboratory at Princeton University, the Special Program for Applied Research on Super Computation of the NSFC-Guangdong Joint Fund
under Grant No. U1501501, and the Beijing Institute of
Big Data Research.
SUPPLEMENTARY MATERIALS
Simulation protocol
The smooth edition of the deep potential 
model is adopted in this work. The cut-oﬀradius is set
to 9 ˚A. The 1/r terms in the network construction is
smoothly switched-oﬀby a cosine shape function 
from 2 ˚A to 9 ˚Aso that the discontinuity due to the
cut-oﬀis removed. The ﬁlter (embedding) net is of size
{25, 50, 100}, and the ﬁtting net is of size {240, 240, 240}.
A skip connection is built between two neighboring layers, so the architecture of the network is ResNet-like .
The Adam stochastic gradient descent method [? ] is
adopted to train the models, with a learning rate starting
at 5.0×10−4 and exponentially decaying to 1.8×10−8 in
400,000 training steps. Four models with the same data
and training setting, but diﬀerent parameter initializations, are trained to estimate the model deviation in the
force prediction. After all the data are collected, the ﬁnal
model is trained with 1,2800,000 training steps.
Exploration
Table S1, S2, and Table S3 report the exploration strategy in each iteration for pure Al, pure Mg,
and Al-Mg alloy systems, respectively. During the exploration, if the model deviation of a conﬁguration falls in
the range [0.05, 0.15] eV/˚A in the case of pure Al and Al-
Mg alloy, or in range [0.03,0.13] eV/˚A in the case of pure
Mg, then the corresponding conﬁguration is selected for
labeling. The number of atoms in each crystalline structure, the total number of explored and labeled conﬁgurations of each crystal structure are reported by Tab. S4.
The DFT simulation is carried out by the
Vienna ab initio simulation package (VASP) version
5.4.4 , within the Perdew-Burke-Ernzerhof generalized gradient approximation. The kinetic energy cutoﬀfor the plane wave expansion is set to 600 eV, and
the K-points is set with the Monkhorst-Pack mesh 
at the spacing hk = 0.08 ˚A−1. The order 1 Methfessel-
Paxton smearing method with σ = 0.25 eV is adopted.
The self-consistent ﬁeld (SCF) iteration will stop when
the total energy and band structure energy diﬀerences
between two consecutive steps are smaller than 10−6 eV.
Additional simulation results
∗Electronic address: wang 
† Electronic address: 
 John Edward Jones. On the determination of molecular
ﬁelds. In Proceedings of the Royal Society of London A:
Mathematical, Physical and Engineering Sciences, volume 106, pages 463–477. The Royal Society, 1924.
FIG. S1: Equation of states of Mg. Solid lines denotes DP
Dashed lines denote MEAM results.
Cross points
denote DFT results.
The energies of DP and MEAM are
shifted so that the MEAM energy of a stable FCC structure
equils to that given by DFT. The DFT relaxations fail in
some HCP and DHCP structures with atomic volume larger
44 ˚A3, thus the EOSs of HCP and DHCP beyond 44 ˚A3 are
not shown.
FIG. S2: The RDFs of liquid Mg at P = 1 bar and temperatures T = 953 K. The DP and MEAM predictions are
compared with the experimental data taken from . The
inserted plot is the zoom-in of RDFs in range 3.5˚A≤r ≤7˚A.
 Frank H Stillinger and Thomas A Weber. Computer simulation of local order in condensed phases of silicon. Physical Review B, 31(8):5262, 1985.
 Murray S Daw and Michael I Baskes. Embedded-atom
method: Derivation and application to impurities, surfaces, and other defects in metals. Physical Review B,
29(12):6443, 1984.
 Alex D MacKerell Jr, Donald Bashford, MLDR Bellott,
Roland Leslie Dunbrack Jr, Jeﬀrey D Evanseck, Martin J
Field, Stefan Fischer, Jiali Gao, H Guo, Sookhee Ha,
et al. All-atom empirical potential for molecular modeling and dynamics studies of proteins. The Journal of
Physical Chemistry B, 102(18):3586–3616, 1998.
 Junmei Wang, Piotr Cieplak, and Peter A Kollman. How
well does a restrained electrostatic potential (resp) model
Exploration strategy for the pure Al system. For each iteration, we report the crystalline structure from which
the initial structures are derived, the number of DPMD simulations, the length of DPMD trajectories, the statistical ensemble,
the temperature of DPMD simulations and the portion of explored data sent to labeling. The pressure is 1 bar for the NPT
ensembles.
Iter. Crystal
#DPMD Length Ensemb.
Labd. Iter. Crystal
#DPMD Length Ensemb.
0 FCC, HCP, DIA, SC
28 FCC, HCP
1 FCC, HCP, DIA, SC
29 FCC, HCP
2 FCC, HCP, DIA, SC
30 FCC, HCP
3 FCC, HCP, DIA, SC
31 FCC, HCP
4 FCC, HCP, DIA, SC
32 FCC, HCP
5 FCC, HCP, DIA, SC
33 FCC, HCP
6 FCC, HCP, DIA, SC
34 FCC, HCP
7 FCC, HCP, DIA, SC
35 FCC, HCP
8 FCC, HCP, DIA, SC
36 FCC(surf.)
9 FCC, HCP, DIA, SC
37 FCC(surf.)
10 FCC, HCP, DIA, SC
38 FCC(surf.)
11 FCC, HCP, DIA, SC
39 FCC(surf.)
12 FCC, HCP
40 FCC(surf.)
13 FCC, HCP
41 FCC(surf.)
14 FCC, HCP
42 FCC(surf.)
15 FCC, HCP
43 FCC(surf.)
16 FCC, HCP
44 FCC(surf.)
17 FCC, HCP
45 HCP(surf.)
18 FCC, HCP
46 HCP(surf.)
19 FCC, HCP
47 HCP(surf.)
20 FCC, HCP
48 HCP(surf.)
21 FCC, HCP
49 HCP(surf.)
22 FCC, HCP
50 HCP(surf.)
23 FCC, HCP
51 HCP(surf.)
24 FCC, HCP
52 HCP(surf.)
25 FCC, HCP
53 HCP(surf.)
26 FCC, HCP
27 FCC, HCP
perform in calculating conformational energies of organic
and biological molecules?
Journal of Computational
Chemistry, 21(12):1049–1074, 2000.
 Adri CT Van Duin, Siddharth Dasgupta, Francois Lorant, and William A Goddard. Reaxﬀ: a reactive force
ﬁeld for hydrocarbons. The Journal of Physical Chemistry A, 105(41):9396–9409, 2001.
 J¨org Behler and Michele Parrinello. Generalized neuralnetwork representation of high-dimensional potentialenergy surfaces. Physical Review Letters, 98(14):146401,
 Albert P Bart´ok, Mike C Payne, Risi Kondor, and G´abor
Cs´anyi. Gaussian approximation potentials: The accuracy of quantum mechanics, without the electrons. Physical Review Letters, 104(13):136403, 2010.
 Matthias Rupp, Alexandre Tkatchenko, Klaus-Robert
M¨uller, and O Anatole VonLilienfeld. Fast and accurate
modeling of molecular atomization energies with machine
learning. Physical Review Letters, 108(5):058301, 2012.
 Gr´egoire Montavon, Matthias Rupp, Vivekanand Gobre, Alvaro Vazquez-Mayagoitia, Katja Hansen, Alexandre Tkatchenko, Klaus-Robert M¨uller, and O Anatole
Von Lilienfeld. Machine learning of molecular electronic
properties in chemical compound space. New Journal of
Physics, 15(9):095003, 2013.
 Venkatesh Botu, Rohit Batra, James Chapman, and
Rampi Ramprasad. Machine learning force ﬁelds: construction, validation, and outlook. The Journal of Physical Chemistry C, 121(1):511–522, 2016.
 Stefan
Tkatchenko,
Sauceda, Igor Poltavsky, Kristof T Sch¨utt, and Klaus-
Robert M¨uller.
Machine learning of accurate energyconserving molecular force ﬁelds.
Science Advances,
3(5):e1603015, 2017.
 Kristof
Pieter-Jan
Kindermans,
Tkatchenko, and Klaus-Robert M¨uller.
continuous-ﬁlter convolutional neural network for modeling quantum interactions.
In Advances in Neural
Information Processing Systems, pages 992–1002, 2017.
 Albert P Bart´ok, Sandip De, Carl Poelking, Noam Bernstein, James R Kermode, G´abor Cs´anyi, and Michele Ceriotti. Machine learning uniﬁes the modeling of materials
and molecules. Science advances, 3(12):e1701816, 2017.
 Justin S Smith, Olexandr Isayev, and Adrian E Roitberg.
ANI-1: an extensible neural network potential with dft
accuracy at force ﬁeld computational cost. Chemical Science, 8(4):3192–3203, 2017.
 Jequn Han, Linfeng Zhang, Roberto Car, and Weinan E.
Deep Potential: a general representation of a many-body
potential energy surface. Communications in Computational Physics, 23(3):629–639, 2018.
Exploration strategy for the pure Mg system. For each iteration, we report the crystalline structure from which
the initial structures are derived, the number of DPMD simulations, the length of DPMD trajectories, the statistical ensemble,
the temperature of DPMD simulations and the portion of explored data sent to labeling. ,The pressure is 1 bar for the NPT
ensembles.
Iter. Crystal
#DPMD Length Ensemb.
Labd. Iter. Crystal
#DPMD Length Ensemb.
0 FCC, HCP, DIA, SC
28 FCC, HCP
1 FCC, HCP, DIA, SC
29 FCC, HCP
2 FCC, HCP, DIA, SC
30 FCC, HCP
3 FCC, HCP, DIA, SC
31 FCC, HCP
4 FCC, HCP, DIA, SC
32 FCC, HCP
5 FCC, HCP, DIA, SC
33 FCC, HCP
6 FCC, HCP, DIA, SC
34 FCC, HCP
7 FCC, HCP, DIA, SC
35 FCC, HCP
8 FCC, HCP, DIA, SC
36 FCC(surf.)
9 FCC, HCP, DIA, SC
37 FCC(surf.)
10 FCC, HCP, DIA, SC
38 FCC(surf.)
11 FCC, HCP, DIA, SC
39 FCC(surf.)
12 FCC, HCP
40 FCC(surf.)
13 FCC, HCP
41 FCC(surf.)
14 FCC, HCP
42 FCC(surf.)
15 FCC, HCP
43 FCC(surf.)
16 FCC, HCP
44 FCC(surf.)
17 FCC, HCP
45 HCP(surf.)
18 FCC, HCP
46 HCP(surf.)
19 FCC, HCP
47 HCP(surf.)
20 FCC, HCP
48 HCP(surf.)
21 FCC, HCP
49 HCP(surf.)
22 FCC, HCP
50 HCP(surf.)
23 FCC, HCP
51 HCP(surf.)
24 FCC, HCP
52 HCP(surf.)
25 FCC, HCP
53 HCP(surf.)
26 FCC, HCP
27 FCC, HCP
 Xin Chen, Mathias Siggaard Jørgensen, Jun Li, and
Bjørk Hammer.
Atomic energies from a convolutional
neural network. Journal of chemical theory and computation, 14:3933–3942, 2018.
 Linfeng Zhang, Jiequn Han, Han Wang, Roberto Car,
and Weinan E. Deep potential molecular dynamics: A
scalable model with the accuracy of quantum mechanics.
Physical review letters, 120:143001, Apr 2018.
 Linfeng Zhang, Jiequn Han, Han Wang, Wissam Saidi,
Roberto Car, and Weinan E.
End-to-end symmetry
preserving inter-atomic potential energy model for ﬁnite and extended systems.
In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and
R. Garnett, editors, Advances in Neural Information Processing Systems 31, pages 4441–4451. Curran Associates,
Inc., 2018.
 Yann LeCun, Yoshua Bengio, and Geoﬀrey Hinton. Deep
learning. nature, 521(7553):436, 2015.
 Burr Settles.
Active learning.
Synthesis Lectures on
Artiﬁcial Intelligence and Machine Learning, 6(1):1–114,
 Neil Rubens, Mehdi Elahi, Masashi Sugiyama, and Dain
Kaplan. Active learning in recommender systems. In Recommender systems handbook, pages 809–846. Springer,
 John P Perdew, Kieron Burke, and Matthias Ernzerhof.
Generalized gradient approximation made simple. Physical review letters, 77(18):3865, 1996.
 Georg Kresse and J¨urgen Furthm¨uller. Eﬃcient iterative
schemes for ab initio total-energy calculations using a
plane-wave basis set.
Physical review B, 54(16):11169,
 Georg Kresse and J¨urgen Furthm¨uller. Eﬃciency of abinitio total energy calculations for metals and semiconductors using a plane-wave basis set. Computational materials science, 6(1):15–50, 1996.
 Hendrik J Monkhorst and James D Pack.
points for brillouin-zone integrations. Physical review B,
13(12):5188, 1976.
 Anubhav Jain,
Shyue Ping Ong,
Geoﬀroy Hautier,
Wei Chen, William Davidson Richards, Stephen Dacek,
Shreyas Cholia, Dan Gunter, David Skinner, Gerbrand
Ceder, et al. The materials project: A materials genome
approach to accelerating materials innovation. Apl Materials, 1(1):011002, 2013.
 Shyue Ping Ong, William Davidson Richards, Anubhav
Jain, Geoﬀroy Hautier, Michael Kocher, Shreyas Cholia,
Dan Gunter, Vincent L Chevrier, Kristin A Persson, and
Gerbrand Ceder.
Python materials genomics (pymatgen): A robust, open-source python library for materials
analysis. Computational Materials Science, 68:314–319,
Exploration strategy for the Al-Mg alloy system. For each iteration, we report the crystalline structure from
which the initial structures are derived, the number of DPMD simulations, the length of DPMD trajectories, the statistical
ensemble, the temperature of DPMD simulations and the portion of explored data sent to labeling. ,The pressure is 1 bar for
the NPT ensembles.
Iter. Crystal
#DPMD Length Ensemb.
Labd. Iter. Crystal
#DPMD Length Ensemb.
0 FCC, HCP, DIA, SC
30 FCC, HCP
1 FCC, HCP, DIA, SC
31 FCC, HCP
2 FCC, HCP, DIA, SC
32 FCC, HCP
3 FCC, HCP, DIA, SC
33 FCC, HCP
4 FCC, HCP, DIA, SC
34 FCC, HCP
5 FCC, HCP, DIA, SC
35 FCC, HCP
6 FCC, HCP, DIA, SC
36 FCC(surf.)
7 FCC, HCP, DIA, SC
37 FCC(surf.)
8 FCC, HCP, DIA, SC
38 FCC(surf.)
9 FCC, HCP, DIA, SC
39 FCC(surf.)
10 FCC, HCP, DIA, SC
40 FCC(surf.)
11 FCC, HCP, DIA, SC
41 FCC(surf.)
12 FCC, HCP
42 FCC(surf.)
13 FCC, HCP
43 FCC(surf.)
14 FCC, HCP
44 FCC(surf.)
15 FCC, HCP
45 FCC(surf.)
16 FCC, HCP
46 FCC(surf.)
17 FCC, HCP
47 FCC(surf.)
18 FCC, HCP
48 HCP(surf.)
19 FCC, HCP
49 HCP(surf.)
20 FCC, HCP
50 HCP(surf.)
21 FCC, HCP
51 HCP(surf.)
22 FCC, HCP
52 HCP(surf.)
23 FCC, HCP
53 HCP(surf.)
24 FCC, HCP
54 HCP(surf.)
25 FCC, HCP
55 HCP(surf.)
26 FCC, HCP
56 HCP(surf.)
27 FCC, HCP
57 HCP(surf.)
28 FCC, HCP
58 HCP(surf.)
29 FCC, HCP
59 HCP(surf.)
TABLE S4: Number of explored and labeled data by the DP-GEN scheme for pure Al, pure Mg, and Mg-Al alloy systems.
Al-Mg alloys
15,174,000
15,174,000
39,266,460
15,174,000
15,174,000
18,999,900
62,203,680
10,744,2720
62,203,680
HCP (0001)
62,203,680
HCP (10¯10)
62,203,680
HCP (11¯20)
107,442,720
60,089,760
60,089,760
529,961,760
bMg and Al-Mg alloy
 Evgeny V Podryabinkin and Alexander V Shapeev. Active learning of linearly parametrized interatomic potentials. Computational Materials Science, 140:171–180,
 Justin S Smith, Ben Nebgen, Nicholas Lubbers, Olexandr
Isayev, and Adrian E Roitberg.
Less is more:
Sampling chemical space with active learning. The Journal
of Chemical Physics, 148(24):241733, 2018.
 John E Herr, Kun Yao, Ryker McIntyre, David W Toth,
and John Parkhill.
Metadynamics for training neural
TABLE S5: The size of supercells used for generating the vacancy and interstitial structures.
Mat.Proj.ID
Mat.Proj.ID
Mat.Proj.ID
mp-1016233
mp-1039141
mp-1094700
mp-1016271
mp-1039180
mp-1094961
mp-1023506
mp-1039192
mp-1094970
mp-1038779
mp-1094116
mp-1094987
mp-1038818
mp-1094664
mp-1038916
mp-1094666
mp-1038934
mp-1094683
mp-1039010
mp-1094685
mp-1039019
mp-1094692
mp-1039119
TABLE S6: Surface formation energies of FCC Al.
100 120 140
Elastic const by DP [GPa]
Elastic const by MEAM [GPa]
0 2 4 6 8 10 12 14
Distribution
of Error (%)
FIG. S3: Elastic constants computed by MEAM compared
with those computed by DFT.
network model chemistries: A competitive assessment.
The Journal of Chemical Physics, 148(24):241710, 2018.
 Luigi Bonati and Michele Parrinello. Silicon liquid structure and crystal nucleation from ab-initio deep metadynamics. arXiv preprint arXiv:1809.11088, 2018.
Interstitial Al
FIG. S4: Comparison of energies predicted by DFT and DP
along the Al interstitial relaxation pathway within DFT. The
interstitial structure is generated from mp-1094116. The insert shows the initial and relaxed interstitial conﬁgurations.
 Felix Musil, Michael Willatt, Mikhail A Langovoy, and
Michele Ceriotti. Fast and accurate uncertainty estimation in chemical machine learning. Journal of chemical
theory and computation, 2019.
 Justin S Smith, Olexandr Isayev, and Adrian E Roitberg.
ANI-1, a data set of 20 million calculated oﬀ-
TABLE S7: Surface formation energies of HCP Mg.
TABLE S8: Equilibrium properties of Mg.
E0 [eV/atom]
V0 [˚A3/atom]
γsf [J/m2]
γtsf [J/m2]
∆Hf[kJ/mol]
9.0(±0.2)l
aReference 
bReference , 300K
cReference 
dReference 
eReference 
fReference 
equilibrium conformations for organic molecules. Scientiﬁc data, 4:170193, 2017.
 Albert P Bartok, James Kermode, Noam Bernstein,
and Gabor Csanyi.
Machine learning a general purpose interatomic potential for silicon.
arXiv preprint
 
 Linfeng Zhang, Han Wang, and Weinan E. Reinforced
dynamics for enhanced sampling in large atomic and
molecular systems.
The Journal of chemical physics,
148(12):124113, 2018.
 Diederik Kingma and Jimmy Ba. Adam: a method for
stochastic optimization. In Proceedings of the International Conference on Learning Representations (ICLR),
 MI Baskes. Modiﬁed embedded-atom potentials for cubic
materials and impurities. Physical review B, 46(5):2727,
 Bohumir Jelinek, Sebastien Groh, Mark F Horstemeyer,
Jeﬀery Houze, Seong-Gon Kim, Gregory J Wagner, Amitava Moitra, and Michael I Baskes. Modiﬁed embedded
atom method potential for al, si, mg, cu, and fe alloys.
Physical Review B, 85(24):245102, 2012.
 Han Wang, Linfeng Zhang, Jiequn Han, and Weinan E.
DeePMD-kit: A deep learning package for many-body
potential energy representation and molecular dynamics.
Computer Physics Communications, 228:178 – 184, 2018.
 Steve Plimpton. Fast parallel algorithms for short-range
molecular dynamics. Journal of computational physics,
117(1):1–19, 1995.
 Cox J. D., Wagman D. D., and Medvedev V. A. CO-
TABLE S9: The formation energy and volume per atom of Mg-Al alloys, displayed in ascending order of Mg concentration and
descending order of structure stability. The numbers in the parenthese give the diﬀerence between the DP/MEAM method
and the DFT calculation.
Mat.Proj.ID
mp-1038916
mp-1039119
mp-1039180
mp-1094116
mp-1039192
mp-1039141
mp-1094987
mp-1038779
mp-1039019
mp-1038934
mp-1039010
mp-1038818
mp-1094664
mp-1094685
mp-1094692
mp-1094683
mp-1094700
mp-1094970
mp-1094961
mp-1016233
mp-1094666
mp-1016271
mp-1023506
DATA Key Values for Thermodynamics.
Hemisphere
Publishing Corp., 1989.
 Ann S Cooper. Precise lattice constants of germanium,
aluminum, gallium arsenide, uranium, sulphur, quartz
and sapphire.
Acta Crystallographica, 15(6):578–582,
 W Triftsh¨auser.
Positron trapping in solid and liquid
metals. Physical Review B, 12(11):4634, 1975.
 MJ Fluss, L C
Smedskjaer, MK Chason, DG Legnini,
and RW Siegel. Measurements of the vacancy formation
enthalpy in aluminum using positron annihilation spectroscopy. Physical Review B, 17(9):3444, 1978.
 Randolph Q Hood, PRC Kent, and Fernando A Reboredo.
Diﬀusion quantum monte carlo study of the
equation of state and point defects in aluminum. Physical
Review B, 85(13):134109, 2012.
 GN Kamm and GA Alers. Low-temperature elastic moduli of aluminum. Journal of Applied Physics, 35(2):327–
330, 1964.
 VC Kannan and G Thomas. Dislocation climb and determination of stacking-fault energies in al and al-1% mg.
Journal of Applied Physics, 37(6):2363–2370, 1966.
 PS Dobson, PJ Goodhew, and RE Smallman.
kinetics of dislocation loops in aluminium. Philosophical
Magazine, 16(139):9–22, 1967.
 Jean-Pierre Tartour and Jack Washburn. Climb kinetics
of dislocation loops in aluminium. Philosophical Magazine, 18(156):1257–1267, 1968.
 Michael J Mills and Pierre Stadelmann. A study of the
structure of lomer and 60 dislocations in aluminium using
high-resolution transmission electron microscopy. Philosophical Magazine A, 60(3):355–384, 1989.
 Dongdong Zhao, Ole Martin Løvvik, Knut Marthinsen,
and Yanjun Li. Impurity eﬀect of mg on the generalized
planar fault energy of al. Journal of materials science,
51(14):6552–6568, 2016.
 Marvin Ross, Lin H Yang, and Reinhard Boehler. Melting of aluminum, molybdenum, and the light actinides.
Physical Review B, 70(18):184112, 2004.
 J Bouchet, F Bottin, G Jomard, and G Z´erah. Melting
curve of aluminum up to 300 gpa obtained through ab
initio molecular dynamics simulations. Physical Review
B, 80(9):094102, 2009.
 Richard Addison McDonald.
Enthalpy, heat capacity,
and heat of fusion of aluminum from 366. degree. to 1647.
degree. k. Journal of Chemical and Engineering Data,
12(1):115–118, 1967.
 Andreas Meyer. The measurement of self-diﬀusion coeﬃcients in liquid metals with quasielastic neutron scattering. In EPJ Web of Conferences, volume 83, page 01002.
EDP Sciences, 2015.
 R t Stedman and G Nilsson.
Dispersion relations for
phonons in aluminum at 80 and 300 k. Physical Review,
145(2):492, 1966.
 Yoshio Waseda. The structure of non-crystalline materials. Liguids and Amorphous Solids, 1980.
 Richard Tran, Zihan Xu, Balachandran Radhakrishnan,
Donald Winston, Wenhao Sun, Kristin A Persson, and
Shyue Ping Ong. Surface energies of elemental crystals.
Scientiﬁc data, 3:160080, 2016.
 Mariette Hellenbrandt. The inorganic crystal structure
database (icsd)present and future. Crystallography Reviews, 10(1):17–22, 2004.
 Samad Hajinazar, Junping Shao, and Aleksey N Kolmogorov. Stratiﬁed construction of neural network based
interatomic models for multicomponent materials. Physical Review B, 95(1):014114, 2017.
 Linfeng Zhang, Jiequn Han, Han Wang, Roberto Car,
and Weinan E.
Constructing coarse-grained
models via deep neural networks. The Journal of Chemical Physics, 149(3):034101, 2018.
 Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
Sun. Deep residual learning for image recognition. In
Proceedings of the IEEE conference on computer vision
and pattern recognition, pages 770–778, 2016.
 Charles Kittel. Introduction to solid state physics. Wiley
New York, 2004.
 FW Von Batchelder and RF Raeuchle. Lattice constants
and brillouin zone overlap in dilute magnesium alloys.
Physical Review, 105(1):59, 1957.
 P Tzanetakis, J Hillairet, and G Revel. The formation
energy of vacancies in aluminium and magnesium. physica status solidi (b), 75(2):433–439, 1976.
 Leon J Slutsky and CW Garland.
Elastic constants
of magnesium from 4.2 k to 300 k.
Physical Review,
107(4):972, 1957.
 DH Sastry, YVRK Prasad, and KI Vasu. On the stacking fault energies of some close-packed hexagonal metals.
Scripta Metallurgica, 3(12):927–929, 1969.
 SH Zhang, IJ Beyerlein, Dominik Legut, ZH Fu, Z Zhang,
SL Shang, ZK Liu, TC Germann, and RF Zhang. Firstprinciples investigation of strain eﬀects on the stacking fault energies, dislocation core structure, and peierls
stress of magnesium and its alloys. Physical Review B,
95(22):224106, 2017.
 These structures are mp-1038916,
mp-1094116,
568106, mp-17659, mp-12766, mp-1039141, mp-1094685,
mp-2151, mp-1094700, mp-1094970, mp-1016271, mp-