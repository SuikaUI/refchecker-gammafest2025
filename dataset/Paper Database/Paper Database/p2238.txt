Solving the Quantum Many-Body Problem with Artiﬁcial Neural Networks
Giuseppe Carleo∗
Theoretical Physics, ETH Zurich, 8093 Zurich, Switzerland
Matthias Troyer
Theoretical Physics, ETH Zurich, 8093 Zurich, Switzerland
Quantum Architectures and Computation Group,
Microsoft Research, Redmond, WA 98052, USA and
Station Q, Microsoft Research, Santa Barbara, CA 93106-6105, USA
The challenge posed by the many-body problem in quantum physics originates from
the diﬃculty of describing the non-trivial correlations encoded in the exponential complexity of the many-body wave function. Here we demonstrate that systematic machine
learning of the wave function can reduce this complexity to a tractable computational
form, for some notable cases of physical interest.
We introduce a variational representation of quantum states based on artiﬁcial neural networks with variable number
of hidden neurons.
A reinforcement-learning scheme is then demonstrated, capable
of either ﬁnding the ground-state or describing the unitary time evolution of complex
interacting quantum systems. We show that this approach achieves very high accuracy
in the description of equilibrium and dynamical properties of prototypical interacting
spins models in both one and two dimensions, thus oﬀering a new powerful tool to
solve the quantum many-body problem.
The wave function Ψ is the fundamental object in
quantum physics and possibly the hardest to grasp in
a classical world. Ψ is a monolithic mathematical quantity that contains all the information on a quantum state,
be it a single particle or a complex molecule. In principle, an exponential amount of information is needed to
fully encode a generic many-body quantum state. However, Nature often proves herself benevolent, and a wave
function representing a physical many-body system can
be typically characterized by an amount of information
much smaller than the maximum capacity of the corresponding Hilbert space.
A limited amount of quantum entanglement, as well as the typicality of a small
number of physical states, are then the blocks on which
modern approaches build upon to solve the many-body
Schrödinger’s equation with a limited amount of classical
resources.
Numerical approaches directly relying on the wave
function can either sample a ﬁnite number of physically relevant conﬁgurations or perform an eﬃcient compression of the quantum state. Stochastic approaches,
like quantum Monte Carlo (QMC) methods, belong to
the ﬁrst category and rely on probabilistic frameworks
typically demanding a positive-semideﬁnite wave function. . Compression approaches instead rely on ef-
ﬁcient representations of the wave function, and most
notably in terms of matrix product states (MPS) 
or more general tensor networks . Examples of systems where existing approaches fail are however numerous, mostly due to the sign problem in QMC , and
to the ineﬃciency of current compression approaches in
high-dimensional systems. As a result, despite the striking success of these methods, a large number of unexplored regimes exist, including many interesting open
problems. These encompass fundamental questions ranging from the dynamical properties of high-dimensional
systems to the exact ground-state properties of
strongly interacting fermions .
At the heart of
this lack of understanding lyes the diﬃculty in ﬁnding
a general strategy to reduce the exponential complexity
of the full many-body wave function down to its most
essential features .
In a much broader context, the problem resides in the
realm of dimensional reduction and feature extraction.
Among the most successful techniques to attack these
problems, artiﬁcial neural networks play a prominent role
 . They can perform exceedingly well in a variety of
contexts ranging from image and speech recognition 
to game playing . Very recently, applications of neural
network to the study of physical phenomena have been
introduced . These have so-far focused on the classiﬁcation of complex phases of matter, when exact sampling of conﬁgurations from these phases is possible. The
challenging goal of solving a many-body problem without prior knowledge of exact samples is nonetheless still
unexplored and the potential beneﬁts of Artiﬁcial Intelligences in this task are at present substantially unknown.
It appears therefore of fundamental and practical interest to understand whether an artiﬁcial neural network
can modify and adapt itself to describe and analyze a
quantum system. This ability could then be used to solve
the quantum many-body problem in those regimes so-far
inaccessible by existing exact numerical approaches.
Here we introduce a representation of the wave function in terms of artiﬁcial neural networks speciﬁed by
a set of internal parameters W. We present a stochasarXiv:1606.02318v1 [cond-mat.dis-nn] 7 Jun 2016
Visible Layer
Hidden Layer
Figure 1. Artiﬁcial Neural network encoding a manybody quantum state of N spins. Shown is a restricted
Boltzmann machine architecture which features a set of N
visible artiﬁcial neurons (yellow dots) and a set of M hidden neurons (grey dots). For each value of the many-body
spin conﬁguration S = (σz
2, . . . σz
N), the artiﬁcial neural
network computes the value of the wave function Ψ(S).
tic framework for reinforcement learning of the parameters W allowing for the best possible representation of
both ground-state and time-dependent physical states of
a given quantum Hamiltonian H.
The parameters of
the neural network are then optimized (trained, in the
language of neural networks) either by static variational
Monte Carlo (VMC) sampling , or in time-dependent
VMC , when dynamical properties are of interest. We validate the accuracy of this approach studying the Ising and Heisenberg models in both one and
two-dimensions. The power of the neural-network quantum states (NQS) is demonstrated obtaining state-of-theart accuracy in both ground-state and out-of-equilibrium
In the latter case, our approach eﬀectively
solves the phase-problem traditionally aﬀecting stochastic Quantum Monte Carlo approaches, since their introduction.
Neural-Network Quantum States —
Consider a quantum system with N discrete-valued degrees of freedom
S = (S1, S2 . . . SN), which may be spins, bosonic occupation numbers, or similar. The many-body wave function is a mapping of the N−dimensional set S to (exponentially many) complex numbers which fully specify the
amplitude and the phase of the quantum state. The point
of view we take here is to interpret the wave function as
a computational black box which, given an input manybody conﬁguration S, returns a phase and an amplitude
according to Ψ(S). Our goal is to approximate this computational black box with a neural network, trained to
best represent Ψ(S). Diﬀerent possible choices for the artiﬁcial neural-network architectures have been proposed
to solve speciﬁc tasks, and the best architecture to describe a many-body quantum system may vary from one
case to another.
For the sake of concreteness, in the
following we specialize our discussion to restricted Boltzmann machines (RBM) architectures, and apply them to
describe spin 1/2 quantum systems. In this case, RBM
artiﬁcial networks are constituted by one visible layer of
N nodes, corresponding to the physical spin variables in a
chosen basis (say for example S = σz
1, . . . σz
N) , and a single hidden layer of M auxiliary spin variables (h1 . . . hM)
(see Fig. 1). This description corresponds to a variational expression for the quantum states which reads:
ΨM(S; W) =
ij Wijhiσz
where hi = {−1, 1} is a set of M hidden spin variables,
and the weights W = {ai, bj, Wij} fully specify the response of the network to a given input state S. Since this
architecture features no intra-layer interactions, the hidden variables can be explicitly traced out, and the wave
function reads Ψ(S; W) = e
i=1Fi(S), where
Fi(S) = 2 cosh
The network weights
are, in general, to be taken complex-valued in order to
provide a complete description of both the amplitude and
the wave-function’s phase.
The mathematical foundations for the ability of NQS
to describe intricate many-body wave functions are the
numerously established representability theorems , which guarantee the existence of network approximates of high-dimensional functions, provided a suﬃcient
level of smoothness and regularity is met in the function
to be approximated. Since in most physically relevant
situations the many-body wave function reasonably satisﬁes these requirements, we can expect the NQS form
to be of broad applicability.
One of the practical advantages of this representation is that its quality can, in
principle, be systematically improved upon increasing the
number of hidden variables. The number M (or equivalently the density α = M/N) then plays a role analogous
to the bond dimension for the MPS. Notice however that
the correlations induced by the hidden units are intrinsically non local in space and are therefore well suited to
describe quantum systems in arbitrary dimension. Another convenient point of the NQS representation is that
it can be formulated in a symmetry-conserving fashion.
For example, lattice translation symmetry can be used
to reduce the number of variational parameters of the
NQS ansatz, in the same spirit of shift-invariant RBM’s
 . Speciﬁcally, for integer hidden variable density
α = 1, 2, . . . , the weight matrix takes the form of feature
ﬁlters W (f)
, for f ∈[1, α]. These ﬁlters have a total of
αN variational elements in lieu of the αN 2 elements of
the asymmetric case (see Supp. Mat. for further details).
Given a general expression for the quantum manybody state, we are now left with the task of solving the
many-body problem upon machine learning of the network parameters W. In the most interesting applications
the exact many-body state is unknown, and it is typically found upon solution either of the static Schrödinger
Heisenberg 1D
Heisenberg 2D
Neural Network representation of the many-body ground states of prototypical spin models in one
and two dimensions. In the left group of panels we show the feature maps for the one-dimensional TFI model at the critical
point h = 1, as well as for the AFH model. In both cases the hidden-unit density is α = 4 and the lattices comprise 80
sites. Each horizontal colormap shows the values that the f-th feature map W (f)
takes on the j-th lattice site (horizontal axis,
broadened along the vertical direction for clarity). In the right group of panels we show the feature maps for the two-dimensional
Heisenberg model on a square lattice, for α = 16. In this case the the horizontal (vertical) axis of the colormaps correspond
to the x(y) coordinates on a 10 × 10 square lattice. Each of the feature maps act as eﬀective ﬁlters on the spin conﬁgurations,
capturing the most important quantum correlations.
equation H |Ψ⟩= E |Ψ⟩, either of the time-dependent
one iH |Ψ( t)⟩=
dt |Ψ(t)⟩, for a given Hamiltonian H.
In the absence of samples drawn according to the exact
wave function, supervised learning of Ψ is therefore not a
viable option. Instead, in the following we derive a consistent reinforcement learning approach, in which either
the ground-state wave function or the time-dependent
one are learned on the basis of feedback from variational
principles.
Ground State —
To demonstrate the accuracy of
the NQS in the description of complex many-body
quantum states, we ﬁrst focus on the goal of ﬁnding the best neural-network representation of the unknown ground state of a given Hamiltonian H.
this context, reinforcement learning is realized through
minimization of the expectation value of the energy
E(W) = ⟨ΨM|H|ΨM⟩/⟨ΨM|ΨM⟩with respect to the
network weights W.
In the stochastic setting, this is
achieved with an iterative scheme. At each iteration k, a
Monte Carlo sampling of |ΨM(S; Wk)|2 is realized, for a
given set of parameters Wk. At the same time, stochastic
estimates of the energy gradient are obtained. These are
then used to propose a next set of weights Wk+1 with an
improved gradient-descent optimization . The overall computational cost of this approach is comparable
to that of standard ground-state Quantum Monte Carlo
simulations (see Supp. Material).
To validate our scheme, we consider the problem of
ﬁnding the ground state of two prototypical spin models, the transverse-ﬁeld Ising (TFI) model and the antiferromagnetic Heisenberg (AFH) model. Their Hamiltonians are
respectively, where σx, σy, σz are Pauli matrices.
In the following, we consider the case of both one and
two dimensional lattices with periodic boundary conditions (PBC). In Fig.
2 we show the optimal network
structure of the ground states of the two spin models for
a hidden variables density α = 4 and with imposed translational symmetries. We ﬁnd that each ﬁlter f = [1, . . . α]
learns speciﬁc correlation features emerging in the ground
state wave function. For example, in the 2D case it can be
seen (Fig. 2, rightmost panels) how the neural network
learns patterns corresponding to anti-ferromagnetic correlations. The general behavior of the NQS is completely
analogous to what observed in convolutional neural networks, where diﬀerent layers learn speciﬁc structures of
the input data.
3 we show the accuracy of the NQS states,
quantiﬁed by the relative error on the ground-state energy ϵrel = (ENQS(α) −Eexact) / |Eexact |, for several values of α and model parameters.
In the left panel, we
compare the variational NQS energies with the exact result obtained by fermionization of the TFI model, on
a one-dimensional chain with PBC. The most striking
result is that NQS achieve a controllable and arbitrary
Figure 3. Finding the many-body ground-state energy with neural-network quantum states. Shown is the error of
the NQS ground-state energy relative to the exact value, for several test cases. Arbitrary precision on the ground-state energy
can be obtained upon increasing the hidden units density, α. (Left panel) Accuracy for the one-dimensional TFI model, at a
few values of the ﬁeld strength h, and for a 80 spins chain with PBC. Points below 10−8 are not shown to easy readability.
(Central panel) Accuracy for the one-dimensional AFH model, for a 80 spins chain with PBC, compared to the Jastrow ansatz
(horizontal dashed line). (Right panel) Accuracy for the AFH model on a 10 × 10 square lattice with PBC, compared to the
precision obtained by EPS (upper dashed line) and PEPS (lower dashed line). For all cases considered here the NQS description
reaches MPS-grade accuracies in 1D, while it systematically improves the best known variational states for 2D ﬁnite lattice
accuracy which is compatible with a power-law behavior
in α. The hardest to learn ground-state is at the quantum critical point h = 1, where nonetheless a remarkable
accuracy of one part per million can be easily achieved
with a relatively modest density of hidden units. The
same remarkable accuracy is obtained for the more complex one-dimensional AFH model (central panel). In this
case we observe as well a systematic drop in the groundstate energy error, which for a small α = 4 attains the
same very high precision obtained for the TFI model at
the critical point.
Our results are compared with the
accuracy obtained with the spin-Jastrow ansatz (dashed
line in the central panel), which we improve by several
orders of magnitude.
It is also interesting to compare
the value of α with the MPS bond dimension M, needed
to reach the same level of accuracy.
For example, on
the AFH model with PBC, we ﬁnd that with a standard
DMRG implementation we need M ∼160 to reach
the accuracy we have at α = 4. This points towards a
more compact representation of the many-body state in
the NQS case, which features about 3 orders of magnitude less variational parameters than the corresponding
MPS ansatz.
We next study the AFH model on a two-dimensional
square lattice, comparing in the right panel of Fig.
to QMC results .
As expected from entanglement
considerations, the 2D case proves harder for the NQS.
Nonetheless, we always ﬁnd a systematic improvement
of the variational energy upon increasing α, qualitatively
similar to the 1D case. The increased diﬃculty of the
problem is reﬂected in a slower convergence. We still obtain results at the level of existing state-of-the-art methods or better. In particular, with a relatively small hidden unit density (α ∼4) we already obtain results at
the same level than the best known variational ansatz
to-date for ﬁnite clusters (the EPS of Ref. and the
PEPS states of Ref.
Further increasing α then
leads to a sizable improvement and consequently yields
the best variational results so-far-reported for this 2D
model on ﬁnite lattices.
Unitary Dynamics —
NQS are not limited to groundstate problems but can be extended to the timedependent Schrödinger equation. For this purpose we de-
ﬁne complex-valued and time-dependent network weights
W(t) which at each time t are trained to best reproduce
the quantum dynamics, in the sense of the Dirac-Frenkel
time-dependent variational principle . In this context, the variational residuals
R(t; ˙W(t)) = dist(∂tΨ(W(t)), −iHΨ)
are the objective functions to be minimized as a function of the time derivatives of the weights
˙W(t) (see
Supp. Mat.) In the stochastic framework, this is achieved
by a time-dependent VMC method , which samples |ΨM(S; W(t))|2 at each time and provides the best
stochastic estimate of the ˙W(t) that minimize R2(t), with
a computational cost O(αN 2). Once the time derivatives
determined, these can be conveniently used to obtain the
full time evolution after time-integration.
To demonstrate the eﬀectiveness of the NQS in the
dynamical context, we consider the unitary dynamics induced by quantum quenches in the coupling constants of
our spin models.
In the TFI model we induce a nontrivial quantum dynamics by means of an instantaneous
change in the transverse ﬁeld: the system is initially prepared in the ground-state of the TFI model for some
h = (4 →2)
h = (1/2 →1)
Jz = (1 →2)
Jz = (1 →1/2)
Figure 4. Describing the many-body unitary time evolution with neural-network quantum states. Shown are
results for the time evolution induced by a quantum quench in the microscopical parameters of the models we study (the
transverse ﬁeld h, for the TFI model and the coupling constant Jz in the AFH model). (Left Panel) NQS results (solid lines)
are compared to exact results for the transverse spin polarization in the one-dimensional TFI model (dashed lines). (Right
Panel) In the AFH model, the time-dependent nearest-neighbors spin correlations are compared to exact numerical results
obtained with t-DMRG for an open one-dimensional chain representative of the thermodynamic limit (dashed lines).
transverse ﬁeld, hi, and then let evolve under the action
of the TFI Hamiltonian with a transverse ﬁeld hf ̸= hi.
We compare our results with the analytical solution obtained from fermionization of the TFI model for a onedimensional chain with PBC. In the left panel of Fig. 4
the exact results for the time-dependent transverse spin
polarization are compared to NQS with α = 4. In the
AFH model, we study instead quantum quenches in the
longitudinal coupling Jz and monitor the time evolution
of the nearest-neighbors correlations. Our results for the
time evolution (and with α = 4 ) are compared with the
numerically-exact MPS dynamics for a system
with open boundaries (see Fig. 4, right panel).
The high accuracy obtained also for the unitary dynamics further conﬁrms that neural network-based approaches can be fruitfully used to solve the quantum
many-body problem not only for ground-state properties
but also to model the evolution induced by a complex set
of excited quantum states. It is all in all remarkable that
a purely stochastic approach can solve with arbitrary degree of accuracy a class of problems which have been
traditionally inaccessible to QMC methods for the past
50 years. The ﬂexibility of the NQS representation indeed allows for an eﬀective solution of the infamous phase
problem plaguing the totality of existing exact stochastic
schemes based on Feynman’s path integrals.
Variational quantum states based on artiﬁcial neural networks can be used to eﬃciently capture
the complexity of entangled many-body systems both in
one a two dimensions. Despite the simplicity of the restricted Boltzmann machines used here, very accurate results for both ground-state and dynamical properties of
prototypical spin models can be readily obtained. Potentially many novel research lines can be envisaged in the
near future. For example, the inclusion of the most recent
advances in machine learning, like deep network architectures, might be further beneﬁcial to increase the expressive power of the NQS. Furthermore, the extension of
our approach to treat quantum systems other than interacting spins is, in principle, straightforward. In this respect, applications to answer the most challenging questions concerning interacting fermions in two-dimensions
can already be anticipated. Finally, at variance with Tensor Network States, the NQS feature intrinsically nonlocal correlations which can lead to substantially more
compact representations of many-body quantum states.
A formal analysis of the NQS entanglement properties
might therefore bring about substantially new concepts
in quantum information theory.
We acknowledge discussions with F. Becca, J.F. Carrasquilla, M. Dolﬁ, J. Osorio, D. Patanï¿œ, and S.
The time-dependent MPS results have been
obtained with the open-source ALPS implementation
 . This work was supported by the European Research Council through ERC Advanced Grant SIMCOFE
by the Swiss National Science Foundation through NCCR
QSIT, and by Microsoft Research. This paper is based
upon work supported in part by ODNI, IARPA via MIT
Lincoln Laboratory Air Force Contract No. FA8721-05-
C-0002. The views and conclusions contained herein are
those of the authors and should not be interpreted as necessarily representing the oﬃcial policies or endorsements,
either expressed or implied, of ODNI, IARPA, or the U.S.
Government. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purpose not-withstanding any copyright annotation thereon.
∗ 
 Ceperley, D. & Alder, B. Quantum Monte Carlo. Science
231, 555–560 .
 Foulkes, W. M. C., Mitas, L., Needs, R. J. & Rajagopal,
Quantum Monte Carlo simulations of solids.
Mod. Phys. 73, 33–83 .
 Carlson, J. et al.
Quantum Monte Carlo methods for
nuclear physics. Rev. Mod. Phys. 87, 1067–1118 .
 White, S. R. Density matrix formulation for quantum
renormalization groups. Phys. Rev. Lett. 69, 2863–2866
 Rommer, S. & Ostlund, S. Class of ansatz wave functions
for one-dimensional spin systems and their relation to the
density matrix renormalization group. Phys. Rev. B 55,
2164–2181 .
 Schollwöck, U.
The density-matrix renormalization
group in the age of matrix product states.
Physics 326, 96–192 .
 Orús, R.
A practical introduction to tensor networks:
Matrix product states and projected entangled pair
states. Annals of Physics 349, 117–158 .
 Verstraete, F., Murg, V. & Cirac, J. I.
Matrix product states, projected entangled pair states, and variational renormalization group methods for quantum spin
systems. Advances in Physics 57, 143–224 .
 Troyer, M. & Wiese, U.-J.
Computational complexity and fundamental limitations to fermionic quantum
Monte Carlo simulations.
Physical Review Letters 94
 Polkovnikov, A., Sengupta, K., Silva, A. & Vengalattore,
M. Colloquium: Nonequilibrium dynamics of closed interacting quantum systems. Reviews of Modern Physics
83, 863–883 .
 J. Eisert, M. Friesdorf & C. Gogolin. Quantum manybody systems out of equilibrium. Nat Phys 11, 124–130
 Montorsi, A.
The Hubbard Model:
A Collection of
Reprints .
 Thouless, D. J. The Quantum Mechanics of Many-Body
Systems: Second Edition , reprint of
the academic press edn.
 Freericks, J. K., Nikolić, B. K. & Frieder, O.
nonequilibrium
paradigm for extreme data science. Int. J. Mod. Phys. B
28, 1430021 .
 Hinton, G. E. & Salakhutdinov, R. R. Reducing the Dimensionality of Data with Neural Networks. Science 313,
504–507 .
 LeCun, Y., Bengio, Y. & Hinton, G. Deep learning. Nature 521, 436–444 .
 Silver, D. et al.
Mastering the game of Go with deep
neural networks and tree search. Nature 529, 484–489
 Schoenholz, S. S., Cubuk, E. D., Sussman, D. M., Kaxiras, E. & Liu, A. J. A structural approach to relaxation
in glassy liquids. Nat Phys 12, 469–471 .
 Carrasquilla, J. & Melko, R. G. Machine learning phases
of matter. arXiv:1605.01735 [cond-mat] . ArXiv:
1605.01735.
 Wang, L.
Discovering Phase Transitions with Unsupervised Learning.
 
 . ArXiv: 1606.00318.
 McMillan, W. L. Ground State of Liquid He4. Phys. Rev.
138, A442–A451 .
 Carleo, G., Becca, F., Schiro, M. & Fabrizio, M. Localization and Glassy Dynamics Of Many-Body Quantum
Systems. Scientiﬁc Reports 2, 243 .
 Carleo, G., Becca, F., Sanchez-Palencia, L., Sorella, S. &
Fabrizio, M. Light-cone eﬀect and supersonic correlations
in one- and two-dimensional bosonic superﬂuids. Phys.
Rev. A 89, 031602 .
 Kolmogorov, A. N. On the representation of continuous
functions of several variables by superpositions of continuous functions of a smaller number of variables. Doklady
Akademii Nauk SSSR 108, 179–182 .
 Hornik, K. Approximation capabilities of multilayer feedforward networks. Neural Networks 4, 251–257 .
 Le Roux, N. & Bengio, Y. Representational Power of Restricted Boltzmann Machines and Deep Belief Networks.
Neural Computation 20, 1631–1649 .
 Sohn, K. & Lee, H. Learning Invariant Representations
with Local Transformations. 1311–1318 .
 Norouzi, M., Ranjbar, M. & Mori, G. Stacks of convolutional Restricted Boltzmann Machines for shift-invariant
feature learning. In IEEE Conference on Computer Vision and Pattern Recognition, 2009. CVPR 2009, 2735–
2742 .
 Sorella, S., Casula, M. & Rocca, D. Weak binding between two aromatic rings: Feeling the van der Waals attraction by quantum Monte Carlo methods. The Journal
of Chemical Physics 127, 014105 .
 Dolﬁ, M. et al. Matrix product state applications for the
ALPS project. Computer Physics Communications 185,
3430–3440 .
 Sandvik, A. W. Finite-size scaling of the ground-state parameters of the two-dimensional Heisenberg model. Physical Review B 56, 11678–11690 .
 Mezzacapo, F., Schuch, N., Boninsegni, M. & Cirac, J. I.
Ground-state properties of quantum many-body systems:
entangled-plaquette states and variational Monte Carlo.
New J. Phys. 11, 083026 .
 Lubasch, M., Cirac, J. I. & Bañuls, M.-C. Algorithms for
ﬁnite projected entangled pair states. Phys. Rev. B 90,
064425 .
 Dirac, P. a. M.
Note on Exchange Phenomena in the
Thomas Atom. Mathematical Proceedings of the Cambridge Philosophical Society 26, 376–385 .
 Frenkel, I. Wave Mechanics: Advanced General Theory.
No. v. 2 in The International series of monographs on
nuclear energy: Reactor design physics .
 White, S. R. & Feiguin, A. E. Real-Time Evolution Using
the Density Matrix Renormalization Group. Phys. Rev.
Lett. 93, 076401 .
 Vidal, G. Eﬃcient Simulation of One-Dimensional Quantum Many-Body Systems. Phys. Rev. Lett. 93, 040502
 Daley, A. J., Kollath, C., Schollwock, U. & Vidal,
Time-dependent density-matrix renormalizationgroup using adaptive eﬀective Hilbert spaces.
of Statistical Mechanics-Theory and Experiment P04005
 Bauer, B. et al.
The ALPS project release 2.0: open
source software for strongly correlated systems. J. Stat.
Mech. 2011, P05001 .
 Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N.,
Teller, A. H. & Teller, E. Equation of State Calculations
by Fast Computing Machines. The Journal of Chemical
Physics 21, 1087–1092 .
 Choi, S.-C. T. & Saunders, M. A.
Algorithm 937:
MINRES-QLP for Symmetric and Hermitian Linear
Equations and Least-Squares Problems.
Math Softw 40 .
Appendix A: Stochastic Optimization For The
Ground State
In the ﬁrst part of our Paper we have considered the
goal of ﬁnding the best representation of the ground
state of a given quantum Hamiltonian H.
The expectation value over our variational states E(W) =
⟨ΨM|H|ΨM⟩/⟨ΨM|ΨM⟩is a functional of the network
weights W. In order to obtain an optimal solution for
which ∇E(W⋆) = 0, several optimization approaches can
be used. Here, we have found convenient to adopt the
Stochastic Reconﬁguration (SR) method of Sorella et al.
 , which can be interpreted as an eﬀective imaginarytime evolution in the variational subspace. Introducing
the variational derivatives with respect to the k-th network parameter,
ΨM(S)∂WkΨM(S),
as well as the so-called local energy
Eloc(S) = ⟨S|H|ΨM⟩
the SR updates at the p−th iteration are of the form
W(p + 1) = W(p) −γS−1(p)F(p),
where we have introduced the (positive-deﬁnite) covariance matrix
Skk′(p) = ⟨O⋆
the forces
Fk(p) = ⟨ElocO⋆
k⟩−⟨Eloc⟩⟨O⋆
and a scaling parameter γ(p). Since the covariance matrix can be non-invertible, S−1 denotes its Moore-Penrose
pseudo-inverse. Alternatively, an explicit regularization
can be applied, of the form Sreg
k,k′ = Sk,k′ +λ(p)δk,k′Sk,k .
In our work we have preferred the latter regularization,
with a decaying parameter λ(p) = max(λ0bp, λmin) and
typically take λ0 = 100, b = 0.9 and λmin = 10−4.
Initially the network weights W are set to some small
random numbers and then optimized with the procedure
outlined above. In Fig. 5 we show the typical behavior of the optimization algorithm, which systematically
approaches the exact energy upon increasing the hidden
units density α.
Appendix B: Time-Dependent Variational Monte
In the second part of our Paper we have considered the
problem of solving the many-body Schrödinger equation
with a variational ansatz of the NQS form. This task
can be eﬃciently accomplished by means of the Time-
Dependent Variational Monte Carlo (t-VMC) method of
Carleo et al.
In particular, the residuals
R(t; ˙W(t)) = dist(∂tΨ(W(t)), −iHΨ)
are a functional of the variational parameters derivatives,
˙W(t), and can be interpreted as the quantum distance
between the exactly-evolved state and the variationally
evolved one. Since in general we work with unnormalized quantum states, the correct Hilbert-space distance
is given by the Fubini-Study metrics, given by
distFS(Φ, Φ′) = arccos
⟨Φ′ |Φ⟩⟨Φ |Φ′⟩
⟨Φ′ |Φ′⟩⟨Φ |Φ⟩.
The explicit form of the residuals is then obtained considering Φ = Ψ+δ∂tΨ(W(t)) and Φ
′ = Ψ−iδHΨ(W(t)).
Taking the lowest order in the time-step δ and explicitly
minimizing distFS(Φ, Φ′)2, yields the equations of motion
˙W(t) = −iS−1(t)F(t),
where the correlation matrix and the forces are deﬁned
analogously to the previous section.
In this case the
diagonal regularization, in general, cannot be applied,
and S−1(t) strictly denotes the Moore-Penrose pseudoinverse.
The outlined procedure is globally stable as also already proven for other wave functions in past works using the t-VMC approach. In Fig. 6 we show the typical
behavior of the time-evolved physical properties of interest, which systematically approach the exact results
when increasing α.
Appendix C: Eﬃcient Stochastic Sampling
We complete the supplementary information giving an
explicit expression for the variational derivatives previously introduced and of the overall computational cost
of the stochastic sampling. We start rewriting the NQS
in the form
j=12 cosh θj(S),
with the eﬀective angles
θj(S) = bj +
The derivatives then read
ΨM(S)∂aiΨM(S) = σz
ΨM(S)∂bjΨM(S) = tanh [θj(S)] ,
ΨM(S)∂WijΨM(S) = σz
i tanh [θj(S)] .
# iteration
# iteration
−0.00002 −4.436×10−1
Figure 5. Convergence properties of the stochastic optimization. Variational energy for the 1D Heisenberg model as a
function of the Stochastic Reconﬁguration iterates, and for diﬀerent values of the hidden units density α. The system has PBC
over a chain of N = 40 spins. The energy converges smoothly to the exact energy (dashed horizontal line) upon increasing α.
In the Left panel we show a complete view of the optimization procedure and on the Right panel a zoom in the neighborhood
of the exact energy.
Convergence properties of the stochastic unitary evolution.
Time-dependent expectation value of the
transverse polarization along the x direction in the TFI model, for a quantum quench from hi = 1/2 to the critical interaction
t-VMC results are shown for diﬀerent values of the hidden units density α.
The system has periodic boundary
conditions over a chain of N = 40 spins.
(Left panel) The variational curves for the expectation value of the transverse
polarization converge smoothly to the exact solution (dashed line) upon increasing α. (Right panel) The relative residual error
r2(t) = R2(t)/D2
0(t), where D2
0(t) = distFS(Φ, Φ −iδH)2 is shown for diﬀerent values of the hidden unit density, and it is
systematically reduced increasing α.
In our stochastic procedure, we generate a Markov
chain of many-body conﬁgurations S(1)
. . . S(P ) sampling the square modulus of the wave function |ΨM(S)|2 for a given set of variational parameters.
This task can be achieved through a simple Metropolis-
Hastings algorithm , in which at each step of the
Markov chain a random spin s is ﬂipped and the new
conﬁguration accepted according to the probability
A(S(k) →S(k+1)) = min
ΨM(S(k+1))
In order to eﬃciently compute these acceptances, as well
as the variational derivatives, it is useful to keep in memory look-up tables for the eﬀective angles θj(S(k)) and update them when a new conﬁguration is accepted. These
are updated according to
θj(S(k+1)) = θj(S(k)) −2Wkjσz
when the spin s has been ﬂipped. The overall cost of a
Monte Carlo sweep (i.e. of O(N) single-spin ﬂip moves)
is therefore O(N × M) = O(αN 2). Notice that the computation of the variational derivatives comes at the same
computational cost as well as the computation of the local energies after a Monte Carlo sweep.
Appendix D: Iterative Solver
The most time-consuming part of both the SR optimization and of the t-VMC method is the solution of the
linear systems (A3 and B3) in the presence of a large
number of variational parameters Nvar. Explicitly forming the correlation matrix S, via stochastic sampling,
has a dominant quadratic cost in the number of variational parameters, O(N 2
var × NMC), where NMC denotes
the number of Monte Carlo sweeps. However, this cost
can be signiﬁcantly reduced by means of iterative solvers
which never form the covariance matrix explicitly. In particular, we adopt the MINRES-QLP method of Choi and
Saunders , which implements a modiﬁed conjugategradient iteration based on Lanczos tridiagonalization.
This method iteratively computes the pseudo-inverse S−1
within numerical precision.
The backbone of iterative
solvers is, in general, the application of the matrix to
be inverted to a given (test) vector.
This can be eﬃciently implemented due to the product structure of the
covariance matrix, and determines a dominant complexity of O(Nvar × NMC) operations for the sparse solver.
For example, in the most challenging case when translational symmetry is absent, we have Nvar = αN 2, and the
dominant computational cost for solving (A3 and B3) is
in line with the complexity of the previously described
Monte Carlo sampling.
Appendix E: Implementing Symmetries
Very often, physical Hamiltonians exhibit intrinsic
symmetries which must be satisﬁed also by their groundand dynamically-evolved quantum states. These symmetries can be conveniently used to reduce the number of
variational parameters in the NQS.
Let us consider a symmetry group deﬁned by a set of
linear transformations Ts, with s = 1, . . . S, such that the
spin conﬁgurations transform according to Tsσz = ˜σz(s).
We can enforce the NQS representation to be invariant
under the action of T deﬁning
Ψα(S; W) =
where the network weights have now a diﬀerent dimension with respect to the standard NQS. In particular, a(f)
and b(f) are vectors in the feature space with f = 1, . . . αs
and the connectivity matrix W (f)
contains αs × N elements.
Notice that this expression corresponds eﬀectively to a standard NQS with M = S × αs hidden variables.
Tracing out explicitly the hidden variables, we
Ψα(S; W) = e
f,s,j a(f) ˜
× ΠfΠs2 cosh
In the speciﬁc case of site translation invariance, we have
that the symmetry group has an orbit of S = N elements.
For a given feature f, the matrix W (f)
can be seen as a
ﬁlter acting on the N translated copies of a given spin
conﬁguration. In other words, each feature has a pool
of N associated hidden variables that act with the same
ﬁlter on the symmetry-transformed images of the spins.