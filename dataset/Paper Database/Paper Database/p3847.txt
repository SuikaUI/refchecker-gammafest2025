IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. XX, NO. XX, 2018
MPTV: Matching Pursuit Based Total Variation
Minimization for Image Deconvolution
Dong Gong, Mingkui Tan, Qinfeng Shi, Anton van den Hengel, and Yanning Zhang
Abstract—Total variation (TV) regularization has proven effective for a range of computer vision tasks through its preferential
weighting of sharp image edges. Existing TV-based methods,
however, often suffer from the over-smoothing issue and solution
bias caused by the homogeneous penalization. In this paper,
we consider addressing these issues by applying inhomogeneous
regularization on different image components. We formulate the
inhomogeneous TV minimization problem as a convex quadratic
constrained linear programming problem. Relying on this new
model, we propose a matching pursuit based total variation
minimization method (MPTV), speciﬁcally for image deconvolution. The proposed MPTV method is essentially a cuttingplane method, which iteratively activates a subset of nonzero
image gradients, and then solves a subproblem focusing on those
activated gradients only. Compared to existing methods, MPTV
is less sensitive to the choice of the trade-off parameter between
data ﬁtting and regularization. Moreover, the inhomogeneity
of MPTV alleviates the over-smoothing and ringing artifacts,
and improves the robustness to errors in blur kernel. Extensive
experiments on different tasks demonstrate the superiority of the
proposed method over the current state-of-the-art.
Index Terms—Total variation, image deconvolution, matching
pursuit, convex programming.
I. INTRODUCTION
ANY image restoration tasks can be formulated as an
inverse problem, which allows the recovery of the latent
image x from a measured image y. The imaging model can
be formulated as:
y = Ax + n,
where x ∈Rn denotes the latent image, y ∈Rn denotes
the measured image, A ∈Rn×n is a linear operator which
models the measurement process, and n ∈Rn is an additive
noise vector. Directly recovering x from model (1) is an illposed problem, because there are usually too many solutions.
A proper prior or regularizer for x is important for reducing the
ill-posedness of the problem. Given y and A, and assuming n
is sampled from i.i.d. Gaussian white noise, image restoration
can be achieved by solving the following for x:
2 + λΩ(x),
Dong Gong and Yanning Zhang are with the School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an, China,
710129 (e-mail: ; ).
Mingkui Tan is with South China University of Technology, Guangzhou,
China, 510006 (e-mail: ).
Qinfeng Shi and Anton van den Hengel are with The University
of Adelaide, SA 5005, Australia (e-mail: ; ).
Corresponding author: Qinfeng Shi. The ﬁrst two authors contributed
equally to this work.
where Ω(·) is the regularizer on x, and λ > 0 is a trade-off
parameter. Many kinds of regularizer Ω(·), such as the total
variation (TV) norm , wavelet frame-based sparse priors
 and Gaussian mixture models , have been proposed
to handle different image restoration tasks, e.g. denoising,
inpainting and deconvolution. In this paper, we focus on one
particular task, namely, non-blind image deconvolution.
For image deconvolution , , the matrix A in model (1)
and (2) represents a convolution matrix, with an embedded blur
kernel (a.k.a. point spread function, PSF) k. The degenerate
image y is usually modeled by
y = x ∗k + n,
where ∗denotes the 2D convolution operator. Non-blind
deconvolution seeks to recover x from the blurred image y
given a known blur kernel k (and thus A). The problem is
ill-posed and non-trivial to address. The practical importance
of the problem has motivated signiﬁcant research attention ,
 , , . In particular, TV regularized methods have been
intensively exploited and have demonstrated great success in
image deconvolution , , , .
The TV-based model was ﬁrst proposed by Rudin et al. 
for image denoising , , . It has subsequently been
applied to a variety of other tasks including deconvolution
 , , , super-resolution , and inpainting .
By assuming that the image gradients are sparse, TV-based
methods reﬂect the tendency of clear, sharp images towards
piecewise smoothness. Although ℓ0-norm regularization can be
applied to promote sparse solution directly, the resultant optimization problem is difﬁcult to solve due to its non-convexity.
In practice, ℓ1-norm or ℓ2,1-norm based TV regularization is
more commonly used , . In this paper, we consider the
ℓ2,1-norm based isotropic TV norm :
ΩTV(x) = ∥Dx∥2,1 =
i=1 ∥[(Dvx)i, (Dhx)i] ∥2,
where D = [DT
h]T, and Dv ∈Rn×n and Dh ∈Rn×n
denote the ﬁrst-order difference matrices in vertical and
horizontal directions, respectively. ∥· ∥2,1 denotes the ℓ2,1norm. Speciﬁcally, [(Dvx)i, (Dvx)i] denotes a 1-by-2 vector
concatenating the i-th element of Dvx and Dhx.
A variety of TV-based methods for reducing the impact of
both image noise and blur have been devised. These methods
tend to suffer from a common set of deﬁciencies, however.
Firstly, the homogeneous penalty may cause over-smoothing
of high-frequency image components (such as edges and
corners). Secondly, due to the regularization bias , ,
 rooted in the speciﬁc ℓ1-norm or ℓ2,1-norm, it is difﬁcult
 
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. XX, NO. XX, 2018
to select an appropriate trade-off hyper-parameter λ to achieve
a solution that has sparse gradients and suffers less bias issue.
Thirdly, existing TV-based deconvolution methods are usually
sensitive to errors or noise in k (i.e. A), and this often causes
heavy ringing artifacts in the latent image x , . For
existing TV methods, it is non-trivial to achieve a balance
between suppressing artifacts and preserving image details.
In this paper, we propose a matching pursuit algorithm,
called MPTV, for solving TV regularization based image
deconvolution. The paper extends our conference paper 
where we addressed the generalized lasso problem. The new
contributions of this paper are summarized as follows.
• We reformulate the TV minimization problem as a
quadratically constrained linear programming (QCLP)
problem and then propose a matching pursuit algorithm
called MPTV to address the resultant problem. Instead
of focusing on all the image gradients at the beginning,
we iteratively invoke the most beneﬁcial gradient subset,
followed by solving a subproblem constrained on selected
subsets only.
• The proposed MPTV method is able to alleviate the oversmoothing issue while yielding a solution with sparse
gradients due to the matching pursuit like optimization
strategy. Compared to existing methods, MPTV can help
to reduce the solution bias. Moreover, the proposed optimization scheme also helps to improve the robustness of
the method to noise and/or errors in A. In particular, for
the task of image deconvolution, MPTV helps to suppress
the ringing artifacts and recover the image details.
• Many TV-based methods require an extensive and often
imprecise selection of hyper-parameters to balance the
sparsity and the ﬁtness to observation. This issue can be
signiﬁcantly alleviated in the proposed MPTV method
due to the new formulation and optimization strategy,
particularly the early stopping strategy that will be introduced. In other words, MPTV is less sensitive to the
selection of the regularization parameter.
The remainder of this paper is organized as follows. In
Section II, we review related work in TV models and image
deconvolution. In Section III, we introduce our matching pursuit based TV minimization (MPTV) algorithm and discuss the
details, including stopping conditions, parameter setting, and
convergence analysis. Empirical studies on various datasets are
presented in Section V. We conclude in Section VI.
II. NOTATION AND RELATED WORK
A. Notation
Let A = [Ai,j] ∈Rm×n and v = [v1, ..., vn]T ∈Rn
denote a matrix and a vector, receptively, where T denotes
the transpose of a vector/matrix. Let 0 and 1 be vectors with
all zeros and all ones, respectively, and let I denote the identity
matrix. Let Ai or Ai be a matrix indexed for some purpose,
and let vi or vi be a vector indexed for some purpose.
Given a vector v, let diag(v) be a diagonal matrix with
diagonal elements equal to the vector v, and ∥v∥p be the ℓpnorm. Let ⊙denote the element-wise (Hadamard) product, ⊗
denote the Kronecker product and supp(v) denote the support
set of v . Given a positive integer n, let [n] = {1, ..., n}. Given
any index set T ⊆[n], let Tc be the complementary set of T,
i.e. Tc = [n] \ T, and card(T) be the cardinality of T. For a
vector v ∈Rn, let vi denote the i-th element of v, and vT
denote the subvector indexed by T. For a matrix A, let AT
denote the columns of A with indeces in T.
B. Total Variation Models
Total variation regularization has been the subject of much
attention over the past two decades, not least due to its
effectiveness in image processing , , compressive sensing and machine learning tasks , . Considering
the piecewise smooth property of images, Rudin et al. 
proposed the TV regularizer for image denoising. Following
that, many variants of the original TV regularizer have been
extensively studied. Beside the isotropic TV model proposed
in , anisotropic TV has also been wildly explored , .
To alleviate the optimization difﬁculties caused by the nondifferentiability of TV models, some approximate TV models
have been proposed, e.g. smooth TV and Huber-norm
based TV . To preserve the sparse nature of the image
gradients, the ℓ0-norm based TV regularizer was proposed
for edge-preserving image editing tasks and blur kernel
estimation . Motivated by the ℓ1−ℓ2-norm in compressive
sensing, Lou et al. proposed a weighted difference of
anisotropic and isotropic TV regularizers to alleviate the
over-smoothing incurred by classical TV methods. For these
methods, achieving acceptable performance is critically dependent on careful turning of hyper-parameters. In fact, due
to the bias nature in regularization, it is non-trivial to reduce
bias issue while pursing sparsity. To handle different types
of noises, different data ﬁtting functions are also studied.
Classical TV models , use ℓ2 loss to ﬁt the Gaussian
noise in observation. To improve the robustness of the model
to outliers, non-smooth loss functions, including ℓ1 loss ,
 , ℓ∞loss and ℓ0 loss , have been used to handle
Laplacian noise, uniform noise and impulse noise, respectively.
Various optimization strategies for TV regularized problems
have also been extensively investigated. Rudin et al. 
minimize the TV model using a gradient projection method,
which, converges slowly due to the non-smoothness of the
problem. Osher et al. proposed an iterative regularization
method based on Bregman distance minimization for solving
the TV based image restoration problem. Burger discussed a series of Bregman distance based approaches for
inverse problems and pointed out that the Bregman iteration
scheme is beneﬁcial for alleviating the bias caused by the TV
regularizer. In the past two decades, many other techniques
have been proposed to accelerate convergence, including the
primal-dual interior point method , the splitting Bregman
method , the half-quadratic formulation based method ,
and alternating direction multiplier methods . Speciﬁcally,
to handle the spatially inhomogeneous structural and textural
information in the image, some approaches proposed to use
spatially varying constraints with the TV regularization ,
 . Gilboa et al. proposed a variational framework
for image denoising, in which spatially varying constraints
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. XX, NO. XX, 2018
are used for different image local areas. In , a spatially
dependent parameter selection scheme is proposed to achieve
spatially adaptive TV regularization for image restoration.
C. Image Deconvolution
Abundant studies have been conducted on (non-blind) image deconvolution, starting from the classical ones including
Wiener ﬁlter and Richadson-Lucy (RL) algorithms . Based
on the piecewise smooth property of natural images and
statistical studies of image gradients, many methods perform
image deconvolution by preserving signiﬁcant edges or sparse
gradients. To this end, a series of TV based methods have
been extensively exploited , , . Additionally, in
 , an iterative reweighed least square (IRLS) has been
used to achieve excellent results by encouraging the piecewise smooth property in image deconvolution. Krishnan and
Fergus proposed to perform image deconvolution using a
hyper-Laplacian prior. Moreover, instead of preserving sparse
gradients, many other methods also perform well by relying on
patch similarity , kernel similarity , progressive multiscale deconvolution , group based sparse representation
 , or stochastic optimization .
Besides the empirically designed models above, some methods have been proposed to learn models for image deconvolution , , , , . The generative prior learning
methods , focus on learning image priors/regularizers
(e.g. a Gaussian Mixture Model based prior in ) from a
set of clear and sharp images, which usually leads to nonconvex problems and time-consuming optimization. For the
sake of computational efﬁciency, some discriminative learning
based methods , , learn the deconvolution models
(e.g. a convolutional neural network based model ) relying
on pairs of sharp and blurred images. The learning based
deconvolution methods are effective to utilize more information from training examples than the empirically designed
approaches. However, suffering from limited ﬂexibility on the
model design, existing learning based methods , often
require customized training for speciﬁc blur kernels or noise,
which limits their practicability.
In practice, image deconvolution results often suffer from
wave-like ringing artifacts, especially in regions near strong
edges. This issue may be caused by the unavoidable error
in blur kernel estimation , the Gibbs phenomenon ,
the zero values in the frequency spectrum of the blur kernel
 and/or the mismatch between the data and the model
(e.g. non-conforming noise, saturation) , . To reduce
these artifacts in deconvolution, Yuan et al. performed
the Richardson-Lucy algorithm in a residual inter-and-intrascale scheme with edge-preserving bilateral ﬁlters. Shan et al.
 proposed to combin a smoothness constraint with the ℓ1norm regularizer. Mosleh et al. proposed a post processing
method to detect and suppress ringing based on frequency
analysis. Some methods tried to avoid artifacts using more
accurate imaging models and data ﬁtting terms , , .
III. MATCHING PURSUIT TOTAL VARIATION
FOR IMAGE DECONVOLUTION
In this section, we present a matching pursuit based TV
minimization method for non-blind image deconvolution.
A. A QCLP Reformulation of TV Model
Image deconvolution is rendered more challenging by the
ill-posed nature of the problem and the noise in both the
blurred image and the estimated blur kernel. With the TV
regularizer introduced in (3), the clear and sharp image can
be recovered by solving the following classic TV-norm regularized optimization problem:
2 + λΩTV(x),
where ΩTV(x) = ∥Dx∥2,1 = Pn
i=1 ∥[(Dvx)i, (Dhx)i] ∥2.
In problem (4), the TV regularizer treats all elements in x
homogeneously. Although the ℓ2,1-norm is used for inducing
sparsity on image gradients, it tends to shrink the large elements in image gradients towards zero . As a result, while
the TV regularizer in (4) favors a piecewise smooth solution,
it may incur over-smoothing deconvolution results due to
the bias issue , . We thus consider minimizing the total
variation value by explicitly detecting and only preserving the
sparse nonzero gradients, while suppressing the insigniﬁcant
components. In this way, we can maintain the signiﬁcant
high-frequency elements in the image and suppress the noise.
To illustrate the above issue, we show an example for 1D
signal deconvolution in Fig. 1. This experiment shows that
minimizing TV with active gradient detection can reduce the
regularization bias signiﬁcantly, and thus alleviates the oversmoothness and increases estimation accuracy accordingly.
To explicitly detect the sparse nonzero image gradients in
image deconvolution, we will formulate the TV model with
a new binary vector to indicate the nonzero gradients, which
will be estimated with the image simultaneously. Firstly, we
introduce z = [zT
h]T ∈R2n to denote the concatenation
of the gradients of two directions, namely Dvx and Dhx.
To ﬁnd the most signiﬁcant image gradients which contribute
the most to the quality of image deconvolution, we introduce
two binary vectors τv ∈{0, 1}n and τh ∈{0, 1}n to indicate
the nonzero ones in Dvx and Dhx, respectively. We further
deﬁne τv = τh ≜τ, since each term in the ℓ2,1-norm
based TV regularizer consists of two elements over vertical
and horizontal directions, e.g. (Dvx)i and (Dhx)i shown
in (3). We then let eτ
= [τ T, τ T]T indicate the nonzero
components in Dx via (z ⊙eτ). To induce the sparsity, we
impose an ℓ0-norm constraint ∥τ∥0 ≤κ. For simplicity, let
Λ = {τ|τ ∈{0, 1}n, ∥τ∥0 ≤κ} be the feasible domain of τ.
With the introduction of τ and the auxiliary variable z,
we propose to address the following TV-norm regularized
i=1 ∥[(zv)i, (zh)i] ∥2
s.t. ξ = y −Ax, Dx = z ⊙eτ,
where (zv)i and (zh)i denote the i-th elements of zv and zh,
respectively. The constraint ∥τ∥0 ≤κ explicitly constrains the
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. XX, NO. XX, 2018
(a) Blurred signal y, blur kernel k and the original sharp signal x
(b) Recovered signal x
(c) Gradients Dx of recovered signal
Fig. 1. Deconvolution results on a 1D signal example. (a) The blurred signal y is generated by blurring the sharp signal xgt with the blur kernel k. In (b) and
(c), the results from left to right are generated by solving the TV regularized model using ADMM (TV-ADMM), solving problem (6) using the proposed
MPTV method (κ = 1), and solving problem (6) using ADMM given the support of the ground truth signal xgt, respectively. (c) shows the gradients of the
recovered signal in (b). In each case, λ = 0.01.
sparsity of gradients via Dx = z ⊙eτ, leading to an image x
with sparse Dx and a small total variation.
To simplify the computation of Pn
i=1 ∥[(zv)i, (zh)i] ∥2, we
deﬁne binary matrices Ci ∈{0, 1}2×2n, ∀i ∈[n] to select both
(zv)i and (zh)i, ∀i ∈[n] from z via multiplication between Ci
and z, i.e. Ciz. As an example, there is Ciz = [(zv)i, (zh)i]T.
In each Ci, the i-th and (i + n)-th elements on the two rows,
respectively, are 1, and the rest are 0. Then, the ℓ2,1-norm in
problem (5) can be rewritten as Pn
i=1 ∥Ciz∥2. Moreover, we
introduce a new vector d to represent z, and let its subvectors
di = Ciz, ∀i ∈[n]. Then, we can obtain an equivalent
formulation of problem (5):
s.t. ξ = y −Ax, Dx = z ⊙eτ,
di = Ciz, ∀i ∈[n].
In problem (6), the integer κ reﬂects our rough knowledge
of the sparsity of Dx. Note that there are |Λ| = Pκ
feasible τ’s in Λ. Problem (6) tends to ﬁnd the optimal τ from
Λ to minimize the objective in (6). Even though the sparsity
constraint ∥τ∥0 ≤κ explicitly induces sparsity in image
gradients, the regularizer λ Pn
i=1 ∥di∥2 is still necessary for
the robust recovery of z due to possible noise in y. Meanwhile,
beneﬁting from the sparsity constraint and the optimization
scheme that will be introduced, a small λ can be used to
reduce the bias induced by the regularization , , which
is beneﬁcial in alleviating over-smoothness.
Unfortunately, problem (6) is a mixed integer programming
problem, and thus hard to address. We consider a convex
relaxation to this problem. To achieve this, we ﬁrst introduce
the following proposition.
Proposition 1. By deriving the dual form of the inner minimization problem in (6) w.r.t. x, ξ, z and d given ﬁxed τ ∈Λ,
problem (6) can be transformed into
s.t. ATα = DTβ,
τi∥βi∥2 ≤λ, βi = Ciβ, ∀i ∈[n].
where α ∈Rn, βv ∈Rn, βh ∈Rn, β = [βT
h]T are the
Lagrangian dual variables. For any τ ∈Λ, α∗= ξ∗at the
optimum of the inner problem.
The proof can be found in Appendix.
From Proposition 1, α∗equals to the ﬁtting error ξ∗.
Without loss of generality, we assume α ∈A = [−l, l]n,
where l is a sufﬁciently large positive number and A is a
compact domain. Based on (7), the feasible domain of α w.r.t.
each τ is Aτ = {α|ATα = DTβ, τi∥βi∥2 ≤λ, ∀i ∈[n], α ∈
[−l, l]n}.
Note that, according to the constraints in (7), all
Aτ’s share the same β. We further deﬁne
φ(α, τ) = 1
2 −αTy, α ∈Aτ.
By applying the minimax inequality in , we have
α∈A −φ(α, τ) ≥max
τ∈Λ −φ(α, τ).
According to (9), maxα∈A minτ∈Λ −φ(α, τ) is a lower
bound of problem (7) and it is a convex problem. By introducing a new variable θ ∈R, maxα∈A minτ∈Λ −φ(α, τ) can
be equivalently written as a quadratically constrained linear
programming (QCLP) problem :
s.t. φ(α, τ) ≤θ, ∀τ ∈Λ,
which is a convex relaxation of problem (7). Note that each
feasible τ corresponds to a constraint. Note that there are
elements in Λ. In other words, problem (10)
has exponentially many constraints, which makes it difﬁcult
to address directly.
B. Optimization of the QCLP TV Model
Though there are exponentially many constraints in (10),
most of them are inactive at the optimum, since only a subset
of components are relevant in ﬁtting the observation. Accordingly, we seek to address problem (10) using a cutting-plane
method , as shown in Algorithm 1. Instead of handling
all constraints at the same time, Algorithm 1 iteratively ﬁnds
the active constraints and then solves a subproblem (11) with
the selected active constraints only.
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. XX, NO. XX, 2018
Algorithm 1: Cutting-plane for the QCLP Problem (10)
Input: Observation y, A, parameter λ.
1 Initializing α0 = y −(1 ⊗(Pn
i=1 yi/n)), and τ0 = 0;
2 Set Λ0 = ∅and t = 1;
3 while Stopping conditions are not achieved do
Find the τt corresponding to the most violated
constraint based on αt−1;
Set Λt = Λt−1 ∪{τt};
Solve the subproblem corresponding to Λt:
α∈A,θ∈R θ,
s.t. φ(α, τ) −θ ≤0, ∀τ ∈Λt, (11)
obtaining the solution αt. Let t = t + 1;
Algorithm 1 involves two main steps: ﬁnding the most violated constraints and the subproblem optimization step. Since
each τ ∈Λ corresponds to a constraint, in the t-th iteration,
we ﬁnd the most active τt based on αt−1 and add it into the
active constraint set Λt, which is initialized as an empty set ∅.
Then we update αt by solving the subproblem (11) with the
constraints deﬁned in Λt. The algorithm terminates when the
stopping conditions are achieved.
As will be shown later, in each iteration t, the activated
τt indicates at most κ nonzero elements in Dvx and Dhx.
Activating the most active τt is equivalent to ﬁnding κ indices
of the corresponding nonzero elements, which can be recorded
in an index set Ct ⊆[n], i.e. Ct = supp(τt). For convenience,
we deﬁne an index set St = ∪t
i=1Ci to record the indices
indicated by all τ’s in Λt. As shown in Section III-C, due to
the difﬁculty of directly solving the subproblem (11) w.r.t. the
dual variable α , , we will investigate an efﬁcient way
to solve the subproblem w.r.t. to the primal variable x instead.
C. Solving QCLP Subproblem in Primal Form
In each iteration of Algorithm 1, after updating the active
constraint set, we address subproblem (11) with a subset of
activated τ’s in Λt. Although the number of constraints in
(11) is signiﬁcantly smaller than the original problem (10),
directly optimizing it w.r.t. the dual variable α is not easy
 , . However, considering that the activated τ’s in Λt
indicate only a subset of nonzero elements in z and Dx, we
will transform problem (11) to an equivalent problem (w.r.t.
the primal variables x) that can be solved much faster ,
Recall that St ⊆[n] is deﬁned to record the indices of the
nonzero elements indicated by τ’s in Λt, and eτ = [τ T, τ T]T ∈
{0, 1}2n in (5) is deﬁned to indicate nonzero elements in Dx ∈
R2n. For convenience, we extend the deﬁnition of St for τ to
a notation eSt for eτ, i.e. , for an St, there is eSt = St ∪(St +n)
and (St+n) = {i|i = j+n, j ∈St}. Armed with the deﬁnition
of eSt, we transform problem (11) into problem (12) w.r.t. the
primal variables x and zeSt as shown in Proposition 2.
Proposition 2. Let S = ∪t
i=1Ci. Assume there is no overlapping element among Ci’s, problem (11) can be addressed by
i∈S ∥CieSzeS∥2
s.t. (Dx)eS = zeS, (Dx)eSc = 0.
Additionally, the optimal value of α∗under problem (11) can
be recovered by α∗= ξ∗where ξ∗= y −Ax∗.
The proof can be found in Appendix. In (12), the subscript
t of eSt is omitted for simplifying the representation.
Proposition 2 implies that activating τ’s in the QCLP
problem in (10) corresponds to activating a subset of nonzero
image gradients in the TV minimization problem in primal,
which are indexed by St. The nonzero gradients activated in
each iteration of Algorithm 1 are recorded in Ct.
In problem (12), only a subset of image gradients (i.e.
DxeS and zeS) indicated by eS can be nonzero, the constraint
(Dx)eSc = 0 thus reduces the uncertainty of the problem,
making the optimization easy. We will introduce an efﬁcient
alternating direction method of multipliers (ADMM) based
algorithm to handle subproblem (12) in Section IV.
D. Finding the Most Violated Constraint
In each iteration of Algorithm 1, we need to ﬁnd the most
active τ within a large number of elements in Λ based on the
updated αt−1 and the corresponding β.
At the optimum of problem (10), the following condition
should hold for all τ’s:
ATα = DTβ, τi∥βi∥2 ≤λ, ∀i ∈[n].
Given an α and β, a subvector βi with the larger ∥βi∥2 (and
τi = 1) violates the optimality condition (13) the more. In this
sense, the most active τ indicates the largest number of ∥βi∥2
with the largest values. Due to the constraint ∥τ∥0 ≤κ, with
a given β, we construct the most active τ by ﬁnding the κ
largest ∥βi∥2, and then setting the corresponding τi to 1 and
the rest to 0.
However, we cannot directly obtain the solution of the
dual variables α and β, since the optimization of subproblem
(11) is achieved by solving the problem in (12) w.r.t. the
primal variable x, as introduced in Section III-C. Thus, in
each iteration, after solving the subproblem in primal (i.e.
problem (12)), we ﬁrstly recover α from the solution x
via α = ξ = y −Ax, and then reconstruct β based on
the equality constraint ATα = DTβ in (14).
Recall that
α ∈Rn and β = [βT
h]T ∈R2n. It is thus highly illposed to recover β from α by solving the linear system
ATα = DTβ. We use the standard ℓ2-norm based regularizer
2 to alleviate the ill-posed nature. Relying on the ℓ2-norm
based regularizer, we can obtain a closed-form solution of β
efﬁciently, which simpliﬁes the optimization. We thus try to
obtain β approximately by solving:
2∥DTβ −ATα∥2
where r > 0 is a penalty parameter. Even though D is a
concatenation of two parts, i.e. D = [DT
h]T, we can still
efﬁciently solve (14) using Fast Fourier Transforms (FFTs)
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. XX, NO. XX, 2018
(see details in Appendix). Then we can easily obtain βi, ∀i ∈
[n] based on βi = Ciβ. For convenience, we deﬁne a vector
g, where gi = ∥βi∥2.
In the t-th iteration of Algorithm 1, with the recovered β,
we can ﬁnd the most active τt. As introduced in Section
III-B, in practice, we recode the κ indices indicated by τt
into a set Ct, i.e. Ct = supp(τt) and let St = ∪t
record the indices of the all activated τ’s. In general, once an
element has been activated and added into St−1, it is unlikely
to be activated again and selected in Ct in the subsequent
iterations. However, if the subproblem is not solved accurately,
some of the activated elements may have large values of
gi (i.e. ∥βi∥2) and be activated again. To avoid overlapping
components among Ct in practice, we form Ct from [n]\St−1.
The algorithm for ﬁnding the most violated constraint is
summarized in Algorithm 2.
Algorithm 2: Finding the Most Violated Constraint
Input: α, κ, A and regularizer parameter r.
1 Recover β from α by solving problem (14);
2 Let βi = Ciβ and calculate gi = ∥βi∥2, ∀i ∈[n];
3 Initialize τ = 0, and ﬁnd the κ largest gi’s;
4 Set τi corresponding to the κ largest gi’s to 1;
5 Form C, and return τ and C.
E. Matching Pursuit for Minimizing TV Model
Based on Proposition 2 and Algorithm 2, we can implement
our algorithm in primal form as summarized in Algorithm
3, which is referred as the matching pursuit total variation
(MPTV) algorithm. In each iteration of Algorithm 3, we
recover the dual variables α and β as well as ﬁnd the most
active τt (relying on Algorithm 2), and then record all indices
indicated by the activated τ’s into St. As shown in Fig. 2
(h), the nonzero gradients are activated according to the gt
(i.e. ∥βi∥2, ∀i ∈[n]), in which the elements with the largest
values indicate the most signiﬁcant gradients in the image.
During the iterations, the image x is recovered based on the
gradually activated gradients (indicated by St). Since no τ is
involved at the initial stage, e.g. S0 = ∅, we initialize x via
solving (12) given S = ∅, i.e. letting x0 = 1 ⊗(Pn
i=1 yi/n).
Reﬁnement for S. To boost the robustness of the MPTV
algorithm for real-world images in practice, we can take
several additional simple steps in Algorithm 3 to reﬁne the
S, which ensures we can make a conservative estimate of the
image pixels. To conduct reﬁnement in 2D image coordinates,
we deﬁne a 2D map M with M(i, j) = 1 for (i, j) ∈S
and 0 for others, where by a slight abuse of notation, we let S
denote the locations of activated components in 2D coordinate
system. Firstly, we perform a binary morphology dilation after
an erosion operation, such that M = (M⊖Re)⊕Rd, where ⊖
and ⊕denote the binary erosion and dilation, respectively. The
structuring elements for both Re and Rd are disks with radius
3. This step helps to remove isolated active components in S.
Fewer artifacts thus arise from fragmented active components.
Since the ideally sharp edges rarely appear in real-world
images, this step does not remove the useful and signiﬁcant
structures while removing the isolated components. Secondly,
similar to , to improve robustness for natural images and
alleviate the visible boundaries between the active and inactive
components, we blur the mask M slightly using a Gaussian
ﬁlter with standard deviation 3 pixels. After reﬁning the M,
we update S by recording the indices of the nonzero elements
of M in S. Note that the above operations are not necessary
for images with ideally sparse gradients.
Algorithm 3: MPTV for Image Deconvolution
Input: Observation y, parameter λ and ρ.
1 Initialize x0 = 1 ⊗(Pn
i=1 yi/n), α0 = y −Ax0, S0 = ∅;
2 Set iteration index t = 1;
3 while Stopping conditions are not achieved do
Finding the most violated constraint: Find the
most active τt based on αt−1 via Algorithm 2, and
record the corresponding indices into Ct;
Let St = St−1 ∪Ct;
Subproblem optimization: Solve subproblem (12)
via the ADMM in Algorithm 4, obtaining xt. Let
αt = y −Axt, and let t = t + 1;
F. Setting of Parameter κ
The integer κ parameter controls the number of activated
gradients in each iteration. In general, a large κ can decrease
the iteration number of MPTV algorithm, and a very small
κ helps to prevent activating too many gradient components.
Thus, the value of κ may affect the quality of the recovered
image. A sensitive study of κ is conducted in Section V-B3.
To balance between the efﬁciency and the performance, we
here provide a strategy for setting κ.
Recall that κ reﬂects a rough knowledge of the support
of Dvx and Dhx together, that is, K = card(supp(Dvx) ∪
supp(Dhx)). As K is unknown, we ﬁrst reconstruct β0 from
the initialization α0, then obtain g0 by letting g0
and normalize g0 as g0/∥g0∥2. Following the thresholding
strategy in previous work , we set κ as the number of of
elements in g0 larger than ζ∥g0∥∞. In practice, ζ ≥0.6 works
well for image deconvolution.
G. Solution Bias and Early Stopping
In general TV based image deconvolution, many existing
methods are sensitive to the choice of the λ and face a dilemma
– a too big a λ produces a solution with sparse gradients and
helps to resist noise, but underﬁts the data and causes oversmoothness in the recovered image, while a small λ ﬁts the
observation well but reduces the regularization strength and
may result in an estimate which suffers from ringing artifacts
and/or noise. As a result it is often necessary to intensively
search for an appropriate λ for a speciﬁc observation by considering the trade-off between the regularization strength and
the solution bias. This is often impractical and inconvenient
for users without speciﬁc knowledge. Due to the nature of
our optimization scheme, we bypass this dilemma to a large
degree, by proposing an early stopping condition below.
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. XX, NO. XX, 2018
(a) Input y and k
(b) Ground truth x∗
(c) Results of TV-ADMM (d) Results of MPTV
Iteration #
Iteration #
(g) Intermediate results xt of MPTV (from x1 to x6)
(h) Intermediate gt in MPTV for gradient activation (from g0 to g5, corresponding to the x1 to x6 in (g))
Fig. 2. An example for the MPTV method that is presented in Algorithm 3. (a) Input blurred image and blur kernel containing estimation error. (b) Ground
truth image. (c) and (d) Results of TV-ADMM and the proposed MPTV, respectively. (e) and (f) show the convergence of TV-ADMM and MPTV. MPTV
converges to a result with higher PSNR and SSIM values. (g) Intermediate results of MPTV, xt in Algorithm 3, corresponding to the green dots in (e) and
(f). (h) shows intermediate gt in MPTV, corresponding to the xt in (g). Note that MPTV is terminated after 6 iterations.
Recall that the MPTV algorithm incrementally activates the
nonzero elements in Dx, the value of ΩTV(x) increases from
0 iteratively. By deﬁning ψ(x) = ∥y −Ax∥2
2 + λΩTV(x), the
algorithm will be stopped when
|ψ(xt−1) −ψ(xt)|/ψ(x0) ≤ϵ,
where ϵ is a tolerance variable.
A too small ϵ may lead to too many iterations and activate
too many τ’s due to the noise in y, resulting in a nonsparse solution. We thus use an early stopping condition with a
relatively large ϵ = 1 × 10−3 (and maximum iteration number
as 7) to prevent MPTV from too many iterations, which helps
to obtain a solution x with small total variation, i.e. small
ΩTV(x), and sparse gradients. Since the early stopping strategy
helps to ensure the sparsity of image gradients, we thus can
use a relatively small λ to reduce the regularization bias in
solution. As a result, MPTV performs well for a wide range of
λ, which saves a lot of computational cost for hyper-parameter
tuning (see Fig. 6). The sensitive study of ϵ can be found in
Section V-B3.
H. Discussions on Ringing Suppression by MPTV
As is outlined above, the deconvolution results often suffer
from ringing artifacts in ﬂat areas and near strong edges (Fig.
2 (c)), which may be caused by errors in the blur kernel
estimate , the Gibbs phenomenon , etc, as discussed
in Section II-C. The classical TV based model, unfortunately,
is inadequate for avoid the undesired ringing artifacts.
For the deconvolution process given a ﬁxed blur kernel k
and corresponding convolution matrix A, an image ex containing ringing artifacts often lies in a domain eX = {x | x =
bx + r, ∥bx −x∗∥2 ≈0, ∥Ar∥2 ≈0}, where x∗denotes the
ground truth image, and r is an error term for artifacts. An
artifact term r corresponding to medium frequency ripples 
lies close to A’s nullspace. Since for any ex ∈eX, there is
∥y−Aex∥2 ≈0, a solution only minimizing the ℓ2-norm based
data ﬁdelity term is very likely in eX. In the conventional model
(5), the strength of the TV regularizer is only controlled by the
parameter λ. Although a large weight of the TV regularizer can
suppress the potential ringing artifacts, it also over smooths
the signiﬁcant edges and textures in the recovered image ,
 . When λ is not large enough, minimizing the TV based
objective cannot produce images with sparse gradients and
leads to results lying in eX with visible ringing. It is hard to
ﬁnd an accurate solution with less ringing artifacts only by
tuning the parameter λ.
Instead of directly optimizing the objective in (2), MPTV
gradually activates the most signiﬁcant gradients according
to the ﬁtting errors as shown in Fig. 2. As shown in ,
the ringing artifacts are less signiﬁcant in the ﬁtting error,
due to the smaller magnitudes. The possible artifacts can be
naturally suppressed by the gradient activation step and the
early stopping condition. Thus, beneﬁting from the optimization scheme, the proposed MPTV can suppress the ringing
artifacts without the need of large λ. Recall that MPTV can
also produce the desired sparse gradients with a small λ, which
is consistent with that for ringing suppression. The example
in Fig. 2 and the experimental results in Section V demonstrate that by selectively, and inhomogeneously, activating the
appropriate gradients the intended effect of the regularizer can
be maintained without causing the unwanted ringing.
I. Convergence Analysis
Similar to the analysis in and , it can be proved that
the θ’s generated through progressive iterations of Algorithm 1
increase monotonically. As a result, the following proposition
shows that MPTV converges to a global solution of (10).
Proposition 3. Let {(αt, θt)} be the sequence generated by
Algorithm 1. If the most violated constraint ﬁnding problem
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. XX, NO. XX, 2018
and subproblem (11) can be solved, the sequence {(αt, θt)}
will converge to an optimal solution of problem (10).
The proof can be found in Appendix.
In practice, we may use an early stopping to prevent MPTV
from activating too many constraints, which will help to obtain
images with sparse gradients.
IV. EFFICIENT OPTIMIZATION OF SUBPROBLEM (12)
In MPTV algorithm (i.e. Algorithm 3), after updating St,
we need to solve the subproblem (12). To handle the equality
constraints, we apply the alternating direction method of
multipliers (ADMM) which can be up to a few orders of
magnitude faster than solving (11) directly . Speciﬁcally,
we iteratively update the primal and dual variables of the
augmented Lagrangian function of (12). Let subvectors
γeS and γeSc be the dual variables w.r.t. the two constraints,
respectively. By introducing a dual variable γ ∈R2n and a
positive penalty parameter ρ > 0, we obtain the augmented
Lagrangian for (12):
L(x, zeS, γ) = 1
i∈S ∥CieSzeS∥2
eS((Dx)eS −zeS) + γT
eSc(Dx)eSc
2∥(Dx)eS −zeS∥2
2∥(Dx)eSc∥2
Then, we can solve for x by iteratively minimizing L(·) w.r.t.
x and zeS, and updating γ. Let k denote the iteration number.
Applying ADMM, we carry out the following steps at each
iteration:
Step 1 Compute zk+1
with ﬁxed xk and γk by solving:
∥CieSzeS∥2 + ρ
2∥(Dxk)eS −zeS + 1
which has an unique closed-form solution. For ∀i ∈S, let
µi = CieS(Dxk + 1
ργk). We can obtain the solution of (16)
by a two-dimensional shrinkage for ∀i ∈S:
where a convention 0 · (0/0) = 0 is followed. Following
this, for convenience, we deﬁne a temporary variable z′ =
h]T, and let z′
Step 2 Update xk+1 by solving minx L(x, zk+1
, γk) w.r.t. x:
2∥Dx −z′ + 1
which is quadratic in x. Let ν = [νT
h]T where νv =
v and νh = z′
h. The minimizer can be recovered
from the normal equation:
ATA + ρ(DTD)
x = ATy + ρDTν.
Under the periodic boundary condition, we can obtain the
solution via FFTs :
F(A)F(y)+ρ(F(Dv)F(νv)+F(Dh)F(νh))
F(A)F(A)+ρ(F(Dv)F(Dv)+F(Dh)F(Dh))
where F(·) and F−1(·) denote the Fourier transform and
the inverse transform, respectively, F(·) denotes the complex
conjugate of F(·), and the multiplication and division are all
component-wise operators.
Step 3 Update the dual variable γ:
γk+1 = γk + ρ(Dxk+1 −z′).
The ADMM method for solving problem (12) is summarized in Algorithm 4. As shown in Proposition 2, the dual
variable can be recovered by α∗= ξ∗= y −Ax∗.
Algorithm 4: ADMM for Solving Subproblem (12)
Input: Observation y, parameter λ and ρ, initialization
of image x0, index set St.
1 Initialize β0 = 0. Set iteration number as k = 0;
2 while Stopping conditions are not achieved do
Compute zk+1
according to (17);
Generate z′ by letting z′
Compute xk+1 by solving problem (18);
Update γk+1 according to (20);
If the stopping condition is achieved, stop;
Let k = k + 1;
Stopping conditions of Algorithm 4. For Algorithm 4
applied in solving subproblem (12), by deﬁning ϕ(x) =
∥y −Ax∥2, the algorithm is stopped when
|ϕ(xt−1) −ϕ(xt)|/ϕ(x0) ≤ϵin,
where ϵin is a tolerance value. This stopping condition is
adapted from . In practice, a sufﬁciently small ϵin is
enough to ﬁnd the most-violated constraint. We suggest setting
ϵin = 0.001 and the maximum iteration to 100. To avoid the
possible early stopping issue in ADMM at the very beginning
iterations, we can let the algorithm be stopped only after a
minimal number of iterations.
V. EXPERIMENTS
In this section, we evaluate the performance of our method
against the state-of-the-art image deconvolution methods on
both synthetic data and real-world images. To make a comprehensive study of the proposed method, we consider different
types of blur kernels (PSFs) and images. We will also study
the sensitivity of the MPTV algorithm to noises, blur level
and different parameter settings, and demonstrate its ability
to suppress ringing artifacts. All experiments are conducted
using MATLAB on a desktop computer with an Intel Core i5
CPU with 8GB of RAM. We use brute-force search for the
parameters to obtain the best performance for every method.
A. Experimental Settings
1) Synthetic dataset generation: Three synthetic datasets
are generated based on sharp images x∗belonging to three
different types – images with sparse gradients, text images
with near sparse gradients and natural images. We use a set of
different blur kernels to construct different A’s. For each A we
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. XX, NO. XX, 2018
(a) Blur kernels for synthesizing data
(b) Synthetic image
(a) Blur kernels (PSFs) for generating synthetic data. #1: 25 × 25
Gaussian blur kernel with standard derivation 1.6; #2: 15×15 disk blur kernel;
#3: 11 × 11 linear motion blur with length 15 and angle 45◦; #4-#8: Motion
blur kernel from Levin et al. ’s dataset (squared kernels with side length
19, 15, 27, 21 and 23). All blur kernels are padded as same size for better
illustration. (b) An example of the synthetic image with sparse gradients,
where kernel #6 is used.
generate the blurry testing images y’s by the imaging model
(1) y = Ax∗+ n, where n denotes the additive Gaussian
white noise with noise level1 0.3% unless stated otherwise. All
synthetic blurry images in these three datasets are generated
using a set of different blur kernels (PSFs), including the
Gaussian blur kernel, disk blur kernel, linear motion blur
kernel and motion blur kernels with different sizes from Levin
et al. ’s dataset , as shown in Fig. 3 (a). A nonperiodic
boundary condition is used for imitating the real blurred
image. We will discuss more details of the datasets in the
following.
2) Evaluation metrics: Since we have the ground truth for
synthetic datasets, we use the peak-signal-noise-ratio (PSNR)
and structural similarity index (SSIM) as the metric.
3) Comparison with other algorithms: We compare the proposed MPTV method with several state-of-the-art competitors
for image deconvolution, including the methods by promoting
sparsity on image gradients (such as e.g. FTVd , L0-Abs
 , WDTV , IRLS , hyper-Laplacian prior based
method and L0TV ), and other methods (e.g. BM3D
 and a kernel similarity based method ). Moreover, we
also compare with a TV-ADMM method by minimizing the
isotropic TV model using ADMM method, which is a direct
baseline of the proposed method.
B. Experiments on Synthetic Image with Sparse Gradients
Recall that the proposed MPTV is based on the identiﬁcation of non-zero subsets of the sparse gradient. We thus ﬁrst
evaluate the performance of the proposed method on an image
with sparse gradients.
Fig. 3 (b) shows a 256 × 256 sharp image with sparse
gradients for synthesizing blurred testing images. We perform
image deconvolution using different methods and record the
averaged values of PSNR and SSIM with 8 different kernels
in Table I. From Table I, the proposed MPTV performs the
best in terms of PSNR and SSIM. Here, the execution time of
MPTV for handling a 256 × 256 image is within 1 second.
1) Sensitivity study on noise: Based on the synthetic data
above, we conduct a noise level sensitivity study for the
proposed MPTV. We ﬁrst generate two blurred images, one
1An image y with (100 × σ)% Gaussian noise is generated by adding
noise with zero mean and standard derivation σ for image Ax∗with 
intensity range.
with the Gaussian blur kernel (#1 in Fig. 3 (a)) and the other
with a motion blur kernel (#6 in Fig. 3 (a)), and then add
Gaussian noise with noise with levels varying from 1% to
10% with interval 1% to the two blurred images. Fig. 4 records
the PSNR and SSIM values of different methods, which show
that the performance of many previous methods decreases as
noise level increases. The performance of MPTV is high and
stable since the cutting-plane optimization method restricts the
elements of Dx corresponding to the inactive τ to be zero.
2) Sensitivity study on blur level: The deconvolution task
becomes more difﬁcult as the level of blur increases. In order
to test the robustness of the various methods to increasing blur
level, we generate synthetic images using both the Gaussian
and linear motion blur kernels, as they exhibit a natural
parametrization for this purpose. We thus generate 8 squared
Gaussian blur kernels where the side lengths range from 15
to 85 pixels with an interval of 10, and standard derivations
1.6, 3, 5 and 7, and 8 linear motion blur kernels with 45◦angle
and lengths from 7 to 63 with an interval of 8. Fig. 5 shows
that the performance of all methods decreases with increasing
blur level for both Gaussian and motion blur. Nevertheless,
the proposed MPTV performs the best for all blur levels.
3) Sensitivity study on parameters: Firstly, we conduct a
sensitivity study for the parameter λ. MPTV with a proper
λ achieves solutions with high accuracy and less regularizer
bias. Due to the cutting-plane method and the early stopping
strategy, MPTV is not sensitive to the value of λ. In this experiment, we primarily compare MPTV with the TV-ADMM
method that shares a similar problem formulation and the
same implementation details apart from the binary indicator τ
and the cutting-plane based optimization scheme. We perform
deconvolution using the two methods given 20 λ’s with values
from 1 × 10−5 to 0.96 × 10−3 with an interval of 5 × 10−5,
and record the average PSNR and SSIM values of all testing
images in Fig. 6. According to evaluation based on both PSNR
and SSIM, the proposed MPTV method is more robust to the
setting of λ and outperforms the TV-ADMM for all λ’s, which
proves the effectiveness of the proposed MPTV formulation
and the cutting-plane based optimization method.
In the second experiment, we study the sensitivity of the
parameter κ for MPTV. The PSNR values of the image
results and the corresponding κ are reported in Fig. 7 (a).
The same stopping condition described in Section III-G is
used for different κ’s (from 64 to 512). From Fig. 7 (a), a
proper κ helps to prevent MPTV from activating too many
or too less nonzero gradients, resulting in high-quality results.
If κ is too small, MPTV may not activate enough nonzero
elements in a limited number of iterations. When κ increases,
the performance slightly degrades.
In the third experiment, we study the inﬂuence of the
parameter ϵ on the performance of MPTV. Different ϵ values
result in different iteration numbers. Fig. 7 (b) records the
PSNR values with 8 different ϵ’s from 1 × 10−5 to 5 × 10−2.
As shown in Fig. 7 (b), MPTV works robust to a wide range
of ϵ. When ϵ is large enough, e.g. ϵ = 1 × 10−3 in Fig 7
(b), the early stopping helps MPTV to produce images with
sparse gradients and satisfactory quality. A too small ϵ leads
to too many iterations and thus activates too many nonzero
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. XX, NO. XX, 2018
COMPARISON ON THE SYNTHETIC IMAGE WITH SPARSE GRADIENTS (PSNR/SSIM).
31.37/0.9622
27.05/0.9178
27.41/0.9236
28.22/0.9324
29.03/0.9466
22.92/0.8610
22.69/0.8911
23.81/0.8881
26.56/0.9154
47.36/0.9820
27.81/0.4727
27.54/0.4416
34.34/0.7328
32.99/0.6801
27.68/0.4767
34.32/0.7375
31.07/0.5823
32.89/0.6382
L0-Abs 
37.69/0.9670
33.83/0.9221
35.99/0.8572
39.22/0.8641
39.37/0.8673
33.52/0.7786
38.32/0.8595
37.76/0.8522
36.96/0.8710
37.00/0.9355
25.68/0.4194
24.61/0.3763
40.62/0.9190
46.88/0.9814
23.14/0.3071
40.06/0.9435
35.57/0.8428
34.20/0.7156
47.44/0.9876
35.17/0.8668
34.42/0.7964
39.54/0.8953
40.45/0.9159
32.13/0.7047
40.29/0.9141
36.42/0.8256
38.23/0.8633
35.97/0.9826
33.96/0.9717
42.48/0.9831
49.24/0.9905
48.52/0.9929
48.82/0.9885
50.68/0.9940
45.66/0.9813
44.42/0.9856
36.76/0.9874
33.72/0.9572
39.90/0.9764
49.23/0.9921
48.97/0.9943
40.54/0.9214
51.27/0.9935
44.88/0.9805
43.16/0.9754
37.21/0.9455
25.91/0.3960
25.06/0.3593
39.98/0.9229
46.80/0.9832
23.60/0.3020
40.14/0.9487
35.87/0.8555
34.32/0.7141
46.69/0.9821
41.09/0.9890
41.76/0.9568
30.95/0.6408
30.84/0.7854
31.88/0.8409
37.43/0.8709
21.87/0.4777
35.31/0.8180
44.14/0.9703
37.24/0.9693
40.78/0.9726
51.48/0.9790
52.93/0.9793
44.05/0.9567
53.59/0.9795
43.60/0.9707
45.98/0.9722
50.41/0.9997
41.09/0.9973
47.56/0.9979
56.98/0.9996
57.13/0.9997
51.80/0.9955
59.85/0.9998
50.51/0.9965
51.92/0.9983
Noise level (%)
Noise level (%)
Noise level (%)
Noise level (%)
Fig. 4. Study of noise sensitivity. PSNR and SSIM of the deconvolution results are evaluated for the blurry images contaminated by Gaussian noise with
increasing noise level. (a) and (b) Results on the blurry images with Gaussian blur. (c) and (d) Results on the blurry images with motion blur.
Gaussian PSF size
Gaussian PSF size
Motion PSF length
Motion PSF length
Fig. 5. Blur level sensitivity study of various methods. PSNR and SSIM of the deconvolution results for 8 blurry images contaminated by Gaussian blur or
linear motion blur with increasing blur level. (a) and (b) Results on the images blurred by the Gaussian PSFs. (c) and (d) Results on the images blurred by
the linear motion PSFs.
(a) Evaluation based on PSNR
(b) Evaluation based on SSIM
Sensitivity study of parameter λ. The deconvolution results of TV-
ADMM and MPTV with varying λ are evaluated and compared.
gradients, which slightly degrades the performance.
C. Quantitative Studies on Text Images
A text image often contains near sparse gradients and
represents an important class of real images. We thus study
(a) PSNR vs. κ
(b) PSNR vs. ϵ
Fig. 7. Sensitivity studies of κ and ϵ for MPTV. PSNR of the deconvolution
results with different values for the parameters are shown. (a) Sensitivity of
κ. (b) Sensitivity of the stopping condition parameter ϵ. In (b), the x axis is
scaled for visualization.
the performance of MPTV on text images using a dataset
containing 14 ground truth text images and 8 kernels (in Fig.
3 (a)). Here, we perform deconvolution with ground-truth blur
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. XX, NO. XX, 2018
kernels. For each blur kernel, we show the averaged PSNR and
SSIM of both input blurred images and the deblurring results
in Table II2. From the table, MPTV consistently performs
better than state-of-the-art methods. In particular, the results
of MPTV appear sharper than others.
D. Experiments on Natural Images
In this section, we evaluate the proposed MPTV algorithm
and other methods using natural images. We construct a dataset
including 192 blurred natural images from 24 sharp images
and the 8 kernels shown in Fig. 3 (a). Since the gradients
of natural images are much denser, MPTV is required to
activate many gradients to ﬁt the observation, leading to lower
superiority over the comparator methods, as shown in Table
III. Nevertheless, the proposed MPTV performs better than
others in terms of PSNR and SSIM values. Fig. 8 provides a
visual comparison which demonstrates that the latent images
estimated by MPTV exhibit sharper edges and less ringing
artifacts than those of its comparators. We also note that
MPTV failed to model some of the subtle textures in the
background due to the binary indicator for the activated
gradients.
1) Sensitivity study on blur kernel errors: In practice, the
blur kernel for image deconvolution is usually an estimate
containing errors, which lead to ringing artifacts and incur
degraded deconvolution performance. We thus here describe
an experiment to study the sensitivity of different methods to
errors in the kernel estimate. Seven 256 × 256 sharp natural
images (among the 24 sharp images above) and two blur
kernels (Gaussian blur kernel #1 and motion blur kernel #6)
are used to generate the test data. The ground truth known
blur kernel is applied to each image, and each kernel then
has noise added to form an erroneous blur kernel estimate
which is passed to the various deblurring methods. The added
noise is sampled from Gaussian distribution with a noise level
increasing from 0.2% to 0.5% (with an interval of 0.05%).
As shown in Fig. 9, the proposed method is more robust
than other algorithms since the cutting-plane of the proposed
MPTV estimates the sharp image by gradually activating
the signiﬁcant gradients which helps to suppress the ringing
artifacts.
E. Experiments on Real-world Images
We evaluate the performance of MPTV on two kinds of
real-world blurred images, i.e. blurred text images and natural
images. Here, the blur kernels are unknown. For real-world
image deconvolution, the kernel estimation error is one main
reason causing ringing artifacts . For fair comparison,
we use blur kernels estimated by the method in for all
compared deconvolution methods.
We ﬁrst report the results on a blurred text image in Fig.
10. From the ﬁgure, the deblurred results of most compared
methods contain signiﬁcant ringing artifacts and/or oversmooth strokes. In fact, since these methods usually use a
2The comparison with L0-ABS is absent since the corresponding code
only works on square images.
universal criterion to suppress undesired components, such as
thresholding on gradients, they may cause over-smoothness
(see Fig. 10 (h)), or fail to suppress artifacts (see Fig. 10 (b)).
On the contrary, the proposed MPTV algorithm can recover
sharper and clearer results by gradually activating signiﬁcant
strokes to ﬁt the blurred observation (Fig. 10 (k) and (l)).
In Fig. 11, we show the deblurring results on a natural
image containing both subtle textures and ﬂat background.
Although the ringing artifacts caused by the kernel estimation
error are unavoidable, MPTV performs favorably against the
state-of-the-art competitors by alleviating ringing artifacts and
preserving shape details simultaneously. Fig. 12 shows that,
on an image with complex contents, the proposed MPTV can
achieve favorable results than other methods. With a smaller
regularization weight (λ = 0.00005, Fig. 12 (j)), MPTV
recovers much sharper and clearer details but still suppresses
the ringing artifacts to quite a low level.
VI. CONCLUSION
We have proposed a matching pursuit based total variation
minimization method for image deconvolution. By introducing
a binary vector to indicate the signiﬁcant components in the
image gradients, we formulate the TV minimization problem
as a QCLP problem and solve it via a cutting-plane method.
The proposed algorithm with early stopping helps to reduce the
solution bias, to alleviate over-smoothness, and suppress the
ringing artifacts in the deconvolution results. Comprehensive
empirical studies on many different datasets show the superior
performance of the proposed MPTV over the state-of-the-art
In the future, we plan to apply the proposed method to a
variety of related image processing tasks, such image superresolution. We are also interested to extend the matching
pursuit framework to the wavelet frame based on the models
introduced in .
APPENDIX A
PROOF OF PROPOSITION 1
Proof. For any ﬁxed τ, we have the inner problem as
s.t. ξ = y −Ax, Dx = (z ⊙eτ),
di = Ciz, ∀i ∈[n].
By introducing Lagrangian dual variables α, β and γ with
= Ciγ to these equality constraints, the Lagrangian
function of the inner problem (21) is:
L(x, z, ξ, α, β, γ) = 1
+ αT(y −Ax −ξ) + βT(Dx −diag(eτ)z)
i (Ciz −di).
We then minimize L(x, z, ξ, α, β, γ) w.r.t. ξ, x and z, respectively:
2 −αTξ + αTy = −1
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. XX, NO. XX, 2018
QUALITATIVE COMPARISON ON TEXT IMAGES WITH NEAR SPARSE GRADIENTS (PSNR/SSIM).
20.04/0.8009
15.97/0.5684
16.88/0.6312
17.51/0.6632
17.54/0.6945
13.49/0.4328
13.86/0.4882
14.63/0.4938
16.24/0.5966
28.91/0.9573
27.03/0.9347
32.58/0.9398
37.00/0.9423
35.81/0.9490
31.88/0.8716
36.95/0.9492
34.18/0.9337
33.04/0.9347
27.14/0.9517
25.52/0.8942
28.76/0.8926
37.93/0.9866
37.01/0.9891
28.86/0.8562
38.49/0.9891
33.18/0.9499
32.11/0.9387
27.38/0.9459
25.40/0.9103
32.06/0.9302
37.25/0.9427
35.95/0.9501
31.96/0.8720
37.25/0.9514
34.23/0.9339
32.68/0.9296
25.78/0.9384
22.96/0.8808
30.16/0.9569
38.49/0.9820
35.63/0.9833
37.22/0.9790
38.11/0.9859
35.00/0.9802
32.92/0.9608
25.60/0.9342
21.03/0.8210
27.63/0.9418
35.06/0.9825
33.65/0.9818
32.60/0.9667
36.26/0.9871
32.72/0.9751
30.57/0.9488
27.52/0.9422
25.70/0.8948
29.28/0.8912
37.95/0.9738
37.12/0.9804
29.27/0.8535
38.67/0.9879
33.55/0.9502
32.38/0.9343
29.24/0.9502
25.62/0.9018
31.99/0.9152
13.91/0.5324
14.38/0.5769
14.94/0.5111
14.09/0.5202
11.62/0.4153
19.47/0.6654
29.98/0.9673
26.91/0.9396
33.64/0.9635
38.98/0.9738
37.46/0.9760
37.10/0.9642
39.13/0.9775
36.68/0.9718
34.99/0.9667
30.15/0.9681
27.82/0.9434
34.27/0.9719
39.94/0.9873
38.04/0.9830
38.05/0.9815
39.96/0.9893
37.30/0.9823
35.69/0.9759
(a) Ground truth x∗
(b) Blurred image y
(c) FTVd 
(d) L0-Abs 
(e) BM3D 
(f) WTVD 
(g) IRLS 
(h) HL 
(i) KS 
(j) L0TV 
(k) TVADMM
Fig. 8. An example of the results on synthetically blurred natural images. The blurred image y is generated using the sharp image cameraman and the #6
blur kernel in Fig. 3 (a). (a) Ground truth sharp image x∗. (b) Input blurred image y. (c)-(l) Deconvolution results of different methods in comparison.
QUALITATIVE COMPARISON ON NATURAL IMAGES (PSNR/SSIM).
25.75/0.7437
21.53/0.4991
22.42/0.5822
23.18/0.6131
23.22/0.6203
18.66/0.3782
19.17/0.4138
20.05/0.4371
21.75/0.5359
29.74/0.8459
23.93/0.5673
23.71/0.5770
31.07/0.8197
29.67/0.7663
25.00/0.6734
31.53/0.8321
27.25/0.7236
27.74/0.7257
L0-Abs 
30.95/0.8911
19.36/0.5190
19.69/0.5368
26.52/0.7709
29.53/0.8588
22.58/0.6414
31.74/0.8913
22.69/0.6637
25.38/0.7216
30.76/0.8799
24.79/0.6477
24.44/0.6576
33.07/0.8916
34.50/0.9281
21.77/0.5983
35.33/0.9392
29.55/0.8434
29.28/0.7982
30.60/0.8818
27.62/0.7784
29.37/0.8323
34.86/0.9228
34.57/0.9216
29.87/0.8496
35.68/0.9359
30.90/0.8742
31.69/0.8746
29.02/0.8423
25.27/0.6933
27.96/0.8019
30.35/0.8609
30.25/0.8582
29.42/0.8394
31.97/0.8938
30.09/0.8576
29.29/0.8309
29.59/0.8540
25.49/0.6980
28.56/0.8164
31.89/0.8889
31.85/0.8836
30.10/0.8614
33.59/0.9161
31.04/0.8773
30.26/0.8495
30.48/0.8780
11.67/0.1524
11.85/0.1807
19.79/0.4958
22.92/0.7444
15.53/0.3038
26.98/0.8139
15.09/0.3183
19.29/0.4859
29.28/0.8615
26.17/0.7345
28.37/0.8189
21.52/0.4082
21.97/0.4506
22.73/0.5399
23.59/0.5455
18.80/0.2801
24.05/0.5799
30.93/0.8881
27.42/0.7753
28.25/0.8119
35.06/0.9263
34.67/0.9230
31.70/0.8869
35.74/0.9363
30.76/0.8744
31.82/0.8778
30.96/0.8869
27.89/0.7918
30.08/0.8627
35.53/0.9394
35.02/0.9330
32.85/0.9188
36.32/0.9489
32.67/0.9161
32.67/0.8997
−αTAx + βTDx =
if ATα = DTβ,
−∞, otherwise,
−βTdiag(eτ)z + γTz =
if γ = diag(eτ)β,
−∞, otherwise,
 λ∥di∥2 −γT
∥ωi∥2≤1,∀i
∥ωi∥2≤1,∀i min
if γi = λωi, ∥ωi∥2 ≤1, ∀i,
−∞, otherwise,
where ωi’s are the dual variables for the ℓ2-norm regularizer.
We obtain α = ξ at the optimality when optimizing L w.r.t. ξ.
By substituting above into L(x, z, ξ, α, β, γ), we obtain the
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. XX, NO. XX, 2018
Noise level on blur kernel (%)
Noise level on blur kernel (%)
Noise level on blur kernel (%)
Noise level on blur kernel (%)
Fig. 9. Study of sensitivity to the error in the blur kernel estimate. Blur kernels with increasing noise level are given for deconvolution. PSNR and SSIM
of the deconvolution results are evaluated for 7 blurry images contaminated by Gaussian blur or motion blur. (a) and (b) Results on the images blurred by
Gaussian blur kernel. (c) and (d) Results on the images blurred by the motion blur kernel.
(a) Input y and k
(b) FTVd 
(c) BM3D 
(d) WDTV 
(e) IRLS 
(f) HL 
(g) KS 
(h) TV2 
(i) TV-ADMM
(k) MPTV gt
(l) MPTV xt
Experimental results on real text image. (a) Input blurred image y and blur kernel k estimated using the method in . (b)-(j) Deconvolution
results of different methods. The results using TV2 in (h) are estimated using the method in . We show the intermediate results during the iterations of
the proposed MPTV in (k) and (l). (k) gt for activating gradients. (l) Intermediate xt. In this example, MPTV terminates after 6 iterations.
dual of the inner problem
s.t. ATα = DTβ,
τi∥βi∥2 ≤λ, βi = Ciβ, ∀i ∈[n].
This completes the proof.
APPENDIX B
SOLVE PROBLEM (14) FOR FINDING THE MOST-VIOLATED
CONSTRAINT
The problem in (14) has a closed-solution:
Since D = [DT
h]T is a concatenation of Dv and Dh,
directly calculating (23) via FFTs is non-trivial.
To calculate (23) using FFTs, we ﬁrstly rewrite (23) as
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. XX, NO. XX, 2018
(a) Input y and k
(b) Xu and Jia 
(c) FTVd 
(d) BM3D 
(e) WDTV 
(f) IRLS 
(g) HL 
(h) KS 
(i) TVADMM
(j) MPTV (λ = 0.00005)
Fig. 11. Experimental results on a real-world image. (a) Input blurred image y and blur kernel k. (b) Deblurring result of the software in is used as
a baseline. (c)-(j) Deconvolution results of different methods. The proposed MPTV recovers more sharp details (see red box) and introduces fewer ringing
artifacts (see blue box).
Through a series of algebra calculation, we can transform the
block-wise matrix inversion as:
h + ρI −DhDT
v + ρI)−1DvDT
v + ρI −DvDT
h + ρI)−1DhDT
Tv = −(DvDT
v + ρI)−1DvDT
Th = −(DhDT
h + ρI)−1DhDT
Therefor, we can achieve β by rewriting (23) as
h DvATα + TvDhATα,
v DvATα + ThDhATα,
which can be easily and efﬁciently calculated using FFTs.
APPENDIX C
PROOF OF PROPOSITION 2
For simplifying the proof, we ﬁrst reformulate problem (12)
by introducing ξ = y −Ax, and one constraint (Dx)Sc = 0.
Problem (12) then can be equivalently reformulated as
i∈S ∥CieSzeS∥2
s.t. ξ = y −Ax, (Dx)eS = zeS, (Dx)eSc = 0.
Following this, before proving Proposition 2, we provide the
following lemma.
Lemma 1. Let µ ∈Π = {µ | Pt
i=1 µi = 1, µi ≥0, ∀i, µ ∈
Rt}, problem (11) can be solved by the following minimax
µiφ(α, τi).
Proof. By introducing the dual variable µi, ∀i
the Lagrangian function of (11) is L(α, θ, µ)
i=1 µi(φ(α, τi)−θ). Let the derivatives w.r.t. θ be zero, we
then can obtain Pt
i=1 µi = 1 at the optimum. Furthermore, we
can exchange the order of the max and min operators based
on the minimax theorem . This completes the proof.
We can directly rewrite problem (29) as
s.t. ATα = DTβ,
τi∥βi∥2 ≤λ, βi = Ciβ, ∀i ∈[n], ∀τ ∈Λt.
Because of the assumption Pt
i=1 µi = 1, problem (29) can
be reformulated as:
s.t. ATα = DTβ,
τi∥βi∥2 ≤λ, βi = Ciβ, ∀i ∈[n], ∀τ ∈Λt.
Based on the assumption that there are no overlapping elements among Ci’s, we have P
i∈S ∥CieSzeS∥2
j∈Ci ∥CjeSzeS∥2. To furthermore simplify the representation, we rewrite the constraints in problem (28) with
the group conﬁguration matrices as CjDx = CjeSzeS, ∀j ∈
Ci, ∀i ∈[t] and CjDx = 0, ∀j ∈Sc, and introduce new
variables dj’s with dj = CjeSzeS. Thus the primal problem
(28) can be rewritten as
j∈Ci ∥dj∥2
s.t. ξ = y −Ax, CjDx = CjeSzeS, ∀j ∈Ci, ∀i ∈[t],
CjDx = 0, ∀j ∈Sc, dj = CjeSzeS, ∀j ∈Ci, ∀i ∈[t].
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. XX, NO. XX, 2018
(a) Input y and k
(b) Xu and Jia 
(c) FTVd 
(d) BM3D 
(e) WDTV 
(f) IRLS 
(g) HL 
(h) KS 
(i) MPTV (λ = 0.0005)
(j) MPTV (λ = 0.00005)
Fig. 12. Experimental results on a real-world image. (a) Input blurred image y and blur kernel k. (b) Deblurring result of the software in is used as a
baseline. (c)-(j) Deconvolution results of different methods. The results of MPTV with different values for parameter λ are shown in (i) and (j). The results
of MPTV suffer from fewer ringing artifacts (see blue boxes).
By introducing dual variables α, β and γ, and letting βi =
Ciβ, the Lagrangian function of problem is
L(x, zeS, ξ, d, α, β, γ) = 1
+ αT(y −Ax −ξ) +
j (CjDx −CjeSzeS)
j (CjeSzeS −dj).
To derive the dual form, we minimize L(x, zeS, ξ, d, α, β, γ)
w.r.t. x, zeS, ξ and d:
2 −αTξ + αTy = −1
if ATα = DTβ,
−∞, otherwise,
j CjeSzeS +
if γj = βj, ∀j ∈S,
−∞, otherwise,
 λ∥dj∥2 −γT
∥ωj∥2≤1,∀j
∥ωj∥2≤1,∀j min
if γj = λωj, ∥ωj∥2 ≤1, ∀j ∈Ci, ∀i ∈[t],
−∞, otherwise,
where ωj’s are the dual variable for the ℓ2-norm regularizer.
We then can obtain the dual problem of problem (28):
s.t. ATα = DTβ,
τj∥βj∥2 ≤λ, βj = Cjβ, ∀j ∈Ci, ∀i ∈[t].
Since, for all i ∈[t], each Ci corresponds to a τi in Λt, we thus
can verify that (30) is the dual form of problem (28). And there
is α∗= ξ∗. Hence, the subproblem (11) can be addressed by
solving (12), and there is α∗= ξ∗and ξ∗= y −Ax∗at the
optimum. This completes the proof.
APPENDIX D
PROOF OF THE CONVERGENCE ANALYSIS
Before proving the proposition for convergence analysis in
Proposition 3 in the main paper, we ﬁrst give the following
Lemma 2. Let (α∗, θ∗) be the global optimal solution of (10),
t=1 be a sequence of θ obtained in the iterations in
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. XX, NO. XX, 2018
Algorithm 1, where T = |Λ| denotes the possibly maximum
iteration number. As the iteration index t increases, {θt} is
monotonically increasing. And there is θt ≤θ∗.
Proof. According to deﬁnition of problem (10) and subproblem (11), we have
τ∈Λ φ(α, τ)
and θt = min
τ∈Λt φ(α, τ).
maxτ∈Λt φ(α, τ)
maxτ∈Λ φ(α, τ), then
τ∈Λt φ(α, τ) ≤min
τ∈Λ φ(α, τ),
which means θt ≤θ∗. Furthermore, as t increases, the size
of the subset Λt is increasing monotonically, so {θt} is
monotonically increasing. The proof is completed.
A. Proof of Proposition 3
For convenience, we ﬁrst deﬁne
τ∈Λ φ(αi, τ)).
Furthermore, to complete the proof, we introduce the following
Lemma 3. Let (α∗, θ∗) be the global optimal solution of (10)
in the main paper, and {ϕt} is corresponding to a sequence
{αt, θt} generated by Algorithm 1. There is ϕt ≤θ∗, and the
sequence {ϕt} is monotonically decreasing.
Proof. For ∀i, (αi, maxτ∈Λ φ(αi, τ)) is the feasible solution
of (10). Then θ∗≤maxτ∈Λ φ(αi, τ) for ∀i ∈[t]. Thus we
θ∗≤ϕt = min
τ∈Λ φ(αi, τ)),
which shows that, with the increasing iteration t, {ϕt} is
monotonically decreasing.
Then we conduct the proof for Proposition 3 in the main
Proof. We measure the convergence of the MPTV via the
gap between the sequence {θt} and {ϕt}. We prove the
convergence of the sequence {(αt, θt)} generated by the
updating procedure deﬁned in Algorithm 1. Speciﬁcally, we
adapt the convergence analysis from , . We assume
a limit point (¯α, ¯θ) exists for (αt, θt) and ¯θ ≤θ∗, where θ∗
denotes the optimal solution. To show (¯α, ¯θ) is global optimal
of problem (10), we need to show (¯α, ¯θ) is a feasible point of
problem (10), i.e. ¯θ ≥φ(¯α, θ) for all τ ∈Λ, so ¯θ ≥θ∗and
we must have ¯θ = θ∗. Let f(α, θ) = minτ∈Λ(θ −φ(α, τ)) =
θ−maxτ∈Λ φ(α, τ). Then f(α, θ) is continuous w.r.t. (α, θ).
Relying on the continuity, we then have
f(¯α, ¯θ) = f(αt, θt) + (f(¯α, ¯θ) −f(αt, θt))
= (θt −φ(αt, τt+1)) + (f(¯α, ¯θ) −f(αt, θt))
≥(θt −φ(αt, τt+1)) −(¯θ −φ(¯α, τt))
+ (f(¯α, ¯θ) −f(αt, θt)) →0 (whent →0).
The proof is completed.
ACKNOWLEDGMENT
This work was partially supported by National Natural
Science Foundation of China (61231016, 61602185), ARC
Discovery Project Grant (DP160100703). Yanning Zhang
is supported by Chang Jiang Scholars Program of China
(100017GH030150, 15GH0301). Mingkui Tan is supported by
Recruitment Program for Young Professionals.