Deep Learning based Recommender System: A Survey and New Perspectives
SHUAI ZHANG, University of New South Wales
LINA YAO, University of New South Wales
AIXIN SUN, Nanyang Technological University
YI TAY, Nanyang Technological University
With the ever-growing volume of online information, recommender systems have been an eﬀective strategy to overcome
such information overload. Te utility of recommender systems cannot be overstated, given its widespread adoption in many
web applications, along with its potential impact to ameliorate many problems related to over-choice. In recent years, deep
learning has garnered considerable interest in many research ﬁelds such as computer vision and natural language processing,
owing not only to stellar performance but also the atractive property of learning feature representations from scratch. Te
inﬂuence of deep learning is also pervasive, recently demonstrating its eﬀectiveness when applied to information retrieval and
recommender systems research. Evidently, the ﬁeld of deep learning in recommender system is ﬂourishing. Tis article aims
to provide a comprehensive review of recent research eﬀorts on deep learning based recommender systems. More concretely,
we provide and devise a taxonomy of deep learning based recommendation models, along with providing a comprehensive
summary of the state-of-the-art. Finally, we expand on current trends and provide new perspectives pertaining to this new
exciting development of the ﬁeld.
CCS Concepts: •Information systems →Recommender systems;
Additional Key Words and Phrases: Recommender System; Deep Learning; Survey
ACM Reference format:
Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay. 2018. Deep Learning based Recommender System: A Survey and New
Perspectives. ACM Comput. Surv. 1, 1, Article 1 , 35 pages.
DOI: 0000001.0000001
INTRODUCTION
Recommender systems are an intuitive line of defense against consumer over-choice. Given the explosive growth
of information available on the web, users are ofen greeted with more than countless products, movies or
restaurants. As such, personalization is an essential strategy for facilitating a beter user experience. All in all,
these systems have been playing a vital and indispensable role in various information access systems to boost
business and facilitate decision-making process and are pervasive across numerous web domains such
as e-commerce and/or media websites.
In general, recommendation lists are generated based on user preferences, item features, user-item past
interactions and some other additional information such as temporal (e.g., sequence-aware recommender) and
Yi Tay is added as an author later to help revise the paper for the major revision.
Author’s addresses: S. Zhang and L. Yao, University of New South Wales; emails: ; ; A. Sun
and Y. Tay, Nanyang Technological University; email: ; ;
ACM acknowledges that this contribution was authored or co-authored by an employee, or contractor of the national government. As such,
the Government retains a nonexclusive, royalty-free right to publish or reproduce this article, or to allow others to do so, for Government
purposes only. Permission to make digital or hard copies for personal or classroom use is granted. Copies must bear this notice and the
full citation on the ﬁrst page. Copyrights for components of this work owned by others than ACM must be honored. To copy otherwise,
distribute, republish, or post, requires prior speciﬁc permission and/or a fee. Request permissions from .
© 2018 ACM. 0360-0300/2018/7-ART1 $15.00
DOI: 0000001.0000001
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
 
S. Zhang et al.
spatial (e.g., POI recommender) data. Recommendation models are mainly categorized into collaborative ﬁltering,
content-based recommender system and hybrid recommender system based on the types of input data .
Deep learning enjoys a massive hype at the moment. Te past few decades have witnessed the tremendous
success of the deep learning (DL) in many application domains such as computer vision and speech recognition.
Te academia and industry have been in a race to apply deep learning to a wider range of applications due to its
capability in solving many complex tasks while providing start-of-the-art results . Recently, deep learning has
been revolutionizing the recommendation architectures dramatically and brings more opportunities to improve
the performance of recommender. Recent advances in deep learning based recommender systems have gained
signiﬁcant atention by overcoming obstacles of conventional models and achieving high recommendation quality.
Deep learning is able to eﬀectively capture the non-linear and non-trivial user-item relationships, and enable the
codiﬁcation of more complex abstractions as data representations in the higher layers. Furthermore, it catches
the intricate relationships within the data itself, from abundant accessible data sources such as contextual, textual
and visual information.
Pervasiveness and ubiquity of deep learning in recommender systems. In industry, recommender systems are critical tools to enhance user experience and promote sales/services for many online websites and mobile
applications . For example, 80 percent of movies watched on Netﬂix came from recommendations , 60 percent of video clicks came from home page recommendation in YouTube . Recently, many
companies employ deep learning for further enhancing their recommendation quality . Covington
et al. presented a deep neural network based recommendation algorithm for video recommendation on
YouTube. Cheng et al. proposed an App recommender system for Google Play with a wide & deep model.
Shumpei et al. presented a RNN based news recommender system for Yahoo News. All of these models
have stood the online testing and shown signiﬁcant improvement over traditional models. Tus, we can see that
deep learning has driven a remarkable revolution in industrial recommender applications.
Te number of research publications on deep learning based recommendation methods has increased exponentially in these years, providing strong evidence of the inevitable pervasiveness of deep learning in recommender
system research. Te leading international conference on recommender system, RecSys1, started to organize
regular workshop on deep learning for recommender system2 since the year 2016. Tis workshop aims to promote
research and encourage applications of deep learning based recommender system.
Te success of deep learning for recommendation both in academia and in industry requires a comprehensive
review and summary for successive researchers and practitioners to beter understand the strength and weakness,
and application scenarios of these models.
What are the diﬀerences between this survey and former ones? Plenty of research has been done in
the ﬁeld of deep learning based recommendation. However, to the best of our knowledge, there are very few
systematic reviews which well shape this area and position existing works and current progresses. Although
some works have explored the recommender applications built on deep learning techniques and have atempted
to formalize this research ﬁeld, few has sought to provide an in-depth summary of current eﬀorts or detail the
open problems present in the area. Tis survey seeks to provide such a comprehensive summary of current
research on deep learning based recommender systems, to identify open problems currently limiting real-world
implementations and to point out future directions along this dimension.
In the last few years, a number of surveys in traditional recommender systems have been presented. For
example, Su et al. presented a systematic review on collaborative ﬁltering techniques; Burke et al. 
proposed a comprehensive survey on hybrid recommender system; Fern´andez-Tob´ıas et al. and Khan et
al. reviewed the cross-domain recommendation models; to name a few. However, there is a lack of extensive
1htps://recsys.acm.org/
2htp://dlrs-workshop.org/
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
Deep Learning based Recommender System: A Survey and New Perspectives
review on deep learning based recommender system. To the extent of our knowledge, only two related short
surveys are formally published. Betru et al. introduced three deep learning based recommendation
models , although these three works are inﬂuential in this research area, this survey lost sight of
other emerging high quality works. Liu et al. reviewed 13 papers on deep learning for recommendation,
and proposed to classify these models based on the form of inputs (approaches using content information and
approaches without content information) and outputs (rating and ranking). However, with the constant advent
of novel research works, this classiﬁcation framework is no longer suitable and a new inclusive framework is
required for beter understanding of this research ﬁeld. Given the rising popularity and potential of deep learning
applied in recommender system, a systematic survey will be of high scientiﬁc and practical values. We analyzed
these works from diﬀerent perspectives and presented some new insights toward this area. To this end, over 100
studies were shortlisted and classiﬁed in this survey.
How do we collect the papers? In this survey, we collected over a hundred of related papers. We used Google
Scholar as the main search engine, we also adopted the database, Web of Science, as an important tool to discover
related papers. In addition, we screened most of the related high-proﬁle conferences such as NIPS, ICML, ICLR,
KDD, WWW, SIGIR, WSDM, RecSys, etc., just to name a few, to ﬁnd out the recent work. Te major keywords we
used including: recommender system, recommendation, deep learning, neural networks, collaborative ﬁltering,
matrix factorization, etc.
Contributions of this survey. Te goal of this survey is to thoroughly review literature on the advances of deep
learning based recommender system. It provides a panorama with which readers can quickly understand and step
into the ﬁeld of deep learning based recommendation. Tis survey lays the foundations to foster innovations in
the area of recommender system and tap into the richness of this research area. Tis survey serves the researchers,
practitioners, and educators who are interested in recommender system, with the hope that they will have a
rough guideline when it comes to choosing the deep neural networks to solve recommendation tasks at hand.
To summarize, the key contributions of this survey are three-folds: (1) We conduct a systematic review for
recommendation models based on deep learning techniques and propose a classiﬁcation scheme to position and
organize the current work; (2) We provide an overview and summary for the state-of-the-arts. (3) We discuss the
challenges and open issues, and identify the new trends and future directions in this research ﬁeld to share the
vision and expand the horizons of deep learning based recommender system research.
Te remaining of this article is organized as follows: Section 2 introduces the preliminaries for recommender
systems and deep neural networks, we also discuss the advantages and disadvantages of deep neural network
based recommendation models. Section 3 ﬁrstly presents our classiﬁcation framework and then gives detailed
introduction to the state-of-the-art. Section 4 discusses the challenges and prominent open research issues.
Section 5 concludes the paper.
OVERVIEW OF RECOMMENDER SYSTEMS AND DEEP LEARNING
Before we dive into the details of this survey, we start with an introduction to the basic terminology and concepts
regarding recommender system and deep learning techniques. We also discuss the reasons and motivations of
introducing deep neural networks to recommender systems.
Recommender Systems
Recommender systems estimate users’ preference on items and recommend items that users might like to them
proactively . Recommendation models are usually classiﬁed into three categories : collaborative
ﬁltering, content based and hybrid recommender system. Collaborative ﬁltering makes recommendations by
learning from user-item historical interactions, either explicit (e.g. user’s previous ratings) or implicit feedback (e.g.
browsing history). Content-based recommendation is based primarily on comparisons across items’ and users’
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
S. Zhang et al.
auxiliary information. A diverse range of auxiliary information such as texts, images and videos can be taken
into account. Hybrid model refers to recommender system that integrates two or more types of recommendation
strategies .
Suppose we have M users and N items, and R denotes the interaction matrix and ˆR denotes the predicted
interaction matrix. Let rui denote the preference of useru to item i, and ˆrui denote the predicted score. Meanwhile,
we use a partially observed vector (rows of R) r(u) = {ru1, ...,ruN } to represent each user u, and partially observed
vector (columns of R) r(i) = {r 1i, ...,r Mi} to represent each item i. O and O−denote the observed and unobserved
interaction set. we use U ∈RM×k andV ∈RN ×k to denote user and item latent factor. k is the dimension of latent
factors. In addition, sequence information such as timestamp can also be considered to make sequence-aware
recommendations. Other notations and denotations will be introduced in corresponding sections.
Deep Learning Techniques
Deep learning can be generally considered to be sub-ﬁeld of machine learning. Te typical deﬁning essence of
deep learning is that it learns deep representations, i.e., learning multiple levels of representations and abstractions
from data. For practical reasons, we consider any neural diﬀerentiable architecture as ‘deep learning‘ as long
as it optimizes a diﬀerentiable objective function using a variant of stochastic gradient descent (SGD). Neural
architectures have demonstrated tremendous success in both supervised and unsupervised learning tasks . In
this subsection, we clarify a diverse array of architectural paradigms that are closely related to this survey.
• Multilayer Perceptron (MLP) is a feed-forward neural network with multiple (one or more) hidden layers
between the input layer and output layer. Here, the perceptron can employ arbitrary activation function
and does not necessarily represent strictly binary classiﬁer. MLPs can be intrepreted as stacked layers
of nonlinear transformations, learning hierarchical feature representations. MLPs are also known to be
universal approximators.
• Autoencoder (AE) is an unsupervised model atempting to reconstruct its input data in the output layer. In
general, the botleneck layer (the middle-most layer) is used as a salient feature representation of the input
data. Tere are many variants of autoencoders such as denoising autoencoder, marginalized denoising
autoencoder, sparse autoencoder, contractive autoencoder and variational autoencoder (VAE) .
• Convolutional Neural Network (CNN) is a special kind of feedforward neural network with convolution layers and pooling operations. It can capture the global and local features and signiﬁcantly
enhancing the eﬃciency and accuracy. It performs well in processing data with grid-like topology.
• Recurrent Neural Network (RNN) is suitable for modelling sequential data. Unlike feedforward
neural network, there are loops and memories in RNN to remember former computations. Variants such
as Long Short Term Memory (LSTM) and Gated Recurrent Unit (GRU) network are ofen deployed in
practice to overcome the vanishing gradient problem.
• Restricted Boltzmann Machine (RBM) is a two layer neural network consisting of a visible layer and a
hidden layer. It can be easily stacked to a deep net. Restricted here means that there are no intra-layer
communications in visible layer or hidden layer.
• Neural Autoregressive Distribution Estimation (NADE) is an unsupervised neural network built
atop autoregressive model and feedforward neural networks. It is a tractable and eﬃcient estimator for
modelling data distribution and densities.
• Adversarial Networks (AN) is a generative neural network which consists of a discriminator and
a generator. Te two neural networks are trained simultaneously by competing with each other in a
minimax game framework.
• Atentional Models (AM) are diﬀerentiable neural architectures that operate based on sof content
addressing over an input sequence (or image). Atention mechanism is typically ubiquitous and was
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
Deep Learning based Recommender System: A Survey and New Perspectives
incepted in Computer Vision and Natural Language Processing domains. However, it has also been an
emerging trend in deep recommender system research.
• Deep Reinforcement Learning (DRL) . Reinforcement learning operates on a trial-and-error paradigm.
Te whole framework mainly consists of the following components: agents, environments, states, actions
and rewards. Te combination between deep neural networks and reinforcement learning formulate
DRL which have achieved human-level performance across multiple domains such as games and selfdriving cars. Deep neural networks enable the agent to get knowledge from raw data and derive eﬃcient
representations without handcrafed features and domain heuristics.
Note that there are numerous advanced model emerging each year, here we only brieﬂy listed some important
ones. Readers who are interested in the details or more advanced models are referred to .
Why Deep Neural Networks for Recommendation?
Before diving into the details of recent advances, it is beneﬁcial to understand the reasons of applying deep
learning techniques to recommender systems. It is evident that numerous deep recommender systems have
been proposed in a short span of several years. Te ﬁeld is indeed bustling with innovation. At this point, it
would be easy to question the need for so many diﬀerent architectures and/or possibly even the utility of neural
networks for the problem domain. Along the same tangent, it would be apt to provide a clear rationale of why
each proposed architecture and to which scenario it would be most beneﬁcial for. All in all, this question is highly
relevant to the issue of task, domains and recommender scenarios. One of the most atractive properties of neural
architectures is that they are (1) end-to-end diﬀerentiable and (2) provide suitable inductive biases catered to the
input data type. As such, if there is an inherent structure that the model can exploit, then deep neural networks
ought to be useful. For instance, CNNs and RNNs have long exploited the instrinsic structure in vision (and/or
human language). Similarly, the sequential structure of session or click-logs are highly suitable for the inductive
biases provided by recurrent/convolutional models .
Moreover, deep neural networks are also composite in the sense that multiple neural building blocks can be
composed into a single (gigantic) diﬀerentiable function and trained end-to-end. Te key advantage here is when
dealing with content-based recommendation. Tis is inevitable when modeling users/items on the web, where
multi-modal data is commonplace. For instance, when dealing with textual data (reviews , tweets 
etc.), image data (social posts, product images), CNNs/RNNs become indispensable neural building blocks. Here,
the traditional alternative (designing modality-speciﬁc features etc.) becomes signiﬁcantly less atractive and
consequently, the recommender system cannot take advantage of joint (end-to-end) representation learning. In
some sense, developments in the ﬁeld of recommender systems are also tightly coupled with advances research in
related modalities (such as vision or language communities). For example, to process reviews, one would have to
perform costly preprocessing (e.g., keyphrase extraction, topic modeling etc.) whilst newer deep learning-based
approaches are able to ingest all textual information end-to-end . All in all, the capabilities of deep learning
in this aspect can be regarded as paradigm-shifing and the ability to represent images, text and interactions in a
uniﬁed joint framework is not possible without these recent advances.
Pertaining to the interaction-only seting (i.e., matrix completion or collaborative ranking problem), the key
idea here is that deep neural networks are justiﬁed when there is a huge amount of complexity or when there is
a large number of training instances. In , the authors used a MLP to approximate the interaction function
and showed reasonable performance gains over traditional methods such as MF. While these neural models
perform beter, we also note that standard machine learning models such as BPR, MF and CML are known to
perform reasonably well when trained with momentum-based gradient descent on interaction-only data .
However, we can also consider these models to be also neural architectures as well, since they take advantage of
recent deep learning advances such as Adam, Dropout or Batch Normalization . It is also easy to see that,
traditional recommender algorithms (matrix factorization, factorization machines, etc.) can also be expressed
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
S. Zhang et al.
as neural/diﬀerentiable architectures and trained eﬃciently with a framework such as Tensorﬂow or
Pytorch, enabling eﬃcient GPU-emabled training and free automatic diﬀerentiation. Hence, in today’s research
climate (and even industrial), there is completely no reason to not used deep learning based tools for development
of any recommender system.
To recapitulate, we summarize the strengths of deep learning based recommendation models that readers
might bear in mind when try to employ them for practice use.
• Nonlinear Transformation. Contrary to linear models, deep neural networks is capable of modelling
the non-linearity in data with nonlinear activations such as relu, sigmoid, tanh, etc. Tis property makes
it possible to capture the complex and intricate user item interaction paterns. Conventional methods
such as matrix factorization, factorization machine, sparse linear model are essentially linear models.
For example, matrix factorization models the user-item interaction by linearly combining user and item
latent factors ; Factorization machine is a member of multivariate linear family ; Obviously, SLIM
is a linear regression model with sparsity constraints. Te linear assumption, acting as the basis of many
traditional recommenders, is oversimpliﬁed and will greatly limit their modelling expressiveness. It is
well-established that neural networks are able to approximate any continuous function with an arbitrary
precision by varying the activation choices and combinations . Tis property makes it possible to
deal with complex interaction paterns and precisely reﬂect user’s preference.
• Representation Learning. Deep neural networks is eﬃcacious in learning the underlying explanatory
factors and useful representations from input data. In general, a large amount of descriptive information
about items and users is available in real-world applications. Making use of this information provides
a way to advance our understanding of items and users, thus, resulting in a beter recommender. As
such, it is a natural choice to apply deep neural networks to representation learning in recommendation
models. Te advantages of using deep neural networks to assist representation learning are in two-folds:
(1) it reduces the eﬀorts in hand-craf feature design. Feature engineering is a labor intensive work, deep
neural networks enable automatically feature learning from raw data in unsupervised or supervised
approach; (2) it enables recommendation models to include heterogeneous content information such as
text, images, audio and even video. Deep learning networks have made breakthroughs in multimedia
data processing and shown potentials in representations learning from various sources.
• Sequence Modelling. Deep neural networks have shown promising results on a number of sequential modelling tasks such as machine translation, natural language understanding, speech recognition,
chatbots, and many others. RNN and CNN play critical roles in these tasks. RNN achives this with
internal memory states while CNN achieves this with ﬁlters sliding along with time. Both of them are
widely applicable and ﬂexible in mining sequential structure in data. Modelling sequential signals is an
important topic for mining the temporal dynamics of user behaviour and item evolution. For example,
next-item/basket prediction and session based recommendation are typical applications. As such, deep
neural networks become a perfect ﬁt for this sequential patern mining task. Tis
• Flexibility. Deep learning techniques possess high ﬂexibility, especially with the advent of many popular
deep learning frameworks such as Tensorﬂow3, Keras4, Caﬀe5, MXnet6, DeepLearning4j7, PyTorch8,
Teano9, etc. Most of these tools are developed in a modular way and have active community and
3htps://www.tensorﬂow.org/
4htps://keras.io/
5htp://caﬀe.berkeleyvision.org/
6htps://mxnet.apache.org/
7htps://deeplearning4j.org/
8htps://pytorch.org/
9htp://deeplearning.net/sofware/theano/
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
Deep Learning based Recommender System: A Survey and New Perspectives
professional support. Te good modularization makes development and engineering a lot more eﬃcient.
For example, it is easy to combine diﬀerent neural structures to formulate powerful hybrid models, or
replace one module with others. Tus, we could easily build hybrid and composite recommendation
models to simultaneously capture diﬀerent characteristics and factors.
On Potential Limitations
Are there really any drawbacks and limitations with using deep learning for recommendation? In this section,
we aim to tackle several commonly cited arguments against the usage of deep learning for recommender systems
• Interpretability. Despite its success, deep learning is well-known to behave as black boxes, and providing
explainable predictions seem to be a really challenging task. A common argument against deep neural
networks is that the hidden weights and activations are generally non-interpretable, limiting explainability.
However, this concern has generally been eased with the advent of neural atention models and have
paved the world for deep neural models that enjoy improved interpretability . While
interpreting individual neurons still pose a challenge for neural models (not only in recommender
systems), present state-of-the-art models are already capable of some extent of interpretability, enabling
explainable recommendation. We discuss this issue in more detail in the open issues section.
• Data Requirement. A second possible limitation is that deep learning is known to be data-hungry, in
the sense that it requires suﬃcient data in order to fully support its rich parameterization. However,
as compared with other domains (such as language or vision) in which labeled data is scarce, it is
relatively easy to garner a signiﬁcant amount of data within the context of recommender systems
research. Million/billion scale datasets are commonplace not only in industry but also released as
academic datasets.
• Extensive Hyperparameter Tuning. A third well-established argument against deep learning is the
need for extensive hyperparameter tuning. However, we note that hyperparameter tuning is not an
exclusive problem of deep learning but machine learning in general (e.g., regularization factors and
learning rate similarly have to be tuned for traditional matrix factorization etc) Granted, deep learning
may introduce additional hyperparameters in some cases. For example, a recent work , atentive
extension of the traditional metric learning algorithm only introduces a single hyperparameter.
DEEP LEARNING BASED RECOMMENDATION: STATE-OF-THE-ART
In this section, we we ﬁrstly introduce the categories of deep learning based recommendation models and then
highlight state-of-the-art research prototypes, aiming to identify the most notable and promising advancement
in recent years.
Categories of deep learning based recommendation models
To provide a bird-eye’s view of this ﬁeld, we classify the existing models based the types of employed deep
learning techniques. We further divide deep learning based recommendation models into the following two
categories. Figure 1 summarizes the classiﬁcation scheme.
• Recommendation with Neural Building Blocks. In this category, models are divided into eight subcategories
in conformity with the aforementioned eight deep learning models: MLP, AE, CNNs, RNNs, RBM, NADE,
AM, AN and DRL based recommender system. Te deep learning technique in use determines the applicability of recommendation model. For instance, MLP can easily model the non-linear interactions between
users and items; CNNs are capable of extracting local and global representations from heterogeneous
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
S. Zhang et al.
Fig. 1. Categories of deep neural network based recommendation models.
Table 1. A lookup table for reviewed publications.
Categories
Publications
 ,
 
Autoencoder
 ,
 
 ,
 
 ,
 
 
 
Neural Atention
 ,
 
Adversary Network
 
 
Hybrid Models
 
data sources such as textual and visual information; RNNs enable the recommender system to model the
temporal dynamics and sequential evolution of content information.
• Recommendation with Deep Hybrid Models. Some deep learning based recommendation models utilize
more than one deep learning technique. Te ﬂexibility of deep neural networks makes it possible to
combine several neural building blocks together to complement one another and form a more powerful
hybrid model. Tere are many possible combinations of these night deep learning techniques but not all
have been exploited. Note that it is diﬀerent from the hybrid deep networks in which refer to the
deep architectures that make use of both generative and discriminative components.
Table 1 lists all the reviewed models, we organize them following the aforementioned classiﬁcation scheme.
Additionally, we also summarize some of the publications from the task perspective in Table 2. Te reviewed
publications are concerned with a variety of tasks. Some of the tasks have started to gain atention due to
use of deep neural networks such as session-based recommendation, image, video recommendations. Some of
the tasks might not be novel to the recommendation research area (a detail review on the side information for
recommender systems can be found in ), but DL provides more possibility to ﬁnd beter solutions. For
example, dealing with images and videos would be tough task without the help of deep learning techniques. Te
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
Deep Learning based Recommender System: A Survey and New Perspectives
Table 2. Deep neural network based recommendation models in specific application fields.
Sources/Tasks
Publications
Sequential
Information
w/t User ID
 
Session based
w/o User ID
 
Check-In, POI
 
 
 
Review texts
 
Visual features
 
 
 
Citation Network
 
Social Network
 
Cross Domain
 
Cold-start
 
 
Explainability
sequence modelling capability of deep neural networks makes it easy to capture the sequential paterns of user
behaviors. Some of the speciﬁc tasks will be discussed in the following text.
Multilayer Perceptron based Recommendation
MLP is a concise but eﬀective network which has been demonstrated to be able to approximate any measurable
function to any desired degree of accuracy . As such, it is the basis of numerous advanced approaches and is
widely used in many areas.
Neural Extension of Traditional Recommendation Methods. Many existing recommendation models are
essentially linear methods. MLP can be used to add nonlinear transformation to existing RS approaches and
interpret them into neural extensions.
Neural Collaborative Filtering. In most cases, recommendation is deemed to be a two-way interaction between
users preferences and items features. For example, matrix factorization decomposes the rating matrix into
low-dimensional user/item latent factors. It is natural to construct a dual neural network to model the two-way
interaction between users and items. Neural Network Matrix Factorization (NNMF) and Neural Collaborative
Filtering (NCF) are two representative works. Figure 2a shows the NCF architecture. Let suser
denote the side information (e.g. user proﬁles and item features), or just one-hot identiﬁer of user u and item i.
Te scoring function is deﬁned as follows:
ˆrui = f (U T · suser
,V T · sitem
where function f (·) represents the multilayer perceptron, and θ is the parameters of this network. Traditional
MF can be viewed as a special case of NCF. Terefore, it is convenient to fuse the neural interpretation of
matrix factorization with MLP to formulate a more general model which makes use of both linearity of MF and
non-linearity of MLP to enhance recommendation quality. Te whole network can be trained with weighted
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
S. Zhang et al.
Fig. 2. Illustration of: (a) Neural Collaborative Filtering; (b) Deep Factorization Machine.
square loss (for explicit feedback) or binary cross-entropy loss (for implicit feedback). Te cross-entropy loss is
deﬁned as:
(u,i)∈O∪O−
rui log ˆrui + (1 −rui) log(1 −ˆrui)
Negative sampling approaches can be used to reduce the number of training unobserved instances. Follow-up
work proposed using pairwise ranking loss to enhance the performance. He et al. extended
the NCF model to cross-domain recommendations. Xue et al. and Zhang et al. showed that the one-hot
identiﬁer can be replaced with columns or rows of the interaction matrix to retain the user-item interaction
Deep Factorization Machine. DeepFM is an end-to-end model which seamlessly integrates factorization
machine and MLP. It is able to model the high-order feature interactions via deep neural network and loworder interactions with factorization machine. Factorization machine (FM) utilizes addition and inner product
operations to capture the linear and pairwise interactions between features (refer to Equation (1) in for
more details). MLP leverages the non-linear activations and deep structure to model the high-order interactions.
Te way of combining MLP with FM is enlightened by wide & deep network. It replaces the wide component
with a neural interpretation of factorization machine. Compared to wide & deep model, DeepFM does not require
tedious feature engineering. Figure 2b illustrates the structure of DeepFM. Te input of DeepFM x is an m-ﬁelds
data consisting of pairs (u,i) (identity and features of user and item). For simplicity, the outputs of FM and MLP
are denoted as yF M(x) and yMLP(x) respectively. Te prediction score is calculated by:
ˆrui = σ(yF M(x) + yMLP(x))
where σ(·) is the sigmoid activation function.
Lian et al. improved DeepMF by proposing a eXtreme deep factorization machine to jointly model the
explicit and implicit feature interactions. Te explicit high-order feature interactions are learned via a compressed
interaction network. A parallel work proposed by He et al. replaces the second-order interactions with MLP
and proposed regularizing the model with dropout and batch normalization.
Feature Representation Learning with MLP. Using MLP for feature representation is very straightforward
and highly eﬃcient, even though it might not be as expressive as autoencoder, CNNs and RNNs.
Wide & Deep Learning. Tis general model (shown in Figure 3a) can solve both regression and classiﬁcation
problems, but initially introduced for App recommendation in Google play . Te wide learning component
is a single layer perceptron which can also be regarded as a generalized linear model. Te deep learning
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
Deep Learning based Recommender System: A Survey and New Perspectives
component is multilayer perceptron. Te rationale of combining these two learning techniques is that it enables
the recommender to capture both memorization and generalization. Memorization achieved by the wide learning
component represents the capability of catching the direct features from historical data. Meanwhile, the deep
learning component catches the generalization by producing more general and abstract representations. Tis
model can improve the accuracy as well as the diversity of recommendation.
Formally, the wide learning is deﬁned as: y = W T
wide{x,ϕ(x)} + b, where W T
wide, b are the model parameters.
Te input {x,ϕ(x)} is the concatenated feature set consisting of raw input feature x and transformed (e.g. crossproduct transformation to capture the correlations between features) feature ϕ(x). Each layer of the deep neural
component is in the form of α(l+1) = f (W (l)
deepa(l) + b(l)), where l indicates the lth layer, and f (·) is the activation
function. W (l)
deep and b(l) are weight and bias terms. Te wide & deep learning model is atained by fusing these
two models:
P(ˆrui = 1|x) = σ(W T
wide{x,ϕ(x)} +W T
deepa(lf ) + bias)
where σ(·) is the sigmoid function, ˆrui is the binary rating label, a(lf ) is the ﬁnal activation. Tis joint model is
optimized with stochastic back-propagation ( follow-the-regularized-leader algorithm). Recommending list is
generated based on the predicted scores.
By extending this model, Chen et al. devised a locally-connected wide & deep learning model for large
scale industrial-level recommendation task. It employs the eﬃcient locally-connected network to replace the
deep learning component, which decreases the running time by one order of magnitude. An important step of
deploying wide & deep learning is selecting features for wide and deep parts. In other word, the system should
be able to determine which features are memorized or generalized. Moreover, the cross-product transformation
also is required to be manually designed. Tese pre-steps will greatly inﬂuence the utility of this model. Te
above mentioned deep factorization based model can alleviate the eﬀort in feature engineering.
Covington et al. explored applying MLP in YouTube recommendation. Tis system divides the recommendation task into two stages: candidate generation and candidate ranking. Te candidate generation network
retrieves a subset (hundreds) from all video corpus. Te ranking network generates a top-n list (dozens) based on
the nearest neighbors scores from the candidates. We notice that the industrial world cares more about feature
engineering (e.g. transformation, normalization, crossing) and scalability of recommendation models.
Alashkar et al. proposed a MLP based model for makeup recommendation. Tis work uses two identical
MLPs to model labeled examples and expert rules respectively. Parameters of these two networks are updated
simultaneously by minimizing the diﬀerences between their outputs. It demonstrates the eﬃcacy of adopting
expert knowledge to guide the learning process of the recommendation model in a MLP framework. It is highly
precise even though the expertise acquisition needs a lot of human involvements.
Collaborative Metric Learning (CML). CML replaces the dot product of MF with Euclidean distance because
dot product does not satisfy the triangle inequality of distance function. Te user and item embeddings are
learned via maximizing the distance between users and their disliked items and minimizing that between users
and their preferred items. In CML, MLP is used to learn representations from item features such as text, images
Recommendation with Deep Structured Semantic Model. Deep Structured Semantic Model (DSSM) 
is a deep neural network for learning semantic representations of entities in a common continuous semantic
space and measuring their semantic similarities. It is widely used in information retrieval area and is supremely
suitable for top-n recommendation . DSSM projects diﬀerent entities into a common low-dimensional
space, and computes their similarities with cosine function. Basic DSSM is made up of MLP so we put it in this
section. Note that, more advanced neural layers such as convolution and max-pooling layers can also be easily
integrated into DSSM.
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
S. Zhang et al.
Fig. 3. Illustration of: (a) Wide & Deep Learning; (b) Multi-View Deep Neural Network.
Deep Semantic Similarity based Personalized Recommendation (DSPR) is a tag-aware personalized recommender where each user xu and item xi are represented by tag annotations and mapped into a common tag
space. Cosine similarity sim(u,i) are applied to decide the relevance of items and users (or user’s preference over
the item). Te loss function of DSPR is deﬁned as follows:
[loд(esim(u,i∗)) −loд(
esim(u,i−))]
where (u,i−) are negative samples which are randomly sampled from the negative user item pairs. Te authors. further improved DSPR using autoencoder to learn low-dimensional representations from user/item
Multi-View Deep Neural Network (MV-DNN) is designed for cross domain recommendation. It treats users
as the pivot view and each domain (suppose we have Z domains) as auxiliary view. Apparently, there are Z
similarity scores for Z user-domain pairs. Figure 3b illustrates the structure of MV-DNN. Te loss function of
MV-DNN is deﬁned as:
L = arдmin
exp(γ · cosine(Yu,Ya,j))
X ′∈Rda exp(γ · cosine(Yu, fa(X ′)))
where θ is the model parameters, γ is the smoothing factor, Yu is the output of user view, a is the index of active
view. Rda is the input domain of view a. MV-DNN is capable of scaling up to many domains. However, it is
based on the hypothesis that users have similar tastes in one domain should have similar tastes in other domains.
Intuitively, this assumption might be unreasonable in many cases. Terefore, we should have some preliminary
knowledge on the correlations across diﬀerent domains to make the most of MV-DNN.
Autoencoder based Recommendation
Tere exist two general ways of applying autoencoder to recommender system: (1) using autoencoder to learn
lower-dimensional feature representations at the botleneck layer; or (2) ﬁlling the blanks of the interaction
matrix directly in the reconstruction layer. Almost all the autoencoder variants such as denoising autoencoder,
variational autoencoder, contactive autoencoder and marginalized autoencoder can be applied to recommendation
task. Table 3 summarizes the recommendation models based on the types of autoencoder in use.
Autoencoder based Collaborative Filtering. One of the successful application is to consider the collaborative
ﬁltering from Autoencoder perspective.
AutoRec takes user partial vectors r(u) or item partial vectors r(i) as input, and aims to reconstruct them
in the output layer. Apparently, it has two variants: item-based AutoRec (I-AutoRec) and user-based AutoRec
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
Deep Learning based Recommender System: A Survey and New Perspectives
Fig. 4. Illustration of: (a) Item based AutoRec; (b) Collaborative denoising autoencoder; (c) Deep collaborative filtering
framework.
Table 3. Summary of four autoencoder based recommendation models
Vanilla/Denoising AE
Variational AE
Contractive AE
Marginalized AE
 
 
 
(U-AutoRec), corresponding to the two types of inputs. Here, we only introduce I-AutoRec, while U-AutoRec can
be easily derived accordingly. Figure 4a illustrates the structure of I-AutoRec. Given input r(i), the reconstruction
is: h(r(i);θ) = f (W ·д(V ·r(i) +µ)+b), where f (·) and д(·) are the activation functions, parameter θ = {W ,V, µ,b}.
Te objective function of I-AutoRec is formulated as follows:
∥r(i) −h(r(i);θ) ∥2
O +λ · reg
Here ∥· ∥2
O means that it only considers observed ratings. Te objective function can be optimized by resilient
propagation (converges faster and produces comparable results) or L-BFGS (Limited-memory Broyden Fletcher
Goldfarb Shanno algorithm). Tere are four important points about AutoRec that worth noticing before deployment: (1) I-AutoRec performs beter than U-AutoRec, which may be due to the higher variance of user partially
observed vectors. (2) Diﬀerent combination of activation functions f (·) and д(·) will inﬂuence the performance
considerably. (3) Increasing the hidden unit size moderately will improve the result as expanding the hidden
layer dimensionality gives AutoRec more capacity to model the characteristics of the input. (4) Adding more
layers to formulate a deep network can lead to slightly improvement.
CFN is an extension of AutoRec, and posses the following two advantages: (1) it deploys the denoising
techniques, which makes CFN more robust; (2) it incorporates the side information such as user proﬁles and item
descriptions to mitigate the sparsity and cold start inﬂuence. Te input of CFN is also partial observed vectors, so
it also has two variants: I-CFN and U-CFN, taking r(i) and r(u) as input respectively. Masking noise is imposed as
a strong regularizer to beter deal with missing elements (their values are zero). Te authors introduced three
widely used corruption approaches to corrupt the input: Gaussian noise, masking noise and salt-and-pepper
noise. Further extension of CFN also incorporates side information. However, instead of just integrating side
information in the ﬁrst layer, CFN injects side information in every layer. Tus, the reconstruction becomes:
h({˜r(i), si}) = f (W2 · {д(W1 · {r(i), si} + µ), si} + b)
where si is side information, {˜r(i), si} indicates the concatenation of ˜r(i) and si. Incorporating side information
improves the prediction accuracy, speeds up the training process and enables the model to be more robust.
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
S. Zhang et al.
Collaborative Denoising Auto-Encoder (CDAE). Te three models reviewed earlier are mainly designed for rating
prediction, while CDAE is principally used for ranking prediction. Te input of CDAE is user partially
observed implicit feedback r(u)
pref . Te entry value is 1 if the user likes the movie, otherwise 0. It can also be
regarded as a preference vector which reﬂects user’s interests to items. Figure 4b illustrates the structure of
CDAE. Te input of CDAE is corrupted by Gaussian noise. Te corrupted input ˜r(u)
pref is drawn from a conditional
Gaussian distribution p(˜r(u)
pref |r(u)
pref ). Te reconstruction is deﬁned as:
pref ) = f (W2 · д(W1 · ˜r(u)
pref + Vu + b1) + b2)
where Vu ∈RK denotes the weight matrix for user node (see ﬁgure 4b). Tis weight matrix is unique for each user
and has signiﬁcant inﬂuence on the model performance. Parameters of CDAE are also learned by minimizing the
reconstruction error:
W1,W2,V,b1,b2
pref |r(u)
pref )[ℓ(˜r(u)
pref ,h(˜r(u)
pref ))] + λ · reg
where the loss function ℓ(·) can be square loss or logistic loss.
CDAE initially updates its parameters using SGD over all feedback. However, the authors argued that it is
impractical to take all ratings into consideration in real world applications, so they proposed a negative sampling
technique to sample a small subset from the negative set (items with which the user has not interacted), which
reduces the time complexity substantially without degrading the ranking quality.
Muli-VAE and Multi-DAE proposed a variant of varitional autoencoder for recommendation with implicit
data, showing beter performance than CDAE. Te authors introduced a principled Bayesian inference approach
for parameters estimation and show favorable results than commonly used likelihood functions.
To the extent of our knowledge, Autoencoder-based Collaborative Filtering (ACF) is the ﬁrst autoencoder
based collaborative recommendation model. Instead of using the original partial observed vectors, it decomposes
them by integer ratings. For example, if the rating score is integer in the range of , each r(i) will be divided
into ﬁve partial vectors. Similar to AutoRec and CFN, the cost function of ACF aims at reducing the mean squared
error. However, there are two demerits of ACF: (1) it fails to deal with non-integer ratings; (2) the decomposition
of partial observed vectors increases the sparseness of input data and leads to worse prediction accuracy.
Feature Representation Learning with Autoencoder. Autoencoder is a class of powerful feature representation learning approach. As such, it can also be used in recommender systems to learn feature representations
from user/item content features.
Collaborative Deep Learning (CDL). CDL is a hierarchical Bayesian model which integrates stacked
denoising autoencoder (SDAE) into probabilistic matrix factorization. To seamlessly combine deep learning and
recommendation model, the authors proposed a general Bayesian deep learning framework consisting
of two tightly hinged components: perception component (deep neural network) and task-speciﬁc component.
Speciﬁcally, the perception component of CDL is a probabilistic interpretation of ordinal SDAE, and PMF acts as
the task-speciﬁc component. Tis tight combination enables CDL to balance the inﬂuences of side information
and interaction history. Te generative process of CDL is as follows:
(1) For each layer l of the SDAE: (a) For each column n of weight matrix Wl, draw Wl,∗n ∼N(0, λ−1
w IDl ); (b)
Draw the bias vector bl ∼N(0, λ−1
w IDl ); (c) For each row i of Xl, draw Xl,i∗∼N(σ(Xl−1,i∗Wl +bl), λ−1
(2) For each item i: (a) Draw a clean input Xc,i∗∼N(XL,i∗, λ−1
n IIi ); (b) Draw a latent oﬀset vector ϵi ∼
v ID) and set the latent item vector: Vi = ϵi + XT
(3) Draw a latent user vector for each user u, Uu ∼N(0, λ−1
(4) Draw a rating rui for each user-item pair (u,i), rui ∼N and collaborative deep ranking (right).
where Wl and bl are the weight matrix and biases vector for layer l, Xl represents layer l. λw, λs, λn, λv, λu are
hyper-parameters,Cui is a conﬁdence parameter for determining the conﬁdence to observations . Figure 5(lef)
illustrates the graphical model of CDL. Te authors exploited an EM-style algorithm to learn the parameters. In
each iteration, it updates U and V ﬁrst, and then updatesW and b by ﬁxing U and V . Te authors also introduced
a sampling-based algorithm to avoid the local optimum.
Before CDL, Wang et al. proposed a similar model, relational stacked denoising autoencoders (RSDAE),
for tag recommendation. Te diﬀerence of CDL and RSDAE is that RSDAE replaces the PMF with a relational
information matrix. Another extension of CDL is collaborative variational autoencoder (CVAE) , which
replaces the deep neural component of CDL with a variational autoencoder. CVAE learns probabilistic latent
variables for content information and can easily incorporate multimedia (video, images) data sources.
Collaborative Deep Ranking (CDR). CDR is devised speciﬁcally in a pairwise framework for top-n
recommendation. Some studies have demonstrated that pairwise model is more suitable for ranking lists
generation . Experimental results also show that CDR outperforms CDL in terms of ranking
prediction. Figure 5(right) presents the structure of CDR. Te ﬁrst and second generative process steps of CDR
are the same as CDL. Te third and fourth steps are replaced by the following step:
• For each user u: (a) Draw a latent user vector for u, Uu ∼N(0, λ−1
u ID); (b) For each pair-wise preference
(i, j) ∈Pi, where Pi = {(i, j) : rui −ruj > 0}, draw the estimator, δuij ∼N(U T
where δuij = rui −ruj represents the pairwise relationship of user’s preference on item i and item j, C−1
a conﬁdence value which indicates how much user u prefers item i than item j. Te optimization process is
performed in the same manner as CDL.
Deep Collaborative Filtering Framework. It is a general framework for unifying deep learning approaches with
collaborative ﬁltering model . Tis framework makes it easily to utilize deep feature learning techniques to
build hybrid collaborative models. Te aforementioned work such as can be viewed as special
cases of this general framework. Formally, the deep collaborative ﬁltering framework is deﬁned as follows:
ℓ(R,U,V ) + β(∥U ∥2
F ) + γL(X,U ) + δL(Y,V )
where β, γ and δ are trade-oﬀparameters to balance the inﬂuences of these three components, X and Y are side
information, ℓ(·) is the loss of collaborative ﬁltering model. L(X,U ) and L(Y,V ) act as hinges for connecting
deep learning and collaborative models and link side information with latent factors. On top of this framework,
the authors proposed the marginalized denoising autoencoder based collaborative ﬁltering model (mDA-CF).
Compared to CDL, mDA-CF explores a more computationally eﬃcient variants of autoencoder: marginalized
denoising autoencoder . It saves the computational costs for searching suﬃcient corrupted version of input
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
S. Zhang et al.
by marginalizing out the corrupted input, which makes mDA-CF more scalable than CDL. In addition, mDA-CF
embeds content information of items and users while CDL only considers the eﬀects of item features.
AutoSVD++ makes use of contractive autoencoder to learn item feature representations, then
integrates them into the classic recommendation model, SVD++ . Te proposed model posses the following
advantages: (1) compared to other autoencoders variants, contractive autoencoder captures the inﬁnitesimal
input variations; (2) it models the implicit feedback to further enhance the accuracy; (3) an eﬃcient training
algorithm is designed to reduce the training time.
HRCD is a hybrid collaborative model based on autoencoder and timeSVD++ . It is a time-aware
model which uses SDAE to learn item representations from raw features and aims at solving the cold item
Convolutional Neural Networks based Recommendation
Convolution Neural Networks are powerful in processing unstructured multimedia data with convolution and
pool operations. Most of the CNNs based recommendation models utilize CNNs for feature extraction.
Feature Representation Learning with CNNs. CNNs can be used for feature representation learning from
multiple sources such as image, text, audio, video, etc.
CNNs for Image Feature Extraction. Wang et al. investigated the inﬂuences of visual features to Pointof-Interest (POI) recommendation, and proposed a visual content enhanced POI recommender system (VPOI).
VPOI adopts CNNs to extract image features. Te recommendation model is built on PMF by exploring the
interactions between: (1) visual content and latent user factor; (2) visual content and latent location factor. Chu
et al. exploited the eﬀectiveness of visual information (e.g. images of food and furnishings of the restaurant)
in restaurant recommendation. Te visual features extracted by CNN joint with the text representation are
input into MF, BPRMF and FM to test their performance. Results show that visual information improves the
performance to some degree but not signiﬁcant. He et al. designed a visual Bayesian personalized ranking
(VBPR) algorithm by incorporating visual features (learned via CNNs) into matrix factorization. He et al. 
extended VBPR with exploring user’s fashion awareness and the evolution of visual factors that user considers
when selecting items. Yu et al. proposed a coupled matrix and tensor factorization model for aesthetic-based
clothing recommendation, in which CNNs is used to learn the images features and aesthetic features. Nguyen
et al. proposed a personalized tag recommendation model based on CNNs. It utilizes the convolutional
and max-pooling layer to get visual features from patches of images. User information is injected for generating
personalized recommendation. To optimize this network, the BPR objective is adopted to maximize the diﬀerences
between the relevant and irrelevant tags. Lei et al. proposed a comparative deep leaning model with CNNs
for image recommendation. Tis network consists of two CNNs which are used for image representation learning
and a MLP for user preferences modelling. It compares two images (one positive image user likes and one negative
image user dislikes) against a user. Te training data is made up of triplets: t (user Ut, positive image I +
t , negative
t ). Assuming that the distance between user and positive image D(π(Ut),ϕ(I +
t )) should be closer than
the distance between user and negative images D(π(Ut),ϕ(I −
t )), where D(·) is the distance metric (e.g. Euclidean
distance). ConTagNet is a context-aware tag recommender system. Te image features are learned by
CNNs. Te context representations are processed by a two layers fully-connected feedforward neural network.
Te outputs of two neural networks are concatenated and fed into a sofmax funcation to predict the probability
of candidate tags.
CNNs for Text Feature Extraction. DeepCoNN adopts two parallel CNNs to model user behaviors and item
properties from review texts. Tis model alleviates the sparsity problem and enhances the model interpretability
by exploiting rich semantic representations of review texts with CNNs. It utilizes a word embedding technique to
map the review texts into a lower-dimensional semantic space as well as keep the words sequences information.
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
Deep Learning based Recommender System: A Survey and New Perspectives
Te extracted review representations then pass through a convolutional layer with diﬀerent kernels, a maxpooling layer, and a full-connected layer consecutively. Te output of the user network xu and item network xi
are ﬁnally concatenated as the input of the prediction layer where the factorization machine is applied to capture
their interactions for rating prediction. Catherine et al. mentioned that DeepCoNN only works well when
the review text writen by the target user for the target item is available at test time, which is unreasonable. As
such, they extended it by introducing a latent layer to represent the target user-target-item pair. Tis model
does not access the reviews during validation/test and can still remain good accuracy. Shen et al. built
an e-learning resources recommendation model. It uses CNNs to extract item features from text information
of learning resources such as introduction and content of learning material, and follows the same procedure
of to perform recommendation. ConvMF combines CNNs with PMF in a similar way as CDL. CDL
uses autoencoder to learn the item feature representations, while ConvMF employs CNNs to learn high level
item representations. Te main advantage of ConvMF over CDL is that CNNs is able to capture more accurate
contextual information of items via word embedding and convolutional kernels. Tuan et al. proposed using
CNNs to learn feature representations form item content information (e.g., name, descriptions, identiﬁer and
category) to enhance the accuracy of session based recommendation.
CNNs for Audio and Video Feature Extraction. Van et al. proposed using CNNs to extract features from
music signals. Te convolutional kernels and pooling layers allow operations at multiple timescales. Tis contentbased model can alleviate the cold start problem (music has not been consumed) of music recommendation. Lee
et al. proposed extracting audio features with the prominent CNNs model ResNet. Te recommendation is
performed in the collaborative metric learning framework similar to CML.
CNNs based Collaborative ﬁltering. Directly applying CNNs to vanilla collaborative ﬁltering is also viable. For
example, He et al. proposed using CNNs to improve NCF and presented the ConvNCF. It uses outer product
instead of dot product to model the user item interaction paterns. CNNs are applied over the result of outer
product and could capture the high-order correlations among embeddings dimensions. Tang et al. presented
sequential recommendation (with user identiﬁer) with CNNs, where two CNNs (hierarchical and vertical) are
used to model the union-level sequential paterns and skip behaviors for sequence-aware recommendation.
Graph CNNs for Recommendation. Graph convolutional Networks is a powerful tool for non-Eulcidean data
such as: social networks, knowledge graphs, protein-interaction networks, etc . Interactions in recommendation area can also be viewed as a such structured dataset (bipartite graph). Tus, it can also be applied to
recommendation tasks. For example, Berg et al. proposed considering the recommendation problem as a link
prediction task with graph CNNs. Tis framework makes it easy to integrate user/item side information such as
social networks and item relationships into recommendation model. Ying et al. proposed using graph CNNs
for recommendations in Pinterest10. Tis model generates item embeddings from both graph structure as well item
feature information with random walk and graph CNNs, and is suitable for very large-scale web recommender.
Te proposed model has been deployed in Pinterest to address a variety of real-world recommendation tasks.
Recurrent Neural Networks based Recommendation
RNNs are extremely suitable for sequential data processing. As such, it becomes a natural choice for dealing with
the temporal dynamics of interactions and sequential paterns of user behaviours, as well as side information
with sequential signals, such as texts, audio, etc.
Session-based Recommendation without User Identiﬁer. In many real world applications or websites, the
system usually does not bother users to log in so that it has no access to user’s identiﬁer and her long period
consumption habits or long-term interests. However, the session or cookie mechanisms enables those systems to
10htps://www.pinterest.com
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
S. Zhang et al.
get user’s short term preferences. Tis is a relatively unappreciated task in recommender systems due to the
extreme sparsity of training data. Recent advancements have demonstrated the eﬃcacy of RNNs in solving this
issue .
GRU4Rec. Hidasi et al. proposed a session-based recommendation model, GRU4Rec, based GRU (shown in
Figure 6a). Te input is the actual state of session with 1-of-N encoding, where N is the number of items. Te
coordinate will be 1 if the corresponding item is active in this session, otherwise 0. Te output is the likelihood of
being the next in the session for each item. To eﬃciently train the proposed framework, the authors proposed a
session-parallel mini-batches algorithm and a sampling method for output. Te ranking loss which is also coined
TOP1 and has the following form:
σ(ˆrsj −ˆrsi) + σ(ˆr 2
where S is the sample size, ˆrsi and ˆrsj are the scores on negative item i and positive item j at session s, σ is the
logistic sigmoid function. Te last term is used as a regularization. Note that, BPR loss is also viable. A recent
work found that the original TOP1 loss and BPR loss deﬁned in suﬀer from the gradient vanishing
problem, as such, two novel loss functions: TOP1-max and BPR-max are proposed.
Te follow-up work proposed several strategies to further improve this model: (1) augment the click
sequences with sequence preprocessing and dropout regularization; (2) adapt to temporal changes by pre-training
with full training data and ﬁne-tuning the model with more recent click-sequences; (3) distillation the model with
privileged information with a teacher model; (4) using item embedding to decrease the number of parameters for
faster computation.
Wu et al. designed a session-based recommendation model for real-world e-commerce website. It utilizes
the basic RNNs to predict what user will buy next based on the click history. To minimize the computation costs,
it only keeps a ﬁnite number of the latest states while collapsing the older states into a single history state. Tis
method helps to balance the trade-oﬀbetween computation costs and prediction accuracy. Qadrana et al. 
presented a hierarchical recurrent neural network for session-based recommendation. Tis model can deal with
both session-aware recommendation when user identiﬁers are present.
Te aforementioned three session-based models do not consider any side information. Two extensions demonstrate that side information has eﬀect on enhancing session recommendation quality. Hidasi et
al. introduced a parallel architecture for session-based recommendation which utilizes three GRUs to learn
representations from identity one-hot vectors, image feature vectors and text feature vectors. Te outputs of
these three GRUs are weightedly concatenated and fed into a non-linear activation to predict the next items
in that session. Smirnova et al. proposed a context-aware session-based recommender system based on
conditional RNNs. It injects context information into input and output layers. Experimental results of these two
models suggest that models incorporated additional information outperform those solely based on historical
interactions.
Despite the success of RNNs in session-based recommendation, Jannach et al. indicated that simple
neighbourhood approach could achieve same accuracy results as GRU4Rec. Combining the neighbourhood with
RNNs methods can usually lead to best performance. Tis work suggests that some baselines in recent works are
not well-justiﬁed and correctly evaluated. A more comprehensive discussion can be found in .
Sequential Recommendation with User Identiﬁer. Unlike session-based recommender where user identiﬁers
are usually not present. Te following studies deal with the sequential recommendation task with known user
identiﬁcations.
Recurrent Recommender Network (RRN) is a non-parametric recommendation model built on RNNs (shown
in Figure 6b). It is capable of modelling the seasonal evolution of items and changes of user preferences over time.
RRN uses two LSTM networks as the building block to model dynamic user state uut and item state vit. In the
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
Deep Learning based Recommender System: A Survey and New Perspectives
Fig. 6. Illustration of: (a) Session-based recommendation with RNN; (b) Recurrent recommender network; (c) Restricted
Boltzmann Machine based Collaborative Filtering.
meantime, considering the ﬁxed properties such as user long-term interests and item static features, the model
also incorporates the stationary latent atributes of user and item: uu and vi. Te predicted rating of item j given
by user i at time t is deﬁned as:
ˆrui |t = f (uut,vit,uu,vi)
where uut and vit are learned from LSTM, uu and vi are learned by the standard matrix factorization. Te
optimization is to minimize the square error between predicted and actual rating values.
Wu et al. further improved the RRNs model by modelling text reviews and ratings simultaneously. Unlike
most text review enhanced recommendation models , this model aims to generate reviews with a
character-level LSTM network with user and item latent states. Te review generation task can be viewed as an
auxiliary task to facilitate rating prediction. Tis model is able to improve the rating prediction accuracy, but
cannot generate coherent and readable review texts. NRT which will be introduced in the following text can
generate readable review tips. Jing et al. proposed a multi-task learning framework to simultaneously predict
the returning time of users and recommend items. Te returning time prediction is motivated by a survival
analysis model designed for estimating the probability of survival of patients. Te authors modiﬁed this model
by using LSTM to estimate the returning time of costumers. Te item recommendation is also performed via
LSTM from user’s past session actions. Unlike aforementioned session-based recommendations which focus on
recommending in the same session, this model aims to provide inter-session recommendations. Li et al. 
presented a behavior-intensive model for sequential recommendation. Tis model consists of two components:
neural item embedding and discriminative behaviors learning. Te later part is made up of two LSTMs for
session and preference behaviors learning respectively. Christakopoulou et al. designed an interactive
recommender with RNNs. Te proposed framework aims to address two critical tasks in interactive recommender:
ask and respond. RNNs are used to tackle both tasks: predict questions that the user might ask based on her
recent behaviors(e.g, watch event) and predict the responses. Donkers et al. designed a novel type of Gated
Recurrent Unit to explicit represent individual user for next item recommendation.
Feature Representation Learning with RNNs. For side information with sequential paterns, using RNNs as
the representation learning tool is an advisable choice.
Dai et al. presented a co-evolutionary latent model to capture the co-evolution nature of users’ and
items’ latent features. Te interactions between users and items play an important role in driving the changes
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
S. Zhang et al.
of user preferences and item status. To model the historical interactions, the author proposed using RNNs to
automatically learn representations of the inﬂuences from drif, evolution and co-evolution of user and item
Bansal et al. proposed using GRUs to encode the text sequences into latent factor model. Tis hybrid
model solves both warm-start and cold-start problems. Furthermore, the authors adopted a multi-task regularizer
to prevent overﬁting and alleviate the sparsity of training data. Te main task is rating prediction while the
auxiliary task is item meta-data (e.g. tags, genres) prediction.
Okura et al. proposed using GRUs to learn more expressive aggregation for user browsing history (browsed
news), and recommend news articles with latent factor model. Te results show a signiﬁcant improvement
compared with the traditional word-based approach. Te system has been fully deployed to online production
services and serving over ten million unique users everyday.
Li et al. presented a multitask learning framework, NRT, for predicting ratings as well as generating textual
tips for users simultaneously. Te generated tips provide concise suggestions and anticipate user’s experience
and feelings on certain products. Te rating prediction task is modelled by non-linear layers over item and user
latent factors U ∈Rku×M, V ∈Rkv ×M, where ku and kv (not necessarily equal) are latent factor dimensions for
users and items. Te predicted rating rui and two latent factor matrices are fed into a GRU for tips generation.
Here, rui is used as context information to decide the sentiment of the generated tips. Te multi-task learning
framework enables the whole model to be trained eﬃciently in an end-to-end paradigm.
Song et al. designed a temporal DSSM model which integrates RNNs into DSSM for recommendation.
Based on traditional DSSM, TDSSM replace the lef network with item static features, and the right network with
two sub-networks to modelling user static features (with MLP) and user temporal features (with RNNs).
Restricted Boltzmann Machine based Recommendation
Salakhutdinov et al. proposed a restricted Boltzmann machine based recommender (shown in Figure 6c).
To the best of our knowledge, it is the ﬁrst recommendation model that built on neural networks. Te visible unit
of RBM is limited to binary values, therefore, the rating score is represented in a one-hot vector to adapt to this
restriction. For example, represents that the user gives a rating score 4 to this item. Let hj, j = 1, ..., F
denote the hidden units with ﬁxed size F. Each user has a unique RBM with shared parameters. Suppose a user
rated m movies, the number of visible units is m, Let X be a K ×m matrix where xy
i = 1 if user u rated movie i as
i = 0 otherwise. Ten:
i = 1|h) =
l=1 exp(bl
p(hj = 1|X) = σ(bj +
ij represents the weight on the connection between the rating y of movie i and the hidden unit j, by
the bias of rating y for movie i, bj is the bias of hidden unit j. RBM is not tractable, but the parameters can be
learned via the Contrastive Divergence (CD) algorithm . Te authors further proposed using a conditional
RBM to incorporate the implicit feedback. Te essence here is that users implicitly tell their preferences by giving
ratings, regardless of how they rate items.
Te above RBM-CF is user-based where a given user’s rating is clamped on the visible layer. Similarity, we can
easily design an item-based RBM-CF if we clamp a given item’s rating on the visible layer. Georgiev et al. 
proposed to combine the user-based and item-based RBM-CF in a uniﬁed framework. In the case, the visible units
are determined both by user and item hidden units. Liu et al. designed a hybrid RBM-CF which incorporates
item features (item categories). Tis model is also based on conditional RBM. Tere are two diﬀerences between
this hybrid model with the conditional RBM-CF with implicit feedback: (1) the conditional layer here is modelled
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
Deep Learning based Recommender System: A Survey and New Perspectives
Table 4. Categories of neural atention based recommendation models.
Vanilla Atention
Co-Atention
 
 
with the binary item genres; (2) the conditional layer aﬀects both the hidden layer and the visible layer with
diﬀerent connected weights.
Neural Atention based Recommendation
Atention mechanism is motivated by human visual atention. For example, people only need to focus on speciﬁc
parts of the visual inputs to understand or recognize them. Atention mechanism is capable of ﬁltering out the
uninformative features from raw inputs and reduce the side eﬀects of noisy data. It is an intuitive but eﬀective
technique and has garnered considerable atention over the recent years across areas such as computer vision ,
natural language processing and speech recognition . Neural atention can not only used in
conjunction with MLP, CNNs and RNNs, but also address some tasks independently . Integrating atention
mechanism into RNNs enables the RNNs to process long and noisy inputs . Although LSTM can solve the
long memory problem theoretically, it is still problematic when dealing with long-range dependencies. Atention
mechanism provides a beter solution and helps the network to beter memorize inputs. Atention-based CNNs
are capable of capturing the most informative elements of the inputs . By applying atention mechanism to
recommender system, one could leverage atention mechanism to ﬁlter out uninformative content and select the
most representative items while providing good interpretability. Although neural atention mechanism is
not exactly a standalone deep neural technique, it is still worthwhile to discuss it separately due to its widespread
Atention model learns to atend to the input with atention scores. Calculating the atention scores lives
at the heart of neural atention models. Based on the way for calculating the atention scores, we classify the
neural atention models into (1) standard vanilla atention and (2) co-atention. Vanilla atention utilizes a
parameterized context vector to learn to atend while co-atention is concerned with learning atention weights
from two-sequences. Self-atention is a special case of co-atention. Recent works demonstrate the
capability of atention mechanism in enhancing recommendation performance. Table 4 summarizes the atention
based recommendation models.
Recommendation with Vanilla Attention
Chen et al. proposed an atentive collaborative ﬁltering model by introducing a two-level atention
mechanism to latent factor model. It consists of item-level and component-level atention. Te item-level
atention is used to select the most representative items to characterize users. Te component-level atention aims
to capture the most informative features from multimedia auxiliary information for each user. Tay et al. 
proposed a memory-based atention for collaborative metric learning. It introduces a latent relation vector
learned via atention to CML. Jhamb et al. proposed using atention mechanism to improve the performance
of autoencoder based CF. Liu et al. proposed a short-term atention and memory priority based model, in
which both long and short term user interests are intergrated for session based recommendation. Ying et al. 
proposed a hierarchical atention model for sequential recommendation. Two atention networks are used to
model user long-term and short-term interests.
Introducing atention mechanism to RNNs could signiﬁcantly improve their performance. Li et al. proposed
such an atention-based LSTM model for hashtag recommendation. Tis work takes the advantages of both RNNs
and atention mechanism to capture the sequential property and recognize the informative words from microblog
posts. Loyala et al. proposed an encoder-decoder architecture with atention for user session and intents
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
S. Zhang et al.
modelling. Tis model consists of two RNNs and could capture the transition regularities in a more expressive
Vanilla atention can also work in conjunction with CNNs for recommender tasks. Gong et al. proposed an
atention based CNNs system for hashtag recommendation in microblog. It treats hashtag recommendation as a
multi-label classiﬁcation problem. Te proposed model consists of a global channel and a local atention channel.
Te global channel is made up of convolution ﬁlters and max-pooling layers. All words are encoded in the input
of global channel. Te local atention channel has an atention layer with given window size and threshold to
select informative words (known as trigger words in this work). Hence, only trigger words are at play in the
subsequent layers. In the follow-up work , Seo et al. made use of two neural networks same as (without
the last two layers) to learn feature representations from user and item review texts, and predict rating scores
with dot product in the ﬁnal layer. Wang et al. presented a combined model for article recommendation, in
which CNNs is used to learn article representations and atention is utilized to deal with the diverse variance of
editors’s selection behavior.
Recommendation with Co-Attention Zhang et al. proposed a combined model, AtRec, which improves
the sequential recommendation performance by capitalizing the strength of both self-atention and metric learning.
It uses self-atention to learn user short-term intents from her recent interactions and takes the advantages
of metric learning to learn more expressive user and item embemddings. Zhou et al. proposed using
self-atention for user heterogeneous behaviour modelling. Self-atention is simple yet eﬀective mechanism and
has shown superior performance than CNNs and RNNs in terms of sequential recommendation task. We believe
that it has the capability to replace many complex neural models and more investigation is expected. Tay et
al. proposed a review based recommendation system with multi-pointer co-atention. Te co-atention
enables the model to select information reviews via co-learning from both user and item reviews. Zhang et
al. proposed a co-atention based hashtag recommendation model that integrates both visual and textual
information. Shi et al. proposed a neural co-atention model for personalized ranking task with meta-path.
Neural AutoRegressive based Recommendation
As mentioned above, RBM is not tractable, thus we usually use the Contrastive Divergence algorithm to approximate the log-likelihood gradient on the parameters , which also limits the usage of RBM-CF. Te so-called
Neural Autoregressive Distribution Estimator (NADE) is a tractable distribution estimator which provides a
desirable alternative to RBM. Inspired by RBM-CF, Zheng et al. proposed a NADE based collaborative
ﬁltering model (CF-NADE). CF-NADE models the distribution of user ratings. Here, we present a detailed
example to illustrate how the CF-NADE works. Suppose we have 4 movies: m1 (rating is 4), m2 (rating is 2), m3
(rating is 3) and m4 (rating is 5). Te CF-NADE models the joint probability of the rating vector r by the chain
rule: p(r) = ÎD
i=1 p(rmoi |rmo<i ),where D is the number of items that the user has rated, o is the D-tuple in the
permutations of (1, 2, ..., D), mi is the index of the ith rated item, rmoi is the rating that the user gives to item moi .
More speciﬁcally, the procedure goes as follows: (1) the probability that the user gives m1 4-star conditioned on
nothing; (2) the probability that the user gives m2 2-star conditioned on giving m1 4-star; (3) the probability that
the user gives m3 3-star conditioned on giving m1 4-star and m2 2-star; (4) the probability that the user gives m4
5-star conditioned on giving m1 4-star, m2 2-star and m3 3-star.
Ideally, the order of movies should follow the time-stamps of ratings. However, empirical study shows that
random drawing also yields good performances. Tis model can be further extended to a deep model. In the
follow-up paper, Zheng et al. proposed incorporating implicit feedback to overcome the sparsity problem
of rating matrix. Du et al. further imporved this model with a user-item co-autoregressive approach, which
ahieves beter performance in both rating estimation and personalized ranking tasks.
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
Deep Learning based Recommender System: A Survey and New Perspectives
Deep Reinforcement Learning for Recommendation
Most recommendation models consider the recommendation process as a static process, which makes it diﬃcult
to capture user’s temporal intentions and to respond in a timely manner. In recent years, DRL has begun to garner
atention in making personalized recommendation. Zhao et al. proposed a DRL
framework, DEERS, for recommendation with both negative and positive feedback in a sequential interaction
seting. Zhao et al. explored the page-wise recommendation scenario with DRL, the proposed framework
DeepPage is able to adaptively optimize a page of items based on user’s real-time actions. Zheng et al. 
proposed a news recommendation system, DRN, with DRL to tackle the following three challenges: (1) dynamic
changes of news content and user preference; (2) incorporating return paterns (to the service) of users; (3)
increase diversity of recommendations. Chen et al. proposed a robust deep Q-learning algorithm to address
the unstable reward estimation issue with two strategies: stratiﬁed sampling replay and approximate regreted
reward. Choi et al. proposed solving the cold-start problem with RL and bi-clustering. Munemasa et al 
proposed using DRL for stores recommendation.
Reinforcement Learning techniques such as contextual-bandit approach had shown superior recommendation performance in real-world applications. Deep neural networks increase the practicality of RL and make it
possible to model various of extra information for designing real-time recommendation strategies.
Adversarial Network based Recommendation
IRGAN is the ﬁrst model which applies GAN to information retrieval area. Speciﬁcally, the authors
demonstrated its capability in three information retrieval tasks, including: web search, item recommendation and
question answering. In this survey, we mainly focus on how to use IRGAN to recommend items.
Firstly, we introduce the general framework of IRGAN. Traditional GAN consists of a discriminator and a
generator. Likely, there are two schools of thinking in information retrieval, that is, generative retrieval and
discriminative retrieval. Generative retrieval assumes that there is an underlying generative process between
documents and queries, and retrieval tasks can be achieved by generating relevant document d given a query q.
Discriminative retrieval learns to predict the relevance score r given labelled relevant query-document pairs. Te
aim of IRGAN is to combine these two thoughts into a uniﬁed model, and make them to play a minimax game
like generator and discriminator in GAN. Te generative retrieval aims to generate relevant documents similar to
ground truth to fool the discriminative retrieval model.
Formally, let ptrue(d|qn,r) refer to the user’s relevance (preference) distribution. Te generative retrieval
model pθ(d|qn,r) tries to approximate the true relevance distribution. Discriminative retrieval fϕ(q,d) tries to
distinguish between relevant documents and non-relevant documents. Similar to the objective function of GAN,
the overall objective is formulated as follows:
JG∗,D∗= min
(Ed∼ptrue(d |qn,r)[loдD(d|qn)] + Ed∼pθ (d |qn,r)[loд(1 −D(d|qn))])
where D(d|qn) = σ(fϕ(q,d)), σ represents the sigmoid function, θ and ϕ are the parameters for generative and
discriminative retrieval respectively. Parameter θ and ϕ can be learned alternately with gradient descent.
Te above objective equation is constructed for pointwise relevance estimation. In some speciﬁc tasks, it
should be in pairwise paradigm to generate higher quality ranking lists. Here, suppose pθ(d|qn,r) is given by a
sofmax function:
pθ(di |q,r) =
exp(дθ(q,di))
dj exp(дθ(q,dj))
дθ(q,d) is the chance of document d being generated from query q. In real-word retrieval system, both дθ(q,d)
and fϕ(q,d) are task-speciﬁc. Tey can either have the same or diﬀerent formulations. Te authors modelled
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
S. Zhang et al.
them with the same function for convenience, and deﬁne them as: дθ(q,d) = sθ(q,d) and fϕ(q,d) = sϕ(q,d).
In the item recommendation scenario, the authors adopted the matrix factorization to formulate s(·). It can be
substituted with other advanced models such as factorization machine or neural network.
He et al. proposed an adversarial personalized ranking approach which enhances the Bayesian personalized
ranking with adversarial training. It plays a minimax game between the original BPR objective and the adversary
which add noises or permutations to maximize the BPR loss. Cai et al. proposed a GAN based representation
learning approach for heterogeneous bibliographic network, which can eﬀectively address the personalized
citation recommendation task. Wang et al. proposed using GAN to generate negative samples for the
memory network based streaming recommender. Experiments show that the proposed GAN based sampler could
signiﬁcantly improve the performance.
Deep Hybrid Models for Recommendation
With the good ﬂexibility of deep neural networks, many neural building blocks can be intergrated to formalize
more powerful and expressive models. Despite the abundant possible ways of combination, we suggest that the
hybrid model should be reasonably and carefully designed for the speciﬁc tasks. Here, we summarize the existing
models that has been proven to be eﬀective in some application ﬁelds.
CNNs and Autoencoder. Collaborative Knowledge Based Embedding (CKE) combines CNNs with autoencoder for images feature extraction. CKE can be viewed as a further step of CDL. CDL only considers item text
information (e.g. abstracts of articles and plots of movies), while CKE leverages structural content, textual content
and visual content with diﬀerent embedding techniques. Structural information includes the atributes of items
and the relationships among items and users. CKE adopts the TransR , a heterogeneous network embedding
method, for interpreting structural information. Similarly, CKE employs SDAE to learn feature representations
from textual information. As for visual information, CKE adopts a stacked convolutional auto-encoders (SCAE).
SCAE makes eﬃcient use of convolution by replacing the fully-connected layers of SDAE with convolutional
layers. Te recommendation process is done in a probabilistic form similar to CDL.
CNNs and RNNs. Lee et al. proposed a deep hybrid model with RNNs and CNNs for quotes recommendation.
Qote recommendation is viewed as a task of generating a ranked list of quotes given the query texts or dialogues
(each dialogue contains a sequence of tweets). It applies CNN sto learn signiﬁcant local semantics from tweets
and maps them to a distributional vectors. Tese distributional vectors are further processed by LSTM to compute
the relevance of target quotes to the given tweet dialogues. Te overall architecture is shown in Figure 12(a).
Zhang et al. proposed a CNNs and RNNs based hybrid model for hashtag recommendation. Given a
tweet with corresponding images, the authors utilized CNNs to extract features from images and LSTM to learn
text features from tweets. Meanwhile, the authors proposed a co-atention mechanism to model the correlation
inﬂuences and balance the contribution of texts and images.
Ebsesu et al. presented a neural citation network which integrates CNNs with RNNs in a encoder-decoder
framework for citation recommendation. In this model, CNNs act as the encoder that captures the long-term
dependencies from citation context. Te RNNs work as a decoder which learns the probability of a word in the
cited paper’s title given all previous words together with representations atained by CNNs.
Chen et al. proposed an intergrated framework with CNNs and RNNs for personalized key frame (in
videos) recommendation, in which CNNs are used to learn feature representations from key frame images and
RNNs are used to process the textual features.
RNNs and Autoencoder. Te former mentioned collaborative deep learning model is lack of robustness and
incapable of modelling the sequences of text information. Wang et al. further exploited integrating RNNs
and denoising autoencoder to overcome this limitations. Te authors ﬁrst designed a generalization of RNNs
named robust recurrent network. Based on the robust recurrent network, the authors proposed the hierarchical
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
Deep Learning based Recommender System: A Survey and New Perspectives
Bayesian recommendation model called CRAE. CRAE also consists of encoding and decoding parts, but it replaces
feedforward neural layers with RNNs, which enables CRAE to capture the sequential information of item content
information. Furthermore, the authors designed a wildcard denoising and a beta-pooling technique to prevent
the model from overﬁting.
RNNs with DRL. Wang et al. proposed combining supervised deep reinforcement learning wth RNNs
for treatment recommendation. Te framework can learn the prescription policy from the indicator signal and
evaluation signal. Experiments demonstrate that this system could infer and discover the optimal treatments
automatically. We believe that this a valuable topic and beneﬁts the social good.
FUTURE RESEARCH DIRECTIONS AND OPEN ISSUES
Whilst existing works have established a solid foundation for deep recommender systems research, this section
outlines several promising prospective research directions. We also elaborate on several open issues, which we
believe is critical to the present state of the ﬁeld.
Joint Representation Learning from User and Item Content Information
Making accurate recommendations requires deep understanding of item characteristics and user’s actual demands
and preferences . Naturally, this can be achieved by exploiting the abundant auxiliary information. For
example, context information tailors services and products according to user’s circumstances and surroundings , and mitigate cold start inﬂuence; Implicit feedback indicates users’ implicit intention and is easier to
collect while gathering explicit feedback is a resource-demanding task. Although existing works have investigated
the eﬃcacy of deep learning model in mining user and item proﬁles , implicit feedback ,
contextual information , and review texts for recommendation, they do
not utilize these various side information in a comprehensive manner and take the full advantages of the available
data. Moreover, there are few works investigating users’ footprints (e.g. Tweets or Facebook posts) from social
media and physical world (e.g. Internet of things) . One can infer user’s temporal interests or intentions
from these side data resources while deep learning method is a desirable and powerful tool for integrating these
additional information. Te capability of deep learning in processing heterogeneous data sources also brings
more opportunities in recommending diverse items with unstructured data such as textual, visual, audio and
video features.
Additionally, feature engineering has not been fully studied in the recommendation research community, but
it is essential and widely employed in industrial applications . However, most of the existing models
require manually crafed and selected features, which is time-consuming and tedious. Deep neural network is
a promising tool for automatic feature crafing by reducing manual intervention . Tere is also an added
advantage of representation learning from free texts, images or data that exists in the ‘wild’ without having to
design intricate feature engineering pipelines. More intensive studies on deep feature engineering speciﬁc for
recommender systems are expected to save human eﬀorts as well as improve recommendation quality.
An interesting forward looking research problem is how to design neural architectures that best exploits the
availability of other modes of data. One recent work potentially paving the way towards models of this nature is
the Joint Representation Learning framework . Learning joint (possibly multi-modal representations) of
user and items will likely become a next emerging trend in recommender systems research. To this end, a deep
learning taking on this aspect would be how to design beter inductive biases (hybrid neural architectures) in an
end-to-end fashion. For example, reasoning over diﬀerent modalities (text, images, interaction) data for beter
recommendation performance.
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
S. Zhang et al.
Explainable Recommendation with Deep Learning
A common interpretation is that deep neural networks are highly non-interpretable. As such, making explainable
recommendations seem to be an uphill task. Along the same vein, it would be also natural to assume that big,
complex neural models are just ﬁting the data with any true understanding (see subsequent section on machine
reasoning for recommendation). Tis is precisely why this direction is both exciting and also crucial. Tere
are mainly two ways that explainable deep learning is important. Te ﬁrst, is to make explainable predictions
to users, allowing them to understand the factors behind the network’s recommendations (i.e., why was this
item/service recommended?) . Te second track is mainly focused on explain-ability to the practitioner,
probing weights and activations to understand more about the model .
As of today, atentional models have more or less eased the non-interpretable concerns of neural
models. If anything, atention models have instead led to greater extents of interpretability since the atention
weights not only give insights about the inner workings of the model but are also able to provide explainable
results to users. While this has been an existing direction of research ‘pre deep learning’, atentional models are
not only capable of enhancing performance but enjoys greater explainability. Tis further motivates the usage of
deep learning for recommendation.
Notably, it is both intuitive and natural that a model’s explainabiity and interpretability strongly relies on the
application domain and usage of content information. For example mainly use reviews as a medium
of interpretability (which reviews led to making which predictions). Many other mediums/modalities can be
considered, such as image .
To this end, a promising direction and next step would to be to design beter atentional mechanisms, possibly
to the level of providing conversational or generative explanations (along the likes of ). Given that models
are already capable of highlighting what contributes to the decision, we believe that this is the next frontier.
Going Deeper for Recommendation
From former studies , we found that the performance of most neural CF models plateaus at three
to four layers. Going deeper has shown promising performance over shallow networks in many tasks ,
nonetheless, going deeper in the context of deep neural network based RS remains largely unclear. If going
deeper give favorable results, how do we train the deep architecture? If not, what is the reason behind this? A
possibility is to look into auxiliary losses at diﬀerent layers in similar spirit to albeit hierarchically instead
of sequentially. Another possibility is to vary layer-wise learning rates for each layer of the deep network or
apply some residual strategies.
Machine Reasoning for Recommendation
Tere have been numerous recent advances in machine reasoning in deep learning, ofen involving reasoning over
natural language or visual input . We believe that tasks like machine reading, reasoning, question
answering or even visual reasoning will have big impacts on the ﬁeld of recommender systems. Tese tasks
are ofen glazed over, given that they seem completely arbitrary and irrelevant with respect to recommender
systems. However, it is imperative that recommendater systems ofen requires reasoning over a single (or
multiple) modalities (reviews, text, images, meta-data) which would eventually require borrowing (and adapting)
techniques from these related ﬁelds. Fundamentally, recommendation and reasoning (e.g., question answering)
are highly related in the sense that they are both information retrieval problems.
Te single most impactful architectural innovation with neural architectures that are capable of machine
reasoning is the key idea of atention . Notably, this key intuition have already (and very recently)
demonstrated eﬀectiveness on several recommender problems. Tay et al. proposed an co-atentive architecture for reasoning over reviews, and showed that diﬀerent recommendation domains have diﬀerent ‘evidence
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
Deep Learning based Recommender System: A Survey and New Perspectives
aggregation’ paterns. For interaction-only recommendation, similar reasoning architectures have utilized similar
co-atentive mechanisms for reasoning over meta-paths . To this end, a next frontier for recommender
systems is possibly to adapt to situations that require multi-step inference and reasoning. A simple example
would to reason over a user’s social proﬁle, purchases etc., reasoning over multiple modalities to recommend a
product. All in all, we can expect that reasoning architectures to start to take the foreground in recommender
system research.
Cross Domain Recommendation with Deep Neural Networks
Nowadays, many large companies oﬀer diversiﬁed products or services to customers. For example, Google
provides us with web searches, mobile applications and news services; We can buy books, electronics and clothes
from Amazon. Single domain recommender system only focuses on one domain while ignores the user interests
on other domains, which also exacerbates sparsity and cold start problems . Cross domain recommender
system, which assists target domain recommendation with the knowledge learned from source domains, provides
a desirable solution for these problems. One of the most widely studied topics in cross domain recommendation
is transfer learning which aims to improve learning tasks in one domain by using knowledge transferred from
other domains . Deep learning is well suited to transfer learning as it learn high-level abstractions that
disentangle the variation of diﬀerent domains. Several existing works indicate the eﬃcacy of deep learning
in catching the generalizations and diﬀerences across diﬀerent domains and generating beter recommendations
on cross-domain platforms. Terefore, it is a promising but largely under-explored area where mores studies are
Deep Multi-Task Learning for Recommendation
Multi-task learning has led to successes in many deep learning tasks, from computer vision to natural language
processing . Among the reviewed studies, several works also applied multi-task learning to
recommender system in a deep neural framework and achieved some improvements over single task learning. Te
advantages of applying deep neural network based multi-task learning are three-fold: (1) learning several tasks
at a time can prevent overﬁting by generalizing the shared hidden representations; (2) auxiliary task provides
interpretable output for explaining the recommendation; (3) multi-task provides an implicit data augmentation for
alleviating the sparsity problem. Multitask can be utilized in traditional recommender system , while deep
learning enables them to be integrated in a tighter fashion. Apart from introducing side tasks, we can also deploy
the multitask learning for cross domain recommendation with each speciﬁc task generating recommendation for
each domain.
Scalability of Deep Neural Networks for Recommendation
Te increasing data volumes in the big data era poses challenges to real-world applications. Consequently,
scalability is critical to the usefulness of recommendation models in real-world systems, and the time complexity
will also be a principal consideration for choosing models. Fortunately, deep learning has demonstrated to be
very eﬀective and promising in big data analytics especially with the increase of GPU computation power.
However, more future works should be studied on how to recommend eﬃciently by exploring the following
problems: (1) incremental learning for non-stationary and streaming data such as large volume of incoming users
and items; (2) computation eﬃciency for high-dimensional tensors and multimedia data sources; (3) balancing of
the model complexity and scalability with the exponential growth of parameters. A promising area of research in
this area involves knowledge distillation which have been explored in for learning small/compact models
for inference in recommender systems. Te key idea is to train a smaller student model that absorbs knowledge
from the large teacher model. Given that inference time is crucial for real time applications at a million/billion
user scale, we believe that this is another promising direction which warrants further investigation. Another
ACM Computing Surveys, Vol. 1, No. 1, Article 1. Publication date: July 2018.
S. Zhang et al.
promising direction involves compression techniques . Te high-dimensional input data can be compressed
to compact embedding to reduce the space and computation time during model learning.
The Field Needs Beter, More Unified and Harder Evaluation
Each time a new model is proposed, it is expected that the publication oﬀers evaluation and comparisons against
several baselines. Te selection of baselines and datasets on most papers are seemingly arbitrary and authors
generally have free reign over the choices of datasets/baselines. Tere are several issues with this.
Firstly, this creates an inconsistent reporting of scores, with each author reporting their own assortment of
results. Till this day, there is seemingly on consensus on a general ranking of models (Notably, we acknowledge
that the no free lunch theorem exists). Occasionally, we ﬁnd that results can be conﬂicting and relative positions
change very frequently. For example, the scores of NCF in is relatively ranked very low as compared to the
original paper that proposed the model . Tis makes the relative benchmark of new neural models extremely
challenging. Te question is how do we solve this? Looking into neighbouring ﬁelds (computer vision or natural
language processing), this is indeed perplexing. Why is there no MNIST, ImageNet or SQAD for recommender
systems? As such, we believe that a suite of standardized evaluation datasets should be proposed.
We also note that datasets such as MovieLens are commonly used by many practioners in evaluating their
models. However, test splits are ofen arbitrary (randomized). Te second problem is that there is no control
over the evaluation procedure. To this end, we urge the recommender systems community to follow the CV/NLP
communities and establish a hidden/blinded test set in which prediction results can be only submited via a web
interface (such as Kaggle).
Finally, a third recurring problem is that there is no control over the diﬃculty of test samples in recommender
system result. Is spliting by time the best? How do we know if test samples are either too trivial or impossible to
infer? Without designing proper test sets, we argue that it is in fact hard to estimate and measure progress of the
ﬁeld. To this end, we believe that the ﬁeld of recommender systems have a lot to learn from computer vision or
NLP communities.
CONCLUSION
In this article, we provided an extensive review of the most notable works to date on deep learning based
recommender systems. We proposed a classiﬁcation scheme for organizing and clustering existing publications,
and highlighted a bunch of inﬂuential research prototypes. We also discussed the advantages/disadvantages of
using deep learning techniques for recommendation tasks. Additionally, we detail some of the most pressing
open problems and promising future extensions. Both deep learning and recommender systems are ongoing hot
research topics in the recent decades. Tere are a large number of new developing techniques and emerging
models each year. We hope this survey can provide readers with a comprehensive understanding towards the
key aspects of this ﬁeld, clarify the most notable advancements and shed some light on future studies.