CutPaste: Self-Supervised Learning for Anomaly Detection and Localization
Chun-Liang Li*, Kihyuk Sohn*, Jinsung Yoon, Tomas Pﬁster
Google Cloud AI Research
{chunliang,kihyuks,jinsungyoon,tpfister}@google.com
We aim at constructing a high performance model for defect detection that detects unknown anomalous patterns of
an image without anomalous data. To this end, we propose
a two-stage framework for building anomaly detectors using normal training data only. We ﬁrst learn self-supervised
deep representations and then build a generative one-class
classiﬁer on learned representations. We learn representations by classifying normal data from the CutPaste, a simple data augmentation strategy that cuts an image patch and
pastes at a random location of a large image. Our empirical
study on MVTec anomaly detection dataset demonstrates
the proposed algorithm is general to be able to detect various types of real-world defects. We bring the improvement
upon previous arts by 3.1 AUCs when learning representations from scratch. By transfer learning on pretrained representations on ImageNet, we achieve a new state-of-theart 96.6 AUC. Lastly, we extend the framework to learn and
extract representations from patches to allow localizing defective areas without annotations during training.
1. Introduction
Anomaly detection aims to detect an instance containing anomalous and defective patterns that are different from
those seen in normal instances. Many problems from different vision applications are anomaly detection, including
manufacturing defect detection , medical image analysis , and video surveillance . Unlike
a typical supervised classiﬁcation problem, anomaly detection faces unique challenges. First, due to the nature of the
problem, it is difﬁcult to obtain a large amount of anomalous data, either labeled or unlabeled. Second, the difference between normal and anomalous patterns are often ﬁnegrained as defective areas might be small and subtle in highresolution images.
Due to limited access to anomalous data, constructing an
anomaly detector is often conducted under semi-supervised
or one-class classiﬁcation settings using normal data only.
*Equal contributions.
Since the distribution of anomaly patterns is unknown in
advance, we train models to learn patterns of normal instances and determine anomaly if the test example is not
represented well by these models. For example, an autoencoder that is trained to reconstruct normal data is used to declare anomalies when the data reconstruction error is high.
Generative models declare anomalies when the probability
density is below a certain threshold. However, the anomaly
score deﬁned as an aggregation of pixel-wise reconstruction
error or probability densities lacks to capture a high-level
semantic information .
Alternative methods using high-level learned representations have shown more effective for anomaly detection.
For example, deep one-class classiﬁer demonstrates
an effective end-to-end trained one-class classiﬁers parameterized by deep neural networks. It outperforms its
shallow counterparts, such as one-class SVMs and
reconstruction-based approaches such as autoencoders .
In self-supervised representation learning, predicting geometric transformations of an image , such as rotation or translation, and contrastive learning have
shown to be successful in distinguishing normal data from
outliers. However, most existing works focus on detecting semantic outliers (e.g., visual objects from different
classes) from object-centric natural images. In Section 4.1,
we show these methods do not generalize well in detecting
ﬁne-grained anomalous patterns as in defect detection.
In this work, we tackle a one-class defect detection problem, a special case of image anomaly detection, where various forms of unknown anomalous patterns present locally in
the high-resolution images. We follow the two-stage framework , where we ﬁrst learn self-supervised representations by solving a proxy task, then build a generative oneclass classiﬁer on learned representations to distinguish data
with anomalous patterns from normal ones. Our innovation is at designing a novel proxy task for self-supervised
learning of representations. Speciﬁcally, we formulate a
proxy classiﬁcation task between normal training data and
the ones augmented by the CutPaste, the proposed data augmentation strategy that cuts an image patch and pastes at a
random location of an image. CutPaste augmentation is mo-
 
Anomaly score
(Upsampled)
Anomaly score
(spatial max-pooling)
Image-level / Patch-level
(a) Learning Self-Supervised Representation
(b) Anomaly Detection and Localization
Figure 1: An overview of our method for anomaly detection and localization. (a) A deep network (CNN) is trained to
distinguish images from normal (blue) and augmented (green) data distributions by CutPaste (orange dotted box), which cuts
a small rectangular region (yellow dotted box) from normal data and pastes it at random location. Representations are trained
either from the whole image or local patches. (b, top) An image-level representation makes a holistic decision for anomaly
detection and is used to localize defect via GradCAM . (b, bottom) A patch-level representation extracts dense features
from local patches to produce anomaly score map, which is then max-pooled for detection or upsampled for localization .
tivated to produce a spatial irregularity to serve as a coarse
approximation of real defects, which we have no access at
training. Rectangular patches of different sizes, aspect ratios, and rotation angles are pasted to generate diverse augmentations. Although CutPaste augmented samples (Figure 2(e)) are easily distinguishable from real defects and
thus might be a crude approximation of a real anomaly distribution, we show that representations learned by detecting
irregularity introduced by CutPaste augmentations generalize well on detecting real defects.
We evaluate our methods on MVTec anomaly detection
dataset , a real-world industrial visual inspection benchmark. By learning deep representations from scratch, we
achieve 95.2 AUC on image-level anomaly detection, which
outperforms existing works by at least 3.1 AUC.
Moreover, we report state-of-the-art 96.6 image-level AUC
by transfer learning from an ImageNet pretrained model.
Moreover, we explain how learned representations could
be used to localize the defective areas in high-resolution
images. Without using any anomaly data, a simple patch
model extension can achieve 96.0 pixel-level localization
AUC, which improves upon previous state-of-the-art 
(95.7 AUC). We conduct an extensive study using different
types of augmentation and proxy tasks to show the effectiveness of CutPaste augmentations for self-supervised representation learning on unknown defect detection.
2. A Framework for Anomaly Detection
In this section, we present our anomaly detection framework for high-resolution image with defects in local regions. Following , we adopt a two-stage framework for
building an anomaly detector, where in the ﬁrst stage we
learn deep representations from normal data and then construct an one-class classiﬁer using learned representations.
Subsequently, in Section 2.1, we present a novel method for
learning self-supervised representations by predicting Cut-
Paste augmentation, and extend to learning and extracting
representations from local patches in Section 2.4.
2.1. Self-Supervised Learning with CutPaste
Deﬁning good pretext tasks is essential for selfsupervised representation learning. While popular methods including rotation prediction and contrastive learning have been studied in the context of semantic
one-class classiﬁcation , our study in Section 4.1 shows that naively applying existing methods, such
as rotation prediction or contrastive learning, is sub-optimal
for detecting local defects as we will show in Section 4.1.
We conjecture that geometric transformations ,
such as rotations and translations, are effective in learning
representation of semantic concepts (e.g., objectness), but
less of regularity (e.g., continuity, repetition). As shown
in Figure 2(b), anomalous patterns of defect detection typically include irregularities such as cracks (bottle, wood) or
twists (toothbrush, grid). Our aim is to design an augmentation strategy creating local irregular patterns. Then we train
the model to identify these local irregularity with the hope
that it can generalize to unseen real defects at test time.
A popular augmentation method that could create a local irregularity in image is Cutout (Figure 2(c)), which
wipes out a randomly selected small rectangular area of
an image. Cutout is found to be a useful data augmenta-
(a) Normal
(b) Anomaly
(c) Cutout
(e) CutPaste
(f) CutPaste (Scar)
Figure 2: Visualization of (a, green) normal, (b, red) anomaly, and (c–h, blue) augmented normal samples from bottle,
toothbrush, screw, grid, and wood classes of MVTec anomaly detection dataset . Augmented normal samples are generated
by baseline augmentations including (c) Cutout and (d) Scar, and our proposed (e) CutPaste and (f) CutPaste (Scar). We use
red arrows in (f) to highlight the pasted patch of scar shape, a thin rectangle with rotation.
tion that enforces invariance, leading to improved accuracy
on multi-class classiﬁcation tasks. In contrast, we start by
discriminating Cutout images from the normal ones. At
ﬁrst glance, the task seems easy to solve by well-crafted
low level image ﬁlters. Surprisingly, as we will show in
Section 4, without the hindsight of knowing this, a deep
convolution network does not learn these shortcuts. Using
Cutout in the algorithm design for defect detection can also
be found in . We can make the task harder by randomly choosing colors and the scale as shown in Figure 2(d)
to avoid naive shortcut solutions.
To further prevent learning naive decision rules for discriminating augmented images and encouraging the model
to learn to detect irregularity, we propose the CutPaste augmentation as follows:
1. Cut a small rectangular area of variable sizes and aspect ratios from a normal training image.
2. Optionally, we rotate or jitter pixel values in the patch.
3. Paste a patch back to an image at a random location.
We show the CutPaste augmentation process in the orange
dotted box of Figure 1 and more examples in Figure 2(e).
Following the idea of rotation prediction , we deﬁne the
training objective of the proposed self-supervised representation learning as follows:
LCP = Ex∈X
CE(g(x), 0) + CE(g(CP(x)), 1)
where X is the set of normal data, CP(·) is a CutPaste augmentation and g is a binary classiﬁer parameterized by deep
networks. CE(·, ·) refers to a cross-entropy loss. In practice, data augmentations, such as translation or color jitter,
are applied before feeding x into g or CP.
2.2. CutPaste Variants
CutPaste-Scar.
A special case of Cutout called “scar” using a long-thin rectangular box of random color, as in Figure 2(d), is proposed in for defect detection. Similarly, in addition to original CutPaste using a large rectangular patch, we propose a CutPaste-Scar using a scar-like
(long-thin) rectangular box ﬁlled with an image patch (Figure 2(f)).
Multi-Class Classiﬁcation.
While CutPaste (large patch)
and CutPaste-Scar share a similarity, the shapes of an image patch of two augmentations are very different. Empirically, they have their own advantages on different types of
defects. To leverage the strength of both scales in the training, we formulate a ﬁner-grained 3-way classiﬁcation task
among normal, CutPaste and CutPaste-Scar by treating Cut-
Paste variants as two separate classes. Detailed study will
be presented in Section 5.2.
Similarity between CutPaste and real defects.
The success of CutPaste may be understood from outlier exposure , where we generate the pseudo anomalies (Cut-
Paste) during the training. Apart from using natural images
as in , CutPaste creates examples preserving more local
structures of the normal examples (i.e., the pasted patch is
(a) bottle
(b) toothbrush
Figure 3: t-SNE visualization of representations of models trained with 3-way CutPaste prediction task. We plot embeddings
of normal (blue), anomaly (red), and augmented normal by CutPaste (“Patch”, green) and CutPaste-scar (“Scar”, yellow).
from the same domain), which is more challenging for the
model to learn to ﬁnd this irregularity.
On the other hand, CutPaste does look similar to some
real defects. A natural question is if the success of Cut-
Paste is from a good mimic of real defects. In Figure 3, we
show the t-SNE plots of the representations from the trained
model. Clearly, the CutPaste examples are almost not overlapped with real defect examples (anomaly), but the learned
representation is able to distinguish between normal example, different CutPaste augmented samples and real defects.
It suggests (1) CutPaste is still not a perfect simulation of
real defects and (2) learning on it to ﬁnd irregularity generalizes well on unseen anomalies.
2.3. Computing Anomaly Score
There exist various ways to compute anomaly scores via
one-class classiﬁers. In this work, we build generative classiﬁers like kernel density estimator or Gaussian density estimator , on representations f. Below, we explain
how to compute anomaly scores and the trade-offs.
Although nonparametric KDE is free from distribution
assumptions, it requires many examples for accurate estimation and could be computationally expensive. With
limited normal training examples for defect detection, we
consider a simple parametric Gaussian density estimator
(GDE) whose log-density is computed as follows:
log pgde(x) ∝
2(f(x) −µ)⊤Σ−1(f(x) −µ)
where µ and Σ are learned from normal training data.1
2.4. Localization with Patch Representation
While we present a method for learning a holistic representation of an image, learning a representation of an image patch would be preferred if we want to localize defective regions in addition to image-level detection.
By learning and extracting representations from an image
1We note that a mixture of Gaussian, which is a middle ground between
KDE and GDE, can also be used for more expressive density modeling. We
do not observe signiﬁcant performance gain empirically.
patch, we can build an anomaly detector that is able to compute the score of an image patch, which then can be used to
localize the defective area.
CutPaste prediction is readily applicable to learn a patch
representation – all we need to do at training is to crop a
patch before applying CutPaste augmentation. Similar to
Equation (1), the training objective can be written as:
CE(g(c(x)), 0) + CE(g(CP(c(x))), 1)
where c(x) crops a patch at random location of x. At test
time, we extract embeddings from all patches with a given
stride. For each patch, we evaluate its anomaly score and
use a Gaussian smoothing to propagate the score to every
pixel . In Section 4.2, we visualize a heatmap using
patch-level detector for defect localization, along with that
of an image-level detector using visual explanation techniques such as GradCAM .
3. Related Work
Anomaly detection under one-class classiﬁcation setting,
where we assume only the normal data is given during the
training, has been widely studied . Recent success of self-supervised learning in computer vision has also been demonstrated effective for one-class classiﬁcation and anomaly detection. One major family is by predicting geometric transformations , such as rotation, translation or ﬂips.
The other family includes variants of contrastive learning
with geometric augmentations . However, the success has been limited to semantic anomaly detection benchmarks, such as CIFAR-10 or ImageNet , and as we
show in Section 4.1, methods relying on geometric transformations perform poorly on defect detection benchmarks.
Because of practical applications, such as industrial inspection or medical diagnosis, defect detection has
received lots of attention. The initial steps have been taken
with methods including autoencoding , generative adversarial networks , using pretrained models
on ImageNet , and self-supervised
learning by solving different proxy tasks with augmentations . The proposed CutPaste prediction
task is not only shown to have strong performance on defect detection, but also amenable to combine with existing
methods, such as transfer learning from pretrained models
for better performance or patch-based models for more accurate localization, which we demonstrate in Section 4.
3.1. Relation to Other Augmentations
Although Cutout and RandomErasing are similar to CutPaste, they create irregularities by a small rectangular region ﬁlled with either zero or uniformly sampled
pixel values instead of a structural image patch as CutPaste.
Moreover, unlike typical use of augmentations for learning
invariant representations, we learn a representation that is
discriminative to these augmentations.
Scar augmentation (Figure 2(d)) is a special case of
Cutout, which uses a long-thin rectangle with random colors. While it demonstrates strong performance, we show
that CutPaste with the same scale (Figure 2(f)), which ﬁlls
a long-thin rectangle by a patch from the same image, improves upon representations trained by predicting Cutout.
CutMix , which extracts a rectangular image patch
from an image and pastes at random location of another image, is related to CutPaste in terms of pasting operations.
One main difference is CutMix leverages existing image labels with MixUp in the objective while CutPaste prediction is a self-supervised learning without the need of image labels. The other difference is CutMix studies standard
supervised tasks, while we aim for one-class classiﬁcation.
 presents a denoising autoencoder with patch-swap
augmentation as noise process. proposes to learn representations by predicting local augmentations using GAN.
Our method is simpler (e.g., no need to train decoder or
GAN) while highly performant, thus more practical.
4. Experiments
We conduct most experiments on MVTec Anomaly Detection dataset that contains 10 object and 5 texture categories for anomaly detection. The dataset is composed of
normal images for training and both normal and anomaly
images with various types of defect for testing. It also provides pixel-level annotations for defective test images. The
dataset is relatively small scale in number of images, where
the number of training images varies from 60 to 391, posing
a unique challenge for learning deep representations.
We follow one-class classiﬁcation protocol, also known
as semi-supervised anomaly detection ,2 where we train
a one-class classiﬁer for each category on its respective normal training examples. Following , we learn the representations by augmentation prediction from scratch with
2While previous works have used unsupervised to describe their
settings, it could be misleading as training data is curated to include normal
data only.
ResNet-18 plus an MLP projection head on top of average pooling layer followed by the last linear layer. We construct a Gaussian density estimation (GDE) as Equation (2)
for anomaly detector based on the top pooled features.
We train a model on 256×256 image. We note that the
same training strategy, such as the selection of hyperparameters or data augmentations, is applied to all categories. Detailed settings of training can be found in Appendix A.
4.1. Main Results
We report the anomaly detection performance in Table 1.
We run experiments 5 times with different random seeds
and report the mean AUC and standard error for each category. We also report the average of mean and standard
errors for texture, object, and all categories.
We test representations trained with different proxy tasks
of self-supervised learning, including baselines such as rotation , Cutout or scar predictions, the proposed Cut-
Paste, CutPaste-Scar predictions, and using both with 3-way
classiﬁcation. We also compare with previous works, including deep one-class classiﬁer (DOCC) , uninformed
student , and patch SVDD . We note that some of
these methods use ImageNet pretrained model for transfer
learning, either by ﬁne-tuning (DOCC) or distillation (uninformed student). The results are in Table 1.
Rotation prediction is demonstrated to be powerful in semantic anomaly detection . However, it results in unsatisfactory 73.1 AUC in defect detection compared with
the Scar prediction (85.0), a Cutout variant.
Some failure of rotation prediction is due to the unaligned objects,
such as screw shown in Figure 2. For aligned objects, although it performs well on toothbrush, it is sub-optimal
on capsule. Detailed ablation study of Cutout variants
can be found in Section 5.
CutPaste and CutPaste-Scar, which improve Cutout and
Scar prediction by avoiding potential naive solutions, outperform other augmentation predictions with 90.9 and 93.5
AUCs, respectively. With a ﬁner-grained 3-way classiﬁcation to leverage different scale of CutPaste, we achieve the
best 95.2 AUC, which surpasses existing works on learning
from scratch, such as P-SVDD (92.1 AUC). The proposed data-driven approach via CutPaste is also better than
existing works leveraging pretrained networks, including
DOCC (87.9 AUC) with pretrained VGG16 and Uninformed Student (92.5 AUC) with pretrained ResNet18.
Last, we further improve the AUC to 96.1 by ensembling
anomaly scores from 5 CutPaste (3-way) models.
4.2. Defect Localization
We conduct anomaly localization experiments using our
representations trained with 3-way classiﬁcation task. One
challenge to accurate localization of defect is that it is difﬁcult to use a heatmap-style approach for localization as our
Table 1: Anomaly detection performance on MVTec AD dataset . We report AUCs of representations trained to classify
CutPaste, CutPaste (scar), both (3-way), and baseline augmentations such as rotation, Cutout, or scar. For comparison, we
report those of deep one-class classiﬁer , uninformed student and patch-SVDD . We report mean and standard
error tested with 5 random seeds. Lastly, we report the AUC using ensemble of 5 CutPaste (3-way) models. The best
performing model and those within standard error are bold-faced.
100.0 ±0.0
100.0 ±0.0
toothbrush
transistor
Figure 4: Defect localization on bottle, hazelnut, metal nut, screw, wood and grid classes of MVTec datasets. From top to
bottom, input images, those with ground-truth localization mask in red, GradCAM results using image-level detector, and
heatmaps using patch-level detector. We provide more examples in Appendix B.
model learns a holistic representation of an image. Instead,
we use visual explanation techniques, GradCAM , to
highlight the area affecting the decision of anomaly detector. We show qualitative results in the second row of Figure 4, which are visually pleasing. We further evaluate the
pixel-wise localization AUC, achieving 88.3.
Instead, we learn a representation of an image patch using CutPaste prediction, as in Section 2.4. We train models of 64×64 patches from 256×256 image. At test time,
we densely extract anomaly scores with a stride of 4 and
propagate the anomaly scores via receptive ﬁeld upsampling with Gaussian smoothing . We report a localization AUC in Table 2. Our patch-based model achieves 96.0
AUC. Speciﬁcally, our model shows strong performance on
texture categories over previous state-of-the-art (96.3 AUC
compared to 93.7). We also outperforms the DistAug contrastive learning , which only results in 90.4 localization AUC. Finally, we visualize representative samples for
localization in Figure 4, showing accurate localization even
when defects are tiny. More comprehensive results on defect localization are given in Appendix B.
4.3. Transfer Learning with Pretrained Models
In Section 4.1, we have shown the proposed data-driven
approach is better than leveraging pretrained networks, such
as DOCC and Uninformed Student . It is consistent
Table 2: Pixel-wise localization AUC on MVTec dataset.
The best and models within standard error are bold-faced.
P-SVDD 
CutPaste (3-way)
toothbrush
transistor
Table 3: Detection performance on MVTec dataset using
representations of EfﬁcientNet (B4) pretrained on ImageNet and ﬁne-tuned by the CutPaste (3-way). The
number is bold when it is better than its pretrained or ﬁnetuned counterpart under the same feature (pool v.s. level-7).
toothbrush
transistor
with the prior study on semantic anomaly detection .
On the other hand, pretrained EfﬁcientNet is found useful for defect detection . As shown in Table 3, without
ﬁne-tuning, the representation from the pretrained Efﬁcient-
Net (B4) results in 94.5 AUC, which is competitive with the
proposed CutPaste prediction (95.2 from Table 1).
Here we demonstrate that the proposed self-supervised
learning via CutPaste is versatile, which can also be used to
improve the pretrained networks to better adapt to the data.
We use pretrained EfﬁcientNet (B4) as a backbone, and follow the standard ﬁne-tuning steps to train with the same
Table 4: Detection AUCs of representations trained to predict Cutout, with mean pixel value, with random color, Confetti noise , or the proposed CutPaste.
(a) Cutout
(Standard)
(b) Cutout
(c) Cutout
(Random Color)
(d) Confetti
(e) CutPaste
Figure 5: Visual comparison between the proposed Cut-
Paste and Cutout variants, including ﬁlling with grey color,
mean pixel values, random colors and Confetti noise .
CutPaste prediction (3-way) task. Detailed settings can be
found in Appendix A. We show the results in Table 3. After
ﬁne-tuning via CutPaste, we achieve the new state-of-theart 96.6 AUC. Furthermore, CutPaste prediction is a general and useful strategy to adapt to the data for most of the
situations. For example, CutPaste improves by a large margin on class pill (81.9 →91.3). For many nearly perfect
situations, such as bottle, CutPaste is still able to improve by a small margin. Last, as suggested by , we
investigate the performance of various deep features. We
ﬁnd that level-7 feature shows the best performance, and
we further improve the level-7 feature of EfﬁcientNet from
96.8 (pretrained) to 97.1±0.0 with CutPaste.
5. Ablation Study
We conduct various additional studies to provide deeper
insights of the proposed CutPaste. We ﬁrst compare Cut-
Paste with different Cutout variants in addition to the standard ones reported in Section 4.1. Second, we showcase the
representation learned via predicting CutPaste generalizes
well to more crafted unseen defects. Last, we compare with
the semantic anomaly detection.
5.1. From Cutout to CutPaste
We evaluate the performance of representations trained
to predict variants of Cutout augmentations whose areas are
ﬁlled by grey color (standard), mean pixel values, random
color, or image patch from different location, i.e., CutPaste.
We also test Confetti noise that jitters a color of a local
patch. We show samples from considered augmentations in
Figure 5 and report the detection AUCs in Table 4. While
Table 5: Detection AUCs of representations trained with
binary classiﬁcation between normal and the union of Cut-
Paste and CutPaste-Scar examples and 3-way classiﬁcation
among normal, CutPaste and CutPaste-scar examples.
CutPaste (scar)
Binary (Union)
achieving 71.3 AUC that already is signiﬁcantly better than
random guessing, predicting a standard Cutout augmentation is still a simple task and the network may have learned
a naive solution from easy proxy task, as discussed in Section 2. By gradually increasing the difﬁculty of proxy task
to avoid known trivial solutions with random color to the
patch, or with structures similar to local patterns of the normal data (Confetti noise, CutPaste), the network learns to
ﬁnd irregularity and generalizes better to detect real defects.
5.2. Binary v.s. Finer-Grained Classiﬁcation
In Table 1, although CutPaste-scar shows better performance on average than CutPaste, there is no clear winner
that works the best for all. As there are diverse types of
defect in practice, we leverage the strength of both augmentations for representation learning. In Section 2.2, we train
a model by solving a 3-way classiﬁcation task between normal, CutPaste and CutPaste-scar. Alternatively, we train to
solve a binary classiﬁcation task by discriminating normal
examples and the union of two augmentations.
The results, along with those of representations trained
with CutPaste and CutPaste-scar, are in Table 5. It is clear
that using both augmentations improve the performance.
Between binary with union of augmentations and 3-way,
we observe better detection performance with representations trained by 3-way classiﬁcation task. A plausible hypothesis on the superiority of 3-way formulation in our case
is that it is more natural to model CutPaste and CutPastescar augmentations separately than together as there exists
a systematic difference between them in the size, shape, and
rotation angle of patches.
5.3. CutPaste on Synthetic Anomaly Detection
We further study the generalization of our models to unseen anomalies. Speciﬁcally, we test on synthetic anomaly
datasets created by patching diverse shape masks to normal
data, such as digits , square, ellipse, or heart , ﬁlled
with random color or natural images. Samples of synthetic
anomalies are shown in Figure 6 and detection results are in
Table 6. We ﬁrst note that these datasets are not trivial – a
model trained by predicting Cutout augmentations achieves
only 81.5. Our proposed CutPaste (3-way) model performs
well on synthetic dataset, achieving 98.3 AUC on average.
We highlight that some shapes (e.g., ellipse, heart) or color
Figure 6: Synthetic defects on pill class. From left to right,
we use MNIST , square, ellipse, heart with random
color, and those ﬁlled with natural image patches.
Table 6: Detection AUCs on synthetic data. Various shapes,
such as digit, square, ellipse, or heart, are patched to normal
images with random color or natural images (†).
statistics inside the patch (e.g., constant color, natural images) are not seen at training, but we can still generalize to
these unseen cases.
5.4. Application to Semantic Outlier Detection
We also conduct the semantic anomaly detection experiment on CIFAR-10 following the protocol in ,
where a single class is treated as normal and remaining 9
classes are anomalies. We make a comparison of Cutout,
CutPaste and rotation prediction . Cutout results in 60.2
AUC, and CutPaste achieves 69.4 AUC, which signiﬁcantly
improves upon Cutout (60.2). However, these are still far
behind that of rotation prediction (91.3 AUC) on CIFAR-10
semantic anomaly detection. On the other hand, in Section 4.1, we have discussed the reversed situation that rotation prediction is much worse than 3-way CutPaste prediction. The results suggest the difference between semantic
anomaly detection and defect detection, which needs different algorithm and augmentation designs.
6. Conclusion
We propose a data-driven approach for defect detection
and localization. The key to our success is self-supervised
learning of representations with CutPaste, a simple yet effective augmentation that encourages the model to ﬁnd local
irregularities. We show superior image-level anomaly detection performance on the real-world dataset. Furthermore,
by learning and extracting patch-level representations, we
demonstrate state-of-the-art pixel-wise anomaly localization performance. We envision the CutPaste augmentation
could be a cornerstone for building a powerful model for
semi-supervised and unsupervised defect detection.
Acknowledgment.
We thank Yang Feng for sharing the
implementation of uninformed student and Sercan Arik for
the proofread of our manuscript.