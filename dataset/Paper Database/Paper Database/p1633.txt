Psychonomic Bulletin & Review
2005, 12 (2), 195-223
Response time (RT), the time taken to complete a task,
is a common dependent variable that has been used to
draw inferences about the nature of mental processing
 . Most researchers tend to analyze only
mean RT, but a growing number are examining whole RT
distributions as a means of providing extensive and insightful tests of cognitive and perceptual theories . Consider the following example, which demonstrates the appeal of distributional analysis.
Sternberg asked participants whether a probe
item was presented in a study set. The resulting data were
well described by a linear relationship between set size
and mean RT, and this pattern is consistent with serial
scanning in immediate memory. Consider the simplest
exhaustive serial model, in which participants match a
probe to each item in memory in succession. Let the time
to match the probe to the ith item be Si. The RT to answer
for a study set of k items is RT  S1  . . .  Sk  R,
where R is the time for residual processes, such as encoding the probe item and executing the response. In the simplest model, it is assumed that the times to match items
follow a common distribution (S) and are independent.
This model yields a number of predictions about how the
data vary as a function of the number of items (k), including the following: mean(RT)  mean(R)  k  mean(S ).
This prediction about mean RT holds in experimental data
 .
Townsend and colleagues, however, have repeatedly
pointed out that this pattern among mean RTs can be consistent with other models, such as those based on parallel
scanning with capacity limits . Instead of relying on model predictions
about mean RT alone, researchers can examine whole RT
distributions. For the case of the simple model above, there
are two other predictions: one about the variability and the
other about the shape of RT distributions. The variability
of an individual’s RT distribution follows: Var(RT) 
Var(R)  k  Var(S). The shape of an individual’s RT distribution approaches that of a normal distribution as study
set size (k) is increased (an application of the central limit
theorem). Ashby et al. provided an exceedingly
comprehensive analysis of RT distributions for the Sternberg memory-scanning task. They tested a number of
distribution-level predictions for a wide class of serial
and parallel models. They concluded that both serial
models and unlimited-capacity parallel models are not
consistent with the data. They favored a limited-capacity,
self-terminating parallel model such as Ratcliff’s 
Copyright 2005 Psychonomic Society, Inc.
This research was supported by National Science Foundation Grant
SES-0095919 to J.N.R., D.S., and P.S., by University of Missouri Research
Board Grant 00-77 to J.N.R., and by National Science Foundation Grant
DMS-9972598 to D.S. and P.S. We are grateful to Michael Stadler, who
allowed us use of his data. We are indebted to Andrew Heathcote, who
has provided constructive criticism and interesting ideas for development in his reviews. Correspondence concerning this article may be addressed to J. N. Rouder, Department of Psychological Sciences, 210
McAlester Hall, University of Missouri, Columbia, MO 65211 (e-mail:
 ).
A hierarchical model for estimating
response time distributions
JEFFREY N. ROUDER, JUN LU, PAUL SPECKMAN, DONGCHU SUN, and YI JIANG
University of Missouri, Columbia, Missouri
We present a statistical model for inference with response time (RT) distributions. The model has
the following features. First, it provides a means of estimating the shape, scale, and location (shift) of
RT distributions. Second, it is hierarchical and models between-subjects and within-subjects variability simultaneously. Third, inference with the model is Bayesian and provides a principled and efficient
means of pooling information across disparate data from different individuals. Because the model efficiently pools information across individuals, it is particularly well suited for those common cases in
which the researcher collects a limited number of observations from several participants. Monte Carlo
simulations reveal that the hierarchical Bayesian model provides more accurate estimates than several
popular competitors do. We illustrate the model by providing an analysis of the symbolic distance effect in which participants can more quickly ascertain the relationship between nonadjacent digits than
that between adjacent digits.
THEORETICAL AND REVIEW ARTICLES
ROUDER, LU, SPECKMAN, SUN, AND JIANG
diffusion model. This example shows how distributionlevel analysis may provide deeper insight into cognitive
processes than just mean-level analyses do.
The main disadvantage of distribution analysis is that
it requires a large number of observations to be effective.
Moreover, these observations need to be independent
replicates from a common source. To meet this requirement, researchers need to gather several hundred observations in each condition from each participant. For example, in testing distributional properties in memory
scanning, Ashby et al. analyzed about 1,500 observations per participant per study set size. Each participant took part in 17 sessions and observed about
6,000 total trials. Likewise, in their analysis of RT distributions, Ratcliff and Rouder 
collected about 10,000 total observations per participant.
The requirement of several replicates per participant
and condition is often burdensome and prohibitive. In
practice, many researchers have access to college participant pools. In these pools, it is convenient to gather data
from a large number of participants who take part in a
single session of a few hundred trials. These trials must
be partitioned across several conditions. The upshot is
that in many applications, the number of RT observations in conditions is in the tens, rather than in the hundreds or thousands.
This requirement of a large number of independent
replicates would not raise problems if participants did
not vary substantially from each other. If data from all
participants were samples from the same underlying distributions, we could simply pool all the data and consider
them as independent replicates from a common source.
There is, however, often great variability in distributional properties across participants themselves. Figure 1
shows an example from a very simple experiment in which
participants had to indicate the location of an asterisk on
the screen. The distributional properties highlighted in
the figure are shift (the time at which the distribution
first attains mass), scale, and shape. Even though this
task is simple, there is still substantial across-participant
variability in these distributional properties. The first
column shows 2 participants whose distributions vary in
shift by a factor of two. The middle column shows 2 participants whose distributions vary in scale by a factor of
two, and the last column shows 2 participants whose distributions vary from very skewed to nearly symmetrical.
This variability in distributional properties across participants eliminates the possibility of considering all of
the RTs as independent replicates from a common source.1
One of the major challenges in using RT distributions is
accounting for variability both within individuals and
between them.
The goal of this article is to provide a statistical model
for the estimation of RT distributions in cases in which
researchers have data from several participants, but with
only a small number of observations per participant. The
model has three main properties. First, it is parametric;
each participant’s RTs are assumed to follow a three-
Figure 1. Histograms of response times (RTs) for selected pairs of participants. The lefthand column emphasizes differences in shift across participants. The middle and right-hand
columns emphasize differences in scale and shape, respectively. Histograms are scaled so that
the total area is one. The area of the rectangles, as opposed to their height, yields the proportion of observations within the corresponding interval. Figure reprinted with permission
from Rouder, Sun, Speckman, Lu, and Zhou .
ESTIMATING RT DISTRIBUTIONS
parameter Weibull distribution2 . The Weibull is a flexible form whose
parameters correspond to the heuristics of shift, scale,
and shape.3 The meaning of these parameters is depicted
graphically in Figure 2. Second, it is hierarchical, with separate model components for variability within a participant
and between participants. Each participant is accorded
unique Weibull parameters, but a common underlying
distribution describes the variability of these parameters.
Third, the method of parameter estimation and hypothesis testing is Bayesian. Researchers typically have several choices of methods in performing inference in nonhierarchical models, including classical methods such as
maximum likelihood (ML) and least squares. We choose
Bayesian methods for the hierarchical models because of
feasibility. Since the three-parameter Weibull is outside
the family of generalized linear models, we know of no
method to perform inference on the hierarchical version
other than Bayesian methods. There has been a great
deal of progress in the last decade in estimating hierarchical models with Bayesian methods , and this progress makes
inference with the presented models feasible.
Before discussing the model, we provide a context for
its intended role. It is important to differentiate between
statistical modeling and substantive modeling. Statistical
models, such as the analysis of variance (ANOVA), regression models, and structural equation models, are used
in a different spirit than more substantive models, such as
the diffusion model or the interactive activation model . The former are used for estimation and inference, whereas the
latter are tested as truthful models of phenomena. We
view our hierarchical Weibull model as best used in the
spirit of the former; its usefulness is derived from the interpretability of its parameters, its ability to provide principled inference on these parameters with small samples
per participant, its ability to provide reasonable inference even when model assumptions have been violated
(this ability is termed robustness to misspecification), and
its ability to provide a reasonable fit to data. We do not
claim that the hierarchical Weibull models provide the
best fit to all data. Other forms, such as the ex-Gaussian,
may indeed do well. We do claim that hierarchical Weibull
models are highly appropriate for inference on characteristics of RT distributions such as shift, scale, and shape in
the common case in which researchers collect a limited
number of observations from many participants.
This article is divided into three sections. First, we
will present the model and method of parameter estimation. Then we will test the model’s ability to provide accurate parameter estimates vis-à-vis other contemporary
methods, such as ML estimation (MLE), Vincentizing,
and quantile-based estimation .
The model outperforms all of these methods in estimating both individual- and group-level parameters. After
demonstrating the benefits of the model, we will discuss
other aspects, including the fit of the Weibull, the interpretation of the parameters, and the model’s robustness
to misspecification. Finally, we will fit the model to an
experiment with a symbolic distance effect. Observers
in the experiment had to decide whether a presented digit
was less than or greater than 5. Digits far from 5 (e.g., 2
and 8) were more quickly classified than digits close to
5 (e.g., 4 and 6). The hierarchical Weibull model revealed a locus for the symbolic distance effect in terms
of distributional properties. Symbolic distance affects
the scale of RT distributions.
The model that we will discuss was first presented by
Rouder, Sun, Speckman, Lu, and Zhou . They provided a detailed and formal account. We will provide a
less formal and more accessible account of the advantages
of the model for experimentalists. As has been mentioned,
the model is parametric and hierarchical, and inference is
done with Bayesian methods. Although the Bayesian approach has played a large role in theories of decision making , it has not been used
extensively for data analysis in cognitive psychology . Likewise, hierarchical modeling
is better known in social and clinical psychology. Because
of this lack of long-standing tradition in either Bayesian
Figure 2. The Weibull parameters of shift, scale, and shape. Each plot shows the effect of
changing one parameter while holding the other two constant.
ROUDER, LU, SPECKMAN, SUN, AND JIANG
data analysis or hierarchical modeling, we will motivate
our model with a true anecdote from a baseball game.
Baseball Example
In the late summer of 2000, the struggling Kansas
City Royals were hosting the Boston Red Sox. Pitching
for Boston was Pedro Martínez, who was having a truly
phenomenal year. Many in the crowd came to see Martínez
and his dominant pitching. Contrary to expectation, in
the first inning, Kansas City scored five runs, and Boston
none. At the end of the first inning, one of our colleagues,
who is a loyal Royals fan and an APA editor, predicted a
final score of 45–0. The reason this prediction is humorous is because it is both quite logical and wildly implausible. It is logical because 45–0 is obtained by multiplying the first inning scores by 9, the number of innings in
a baseball game. It is wildly implausible on three accounts. First, there has never been a baseball game with
such an extremely high score. Second, Boston was far
superior to Kansas City. Third, Boston had the best pitcher
in baseball on the mound. After the first inning, Martínez
pitched well, allowing only one additional run. Kansas
City lost the game by a score of 7–6; Martínez was the
winning pitcher.
The reason the logical prediction of 45–0 was so bad is
that it was based on a small sample, the result of a single
Figure 3. An illustration of shrinkage in a hierarchical model. Estimates of shape from histograms reflect sampling variability. When these estimates are constrained by a plausible parent distribution, they
can be adjusted to more reasonable values.
ESTIMATING RT DISTRIBUTIONS
inning of play. One way of improving the estimate is to
combine it with our previous knowledge of baseball. Simply put, any person with any inkling about baseball could
have produced a better estimate. This prior knowledge
does not need to reflect anything more than a knowledge
of the distribution of baseball scores. One need not know
about pitchers and teams; all one needs for a vastly better
estimate is the final score of a few hundred previous baseball games. Of course, the estimate would be even further
improved by a detailed knowledge of baseball.
This technique of using a small amount of prior knowledge to improve estimates can be used in the analysis of
human performance in psychology experiments. Participants’ data, especially when obtained from a small sample, are highly variable. The effects of this variability are
acute for estimating higher order properties, such as
scale and shape. By using the higher order properties of
all the participants together as a baseline, we can better
assess whether extreme estimates come about from sampling variability, and if they do, we can correct our estimates accordingly. The baseline need not be overly subjective; in our model, it reflects the contribution of the
participants in the present experiment.
Hierarchical Prior Distributions
The key concept in the model is its hierarchical nature.
In hierarchical models, parameters are assumed to come
from underlying parent distributions.4 Figure 3 provides
an illustration of the advantage of using hierarchical
models with parent distributions. The example is for the
shape parameter, although any distributional parameter
can be treated in a hierarchical manner. Panel A shows
hypothetical histograms of 30 RTs from each of 6 participants. In fact, each of these histograms was sampled
from a three-Weibull distribution with the same shift
(200 msec), scale (200 msec), and shape (1.7). Due to
sampling variability, the histograms are diverse. The
best-fitting Weibull distributions are drawn over the histograms. The estimated shape parameters are shown, and
these are also diverse, ranging from 0.74 (skewed right)
to 4.37 (skewed left). Panel B shows a hypothetical parent distribution of the shape parameters. For the purpose
of the example, let’s assume that this distribution accurately reflects the distribution of shapes in a population.
In practice, we only assume a parametric form for the
parent distributions and estimate parent distribution parameters from the data. The six shape estimates from the
histogram in panel A are indicated by Xs. On the basis
of the parent distribution, it is obvious that the two extreme shape values are implausible and reflect a large degree of sampling variability. A reasonable correction is
to adjust it toward a more probable value. This adjustment is shown by thick lines with arrows, and the resulting parameter estimates are denoted by Hs (for hierarchical estimates). As can be seen, these new values,
which reflect the influence of the parent distribution, are
closer to the true shape (1.7 in this case) than the original
individual estimates are. The adjustment of an extreme
estimate to a more moderate one is termed shrinkage.
The gains from hierarchical models have been well understood within the statistical literature . The main problem is that of tractability; although it is easy to postulate
hierarchical models, it has traditionally been computationally difficult to analyze them. Over the last decade
or so, there have been steady gains in Bayesian statistics
that have made these hierarchical models more tractable
 . One recent example
of success of Bayesian analysis in psychology is that in
item response theory . Our model is based on these statistical
advances and would not have been possible a decade ago.
In our model, the scale and shape parameters are treated
hierarchically, but the shift parameter is not.5 The parent
distributions for scale and shape are gamma distributions. The gamma distribution is a two-parameter form;
it is quite flexible and can be arbitrarily broad or narrow.
The gamma was chosen on the basis of tractability and
convenience. The parameters that determine the specific
form of the parent distribution are themselves free parameters that are estimated from the data. A more technical specification of the model is given in Appendix A,
and an extensive discussion of issues related to parameter estimation may be found in Rouder, Sun, et al.
 . Software in Splus/R and in WinBUGS may be
found at www.missouri.edu/~pcl.
THE ADVANTAGES OF THE
HIERARCHICAL WEIBULL MODEL
In this article, we claim that the hierarchical Weibull
model is useful in the analysis of RT distributions for four
reasons: (1) It allows researchers to pool data across several participants, resulting in vastly improved inference
with small samples per participant; (2) its parameters are
interpretable in terms of psychological process; (3) it fits
data reasonably well; and (4) it is reasonably robust to
misspecification. In the following sections, we will examine all four of these reasons in turn.
Estimation With Small Samples
In this section, we will compare Bayesian estimation of
the hierarchical Weibull model (HB) with that of other
methods. The gold standard of estimation of distributions
is ML estimation. ML is an accepted and recommended
method in both the statistical literature and the psychological literature . Several good introductory texts cover ML,
including Hogg and Craig and Lehmann .
There is a problem encountered if ML is used to estimate Weibull parameters when the shape parameter is
less than 1. When the shape is less than 1, the Weibull resembles an exponential but is even more skewed. In this
case, ML estimates of the Weibull are not necessarily
consistent . In our opinion, shape
ROUDER, LU, SPECKMAN, SUN, AND JIANG
parameters are always greater than 1 in most perceptual
and cognitive experiments. Therefore, ML has ample
theoretical justification.
In the following subsection, we will estimate parameters from a data set, using HB and ML estimation. For
certain participants, the estimates are different. After
that, we will describe a large simulation in which 10 estimation methods are compared. The Bayesian method
with the hierarchical Weibull model provided more accurate estimates than any other method did.
Figure 4. Maximum likelihood and hierarchical Bayesian estimates for Stadler’s data.
Adapted with permission from Rouder, Sun, Speckman, Lu, and Zhou .
Figure 5. Histograms and fits for 4 selected participants. The solid and dotted lines
show Weibull density with parameters from maximum likelihood and hierarchical
Bayesian estimates, respectively. These particular participants were selected to maximize the difference between estimation methods. Reprinted with permission from
Rouder, Sun, Speckman, Lu, and Zhou .
ESTIMATING RT DISTRIBUTIONS
Application to a Data Set
Rouder, Sun, et al. have provided an example in
which both ML and HB estimates are produced from the
same data set. The set, collected by Michael Stadler, consists of 80 observations for each of 80 individuals.6 Figure 4 shows the relationship between ML and HB estimates as scatterplots. The points represent estimates from
individuals. The x-axis value of a point denotes the ML estimate, and the y-axis value denotes the HB estimate. Overall, many of the points cluster on the diagonal, indicating
concordance between the HB and the ML estimates. The
big difference is in the shape parameter. Here, the points
deviate substantially from the diagonal. The slope is less
than 45º, indicating greater variability for the ML estimates than for the HB estimates. To better understand the
nature of these differences, it is helpful to show the fits of
the Weibull density to individuals’ data (Figure 5). The top
two panels show data that are fairly skewed, and the ML
predictions track this skew well. HB predictions are a little
less skewed. According to the hierarchical interpretation,
the degree of skew in the data is atypical, given the rest of
the participants, and may reflect sampling variability. The
Bayesian prediction, which takes this into account, is more
moderate. The same dynamics are evident in the bottom
panels. Here, the data are atypically symmetric, and the
Bayesian predictions are more skewed than the ML predictions. Overall, the extreme Bayesian estimates are less
extreme than their ML counterparts and are more like
those from typical participants.
Simulation Study
The above analysis shows where HB estimation diverges
from more conventional ML estimation. To assess which
estimation method is most accurate, we performed a
Monte Carlo simulation study. In addition to HB and ML,
we included several other methods used or proposed in
experimental psychology. We split the methods into two
types: those that estimate individuals’ shift, scale, and
shape parameters and those that estimate group-level
shift, scale, and shape.
Individual-Level Methods
Bayesian estimation with the hierarchical Weibull.
As has been discussed, Weibull parameters are assumed
to be randomly sampled from parent distributions (see
Appendix A for details). Estimation is done through
Monte Carlo Markov chain techniques, with details provided in Rouder, Sun, et al. . The model yields individual estimates of shift, scale, and shape parameters.
Maximum likelihood. Parameters are obtained by
maximizing the likelihood function with the simplex
routine . Each individual’s RT
distribution is fit separately, yielding individual estimates of shift, scale, and shape.
Quantile maximum likelihood. Quantile maximum
likelihood (QML) is a new method from Heathcote et al.
 . Unlike conventional ML, estimates are based on
sample quantiles.7 The basic idea is that the likelihood of
the parameters can be expressed as a function of the sample quantiles. The estimates are those values that maximize the likelihood of the parameters, given the sample
quantiles.8 QML is applied to an individual’s sample
quantiles to obtain individual parameter estimates. We
experimented with several choices of sample quantiles
and found that estimators were most accurate when all of
the data points served as sample quantiles.9 Choices with
fewer quantiles, such as 5 or 10, led to dramatically worse
estimation.
Quantile least-squares. In the quantile least-squares
(QLS) method, the parameter estimate is that which minimizes the summed squared error between the sample
quantiles and the predicted quantiles. Jiang, Rouder, and
Speckman have shown that QLS is the most efficient means of estimating parameters from sample quan-
Figure 6. A schematic of the simulation tests.
ROUDER, LU, SPECKMAN, SUN, AND JIANG
tiles for a restricted class of distributions called location–
scale models. Although the three-parameter Weibull is
not a location–scale model, it is reasonable to suspect
that this method will do well. Rouder and Speckman
 used this method to estimate parameters from the
Weibull, ex-Gaussian, and shifted-Wald with varying degrees of success. To use the method, it is necessary to
choose a set of sample quantiles, and we chose to use all
of the data points as sample quantiles.10 Choices with
few quantiles, such as 5 or 10, led to dramatically worse
estimation.
Group-Level Methods
Vincentizing  quantile maximum likelihood. Vincentizing is a popular nonparametric method for constructing group-level RT distributions .
The basic idea is that individuals’ sample quantiles are
averaged to produce a group distribution.11 For example,
the 10th percentile of the group distribution is the average of individuals’ 10th percentiles. The method of estimating parameters from a Vincentized form is a wellused method of obtaining stable estimates with small
sample sizes .
Hence, a comparison of Vincentizing with the HB estimation is of particular interest. In the Vincentizing 
QML (VQML) method, estimates are obtained from
averaged quantiles by the QML method described above.
Vincentizing  quantile least squares. This method
is identical to VQML, with the exception that QLS is
used to estimate parameters from averaged quantiles.
Parameter averaging. An obvious method for constructing group-level estimates is to average individual parameter estimates. This method can be implemented with
all the individual parameter estimation methods listed
above. When using this method, we add the suffix PA (for
parameter averaging) to the method label. For example,
HBPA refers to the method of averaging individual parameters obtained with the HB method. There are four PA
methods: HBPA, MLPA, QMLPA, and QLSPA.
Simulation Method
To assess the relative performance of the individualand group-level estimation methods, we performed a set
of simulation studies. Figure 6 provides a schematic of
the simulations for the individual-level methods. The
first step is to pick “true” values for the simulations. To
ensure that we started with a realistic degree of participant variability, we used the ML estimates of the Weibull
parameters from Stadler’s data set as true values (see
Figure 4). There are three estimates per individual and
80 individuals in the set. The resulting 240 true values are
depicted in Box 1 in Figure 6 as “T–Shift,” “T–Scale,” and
“T–Shape.” We defined the true group parameter as the
arithmetic average across the true individual parameters—
for example, the true group shift parameter is the average
of the individual true shift parameters (see Box 2 in the
figure). Artificial data were simulated using individual
true values (see Box 3). Individual-level parameters were
estimated (Box 4) and then averaged to produce grouplevel estimates (Box 5). The artificial data were Vincentized (Box 6), and the resulting averaged quantiles were
used to produce group-level estimates (Box 7). The process of generating data from true values and estimating
parameters was repeated 600 times to obtain the sampling properties of all of the methods.
Two sample sizes were used in the simulations. In the
first test, an artificial data set consisted of 80 observations for each of the 80 individuals (shown in Figure 6).
These sample sizes are fairly typical for large experiments in cognitive and perceptual psychology. In the second test, the number of observations per individual was
reduced to 20. Although 20 seems like a small number,
it is typical of the numbers of trials per cell in multifactor experiments. According to conventional wisdom, 20
observations per individual is not sufficient for distributional analysis without the aid of Vincentizing . Therefore, this small-sample
simulation provides a stringent test for HB estimation.
The appropriate statistic to consider is estimation error:
the difference between the true value of a parameter and its
estimate. By considering errors across all of the data sets,
it is possible to construct the sample error distributions.
The root mean square error (RMSE) serves as a summary
statistic. Table 1 shows RMSE for the first test (80 observations per individual) under the columns “RMSE.”
The columns labeled “HB Gain” provide a convenient
comparison of each method to HB. It is the RMSE of estimates from an alternative method divided by the RMSE
of the HB estimates. If the HB estimates are more accurate, the gain is greater than 1. For example, if the gain
of the HB estimate over an alternative is 2.0, HB estimates are, on average, twice as accurate as the estimates
from the alternative.
The HB method is best for estimating individuals’ parameters. The results, however, are more equivocal for
estimating group averages. All of the PA methods as a
group fared well and outperformed the Vincentizingbased methods. As has been pointed out by Rouder and
Speckman and Thomas and Ross , Vincentizing is not a theoretically justified method for threeparameter distributions, such as the Weibull or the ex-
Gaussian. The reason is that in these cases, Vincentized
estimators are not consistent; that is, they do not become
arbitrarily accurate with sufficiently large sample sizes.12
The PA methods discussed above are consistent, and
given a sufficiently large sample, they can be made arbitrarily accurate. This lack of consistency in estimates
from Vincentizing explains its relatively weaker performance with larger sample sizes. Although all of the PA
methods performed well, averaged HB estimates held a
slight edge for estimating group shift and group scale,
whereas averaged ML was best for estimating group
shape. Overall, HBPA and QMLPA were the most
accurate group-level methods.
ESTIMATING RT DISTRIBUTIONS
Table 2 shows the results from the second simulation,
in which there were only 20 observations per individual.
The results are dramatic. Reasonable individual estimates could be obtained only by HB. The ML, QML, and
QLS methods failed completely. Likewise, for grouplevel estimates, HBPA provided reasonable estimates,
whereas MLPA, QMLPA, and QLSPA failed completely. The Vincentizing methods did not fail dramatically but were about half as accurate as the HBPA
The reason for the dramatic difference in RMSE stems
from a pathology of the Weibull for distributions that are
skewed left—for example, those with a high shape parameter value. In this case, changes in the shape parameter
have little effect on the distribution. Figure 7 shows this
phenomenon. Here, three Weibull densities are drawn.
Each density has the same mean and standard deviation.
The shapes are varied from 7 to 7,000. Even though the
parameters vary by several orders of magnitude, the
three densities are very similar. The fact that large differences in parameters do not produce large differences
in the densities means that parameter estimation is highly
unstable. Fortunately, this parameter instability is present
only for Weibull distributions with high shape values,
such as those over 4. Typical RT distributions are characterized by Weibulls with shapes between 1.5 and 2.5.
The tradeoff demonstrated in Figure 7 raises problems
when Weibull parameters are estimated from small samples. Due to random variability, the sample distribution
for small samples may appear to be roughly symmetric
or even skewed left. In this case, the Weibull estimates
may change by several orders of magnitude. Indeed, this
happened in our simulations, and the resulting extreme
values dominated the RMSE measure.13 The influence
of the parent distribution in the hierarchical model is
greatest in the relatively rare cases in which the samples
are symmetric or skewed left. In these cases, extreme parameter estimates are inconsistent with the parent distribution and are not obtained.
Extreme estimates in nonhierarchical approaches (ML,
QML, and QLS) are not outliers in the conventional sense.
Often, researchers exclude extreme or outlying points from
RT analyses. The rationale is that these points may reflect extraneous psychological processes not under consideration. These extreme estimates in the nonhierarchical methods are part of the sampling distribution of the
estimators and do not arise from some extraneous process. Hence, there is no logical argument for excluding
them. Even if one chooses to exclude extreme estimates,
the sampling distribution has smooth tails, indicating
that there is no natural method with which to classify
whether an estimate is extreme.
The ill-behavior of nonhierarchical estimates comes
from the previously discussed pathology of the Weibull.
This type of pathology is not evident in the ex-Gaussian
and is evident to a far less extent in the shifted Wald
 . Without HB estimation,
the Weibull is a poor choice as a descriptive model with
small sample sizes, because of these statistical considerations. The HB approach can, in theory, be adopted with
other descriptive distributions. Gains in estimation would
be expected in these cases too, although these gains would
not be as dramatic as with the Weibull.
Researchers may question whether conventional methods can be used with small sample sizes if outlying observations are truncated or censored. Unfortunately, these
poor estimates do not result because of extreme observations. In fact, in all cases, no simulated RT was below
the smallest true shift parameter of 180 msec. The poor
estimates occur when the overall shape of the distribution
is skewed left—that is, when typically long observations
do not occur in sufficient numbers. Truncation of extreme observations will not lead to good estimation for
conventional methods in these cases.
Overall, the results are clear and consistent. The HB
method is superior especially for those researchers who
gather a few observations per condition from several par-
Estimation Errors: 80 Observations per Participant
Error in Shift
Error in Scale
Error in Shape
HB Gain RMSE HB Gain
Individual-Level Methods
Group-Level Methods
Note—RMSE, root mean square error; HB, hierarchical Bayesian; ML,
maximum likelihood; QML, quantile ML; QLS, quantile least squares;
PA, parameter averaging; V, Vincentizing.
Estimation Errors: 20 Observations per Participant
Error in Shift
Error in Scale
Error in Shape
Individual-Level Methods
Group-Level Methods
Note—RMSE, root mean square error; HB, hierarchical Bayesian; ML,
maximum likelihood; QML, quantile ML; QLS, quantile least squares;
PA, parameter averaging; V, Vincentizing.
ROUDER, LU, SPECKMAN, SUN, AND JIANG
ticipants. We have run these simulations with other true
values and for different sample sizes . The HB method always provides more
accurate estimates (has smaller RMSEs) for individual parameters than does any other method.
Interpretation of Weibull Parameters
One of the reasons we find the hierarchical Weibull
model useful is that its parameters are interpretable, often
in terms of psychological processes. In this section, we
will describe three different approaches to interpreting
Weibull parameters.
The Weibull as a Descriptive Model
At the least-committed level, the Weibull can be regarded as a convenient descriptive form. The goal then
is to provide robust measures of shift, scale, and shape in
different experimental conditions with few observations
per participant. Shift, scale, and shape are fairly meaningful characteristics of distributions. Accurately measuring the effects of manipulations and group membership on these characteristics can provide motivation for
new theories and test beds for existing ones. In this sense,
the Weibull model is used analogously to the ANOVA,
except that the distributional assumptions are far more
realistic and the dependent variables are shift, scale, and
shape, rather than the mean.
The Weibull can be used in a descriptive fashion as an
intermediary in the fitting of more complicated, theoretically invested models. For example, consider the following possible strategy for fitting Ratcliff’s diffusion model
 . The diffusion
model is usually fit when there are hundreds of observations per participant per condition, since there is a loss of
parameter stability with smaller numbers of observations
per participant. The hierarchical Weibull model advocated
here can be used to potentially increase stability in smallsample applications. In the first stage, the Weibull parameters are obtained by the method presented here. The advantage is that the hierarchical formulation provides a
sophisticated means of pooling data across several participants. Then the diffusion model is fit to these Weibull
parameters, instead of directly to the data. This process of
using one distribution as an intermediary in fitting the diffusion model is not novel. Ratcliff used the ex-
Gaussian in this capacity. This approach will not yield
consistent estimates, since the Weibull only approximates
the diffusion model densities and should be used with
care, rather than programmatically.
The Weibull as a Stage Model
We offer a stage-based, process-oriented interpretation of the Weibull. As Balota and Spieler have
noted, experimental psychologists make a broad, longstanding distinction between two types of processes:
central and peripheral14 . Peripheral processes are quick sensory and motor processes
that occur automatically, whereas central processes are
processes that require conscious control and attention
 . For example, eye movements to a location of a bright flash rely mainly on peripheral processes, whereas maintenance of a 10-digit
phone number in memory relies mainly on central processes. It is common to assume that the latency of peripheral processes is small and of low variance, whereas
the latency of central processes is large, variable, and
skewed right .
Figure 7. The Weibull distribution is “ill behaved” when skewed left. Distributions with vastly
different parameters mimic each other. This behavior raises problems for all of the individualbased methods except the hierarchical Bayesian.
ESTIMATING RT DISTRIBUTIONS
This distinction between central and peripheral processing can be implemented within the Weibull distribution. The Weibull scale and shape parameters index the
central processes, whereas the shift parameter indexes peripheral processes. Differences in the structure of central
processes across groups or conditions would be manifested as a difference in the shape parameter. Difference
in the structure of central processes would include the insertion of stages or changes in processing strategy
 . However if the central
processes follow the same structure across different groups
or conditions but the speed of execution is different, there
would be differences in the scale parameter, but not in the
shape parameter. Finally, differences in the speed of peripheral processes are manifested largely in changes in the
shift parameter . A shift parameter is included in several decision-making RT models and is a measure of the irreducible minimum —that is, the minimum possible latency for encoding
and responding to a stimulus.
The stage model interpretation offered above is plausible but untested. Perhaps the best way to assess this interpretation is to test whether benchmark manipulations
selectively influence model parameters . The model passes the selective influence test if
benchmark manipulations affect only the intended parameter. We hope that the community of researchers will
identify selective influence tests of distributional quantities in various domains.
One easy-to-identify selective influence test of the stage
model parameter interpretation is that peripheral processes
(shift parameter) should not be much affected by decisioncritical stimulus variables. These variables presumably
affect only central components. This selective influence
test can be performed with Ratcliff and Rouder’s 
Experiment 1. In that experiment, 3 participants observed
squares that varied in brightness and indicated whether the
brightness was greater than or less than a gray background.
Accuracy in this task ranged from ceiling for dark and
light stimuli to chance for stimuli that were similar in
brightness to the background. According to the stage
model interpretation, the peripheral processes (shift parameter) should not vary with brightness. We analyzed the
correct response distributions as a function of luminance.15
Weibull parameters were estimated separately for each
participant and luminance level by maximizing likelihood.16 Then these estimates were averaged across participants. In this experiment, there was a fair amount of
symmetry, in that correct RTs to the darkest stimuli were
similar to those to the lightest ones. Likewise, correct
RTs (and probabilities) to stimuli slightly brighter than
the background were similar to those to stimuli slightly
darker than the background. Because this symmetry was
evident across several levels of luminance, Ratcliff and
Rouder collapsed the data. For ease of presentation, we averaged estimates in the same manner. Estimates for shift and scale are displayed in the left panel of
Figure 8 as a function of the distance in luminance between the stimulus and the background. Shift estimates
appear invariant across these different conditions, especially when compared with scale estimates.
It may prove more difficult to specify a selectiveinfluence test to differentiate scale and shape. Scale indexes the speed of processing, whereas shape indexes the
architecture. It may be more contentious to specify a particular manipulation as one that affects speed or architecture exclusively. On a practical level, the example
Figure 8. Shift, scale, and shape parameter estimates as a function of the magnitude
of the difference between the background and the target stimulus. Data are from Ratcliff and Rouder .
ROUDER, LU, SPECKMAN, SUN, AND JIANG
from Ratcliff and Rouder’s experiment is informative. If one believes a priori that stimulus luminance
does not change processing architecture, invariance of
shape will be expected. This does not occur in Figure 8
(right panel). If one maintains the stage-based interpretation, it must be that luminance affects architecture. Of
course, this is not unreasonable; it is plausible that participants may engage additional processing steps for obviously difficult stimuli, especially when instructed to be
accurate. If a recheck mechanism is added for difficult
decisions, it may have a very long latency, and the increase
in skew comes about from a mixture of slow trials in
which the mixture is performed with quicker, unchecked
trials. From the figure, it is unclear whether this decrease
in shape is sudden or is more gradual. The challenge before theorists is to explain why the shape of the distribution becomes more skewed with increasing difficulty.
One model that appears to be in conflict with the stagebased interpretation of the Weibull parameters is the diffusion model. The diffusion model does not give rise to
location–scale–shape RT distribution. In particular, the
drift rate affects both scale and shape. In the luminance
identification paradigm discussed previously, the greater
the difference between the stimulus and the background,
the more extreme the drift rate. As the drift rate increases
in absolute value, the variance of the RT distributions decreases, and the shape changes. The direction of the
shape change, whether more skewed or symmetric, depends on the particular parameters of the process. This
shape change poses a challenge to the stage interpretation presented here. Clearly, a change in drift rate is not
a change in architecture, yet a change in drift rate does
result in a change in shape.
This argument, although true, poses more of a theoretical than a practical challenge. The change in shape
predicted by the drift rate changes is quite small, often
within the realm of sampling noise. Figure 9 provides an
informative example. Data were simulated17 from a diffusion model with the parameter values reported in Ratcliff and Rouder’s Table 1 (accuracy–stressed
condition). The five panels show how various properties
change as a function of drift rate. The empirical statistics, accuracy and mean correct RT, vary through the full
range of performance for this task. The effect on the
Weibull parameters is predominantly on scale; importantly, there is only a small effect on shape. In sum, although the diffusion model does predict some shape
changes within a single architecture, the degree of these
changes is small.
The stage-based interpretation still needs to be benchmarked, rather than assumed. It is likely that there are
some domains in which the stage-based interpretation
will be quite reasonable and others in which it will not.
It is hoped that, over time, researchers in various domains will perform selective influence tests similar to
those discussed here. If there is sufficient consensus that
parameters behave reasonably within a domain, the stage
interpretation can be especially useful in investigating
which manipulations affect the architecture of processing versus its rate.
The stage-based interpretation has important consequences for data analysis. Shape serves as the primary
characteristic of interest, rather than mean or variance.
Shape indexes cognitive architecture, and it should be
analyzed first because it is difficult to interpret changes
in processing speed (scale) across conditions if there are
accompanying changes in the processing of architecture
(shape). Measures of speed are particular to given architectures and are not comparable across architectures. For
example, the value of the speed of scanning in a serial
process is not comparable to the value of the speed of information gain in parallel counters. If there is a significant and consistent change in shape, the main theoretical
Figure 9. Effect of drift rate on performance. The top two panels show how drift rate affects accuracy and mean response time
(RT) for correct responses, respectively. The bottom three panels
show how drift rate affects Weibull parameters of shift, scale, and
shape, respectively. The effects were obtained by simulating the
diffusion model with parameters from Ratcliff and Rouder . The solid, dashed, and dotted lines are for simulations
in which estimates from Participants N.H., J.F., and K.R. served
as true values, respectively.
ESTIMATING RT DISTRIBUTIONS
enterprise should focus on how to explain this shape
change. Only if the shapes are relatively constant can
questions about scale (processing speed) be asked and
The Weibull as a Race Model
It is possible to commit to the Weibull distribution as
a theoretically oriented model of RT. One interpretation
is provided by Logan , who capitalizes on a
limit property of the Weibull. The Weibull distribution
describes the distribution of the winning times of a race
process. Logan accounts for the process of automatizing
a response, a skill, or a task by assuming that identically
distributed memory traces race each other to be recalled.
The RT is the time of the fastest trace to be recalled. Under
reasonable conditions, RT is distributed approximately
as a Weibull.18 Hence, the Weibull is a principled choice
when researchers are willing to believe that RT is the result of a race among latent processes.
Fit of the Hierarchical Weibull Model
In this section, we will assess the fit of the hierarchical Weibull model to Stadler’s data. In many endeavors,
researchers search for models that explain the largest degree of variability in their dependent measures. We make
no claims that the hierarchical model is the best model in
this regard. It may be that for several data sets, other
models, such as the ex-Gaussian or the diffusion model,
may do a better job of describing the precise details of
data. We treat our model as a statistical model, rather
than as a substantive one; its benefit lies in the ability to
do estimation and inference in typical applications. Given
the intended statistical use of the model, we show that
the hierarchical Weibull model fits reasonably well. In
the first subsection, we will assess how well the Weibull
accounts for individual RT distributions; in the second,
we will assess how well the gamma distribution accounts
for variation across individuals.
Fit of the Weibull Distribution
A conventional approach to assessing the fit is to compute chi-square goodness-of-fit statistics. We do so here
with the caveat that because the Weibull is irregular, the
chi-square statistic may not converge to the chi-square
distribution. The distribution of the statistics will be, in
fact, larger than that of the corresponding theoretical distribution, although the correction is not easily obtained.
To compute a chi-square statistic, we first divided the
range of variability of each participant’s distribution into
eight bins. The inner six bins had the same range; the two
outer bins were twice the range of the inner bins. This
small deviation from uniformly sized bins helps avoid
small bin counts that tend to occur in the outer bins. We
used the simplex routine to minimize the chi-square fit
statistic for each participant separately. This resulted in
80 chi-square statistics. If the model fit well, each chisquare statistic should be an independent sample from a
chi-square distribution with four degrees of freedom.19
To assess fit, we compared the empirical cumulative distribution function of the obtained chi-square statistics
with the theoretical cumulative distribution function
(Figure 10, left panel). The empirical cumulative distribution function of the chi-square statistics is the line
with discontinuities. Chi-square value is plotted on the
x-axis; the proportion of obtained values below a specific value is plotted on the y-axis. The center dotted line
is the theoretical cumulative distribution function for the
chi-square distribution with four degrees of freedom.
The surrounding two dashed lines denote pointwise 95%
estimation error bounds.20 Theoretically, for each value
on the x-axis, there is a 95% probability that the empirical cumulative distribution function would fall within the
upper and lower bounds if the obtained chi-square statistics do follow the appropriate chi-square distribution and,
by extension, if the Weibull assumption is correct. As can
be seen, the obtained empirical distribution function falls
within acceptable ranges, indicating a good fit of the
Figure 10. Chi-square fit statistics. The solid line with discontinuities denotes the
empirical cumulative distribution function of individuals’ chi-square fit statistics. The
dotted line is the theoretical cumulative distribution function (CDF) that the chisquare fit statistics should follow if response time is distributed as a Weibull. The
dashed lines are the 95% estimation error bounds on the CDF.
Chi-Square Value
Chi-Square Value
Cumulative Probability
Cumulative Probability
Ex–Gaussian
ROUDER, LU, SPECKMAN, SUN, AND JIANG
Weibull to empirical RT distributions. The right panel of
the figure shows the same plot of chi-square statistics for
the fit of the ex-Gaussian distribution. The fits are comparable.
We also used quantile–quantile (QQ) plots to graphically explore the fits of distributions. Our plots make use
of the fact that Weibull random variables can be transformed to exponential ones. If Y is a Weibull random
variable, X  [(Y  ψ)/θ]β is a standard exponential
random variable with density f (x)  exp(x), where ψ,
θ, and β are the shift, scale, and shape of Y. We performed this transformation for each individual’s data,
using each individual’s HB parameter estimates. Quantiles from the transformed data are plotted against those
for a standard exponential (Figure 11, left panel). If the
data were distributed as a Weibull, the relationship in the
QQ plot should be a straight line with a slope of 1 (white
line). There are some evident variations from the expected line. The curves are below the line for values between 2 and 3 and above it for values between 3 and 4.
This discrepancy indicates that the data have more mass
in the tail than does the Weibull distribution. The right
Figure 11. Quantile–quantile (QQ) plots for transformed data (left) and simulated data (right). The diagonal, which would describe a perfect relationship, is indicated with a white line. The figure shows that
although the QQ plots for data look similar to those for simulated data of the same sample size, there is a
misfit in the tail. The data have slightly heavier tails than those predicted by the Weibull. Data are transformed by hierarchical Bayesian estimates.
Figure 12. The left panel shows the histogram of maximum likelihood (ML) shape parameter estimates. The solid line shows the best-fitting gamma density. The dotted line is the
parent distribution from the hierarchical Bayesian analysis, which is, as was expected, narrower than the ML estimates. The right panel shows the same for the function of scale and
shape that was treated hierarchically [g(, )  ; see Appendix A]. In both cases, the assumption of a gamma-distributed parent seems quite reasonable.
ESTIMATING RT DISTRIBUTIONS
panel shows a random sample from the exponential distribution (80 observations for 80 participants). The comparison of the panels confirms that there is a slight misfit with the Weibull: It tends to underestimate the tail in
some of the participants.
The result of the preceding analyses is that the Weibull
distribution fits reasonably well, although not perfectly.
In particular, the Weibull’s tail is not as heavy as that observed in the data. The reason for this misfit is unclear,
but it may very well be that there are a few outliers in the
data that come about from atypical processing. For example, if a few participants lost attention on a few trials,
the resulting large RTs would cause the observed misfit
in the QQ plot. As was mentioned earlier, our goal is to
provide a reasonably well fitting statistical model for
pragmatic measurement. The fit of the Weibull is more
than adequate for this purpose.
Fit of the Parent Distribution
Our hierarchical Weibull model assumes that there is
a parent distribution from which individual parameters
are drawn and that this distribution has a gamma form.
It is reasonable to ask whether such a choice is judicious,
especially since it was made without recourse to psychological considerations. The gamma, for example, is
unimodal. In certain cases, it may be that participants’
parameters are not distributed unimodally. It may be that
participants cluster into modes—for example, those that
have a symmetric shape and those that have a skewed
shape, without many in between. To test this possibility,
we plotted the obtained individual ML parameters. Figure 12 shows that ML estimates were unimodal and well
fit by a gamma distribution (solid line). The actual gamma
distribution that was estimated as the parent in the hierarchical analysis is shown as a dotted line. The estimated
parent distribution is narrower because the extreme ML
estimates typically reflect a large degree of sampling
noise. It is the narrowness of the parent distribution
(which is not assumed but estimated) that gives rise to
shrinkage in the HB estimation.
Researchers heavily concerned about bimodality can
take solace in three facts. First, the effects of misspecification of the prior will be overcome by collecting larger
amounts of data. As the amount of data increases, the impact of the prior becomes smaller and smaller. In the asymptotic limit, the prior plays no role. Second, as we will
discuss in the next section, the effects of misspecification of the parent distribution are rather marginal. Third,
it may be possible to specify reasonable priors that allow
for two or more modes.
Robustness to Misspecification
As was mentioned previously, we treat the hierarchical Weibull model as a statistical model, rather than as a
more substantive one. One consequence of this treatment
is that the inference should be relatively robust to misspecification of the model. In this section, we will explore the consequences when the underlying data are not
distributed as a Weibull. We show through simulation
that reasonable inferences about location, scale, and
shape are possible even when the data are distributed as
an ex-Gaussian.
The ex-Gaussian is usually parameterized as the addition of a normal random variable with an exponential
random variable. The distribution has three parameters—
μ, σ, and τ—corresponding to the location and scale of
the normal and the scale of the exponential. There is a
little-known alternative parameterization in the location–
scale form, as is discussed in note 2. The alternative is
based on parameter η, where η  τ /σ. In this parameterization, μ serves as the location parameter, σ serves as
the scale parameter, and η serves as the shape parameter.21 Figure 13 shows the dependence of the distribution on the parameters. In this parameterization, σ scales
both the normal and the exponential components proportionately. Changes in σ alone do not affect higher
order shape-related properties, such as skew and kurtosis. Only the value of η determines these higher order
properties.
The question at hand is whether we can reliably recover changes in ex-Gaussian location, scale, and shape
parameters with the hierarchical Weibull model. To answer this question, we performed a small simulation experiment in which artificial data were distributed as an
ex-Gaussian. In the simulation, we constructed two groups
of 50 hypothetical participants contributing 50 hypothetical observations each. Each hypothetical participant
had his or her own parameters (μ, σ, η), and these parameters were sampled from parent distributions. There
were two sets of parent distributions, one for each group.
Figure 13. The ex-Gaussian parameters of location, scale, and shape. Each plot shows the
effect of changing one parameter while holding the other two constant.
ROUDER, LU, SPECKMAN, SUN, AND JIANG
In Simulation 1, there was only a group difference22 in
the ex-Gaussian location parameter. Hence, hierarchical
Weibull analysis should reveal a shift difference but no
scale or shape difference across groups. Figure 14 shows
HB estimates as box plots, and the upper row shows the
results from Simulation 1. Only estimates of shift were
affected by group membership.
There are some minor differences in scale and shape
across the two groups in Simulation 1. Some random
variation is indeed expected, for two reasons. First, although the true population parameters are invariant across
conditions, individuals’ shapes and scales were randomly
sampled. Given that the simulations consist of only 50
individuals, we expect some variation in the distribution
of individual true parameters. Second, in the simulations, there were only 50 observations per individual;
hence, individuals’ samples do not perfectly reflect their
true parameter values.
In Simulation 2, there were only group differences in
ex-Gaussian scale parameters. Consequently, hierarchical Weibull analysis should reveal a scale difference and
no shape or location difference across groups. The middle row shows HB estimates: There is a large scale difference and no shape difference across groups. There is
a small shift difference, and the reason for this deviation
will be discussed below. In Simulation 3, there were only
group differences in ex-Gaussian shape parameters. As
has been discussed previously, hierarchical Weibull analysis should reveal a difference in shape and no difference
in location. There is no interpretation of scale parameters
in this case, since scale (in)variance is fairly meaningless
when shape changes. Differences in scale are interpretable
only when shape is constant. The bottom panel shows a
large effect of group membership on shape estimates,
but not on location estimates.
Overall, the hierarchical Weibull provides a robust
platform for exploring the effects of manipulations and
group membership. The only problem is in measuring
shift: Location parameters may not show appropriate invariances when the distribution is misspecified. The
Weibull has a true lower bound parameter, below which
there is no mass. If the underlying distribution has no
such lower bound, the Weibull shift may also change
when scale changes. Although the ex-Gaussian lacks a
lower bound, real human data certainly have a lower
bound (no participant, for example, responds before the
experiment begins). We, along with others, argue that the
inclusion of a lower bound is sensible. The lower bound
is interpretable as a minimum residual, the speed of the
fastest possible response .
There is a misspecification that is worthy of careful
attention: the possibility of fast guesses . Even occasional fast guesses, should they
occur, will necessarily have heavy influence on param-
Figure 14. Hierarchical Bayesian estimates of shift, scale, and shape from data generated from an ex-Gaussian.
ESTIMATING RT DISTRIBUTIONS
eter estimation. The reason is that the shift parameter estimate is always below the smallest observed value. If
this value is not from the processes under consideration,
it is possible to estimate shifts that are too small, scales
that are too large, and shapes that are too symmetric.
Currently, researchers can take one of two mitigating
steps. The first is to use instructions that minimize fast
guesses. Green, Smith, and von Gierke , for example, were able to eliminate fast guesses by stressing to
their participants the need to wait for stimuli. The second
is to trim responses in analysis that could not conceivably be stimulus related. We took this tactic and trimmed
responses below 200 msec. The good fit of the Weibull
(Figure 11), especially for the fast quantiles, indicates that
our trimming was indeed successful in this application.
The most elegant solution is to expand the model so that it
is a mixture of the guessing state and the Weibull. In this
model, the distribution of the guessing state would be specified beforehand—for example, a uniform distribution
from 0 to 5 sec. The probability of responses coming from
the Weibull or the guessing state would be an additional
free parameter. This type of mixture would allow for more
robust estimation of Weibull parameters. We are currently
developing this type of mixture model for the hierarchical
Weibull. It is worth noting that all models that posit a lower
bound, such as sequential sampling models, are affected
by the presence of fast guesses.
It is worth considering the violation of the model’s assumptions about the parent distributions. It turns out that
proper specification of these is not critical. The real gain
in estimation comes not from proper specification of the
majority of the parent distribution’s mass, but from the
orderly decrease in its tails. The parent distribution has
its largest influence when an individual’s data lead to extreme estimates. In this case, the individual estimate is
typically in the tails of the parent distribution. Consider
the previous example in Figure 3, in which the extreme
estimates were in the tails of the parent distribution.
Consequently, they were adjusted to regions of the parent distribution with more mass. In essence, it is the fact
that the parent distribution’s tails fall off in a reasonable
manner that provides much of the gain. Misspecifying
the more central regions will certainly add some bias to
estimates. This bias, however, is minimal, considering the
gain in accuracy from the shrinkage of extreme estimates.
AN APPLICATION TO A SYMBOLIC
DISTANCE EFFECT
In this section, we apply the model to a well-known
symbolic distance effect. In the experimental task, participants decide whether a presented digit is greater than or
less than 5. In this task, it typically takes longer to make
decisions about digits close to 5, such as 6 and 4, than to
digits far from 5, such as 2 and 8 .
The interpretation typically offered is that when performing this task, participants represent numbers in an analogue fashion . The analogue
code of 5 is more similar to 4 than to 2. When the codes
are similar, it takes longer to obtain an accurate comparison. This finding is one of several semantic and symbolic
distance effects that have been used to examine whether
there are analogue mental representations . The question we ask is whether the
distance-from-5 symbolic distance affects shift, scale,
shape, or some combination of these distributional properties. Fifty-four participants each contributed about 40
observations in each of the six conditions.
Participants. Fifty-four University of Missouri undergraduate
students served as participants in partial fulfillment of a require-
Figure 15. Mean response time (RT) for the six different digits. Error bars denote
95% “within-subject” confidence intervals .
Mean RT for Correct Responses (msec)
ROUDER, LU, SPECKMAN, SUN, AND JIANG
ment in an introductory psychology course. Two were eliminated
for excessive anticipatory responses.
Design. The to-be-classified digit served as the main independent variable. The digit was 2, 3, 4, 6, 7, or 8. The levels were manipulated in a within-subjects design. All of the digits appeared
equally often and in a random order.
Procedure. A trial began with a black screen. After 1,000 msec,
a digit was presented in the center of the screen in a standard DOS
font. The digit remained on the screen until the end of the trial. The
participants were instructed to depress the “z” key if the digit was
less than 5 and the “/” key if the digit was greater than 5. Following the response, feedback was provided: A pleasant, rising two-tone
sequence indicated a correct response, whereas a low-frequency buzz
indicated a wrong response. Feedback lasted for 400 msec, after
which the next trial followed. Sixty trials made up a block. The participants were instructed to take breaks between blocks. The session
consisted of six blocks and took approximately 20 min to complete.
Empirical Analysis
Visual inspection of mean RT as a function of trial
number revealed that all noticeable practice effects occurred within the first 25 trials. Hence, these trials were
discarded. Additional trials were discarded if (1) the trial
followed a break, (2) the response was incorrect, or (3) the
response time was less than 200 msec or greater than
2,000 msec. Fewer than 1.8% of the responses were errors, and fewer than 0.7% were outside the window from
200 to 2,000 msec. The mean RT for the six digits is
shown in Figure 15. As can be seen, there is a significant
50-msec symbolic distance effect [F(5,255)  42.2, p 
.05]. The latency of the decision varies inversely with the
distance from five.
Hierarchical Model Analysis
We used the hierarchical Weibull model to estimate
each individual’s shift, scale, and shape parameters in all
six digit conditions. We started with a general model in
which there are separate shift, scale, and shape parameters
for every participant–digit combination. This model
yielded a total of 3  52 participants  6 digit condition 
936 primary parameters. Details of this model are presented in Appendix B. Figure 16 shows the resulting estimates as box plots. The top row contains separate panels for shift, scale, and shape estimates. Within each of
these panels, there are box plots of the distribution of the
52 individuals’ parameters tabulated by digit condition.
Figure 16. Parameter estimates. The top panel shows box plots of the distribution of parameters across participants.
The points and lines denote means. There is no effect of digit for shift, a moderate effect for scale, and an unsubstantial
effect for shape. The bottom row shows the effect of scale and shape on response time (RT) distributions. The difference
is much larger for scale than for shape.
2 3 4 6 7 8
2 3 4 6 7 8
2 3 4 6 7 8
Scale Effects on RT
Shape Effects on RT
Individuals’ Parameter Estimates
ESTIMATING RT DISTRIBUTIONS
The distribution of the shift parameters (top left) shows
that shift hardly varies with digit. This indicates that peripheral processes are unaffected by digit condition. For
the scale parameter (top-middle panel), there is a clear
dependence on digit with larger scales for digits closer to
5. The effect of digit on shape is less clear. The change
in mean shape across digits is sizable in terms of participant variability but fairly small in substantial significance (from 1.65 to 1.52). The bottom row of panels
makes this point clear. The first panel shows the difference between two Weibull distributions that vary in scale
(shift fixed at 0.4 sec, shape fixed at 1.6). The two scale
values (0.218 and 0.272 sec) were chosen because they
were the most extreme mean scales (from digit conditions 2 and 4, respectively). As can be seen, there is a
moderate difference between these distributions. The
middle panel is the comparable plot for shape. The scales
and shifts are fixed (shift of 0.4 sec, scale of 0.24 sec).
The shape values (1.52, 1.65) were chosen because they
are the most extreme mean shapes (from digit conditions
Figure 17. Group-level response time (RT) distribution for the digit conditions. The effect of digit is on the scale of the distribution.
Figure 18. Scatterplots for the shift parameter. Each point corresponds to a particular participant. There is a
high degree of correlation, indicating that the participants who had a high shift in one condition tended to have
a high shift in another.
Digit 3 vs. Digit 2
Digit 4 vs. Digit 3
Digit 4 vs. Digit 2
Digit 7 vs. Digit 8
Digit 6 vs. Digit 7
Digit 6 vs. Digit 8
Shift Parameter (sec)
Shift Parameter (sec)
ROUDER, LU, SPECKMAN, SUN, AND JIANG
7 and 2, respectively). As can be seen, there is very little
effect of the variability in shape across digit condition
It is possible to generate group-level RT distributions
from model-based parameter estimates. The method is
straightforward. We evaluate the Weibull density function using parameters averaged across participants (indicated by the lines in the top row of panels in Figure 16).
The resulting group-level RT distributions are shown in
Figure 17.
A more refined analysis of participant and condition
effects is shown in Figures 18–20. Each figure is composed of a series of scatterplots. Figure 18 is for the shift
parameter, and each scatterplot shows a participant’s
shift in one condition as a function of his or her shift in
another condition. Each point corresponds to a particular participant. As can be seen, there is a high degree of
correlation, indicating that the participants who had a
high shift in one condition tended to have a high shift in
another. The fact that points cluster near the diagonal indicates that there is little systematic effect of condition.
One way of characterizing the shift estimates is that there
are large participant-specific main effects, as well as
more modest participant  condition interactions. There
is no digit condition main effect.
Figure 19 shows scatterplots for the scale parameter.
Once again, there is a fair amount of correlation, indicating the presence of participant-specific main effects.
In addition, main effects of condition are evident in this
plot. The y-axis of the plots always represents a digit
closer to 5, whereas the x-axis always represents a digit
further from 5. The fact that most points cluster above
the diagonal indicates greater scale values for digits
closer to 5. Figure 20 shows scatterplots for the shape
parameter. Here, there is little systematic variation. The
interpretation is that there are only participant  condition interactions but no discernible main effects. This
plot confirms the conclusion that the systematic effects
of digit condition are not in the shape parameter. It suggests that all the participant  item combinations may
have similar if not identical shape-parameter values.
An Additive Hierarchical Model
In the original model, there is a separate parameter estimate for each participant  condition combination.
The graphical analyses indicate that a more parsimonious model may be obtained by modeling a main effect
of symbolic distance on scale. In this section, we will implement such a model. The goal is to provide an additive
model that provides a means of estimating the main effects of symbolic distance, as well as testing whether this
main effect is statistically significant.
We provide an additive model with main effects of
participants and conditions. Ideally, this additive model
would be placed on the scale parameter, but the analysis
of this model appears intractable.23 To meet the goal, we
adopt an alternative parameterization of the Weibull.
Previously, the Weibull was parameterized with shift,
scale, and shape. But, in our additive model, we parameterized the Weibull in terms of shift, rate, and shape.
The details of the change of parameterization are given
in Appendix C. In cases in which there is no systematic
Figure 19. Scatterplots for the scale parameter. Each point corresponds to a particular participant.
Scale Parameter (sec)
Digit 3 vs. Digit 2
Digit 4 vs. Digit 3
Digit 4 vs. Digit 2
Digit 7 vs. Digit 8
Digit 6 vs. Digit 7
Digit 6 vs. Digit 8
Scale Parameter (sec)
ESTIMATING RT DISTRIBUTIONS
change in shape across conditions, rate is inversely related to scale. The additive model is placed on rate, rather
than on scale, and is given by:
Log(Rate)  Grand Effect  Participant Effect
 Condition Effect  Noise.
The key concept is that there is a main effect of digit condition on the logarithm of rate. This main effect, which is
separate from and added to the participant-specific effect,
serves as our parameter of interest. The complete model is
provided in Appendix C. This model is one of a family of
additive models we have presented for psychological data
 , and further statistical details have been presented there. Peruggia,
Van Zandt, and Chen presented a similar approach
with the two-parameter Weibull (shift set to zero), in which
they also placed a linear model on logarithm of the rate.
Before discussing the analysis, we will justify the
choice of placing an additive model on the logarithm of
the rate parameter, rather than on the rate parameter itself. Once again, the reason for doing so is computational tractability. It may prove quite difficult to estimate
other additive models. Fortunately, an additive model on
the logarithm of rate is indicated by the previous model
analysis. Figure 21 shows the values of the logarithm of
rate for the different conditions. The plots in the figure
are analogous to those previously displayed for shift,
scale, and shape parameters. An additive model is indicated because the points tend to fall on a line parallel to
the diagonal. The distance of this line from the diagonal
indicates the size of the condition effect.
Figure 22 shows the resulting parameter estimates for
the main effect of digit. The points are the estimates
(mean of the posterior distributions), and the error bars
are 95% credible intervals. Credible intervals in Bayesian
statistics are analogous to confidence intervals in classical statistics. As can be seen, rate is affected by numerical distance; it is largest (quickest RTs) for the digits far
from 5 and smallest (slowest RTs) for digits near 5.
To test the statistical significance of the distance main
effect, we will employ the Bayes factor method used by
Lu . The Bayes factor approach
has been discussed extensively in the statistical literature
 and has
been imported to the psychological literature . The Bayes factor is the odds that one model
is true relative to another, given the data (and the priors).
In our case, the first hypothesis is that there are nonzero
main effects, and the second one is that all main effects
are zero. The odds for the first hypothesis relative to the
second are 4.1  1014; hence, we can safely conclude that
the main effects are significant. Details of Bayes factor
computation can be found in Lu et al.; the additive model
discussed here corresponds to their unstructured model.
Discussion
The analyses above provide a locus for the symbolic
distance effect: It is largely in scale (rate) and not in
shape. The results are not consistent with a theory that
postulates that the effect is due to a processing change,
such as the insertion of recheck stages for numbers close
to 5. Some caution is necessary for an outright rejection
Figure 20. Scatterplots for the shape parameter. Each point corresponds to a particular participant.
Shape Parameter (sec)
Digit 3 vs. Digit 2
Shape Parameter (sec)
Digit 4 vs. Digit 3
Digit 4 vs. Digit 2
Digit 7 vs. Digit 8
Digit 6 vs. Digit 7
Digit 6 vs. Digit 8
ROUDER, LU, SPECKMAN, SUN, AND JIANG
of theories of architecture change, such as rechecking.
The present analysis reveals that if shapes vary systematically across conditions, they do so slightly. It may be
possible to construct an architecture change theory that
yields a sufficiently small shape effect, so as not to be
contradicted by the present analysis.
Symbolic distance is not typically modeled as an architecture change; instead, it is modeled as a diffusion
process or random walk . Changes in
scale are broadly consistent with either a change in drift
rate or a change in bounds. For a small change in drift
rate, such as the type needed to produce the 50-msec effects observed here, the changes in shape are minimal
(see Figure 9). The results indicate that the effect can be
accounted for parsimoniously with a model that postulates that symbolic distance affects scale (speed) of processing, rather than functional architecture.
GENERAL DISCUSSION
In this article, we have presented a framework for estimating the shift, scale, and shape of RT distributions.
The framework is parametric, hierarchical, and Bayesian.
It is suited for cases in which there are several participants but only a few observations per participant per condition. The main advantage of a hierarchical model is that
it allows for the pooling of information across several
participants. The Weibull hierarchical model has four advantages. (1) It allows for superior parameter estimation.
(2) The Weibull parameters can be interpreted at several
levels, including that of a process-oriented stage model.
At this level, differences in shift index differences in peripheral processes, differences in scale index differences
in central processing speed, and differences in shape
index differences in processing architecture. (3) The hierarchical Weibull model fits the data well. (4) The model
is fairly robust to misspecification. The main reason we
prefer the Bayesian approach is tractability. Although statistical analysis with Bayesian methods is not simple, it is
feasible. We do not know how to analyze the models presented here with classical methods.
Application of the method to a symbolic distance effect revealed a clear locus for the effect in scale. The ensuing interpretation is that increasing numerical distance
increases the rate of processing but does not change the
form or architecture of the underlying process.
The question of addressing shape need not be done in
the context of the Weibull, the ex-Gaussian, or any other
parametric form. It can be done in a nonparametric manner by studying higher order distributional properties,
such as skew or interquartile skew. We recommend parametric, rather than nonparametric, analysis for increased
power. The hierarchical implementation presented here
increases the accuracy of parameter estimates in a principled manner.
The General Benefit of Hierarchical
Models in Cognition
We believe that there are several domains in which hierarchical models can be of service. The strength of this
Figure 21. Scatterplots for logarithm of the rate parameter. Each point corresponds to a particular participant.
Digit 4 vs. Digit 3
Digit 4 vs. Digit 2
Digit 7 vs. Digit 8
Digit 6 vs. Digit 7
Digit 6 vs. Digit 8
Digit 3 vs. Digit 2
ESTIMATING RT DISTRIBUTIONS
approach is that it provides a principled and powerful
method of pooling data across disparate individuals. We
have illustrated how they can be used to assess manipulation effects on RT distribution properties in cases in
which participants are assumed to have their own unique
shift, scale, and shape. Below, we will mention a few
other domains in which future hierarchical approaches
may prove valuable.
Learning is one such domain. There are several theoretical and methodological issues involved in describing
the speeding of tasks from practice. Although the power
law of practice has been widely believed to describe this
effect, it has recently come under considerable scrutiny
 . The power law states that
RT decreases as a power function of the number of practice trials. Other alternatives are that practice follows an
exponential , follows a mixture of power laws , or makes
a sharp transition . A number
of authors have pointed out that averaging RT across individuals will distort the shape of empirical-learning
curves, and these distortions tend to artificially favor a
power law interpretation . Hence, studying
participant-averaged curves provides a misleading picture of how each individual’s RT changes with practice.
We have presented a set of hierarchical models of
learning similar to that for symbolic distance . Each individual’s RT on each trial is described by
a three-parameter Weibull, with parameters drawn from
parent distributions. Practice is postulated to affect the
scale parameter, and the form of this effect, whether as a
power function or as an exponential, is assessed. We are
in the process of analyzing practice effects in an alphabet arithmetic task with these models
 .
Hierarchical models also may be useful in domains in
which there is variability over items, such as in verbal
learning or memory experiments. There has long been a
concern about unaccounted variability from stimulus
items in ANOVAs. Clark argued that unaccounted
variance from items in a memory test could inflate the
true Type I error rate. Fortunately, Wickens and Keppel
 showed that this type of variability represents only
a minor concern in well-counterbalanced experiments.
The situation, however, is not as sanguine with regard to
nonlinear models, such as the process dissociation procedure or other sequential stage type
multinomial models . Curran and Hintzman 
have pointed out that variability across items or individuals can greatly bias estimation and inference . Their critique was aimed at Jacoby’s process dissociation model,
a model that seeks to isolate the effects of conscious recollection from automatic forms of recognition, such as
feelings of familiarity. Curran and Hintzman’s critiques
center on latent covariation in psychological processing.
They speculate that participants who are better at recalling items from conscious recall may be better at recalling
items from familiarity. Likewise, items that are more easily consciously recalled may give rise to greater feelings
of familiarity. They show that these types of covariation
will bias estimates.
Unfortunately, Curran and Hintzman’s critique
is applicable to just about every nonlinear model. For example, Rouder and Batchelder proposed a multinomial model for separating storage and retrieval factors
in memory. The effectiveness of the model, however, is
undermined if items that are more easily stored are also
more easily retrieved. Psychologists, in general, have not
sufficiently addressed the possibility of the deleterious
effects of unaccounted variability and correlation in nonlinear models.
We believe that hierarchical modeling provides an attractive means of accounting for and assessing variability and correlation at several different levels. In particular, correlation among parameters across individuals or
items may be modeled at the level of parent distributions.
For example, in the case of the process dissociation procedure, correlations in recollectability and familiarity
Figure 22. Main effect of digit condition on rate. Error bars denote 95%
credible intervals from the posterior distributions of parameter estimates.
ROUDER, LU, SPECKMAN, SUN, AND JIANG
across items or participants may be modeled by assuming that the participant and the item effects are sampled
from a correlated bivariate distribution. Theoretically,
the degree of correlation would be a free parameter; one
would obtain not only corrected estimates, but an estimate of correlation as well.
Although the hallmark of experimental psychology is
rigorous control, there are always sources of variability
that cannot be reduced. When these sources occur simultaneously at different levels, researchers can gain better
statistical control with hierarchical models. Bayesian
analysis is well suited to hierarchical models and can
often provide a tractable means of inference. In this article, we have postulated a hierarchical model to account
for both within-subjects and between-subjects variability
in RT. We believe that the same modeling approach may
be applicable across a number of domains within cognitive and perceptual psychology.