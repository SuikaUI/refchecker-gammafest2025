FILTERING VIA SIMULATION: AUXILIARY PARTICLE
Michael K Pitt
Department of Mathematics, Imperial College, Queen’s Gate, London, SW7 2BZ, UK
 
Neil Shephard
Nuﬃeld College, University of Oxford, Oxford OX1 1NF, UK
 
www.nuff.ox.ac.uk/users/shephard/
October 22, 1997
This paper analyses the recently suggested particle approach to ﬁltering time series.
We suggest that the algorithm is not robust to outliers for two reasons: the design of the
simulators and the use of the discrete support to represent the sequentially updating prior
distribution. Both problems are tackled in this paper. We believe we have largely solved the
ﬁrst problem and have reduced the order of magnitude of the second.
In addition we introduce the idea of stratiﬁcation into the particle ﬁlter which allows
us to perform on-line Bayesian calculations about the parameters which index the models
and maximum likelihood estimation. The new methods are illustrated by using a stochastic
volatility model and a time series model of angles.
Some key words: Filtering, Markov chain Monte Carlo, Particle ﬁlter, Simulation, SIR, State
INTRODUCTION
In this paper we model a time series yt, t = 1, ..., n, as being conditionally independent given
an unobserved suﬃcient state αt, which is itself assumed to be Markovian. The task will be to
use simulation to carry out on-line ﬁltering — that is to learn about the state given contemporaneously available information. We do this by estimating the diﬃcult to compute density (or
probability distribution function) f(αt|y1, ..., yt) = f(αt|Yt), t = 1, ..., n. In a later section we
will extend this model to the case where lagged observations aﬀect both the measurement and
transition equations and to where yt depends on both αt and αt−1.
We assume parametric forms for both the ‘measurement’ density f(yt|αt) and the ‘transition’
density of the state f(αt+1|αt). The state evolution is initialized by some density f(α0).
Filtering can be thought of as the repeated application of a two stage procedure. First the
current density has to be propagated into the future via the transition density f(αt+1|αt) to
produce the prediction density
f(αt+1|Yt) =
f(αt+1|αt)dF(αt|Yt).
Second, we move to the ﬁltering density via Bayes theorem
f(αt+1|Yt+1) = f(yt+1|αt+1)f(αt+1|Yt)
f(yt+1|Yt)
f(yt+1|Yt) =
f(yt+1|αt+1)dF(αt+1|Yt).
This implies the data can be processed in a single sweep, updating our knowledge about the
states as we receive more information. When the integrals cannot be analytically solved then
numerical methods have to be used. These typically require us to be able to evaluate both
f(yt|αt) and f(αt+1|αt). We will see that the most basic of the methods developed in this paper
will only require that we can simulate from f(αt+1|αt) and evaluate f(yt|αt). If we can evaluate
f(αt+1|αt) then this knowledge can be used to improve the eﬃciency of the procedures.
There have been numerous attempts to provide algorithms which approximate the ﬁltering
densities. Important recent work includes Kitagawa , West , West , Gerlach, Carter, and Kohn and those papers reviewed in Harvey and
West and Harrison .
This paper uses simulation to perform ﬁltering following an extensive recent literature. Our
approach is to develop the particle ﬁlter which has recently been suggested independently by
various authors. In particular it is used by Gordon, Salmond, and Smith on non-Gaussian
state space models. The same algorithm, with extensions to the smoothing problem, has been
independently proposed by Kitagawa for use in time series problems. It reappears and
is then discarded by Berzuini, Best, Gilks, and Larizza in the context of a real time
application of the sequential analysis of medical patients. It is again proposed by Isard and
Blake , in the context of robustly tracking motion in visual clutter, under the name of the
“condensation” algorithm. Similar ideas are used on the blind deconvolution problem by Liu and
Chen . Some statistical reﬁnements of this class of algorithm, generically called particle
ﬁlters, is given in a paper by Carpenter, Cliﬀord, and Fearnhead . The idea of calling this
class of algorithm ‘particle ﬁlters’ is due to Carpenter, Cliﬀord, and Fearnhead , although
the use of the phrase ‘particles’ appears in Kitagawa .
Our paper will discuss the particle ﬁltering literature and extend it in a number of directions
so that it can be used in a much broader context.
The outline of the sections of this paper is as follows. In Section 2 we analyse the statistical
basis of particle ﬁlters and focus on its weaknesses. In Section 3 we introduce our main contribution, which is an auxiliary particle ﬁlter method. This is as simple and as general as the original
particle ﬁlter, but it is much more eﬃcient when we deal with diﬃcult problems. Further, it can
be extended conveniently in cases where the transition and measurement densities of the state
space model are analytically tractable. In Section 4 we generalize the particle ﬁlter approach
to what we call a ﬁxed lag ﬁltering algorithm, where we update the discrete distribution due to
the arrival of blocks of data. In addition we discuss the use of stratiﬁcation in this context. In
Section 5 we apply the particle ﬁlters to estimating unknown parameters using a Bayesian and
maximum likelihood approach. Section 6 applies this work to a stochastic volatility model. Section 7 extend the methods to allow for feedback. Section 8 concludes, pointing out the remaining
weaknesses of our new method.
PARTICLE FILTERS
Discrete support makes ﬁltering easier
Importantly, if the support of αt is ﬁnite set of known discrete points, rather than continuous,
then the problem of approximating the integrals required to evaluate the ﬁltering densities
disappears. In particular the prediction density, (1), becomes
f(αt+1|Yt) =
Pr(αt+1|αt)f(αt|Yt),
which weighs all propagated points by the transition density. Likewise the ﬁltering density, (2),
f(αt+1|Yt+1) =
f(yt+1|αt+1)f(αt+1|Yt)
αt+1 f(yt+1|αt+1)f(αt+1|Yt),
which weighs each state by the likelihood. Hence discrete state space models are easier to handle
than continuous ones.
The deﬁnition of particle ﬁlters
Particle ﬁlters are the class of simulation ﬁlters which recursively approximate the ﬁltering
random variable αt|Yt = (y1, ..., yt)′ by the cloud of points or ‘particles’ α1
t , ..., αM
t , with discrete
probability mass of π1
t , ..., πM
respectively.
Hence a continuous variable is approximated by
a discrete one with a random support. These discrete points are thought of as samples from
f(αt|Yt). In the literature all the πj
t are assumed to all equal 1/M, so the samples can be thought
of as a random sample, but here we will allow more ﬂexibility. Throughout M is taken to be
very large. Then we assume that as M →∞, the particles can be used to increasingly well
approximate the density of αt|Yt.
Particle ﬁlters treat the discrete support generated by the particles as the true ﬁltering
density )). This
allows us to produce an approximation to the prediction density, (1), via the results on discrete
ﬁlters. We call
bf(αt+1|Yt) =
the ‘empirical prediction density’.
This can be combined with the measurement density to
produce, up to proportionality,
bf(αt+1|Yt+1) ∝f(yt+1|αt+1)
the ‘empirical ﬁltering density’ as an approximation to the true ﬁltering density (2). Generically
particle ﬁlters then sample from this density to produce new particles α1
t+1, ..., αM
t+1 with weights
t+1, ..., πM
t+1. This procedure can be repeated allowing us to progress through the data. We will
call a particle ﬁlter ‘exact’ if it produces independent and identically distributed samples from
the empirical ﬁltering density.
If the particle ﬁlter can be made to work it could be used in a number of diﬀerent contexts.
First, it can be used in on-line tracking problems, which are important in many branches of
applied science. Second, it is sometimes useful to be able to estimate the one-step ahead density
f(yt+1|Yt) and so, via the prediction decomposition, the joint density of the observation. This
can be carried out in its simplest form by computing
f(yt+1|αj,k
t+1 ∼αt+1|αj
k = 1, ..., K,
where the αj,1
t+1, ..., αj,K
t+1 are drawn from αt+1|αj
t. If attention focuses on this quantity it may
be worthwhile setting K to be larger than one. In addition the use of importance sampling or
antithetic and control variables could be useful in this context if we have suﬃcient knowledge
of the transition density to be able to employ them.
Third, a particularly useful diagnostic measure of ﬁt for non-Gaussian statistical problems
is to compute
Pr(yt+1 ≤yobst+1|Yt) =
Pr ). This allows the development of a whole
portfolio of exact diagnostic tests via the routine application of Monte Carlo test and Smith , Shephard and Gerlach, Carter, and Kohn
 in the time series context. Shephard , Geweke and Gerlach, Carter, and
Kohn give O(n2) algorithms for estimating this probability using the output from a
Markov chain Monte Carlo (MCMC) algorithm, although the algorithm by Gerlach, Carter,
and Kohn is typically quite fast for many models even when n is moderately large.
Particle ﬁlters are at ﬁrst sight less useful in performing parameter estimation, due to the
availability of MCMC methods for solving the much easier problem (as it involves no iterative
approximations) of simulating from the joint density of the parameters and states given the
whole of the data y1, ..., yn. Examples of this include, Albert and Chib , McCulloch and
Tsay , McCulloch and Tsay , Carter and Kohn , Carter and Kohn ,
Shephard , Fruhwirth-Schnatter , West , Carpenter, Cliﬀord, and Fearnhead
 and Shephard and Pitt . For a review, see West and Harrison .
However, particle ﬁlters do oﬀer the hope of allowing estimation in models where evaluating the
transition density is diﬃcult or impossible, as well as allowing on-line parameter estimation. To
the authors knowledge designing MCMC algorithms for such problems is an open question as
the Metropolis rejection rate generally involves the transition density.
Sampling the empirical prediction density
One way of sampling from the empirical prediction density is to think of PM
j=1 f(αt+1|αj
as a ‘prior’ density bf(αt+1|Yt) which is combined with the likelihood f(yt+1|αt+1) to produce
a posterior. Then we have already assumed that we can simulate from f(αt+1|αj
t), so we can
sample from bf(αt+1|Yt) by choosing αj
t with probability πj
t and then drawing from f(αt+1|αj
If we can also evaluate f(yt+1|αt+1) up to proportionality this leaves us with three sampling
methods to draw from f(αt+1|Yt+1) : sampling/importance resampling, acceptance sampling
and Markov chain Monte Carlo. In the rest of this section we write the prior as f(α) and the
likelihood as f(y|α), abstracting from subscripts and conditioning arguments, in order to brieﬂy
review these methods in this context.
Sampling/importance resampling (SIR)
This method , Rubin and Smith and Gelfand ) can be used
to simulate from a posterior density f(α|y), given an ability to:
1. simulate from the prior f(α);
2. evaluate (up to proportionality) the conditional likelihood f(y|α) which is assumed to vary
smoothly with α.
The idea is to draw proposals α1, ..., αR from f(α) and then associate with each of these
draws the weights πj where
wj = f(y|αj),
j = 1, ..., R.
Then the weighted sample will converge, as R →∞, to a non-random sample from the desired
posterior f(α|y) as PR
p→f(y). Intuitively we would expect that the speed of convergence
will depend upon the variability of these weights, so if the variability of the weights is small
convergence will be quite rapid. The non-random sample can be converted into a random sample
by resampling the α1, ..., αR using weights π1, ..., πR to produce an independent and identically
distributed sample of size M. This requires R →∞and R >> M. A major attraction of the
SIR method is that it can be run eﬃciently on a massively parallel computer with a large amount
of memory as each part of the computations can be carried out separately. A disadvantage of
the method is that it typically requires R to be large and so is quite demanding in terms of
The use of this method has been suggested in the particle ﬁlter framework by Gordon,
Salmond, and Smith , Kitagawa , Berzuini, Best, Gilks, and Larizza and
Isard and Blake .
To understand the eﬃciency of the SIR method it is useful to think of the SIR method as
an approximation to the importance sampler of the moment
Efπ {h(α)} =
h(α)π(α)dF(α),
h(αj)π(αj),
π(α) = f(y|α)
Notice that this setup implies Ef {π(α)} = 1. The approximation comes about due to the SIR’s
πj having a scaling factor which is a sum rather than an integral. Liu has recently studied
the variance of this type of importance sampler and suggested that when h(α) does not vary
very quickly with α then the variance is approximately proportional to
1 + varf {π(α)}
Hence the SIR method will become very imprecise when the πj become very variable. This will
happen if the likelihood is highly peaked compared to the prior.
Example Consider α ∼N (0, 1), y|α ∼N
 α, σ2. Then E
equals (using the moment
generating function of a non-central chi-squared)
2σ2 (y −α)2
(σ2 + 2) (σ2 + 1)
increases exponentially in y2, while it increases without bound as σ2 →0. This conﬁrms the
above impresion of the fragility of the SIR method to outliers and to highly peaked likelihoods.
Of course, for many problems the prior will be much more spread out than the likelihood and
so the second of these problems should not be typically important. However, the sensitivity to
aberrant observations will be important.
Rejection sampling
The SIR method has some similarities with rejection sampling and Smith and Gelfand ), which is based on simulating from f(α) and accepting
with probability π(α) = f(y|α)/f(y|αmax), where αmax = arg maxα f(y|α). Again the rejection
becomes worse if the varf {π(α)} is high. A fundamental diﬀerence is that rejection sampling
produces a random sample regardless of the size of M, while the SIR’s sample are dependent
and only valid as M →∞. This means that the rejection sampler is generally preferable as it is
easier to determine how much simulation to perform on a particular problem, but it requires us
to compute αmax which in high dimensional problems can be computationally demanding.
If the varf {π(α)} is high it is sometimes possible and worthwhile to adapt both SIR and
rejection sampling to improve their behaviour by taking some of the variability of the f(y|α)
into the proposal density. A simple example of this for SIR is where f(α) is Gaussian and the
log f(y|α) is concave. In this case we can adapt the proposal. In particular, we might Taylor
expand the log f(y|α) to second order to give log g(α) and then sample from the Gaussian density
proportional to f(α)g(α). Then π(α) becomes proportional to f(y|α)/g(α). This may greatly
reduce the variability of the SIR method. More generally, if we can (instead of step 1. given
1a. evaluate f(α);
1b. sample from g(α|y);
1c. evaluate g(α|y);
then we could draw α ∼g(α|y) and let π(α) = f(y|α)f(α)/g(α|y). Of course the choice of
g(α|y) will be critical in this context and will usually be chosen to be close to f(α|y) but with
fatter tails.
Adapting the rejection sampling or SIR in these ways, whilst ensuring coverage in the rejection case, can be useful in a number of problems where there is substantial knowledge of the
form of the likelihood. However, such adaption is not always possible and so the SIR method is
vulnerable to diﬃcult problems.
Finally, adaption comes at quite a considerable cost in the context of ﬁltering. In particular
evaluating f(α) = PM
j=1 f(αt+1|αj
t means we have to be able to calculate f(αt+1|αj
t). Further,
even if we can do this calculating f(α) means we have to evaluate M densities which can be
expensive if M is large.
Markov chain Monte Carlo
Another alternative to SIR is the use of a Markov chain Monte Carlo (MCMC) method for a review). In this context the MCMC method accepts
a move from a current state αi to αi+1 ∼f(α) with probability min
1, f(y|αi+1)/f(y|αi)
otherwise it sets αi+1 = αi. This procedure produces, after it is iterated until convergence,
a stationary sequence whose marginal distribution is the required posterior f(α|y). Again if
the likelihood is highly peaked there may be a large amount of rejection which will mean the
Markov chain will have a great deal of dependence. This will mean it takes a large number of
iterations until it converges to its equilibrium distribution and determining the point at which
it has reached the equilibrium can be diﬃcult. This suggests adapting, when this is possible,
the MCMC method to draw from g(α|y) and then accept these draws with probability
1, f(y|αi+1)f(αi+1)
f(y|αi)f(αi)
Again the problem with this is that having to evaluate f(α) can be troublesome.
Particle ﬁlter’s weaknesses
The propagation of samples through the empirical prediction density (3) and then sampling from
the empirical ﬁltering density (4) provides a general, simple and powerful approach to ﬁltering
time series.
The particle ﬁlter works well for standard problems where the model is a good approximation
to the data and the conditional densities f(yt|αt) are reasonably ﬂat in αt, but when we have
very severe outliers there are problems. In this context the fact that the particle ﬁlter is very
diﬃcult to adapt is an enormous weakness of the method.
To illustrate the potential problem we assume the observations arise from an autoregression
observed with noise
NID(0, σ2),
where φ = 0.9, σ2 = 0.01 and εt and ηt are independent white noise processes. The model is
initialised by αt’s stationary prior. Set n = 6 and let the ﬁrst ﬁve observations arise from the
above autoregression observed with noise model (5) and then assign to the sixth observation the
value 20. We observe the series
y = (−0.65201, −0.34482, −0.67626, 1.1423, 0.72085, 20.000)′ .
The last observation is around twenty standard deviations away from that predicted by the
model. We run a SIR (recall section 2.3.1) based particle ﬁlter on this problem using a variety
of values of M and R, averaging over 125 replications and always taking πj = 1/M. Table 1
displays the average simulation-based estimate of E (α6|Y6) and the true values computed using
the Kalman ﬁlter. Hence the Table’s focus is on the bias of the simulation procedure. The
Table shows that the SIR based particle ﬁlter grossly underestimates the values of the states
even when M and R are very large.
The particle ﬁlter based on SIR has two basic weaknesses. The ﬁrst is well known and repeats
the discussion of SIR given in section 2.3.1. When there is an outlier, the weights πj will be very
unevenly distributed and so it will require an extremely large value of R for the draws to be close
to samples from the empirical ﬁltering density. This is of particular concern if the measurement
Auxiliary particle
M = 1, 000
Table 1: SIR based particle and SIR based auxiliary particle algorithms. Recorded are the means
of 125 independent replications of the SIR based particle and auxiliary particle ﬁlters run on
the ﬁxed y using a variety of values of M and R. Thus the Table demonstrates the bias of the
density f(yt+1|αt+1) is highly sensitive to αt+1. Notice this is not a problem of having too small
a value of M. That parameter controls the accuracy of (3). Instead, the diﬃculty is, given
that degree of accuracy, how to eﬃciently sample from (4)? Can SIR be improved upon in
this problem? This paper will show that we can answer this question positively, with no added
assumptions and little extra computational expense.
The second weakness holds in general for particle ﬁlters which have their πj equal and who
update the states one period at a time. As R →∞, so the weighted samples can be used to
arbitrarily well approximate (4). However, the tails of (3) usually only poorly approximate the
true tails of αt+1|Yt due to the use of the mixture approximation. As a result (4) can only ever
poorly approximate the true f(αt+1|Yt+1) when there is an outlier. Hence the second question
is how do we improve the empirical prediction density’s behaviour in the tails? Section 4 of this
paper partially deals with this much harder problem.
AUXILIARY VARIABLE
The basics
A fundamental problem with existing particle ﬁlters is that its mixture structure means that
it is diﬃcult to improve the simulation performance of the SIR, rejection or MCMC sampling
methods due to the expense of evaluating the empirical prediction density (3).
We call the
generic process of changing the sampling mechanism adaption.
The lack of adaptability makes particle ﬁlters less attractive for diﬃcult problems where
their naive application is less eﬀective. Here we argue that many of these problems are reduced
when we perform particle ﬁltering in a higher dimension.
Our task will be to sample from the joint density f(αt+1, k|Yt+1), where k is an index on the
mixture in (3). Deﬁne
f(αt+1, k|Yt+1) ∝f(yt+1|αt+1)f(αt+1|αk
k = 1, ..., M,
and we draw from this joint density and then discard the index we produce a sample from the
empirical ﬁltering density (4) as required. We call k an auxiliary variable as it is present simply
to aid the task of the simulation. Generic particle ﬁlters of this type will be labelled auxiliary
particle ﬁlters.
We can sample from f(αt+1, k|Yt+1) using SIR, rejection or MCMC. We ﬁrst of all deal with
a very basic SIR. We approximate (6) by
g(αt+1, k|Yt+1) ∝f(yt+1|µk
t+1)f(αt+1|αk
k = 1, ..., M,
t+1 is the mean, the mode, a draw, or some other likely value associated with the density
of αt+1|αk
t . The form of the approximating density is designed so that
g(k|Yt+1) ∝πk
t+1)dF(αt+1|αk
t ) = πkf(yt+1|µk
Thus we can sample from g(αt+1, k|Yt+1) by simulating the index with probability λk, which
is proportional to g(k|Yt+1), and then sampling from the transition density given the mixture
t ). We call the λk the ﬁrst stage weights.
The implication is that we will simulate from particles which are associated with large predictive likelihoods. Having sampled the joint density of g(αt+1, k|Yt+1) R times we perform
a reweighting, putting on the draw (αj
t+1, kj) the weights proportional to the so-called second
stage weights
wj = f . In practice,
it runs slightly less quickly that the Gordon, Salmond, and Smith suggestion as we need
to evaluate g(k|Yt+1) and to perform two weighted bootstraps rather than one weighted and one
unweighted bootstrap. However, the gains in sampling will usually dominate these small eﬀects.
By making proposals which have high conditional likelihoods we reduce the costs of sampling
many times from particles which have very low likelihoods and so will not be resampled at the
second stage of the process. This improves the statistical eﬃciency of the sampling procedure
and means that we can reduce the value of R substantially.
To measure the statistical eﬃciency of these procedures we argued in the ﬁrst section that
we could look at minimizing E
π(α)2 . Here we compare a standard SIR with a SIR based on
our auxiliary variable. For simplicity we set πk = 1/M in both cases.
For a standard SIR based particle ﬁlter, for large M,
R f(yt+1|αt+1)2dF(αt+1|αk
R f(yt+1|αt+1)dF(αt+1|αk
f(yt+1|αt+1)
dF(αt+1|αk
f(yt+1|αt+1)
dF(αt+1|αk
The same calculation for a SIR based auxiliary variable particle ﬁlter gives
which shows an eﬃciency gain if
If fk does not vary over k then the auxiliary variable particle ﬁlter will be more eﬃcient as
More likely is that fk will depend on k but only mildly as
t ) will be typically quite tightly peaked (much more tightly peaked than f(αt+1|Yt))
compared to the conditional likelihood.
To assess the eﬀectiveness of the SIR based auxiliary particle ﬁlter, the right hand sides
of Table 1 replicate the earlier SIR studies on simulated Gaussian data using the auxiliary
algorithm. Table 1, which reports the results of an experiment in which there is a very extreme
outlier, suggests a very signiﬁcant improvement due to the use of the auxiliary particle ﬁlter.
In particular our simulations suggest that if we keep M ﬁxed, that for the same value of R,
auxiliary algorithm is an order of magnitude more eﬃcient than SIR for outlier problems. As a
result the auxiliary algorithm reduces the bias by an amount which would take many times the
computational eﬀort for the SIR to improve by the same degree.
Rejection sampling can also be used for the auxiliary particle ﬁlter so long as αt+1,max =
arg maxαt+1 f(yt+1|αt+1) can be found. The task is to draw from
f(αt+1, k|Yt+1) ∝f(yt+1|αt+1)f(αt+1|αk
t )πk ≤f(yt+1|αt+1,max)f(αt+1|αk
and so we can sample from the density by drawing k with probability πk and then accepting
αt+1 ∼f(αt+1|αk
t ) with probability f(yt+1|αt+1)/f(yt+1|αt+1,max). This is likely to perform
quite poorly for some problems as this ratio can be very small.
The MCMC variate of the auxiliary particle ﬁlter designs a Metropolis chain with an equilibrium distribution of the form f(αt+1, k|Yt+1).
If we make proposals from α(i+1)
t+1 , k(i+1) ∼
g(αt+1, k|Yt+1), where g(αt+1, k|Yt+1) is some arbitrary density, then these moves are accepted
with probability
1, f(yt+1|α(i+1)
t+1 )f(α(i+1)
t+1 |αk(i+1)
f(yt+1|α(i)
t+1)f(α(i)
t+1, k(i)|Yt+1)
t+1 , k(i+1)|Yt+1)
In the special case where g(αt+1, k|Yt+1) ∝g(k|Yt+1)f(αt+1|αk
t ), this simpliﬁes to
1, f(yt+1|α(i+1)
f(yt+1|µk(i+1)
f(yt+1|µk(i)
f(yt+1|α(i)
which is extremely convenient as it involves just the evaluation of the measurement density.
Hence this approach is particularly useful when it is not possible to evaluate the transition
In this subsection we will show that these three sampling procedures are now easy to adapt.
Non-linear Gaussian model
In the Gaussian measurement case, the absorption of the measurement density into the transition
equation is particularly convenient. Consider a non-linear transition density with αt+1|αt ∼
µ (αt) , σ2 (αt)
and yt+1|αt+1 ∼N(αt+1, 1). Then
f(αt+1, k|Yt+1) ∝f(yt+1|αt+1)f(αt+1|αk
t ) = gk(yt+1)f(αt+1|αk
t , yt+1),
t , yt+1) = N(µp,k, σ2
σ2 (αt) + yt+1
p,k = 1 + σ−2 
This implies that the ﬁrst stage weights are
gk(yt+1) ∝exp
The Gaussian measurement density implies the second stage weights are all equal and so a
weighted bootstrap at this stage is not required as all the draws would have equal weight.
Consequently we say that the auxiliary particle ﬁlter has been fully adapted to the problem and
it makes sense to take R = M. Of course in many problems full adaption is not realistic, but
some form of adaption can be used and will improve the eﬃciency and reliability of the method.
In many cases it is unnecessary, however it can be helpful when we come across very diﬃcult
Example: ARCH with error
Consider the simplest Gaussian ARCH model for a review) observed with independent Gaussian
error. So we have
yt|αt ∼N(αt, σ2),
αt+1|αt ∼N , Harvey, Ruiz, and Sentana and King, Sentana, and Wadhwani .
As far as we know no likelihood methods exist in the literature for the analysis of this type of
model (and its various generalizations) although a number of very good approximations have
been suggested.
Extended example: factor GARCH
A more diﬃcult example of this class of problem,
following the work of King, Sentana, and Wadhwani , is the bivariate factor GARCH
model where
yt+1 = γε1t+1σ1t+1 +
ε2t+1σ2t+1
ε3t+1σ3t+1
iid NID(0, 1),
it+1 follows a GARCH(1,1) type volatility process σ2
it+1 = βi0 + βi1σ2
it + βi2εit. If we write
1t+1, ε1t+1, ..., σ2
3t+1, ε3t+1
bf(αt+1, k|Yt+1)
yt+1 = γε1t+1σ1t+1 +
ε2t+1σ2t+1
ε3t+1σ3t+1
f(ε1t+1, ..., ε3t+1|αk
c(k)f(ε1t+1, ..., ε3t+1|αk
t , yt+1).
c(k) ∝f(y1t+1 = γε1t+1σ1t+1 + ε2t+1σ2t+1|αk
t )f(y2t+1 = γε1t+1σ1t+1 + ε3t+1σ3t+1|αk
t , y1t+1).
Thus we can draw k with probability proportional to c(k) and then sample ε1t+1, ..., ε3t+1
from a constrained multivariate normal distribution. Hence in this example adaption is again
exact. This argument generalizes to any factor GARCH model.
Log-concave measurement densities
Suppose that f(αt+1|αk
t ) is Gaussian, then we might extend the above argument by Taylor
expanding log f(yt+1|αt+1) to a second order term, again around µk
t+1, to give the approximation
log g(yt+1|αt+1, µk
log f(yt+1|µk
 ∂log f(yt+1|µk
′ ∂2 log f(yt+1|µk
g(αt+1, k|Yt+1) ∝g(yt+1|αt+1; µk
t+1)f(αt+1|αk
Rearranging, we can express this as
g(αt+1, k|Yt+1) ∝g(yt+1|µk
t+1)g(αt+1|αk
t , yt+1; µk
which means we could simulate the index with probability proportional to g(yt+1|µk
t+1) and then
draw from g(αt+1|αk
t , yt+1, µk
t+1). The resulting reweighted sample’s second stage weights are
proportional to the hopefully fairly even weights
t+1)f(αt+1|αkj
g(yt+1|µkj
t , yt+1, µk
j = 1, ..., R.
Thus, we can exploit the special structure of the model, if available, to improve upon the auxiliary
particle ﬁlter.
Stochastic volatility and rejection sampling
The same argument carries over when we use a ﬁrst order Taylor expansion to construct
g(yt+1|αt+1, µk
t+1), but in this case we know that g(yt+1|αt+1, µk
t+1) ≥f(yt+1|αt+1) for any
value of µk
t+1 due to the assumed log-concavity of the measurement density. Thus
f(αt+1, k|Yt+1) ≤g(αt+1, k|Yt+1) ∝g(yt+1|αt+1; µk
t+1)f(αt+1|αk
t ) = g(yt+1|µk
t+1)g(αt+1|αk
t , yt+1; µk
Thus we can perform rejection sampling from f(αt+1, k|Yt+1) by simply sampling k with probability proportional to g(yt+1|µk
t+1) and then drawing αt+1 from g(αt+1|αk
t , yt+1; µk
t+1). This
pair is then accepted with probability f(yt+1|αt+1)/g(yt+1|αt+1; µk
This argument applies to the non-linear time series model of evolving scale: the stochastic
volatility (SV) model
yt = ϵtβ exp(αt/2),
αt+1 = φαt + ηt,
where ϵt and ηt are independent Gaussian processes with variances of 1 and σ2 respectively.
Here β has the interpretation as the modal volatility, φ the persistence in the volatility shocks
η is the volatility of the volatility. This model has attracted much recent attention in the
econometrics literature as a way of generalizing the Black-Scholes option pricing formula to allow
volatility clustering in asset returns; see, for instance, Hull and White , Harvey, Ruiz, and
Shephard and Jacquier, Polson, and Rossi . MCMC methods have been used on
this model by, for instance, Jacquier, Polson, and Rossi , Shephard and Pitt and
Kim, Shephard, and Chib .
For this model log f(yt+1|αt+1) is concave in αt+1 so that
log g(yt+1|αt+1; µk
2β2 exp(−µk
The implication is that
t , yt+1; µk
β2 exp(−µk
t+1) = exp
2β2 exp(−µk
Finally the log-probability of acceptance is
exp(−αt+1) −exp(−µk
Notice that as σ2 falls to zero so the acceptance probability goes to one.
If an adapted SIR method had been applied here exactly the same calculations would have
been applied except that no suggestion would be rejected and instead the second stage bootstrap
weights would be the same as the acceptance rates.
Limited dependent processes
A less trivial example of exact adaption is a special cases of limited dependent processes, where
the observations are deterministic functions of the states. A simple example of this is a Probit
time series where yt = I(αt > 0), where αt is Gaussian and univariate and I(.) denotes an
indicator function. Then if yt+1 = 1 we have, exactly,
Pr(αt+1, k|Yt+1) ∝wk Pr
t , αt+1 > 0
αt+1 > 0|αk
Hence we choose k with probability proportional to wk and then draw from a truncated distribution conditional on k. If yt+1 is negative then the weights wk would be Pr
αt+1 < 0|αk
while the truncated draw would be from Pr
t , αt+1 < 0
. This style of argument carries
over to ordered Probit and censored models where we observe, for example, min(0, αt).
Adaption can be very important in these types of models for naively implemented particle
and auxiliary variable ﬁlters are generally vulnerable to tightly peaked measurement densities.
In the censored model, where yt+1 = min(0, αt+1), the measurement density is degenerate when
yt+1 > 0 and so the particle ﬁlter will degenerate to give all of its mass on the simulation which
is closest (but because they are simulated from Pr
not equal) to yt+1.
overcomes this problem instantly.
Disequilibrium models
Adaption is also essential for the following problem.
Suppose αt+1|αt is Gaussian, αt+1 is
bivariate and that we observe yt+1 = min(αt+1). Such models are called disequilibrium models
in economics and Lee ).
Pr(αt+1, k|Yt+1) ∝Pr(yt+1|αt+1) Pr(αt+1|αk
Then we have that wk should be proportional to the probability of αt+1|αk
t having its minimum
exactly at yt+1. This can be shown to be exactly
1,t+1|αt(yt+1)
1 −Pr α2,t+1|αt (yt+1)
+ fα2,t+1|αt(yt+1)
1 −Pr α1,t+1|αt (yt+1)
while having selected k we sample
α1,t+1 = yt+1
with probability
fα1,t+1|αk
1 −Pr α2,t+1|αk
and then from
α2,t+1|α1,t+1 = yt+1, αk
t , α2,t+1 > yt+1.
Likewise α2,t+1 = yt+1 with probability 1 −λt+1.
Mixtures of normals
Suppose f (αt+1|αt) is Gaussian, but the measurement density is a discrete mixture of normals
j=1 λjfj(yt+1|αt+1). Then we can perfectly sample from f(αt+1, k|Yt+1) by working with
f(αt+1, k, j|Yt+1) ∝λjfj(yt+1|αt+1)f
= wj,kfj(αt+1|αk
t , yt+1).
Then we sample from f(αt+1, k, j|Yt+1) by selecting the index k, j with probability proportional
to wj,k and then drawing from fj(αt+1|αk
t , yt+1). The disadvantage of this approach is that
the complete enumeration and storage of wj,k involves PM calculations. This approach can
be trivially extended to cover the case where f (αt+1|αt) is a mixture of normals.
smoothing methods for state space models with mixtures have been studied by, for example,
Carter and Kohn , Carter and Kohn and Shephard . The special case of an
autoregression with additive and innovative outliers, as well as mean shifts, can also be put in
this framework. Again there is an extensive MCMC literature on this topic starting with Albert
and Chib and then further developed and popularised by McCulloch and Tsay 
and McCulloch and Tsay . Filtering via MCMC methods is developed in Gerlach, Carter,
and Kohn , although their methods are O(n2).
Existing literature
The above auxiliary variable particle ﬁlter seems to be a new idea. However, there are some
similarities with a recent paper by Berzuini, Best, Gilks, and Larizza (BBGL). In Section
4 of BBGL, the method of Gordon, Salmond, and Smith reappears and is then studied in
some detail before being rejected as being ineﬃcient. Then in Section 5 BBGL do not propose
sampling the index k with equal weight (as in SIR), or sampling with weights proportional to
t+1) (as in SIR in the context of a auxiliary particle ﬁlter). Instead they use a uniform
distribution as a proposal density for a MCMC algorithm which updates k given the current
value of the state αt+1. Their MCMC algorithm is completed by using a MCMC suggestion
for the state αt+1 given the mixture. This delivers a simulation whose equilibrium distribution,
f(αt+1, k|Yt), is the same as advocated above.
We believe our approach is superior for a number of reasons. Making uniform proposals for
moving k means that BBGL make enormous numbers of draws which are irrelevant in cases
where the measurement density is highly peaked. In particular, it can take a long time until
a single sensible value of k is chosen. Our method is much simpler and immediately achieves
the desired goal of sampling the important indices. Further, the index k and state αt+1 may
be quite highly correlated given past information. Hence the MCMC algorithm may converge
very slowly. Indeed, in the special case of a model with no measurement error this sampler will
never converge. We avoid this by integrating out the index. In most cases we avoid MCMC
altogether and just use SIR on the auxiliary particle ﬁlter, which is helpful as this is then simpler
to monitor.
Example: a time series of angles
In this section we will compare the performance of the particle and auxiliary particle ﬁlter
methods for an angular time series model; the bearings-only model. Typically, the model is
used for the problem of tracking a ship by using only angular information, hence the term
“bearings-only”. We are provided with no information about range.
We consider the simple scenario described by Gordon, Salmond, and Smith . The
observer is considered stationary at the origin of the x −z plane. A simple model for the ship is
obtained by assuming that the ship gradually accelerates or decelerates randomly over time. We
use the following discretisation of this system provided by Carpenter, Cliﬀord, and Fearnhead
 , where αt = (xt, vxt, zt, vzt)′,
ut ∼NID(0, I).
In obvious notation xt, zt represent the ship’s horizontal and vertical position at time t and vxt,
vzt represent the corresponding velocities. The state evolution is thus a VAR(1) of the form
αt+1 = Tαt + Hut. The model indicates that the source of state evolution error is due to the
accelerations being white noise. The velocities therefore follow a random walk. The initial state
describes the ship’s starting positions and velocities α1 ∼NID(a1,P1). This prior together with
the state evolution of (8) describes the overall prior for the states.
The measurements consist of the true angle of the ship corrupted by a wrapped Cauchy error
term. Hence we have,
yt|µt ∼WC(µt, ρ),
µt = tan−1(zt/xt).
The density for the two parameter wrapped Cauchy distribution; WC(µ, ρ), see Fisher , is of the following form,
f(yt|µ) = 1
1 + ρ2 −2ρ cos(yt −µ),
0 ≤yt < 2π,
where µ is the mean direction and ρ is termed the mean resultant length.
We choose the
wrapped Cauchy as this allows very heavy tails which models the aberrant measurements which
occasionally arise from radar systems.
Particle ﬁlters
The proposal density for the auxiliary particle ﬁlter (projected just one step ahead) is exactly
correct for particular expansion values in the mixture as
f(αt+1, k|Yt+1) ∝f(yt+1|αt+1)f(αt+1|k) = f(yt+1|bαk
t+1)f(αt+1|k),
t+1 = T bαk
t representing the component of the mixture k at the time t. Hence the
auxiliary approximation to the joint empirical ﬁltering density is exact for the bearings-only
model. This equality arises because the suﬃcient state elements for the measurement density
are the position elements αt+1,1, αt+1,3. However, since these elements are projected without
noise through the state equation then (αt+1,1, αt+1,3)′ = (bαk
For the bearings-only model the equality is extremely useful. Since we can exactly sample
from the empirical ﬁltering density we can dispense with the reweighting procedure. Hence we
have only one weighted bootstrap, of size M, to perform at each time step. By contrast it can
immediately be seen that for ﬁxed M the particle ﬁlter approach requires R →∞in order to
obtain the same accuracy.
Figure 1: Plot of the angular measurements from origin, the true trajectory (solid line, crosses),
the particle ﬁltered mean trajectory (dashed line, boxes) and the auxiliary particle mean trajectory
(dotted line, circles). Ship moving South-East. T = 10, M = 300, R = 500.
The simulated scenario
In order to assess the relative eﬃciency of the particle ﬁlter and auxiliary method we have closely
followed the setup described by Gordon, Salmond, and Smith . They consider ση = 0.001
and σε = 0.005, where zt|µt ∼NID(µt, σ2
ε). We choose ρ = 1 −σ2
ε (yielding the same circular
dispersion) for our wrapped Cauchy density. The actual initial starting vector of this is taken
to be α1 = (−0.05, 0.001, 0.2, −0.055)′. By contrast with Gordon, Salmond, and Smith ,
we wish to have an extremely accurate and tight prior for the initial state. This is because we
want the variance of quantities arising from the ﬁltered posterior density to be small enabling
reasonably conclusive evidence to be formulated about the relative eﬃciency of the auxiliary
method to the standard method. We therefore take a1 = α1 and have a diagonal initial variance
P1 with the elements 0.001 × (0.52, 0.0052, 0.32, 0.012) on the diagonal.
Figure 1 illustrates a realization of the model for the above scenario with T = 10. The ship is
moving in a South-Easterly direction over time. The trajectories given by the posterior ﬁltered
means from the particle method (M = 300, R = 500) and the auxiliary method (M = 300) are
both fairly close to the true path despite the small amount of simulation used.
Monte Carlo comparison
The two methods are now compared using a Monte Carlo study of the above scenario with
T = 20. The number of scenario replications, REP say, is set to 20. The “true” ﬁltered mean
is calculated for each replication by using the auxiliary method with M = 80, 000. Within each
replication the mean squared error for the particle method for each component of the state over
time is evaluated by running the method, with a diﬀerent random number seed, S times and
recording the average of the resulting squared diﬀerence between the resulting particle’ estimated
mean and the “true” ﬁltered mean. Hence for replication i, state component j, at time t we
t,j,s −eαi
t,j,s is the particle mean for replication i, state component j, at time t, for simulation s
t,j is the “true” ﬁltered mean replication i, state component j, at time t. The log mean
squared error for component j at time t is obtained as
The same operation is performed for the auxiliary method to deliver the corresponding quantity
j,t . For this study we use M = 2000, REP = 20 and S = 20. Figure 2 shows the relative
performance of the two methods for each component of the state vector over time. For each
component j, the quantity LMSEAM
j,t is plotted against time. The four plots in each
box indicate the diﬀerent values of R, for the particle method, which are M/4, M, M × 4, and
M × 16. Values close to 0 indicate that the two methods are broadly equivalent in performance
whilst negative values indicate that the auxiliary method performs better than the standard
particle ﬁlter.
The graphs give the expected result with the auxiliary particle ﬁlter typically being more
precise, but with the diﬀerence between the two methods falling as R increases.
computational burden for the auxiliary particle ﬁlter is proportional to M, while for the particle
ﬁlter is roughly proportional to M + R.
GENERALIZATIONS
Fixed lag ﬁltering
The auxiliary particle ﬁlter method can also be used when we update the estimates of the
states not by a single observation but by a block of observations.
Again suppose that we
approximate the density of αt|Yt = (y1, ..., yt)′ by a distribution with discrete support at the
(a): Horizontal position
(b): Horizontal velocity
(c): Vertical position
(d): Vertical velocity
Figure 2: Plot of the relative mean square error performance (on the log-scale) of the particle
ﬁlter and the auxiliary based particle ﬁlter for the bearings only tracking problem. Numbers below
zero indicate a superior performance by the auxiliary particle ﬁlter. In these graphs R takes on
the values M/4, M, 4M and 16M. Throughout SIR is used as the sampling mechanism. Figure
(a): αt1 = xt, Figure (c): αt3 = zt, while Figure (b): αt2 = vxt and Figure (d): αt4 = vzt.
t , ..., αM
t , with mass π1
t , ..., πM
t . Then the task will be to update this distribution to
provide a sample from αt+1, ..., αt+p|Yt+p. At ﬁrst sight this result seems specialized as it is not
often that we have to update after the arrival of a block of observations. However, as well as
solving this problem it also suggests a way of reducing the bias caused by using the empirical
prediction density as an approximation to f(αt+1|Yt). Suppose that instead of updating p future
observations simultaneously, we store p−1 observations and update those observations together
with an empirical prediction density for f(αt−p+2|Yt−p+1). This would provide us with draws
from f(αt+1|Yt+1) as required. We call this ﬁxed lag ﬁltering. The hope is that the inﬂuence of
the empirical prediction density will be reduced as it will have been propagated p times through
the transition density. This may reduce the inﬂuence of outliers on the auxiliary method.
This can be carried out by using a straightforward particle ﬁlter using SIR, rejection sampling
or MCMC, or by building in an auxiliary variable so that we sample from αt+1, ..., αt+p, k|Yt+p.
Typically the gains from using the auxiliary approach is greater here for as p grows so naive
implementations of the particle ﬁlter will become less and less eﬃcient due to not being able to
adapt the sampler to the measurement density.
To illustrate this general setup consider the use of an auxiliary particle ﬁlter where we take
t+p)...f(yt+1|µk
t+1)dF(αt+p|αt+p−1)...dF(αt+1|αk
t+p)...f(yt+1|µk
and then sampling the index k with weights proportional to g(k|Yt+p). Having selected the
index kj we then propagate the transition equation p steps to produce a draw αj
t+1, ..., αj
j = 1, ..., R. These are then reweighted according to the ratio
t+p)...f(yt+1|αj
f(yt+p|µkj
t+p)...f(yt+1|µkj
This approach has three main diﬃculties. First it requires us to store p sets of observations
and p × M mixture components.
This is more expensive than the previous method as well
as being slightly harder to implement. Second, each auxiliary variable draw now involves 3p
density evaluations and the generation of p simulated propagation steps. Third, the auxiliary
variable method is based on approximating the true density of f(k, αt−p+1, ..., αt|Yt), and this
approximation is likely to deteriorate as p increases. This suggests that the more sophisticated
adaptive sampling schemes, discussed above, may be particularly useful at this point. Again
however, this complicates the implementation of the algorithm.
We tried the ﬁxed lag versions of SIR based particle and auxiliary particle ﬁlters on the
diﬃcult outlier problem previously discussed in Section 2.4 and report the results in detail in
Table 2. The results all take p = 2, 3 and suggest an order of magnitude improvement in the
auxiliary method, and a fall in the eﬃciency of SIR based particle ﬁlters as p increases due to
the poor sampling behaviour of the algorithm. The ﬁxed lag auxiliary ﬁlter is now 50 to 500
times as eﬃcient, in terms of the reducing the bias, as the plain particle ﬁlter for the p = 3
case. This suggests that the ﬁxed lag approach has some uses and should be followed up when
we deal with diﬃcult problems.
Stratiﬁcation
The basics
Suppose that instead of having an equally weighted empirical prediction density, we had a
stratiﬁed density based on S sets of samples of size {Mi, i = 1, ..., S}. We write the individual
elements as
t , i = 1, ..., S, j = 1, ..., Mi
. The stratiﬁed empirical prediction density is then
going to be of the form
f(αt+1|αj,i
auxiliary particle
Table 2: Fixed lag SIR based particle and auxiliary particle ﬁltering algorithms, using p = 2, 3.
Recorded are the means of 125 independent replications of the ﬁlters run on the ﬁxed y using a
variety of values of M and R. Thus the Table demonstrates the bias of the methods.
We will propagate Ri times from the i−th strata. The associated propagation probabilities will
be 1/Ri for a particle based SIR or
f(yt+1|µj,i
k=1 f(yt+1|µk,i
for an SIR applied to a auxiliary particle ﬁlter.
We write the propagated samples’ one-step ahead weights as lj,i = f(yt+1|αj,i
t+1)/pj,i and we
resample within each strata. Then we can estimate the strata probabilities as
Clearly stratiﬁcation has the diﬃculty that, in eﬀect, we are performing a SIR sampling method
within each strata and so we are likely to need Ri and Mi to be quite large for all values of i. Of
course, the advantage is that the strata can be chosen so that the associated weights l1,i, ..., lRi,i
maybe quite even within the strata which may reduce the amount of simulation we require.
One possible generalization of this idea is that we can estimate the strata probabilities,
, not as a by-product of the SIR operation but as an independent statistical calculation.
We can estimate replace πi
t+1 given above by an alternative estimator which is proportional to
f although their motivation is rather diﬀerent than ours.
Posterior density of parameters
A fundamental characteristic of the particle ﬁlter is that it uses a discrete support for the states
which randomly changes as time progresses through the propagation mechanism of the transition
equation. Points of support with high measurement densities ﬂourish and multiply, while points
with low support die out.
Theoretically a state could represent any quantity which we might wish to learn about and
so we might be tempted to perform particle ﬁltering on unknown parameters or states which do
not change over time. Unfortunately it is well known that this performs very poorly for points
of support with low likelihoods are quickly discarded even though they will be very important
when the sample size is larger.
A radical alternative is to use stratiﬁcation for this problem. The idea will be to generate
a set of parameter points θ1, ..., θS and then to draw the random states associated with each of
the parameter values. A sensible way to proceed would be in the ﬁrst strata to draw M1 lots
of states α1,1
t , ..., αM1,1
from α0|θ1. The same operation can be conducted for each parameter
value. Then we proceed as before.
In this situation the strata probabilities have an interesting interpretation. Clearly πi
an estimate of a constant times πi
t−1f(yt|Yt−1, θi), from (12). That is the strata weights are
the normalized likelihood functions for the parameter values. This allows either Bayesian or
maximum likelihood calculations.
As we process more information the strata probabilities will increasingly become more concentrated on a few points of support. In this case we can start to discard points of support with
extremely low strata probabilities (typically log πi
t > −100) and we can replace them by other
values of θ which are close to the points of support which have high strata probabilities. These
methods will be discussed at more length in the next section.
ESTIMATORS OF PARAMETERS
Motivation
Suppose that we have a Gaussian autoregression observed with noise (5) and we wished to
perform parameter estimation. The Kalman ﬁlter yields the exact likelihood in this case, but
it might be useful to look at using particle ﬁlters to estimate θ in this case as we can use the
Kalman ﬁlter to check the results. Let n = 550, β = 0.5, φ = 0.975 and σ2 = 0.02, where
NID(0, 4.9)
φ (αt −β) + ηt,
NID(0, σ2),
and εt and ηt are independent white noise processes. Suppose initially that φ and σ2 is known.
Then we will employ a particle ﬁlter to estimate the relative log-likelihood as β varies for this
problem. Initially we carry out this calculation for 280 diﬀerent values of β which are drawn
from a N(0, 10) distribution.
The particle ﬁlter will be stratiﬁed, with each point of support for β being given a separate
strata. We discard points of support for β which at some stage have
which is less than
exp(−50). Naturally a large number of points of support die during the iterative procedure.
Typically around a half will survive this experiment. Throughout we will initialize the states by
using their unconditional density, so that α0|β ∼N
In this experiment we will use a straightforward SIR based particle ﬁlter with M = R/2 in
each strata and take R = 150, 500, 1000, 3000. The resulting
, which are proportional to the
estimated likelihood function, are graphed in Figure 3. This ﬁgure is very ragged reﬂecting the
many sources of randomness in this process. It can be used to estimate the posterior moments
of β|y by weighting each strata by the prior density of the value of β indexing the strata.
Smoothing via common random numbers
Some of the roughness of the estimates of the relative log-likelihood function is caused by the
use of diﬀerent random numbers in the diﬀerent strata. There would seem to be little point in
this if we want to compare the estimated log-likelihood in the diﬀerent strata. Hence we carry
out the same experiment but with common random numbers for each strata — using a common
seed across each strata, but a diﬀerent one for each time period. The results are given in Figure
The Figure indicates that using common random numbers does not really change the estimators very much. The estimated log-likelihood is still very random across strata. The reason
for this is that the bootstrapping operation is extremely rough so that small changes in the resampling weights can mean that a very diﬀerent state is sampled. This can eﬀect the estimated
(a) R=150, M=75
(b) R=500, M=250
(c) R=1000, M=500
(d) R=3000, M=1500
Figure 3: Estimators of the relative log-likelihood computed via simulation estimators of the
prediction decomposition. The graphs plot the estimated log-likelihood against the β, which means
the true value is 0.5. Each value of β is used as a strata.
log-likelihood dramatically.
Smoothing via sorting and recycling
An alternative to recycling the random numbers is to try to smooth the likelihood via the use of
sorting. The discontinuities result as diﬀerent αj
t are randomly chosen, when θ changes, in the
bootstrap. As contiguous αj
t can be very diﬀerent so these changes can make quite a big impact
on the estimated likelihood function. We can reduce the impact by simply sorting the αj
their weights if using an auxiliary variable) before bootstrapping. Then small changes in θ may
change the αj
t which is selected, but the impact on the estimated log-likelihood will be small.
This approach has three problems. First, sorting is quite expensive and so this addition to
the algorithm considerably slows it. Second, although this reduces the discontinuities, they are
not removed. Third, in very complicated problems it may not be immediately obvious how to
sort the states (or signals) in order to reduce their sensitivity.
Usually we have found the pure particle ﬁlter is far smoother than its auxiliary variable
generalization. This is because the second stage resampling weights of the auxiliary variable are
more sensitive to θ than the standard particle ﬁlter.
(a) R=150, M=75
(b) R=500, M=250
(c) R=1000, M=500
(d) R=3000, M=1500
Figure 4: Estimators of the relative log-likelihood computed via simulation estimators of the
prediction decomposition using common random numbers in each strata. The graphs plot the
estimated log-likelihood against the β, which means the true value is 0.5. Each value of β is used
as a strata and common random numbers are used in each strata.
To illustrate this we repeat the above experiment but now with common random numbers
and using sorting. The resulting estimates of the log-likelihood are given in Figure 5. These
curves are now extremely smooth — although they are still not diﬀerentiable for all parameter
These estimated log-likelihood functions are suﬃciently smooth to enable us to use a standard Nelder-Meed simplex numerical optimization routine to approximate the maximum likelihood estimator and its sampling variation. The parameterization has been selected so that the
optimization can be carried out in a relatively small number of steps.
In this experiment we take the same model but with n = 955 and now use M = 2500 and
R = 5000. Throughout we use constant random numbers and sort the states for each value of t.
The reported standard errors, given in Table 3 are computed using an outer-product estimator
of the covariance of the score, using quite a coarse numerical derivative on the parameterization
β/2, {log φ/ (1 −φ)} /4 and σ1/2. The Table also reports the implied 95% conﬁdence intervals
for the parameters of interest, β, φ and σ.
The results are suggestive that the MLE estimator is quite easily approximated by the
simulation version. To conﬁrm this we can estimate the score a number of times using new sets
(a) R=150, M=75
(b) R=500, M=250
(c) R=1000, M=500
(d) R=3000, M=1500
Figure 5: Estimators of the relative log-likelihood computed via simulation estimators of the
prediction decomposition. The graphs plot the estimated log-likelihood against the β, which means
the true value is 0.5. Each value of β is used as a strata and common random numbers are used
in each strata. Further the value of the states are sorted during each propogation step.
of random numbers. This will allow us to estimate the variability of the score as a function of
the simulation process and so estimate the contribution the simulation makes to the parameter
uncertainty.
In this experiment we estimate the score 10 independent (with ﬁxed data but with new simulations each time) times and report in Table 4 the average score and the associated covariance
matrix. The values reported are very small.
Moment conditions
The particle ﬁlters deliver draws from αt+1|Yt and so can be used to unbiasedly estimate the
moments (assuming they exist) of yt+1|Yt for every value of t. Hence we can construct a series
of moment conditions
, k = 1, ...
replacing the expected value by an unbiased simulated version of this expectation (notice the
simulation error does not eﬀect this argument). Such estimated moment conditions hold true
over the whole data and are independent over t when the parameter is taken at the true value.
Covariance
log(φ/(1 −φ))/4
-0.00052404
-0.00052404
upper .025
lower .975
Initial values
Table 3: Simulation estimation of the ML estimator of the parameters: one version is with the
transformed parameters, the other with the parameters of interest. The conﬁdence intervals are
calculated as being two sided and contain the truth with 0.95 probability. Initial values denote
the initial values used in the optimizarion. MLE denotes the true maximum likelihood estimator
of these parameters.
Average score
Covariance of score
log(φ/(1 −φ))/4
-0.00018226
2.1655e-006
4.9657e-007
2.1291e-007
-0.00012770
4.9657e-007
3.0412e-007
1.7816e-007
-0.00049014
2.1291e-007
1.7816e-007
4.6521e-007
Table 4: Simulation of the score at the simulated MLE, varying the random numbers in the
simulation. The estimate of the average score and the covariance of the score is carried out
using 10 replications.
Hence a second set of estimated moment constraints is that
{yt+1 −E (yt+1|Yt; θ)} {yt+s −E (yt+s|Yt+s−1; θ)} , s = 2, ...
All of these moments could be used as an input into a generalized method of moment (GMM)
estimation procedure. For a discussion of GMM see, for example, Hansen and an introduction given in Hamilton .
A continual problem with this approach is that the moment conditions are again not smooth
in θ even with ﬁxed random numbers and employing sorting.
APPLIED EXAMPLE: STOCHASTIC VOLATILITY
Application
In this section we will analyse the weekday closes (diﬀerence of the log of the series) on the
Pound Sterling/US Dollar exchange rate from 1/10/81 to 28/6/85. The sample size is n = 946.
This dataset has been previously analysed using quasi-likelihood methods in Harvey, Ruiz, and
Shephard and by Bayesian MCMC by Kim, Shephard, and Chib , whose result are
250000 500000 750000
(a) phi|y against iteration
250000 500000 750000
(b) sigma_eta|y against iteration
250000 500000 750000
(c) beta|y against iteration
(d) Histogram of phi|y
(e) Histogram of sigma_eta|y
(f) Histogram of beta|y
(g) Correlogram for phi|y
(h) Correlogram for sigma_eta|y
(i) Correlogram for beta|y
Figure 6: Single move Gibbs sampler for the Sterling series. Graphs (a)-(c): simulations against
iteration. Graphs (d)-(f): histograms of marginal distribution. Graphs (g)-(i): corresponding
correlograms for simulation. In total 1,000,000 iterations were drawn, discarding the ﬁrst 50,000.
summarized in Table 5 using simulations graphed in Figure 6. In that paper the prior for the
parameters were independent, with φ ∼2Beta(20, 1.5) −1.0, σ2
η ∼0.01 × 5/χ2
5 and a diﬀuse
prior on log β. Here we replace the diﬀuse prior by a Gaussian distribution with a mean of zero
and variance of ten as particle ﬁlters cannot deal with diﬀuse conditions.
Ineﬃciency
Covariance & Correlation
0.00013754
0.00011062
0.00063273
-0.00022570
0.00098303
0.00036464
0.00021196
-0.00040183
Table 5: Daily returns for Sterling: summaries of Figure 6. The Monte Carlo S.E. of simulation
is computed using a bandwidth of 2,000, 4,000 and 2,000 respectively. Italics are correlations
rather than covariances of the posterior.
Ineﬃciency denotes an estimate of the simulation
eﬃciency of this MCMC procedure compared to a hypothetical sampler which produces iid draws
using the same computer time.
Here we will perform an on-line Bayesian analysis of this problem as well as a simulated
maximum likelihood analysis. Throughout we use the simplest of particle ﬁlters based on a SIR
algorithm. The simulation eﬃciency of this procedure could be very signiﬁcantly improved by
using the auxiliary variables rejection algorithm which is available for the SV model.
On-line Bayesian estimation and diagnostic checking
In this section we estimate the SV model on-line using a SIR based ﬁltering algorithm with
stratiﬁcation. We stratify to keep 840 diﬀerent values of the parameters. These parameters are
initially drawn from the prior density. In each strata we take R = 1785 and M = 892. Common
random numbers were used across strata and sorting was employed. Up to t = 100 we replace
draws from the prior which had relatively log-likelihoods which were less than −1 × 1040. At
the end of the sample we have 216 remaining points of support.
The resulting simulation estimates of the posterior means and covariances are given in Table
6. The results are very slightly diﬀerent from Table 5 for the MCMC algorithm.
Covariance & Correlation
lower .025
upper .975
-0.0001566
Table 6: SIR based stratiﬁed sampler to perform Bayesian calculations. The lower and upper
points are estimates of the upper and lower 0.025 and 0.975 quantiles of the posterior density.
MC S.E. denotes a bootstrap estimator of the standard error in estimating via simulation the
posterior mean. Ineﬀdenotes the ineﬃciency factor, which is an estimate of the simulation
eﬃciency of the SIR based sampler (using 840 strata drawn from the prior) compared to a
hypothetical sampling which produces iid draws from the posterior distribution.
The simulation error induced by using this procedure is estimated in the following way.
Suppose we use, in total, S strata then we estimate the posterior moments as
where πi represents the relative likelihood for the simulated prior value θi. Then the simulation
error is estimated via a bootstrap conducted on the discrete population (θ1, π1) , ..., (θS, πS).
The i-th replication of the bootstrap draws from the S strata with equal probability and with
replacement to produce a bootstrap sample
 θ1,i, π1,i , ...,
θS,i, πS,i
and records the corresponding mean
i = 1, ..., B.
The estimated of the simulation error is then the standard deviation of the bootstrap replications
bθ1, ..., bθB.
The ineﬃciency factor attempts to measure the statistical eﬃciency of the simulation method
compared to a hypothetical sampler which is able to produce iid samples from the posterior density. The stratiﬁcation sampler we are using draws S samples from the prior and then produces an
estimated Monte Carlo variance via the above bootstrap argument. Call the simulation variance
V ar(Eθ|y), then we compute the ineﬃciency factor by looking at the ratio of S × V ar(Eθ|y) to
the posterior variance.
The advantage of this approach is that it produces on-line estimates of the parameters and so
allows us to see how the parameter estimates are inﬂuenced by various stretches of data. Figure
7 displays the evolution of the posterior means of the parameters together with the upper and
lower 2.5 percentage of the distribution. Inevitably these quantiles are rather roughly estimated
and so vary quite dramatically at times.
(a) phi | y: upper and lower quantiles and mean
(b) sigma_eta | y: upper and lower quantiles and mean
(c) beta |y: upper and lower quantiles and mean
(d) One step ahead forecast distribution functions
Figure 7: On-line Bayesian estimation of the SV model. (a)-(c) Graphs the estimated posterior
mean and upper and lower 2.5 percentage points of the posterior distribution function against
observation number. (a) is for φ|y, (b) has ση and (c) has β|y. Graph (d) plots the estimated
distribution function of the one step ahead prediction distribution against observation number.
These shoulc be UID(0, 1) if the model and prior are true.
The estimated distribution functions are used in a series of statistical graphs to assess the
validity of the model and prior densities. Let us write ut as the distribution functions, then
we will compute a histogram of their marginal distribution and an associated QQ-plot. We
will also map them to normals via the inverse of the Gaussian distribution function.
their correlogram will be plotted.
In addition the same operation will be performed on the
reﬂected uniforms, which work on 2|ut −0.5|. These reﬂected uniforms assess whether there is
predictability in the size of discrepancy of the uniforms from their means. The corresponding
correlogram should pick up failures in the scale of the forecast density. It is the natural extension
of an ARCH based test which is used for linear models. The results of these calculations are
plotted in Figure 8.
(a) Histogram of distribution functions
(b) Correlogram for normalised innovations
(c) Correlogram for reflected innovations
(d) QQ plot of distribution functions
Figure 8: Diagnostics for on-line Bayesian estimation of the SV model. Graph (a) is the marginal
histogram of the estimated distribution functions. These should be uniform if the model and
prior are true. Graph (b) works on the inverse Gaussian distribution function evaluated at the
estimated distribution function. These should be white noise if the the model and prior is true
and so Graph (b) plots their correlogram. Graph (c) does the same operation but on the reﬂected
uniforms. Graph (d) is the QQ plot of the estimated distribution function and so contains the
same information as Graph (a).
These graphs show the model ﬁts this data quite well with a little failure in Graph (b).
However, this is a failure of the mean of the model, not the volatility part which would have
been picked up in Graph (c). The histogram and QQ-plot suggest the model and prior ﬁt the
data quite well.
Formalizing tests of the model and prior are in principle completely straightforward given
the nature of the estimated distribution functions under the null hypothesis. Let sy denote any
test statistic which is a function of the data only through the estimate distribution functions.
Under the null sy is exactly pivotal and so we can use it as the basis of an exact Monte Carlo
test of the hypothesis that the model and prior are true ). This takes on the remarkably simple form of simulating uj
1, ..., uj
n as iid draws from
UID(0, 1) and then using these as an input into the statistic s, to deliver the observed value suj.
Carrying this out M times delivers a population su1, ..., suM which gives us a basis for judging
the size of the observed value sy which resulted from the data. Under the null sy comes from
the same population as su1, ..., suM and so can be used as a basis for a formal test.
This setup is both remarkably simple and extends to the case where we think of computing
the exact distribution of many tests simultaneously. Indeed it would seem that we can control
the overall size of all simultaneous tests in this framework.
Maximum likelihood estimation
We also used the SIR based particle ﬁlter to perform maximum simulated likelihood estimation
of the SV model for this data set. The results are given in Table 7 and are based on taking
M = 2500 and R = 5000. The results are broadly in line with the Bayesian estimation except
that σ is estimated to be quite a lot higher in this experiment. This could be due to the prior
density for the Bayesian estimator which had quite a lot of mass below 0.1. The conﬁdence
intervals are of the same type of size as observed for the Bayesian analysis.
Again Table 7
displays the simulation covariance of the scores to give a guide as to the uncertainty associated
with this simulation based estimator. The covariance is very small and so we feel conﬁdent that
the estimator is very close to the maximum likelihood estimator.
Covariance
log(φ/(1 −φ))/4
0.00024964
-0.0023843
0.00024964
-0.0023843
upper .025
lower .975
Initial values
Simulation error
Covariance
for the score
log(φ/(1 −φ))/4
3.0465e-006
2.0024e-007
8.4064e-007
2.0024e-007
1.0137e-006
1.0890e-006
8.4064e-007
1.0890e-006
2.9953e-006
Table 7: Simulation estimation of the ML estimator of the SV parameters: one version is with
the transformed parameters, the other with the parameters of interest. The conﬁdence intervals
are calculated as being two sided and contain the truth with 0.95 probability. Initial values denote
the initial values used in the optimizarion. Simulation error for the score is the covariance of
10 independent simulations of the score evaluated at the simulated ML estimator.
EXTENSIONS
Allowing feedback
In some problems the standard model is not suﬃciently rich and has to be extended. In particular it is often helpful to allow the measurement and transition equations to depend on past
observations. If we write the information up to time t as Yt, then the measurement density becomes f(yt|αt, αt−1, Yt−1), while the transition density is f(αt+1|αt, Yt). We call this a feedback
In principle the particle and auxiliary particle ﬁlter methods are not complicated by this
extension, although now it is necessary to store the history of the time series. All that changes
is that we now must be able to simulate from f(αt+1|αt, Yt) and evaluate f(yt|αt, αt−1, Yt−1).
A simple example of this framework is where f(yt|αt, Yt−1) is a switching autoregression with
outliers and level shifts, with αt being a discrete state Markov chain so that f(αt+1|αt, Yt) =
f(αt+1|αt). Such models have attracted quite a lot of interest following the work of, for example,
Hamilton , Albert and Chib , McCulloch and Tsay , McCulloch and Tsay
 and Gerlach, Carter, and Kohn .
Simulation based models
In this paper we have shown how to perform ﬁltering even in cases where we can only simulate
from f(αt+1|αt) and evaluate the measurement density f(yt|αt). In some problems it may be
unrealistic to assume that we can compute f(yt|αt), but in such situations it might still be
possible to simulate from yt|αt. In these cases we could draw a large sample y1
t , ..., yS
t from yt|αt
and then use some non-parametric density estimator to form an estimate
f(yt|αt). This could
then replace the true density in the SIR algorithm outlined above for the particle ﬁlter. The
use of common random numbers and a smooth density estimator could be very useful in this
situation as this could reduce the impact of the simulation error in estimating the likelihood
ratios important in the SIR algorithm.
CONCLUSION
This paper has studied the weaknesses of the very attractive particle ﬁltering method proposed
by Gordon, Salmond, and Smith . The SIR implementation of this method is not robust
to outliers for two diﬀerent reasons: sampling eﬃciency and the unreliability of the empirical
prediction density in the tails of the distribution. We introduce an auxiliary variable into the
particle ﬁlter to overcome the ﬁrst of these problems, providing a powerful framework which is as
simple as SIR, but more ﬂexible and reliable. We study the ﬁxed lag ﬁltering algorithm to tackle
the second problem. Our experiments suggest that this produces a signiﬁcant improvement in
the algorithm, however it still cannot deal with some problems.
The combination of the two improvements produce an algorithm which is a very signiﬁcant
improvement over the existing technology. Further, it can be tailored to the particular problem
We believe that except in some very exceptional problems, the auxiliary variable
particle ﬁxed lag ﬁltering algorithm can be used reliably.
Multinomial sampling
The following algorithm is discussed in Carpenter, Cliﬀord, and Fearnhead . Suppose x
takes on the values 0, ..., I −1 with probability of π0, ..., πI−1. Then the task will be to draw
a sample of size R from this discrete distribution in O(R) computations. We carry this out by
sampling an ordered version of these variables, so that x0 ≤x1 ≤... ≤xR−2 ≤xR−1. In the
applications discussed in this paper it is not necessary to shuﬄe these variables.
Drawing order variables will be carried out by ﬁrst drawing order uniforms ). Let u0, ..., uR−1 ∼UID(0, 1), then
u(R−1) = u1/R
u(k) = u(k+1)u1/(k+1)
k = R −2, R −3, ..., 1, 0,
where u(0) < u(1) < ... < u(R−2) < u(R−1). This is most easily carried out in logarithms.
Then we calculate the ordered x using the following trivial algorithm
s=0,k=0,j=0;
for (i=0; i<I; i++)
while (u(j) ≤s
ACKNOWLEDGEMENTS
We would like to thank the ESRC for their ﬁnancial support through the project ‘Estimation
via Simulation in Econometrics’ and the EU through their grant ‘Econometric inference using
Simulation Techniques’. All the computations reported in this paper were carried out using the
Ox language of Doornik . Neil Shephard would like to thank Robert Kohn, Peter Cliﬀord,
Angelo Melino and David Firth for various helpful conversations.