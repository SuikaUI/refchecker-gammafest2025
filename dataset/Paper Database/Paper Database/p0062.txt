Considerations for a PAP Smear Image Analysis
System with CNN Features
Srishti Gautam, Harinarayan K. K., Nirmal Jith, Anil K. Sao, Arnav Bhavsar, and Adarsh Natarajan
Abstract—It has been shown that for automated PAP-smear
image classiﬁcation, nucleus features can be very informative.
Therefore, the primary step for automated screening can be
cell-nuclei detection followed by segmentation of nuclei in the
resulting single cell PAP-smear images. We propose a patch based
approach using CNN for segmentation of nuclei in single cell
images. We then pose the question of ion of segmentation for classiﬁcation using representation learning with CNN, and whether
low-level CNN features may be useful for classiﬁcation. We suggest a CNN-based feature level analysis and a transfer learning
based approach for classiﬁcation using both segmented as well
full single cell images. We also propose a decision-tree based
approach for classiﬁcation. Experimental results demonstrate the
effectiveness of the proposed algorithms individually (with lowlevel CNN features), and simultaneously proving the sufﬁciency
of cell-nuclei detection (rather than accurate segmentation) for
classiﬁcation. Thus, we propose a system for analysis of multicell PAP-smear images consisting of a simple nuclei detection
algorithm followed by classiﬁcation using transfer learning.
Index Terms—Cervical cancer screening, Nuclei segmentation,
Nuclei detection, PAP-smear image classiﬁcation, Transfer learning, Convolutional neural networks (CNN).
I. INTRODUCTION
ERVICAL cancer continues to be one of the deadliest
cancers among women worldwide, especially with it
being the most common cause of death in developing countries
 – . Every year, approximately 500,000 new cases are
reported, out of which 85% occur in developing countries,
along with approximately 270,000 deaths worldwide . The
pre-cancerous lesions of cervical cancer take almost a decade
to convert into the cancerous ones. Hence, despite the above
facts, unlike many other cancers, it can be fully cured if
detected early .
For screening, traditional PAP-smear test continues to be
prevalent, especially in the developing countries . Due
to vast differences in the morphology of cells (in size and
regularity of nucleus) because of the cancerous/pre-cancerous
changes, manual screening is reasonably straightforward.
However, it has many drawbacks in terms of being tedious,
time-consuming and expensive . Also, there can be huge
inter and intra observer variability . Hence, automation
is essential for development of a system with lower cost,
adequate speed up and higher accuracy.
Automatic screening system using PAP-smear image analysis, traditionally comprises of three steps i.e cell (cytoplasm
Srishti Gautam (email: ), Anil K.
Sao and Arnav Bhavsar (email: anil/ ) are with Indian
Institute of Technology, Mandi.
Harinarayan K. K., Nirmal Jith and Adarsh Natarajan are with Aindra
Systems Pvt. Ltd., Bangalore. (email: hari/nirmal/ )
and nuclei) segmentation, feature extraction and cell classiﬁcation. Segmentation seems important because the morphological changes associated with the degree of malignancy can be
represented by features calculated from the segmented nuclei
and cytoplasm, for example, the nucleus-cytoplasm ratio or
texture features associated with chromatin pattern irregularity
 . However, typically the segmentation of nucleus is more
reliable than that of cytoplasm (possibly due to overlapping,
occluded cytoplasm in multi-cell images). Moreover, only the
nucleus based features can also be extremely valuable and
effective in cervical cancer screening . Further, for some
classiﬁcation frameworks, a Region of Interest (ROI) / nuclei
detection step in the images containing multiple cells may
be used as a substitute to accurate segmentation step. These
detected nuclei can be used for classiﬁcation.
While the segmentation process is more rigorous, but can
assist the classiﬁer to focus only on the features of the
object in question, detection is relatively easier. Additionally,
due to presence of background in the detected sub-images,
some background contextual information is available when
using detected cells as opposed to accurately segmented ones.
Therefore, an interesting question to consider is that whether
an accurate segmentation necessary for classiﬁcation with
contemporary frameworks (e.g. CNN)? Having said that, we
acknowledge that segmentation can be useful on its own,
in case one considers manual interventions, and for medical
education and training applications. With regards to the CNN
based classiﬁcation, we note that unlike in standard computer
vision applications, cell images, arguably do not contain highlevel semantics. Thus, we also explore the effect of high-level
CNN features vs. the low-level CNN features, where the latter
can enable the system to be more efﬁcient.
Thus, noting the above aspects, for an overall system
development, we propose algorithms for 1) Detection of nuclei
in multi-cell images in single cell images, 2) Segmentation
of nuclei in single cell images, 3) Classiﬁcation strategies
considering both accurate nuclei segmentation, and nuclei
detection (involving some cellular background pixels), and
also considering CNN features from different layers.
A. Related work: Segmentation
Numerous works have been reported for cervical cell nucleus segmentation, indicating its importance. Phoulady et. al
 , uses adaptive multilevel thresholding and ellipse ﬁtting
followed by iterative thresholding and subsequent binarizations but on a different problem of segmenting overlapping
cells. Cheng et. al uses HSV color space and color clustering.
 
Genctav et. al uses multi-scale hierarchical segmentation
algorithm. Ref uses patch-based fuzzy C-means (FCM)
clustering technique, where, on the over-segmented image
obtained from FCM, a threshold is applied to classify the FCM
cluster centers as nucleus and background. A superpixel-based
Markov random ﬁeld (MRF) framework with a gap-search
algorithm is proposed in . Bora et. al uses Wavelet and
Haar transform along with MSER (maximally stable extremal
region). In recent years, deep learning techniques have also
been explored in this area. Multiscale CNNs are used in
 along with superpixels for multi-cellular images. Song
et. al. also uses neural networks in for nucleus and
cytoplasm segmentation, and multiple scale deep CNNs ,
 for overlapping cell segmentation. However, most of the
above approaches use non-public datasets, or public datasets
lacking variation of normal and abnormal cell images (which
typically have very different characteristics). For example,
ISBI segmentation challenge dataset for overlapping cells,
has no distinction between normal and abnormal slides. Only
the approaches in , use a publicly available dataset
suitable for full cervical cancer diagnosis i.e. segmentation
and classiﬁcation of cells into normal vs abnormal.
In this work, we report a CNN based segmentation approach, which works on selectively pre-processed cell images
depending on the homogeneity of the nucleus, post which the
pre-processed and non-pre-processed cells are segmented with
two different CNNs. Considering low amount of variety in
data, such a selective preprocessing helps each of the CNNs
to learn the data characteristics better.
B. Related work: Classiﬁcation
Recently, deep learning and CNNs have gained the center
stage for various classiﬁcation problems , . They have
also gained some popularity in the medical imaging applications – . An important feature of CNN is a reduced
dependency on an exact segmentation for classiﬁcation. More
speciﬁcally, an approximate segmentation (or ROI detection)
can be considered to be sufﬁcient for classiﬁcation. This
is especially important for the application of classiﬁcation
in medical imaging. However, there are a few drawbacks
associated with training a CNN from scratch for a particular
problem, for example, the availability of a very few number
of annotated images especially in the case of medical datasets
 , requirement of a huge number of days/weeks to train
etc. Transfer learning has proved to be very effective in
overcoming these limitations, both in medical , and
non-medical domains . On account of the CNN features
being more generic at early layers and having been
already learned on a million images , these can be used to
train the subsequent layers of application-speciﬁc CNN. This
reduces the chances of overﬁtting as well as the overall training
time of CNN. Recently, both methodologies i.e training a CNN
from scratch as well as transfer learning have also been applied
on PAP-smear images , .
In this work, we consider deep learning methods for classi-
ﬁcation, using transfer learning on Alexnet , on both segmented as well as non-segmented single cell images. Alexnet
is selected considering the need for a smaller architecture,
enabling an efﬁcient processing in medical systems. We also
propose a combination of decision-tree based classiﬁcation
with transfer learning. Finally, the transfer learning approach
is applied on the detected cells from multi-cell images and is
also shown to perform effectively.
Thus, the overall contributions of this work are: 1) We
propose a patch-based CNN approach for segmentation using
selective pre-processing and show that the proposed selectiveness is effective for nuclei segmentation in single-cell
images. 2) We explore the classiﬁcation results with transfer
learning from the features extracted from different CNN layers
in Alexnet , and demonstrate that the low-level features
can be more effective. 3) We demonstrate that the easier
cell-nuclei detection can be more effective than an accurate
segmentation for CNN-based classiﬁcation. 4) We introduce a
decision-tree based classiﬁcation, which outperforms a simple
multi-class classiﬁcation with transfer learning. 5) We consider
various classiﬁcation scenarios and demonstrate state-of-theart classiﬁcation results.
A preliminary version of this work has been reported .
II. DATASET
In this work, we have used two datasets for our experimentation, one for single cell images and another for multi-cell
images. The latter is relatively more noisy and artifact-prone.
A. Herlev dataset
The ﬁrst dataset on which we have evaluated our algorithms
is Herlev PAP-smear dataset . It consists of 917 cell
images whose description in the increasing order of abnormality is given in Table I. Each image in Herlev dataset
consists of a single nuclei. It is a publicly available dataset
collected at Herlev University Hospital by a digital camera
and microscope.
B. Aindra dataset
80 multi-cell images were collected by Aindra Systems Pvt.
ltd., Bangalore, India, from an oncology center. Staining and
preparation of slides was done at the same center. The images
are labeled into 4 classes i.e Normal, Low-grade squamous
intraepithelial lesion (LSIL), High-grade squamous intraepithelial lesion (HSIL) and Squamous cell carcinoma (SCC).
The nuclei in these images have been annotated by doctors.
The sample images in the increasing order of abnormality are
shown in Table II.
III. PROPOSED METHODOLOGY
We now describe the proposed system which consists
of three methods i.e detection of nuclei, segmentation of
nuclei, and classiﬁcation of segmented/detected nuclei via
deep-learning approaches. The block diagram of the proposed
system is given in Figure 1.
Figure 1. Proposed system for automated analysis of PAP-smear images.
SAMPLE CERVICAL CELLS IN HERLEV DATASET
Superﬁcial
Intermediate
in situ (cis)
Sample cells
Total cells
SAMPLE CERVICAL CELLS IN AINDRA DATASET.
Sample cells
Total cells
A. Detection of nuclei in multi-cell images
For detection of nuclei in multi-cell images, we propose a
straightforward algorithm applied on the V channel of HSV
(Hue, Saturation, Value) color space of the images. Here
we neglect the color information because of the presence of
extreme color variation in the stains, as can be seen in Table
II. The process is divided into three steps: 1) The PAP-smear
images are generally noisy as can be seen in Figure 2. Hence,
we apply median ﬁltering with a 5×5 window. 2) To improve
the contrast and accentuate the differences between nucleus
and background, we apply contrast-limited adaptive histogram
equalization (CLAHE ). 3) Finally a global threshold, is
applied which localizes the nuclei. We note that the detection
is required only for the Aindra dataset. The Herlev dataset
 , consists of such detected single cell images.
B. Segmentation of nuclei in single-cell PAP-smear images
We propose a segmentation method comprising broadly
of two steps i.e selective pre-processing followed by patchbased classiﬁcation using CNN, as described in the following
subsections. We have reported this method in . However,
for self sufﬁciency, we also brieﬂy discuss it here. We note
Figure 2. Nuclei detection (a) Multi-cell image, (c) V channel after contrast
adjustment by CLAHE, (d) Detected nuclei by a global threshold
that the approach assumes that the cell detection is already
carried out, and thus operates on single-cell images.
1) Cell separation and selective pre-processing: Often, a
contrast enhancement pre-processing aids the segmentation
task. While this is useful for small and uniform nuclei, in this
case, in most cells with larger nuclei due to the irregularity of
chromatin pattern, pre-processing hinders good segmentation
as it also increases the intra-nuclear contrast (within the
nucleus) (see Figure 3). Thus, we suggest that the cells with
small and compact nuclei need pre-processing, while those
with bigger nuclei and irregular chromatin pattern don’t.
Pre-processing. (a, c) Original Image: Carcinoma in-situ, Normal
intermediate (b, d) Respective pre-processed image with ground truth overlapped, Note that pre-processing on (a) increases the contrast within the nuclei,
while on (c) increases the contrast between the nuclei and the background.
We propose feature-based cell separation method where
we compute homogeneity of the original images, and
use a threshold on its value for separating the cell images
in two categories. Thus, images with relatively homogeneous
and compact nuclei are passed on for pre-processing, before
computing the ﬁnal segmentation via CNN. For images with
irregular nuclei, no pre-processing is done.
2) Patch-based CNN: For segmentation, we train two independent CNNs from scratch, one operating on patches from
the pre-processed images and the other on patches from
non-preprocessed images. During the testing phase, after cell
separation, the images are passed on to the respective CNN.
We convert our 2-class classiﬁcation problem (nucleus vs
background) into a 3-class problem among nucleus (interior),
edge (boundary) and background classes . The details of
the overall approach can be found in .
C. Classiﬁcation with detected nuclei
In this section, we explore different strategies and scenarios
for the classiﬁcation of nuclei in cervical cell images.
1) Multi-class classiﬁcation using transfer learning: Considering the success of deep learning methodologies in recent
years for the task of classiﬁcation, we too explore their
application in our work. The PAP-smear images generally have
a large appearance variation in terms of both contrast and color
in the normal and abnormal cells. Furthermore, in medical
imaging applications, very few annotated images are available,
in the range of hundreds, as opposed to the millions of natural
images available for other applications . To overcome the
aforementioned difﬁculties, we make use of the concept of
transfer learning where the ﬁlters learned by a CNN, pretrained on ImageNet consisting of millions of images, are
directly used for classiﬁcation in some other domain (medical
images in our case). This strategy helps us in two ways: 1) It
mitigates the dependency of deep CNNs on huge amount of
annotated training data. 2) It effectively reduces the training
time required for training a CNN from scratch.
It is shown in literature that the lower level convolutional
layers learn the low-level primitive features such as gradients,
texture etc., and the deeper layers, learn the high-level data
speciﬁc semantic features . Considering the hypothesis that
semantic features may not be important for cell classiﬁcation,
we explore for classiﬁcation, the outputs from the ﬁlters
learned by Alexnet at last (conv5), intermediate (conv3)
and ﬁrst (conv1) convolutional layers followed by two fully
connected layers which we retrain, one consisting of 256
neurons and the last layer consisting of number of neurons
equal to number of classes. We refer to these new transferlearning based networks in the rest of the paper as conv5T
(Figure 4), conv3T (Figure 5) and conv1T (Figure 6).
Figure 4. conv5T: features from ﬁfth convolutional layer of Alexnet.
Figure 5. conv3T:features from third convolutional layer of Alexnet
Figure 6. conv1T: features from ﬁrst convolutional layer of Alexnet
2) Decision-tree based classiﬁcation using transfer learning: Considering certain similarities and differences between
some classes, we propose a decision-tree based approach for
classifying the cell images in a hierarchical way as shown
in Figure 7. At the ﬁrst node, a two-class classiﬁcation is
done between the normal and abnormal classes. This is also
important from the perspective of a screening system where
only the difference between normal and abnormal classes can
also be considered important. Additionally, once we have a
good classiﬁcation between the normal and abnormal class,
we can classify the abnormal cells into further gradations of
abnormalities. We achieve this in the daughter nodes where
at the second level we discriminate between the highest level
of abnormal class with other classes. Next, we discriminate
between the lowest level of abnormal class with the remaining
classes. Finally, at the leaf node, we discriminate between the
leftover abnormal classes. The number of levels in the tree
is based on the number of gradations of abnormalities in the
dataset. At each node, we use a CNN with conv1T architecture
(Figure 6) for classiﬁcation.
Figure 7. Decision-tree based approach for classiﬁcation
3) Classiﬁcation of detected nuclei in multi-cell images
using transfer learning: Following the success of CNN-based
classiﬁcation approach, we apply the transfer learning based
methodology to the real-world multi-cell PAP-smear images.
After detecting the nuclei with the help of detection algorithm
mentioned, we extract the detected nuclei regions as subimages using bounding boxes around the connected components. These sub-images are now passed on for classiﬁcation
to a CNN whose features for the ﬁrst convolutional layer
are extracted directly from the ﬁrst convolutional layer of the
pre-trained Alexnet. Because there can be large variations in
multi-cell images, overﬁtting can occur. To reduce the chances
of overﬁtting, we use two techniques: 1) By appending a
few untrained convolutional layers before the fully connected
layers, the number of nodes in the fully connected layers are
reduced and hence the number of parameters to be trained in
the network are reduced. 2) Using max-pooling dropout after
every untrained convolutional layer .
4) Classiﬁcation with segmented nuclei: For classiﬁcation
on segmented nuclei images with conv1T architecture. From
the detected cells, the nuclei is segmented and the background
values are replaced by 255. These images are now fed into the
conv1T architecture, assisting it by emphasizing the nucleus
features. Here, we also pose the question if the exact segmentation is needed for classiﬁcation and demonstrate the answer
through experimentation with and without segmentation of
nuclei in single-cell images.
IV. EXPERIMENTS AND RESULTS
We now discuss various experiments for detection, segmentation and different classiﬁcation scenarios. In all the
experiments involving supervised learning (segmentation and
classiﬁcation), we have used 70% of images from each class
are used for training, 15% for validation and remaining 15%
for testing. The results are reported over a 5 random training,
validation and testing sets.
A. Evaluation metrics
For segmentation, we have quantiﬁed the boundary of
segmented nuclei using pixel-based F-score . For comparisons with other segmentation techniques, we use Zijdenbos
similarity index (ZSI) .
For classiﬁcation, based on the ground-truth label information in the datasets, we consider 2 problems i.e 2-class classiﬁcation in Herlev and Aindra datasets and 7-class classiﬁcation
in Herlev dataset. We use accuracy for quantiﬁcation of classiﬁcation approaches on both 2-class and 7-class classiﬁcation
problems. The overall accuracy is computed as the fraction of
correctly classiﬁed cells over all classes .
B. Cervical cell nuclei detection results on Aindra dataset
After obtaining the output from nuclei detection algorithm
on multi-cell images, a bounding box with a padding of 20
pixels on 4 sides around each connected component is used to
capture a sub-image containing the nuclei. These sub-images
are labeled as normal/abnormal nuclei based on the ground
truth annotations. The visual results for nuclei detection on
Aindra dataset are shown in Table III. We observe that in most
cases the detected cells indeed focuses on a single cell-nuclei,
with some cell and background regions.
NUCLEI DETECTION ON AINDRA DATASET. NORMAL AND ABNORMAL
DETECTED NUCLEI ARE MARKED WITH GREEN AND RED RESPECTIVELY.
Original Image
Detected nuclei
Normal nuclei
Abnormal nuclei
C. Cervical cell nuclei segmentation results
We provide the quantitative effectiveness of the proposed
segmentation algorithm on Herlev dataset. We have used an
architecture similar to that of VGGNet for both our CNNs
i.e CNN trained without pre-processed images (CNNw1) and
CNN trained with pre-processed images. (CNNp1).
In Table IV, we compare ﬁnal results of our approach
(row1) with its counterpart without selective pre-processing i.e
with 1) same pre-processing on all images (row3) 2) no preprocessing on any image (row2), which further stresses on the
importance of cell separation step. We compare the results
of CNN with 2 classes (nucleus and background, without
the boundary class) with similar architecture as CNNw1 and
CNNp1 and homogeneity-based cell separation technique (row
4). The results clearly show that a CNN with 2 class does not
perform well. Therefore, the third class has signiﬁcant effect in
disambiguating the boundary class. We note that our method
performs better than the state of the art FCM based technique
 , which also reports F-scores for individual classes.
We provide ZSI comparisons in Table V with various
contemporary methods which are also compared in . We
note that the performance of the proposed approach is better
than some of the contemporary methods (FCM , Threshold
 & Hierarchical tree ) and comparable to the best (MRF
 & RGVF ). Some visual results for the algorithm are
shown in Figure 8, where the segmentation map obtained is
also shown with 3 classes i.e nuclei, edge and background.
CLASS-WISE F-SCORES FOR NUCLEUS SEGMENTATION RESULTS FOR HERLEV DATASET.
Proposed: feature-based CS with Homogeneity
Without cell separation: no pre-processing on any image
Without cell separation: same pre-processing on all images
2-class CNN with homogeneity based CS
PIXEL-BASED ZSI COMPARISON
Threshold 
Hierarchical tree 
Nucleus segmentation.
(a),(e),(i) Original images of different
sizes, (b),(f),(j) Segmentation map produced by CNN, where blue, cyan
& yellow color represents nucleus, edge and boundary pixels respectively,
(c),(g),(k) Final segmentation map, (d),(h),(l) Ground truth.
D. Cervical cell classiﬁcation results
1) With detected nuclei using transfer learning: For multiclass classiﬁcation using transfer learning, we explore the
architectures conv5T, conv3T and conv1T given in Figure
4, 5 and 6 where we use the outputs from the ﬁfth, third
and ﬁrst convolutional layers of Alexnet, respectively. After
getting the respective outputs from pre-trained Alexnet, we
train the fully connected layers with a 256-neuron hidden
layer and a ﬁnal output layer with number of neurons equal to
the number of classes. Because of high dimensional outputs
from the convolution layers of Alexnet, the number of weights
to be trained are huge (in the range of 1 million), hence
we use data augmentation on the training data. We also use
data augmentation on validation data to reduce the extreme
ﬂuctuations in validation accuracy while training. After this,
we end up with 12,000 examples for training and 3000 for
validation. We use 5 random sets of training, validation and
testing data for the experimentation and report the average
results in Figure 9. All three of these networks are trained for
200 epochs and mean squared error as loss function.
Activation map from different convolutional layers of
Alexnet for an example image are shown in Figure 10. It can
be seen that the activation map from the ﬁrst convolutional
layer learns the prominant texture features from the images
as opposed to the third and ﬁfth convolutional layers. This
observation supports the hypothesis that for cell images, as
the depth of the network increases, the high-level features
do not seem informative. This also supports our motivation
to select Alexnet consisting of smaller number of layers. We
provide the average training, validation and testing accuracies
for the 7-class classiﬁcation, over 5 random trials for different
architectures in Figure 9. The constant increase in accuracies
from conv5T to conv1T shows that the cell classiﬁcation
problem performs better with low-level features rather than
those at the deeper levels. We believe this is an interesting
and important insight, as typical deep learning approaches only
consider the last layer features for classiﬁcation.
2) With detected nuclei using decision-tree: Next, we explore the results of decision-tree based classiﬁcation using
transfer learning. Because of the transfer learning with conv1T
giving the best results, we report the decision-tree based
classiﬁcation results with the architecture given in Figure 6.
The overall accuracies at each stage with transfer learning are
given in Table VI. We note that the decision-tree based method
with transfer learning gives high accuracy at each stage.
ACCURACIES AT DIFFERENT STAGE OF DECISION-TREE BASED APPROACH
USING TRADITIONAL AND DEEP LEARNING BASED METHODS.
3) Classiﬁcation on Aindra dataset: After detection of
nuclei in multi-cell images of Aindra dataset, we use transfer
learning for classiﬁcation. The connected components obtained
from the nuclei detection step are extracted by taking a bounding box around the detected nuclei. A padding of 20 pixels
from all four sides is applied on the actual seed region bounding box. These sub-images are labeled as normal/abnormal
based on the overlap with the ground truth. Next, 3 random
training and validation sets are created based on the whole
slide images, which are passed on to the transfer learning
architecture for classiﬁcation into normal/abnormal classes.
The mean training and validation accuracies are reported in
Table VII. The training and validation accuracies are quite
good considering that the Aindra dataset is complex in terms
of contrast variation and artifacts.
4) With segmented nuclei: Considering the best results with
conv1T architecture, we now explore the test accuracies using
conv1T with segmented nuclei Herlev dataset for 7 class
Figure 9. 7-class CNN accuracies with transfer learning on Herlev dataset
Figure 10. Activation maps: Left to Right: Conv1, Conv3 and Conv5 activation maps for Normal superﬁcial cell images.
TRAINING AND VALIDATION ACCURACIES ON AINDRA DATASET AFTER
NUCLEI DETECTION
Training accuracy
Validation accuracy
classiﬁcation. For this, we keep the original nuclei intensity
values and set the background values as 255. The results of
classiﬁcation with ground-truth and proposed segmentations,
and using the full cell images (without segmentation) are
shown in Table VIII. The results clearly demonstrate that
with segmentation the performance is rather limited, and
suggests that the contextual information in images with nuclei
detections, may be important for good classiﬁcation. Thus,
it indicates that, as far as the classiﬁcation performance is
concerned, an easier nuclei detection process may be sufﬁcient
rather than a sophisticated segmentation approach.
Table VIII
ACCURACIES FOR SEGMENTED AND NON SEGMENTED CELL IMAGES.
segmentation
With ground truth
segmentation
With segmentation using
proposed method
5) Comparisons: In Table IX, we compare the results of
our classiﬁcation approaches on Herlev dataset for 2-class
classiﬁcation problem with the following existing methods:
1) Benchmark results in , 2) Ensemble learning for three
classiﬁers , 3) Particle swarm feature selection and 1nearest neighbor as classiﬁer , 4) Genetic algorithm feature
selection , 5) Artiﬁcial neural network with 9 cell-based
features and 6) Transfer learning by training a new
architecture (ConvNet-T) from scratch . We note that our
results with conv1T surpass all of the existing algorithms and
are quite close to the results with ANN in . This might
suggest that this is the best accuracy that can be reached
for this dataset. For 7-class classiﬁcation problem in Herlev
dataset, we provide a comparison in Table X. The results show
that our approach surpasses the benchmark results and the
results are extremely close to that of ANN .
We stress on the fact that our approach is comparatively
easier (segmentation-free) and faster than that of wherein
both nuclei and cytoplasm are segmented, whereas we pass
on the cell images directly to a CNN trained with transfer
learning. Also, we note that our approach is arguably better
than the similar approaches stated in in terms of training
time where they train their CNN architecture from scratch and
we only train the fully connected layers.
V. CONCLUSION
In this paper, we reported a PAP-smear image analysis
system for cervical cancer screening for both single and multicell images. The image analysis generally consists of three
steps: detection, segmentation and classiﬁcation. We propose
a simple nuclei detection algorithm for multi-cell images, and
a patch-based CNN approach with selective pre-processing for
segmentation. This approach results in an overall F-score of
0.90 on Herlev dataset. For classiﬁcation, we propose featurelevel analysis using transfer learning on Alexnet on both single
and multi-cell images. A decision-tree based classiﬁcation is
proposed as an alternative to the multi-class classiﬁcation. Further, we prove through experimentation that accurate segmentation is not necessary for classiﬁcation with deep learning.
We obtain state-of-the-art classiﬁcation accuracy on Herlev
for 2-class (99.3%) and for 7-class classiﬁcation (93.75%).
2-CLASS CLASSIFICATION (NORMAL VS ABNORMAL) ON HERLEV DATASET
Proposed:conv1T
Benchmark 
Ensemble 
PSO-1nn 
GEN-1nn 
ConvNet-T 
7-CLASS CLASSIFICATION ON HERLEV DATASET
Proposed (conv1T)
Benchmark 
ACKNOWLEDGMENT
We acknowledge the support of Aindra Systems Pvt. Ltd.
for funding this research and regular discussions.