RTG: A Recursive Realistic Graph Generator
using Random Typing
Leman Akoglu
Christos Faloutsos
Carnegie Mellon University
School of Computer Science
{lakoglu, christos}@cs.cmu.edu
Abstract. We propose a new, recursive model to generate realistic graphs,
evolving over time. Our model has the following properties: it is (a) ﬂexible, capable of generating the cross product of weighted/unweighted, directed/undirected, uni/bipartite graphs; (b) realistic, giving graphs that
obey eleven static and dynamic laws that real graphs follow (we formally
prove that for several of the (power) laws and we estimate their exponents as a function of the model parameters); (c) parsimonious, requiring
only four parameters. (d) fast, being linear on the number of edges; (e)
simple, intuitively leading to the generation of macroscopic patterns. We
empirically show that our model mimics two real-world graphs very well:
Blognet (unipartite, undirected, unweighted) with 27K nodes and 125K
edges; and Committee-to-Candidate campaign donations (bipartite, directed, weighted) with 23K nodes and 880K edges. We also show how to
handle time so that edge/weight additions are bursty and self-similar.
Introduction
Study of complex graphs such as computer and biological networks, the link
structure of the WWW, the topology of the Internet, and recently with the
widespread use of the Internet, large social networks, has been a vital research
area. Many fascinating properties have been discovered, such as small and shrinking diameter , power-laws , and community structures . As a result of such interesting patterns being discovered, and
for many other reasons which we will discuss next, how to ﬁnd a model that
would produce synthetic but realistic graphs is a natural question to ask. There
are several applications and advantages of modeling real-world graphs:
– Simulation studies: if we want to run tests for, say a spam detection algorithm, and want to observe how the algorithm behaves on graphs with
diﬀerent sizes and structural properties, we can use graph generators to produce such graphs by changing the parameters. This is also true when it is
diﬃcult to collect any kind of real data.
– Sampling/Extrapolation: we can generate a smaller graph for example for
visualization purposes or in case the original graph is too big to run tests
on it; or conversely to generate a larger graph for instance to make future
prediction and answer what-if questions.
Leman Akoglu
Christos Faloutsos
– Summarization/Compression: model parameters can be used to summarize
and compress a given graph as well as to measure similarity to other graphs.
– Motivation to understand pattern generating processes: graph generators give
intuition and shed light upon what kind of processes can (or cannot) yield the
emergence of certain patterns. Moreover, modeling addresses the question of
what patterns real networks exhibit that needs to be matched and provides
motivation to ﬁgure out such properties.
Graph generator models are surveyed in . Ideally, we would like a graph
generator that is:
1. simple: it would be easy to understand and it would intuitively lead to the
emergence of macroscopic patterns.
2. realistic: it would produce graphs that obey all the discovered “laws” of
real-world graphs with appropriate values.
3. parsimonious: it would require only a few number of parameters.
4. ﬂexible: it would be able to generate the cross product of weighted/unweighted,
directed/undirected and unipartite/bipartite graphs.
5. fast: the generation process would ideally take linear time with respect to
the number of edges in the output graph.
In this paper we propose RTG, for Random Typing Generator. Our model
uses a process of ‘random typing’, to generate source- and destination- node
identiﬁers, and it meets all the above requirements. In fact, we show that it can
generate graphs that obey all eleven patterns that real graphs typically exhibit.
Next, we provide a survey on related work. Section 3 describes our RTG
generator in detail. Section 4 provides experimental results and discussion. We
conclude in Section 5. Appendix gives proofs showing some of the power-laws
that the model generates.
Related Work
Graph patterns: Many interesting patterns that real graphs obey have been
found, which we give a detailed list of in the next section. Ideally, a generator
should be able to produce all of such properties.
Graph generators: The vast majority of earlier graph generators have focused
on modeling a small number of common properties, but fail to mimic others.
Such models include the Erdos & Renyi model , the preferential attachment
model and numerous more, like the ‘small-world’, ‘winners don’t take all’,
‘forest ﬁre’ and ‘butterﬂy’ models . See for a recent survey and
discussion. In general, these methods are limited in trying to model some static
network property while neglecting others as well as dynamic properties or cannot
be generalized to produce weighted graphs.
Random dot product graphs assign each vertex a random vector in
some d-dimensional space and an edge is put between two vertices with probability equal to the dot product of the endpoints. This model does not generate
RTG: A Recursive Realistic Graph Generator using Random Typing
weighted graphs and by deﬁnition only produces undirected graphs. It also seems
to require the computation of the dot product for each pair of nodes which takes
quadratic time.
A diﬀerent family of models is utility-based, where agents try to optimize
a predeﬁned utility function and the network structure takes shape from their
collective strategic behavior . This class of models, however, is usually
hard to analyze.
Kronecker graph generators and their tensor followups are successful
in the sense that they match several of the properties of real graphs and they
have proved useful for generating self-similar properties of graphs. However, they
have two disadvantages: The ﬁrst is that they generate multinomial/lognormal
distributions for their degree and eigenvalue distribution, instead of a power-law
one. The second is that it is not easy to grow the graph incrementally: They
have a ﬁxed, predetermined number of nodes (say, N k, where N is the number
of nodes of the generator graph, and k is the number of iterations); where adding
more edges than expected does not create additional nodes. In contrast, in our
model, nodes emerge naturally.
Proposed Model
We ﬁrst give a concise list of the static and dynamic ‘laws’ that real graphs obey,
which a graph generator should be able to match.
L01 Power-law degree distribution: the degree distibution should follow a powerlaw in the form of f(d) ∝dγ, with the exponent γ < 0 
L02 Densiﬁcation Power Law (DPL): the number of nodes N and the number
of edges E should follow a power-law in the form of E(t) ∝N(t)α, with
α > 1, over time .
L03 Weigth Power Law (WPL): the total weight of the edges W and the number
of edges E should follow a power-law in the form of W(t) ∝E(t)β, with
β > 1, over time .
L04 Snapshot Power Law (SPL): the total weight of the edges Wn attached to
each node and the number of such edges, that is, the degree dn should follow
a power-law in the form of Wn ∝dθ
n, with θ > 1 .
L05 Triangle Power Law (TPL): the number of triangles ∆and the number of
nodes that participate in ∆number of triangles should follow a power-law
in the form of f(∆) ∝∆σ, with σ < 0 .
L06 Eigenvalue Power Law (EPL): the eigenvalues of the adjacency matrix of
the graph should be power-law distributed .
L07 Principal Eigenvalue Power Law (λ1PL): the largest eigenvalue λ1 of the
adjacency matrix of the graph and the number of edges E should follow a
power-law in the form of λ1(t) ∝E(t)δ, with δ < 0.5, over time .
L08 small and shrinking diameter: the (eﬀective) diameter of the graph should
be small with a possible spike at the ‘gelling point’ . It should also
shrink over time .
Leman Akoglu
Christos Faloutsos
L09 constant size secondary and tertiary connected components: while the ‘giant
connected component’ keeps growing, the secondary and tertiary connected
components tend to remain constant in size with small oscillations .
L10 community structure: the graph should exhibit a modular structure, with
nodes forming groups, and possibly groups within groups .
L11 bursty/self-similar edge/weight additions: Edge (weight) additions to the
graph over time should be self-similar amd bursty rather than uniform with
possible spikes .
Zipf introduced probably the earliest power law , stating that, in many
natural languages, the rank r and the frequency fr of vocabulary words follow
a power-law fr ∝1/r. Mandelbrot argued that Zipf‘s law is the result
of optimizing the average amount of information per unit transmission cost.
Miller showed that a random process also leads to Zipf-like power laws. He
suggested the following experiment: “A monkey types randomly on a keyboard
with k characters and a space bar. A space is hit with probability q; all other
characters are hit with equal probability,
. A space is used to separate
words”. The resulting words of this random typing process follow a power-law.
Conrad and Mitzenmacher showed that this relation still holds when the keys
are hit with unequal probability.
Our model generalizes the above model of natural human behavior, using
‘random typing’. We build our model RTG (Random Typing Generator) in three
steps, incrementally. In the next two steps, we introduce the base version of the
proposed model to give an insight. However, as will become clear, it has two
shortcomings in matching desired real-world properties. In particular, the base
model does not capture (1) homophily, and (2) community structure.
RTG-IE: RTG with Independent Equiprobable keys
In Miller’s experimental setting, we propose each unique word typed by the monkey to represent a node in the output graph (one can think of each unique word
as the label of the corresponding node). To form links between nodes, we mark
the sequence of words as ‘source’ and ‘destination’, alternatingly. That is, we
divide the sequence of words into groups of two and link the ﬁrst node to the
second node in each pair. If two nodes are already linked, the weight of the edge
is simply increased by 1. Therefore, if W words are typed, the total weight of the
output graph is W/2. See Figure 1 for an example illustration. Intuitively, random typing introduces new nodes to the graph as more words are typed, because
the possibility of generating longer words increases with increasing number of
words typed.
Due to its simple structure, this model is very easy to implement and is
indeed mathematically tractable: If W words are typed on a keyboard with k
keys and a space bar, the probability p of hitting a key being the same for all keys
and the probability of hitting the space bar being denoted as q=(1 −kp):
RTG: A Recursive Realistic Graph Generator using Random Typing
Destination
ab a bba ab b ab a b ab a
Fig. 1. Illustration of the RTG-IE. Upper left: how words are (recursively) generated
on a keyboard with two equiprobable keys, ‘a’ and ‘b’, and a space bar; lower left:
a keyboard is used to randomly type words, separated by the space character; upper
right: how words are organized in pairs to create source and destination nodes in the
graph over time; lower right: the output graph; each node label corresponds to a unique
word, while labels on edges denote weights.
Lemma 1. The expected number of nodes N in the output graph G of the RTG-
IE model is
N ∝W −logpk.
Proof: In the Appendix.
Lemma 2. The expected number of edges E in the output graph G of the RTG-
IE model is
E ≈W −logpk ∗(1 + c′logW),
for c′ = q−logpk
−logp > 0.
Proof: In the Appendix.
Lemma 3. The in(out)-degree dn of a node in the output graph G of the RTG-
IE model is power law related to its total in(out)-weight Wn, that is,
Wn ∝d−logkp
with expected exponent −logkp > 1.
Proof: In the Appendix.
Even though most of the properties listed at the beginning of this section are
matched, there are two problems with this model: (1) the degree distribution
follows a power-law only for small degrees and then shows multinomial characteristics (See Figure 2), and (2) it does not generate homophily and community
structure, because it is possible for every node to get connected to every other
node, rather than to ‘similar’ nodes in the graph.
Leman Akoglu
Christos Faloutsos
Fig. 2. Top row: Results of RTG-IE (k = 5, p = 0.16, W = 1M). The problem with
this model is that in(out)-degrees form multinomial clusters (left). This is because
nodes with labels of the same length are expected to have the same degree. This can
be observed on the rank-frequency plot (right) where we see many words with the
same frequency. Notice the ‘staircase eﬀect’. Bottom row: Results of RTG-IU (k = 5,
p = [0.03, 0.05, 0.1, 0.22, 0.30], W = 1M). Unequal probabilities introduce smoothing
on the frequency of words that are of the same length (right). As a result, the degree
distribution follows a power-law with expected heavy tails (left).
RTG-IU: RTG with Independent Un-equiprobable keys
We can spread the degrees so that nodes with the same-length but otherwise
distinct labels would have diﬀerent degrees by making keys have unequal probabilities. This procedure introduces smoothing in the distribution of degrees,
which remedies the ﬁrst problem introduced by the RTG-IE model. In addition,
thanks to , we are still guaranteed to obtain the desired power-law characteristics as before. See Figure 2.
RTG: Random Typing Graphs
What the previous model fails to capture is the homophily and community structure. In a real network, we would expect nodes to get connected to similar nodes
(homophily), and form groups and possibly groups within groups (modular structure). In our model, for example on a keyboard with two keys ‘a’ and ‘b’, we
would like nodes with many ‘a’s in their labels to be connected to similar nodes,
as opposed to nodes labeled with many ‘b’s. However, in both RTG-IE and
RTG: A Recursive Realistic Graph Generator using Random Typing
RTG-IU it is possible for every node to conenct to every other node. In fact, this
yields a tightly connected core of nodes with rather short labels.
Our proposal to ﬁx this is to envision a two-dimensional keyboard that generates source and destination labels in one shot, as shown in Figure 3. The previous
model generates a word for source, and, completely independently, another word
for destination. In the example with two keys, we can envision this process as
picking one of the nine keys in Figure 3(a), using the independence assumption:
the probability for each key is the product of the probability of the corresponding row times the probability of the corresponding column: pl for letter l, and
q for space (‘S’). After a key is selected, its row character is appended to the
source label, and the column character to the destination label. This process
repeats recursively as in Figure 3(b), until the space character is hit on the ﬁrst
dimension in which case the source label is terminated and also on the second
dimension in which case the destination label is terminated.
prob(a*,a*) =
pa – prob(a*,b*)
– prob(a*,S)
prob(b*,b*) =
pb – prob(b*,a*)
– prob(b*,S)
prob(S,S) =
q – prob(S,a*)
– prob(S,b*)
(a) ﬁrst level
(b) recursion
(c) communities
Fig. 3. The RTG model: random typing on a 2-d keyboard, generating edges (sourcedestination pairs). See Algorithm 1. (a) an example 2-d keyboard (nine keys), hitting a
key generates the row(column) character for source(destination), shaded keys terminate
source and/or destination words. (b) illustarates recursive nature. (c) the imbalance
factor β favors diagonal keys and leads to homophily.
In order to model homophily and communities, rather than assigning crossproduct probabilities to keys on the 2-d keyboard, we introduce an imbalance
factor β, which will decrease the chance of a-to-b edges, and increase the chance
for a-to-a and b-to-b edges, as shown in Figure 3(c). Thus, for the example that
we have, the formulas for the probabilities of the nine keys become:
prob(a, b) = papbβ prob(a, S) = paqβ prob(a, a) = pa −(prob(a, b) + prob(a, S))
prob(b, a) = pbpaβ prob(b, S) = pbqβ prob(b, b) = pb −(prob(b, a) + prob(b, S))
prob(S, a) = qpaβ prob(S, b) = qpbβ prob(S, S) = q −(prob(S, a) + prob(S, b))
By boosting the probabilities of the diagonal keys and downrating the probabilities of the oﬀ-diagonal keys, we are guaranteed that nodes with similar labels
will have higher chance to get connected. The pseudo-code of generating edges
as described above is shown in Algorithm 1.
Leman Akoglu
Christos Faloutsos
Next, before showing the experimental results of RTG, we take a detour to
describe how we handle time so that edge/weight additions are bursty and selfsimilar. We also discuss the generalizations of the model in order to produce all
types of uni/bipartite, (un)weighted, and (un)directed graphs.
Algorithm 1 RTG
Input: k, q, W, β
Output: edge-list L for output graph G
1: Initialize (k + 1)-by-(k + 1) matrix M with cross-product probabilities
2: // in order to ensure homophily and community structure
3: Multiply oﬀ-diagonal probabilities by β, 0 < β < 1
4: Boost diagonal probabilities such that sum of row(column) probabilities remain
5: Initialize edge list L
6: for 1 to W do
L1, L2 ←SelectNodeLabels(M)
Append L1, L2 to L
9: end for
11: function SelectNodeLabels (M) : L1, L2
12: Initialize L1 and L2 to empty string
13: while not terminated L1 and not terminated L2 do
Pick a random number r, 0 < r < 1
if r falls into M(i, j), i ≤k, j ≤k then
Append character ‘i’ to L1 and ‘j’ to L2 if not terminated
else if r falls into M(i, j), i ≤k, j=k + 1 then
Append character ‘i’ to L1 if not terminated
Terminate L2
else if r falls into M(i, j), i=k + 1, j ≤k then
Append character ‘j’ to L2 if not terminated
Terminate L1
Terminate L1 and L2
26: end while
27: Return L1 and L2
28: end function
Burstiness and Self-similarity
Most real-world traﬃc as well as edge/weight additions to real-world graphs
have been found to be self-similar and bursty . Therefore, in this
section we give a brief overview of how to aggregate time so that edge and
weight additions, that is ∆E and ∆W, are bursty and self-similar.
Notice that when we link two nodes at each step, we add 1 to the total weight
W. So, if every step is represented as a single time-tick, the weight additions are
RTG: A Recursive Realistic Graph Generator using Random Typing
uniform. However, to generate bursty traﬃc, we need to have a bias factor b> 0.5,
such that b-fraction of the additions happen in one half and the remaining in the
other half. We will use the b-model , which generates such self-similar and
bursty traﬃc. Speciﬁcally, starting with a uniform interval, we will recursively
subdivide weight additions to each half, quarter, and so on, according to the
bias b. To create randomness, at each step we will randomly swap the order of
fractions b and (1 −b).
Among many methods that measure self-similarity we use the entropy plot ,
which plots the entropy H(r) versus the resolution r. The resolution is the scale,
that is, at resolution r, we divide our time interval into 2r equal sub-intervals,
compute ∆E in each sub-interval k(k = 1 . . . 2r), normalize into fractions pk =
E , and compute the Shannon entropy H(r) of the sequence pk. If the plot H(r)
is linear, the corresponding time sequence is said to be self-similar, and the slope
of the plot is deﬁned as the fractal dimension fd of the time sequence. Notice
that a uniform ∆distribution yields fd=1; a lower value of fd corresponds to
a more bursty time sequence, with a single burst having the lowest fd=0: the
fractal dimension of a point.
Generalizations
We can easily generalize RTG to model all type of graphs. To generate undirected
graphs, we can simply assume edges from source to destination to be undirected
as the formation of source and destination labels is the same and symmetric.
For unweighted graphs, we can simply ignore duplicate edges, that is, edges
that connect already linked nodes. Finally, for bipartite graphs, we can use two
diﬀerent sets of keys such that on the 2-d keyboard, source dimension contains
keys from the ﬁrst set, and the destination dimension from the other set. This
assures source and destination labels to be completely diﬀerent, as desired.
Experimental Results
The question we wish to answer here is how RTG is able to model real-world
graphs. The datasets we used are:
Blognet: a social network of blogs based on citations (undirected, unipartite and
unweighted with N=27, 726; E=126, 227; over 80 time ticks).
Com2Cand: the U.S. electoral campaign donations network from organizations
to candidates (directed, bipartite and weighted with N=23, 191; E=877, 721;
and W=4, 383, 105, 580 over 29 time ticks). Weights on edges indicate donated
dollar amounts.
In Figures 4 and 5, we show the related patterns for Blognet and Com2Cand
as well as synthetic results, respectively. In order to model these networks, we
ran experiments for diﬀerent parameter values k, q, W, and β. Here, we show the
closest results that RTG generated, though ﬁtting the parameters is a challenging
future direction. We observe that RTG is able match the long wish-list of static
and dynamic properties for the two real graphs.
Leman Akoglu
Christos Faloutsos
In order to evaluate community structure, we use the modularity measure
in . Figure 6(left) shows that modularity increases with smaller imbalance
factor β. Without any imbalance, β=1, modularity is as low as 0.35, which
indicates that no signiﬁcant modularity exists. In Figure 6(right), we also show
the running time of RTG wrt the number of duplicate edges (that is, number of
iterations W). Notice the linear growth with increasing W.
(a) diameter
(b) components
(c) degrees
(f) entropy ∆E
(a) L08 diameter
(b) L09 components (c) L01 degree distr.
(d) L05 TPL
(e) L02 DPL
(f) L11 entropy ∆E
(g) L07 λ1PL
(h) L06 EPL
Fig. 4. Top two rows: properties of Blognet: (a) small and shrinking diameter; (b)
largest 3 connected components; (c) degree distribution; (d) triangles ∆vs number
of nodes with ∆triangles; (e) densiﬁcation; (f) bursty edge additions; (g) largest 3
eigenvalues wrt E; (h) rank spectrum of the adjacency matrix. Bottom two rows:
results of RTG. Notice the similar qualitative behavior for all eight laws.
RTG: A Recursive Realistic Graph Generator using Random Typing
(a) diameter
(b) components
(c) degree distr.
(e) D(W)PL
(f) entropy ∆W(E)
(a) L08 diameter
(b) L09 components
(c) L01 degree distr.
(d) L04 SPL
(e) L02, L03 D(W)PL (f) L11 entropy ∆W(E)
(g) L07 λ1PL
(h) L06 EPL
Fig. 5. Top two rows: properties of Com2Cand; as opposed to Blognet, Com2Cand is
weighted. So, diﬀerent from above we show: (d) node weight vs in(inset: out)degree; (e)
total weight vs number of edges(inset); (f) bursty weight additions(inset); Bottom two
rows: results of RTG. Notice the similar qualitative behavior for all nine laws.
Conclusion
We have designed a generator that meets all the ﬁve desirable properties in the
introduction. Particularly, our model is
1. simple and intuitive, yet it generates the emergent, macroscopic patterns
that we see in real graphs.
Leman Akoglu
Christos Faloutsos
modularity
Fig. 6. Left: modularity score vs. imbalance factor β, modularity increases with decreasing β. For β=1, the score is very low indicating no signiﬁcant modularity. Right:
computation time vs. W, time grows linearly with increasing number of iterations W.
2. realistic, generating graphs that obey all eleven properties that real graphs
obey - no other generator has been shown to achieve that.
3. parsimonious, requiring only a handful of parameters.
4. ﬂexible, capable of generating weighted/unweighted, directed/undirected,
and bipartited/unipartite graphs, and any combination of the above.
5. fast, being linear on the number of iterations (on a par with the number of
duplicate edges in the output graph).
Moreover, we showed how well RTG can mimic some large, real graphs. We
have also proven that an early version of RTG generates several of the desired
(power) laws, formulated in terms of model parameters.
Consider the following setting: W words are typed on a keyboard with k keys
and a space bar, the probability of hitting a key p being the same for all keys and
probability of hitting the space bar being denoted as q=(1 −kp), in the output
graph G of the RTG-IE model:
Lemma 1. The expected number of nodes N is
N ∝W −logpk.
Proof. Given the number of words W, we want to ﬁnd the expected number of
nodes N that the RTG-IE graph consists of. This question can be reformulated
as follows: ”Given W words typed by a monkey on a keyboard with k keys and
a space bar, what is the size of the vocabulary V ?” The number of unique words
V is basically equal to the number of nodes N in the output graph.
Let w denote a single word generated by the deﬁned random process. Then,
w can recursively be written as follows: “w : ciw|S”, where ci is the character
that corresponds to key i, 1 ≤i ≤k, and S is the space character. So, V as a
RTG: A Recursive Realistic Graph Generator using Random Typing
function of model parameters can be formulated as:
V (W) = V (c1, Wp) + V (c2, Wp) + . . . + V (ck, Wp) + V (S)
= k ∗V (Wp) + V (S) = k ∗V (Wp) +
n 1, 1 −(1 −q)W
0, (1 −q)W
where q denotes the probability of hitting the space bar, i.e. q = 1 −kp. Given
the fact that W is often large, and (1 −q) < 1, it is almost always the case that
w=S is generated; but since this adds only a constant factor, we can ignore it
in the rest of the computation. That is,
V (W) ≈k ∗V (Wp) = k ∗(k ∗V (Wp2)) = kn ∗V (1)
where n = logp(1/W) = −logpW. By deﬁnition, when W=1, that is, in case
only one word is generated, the vocabulary size is 1, i.e. V(1)=1. Therefore,
V (W) = N ∝kn = k−logpW = W −logpk.
pk*(1+c’logW)
1.2131x + (−0.40331) = y
Fig. 7. (a) Rank vs count of vocabulary words typed randomly on a keyboard with k
equiprobable keys (with probability p) and a space bar (with probability q), follow a
power law with exponent α = logkp. Approximately, the area under the curve gives
the total number of words typed. (b) The relationship between number of edges E and
total weight W behaves like a power-law (k=2, p=0.4).
The above proof shown using recursion is in agreement with the early result of Miller , who showed that in the monkey-typing experiment with k
equiprobable keys (with probability p) and a space bar (with probability q), the
rank-frequency distribution of words follow a power law. In particular,
f(r) ∝r−1+logk(1−q)−1 = rlogkp.
In this case, the number of ranks corresponds to the number of unique words,
that is, the vocabulary size V . And, the sum of the counts of occurrences of all
words in the vocabulary should give W, the number of words typed. The total
count can be approximated by the area under the curve on the rank-count plot.
See Figure 7(a). Next, we give a second proof of Lemma 1 using Miller’s result.
Leman Akoglu
Christos Faloutsos
Proof. Let α = logkp and C(r) denote the number of times that the word with
rank r is typed. Then, C(r) = crα, where C(r)min = C(V ) = cV α and the
constant c = C(V )V −α. Then we can write W as
W = C(V )V −α
≈C(V )V −α
= C(V )V −α
= C(V )V −α
(−α −1)V −α−1
where c′ = C(V )
−α−1, where α < −1 and C(V ) is very small (usually 1). Therefore,
V = N ∝W −1
α = W −logpk.
Lemma 2. The expected number of edges E is
E ≈W −logpk ∗(1 + c′logW),
for c′ = q−logpk
−logp > 0.
Proof. Given the number of words W, we want to ﬁnd the expected number of
edges E that the RTG-IE graph consists of. The number of edges E is the same
as the unique number of pairs of words. We can think of a pair of words as a
single word e, the generation of which is stopped after the second hit to the space
bar. So, e always contains a single space character. Recursively, “e : cie|Sw”,
where “w : ciw|S”. So, E can be formulated as:
E(W) = k ∗E(Wp) + V (Wq)
V (Wq) = k ∗V (Wqp) +
n 1, 1 −(1 −q)W q
0, (1 −q)W q
From Lemma 1, Equ.(2) can be approximately written as V (Wq) = (Wq)−logpk.
Then, Equ.(1) becomes E(W) = k ∗E(Wp) + cW α, where c = q−logpk and
α = −logpk. Given that E(W=1)=1, we can solve the recursion as follows:
E(W) ≈k ∗(k ∗E(Wp2) + c(Wp)α) + cW α
= k ∗(k ∗(k ∗V (Wp3) + c(Wp2)α) + c(Wp)α) + cW α
= kn ∗V (1) + kn−1 ∗c(Wpn−1) + kn−2 ∗c(Wpn−2)α + . . . + cW α
= kn ∗V (1) + cW α((kpα)n−1 + (kpα)n−2 + . . . + 1)
where n = logp(1/W) = −logpW. Since kpα = kp−logpk = 1,
E(W) ≈kn ∗V (1) + n ∗cW α = k−logpW + c−log 1
−logp W −logpk = W −logpk(1 + c′logW)
where c′ =
−logp = q−logpk
−logp > 0.
RTG: A Recursive Realistic Graph Generator using Random Typing
The above function of E in terms of W and other model parameters looks like
a power-law for a wide range of W. See Figure 7(b).
Lemma 3. The in/out-degree dn of a node is power law related to its total
in/out-weight Wn, that is,
Wn ∝d−logkp
with expected exponent −logkp > 1.
Proof. We will show that Wn ∝d−logkp
for out-edges, and a similar argument
holds for in-edges. Given that the experiment is repeated W times, let Wn denote
the number of times a unique word is typed as a source. Each such unique word
corresponds to a node in the ﬁnal graph and Wn is basically its out-weight, since
the node appears as a source node. Then, the out-degree dn of a node is simply
the number of unique words typed as a destination. From Lemma 1,
Wn ∝d−logkp
for −logkp > 1.
Acknowledgments
This material is based upon work supported by the National Science Foundation under Grants No.
IIS-0705359 and CNS-0721736. This work is also partially supported by an IBM Faculty Award, a
Yahoo Research Alliance Gift, a SPRINT gift, with additional funding from Intel, NTT and Hewlett-
Packard. Any opinions, ﬁndings, and conclusions or recommendations expressed in this material are
those of the author(s) and do not necessarily reﬂect the views of any of the funding parties.