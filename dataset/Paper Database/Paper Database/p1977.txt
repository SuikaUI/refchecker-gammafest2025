Journal of Statistical Software
June 2011, Volume 42, Issue 9.
 
MCMCpack: Markov Chain Monte Carlo in R
Andrew D. Martin
Washington University
in St. Louis
Kevin M. Quinn
University of California,
Jong Hee Park
University of Chicago
We introduce MCMCpack, an R package that contains functions to perform Bayesian
inference using posterior simulation for a number of statistical models. In addition to
code that can be used to ﬁt commonly used models, MCMCpack also contains some
useful utility functions, including some additional density functions and pseudo-random
number generators for statistical distributions, a general purpose Metropolis sampling
algorithm, and tools for visualization.
Keywords: Bayesian inference, Markov chain Monte Carlo, R.
1. Introduction
The Bayesian paradigm for statistical inference is appealing to researchers on both theoretical and practical grounds. The interest in Bayesian methods in the social sciences is growing,
and a number of researchers are using these approaches in substantive applications dealing
with: deliberative bodies , economic performance , income dynamics , legislative
redistricting , mass voting , party
competition , social networks
 , and historical changes .
Despite this interest, the social scientiﬁc community has yet to take full advantage of Bayesian
techniques when approaching research problems. This is due primarily to two distinct problems. The ﬁrst problem, which has been largely solved, was the inability to compute the
high dimensional integrals necessary to characterize the posterior distribution for most models. To a large extent, this has been solved by the advent of Markov chain Monte Carlo
(MCMC) methods and the dramatic increases in computing power over the past twenty
years. For a comprehensive treatment of MCMC methods, see Robert and Casella .
MCMC methods are widely considered the most important development in statistical computing in recent history. MCMC has allowed statisticians to ﬁt essentially any probability
model—including those not even considered a few years ago.
Unfortunately, statisticians
have been about the only people who have been willing, and able, to write the computer code
necessary to use MCMC methods to ﬁt probability models.
Which brings us to the second problem; namely, the lack of ﬂexible, yet easy-to-use software
for social scientists unwilling or unable to devote substantial time and energy writing custom
software to ﬁt models via MCMC. Since reasonably eﬃcient MCMC algorithms exist to sample
from the posterior distribution for most classes of models, developing software to meet the
needs of social scientists is feasible.
MCMCpack is an R 
package that contains functions to perform Bayesian inference. It provides a computational
environment that puts Bayesian tools (particularly MCMC methods) into the hands of social
science researchers so that they (like statisticians) can ﬁt innovative models of their choosing.
Just as the advent of general purpose statistical software (like SPSS and SAS) on mainframe
and then personal computers led to the widespread adoption of statistical approaches in the
social sciences, providing easy-to-use general purpose software to perform Bayesian inference
will bring Bayesian methods into mainstream social science.
MCMCpack currently contains the eighteen statistical models: linear regression models (linear
regression with Gaussian errors, a singular value decomposition regression, and regression
for a censored dependent variable), discrete choice models (logistic regression, multinomial
logistic regression, ordinal probit regression, and probit regression), measurement models
(a one-dimensional IRT model, a k-dimensional IRT model, a k-dimensional ordinal factor
model, a k-dimensional linear factor model, a k-dimensional mixed factor model, and a kdimensional robust IRT model), a model for count data (a Poisson regression model), models
for ecological inference (a hierarchical ecological inference model and a dynamic ecological
inference model), and time-series models for change-point problems (a binary change-point
model, a probit change-point model, an ordinal probit change-point model, and a Poisson
change-point model). Many of these models, especially the measurement models, are otherwise
intractable unless one uses MCMC.
The package also contains the density functions and pseudo-random number generators for
the Dirichlet, inverse Gamma, inverse Wishart, noncentral Hypergeometric, and Wishart distributions. These functions are particularly useful for visualizing prior distributions. Finally,
MCMCpack contains a number of utility functions for creating graphs, reading and writing
data to external ﬁles, creating mcmc objects, and manipulating variance-covariance matrices.
The coda package is currently used for posterior visualization and summarization . MCMCpack is available from the Comprehensive R Archive
Network at 
The remainder of this paper is organized as follows. In Section 2 we discuss the package
environment and features of MCMCpack. The following sections will show how model ﬁtting
functions in MCMCpack are implemented in a Gaussian linear model, and a Poisson changepoint model. We conclude with a discussion of possible MCMCpack future developments.
Journal of Statistical Software
2. The MCMCpack environment
We have chosen to make the R system for statistical computation and graphics the home
environment for our software. R has a number of features that make it ideal for our purposes.
It is open-source, free software that is distributed under the GNU General Public License. It is
an extremely powerful programming environment that is designed for statistical data analysis
and data visualization. R is very similar to the S language , and provides an easy-to-use interface to compiled C, C++ or Fortran code, as well as
excellent facilities for debugging, proﬁling, and documenting native R programs. R is already
the general purpose tool of choice for most applied statisticians and is well documented and
supported . Evidence
of the move toward R among social scientists can be found in the growing number of texts
designed for social science graduate students that explicitly advocate R usage , and the decision of the Inter-University Consortium for Political and Social Research
to require students to use R as a means of integrating its most advanced courses in their
summer training program . Over the last ﬁve years
R has become the lingua franca of applied statisticians working in the social sciences.
2.1. Design philosophy
In building the MCMCpack package we have attempted to adhere to a design philosophy that
emphasizes: (a) widespread availability; (b) model-speciﬁc, computationally eﬃcient MCMC
algorithms; (c) compiled C++ code to maximize computational speed; (d) an easy-to-use,
standardized model interface that is very similar to the standard R model ﬁtting functions;
and (e) compatibility with existing R packages (such as coda) for convergence assessment,
posterior summarization, and data visualization.
From a purely practical perspective, the most important design goal has been the implementation of MCMC algorithms that are model-speciﬁc. The major advantage of such an
approach is that the sampling algorithms, being hand-crafted to particular classes of models,
can be made dramatically more eﬃcient than black box approaches, such as those found in
the WinBUGS software, while remaining robust to poorly conditioned or unusual data. In
addition to using reasonably computationally eﬃcient sampling algorithms, the MCMCpack
model ﬁtting functions are also designed to be fast implementations of particular algorithms.
To this end, nearly all of the actual MCMC sampling takes place in C++ code that is called
from within R.
The model ﬁtting functions in MCMCpack have been written to be as similar as possible to
the corresponding R functions for classical estimation of the models in question. This largely
eliminates the need to learn a specialized model syntax for anyone who is even a novice user
of R. For instance, to ﬁt a linear regression model in R via ordinary least squares one could
use the following syntax:
reg.out <- lm(y ~ x1 + x2 + x3, data = mydata)
Bayesian ﬁtting of the same model with an improper uniform prior on the coeﬃcient vector and
the default settings for the parameters governing the MCMC algorithm can be accomplished
with MCMCpack using the following syntax:
Bayes.reg.out <- MCMCregress(y ~ x1 + x2 + x3, data = mydata)
MCMCpack: Markov Chain Monte Carlo in R
It is our experience that such similarities greatly decrease the amount of time it takes to
become a competent user of the MCMCpack package.
In addition, the MCMCpack model ﬁtting functions are designed to be as similar to each
other as possible. As a result, once a user becomes familiar with the basics of using one model
ﬁtting function she can quickly move on to conﬁdently use other model ﬁtting functions. For
instance, to ﬁt a probit model in which the β vector is assumed to have a multivariate normal
prior with mean m and precision P one would use the MCMCpack syntax:
Bayes.probit.out <- MCMCprobit(y ~ x1 + x2 + x3, b0 = m, B0 = P,
data = mydata)
To ﬁt a Poisson regression model in which the β vector is assumed to have a multivariate
normal prior with mean m and precision P one would use the MCMCpack syntax:
Bayes.poisson.out <- MCMCpoisson(y ~ x1 + x2 + x3, b0 = m, B0 = P,
data = mydata)
Using R as the home environment for MCMCpack allows us to make use of a wide range of
software for MCMC convergence assessment, posterior summarization, and data visualization
 that is already part of the R system.
Output objects from all of the MCMCpack model ﬁtting functions are formatted as coda
mcmc objects, sometimes with additional attributes to allow for other types of analyses. This
provides for a very easy-to-use interface between the two packages. For instance, to generate
trace plots and density plots of the output in Bayes.poisson.out using the plot method,
one would enter
plot(Bayes.poisson.out)
at the R command prompt.
Similarly, to compute posterior means, standard deviations,
quantiles, etc. using the summary method one would enter
summary(Bayes.poisson.out)
at the R command prompt. All other coda functions can used in conjunction with MCMCpack
with similar ease.
2.2. Comparison with existing software
Perhaps the most widely used piece of software for applied Bayesian inference is the WinBUGS
package, distributed by the MRC Biostatistics Unit at Cambridge . WinBUGS is an important contribution, and is ideally suited for small
models (both in the number of parameters and in the amount of data). WinBUGS is based on
a set of general computational algorithms that can be used to estimate models speciﬁed using
a model deﬁnition syntax. WinBUGS oftentimes does not exploit model-speciﬁc information
for estimation. All models are estimated using general purpose black-box algorithms. For the
most part, sampling is done parameter-by-parameter. There are two other implementations of
the BUGS language: JAGS and OpenBUGS . Furthermore, there are various R interfaces including R2WinBUGS , rjags , or BRugs .
While the BUGS language is useful for ﬁtting many types of models, it has its limitations.
The generic estimation engine used in WinBUGS is quite ﬂexible, but because it does not
exploit model-speciﬁc information, it is often ineﬃcient, and sometimes ineﬀective. It is well
known that WinBUGS has trouble with algorithms that require sampling from truncated
distributions, such as the Albert and Chib algorithm for the binary probit model,
and algorithms for ﬁtting ordinal data models . The
parameter-by-parameter approach is computationally ineﬃcient, both in terms of computation time and clock time . While we think MCMCpack has
deﬁnite advantages over WinBUGS for many users, we emphasize that we view BUGS and
MCMCpack as complementary tools for the applied researcher. In particular, the greater ﬂexibility of the BUGS language is perfect for users who need to build and ﬁt custom probability
Other general purpose software packages with designs similar to that of MCMCpack exist.
One is the BACC package (for Bayesian analysis, computation, and communication) discussed
in Geweke . The development of BACC was supported by the National Science Foundation, and the newest release was made available on 2003-06-03. BACC is available as a
computational engine for MATLAB, R, S-PLUS, GAUSS, and the UNIX or Windows console.
BACC shares a design component with MCMCpack, as each algorithm is coded in compiled
code for each individual model. Another general purpose software package is the recently
released bayesm package by Rossi and McCulloch . This package is geared to analyses
in marketing and applied econometrics. Both BACC and bayesm use an interface where users
provide appropriate scalars, vectors, and matrices for data and priors, and where posterior
density samples are returned as matrices, requiring the user to perform additional computation to summarize results, assess model ﬁt, and the like. MCMCpack, on the other hand, has
a more R-like interface. We also view these packages as complementary to MCMCpack, as
they provide estimation engines for useful models.
In addition to these packages that oﬀer a comprehensive set of tools, there are a number of
other available R packages that perform Bayesian inference for single classes of models. For
a list of available packages, see the “Bayesian Inference” task view on the Comprehensive R
Archive Network .
2.3. An overview of MCMCpack features
In addition to the model ﬁtting functions mentioned above, MCMCpack has numerous features aimed at both researchers and instructors. For the sake of space we do not comprehensively demonstrate this functionality here. Rather, we highlight three features that may be
of interest. We encourage interested users to consult the documentation for further details.
The MCMCmetrop1R function allows users to sample from a user-deﬁned continuous density
using a random walk Metropolis algorithm with a multivariate normal proposal distribution.
This can be used to explore a posterior (or log-posterior) distribution, as well as any other
target distribution of interest. See Gelman et al. and Robert and Casella for
details of the random walk Metropolis algorithm. The sampler itself is coded in C++, so the
iterations run quite fast. Users only have to provide the target density as an R function.
MCMCpack is sometimes used on large problems where parallel computation might aﬀord
MCMCpack: Markov Chain Monte Carlo in R
some advantages. While MCMCpack does not currently support parallelization within the
Monte Carlo loop, for some problems it is useful to perform embarrassingly parallel simuations,
e.g., sampling from the posterior density of the same model with twenty-ﬁve simultaneous
processes. Doing so requires the availability of a random number generator that provides independent substreams of pseudo-random digits across processes. The default pseudo-random
rumber generator in MCMCpack is the Mersenne twister .
MCMCpack provides a default seed, which can be changed in any model-ﬁtting function.
The package also provides the generator of L’Ecuyer, Simard, Chen, and Kelton ,
which provides independent substreams suitable for parallel computation. Again, the seed
can be changed by the user, who only needs to provide a unique substream number to ensure independence. This generator works just ﬁne with the powerful snow package .
To enhance the usability of MCMCpack in the classroom, the package also contains a number
of “toy” instructional models.
While the use of Monte Carlo simulation is not necessary
to characterize the posterior density of these models, we ﬁnd it useful to introduce Monte
Carlo methods in contexts where analytical results are readily available. To wit, MCMCpack
provides MCmultinomdirichlet (Monte Carlo simulation from a multinomial likelihood with
a Dirichlet prior), MCnormalnormal (Monte Carlo simulation from a normal likelihood with
known variance and a normal prior), and MCpoissongamma (Monte Carlo simulation from a
Poisson likelihood with a gamma prior).
3. An example of Bayesian linear regression
In this section, we look at how to ﬁt a Bayesian linear model using MCMCregress. We use
Wilkerson’s analysis of “killer” amendments in US Congress as an example. A killer
amendment causes a bill, that would pass absent the amendment, to fail.
According to
Wilkerson , a typical example of a killer amendment occurred in 1996,
...when the House was asked to approve an international shipbuilding trade agreement that had taken more than a decade to negotiate. During the debate, a majority party member, Herbert Bateman (R-VA), proposed adding 30 months of“transition assistance” for US shipbuilders to the agreement.. . . Jennifer Dunn (R-WA)
argued “Some individuals argue that no agreement is better than this agreement.
In reality, if the Bateman amendment is adopted, that is exactly what we would
have: No agreement” .. . . Ignoring
Dunn’s warning, the House passed the amendment (278-149) and voted for the
bill (325-100). Recognizing that the shipbuilding agreement was dead on arrival
. . . , the Senate never took it up. (pp. 544–545)
Thus, in order to achieve the preferred ﬁnal result (an international shipbuilding trade agreement), legislative majorities are often forced to vote against an amendement which seems
closer to their preferences (the Bateman amendment) than an original bill. Doing so is a
classic example of strategic voting; i.e., voting for a less preferred choice at an early stage of
a voting procedure to ultimately get a better outcome in the end.
Using a linear regression model estimated with ordinary least squares, Wilkerson shows that
killer amendments are rare and hence legislative majorities seldom face situations that require
Journal of Statistical Software
strategic voting. To investigate the existence of strategic voting, Wilkerson relies upon Poole
and Rosenthal’s measures that capture the ﬁt of actual roll call voting positions to
estimated unidimensional legislative preferences . Among them, we focus on proportional reduction in error (PRE), which
compares NOMINATE’s success at predicting roll call voting positions with the success rate
of simply assuming that everyone votes with the majority:
PRE = (Minority vote −NOMINATE classiﬁcation errors)
(Minority vote)
A high value of PRE for a particular roll call implies that the NOMINATE is accurately
classifying the votes on that roll call compared to the prediction based on the majority voting.
Wilkerson identiﬁes ﬁve types of killer amendments and includes them as covariates: major
weakening, strengthening, political cover, minor weakening, and new issue. Wilkerson also
considers the sponsor. Amendments proposed by a member of the majority party are much
more likely to be viewed as sincere attempts to improve the content of the legislation, rather
than deliberate eﬀorts to sabotage it. Lastly, Wilkerson controls for the chamber of introduction, in case there are chamber eﬀects on sincerity of voting. The model to be estimated
εi ∼N(0, σ2)
With priors:
b ∼NK(b0, B−1
σ2 ∼IG(c0/2, d0/2)
To simulate from the posterior distribution of the model using MCMCregress we load Wilkerson’s data and call MCMCregress.
R> library("MCMCpack")
R> load("killamdt.rda")
R> wilkerson <- MCMCregress(APRE1 ~ STRENGTH + COVER + WEAKMIN +
NEWISSUE + SPONSOR + CHAMBER, data = killamdt, b0 = 0,
B0 = 0.1, c0 = 2, d0 = 0.11, marginal.likelihood = "Chib95")
Note that the output from the call to MCMCregress has been placed in an mcmc object called
wilkerson. By default, MCMCregress uses a noninformative prior for the coeﬃcient parameters. To facilitate model comparison, here we use a weakly informative prior. The prior for
β is speciﬁed using the b0 and B0 arguments, where b0 is the prior mean and B0 is the prior
precision of β. The prior for σ2 is governed by two parameters c0 and d0. We use a weakly
informative prior (c0 = 2 and d0 = 0.11) with a mean equal to the marginal variance of the
APRE1 (0.11).
Before examining the results of our model, it is necessary to examine some diagnostics to
assess whether the Markov chain has converged to its stationary distribution.
method for an mcmc object produces a trace plot and a density plot for each parameter. To
save space, we only report these plots for ﬁrst two parameters in Figure 1. There are also
a number of standard convergence diagnostics implemented in coda one should check before
using the posterior density sample for inference.
The coda summary method can be used to summarize an the mcmc object produced by
MCMCregress.
MCMCpack: Markov Chain Monte Carlo in R
Figure 1: Trace and density plots for two coeﬃcients in the MCMCregress example.
R> summary(wilkerson)
Iterations = 1001:11000
Thinning interval = 1
Number of chains = 1
Sample size per chain = 10000
1. Empirical mean and standard deviation for each variable,
plus standard error of the mean:
Naive SE Time-series SE
(Intercept)
0.72631 0.06934 0.0006934
-0.09573 0.15828 0.0015828
-0.47822 0.15122 0.0015122
-0.28246 0.07989 0.0007989
-0.49685 0.11002 0.0011002
-0.14988 0.07425 0.0007425
0.18924 0.07666 0.0007666
Journal of Statistical Software
Table 1: Analysis of killer amendments . The dependent variable is proportional reduction in error (PRE) when the minority vote is used as benchmark. Lower and
Upper indicate central 95 percent Bayesian credible intervals.
0.07493 0.01387 0.0001387
2. Quantiles for each variable:
(Intercept)
-0.40370 -0.20210 -0.09570
-0.77342 -0.57890 -0.48005 -0.37593 -0.184722
-0.43952 -0.33595 -0.28221 -0.22865 -0.127368
-0.71283 -0.57028 -0.49699 -0.42332 -0.281150
-0.29571 -0.19903 -0.14914 -0.10004 -0.005032
One of main advantage of Bayesian methods is that posterior inference is quite straightforward using MCMC output since the methods provide direct samples of parameters of interest. In this example, Wilkerson’s primary quantity of interest is in whether PRE is higher for
minority-sponsored major weakening amendments than for majority-sponsored major weakening amendments. Wilkerson considers a higher PRE for minority-sponsored major weakening
amendments than for majority-sponsored major weakening amendments as major evidence
for killer amendments.
We can answer this question using our posterior samples. In our data set, SPONSOR is coded
1 if majority-sponsored amendments and WEAKMIN is coded 1 if minor weakening amendments, and 0 otherwise. Thus, the probability that PRE is higher for minority-sponsored
major weakening amendments than for majority-sponsored major weakening amendments
can be shown by comparing a posterior distribution of Constant with a posterior distribution
of Constant + SPONSOR.
Figure 2 demonstrates that minority-sponsored major weakening amendments are better predicted by NOMINATE scores than majority-sponsored major weakening amendments. This
result is consistent with Wilkerson’s ﬁnding that members of the majority party are more
likely to give serious consideration to the substance and strategic implications of amendments
MCMCpack: Markov Chain Monte Carlo in R
majority sponsored major weakening
minority sponsored major weakening
Figure 2: PRE for various types of amendments and sponsors.
oﬀered by fellow party members.
MCMCpack also provides a tool for Bayesian model comparison (for some of its models):
Bayes factors. Bayes factors can be used to compare any model of the same data. Suppose
that the observed data y could have been generated under one of two models A1 and A2. A
natural thing to ask from the Bayesian perspective is: “What is the posterior probability that
A1 is true assuming either A1 or A2 is true?” Using Bayes theorem we can write:
Pr(A1|y) =
p(y|A1) Pr(A1)
p(y|A1) Pr(A1) + p(y|A2) Pr(A2)
It is instructive to look at the posterior odds in favor of one model (say A1):
Pr(A2|y) = p(y|A1)
p(y|A2) × Pr(A1)
What this means is that if we want to move from the prior odds in favor of A1 to the posterior
odds in favor of A1 we simply multiply the prior odds by:
B12 = p(y|A1)
which is called the Bayes factor for A1 relative to A2. B12 provides a measure of the strength
of evidence for A1 over A2. For a thorough discussion of Bayes factors see Kass and Raftery
Journal of Statistical Software
Table 2: A matrix of Bayes factors (on the natural log scale) for the Wilkerson replication. The dependent variable is PRE.
(Intercept)
Table 3: Killer amendments results from model 2.
Lower and Upper indicate central 95
percent Bayesian credible intervals.
The key ingredients necessary for calculating Bayes factors (and posterior model probabilities)
are the marginal likelihoods. There are several eﬃcient methods for these calculations. MCMCregress computes marginal
likelihoods using either the Laplace approximation or Chib’s
 method to compute the marginal likelihoods. Using Chib’s method, we compare three
alternative models with Wilkerson’s model using comparable prior distributions.
R> model1 <- MCMCregress(APRE1 ~ STRENGTH + COVER, data = killamdt,
mcmc = 10000, b0 = 0, B0 = 0.1, c0 = 2, d0 = 0.11,
marginal.likelihood = "Chib95")
R> model2 <- MCMCregress(APRE1 ~ STRENGTH + COVER + WEAKMIN +
NEWISSUE, data = killamdt, mcmc = 10000, b0 = 0,
B0 = 0.1, c0 = 2, d0 = 0.11, marginal.likelihood = "Chib95")
R> model3 <- MCMCregress(APRE1 ~ SPONSOR + CHAMBER, data = killamdt,
mcmc = 10000, b0 = 0, B0 = 0.1, c0 = 2, d0 = 0.11,
marginal.likelihood = "Chib95")
R> BF <- BayesFactor(model1, model2, model3, wilkerson)
R> summary(BF)
The output from BayesFactor shows a matrix of Bayes Factors for all pairs of models speciﬁed
in the argument. Table 2 shows that there is positive evidence or better to support model 2
over all other models considered. That is, information about the sponsorship and the chamber
of introduction does not help explain the variation of PRE given the information on ﬁve types
of killer amendments. We report a posterior summary of model 2 in Table 3 for interested
MCMCpack: Markov Chain Monte Carlo in R
Cycle phases
Stagnation
Level of conﬂict
Low conﬂict
High conﬂict
High conﬂict
Highest conﬂict
Wallerstein
Level of conﬂict
Scattered conﬂict
Lowest conﬂict
Competitiveness
Highest conﬂict
Modelski and
World Power
Delegitimation
Deconcentration
Global war
Level of conﬂict
Lowest conﬂict
High conﬂict
Low conﬂict
Highest conﬂict
UK hegemony
No hegemony
US hegemony
Level of conﬂict
Low conﬂict
High conﬂict
Low conﬂict
Table 4: Starting dates of cycle phases and predicted level of conﬂict. Source: Pollins .
4. A Bayesian Poisson changepoint model example
We show how to ﬁt a Poisson change-point model using MCMCpoissonChange in this section.
Generally speaking, a change-point model is a time series model in which data are generated
from multiple regimes or states. Main quantities of interests in the change-point analysis are
the number, timing, and eﬀects of regime changes. Chib reinterprets the change-point
problem in the context of Markov mixture model in which observations are assumed to be
drawn from latent states. The sampling algorithm of latent states in MCMCpoissonChange is
based on Chib .
Using conjugate prior distributions, we can write a Bayesian Poisson change-point model
without covariates as follows:
Poisson(λi), i = 1, . . . , k
G(c0, d0), i = 1, . . . , k
Beta(α, β), i = 1, . . . , k.
When there is no covariate, all parameters can be sampled using the Gibbs sampler as shown
in Chib . When users have covariates to model the expected count, MCMCpoissonChange
uses the auxiliary mixture sampling method suggested by Fr¨uhwirth-Schnatter and Wagner
 to sample regression parameters. The details of the algorithm are discussed in Park
In this section, we employ MCMCpoissonChange to revisit the empirical test of cyclical theories
of great-power war by Pollins . Pollins identiﬁes four core frameworks in the study of
cyclical patterns of international conﬂicts based on “(1) the relative importance of global
political versus economic subsystems, (2) the dating of the phases they identify in the cycle,
and (3) predictions regarding the level of conﬂict within particular phases of their respective
Journal of Statistical Software
Figure 3: Militarized interstate disputes data.
Table 5: A matrix of Bayes factors (on the natural log scale) for the Poisson change-point
analysis of militarized interstate disputes between 1816 and 1995.
cycles” . These four core frameworks are a theory of hegemony by Gilpin
 , a theory of the world system by Wallerstein , the long wave in the global
economy by Goldstein , and the world leadership cycle by Modelski and Thompson
These four theories give diﬀerent weights on the role of global economic order and global
political order in explaining the patterns of international conﬂicts. For example, while the
theory of Long Wave and the theory of world system argue that the growth and stagnation
of global economy or economic hegemon in the system 
generate diﬀerent levels of international conﬂicts, Modelski and Thompson and Gilpin
 consider the rise and decline of global leadership or a hegemonic power to play a
central role in producing international conﬂicts. These four theories are further diverged in
their predictions on the speciﬁc cycle phases of international conﬂicts as shown in Table 4.
Following Pollins , we use the annual number of military conﬂicts from the militarized
interstate disputes (MID) data to detect the number and
MCMCpack: Markov Chain Monte Carlo in R
Posterior Regime Probability
Pr(St= k |Yt)
GGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
Figure 4: Posterior probabilities of states: each circled line shows the time-varying probabilities of each regime. For example, the probability of Regime 1 (the solid circled line) starts
from 1 in the beginning of the sample period and drops to 0 around the 1840s. Estimates are
from the Poisson change-point analysis of militarized interstate disputes from 1816 to 1995.
timing of cycle phases in international conﬂicts.
To implement MCMCpoissonChange, a user needs to specify data, the number of states (m),
and hyperparameters of λ (c0 and d0). Users must provide hyperparameters of λ (c0 and d0)
for model comparison using Bayes factors. Marginal likelihoods are not identiﬁed under diﬀuse
priors. Thus, users should avoid diﬀuse priors for model comparison. In this speciﬁc example,
we set c0 = 13 and d0 = 1 since the mean of MID is about 13. The following R commands
implement eight Poisson change-point models for the militarized interstate disputes data.
R> model1 <- MCMCpoissonChange(mida, m = 1, c0 = 13, d0 = 1,
marginal.likelihood = c("Chib95"))
R> model2 <- MCMCpoissonChange(mida, m = 2, c0 = 13, d0 = 1,
marginal.likelihood = c("Chib95"))
R> model3 <- MCMCpoissonChange(mida, m = 3, c0 = 13, d0 = 1,
marginal.likelihood = c("Chib95"))
R> model4 <- MCMCpoissonChange(mida, m = 4, c0 = 13, d0 = 1,
marginal.likelihood = c("Chib95"))
R> model5 <- MCMCpoissonChange(mida, m = 5, c0 = 13, d0 = 1,
marginal.likelihood = c("Chib95"))
R> model6 <- MCMCpoissonChange(mida, m = 6, c0 = 13, d0 = 1,
marginal.likelihood = c("Chib95"))
R> model7 <- MCMCpoissonChange(mida, m = 7, c0 = 13, d0 = 1,
marginal.likelihood = c("Chib95"))
Journal of Statistical Software
Figure 5: Posterior density of regime change probability: each panel shows the posterior
distribution of regime change probabilities. For example, the top panel shows the probability
density of the regime change from Regime 1 to Regime 2.
R> model8 <- MCMCpoissonChange(mida, m = 8, c0 = 13, d0 = 1,
marginal.likelihood = c("Chib95"))
The results of the model comparison are summarized in Table 5. The ratio of marginal likelihoods shows that the sixth change-point model is favored over the alternatives. Using Jeﬀrey’s
rule, which provides guidelines as to the strength of a Bayes factor, we can conclude that there
is positive evidence for the sixth change-point model over the alternatives considered.
plotState() generates a plot of posterior state probabilities and plotChangepoint() plots
of posterior probabilities of six change-points as shown in Figures 4 and 5, respectively. Both
graphs indicate that critical shifts in the level of international conﬂicts are concentrated in
the ﬁrst half of the twentieth century and cyclical patterns predicted by the four theoretical
models are not supported by the evidence. However, the picture provided by the Poisson
change-point analysis is closest to Gilpin’s theory of hegemony which predicts high levels of
conﬂicts in the absence of a world hegemon between 1873 and 1945.
MCMCpack: Markov Chain Monte Carlo in R
5. Conclusion
MCMCpack remains a work in progress. While it is diﬃcult to commit to speciﬁc future
development eﬀorts, we hope to implement additional models others will ﬁnd useful in their
research and teaching. The ability to estimate marginal likelihoods and compute Bayes factors
is a new feature in MCMCpack, and is only currently available for a handful of models. We
hope to implement this for a wider range of models in the future. Of course, since MCMCpack
is open source, others can build on this code-base to implement models of their choice.
In the next few years Jong Hee Park will develop a number of models to be used for Bayesian
time series analysis, including change-point models and state space models. He intends to
expand some of these models to include covariates, and to provide various methods to enhance
usability for this class of models. Finally, while the the coda package provides a great deal
of power for convergence checking and posterior density summarization, it does not provide
adequate methods for formal model assessment, including prior and predictive checks, Bayes
factors, and Bayesian model averaging . Our
hope is develop software to make these tools as easy to use as possible.
Acknowledgments
We have received a great deal of support for the MCMCpack project. First, we thank all
of those in the R community who have used our software, found bugs, and provided suggestions, feedback, and patches. Second, we would like to thank all of the research assistants
who have worked with us at Harvard University and Washington University over the years
on this project: Lucy Barnes, Matthew Fasman, Ben Goodrich, Steve Haptonstahl, Kate
Jensen, Laura Keys, Dan Pemstein, and Ellie Powell.
Finally, we gratefully acknowledge
ﬁnancial support from: the US National Science Foundation, Program in Methodology, Measurement, and Statistics, Grants SES-0350646 and SES-0350613, the Institute for Quantitative
Social Sciences ( at Harvard University, the Weidenbaum Center
on the Economy, Government, and Public Policy ( at Washington
University, and the Center for Empirical Research in the Law ( 
at Washington University. Neither the National Science Foundation, Washington University,
or Harvard University bear any responsibility for the content of this package. In addition,
Quinn thanks the Center for Advanced Study in the Behavioral Sciences for its hospitality
and support.