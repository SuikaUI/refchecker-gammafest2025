ADASYN: Adaptive Synthetic Sampling Approach for Imbalanced
Haibo He, Yang Bai, Edwardo A. Garcia, and Shutao Li
Abstract—This paper presents a novel adaptive synthetic
(ADASYN) sampling approach for learning from imbalanced
data sets. The essential idea of ADASYN is to use a weighted
distribution for different minority class examples according to
their level of difﬁculty in learning, where more synthetic data
is generated for minority class examples that are harder to
learn compared to those minority examples that are easier to
learn. As a result, the ADASYN approach improves learning
with respect to the data distributions in two ways: (1) reducing
the bias introduced by the class imbalance, and (2) adaptively
shifting the classiﬁcation decision boundary toward the difﬁcult
examples. Simulation analyses on several machine learning data
sets show the effectiveness of this method across ﬁve evaluation
I. INTRODUCTION
EARNING from imbalanced data sets is a relatively new
challenge for many of today’s data mining applications.
From applications in Web mining to text categorization to
biomedical data analysis , this challenge manifests itself
in two common forms: minority interests and rare instances.
Minority interests arise in domains where rare objects (minority class samples) are of great interest, and it is the objective
of the machine learning algorithm to identify these minority
class examples as accurately as possible. For instance, in
ﬁnancial engineering, it is important to detect fraudulent credit
card activities in a pool of large transactions . Rare
instances, on the other hand, concerns itself with situations
where data representing a particular event is limited compared
to other distributions , such as the detection of oil
spills from satellite images . One should note that many
imbalanced learning problems are caused by a combination of
these two factors. For instance, in biomedical data analysis, the
data samples for different kinds of cancers are normally very
limited (rare instances) compared to normal non-cancerous
cases; therefore, the ratio of the minority class to the majority
class can be signiﬁcant (at a ratio of 1 to 1000 or even
more ). On the other hand, it is essential to predict
the presence of cancers, or further classify different types of
cancers as accurate as possible for earlier and proper treatment
(minority interests).
Haibo He, Yang Bai, and Edwardo A. Garcia are with the Department of
Electrical and Computer Engineering, Stevens Institute of Technology, Hoboken, New Jersey 07030, USA (email: {hhe, ybai1, egarcia}@stevens.edu).
Shutao Li is with the College of Electrical and Information Engineering,
Hunan University, Changsha, 410082, China.(Email: shutao )
This work was supported in part by the Center for Intelligent Networked
Systems (iNetS) at Stevens Institute of Technology and the Excellent Youth
Foundation of Hunan Province (Grant No. 06JJ1010).
Generally speaking, imbalanced learning occurs whenever
some types of data distribution signiﬁcantly dominate the
instance space compared to other data distributions. In this
paper, we focus on the two-class classiﬁcation problem for
imbalanced data sets, a topic of major focus in recent research
activities in the research community. Recently, theoretical
analysis and practical applications for this problem have
attracted a growing attention from both academia and industry.
This is reﬂected by the establishment of several major workshops and special issue conferences, including the American
Association for Artiﬁcial Intelligence workshop on Learning
from Imbalanced Data Sets (AAAI’00) , the International
Conference on Machine Learning workshop on Learning from
Imbalanced Data Sets (ICML’03) , and the Association
for Computing Machinery (ACM) Special Interest Group on
Knowledge Discovery and Data Mining explorations (ACM
SIGKDD Explorations’04) .
The state-of-the-art research methodologies to handle imbalanced learning problems can be categorized into the following
ﬁve major directions:
(1) Sampling strategies. This method aims to develop various oversampling and/or undersampling techniques to compensate for imbalanced distributions in the original data sets.
For instance, in the cost curves technique was used to
study the interaction of both oversampling and undersampling
with decision tree based learning algorithms. Sampling techniques with the integration of probabilistic estimates, pruning,
and data preprocessing were studied for decision tree learning
in . Additionally, in , “JOUS-Boost” was proposed
to handle imbalanced data learning by integrating adaptive
boosting with jittering sampling techniques.
(2) Synthetic data generation. This approach aims to overcome imbalance in the original data sets by artiﬁcially generating data samples. The SMOTE algorithm , generates an
arbitrary number of synthetic minority examples to shift the
classiﬁer learning bias toward the minority class. SMOTE-
Boost, an extension work based on this idea, was proposed
in , in which the synthetic procedure was integrated with
adaptive boosting techniques to change the method of updating
weights to better compensate for skewed distributions. In order
to ensure optimal classiﬁcation accuracy for minority and
majority class, DataBoost-IM algorithm was proposed in 
where synthetic data examples are generated for both minority
and majority classes through the use of “seed” samples.
(3) Cost-sensitive learning. Instead of creating balanced
data distributions by sampling strategies or synthetic data
generation methods, cost-sensitive learning takes a different
978-1-4244-1821-3/08/$25.00 c⃝2008 IEEE
Authorized licensed use limited to: UNIVERSIDAD DE GRANADA. Downloaded on April 14,2010 at 08:32:10 UTC from IEEE Xplore. Restrictions apply.
approach to address this issue: It uses a cost-matrix for
different types of errors or instance to facilitate learning from
imbalanced data sets. That is to say, cost-sensitive learning
does not modify the imbalanced data distribution directly;
instead, it targets this problem by using different cost-matrices
that describe the cost for misclassifying any particular data
sample. A theoretical analysis on optimal cost-sensitive learning for binary classiﬁcation problems was studied in .
In instead of using misclassiﬁcation costs, an instanceweighting method was used to induce cost-sensitive trees
and demonstrated better performance. In , Metacost, a
general cost-sensitive learning framework was proposed. By
wrapping a cost-minimizing procedure, Metacost can make
any arbitrary classiﬁer cost-sensitive according to different
requirements. In , cost-sensitive neural network models
were investigated for imbalanced classiﬁcation problems. A
threshold-moving technique was used in this method to adjust
the output threshold toward inexpensive classes, such that
high-cost (expensive) samples are unlikely to be misclassiﬁed.
(4) Active learning. Active learning techniques are conventionally used to solve problems related to unlabeled training
data. Recently, various approaches on active learning from
imbalanced data sets have been proposed in literature 
 . In particular, an active learning method based on
support vector machines (SVM) was proposed in .
Instead of searching the entire training data space, this method
can effectively select informative instances from a random
set of training populations, therefore signiﬁcantly reducing
the computational cost when dealing with large imbalanced
data sets. In , active learning was used to study the class
imbalance problems of word sense disambiguation (WSD)
applications. Various strategies including max-conﬁdence and
min-error were investigated as the stopping criteria for the
proposed active learning methods.
(5) Kernel-based methods. Kernel-based methods have also
been used to study the imbalanced learning problem. By
integrating the regularized orthogonal weighted least squares
(ROWLS) estimator, a kernel classiﬁer construction algorithm
based on orthogonal forward selection (OFS) was proposed in
 to optimize the model generalization for learning from
two-class imbalanced data sets. In , a kernel-boundaryalignment (KBA) algorithm based on the idea of modifying
the kernel matrix according to the imbalanced data distribution
was proposed to solve this problem. Theoretical analyses in
addition to empirical studies were used to demonstrate the
effectiveness of this method.
In this paper, we propose an adaptive synthetic (ADASYN)
sampling approach to address this problem. ADASYN is
based on the idea of adaptively generating minority data
samples according to their distributions: more synthetic data
is generated for minority class samples that are harder to learn
compared to those minority samples that are easier to learn.
The ADASYN method can not only reduce the learning bias
introduced by the original imbalance data distribution, but can
also adaptively shift the decision boundary to focus on those
difﬁcult to learn samples.
The remainder of this paper is organized as follow. Section
II presents the ADASYN algorithm in detail, and discusses the
major advantages of this method compared to conventional
synthetic approaches for imbalanced learning problems. In
section III, we test the performance of ADASYN on various
machine learning test benches. Various evaluation metrics are
used to assess the performance of this method against existing
methods. Finally, a conclusion is presented in Section IV.
II. ADASYN ALGORITHM
Motivated by the success of recent synthetic approaches
including SMOTE , SMOTEBoost , and DataBoost-
IM , we propose an adaptive method to facilitate learning
from imbalanced data sets. The objective here is two-fold:
reducing the bias and adaptively learning. The proposed
algorithm for the two-class classiﬁcation problem is described
in [Algorithm ADASYN]:
[Algorithm - ADASYN]
(1) Training data set Dtr with m samples {xi, yi}, i =
1, ..., m, where xi is an instance in the n dimensional feature
space X and yi ∈Y = {1, −1} is the class identity label associated with xi. Deﬁne ms and ml as the number of minority
class examples and the number of majority class examples,
respectively. Therefore, ms ≤ml and ms + ml = m.
(1) Calculate the degree of class imbalance:
where d ∈(0, 1].
(2) If d < dth then (dth is a preset threshold for the maximum
tolerated degree of class imbalance ratio):
(a) Calculate the number of synthetic data examples that
need to be generated for the minority class:
G = (ml −ms) × β
Where β∈ is a parameter used to specify the desired
balance level after generation of the synthetic data. β = 1
means a fully balanced data set is created after the generalization process.
(b) For each example xi ∈minorityclass, ﬁnd K nearest
neighbors based on the Euclidean distance in n dimensional
space, and calculate the ratio ri deﬁned as:
ri = Δi/K,
i = 1, ..., ms
where Δi is the number of examples in the K nearest
neighbors of xi that belong to the majority class, therefore
ri ∈ ;
(c) Normalize ri according to ˆri = ri/
ri, so that ˆri is
2008 International Joint Conference on Neural Networks 
Authorized licensed use limited to: UNIVERSIDAD DE GRANADA. Downloaded on April 14,2010 at 08:32:10 UTC from IEEE Xplore. Restrictions apply.
a density distribution (
(d) Calculate the number of synthetic data examples that
need to be generated for each minority example xi:
gi = ˆri × G
where G is the total number of synthetic data examples that
need to be generated for the minority class as deﬁned in
Equation (2).
(e) For each minority class data example xi, generate gi
synthetic data examples according to the following steps:
Do the Loop from 1 to gi:
(i) Randomly choose one minority data example, xzi,
from the K nearest neighbors for data xi.
(ii) Generate the synthetic data example:
si = xi + (xzi −xi) × λ
where (xzi −xi) is the difference vector in n dimensional
spaces, and λ is a random number: λ ∈ .
The key idea of ADASYN algorithm is to use a density
distribution ˆri as a criterion to automatically decide the
number of synthetic samples that need to be generated for
each minority data example. Physically, ˆri is a measurement
of the distribution of weights for different minority class
examples according to their level of difﬁculty in learning.
The resulting dataset post ADASYN will not only provide a
balanced representation of the data distribution (according to
the desired balance level deﬁned by the β coefﬁcient), but it
will also force the learning algorithm to focus on those difﬁcult
to learn examples. This is a major difference compared to the
SMOTE algorithm, in which equal numbers of synthetic
samples are generated for each minority data example. Our
objective here is similar to those in SMOTEBoost and
DataBoost-IM algorithms: providing different weights for
different minority examples to compensate for the skewed
distributions. However, the approach used in ADASYN is
more efﬁcient since both SMOTEBoost and DataBoost-IM
rely on the evaluation of hypothesis performance to update
the distribution function, whereas our algorithm adaptively
updates the distribution based on the data distribution characteristics. Hence, there is no hypothesis evaluation required
for generating synthetic data samples in our algorithm.
Fig. 1 shows the classiﬁcation error performance for different β coefﬁcients for an artiﬁcial two-class imbalanced data
set. The training data set includes 50 minority class examples
and 200 majority class examples, and the testing data set
includes 200 examples. All data examples are generated by
multidimensional Gaussian distributions with different mean
and covariance matrix parameters. These results are based
on the average of 100 runs with a decision tree as the base
classiﬁer. In Fig. 1, β = 0 corresponds to the classiﬁcation
error based on the original imbalanced data set, while β = 1
represents a fully balanced data set generated by the ADASYN
algorithm. Fig. 1 shows that the ADASYN algorithm can
improve the classiﬁcation performance by reducing the bias
introduced in the original imbalanced data sets. Further more,
it also demonstrates the tendency in error reduction as balance
level is increased by ADASYN.
#&#5;0CNIQTKVJOHQTFKHHGTGPVEEQGHHKEKGPVU
&KHHGTGPVEEQGHHKEKGPVU
'TTQTRGTHQTOCPEG
EEQTTGURQPFUVQVJG
QTKIKPCNKODCNCPEGFFCVC
EEQTTGURQPFUVQHWNN[
DCNCPEGFFCVCCHVGT
#&#5;0CNIQTKVJO
ADASYN algorithm for imbalanced learning
III. SIMULATION ANALYSIS AND DISCUSSIONS
A. Data set analysis
We test our algorithm on various real-world machine learning data sets as summarized in Table 1. All these data sets are
available from the UCI Machine Learning Repository .
In addition, since our interest here is to test the learning
capabilities from two-class imbalanced problems, we made
modiﬁcations on several of the original data sets according to
various literary results from similar experiments . A
brief description of such modiﬁcations is discussed as follows.
DATA SET CHARACTERISTICS USED IN THIS PAPER.
# minority
# majority
attributes
Diabetes (PID)
Ionosphere
Vehicle dataset. This data set is used to classify a given
silhouette as one of four types of vehicles . This dataset
has a total of 846 data examples and 4 classes (opel, saab,
bus and van). Each example is represented by 18 attributes. We
choose “Van” as the minority class and collapse the remaining
classes into one majority class. This gives us an imbalanced
two-class dataset, with 199 minority class examples and 647
majority class examples.
2008 International Joint Conference on Neural Networks 
Authorized licensed use limited to: UNIVERSIDAD DE GRANADA. Downloaded on April 14,2010 at 08:32:10 UTC from IEEE Xplore. Restrictions apply.
Pima Indian Diabetes dataset. This is a two-class data set
and is used to predict positive diabetes cases. It includes a
total of 768 cases with 8 attributes. We use the positive cases
as the minority class, which give us 268 minority class cases
and 500 majority class cases.
Vowel recognition dataset. This is a speech recognition
dataset used to classify different vowels. The original dataset
includes 990 examples and 11 classes. Each example is represented by 10 attributes. Since each vowel in the original data
set has 10 examples, we choose the ﬁrst vowel as the minority
class and collapse the rest to be the majority class, which gives
90 and 900 minority and majority examples, respectively.
Ionosphere dataset. This data set includes 351 examples
with 2 classes (good radar returns versus bad radar returns).
Each example is represented by 34 numeric attributes. We
choose the “bad radar” instances as minority class and “good
radar” instance as the majority class, which gives us 126
minority class examples and 225 majority class examples.
Abalone dataset. This data set is used to predict the age
of abalone from physical measurements. The original data set
includes 4177 examples and 29 classes, and each example
is represented by 8 attributes. We choose class “18” as the
minority class and class “9” as the majority class as suggested
in . In addition, we also removed the discrete feature
(feature “sex”) in our current simulation. This gives us 42
minority class examples and 689 majority class examples; each
represented by 7 numerical attributes.
B. Evaluation metrics for imbalanced data sets
Instead of using the overall classiﬁcation accuracy as a
single evaluation criterion, we use a set of assessment metrics
related to receiver operating characteristics (ROC) graphs 
to evaluate the performance of ADASYN algorithm. We use
ROC based evaluation metrics because under the imbalanced
learning condition, traditional overall classiﬁcation accuracy
may not be able to provide a comprehensive assessment
of the observed learning algorithm 
 . Let {p, n} be the positive and negative testing
examples and {Y, N} be the classiﬁcation results given by
a learning algorithm for positive and negative predictions. A
representation of classiﬁcation performance can be formulated
by a confusion matrix (contingency table) as illustrated in
Fig. 2. We followed the suggestions of and use the
minority class as the positive class and majority class as the
negative class.
Based on Fig. 2, the evaluation metrics used to assess
learning from imbalanced data sets are deﬁned as:
Overall Accuracy (OA):
TP + FP + FN + TN
Precision:
Precision =
Confusion matrix for performance evaluation
F Measure:
F Measure = (1 + β2) · recall · precision
β2 · recall + precision
Where β is a coefﬁcient to adjust the relative importance of
precision versus recall (usually β = 1).
PositiveAccuracy × NegativeAccuracy
C. Simulation analyses
We use the decision tree as the base learning model in our
current study. According to the assessment metrics presented
in Section III-B, Table 2 illustrates the performance of the
ADASYN algorithm compared to the SMOTE algorithm. As
a reference, we also give the performance of the decision tree
learning based on the original imbalanced data sets. These
results are based on the average of 100 runs. At each run, we
randomly select half of the minority class and majority class
examples as the training data, and use the remaining half for
testing purpose. For both SMOTE and ADASYN, we set the
number of nearest neighbors K = 5. Other parameters include
N = 200 for SMOTE according to , β = 1 and dth = 0.75
for ADASYN.
For each method, the best performance is highlighted in
each category. In addition, the total winning times for each
method across different evaluation metrics are also shown in
Table 2. Based on these simulation results, the ADASYN
algorithm can achieve competitive results on these ﬁve test
benches. As far as the overall winning times are concerned,
ADASYN outperforms the other methods. Further more,
ADASYN algorithm also provides the best performance in
terms of G-mean for all data sets. This means our algorithm
provides improved accuracy for both minority and majority
classes and does not sacriﬁce one class in preference for
another. This is one of the advantages of our method to handle
the imbalanced learning problems.
There is another interesting observation that merit further
discussion. From Table 2 one can see there are situations
that learning from the original data set can actually achieve
better performance for certain assessment criterion, such as
the precision assessment. This raises an important question:
generally speaking, to what level the imbalanced learning
2008 International Joint Conference on Neural Networks 
Authorized licensed use limited to: UNIVERSIDAD DE GRANADA. Downloaded on April 14,2010 at 08:32:10 UTC from IEEE Xplore. Restrictions apply.
EVALUATION METRICS AND PERFORMANCE COMPARISON
Decision tree
Pima Indian Diabetes
Decision tree
Vowel recognition
Decision tree
Ionosphere
Decision tree
Decision tree
Winning times
Decision tree
methods such as adjusting the class balance can help the learning capabilities? This is a fundamental and critical question in
this domain. In fact, the importance of this question has been
previously addressed by F. Provost in the invited paper for the
AAAI’2000 Workshop on Imbalanced Data Sets :
“Isn’t the best research strategy to concentrate on how
machine learning algorithms can deal most effectively with
whatever data they are given?”
Based on our simulation results, we believe that this
fundamental question should be investigated in more depth
both theoretically and empirically in the research community
to correctly understand the essence of imbalanced learning
D. Discussions
As a new learning method, ADASYN can be further extended to handle imbalanced learning in different scenarios,
therefore potentially beneﬁt a wide range of real-world applications for learning from imbalanced data sets. We give a
brief discussion on possible future research directions in this
Firstly of all, in our current study, we compared the
ADASYN algorithm to single decision tree and SMTOE
algorithm for performance assessment. This is mainly
because all of these methods are single-model based learning
algorithms. Statistically speaking, ensemble based learning algorithms can improve the accuracy and robustness of learning
performance, thus as a future research direction, the ADASYN
algorithm can be extended for integration with ensemble
based learning algorithms. To do this, one will need to use
a bootstrap sampling technique to sample the original training
data sets, and then embed ADASYN to each sampled set to
train a hypothesis. Finally, a weighted combination voting rule
similar to AdaBoost.M1 can be used to combine
all decisions from different hypotheses for the ﬁnal predicted
outputs. In such situation, it would be interesting to see the
performance of such boosted ADASYN algorithm with those
of SMOTEBoost , DataBoost-IM and other ensemble
2008 International Joint Conference on Neural Networks 
Authorized licensed use limited to: UNIVERSIDAD DE GRANADA. Downloaded on April 14,2010 at 08:32:10 UTC from IEEE Xplore. Restrictions apply.
based imbalanced learning algorithms.
Secondly, ADASYN can be generalized to multiple-class
imbalanced learning problems as well. Although two-class
imbalanced classiﬁcation problems dominate the research activities in today’s research community, this is not a limitation
to our method. To extend the ADASYN idea to multi-class
problems, one ﬁrst needs to calculate and sort the degree
of class imbalance for each class with respect to the most
signiﬁcant class, ys ∈Y = {1, ..., C}, which is deﬁned as
the class identity label with the largest number of examples.
Then for all classes that satisfy the condition d < dth, the
ADASYN algorithm is executed to balance them according to
their own data distribution characteristics. In this situation, the
update of ri in equation (3) can be modiﬁed to reﬂect different
needs in different applications. For instance, if one would like
to balance the examples in class yk, (yk ∈{1, ..., C} and
yk ̸= ys), then the deﬁnition of Δi in equation (3) can be
deﬁned as the number of examples in the nearest neighbors
belonging to class ys, or belonging to all other classes except
yk (similar to transforming the calculation of the nearest
neighbors to a Boolean type function: belonging to yk or not
belonging to yk).
Further more, the ADASYN algorithm can also be modiﬁed
to facilitate incremental learning applications. Most current
imbalanced learning algorithms assume that representative
data samples are available during the training process. However, in many real-world applications such as mobile sensor
networks, Web mining, surveillance, homeland security, and
communication networks, training data may continuously become available in small chunks over a period of time. In
this situation, a learning algorithm should have the capability
to accumulate previous experience and use this knowledge
to learn additional new information to aid prediction and
future decision-making processes. The ADASYN algorithm
can potentially be adapted to such an incremental learning
scenario. To do this, one will need to dynamically update the ri
distribution whenever a new chunk of data samples is received.
This can be accomplished by an online learning and evaluation
IV. CONCLUSION
In this paper, we propose a novel adaptive learning algorithm ADASYN for imbalanced data classiﬁcation problems. Based on the original data distribution, ADASYN can
adaptively generate synthetic data samples for the minority
class to reduce the bias introduced by the imbalanced data
distribution. Further more, ADASYN can also autonomously
shift the classiﬁer decision boundary to be more focused on
those difﬁcult to learn examples, therefore improving learning
performance. These two objectives are accomplished by a
dynamic adjustment of weights and an adaptive learning
procedure according to data distributions. Simulation results
on ﬁve data sets based on various evaluation metrics show the
effectiveness of this method.
Imbalanced learning is a challenging and active research
topic in the artiﬁcial intelligence, machine learning, data
mining and many related areas. We are currently investigating
various issues, such as multiple classes imbalanced learning
and incremental imbalanced learning. Motivated by the results
in this paper, we believe that ADASYN may provide a
powerful method in this domain.