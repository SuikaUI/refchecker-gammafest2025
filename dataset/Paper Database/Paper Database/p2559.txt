SPARSE REPRESENTATION FOR COMPUTER VISION
AND PATTERN RECOGNITION
John Wright
Julien Mairal
Guillermo Sapiro
Thomas Huang
Shuicheng Yan
IMA Preprint Series # 2252
 
INSTITUTE FOR MATHEMATICS AND ITS APPLICATIONS
UNIVERSITY OF MINNESOTA
400 Lind Hall
207 Church Street S.E.
Minneapolis, Minnesota 55455–0436
Phone: 612-624-6066
Fax: 612-626-7370
URL: 
PROCEEDINGS OF IEEE, MARCH 2009
Sparse Representation For Computer Vision and
Pattern Recognition
John Wright∗, Member, Yi Ma∗, Senior Member, Julien Mairal†, Member, Guillermo Sapiro‡, Senior Member,
Thomas Huang§, Life Fellow, Shuicheng Yan¶, Member
Abstract—Techniques from sparse signal representation are
beginning to see signiﬁcant impact in computer vision, often
on non-traditional applications where the goal is not just to
obtain a compact high-ﬁdelity representation of the observed
signal, but also to extract semantic information. The choice of
dictionary plays a key role in bridging this gap: unconventional dictionaries consisting of, or learned from, the training
samples themselves provide the key to obtaining state-of-theart results and to attaching semantic meaning to sparse signal
representations. Understanding the good performance of such
unconventional dictionaries in turn demands new algorithmic
and analytical techniques. This review paper highlights a few
representative examples of how the interaction between sparse
signal representation and computer vision can enrich both ﬁelds,
and raises a number of open questions for further study.
I. INTRODUCTION
Sparse signal representation has proven to be an extremely
powerful tool for acquiring, representing, and compressing
high-dimensional signals. This success is mainly due to the
fact that important classes of signals such as audio and images
have naturally sparse representations with respect to ﬁxed
bases (i.e., Fourier, Wavelet), or concatenations of such bases.
Moreover, efﬁcient and provably effective algorithms based
on convex optimization or greedy pursuit are available for
computing such representations with high ﬁdelity .
While these successes in classical signal processing applications are inspiring, in computer vision we are often more
interested in the content or semantics of an image rather than
a compact, high-ﬁdelity representation. One might justiﬁably
wonder, then, whether sparse representation can be useful at
all for vision tasks. The answer has been largely positive:
in the past few years, variations and extensions of ℓ1 minimization have been applied to many vision tasks, including
∗John Wright and Yi Ma are with the Department of Electrical and
Computer Engineering, University of Illinois at Urbana-Champaign. Address:
145 Coordinated Science Laboratory, 1308 West Main Street, Urbana, IL
61801. Email: , 
†Julien Mairal
the INRIA-Willow
project, Ecole Normale
Sup´erieure, Laboratoire d’Informatique de l’Ecole Normale Sup´erieure (IN-
RIA/ENS/CNRS UMR 8548), 45, rue d’Ulm 75005, Paris, France. Email:
 
‡Guillermo Sapiro is with the Department of Electrical and Computer Engineering, University of Minnesota. Address: 200 Union Street SE, Minneapolis,
MN 55455. Email: 
§ Thomas Huang is with the Department of Electrical and Computer
Engineering, University of Illinois at Urbana-Champaign. Address: 2039
Beckman Institute, MC-251 405 N. Mathews, Urbana, IL 61801. Email: 
¶ Shuicheng Yan is with the Department of Electrical and Computer
Engineering, National University of Singapore. Address: Ofﬁce E4-05-11, 4
Engineering Drive 3, 117576, Singapore. Email: 
face recognition , image super-resolution , motion
and data segmentation , , supervised denoising and
inpainting and background modeling , and image
classiﬁcation , . In almost all of these applications,
using sparsity as a prior leads to state-of-the-art results.
The ability of sparse representations to uncover semantic information derives in part from a simple but important property
of the data: although the images (or their features) are naturally
very high dimensional, in many applications images belonging
to the same class exhibit degenerate structure. That is, they
lie on or near low-dimensional subspaces, submanifolds, or
stratiﬁcations. If a collection of representative samples are
found for the distribution, we should expect that a typical
sample have a very sparse representation with respect to
such a (possibly learned) basis.1 Such a sparse representation,
if computed correctly, could naturally encode the semantic
information of the image.
However, to successfully apply sparse representation to
computer vision tasks, we typically have to address the additional problem of how to correctly choose the basis for representing the data. This is different from the conventional setting
in signal processing where a given basis with good property
(such as being sufﬁciently incoherent) can be assumed. In
computer vision, we often have to learn from given sample
images a task-speciﬁc (often overcomplete) dictionary; or we
have to work with one that is not necessarily incoherent. As
a result, we need to extend the existing theory and algorithms
for sparse representation to new scenarios.
This paper will feature a few representative examples of
sparse representation in computer vision. These examples
not only conﬁrm that sparsity is a powerful prior for visual
inference, but also suggest how vision problems could enrich
the theory of sparse representation. Understanding why these
new algorithms work and how well they work can greatly
improve our insights to some of the most challenging problems
in computer vision.
II. ROBUST FACE RECOGNITION: CONFLUENCE OF
PRACTICE AND THEORY
Automatic face recognition remains one of the most visible
and challenging application domains of computer vision .
Foundational results in the theory of sparse representation have
recently inspired signiﬁcant progress on this difﬁcult problem.
1We use the term “basis” loosely here, since the dictionary can be
overcomplete and, even in the case of just complete, there is no guarantee of
independence between the atoms.
PROCEEDINGS OF IEEE, MARCH 2009
The key idea is a judicious choice of dictionary: representing
the test signal as a sparse linear combination of the training
signals themselves. We will ﬁrst see how this approach leads to
simple and surprisingly effective solutions to face recognition.
In turn, the face recognition example reveals new theoretical
phenomena in sparse representation that may seem surprising
in light of prior results.
A. From Theory to Practice: Face Recognition as Sparse
Representation
Our approach to face recognition assumes access to wellaligned training images of each subject, taken under varying illumination.2 We stack the given Ni training images from the ith class as columns of a matrix Di .= [di,1, di,2, . . . , di,Ni] ∈
Rm×Ni, each normalized to have unit ℓ2 norm. One classical observation from computer vision is that images of the
same face under varying illumination lie near a special lowdimensional subspace , , often called a face subspace.
So, given a sufﬁciently expressive training set Di, a new image
of subject i taken under different illumination and also stacked
as a vector x ∈Rm, can be represented as a linear combination
of the given training: x ≈Diαi for some coefﬁcient vector
The problem becomes more interesting and more challenging if the identity of the test sample is initially unknown.
We deﬁne a new matrix D for the entire training set as the
concatenation of the N = P
i Ni training samples of all c
object classes:
D .= [D1, D2, . . . , Dc] = [d1,1, d1,2, . . . , dk,Nk].
Then the linear representation of x can be rewritten in terms
of all training samples as
where α0 = [0, · · · , 0, αT
i , 0, . . . , 0]T ∈RN is a coefﬁcient
vector whose entries are all zero except for those associated
with the i-th class. The special support pattern of this coef-
ﬁcient vector is highly informative for recognition: ideally, it
precisely identiﬁes the subject pictured. However, in practical
face recognition scenarios, the search for such an informative
coefﬁcient vector α0 is often complicated by the presence
of partial corruption or occlusion: gross errors affect some
fraction of the image pixels. In this case, the above linear
model (2) should be modiﬁed as
D α0 + e0,
where e0 ∈Rm is a vector of errors – a fraction, ρ, of its
entries are nonzero.
Thus, face recognition in the presence of varying illumination and occlusion can be treated as the search for a certain
sparse coefﬁcient vector α0, in the presence of a certain sparse
error e0. The number of unknowns in (3) exceeds the number
of observations, and we cannot directly solve for α0. However,
under mild conditions , the desired solution (α0, e0) is
2For a detailed explanation of how such images can be obtained, see .
Overview of the face recognition approach. The method represents
a test image (left), which is potentially occluded (top) or corrupted (bottom),
as a sparse linear combination of all the training images (middle) plus sparse
errors (right) due to occlusion or corruption . Red (darker) coefﬁcients
correspond to training images of the correct individual. The algorithm determines the true identity (indicated with a red box at second row and third
column) from 700 training images of 100 individuals (7 each) in the standard
AR face database.
not only sparse, it is the sparsest solution to the system of
equations (3):
(α0, e0) = arg min ∥α∥0 + ∥e∥0
x = Dα + e. (4)
Here, the ℓ0 “norm” ∥·∥0 counts the number of nonzeros in a
vector. Originally inspired by theoretical results on equivalence
between ℓ1 and ℓ0-minimizations , , in the authors
proposed to seek this informative vector α0 by solving the
convex relaxation
min ∥α∥1 + ∥e∥1
x = Dα + e,
where ∥α∥1 .= P
i |αi|. That work reported striking empirical
results: the ℓ1-minimizer, visualized in Figure 1, has a strong
tendency to separate the identity of the face (red coefﬁcients)
from the error due to corruption or occlusion.
Once the ℓ1-minimization problem has been solved (see,
e.g., , , ), classiﬁcation (identifying the subject
pictured) or validation (determining if the subject is present in
the training database) can proceed by considering how strongly
the recovered coefﬁcients concentrate on any one subject (see
 for details). Here, we present only a few representative
results; a more thorough empirical evaluation can be found
in . Figure 2 (left) compares the recognition rate of this
approach (labeled SRC) with several popular methods on
the Extended Yale B Database under varying levels of
synthetic block occlusion.
Figure 2 compares the sparsity-based approach outlined here
with several popular methods from the literature3: the Principal
Component Analysis (PCA) approach of , Independent
Component Analysis (ICA) , and Local Nonnegative Matrix Factorization (LNMF) . The ﬁrst provides a standard
baseline of comparison, while the latter two methods are
more directly suited for occlusion, as they produce lowerdimensional feature sets that are spatially localized. Figure
2 left also compares to the Nearest Subspace method ,
which makes similar use of linear illumination models, but is
not based on sparsity and does not correct sparse errors.
The ℓ1-based approach achieves the highest overall recognition rate of the methods tested, with almost perfect recognition
3See for a more thorough review of the vast literature on face
recognition.
PROCEEDINGS OF IEEE, MARCH 2009
Percent occluded (%)
Recognition rate (%)
ICA I + NN
False Positive Rate
True Positive Rate
Face recognition and validation. Left: Recognition rate of the ℓ1based method (labeled SRC), as well as Principal Component Analysis (PCA)
 , Independent Component Analysis , Localized Nonnegative Matrix
Factorization (LNMF) and Nearest Subspace (NS) on the Extended
Yale B Face Database under varying levels of contiguous occlusion. Right:
Receiver Operating Characteristic (ROC) for validation with 30% occlusion.
In both scenarios, the sparse representation-based approach signiﬁcantly
outperforms the competitors .
Cross Polytope ±I
di ∼N(µ, σ2I)
Coherent Gaussian Vectors
The “cross-and-bouquet” model. Left: the bouquet D and the
crosspolytope spanned by the matrix ±I. Right: tip of the bouquet magniﬁed;
it is modeled as a collection of iid Gaussian vectors with small variance σ2
and common mean vector µ. The cross-and-bouquet polytope is spanned by
vertices from both the bouquet D and the cross ±I .
up to 30% occlusion and a recognition rate above 90% with
40% occlusion. Figure 2 (right) shows the validation performance of the various methods, under 30% contiguous occlusion, plotted as a Reciever Operating Characteristic (ROC)
curve. At this level of occlusion, the sparsity-based method
is the only one that performs signiﬁcantly better than chance.
The performance under random pixel corruption is even more
striking (see Figure 1, bottom), with recognition rates above
90% even at 70% corruption.
B. From Practice to Theory: Dense Error Correction by ℓ1-
Minimization
The strong empirical results alluded to in the previous
section seem to demand a correspondingly strong theoretical
justiﬁcation. However, a more thoughtful consideration reveals
that the underdetermined system of linear equations (3) does
not satisfy popular sufﬁcient conditions for guaranteeing correct sparse recovery by ℓ1-minimization.
In face recognition, the columns of A are highly correlated:
they are all images of some face. As m becomes large (i.e.
the resolution of the image becomes high), the convex hull
spanned by all face images of all subjects is only an extremely
tiny portion of the unit sphere Sm−1. For example, the images
in Figure 1 lie on S8,063. The smallest inner product with
their normalized mean is 0.723; they are contained within
a spherical cap of volume ≤1.47 × 10−229. These vectors
are tightly bundled together as a “bouquet,” whereas the
standard pixel basis ±I with respect to which we represent
the errors e forms a “cross” in Rm , as illustrated in Figure 3.
The incoherence and restricted isometry properties
that are so useful in providing performance guarantees for
ℓ1-minimization therefore do not hold for the “cross-andbouquet” matrix [D I] (similarly, conditions that guarantee
sparse recovery via greedy techniques such as orthogonal
matching pursuit are also often violated by these type of
dictionaries). Also, the density of the desired solution is not
uniform either: α is usually a very sparse non-negative vector4,
but e could be dense (with a fraction nonzeros close to one)
and have arbitrary signs. Existing results for recovering sparse
signals suggest that ℓ1-minimization may have difﬁculty in
dealing with such signals, contrary to its empirical success in
face recognition.
In an attempt to better understand the face recognition example outlined above, we consider the more abstract problem
of recovering such a non-negative sparse signal α0 ∈RN
from highly corrupted observations x ∈Rm:
x = Dα0 + e0,
where e0 ∈Rm is a vector of errors of arbitrary magnitude.
The model for D ∈Rm×N should capture the idea that it
consists of small deviations about a mean, hence a “bouquet.”
We can model this by assuming the columns of D are iid
samples from a Gaussian distribution:
D = [d1 . . . dN] ∈Rm×N,
∥µ∥∞≤Cµm−1/2.
Together, the two assumptions on the mean force µ to remain
incoherent with the standard basis (or “cross”) as m →∞.
We study the behavior of the solution to the ℓ1-minimization
(5) for this model, in the following asymptotic scenario:
Assumption 1 (Weak Proportional Growth): A sequence of
signal-error problems exhibits weak proportional growth with
parameters δ > 0, ρ ∈(0, 1), C0 > 0, η0 > 0, denoted
WPGδ,ρ,C0,η0, if as m →∞,
∥α0∥0 ≤C0 m1−η0.
This should be contrasted with the “total proportional growth”
(TPG) setting of, e.g., , in which the number of nonzero
entries in the signal α0 also grows as a ﬁxed fraction of the
dimension. In that setting, one might expect a sharp phase
transition in the combined sparsity of (α0, e0) that can be
recovered by ℓ1-minimization. In WPG, on the other hand,
we observe a striking phenomenon not seen in TPG: the
correction of arbitrary fractions of errors. This comes at the
expense of the stronger assumption that ∥α0∥0 is sublinear,
an assumption that is valid in some real applications such as
the face recognition example above.
In the following, we say the cross-and-bouquet model is ℓ1recoverable at (I, J, σ) if for all α0 ≥0 with support I and
4The nonnegativity of α can be viewed as a consequence of convex
cone models for illumination ; the existence of such a solution can be
guaranteed by choosing training samples that span the cone of observable test
illuminations .
PROCEEDINGS OF IEEE, MARCH 2009
e0 with support J and signs σ,
arg min ∥α∥1 + ∥e∥1
subject to Dα + e = Dα0 + e0, (8)
and the minimizer is uniquely deﬁned. From the geometry of
ℓ1-minimization, if (8) does not hold for some pair (α0, e0),
then it does not hold for any (α, e) with the same signs
and support as (α0, e0) . Understanding ℓ1-recoverability
at each (I, J, σ) completely characterizes which solutions to
x = Dα+e can be correctly recovered. In this language, the
following characterization of the error correction capability of
ℓ1-minimization can be given :
Theorem 1 (Error Correction with the Cross-and-Bouquet):
For any δ > 0, ∃ν0(δ) > 0 such that if ν < ν0 and ρ < 1,
in WPGδ,ρ,C0,η0 with D distributed according to (6), if the
error support J and signs σ are chosen uniformly at random,
then as m →∞,
ℓ1-recoverability at (I, J, σ) ∀I ∈
In other words, as long as the bouquet is sufﬁciently tight,
asymptotically ℓ1-minimization recovers any non-negative
sparse signal from almost any error with support size less
than 100% . This provides some theoretical corroboration
to the strong practical and empirical results observed in the
face recognition example, especially in the presence of random
corruption.
C. Remarks on Sparsity-Based Recognition
The theoretical justiﬁcations of this approach discussed here
have inspired further practical work in this direction. The work
reported in addresses issues such as pose and alignment as
well as obtaining sufﬁcient training data of each subject, and
integrates these results into a practical system for face recognition that achieves state-of-the-art results. Moreover, while in
this section we have focused on the interplay between theory
and practice in one particular application, face recognition,
similar ideas have seen application on a number of problems
in and even beyond vision, e.g., in sensor networks and human
activity classiﬁcation as well as speech recognition ,
Although the cross-and-bouquet model has successfully
explained the error correction ability of ℓ1 minimization in
this application, the striking discriminative power of the sparse
representation (see also sections III and IV) still lacks rigorous
mathematical justiﬁcation. Better understanding this behavior
seems to require a better characterization of the internal
structure of the bouquet and its effect on the ℓ1-minimizer.
To the best of our knowledge, this remains a wide open topic
for future investigation.
III. ℓ1-GRAPHS
The previous section showed how for face recognition, a
representation of the test sample in terms of the training
samples themselves yielded useful information for recognition. Whereas before, this representation was motivated via
linear illumination models, we now consider a more general
setting in which an explicit linear model is absent. Here, the
sparse coefﬁcients computed by ℓ1-minimization are used to
characterize relationships between the data samples, in order to
accomplish various machine learning tasks. The key idea is to
accomplish this by interpreting the coefﬁcients as weights in a
directed graph, which we term the ℓ1-graph (see also for
a graphical model interpretation of the sparse representation
approach for image classiﬁcation described in Section IV).
A. Motivations
An informative graph, directed or undirected, is critical
for graph-based machine learning tasks such as data clustering, subspace learning, and semi-supervised learning. Popular
spectral approaches to clustering start with a graph representing pairwise relationships between the data samples .
Manifold learning algorithms such as ISOMAP , Locally
Linear Embedding (LLE) , and Laplacian Eigenmaps (LE)
 , all rely on graphs constructed with different motivations
 . Moreover, most popular subspace learning algorithms,
e.g., Principal Component Analysis (PCA) and Linear
Discriminant Analysis (LDA) , can all be explained within
the graph embedding framework . Also, a number of semisupervised learning algorithms are driven by the regularizing
graphs constructed over both labeled and unlabeled data .
Most of the works described above rely on one of two popular approaches to graph construction: the k-nearest-neighbor
method and the ε-ball method. The ﬁrst assigns edges between
each data point and its k-nearest neighbors, whereas the second
assigns edges between each data point and all samples within
its surrounding ε-ball. From a machine learning perspective,
the following graph characteristics are desirable:
1) High discriminating power. For data clustering and label
propagation in semi-supervised learning, the data from
the same cluster/class are expected to be assigned large
connecting weights. The graphs constructed in those
popular ways however, often fail to capture piecewise
linear relationships between data samples in the same
2) Sparsity. Recent research on manifold learning shows
that a sparse graph characterizing locality relations can
convey the valuable information for classiﬁcation. Also
for large-scale applications, a sparse graph is the inevitable choice due to storage limitations.
3) Adaptive neighborhood. It often happens that the available data are inadequate and do not evenly distribute,
resulting in different neighborhood structure for different data points. Both the k-nearest-neighbor and ε-ball
methods (in general) use a ﬁxed global parameter to
determine the neighborhoods for all the data, and thus
do not handle situations where an adaptive neighborhood
is required.
Enlightened by recent advances in our understanding of
sparse coding by ℓ1 optimization and in applications such
as the face recognition example described in the previous
section, we propose to construct the so-called ℓ1-graph via
sparse data coding, and then harness it for popular graph-based
machine learning tasks. An ℓ1 graph over a dataset is derived
PROCEEDINGS OF IEEE, MARCH 2009
by encoding each datum as the sparse representation of the
remaining samples, and automatically selects the most informative neighbors for each datum. The sparse representation
computed by ℓ1-minimization naturally satisﬁes the properties
of sparsity and adaptivity. Moreover, we will see empirically
that characterizing linear relationships between data samples
via ℓ1-minimization can signiﬁcantly enhance the performance
of existing graph-based learning algorithms.
B. ℓ1-Graph Construction
[x1, x2, . . . , xN] ∈Rm×N, where N is the sample number and m is the feature dimension. We denote the ℓ1graph as G = {X, W}, where X is the vertex set and
W = [wij] ∈RN×N the edge weight matrix. The graph
is constructed in an unsupervised manner, with a goal of
automatically determining the neighborhood structure as well
as the corresponding connection weights for each datum.
Unlike the k-nearest-neighbor and ε-ball based graphs in
which the edge weights characterize pairwise relations, the
edge weights of ℓ1-graph are determined in a group manner,
and the weights related to a certain vertex characterize how
the rest samples contribute to the sparse representation of this
vertex. The procedure to construct the ℓ1-graph is:
1) Inputs: The sample set X.
2) Sparse coding: For each sample xi, solve the ℓ1 norm
minimization problem
αi ∥αi∥1, s.t. xi = Diαi,
where matrix Di = [x1, ..., xi−1, xi+1, ..., xN, I] ∈
Rm×(m+N−1) and αi ∈Rm+N−1.
3) Graph weights setting: Wij = αi
j (nonnegativity constraints may be imposed if for similarity measurement)
if i > j, and Wij = αi
j−1 if i < j.
For data with linear or piecewise-linear class structure the
sparse representation conveys important discriminative information, which is automatically encoded in the ℓ1-graph. The
derived graph is naturally sparse – the sparse representation
computed by ℓ1-minimization never involves more than m
nonzero coefﬁcients, and may be especially sparse when
the data have degenerate or low-dimensional structure. The
number of neighbors selected by ℓ1-graph is adaptive to each
data point, and these numbers are automatically determined by
the ℓ1 optimization process. Thus, the ℓ1-graph possesses all
the three characteristics of a desired graph for data clustering,
subspace learning, and semi-supervised learning , .
C. ℓ1-Graph for Machine Learning Tasks
An informative graph is critical for achieving high performance with graph-based learning algorithms. Similar to
conventional graphs constructed by k-nearest-neighbor or εball method, ℓ1-graph can also be integrated with graph-based
algorithms for tasks such as data clustering, subspace learning,
and semi-supervised learning. In the following sections, we
show how ℓ1-graphs can be used for each of these purposes.
1) Spectral clustering with ℓ1-graph: Data clustering is the
partitioning of samples into subsets, such that the data within
each subset are similar to each other. Some of the most popular
algorithms for this task are based on spectral clustering .
Using the ℓ1-graph, the algorithm can automatically derive
the similarity matrix from the calculation of these sparse
codings (namely wij = αi
j). Inheriting the property of greater
discriminating power from ℓ1-graph, the spectral clustering
based on ℓ1-graph has greater potential to correctly separate
the data into different clusters. Based on the derived ℓ1-graph,
the spectral clustering process can be performed in the
same way as for conventional graphs.
2) Subspace learning with ℓ1-graph: Subspace learning
algorithms search for a projection matrix P ∈Rm×d (usually
d ≪m) such that distances in the projected space are as
informative as possible for classiﬁcation. If the dimension of
the projected space is large enough, then linear relationships
between the training samples may be preserved, or approximately preserved. The pursuit of a projection matrix that
simultaneously respects the sparse representations of all of the
data samples can be formulated as an optimization problem
(closely related to the problem of metric learning)
P T XXT P = I
and solved via generalized eigenvalue decomposition.
3) Semi-supervised
Semisupervised learning has attracted a great deal of recent
attention. The main idea is to improve classiﬁer performance
by using additional unlabeled training samples to characterize
the intrinsic geometry of the observation space (see for
example for the application of sparse models for semisupervised learning problems). For classiﬁcation algorithms
that rely on optimal projections or embeddings of the data,
this can be achieved by adding a regularization term to the
objective function that forces the embedding to respect the
relationships between the unlabeled data.
In the context of ℓ1-graphs, we can modify the classical
LDA criterion to also demand that the computed projection
respects the sparse coefﬁcients computed by ℓ1-minimization:
γSw(P) + (1 −γ) PN
i=1 ∥P T xi −PN
j=1 wijP T xj∥2
where Sw(P) and Sb(P) measure the within-class scatter and
inter-class scatter of the labeled data respectively, and γ ∈
(0, 1) is a coefﬁcient that balances the supervised term and
ℓ1-graph regularization term (see also ).
D. Experimental Results
In this section, we systematically evaluate the effectiveness
of the ℓ1-graph in the machine learning scenarios outlined
above. The USPS handwritten digit database (200 samples
are selected for each class), forest covertype database 
(120 samples are selected for each class), and ETH-80 object
recognition database are used for the experiments. Note
that all the results reported here are from the best tuning of
PROCEEDINGS OF IEEE, MARCH 2009
all possible algorithmic parameters, and the results on the ﬁrst
two databases are the averages of ten runs while the results
on ETH-80 are from one run.
Table I compares the accuracy of spectral clustering based
on the ℓ1-graph with spectral algorithms based on a number
of alternative graph constructions, as well as the simple baseline of K-means. The clustering results from ℓ1-graph based
spectral clustering algorithm are consistently much better than
the other algorithms tested.
CLUSTERING ACCURACIES (NORMALIZED MUTUAL INFORMATION) FOR
SPECTRAL CLUSTERING ALGORITHMS BASED ON ℓ1-GRAPH,
GAUSSIAN-KERNEL GRAPH (G-G), LE-GRAPH (LE-G), AND LLE-GRAPH
(LLE-G), AS WELL AS PCA+K-MEANS (PCA+KM).
Our next experiment concerns data classiﬁcation based on
low-dimensional projections. Table II compares the classi-
ﬁcation accuracy of the ℓ1-graph based subspace learning
algorithm with several more conventional subspace learning
algorithms. The following observations emerge: 1) the ℓ1graph based subspace learning algorithm is superior to all
the other evaluated unsupervised subspace learning algorithms,
and 2) ℓ1-graph based subspace learning algorithm generally
performs a little worse than the supervised algorithm Fisherfaces, but on the forest covertype database, ℓ1-graph based
subspace learning algorithm is better than Fisherfaces. Note
that all the algorithms are trained on all the data available,
and the results are based on nearest neighbor classiﬁer; for all
experiments, 10 samples for each class are randomly selected
as gallery set and the remaining ones are used for testing.
COMPARISON CLASSIFICATION ERROR RATES (%) FOR DIFFERENT
SUBSPACE LEARNING ALGORITHMS. LPP AND NPE ARE THE LINEAR
EXTENSIONS OF LE AND LLE RESPECTIVELY.
ℓ1-graph-SL
Fisherfaces 
Finally, we evaluate the effectiveness of the ℓ1 graph in
semi-supervised learning scenarios. Table III compares results
with the ℓ1-graph to several alternative graph constructions.
We make two observations: 1) the ℓ1-graph based semisupervised learning algorithm generally achieves the lowest
error rates compared to semi-supervised learning based on
more conventional graphs, and 2) semi-supervised learning
based on the ℓ1-graph and the graph used in LE algorithm
can generally bring accuracy improvements compared to the
counterpart without harnessing extra information from unlabeled data. Note that all the semi-supervised algorithms are
based on the supervised algorithm Marginal Fisher Analysis
(MFA) .
E. Remarks on ℓ1-Graphs
Although in this section we have illustrated with a few
generic examples the potential of ℓ1-graphs for some gen-
COMPARISON CLASSIFICATION ERROR RATES (%) FOR SEMI-SUPERVISED
ALGORITHMS ℓ1-GRAPH (ℓ1-G), LE-GRAPH (LE-G), AND LLE-GRAPH
(LLE-G), SUPERVISED (MFA) AND UNSUPERVISED LEARNING (PCA)
ALGORITHMS.
eral problems in machine learning, the idea of using sparse
coefﬁcients computed by ℓ1-minimization for clustering has
already found good success in the classical vision problem
of segmenting multiple motions in a video, where lowdimensional self-expressive representations can be motivated
by linear camera models. In that domain, algorithms combining sparse representation and spectral clustering also achieve
state-of-the-art results on extensive public data sets , .
Despite apparent empirical successes, precisely characterizing
the conditions under which ℓ1-graphs can better capture certain
geometric or statistic relationships among data remains an
open problem. We expect many interesting and important
mathematical problems may arise from this rich research
ﬁeld. The next section further investigates the use of sparse
representations for image classiﬁcation, including exploiting
the sparse coefﬁcients with respect to learned dictionaries.
IV. DICTIONARY LEARNING FOR IMAGE ANALYSIS
The previous sections examined applications in vision and
machine learning in which a sparse representation in an overcomplete dictionary consisting of the samples themselves
yielded semantic information. For many applications, however,
rather than simply using the data themselves, it is desirable
to use a compact dictionary that is obtained from the data
by optimizing some task-speciﬁc objective function. This
section provides an overview of approaches to learning such
dictionaries, as well as their applications in computer vision
and image processing.
A. Motivations
As detailed in the previous sections, sparse modeling calls
for constructing efﬁcient representations of data as a (often
linear) combination of a few typical patterns (atoms) learned
from the data itself. Signiﬁcant contributions to the theory
and practice of learning such collections of atoms (usually
called dictionaries or codebooks), e.g., , , , and of
representing the actual data in terms of them, e.g., , ,
 , have been developed in recent years, leading to state-ofthe-art results in many signal and image processing tasks ,
 , , , , . We refer the reader to for a
recent review on the subject.
The actual dictionary plays a critical role, and it has
been shown again and again that learned and data adaptive
dictionaries signiﬁcantly outperform off-the-shelf ones such as
wavelets. Current techniques for obtaining such dictionaries
mostly involve their optimization in terms of the task to be
performed, e.g., representation , denoising , , and
classiﬁcation . Theoretical results addressing the stability
PROCEEDINGS OF IEEE, MARCH 2009
and consistency of the sparse solutions (active set of selected
atoms), as well as the efﬁciency of the coding algorithms,
are related to intrinsic properties of the dictionary such as
the mutual coherence, the cumulative coherence, and the
Gram matrix norm of the dictionary , , , ,
 . Dictionaries can be learned by locally optimizing these
and related objectives , . In this section, we present
basic concepts associated with dictionary learning, and provide
illustrative examples of algorithm performance.
B. Sparse Modeling for Image Reconstruction
Let X ∈Rm×N be a set of N column data vectors xj ∈
Rm (e.g., image patches), D ∈Rm×K be a dictionary of K
atoms represented as columns dk ∈Rm. Each data vector xj
will have a corresponding vector of reconstruction coefﬁcients
αj ∈RK (in contrast with the cases described in previous
sections, K will now be orders of magnitude smaller than
N), which we will treat as columns of a matrix
A = [α1, . . . , αN] ∈RK×N.
The goal of sparse modeling is to design a dictionary D such
that X ≃DA with ∥αj∥0 sufﬁciently small (usually below
some threshold) for all or most data samples xj. For a ﬁxed
D, the computation of A is called sparse coding.
We begin our discussion with the standard ℓ0 or ℓ1 penalty
modeling problem,
(A∗, D∗) = arg min
A,D ∥X −DA∥2
F + λ ∥A∥p ,
where ∥·∥F denotes Frobenius norm and p = 0, 1. The cost
function to be minimized in (11) consists of a quadratic
ﬁtting term and an ℓ0 or ℓ1 regularization term for each
column of A, the balance of the two being deﬁned by the
penalty parameter λ (this parameter has been studied in ,
 , , , ). As mentioned above, the ℓ1 norm
can be used as an approximation to ℓ0, making the problem
convex in A while still encouraging sparse solutions .
While for reconstruction we found that the ℓ0 penalty often
produces better results, ℓ1 leads to more stable active sets
and is preferred for the classiﬁcation tasks introduced in the
next section. In addition, these costs can be replaced by a
(non-convex) Lorentzian penalty function, motivated either by
further approximating the ℓ0 by ℓ1 , or by considering
a mixture of Laplacians prior for the coefﬁcients in A and
exploiting MDL concepts , instead of the more classical
Laplacian prior.5
Since (11) is not simultaneously convex in {A, D}, coordinate descent type optimization techniques have been proposed
 , . These approaches have been extended for multiscale
dictionaries and color images in , leading to state-of-the-art
results. See Figure 4 for an example of color image denosing
with this approach, and , for numerous additional
examples, comparisons, and applications in image demosaicing, image inpainting, and image denoising. An example of a
5The expression (11) can be derived from a MAP estimation with a
Laplacian prior for the coefﬁcients in A and a Gaussian prior for the sparse
representation error.
Image denoising via sparse modeling and dictionary learned from
a standard set of color images .
learned dictionary is shown in Figure 4 as well (K = 256).
It is important to note that for image denoising, overcomplete
dictionaries are used, K > m, and the patch sizes vary from
7 × 7, m = 49, to 20 × 20, m = 400 (in the multiscale case),
with a sparsity of about 1/10th of the signal dimension m.
State-of-the-art results obtained in are “shared” with
those in , which extends the non-local means approach
developed in , . Interestingly, the two frameworks are
quite related, since they both use patches as building blocks
(in , the sparse coding is applied to all overlapping
image patches), and while a dictionary is learned in 
from a large dataset, the patches of the processed image
itself are the “dictionary” in non-local means. The sparsity
constraint in is replaced by a proximity constraint and
other processing steps in , . The exact relationship and
the combination of non-local-means with sparsity modeling
has been recently exploited by the authors of to further
improve on these results. The authors also developed a very
fast on-line dictionary learning approach.
C. Sparse Modeling for Image Classiﬁcation
While image representation and reconstruction has been the
most popular goal of sparse modeling and dictionary learning,
other important image science applications are starting to
be addressed by this framework, in particular, classiﬁcation
and detection. In , the authors use the reconstruction/generative formulation (11), exploiting the quality of the
representation and/or the coefﬁcients A for the classiﬁcation
tasks. This generative only formulation can be augmented
by discriminative terms , , , , where an
additional term is added in (11) to encourage the learning of
PROCEEDINGS OF IEEE, MARCH 2009
Image classiﬁcation via sparse modeling. Two classes have been
considered, “bikes” and “background,” and the dictionaries where trained in
a semi-supervised fashion .
dictionaries that are most relevant to the task at hand. The
dictionary learning then becomes task-dependent and
(semi-) supervised. In the case of for example, a Fisherdiscriminant type term is added in order to encourage signals
(images) from different classes to pick different atoms from the
learned dictionary. In , multiple dictionaries are learned,
one per class, so that each class’s dictionary provides a
good reconstruction for its corresponding class and a poor
one for the other classes (simultaneous positive and negative
learning). This idea was then applied in for learning to
detect edges as part of an image classiﬁcation system. These
frameworks have been extended in , where a graphical
model interpretation and connections with kernel methods
are presented as well for the novel sparse model introduced
there. Of course, adding such new terms makes the actual
optimization even more challenging, and the reader is referred
to those papers for details.
This framework of adapting the dictionary to the task,
combining generative with discriminative terms for the case of
classiﬁcation, has been shown to outperform the generic dictionary learning algorithms, achieving state-of-the-art results for
a number of standard datasets. An example from of the
detection of patches corresponding to bikes from the popular
Gratz dataset is shown in Figure 5. The reader is referred to
 , , , for additional examples and comparisons
with the literature.
D. Learning to Sense
As we have seen, learning overcomplete dictionaries that
facilitate a sparse representation of the data as a liner combination of a few atoms from such dictionary leads to state-ofthe-art results in image and video restoration and classiﬁcation.
The emerging area of compressed sensing (CS), see , ,
 and references therein, has shown that sparse signals
can be recovered from far fewer samples than required by
the classical Shannon-Nyquist Theorem. The samples used
in CS correspond to linear projections obtained by a sensing
projection matrix. It has been shown that, for example, a nonadaptive random sampling matrix satisﬁes the fundamental
theoretical requirements of CS, enjoying the additional beneﬁt
of universality. A projection sensing matrix that is optimally
Fig. 6. Simultaneously learning the dictionary and sensing matrices (right
ﬁgure) signiﬁcantly outperforms classical CS, where for example a random
sensing matrix is used in conjunction with an independently learned dictionary
(left ﬁgure) .
designed for a certain class of signals can further improve
the reconstruction accuracy or further reduce the necessary
number of samples. In , the authors extended the formulation in (11) to design a framework for the joint design
and optimization, from a set of training images, of the nonparametric dictionary and the sensing matrix Φ,
(A∗, D∗, Φ∗) = arg min
A,D,Φ ∥X −DA∥2
F + λ1 ∥Y −ΦDA∥2
(ΦD)T (ΦD) −I
F + λ3 ∥A∥p .
In this formulation we include the sensing matrix Φ in
the optimization, the sensed signal Y obtained from the data
= ΦX, and the critical term that encourages
orthogonality of the components of the effective dictionary
ΦD, as suggested by the critical restricted isometry property in
CS (see for details on the optimization of this functional).
This joint optimization outperforms both the use of random
sensing matrices and those matrices that are optimized independently of the learning of the dictionary, Figure 6. Particular
cases of the proposed framework include the optimization
of the sensing matrix for a given dictionary as well as
the optimization of the dictionary for a pre-deﬁned sensing
environment (see also , , ).
E. Remarks on Dictionary Learning
In this section we brieﬂy discussed the topic of dictionary
learning. We illustrated with a number of examples the importance of learning the dictionary for the task as well as
the processing and acquisition pipeline. Sparse modeling, and
in particular the (semi-) supervised case, can be considered
as a non-linear extension of metric learning (see for
bibliography on the subject and for details on the connections between sparse modeling and metric learning). Such
interesting connection brings yet another exciting aspect into
the ongoing sparse modeling developments. The connection
with (regression) approaches based on Dirichlet priors, e.g.,
 and references therein, is yet another interesting area for
future research.
PROCEEDINGS OF IEEE, MARCH 2009
V. FINAL REMARKS
The examples considered in this paper illustrate several
important aspects in the application of sparse representation
to problems in computer vision. First, sparsity provides a
powerful prior for inference with high-dimensional visual
data that have intricate low-dimensional structures. Methods
like ℓ1-minimization offer computational tools to extract such
structures and hence help harness the semantics of the data.
As we have seen in the few highlighted examples, if properly
applied, algorithms based on sparse representation can often
achieve state-of-the-art performance. Second, the key to realizing this power is choosing the dictionary in such a way that
sparse representations with respect to the dictionary correctly
reveal the semantics of the data. This can be done implicitly, by
building the dictionary from data with linear or locally linear
structure, or explicitly, by optimizing various measures of how
informative the dictionary is. Finally, rich data and problems in
computer vision provide new examples for the theory of sparse
representation, in some cases demanding new mathematical
analysis and justiﬁcation. Understanding the performance of
the resulting algorithms can greatly enrich our understanding
of both sparse representation and computer vision.
ACKNOWLEDGMENT
JW and YM thank their colleagues on the work of face
recognition, A. Ganesh, S. Sastry, A. Yang, A. Wagner, and
Z. Zhou and the work on motion segmentation, S. Rao, R.
Tron, and R. Vidal. Their work is partially supported by NSF,
ONR, and a Microsoft Fellowship.
GS thanks his partners and teachers in the journey of sparse
modeling, F. Bach, J. Duarte, M. Elad, F. Lecumberry, J.
Mairel, J. Ponce, I. Ramirez, F. Rodriguez, and A. Szlam.
J. Duarte, F. Lecumberry, J. Mairal, and I. Ramirez produced
the images and results in the dictionary learning section. GS
is partially supported by ONR, NGA, NSF, NIH, DARPA, and
SC thanks Huan Wang, Bin Cheng, and Jianchao Yang
for the work of ℓ1-graph. His work is partially supported by
NRF/IDM grant NRF2008IDM-IDM004-029.
The work of TSH was supported in part by IARPA VACE