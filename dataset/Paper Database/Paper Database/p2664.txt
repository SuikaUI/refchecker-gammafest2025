Prototype RectiÔ¨Åcation for Few-Shot Learning
Jinlu Liu, Liang Song, and Yongqiang Qin‚ãÜ
AInnovation Technology Co., Ltd.
liujinlu, songliang, 
Abstract. Few-shot learning requires to recognize novel classes with
scarce labeled data. Prototypical network is useful in existing researches,
however, training on narrow-size distribution of scarce data usually tends
to get biased prototypes. In this paper, we Ô¨Ågure out two key inÔ¨Çuencing factors of the process: the intra-class bias and the cross-class bias.
We then propose a simple yet eÔ¨Äective approach for prototype rectiÔ¨Åcation in transductive setting. The approach utilizes label propagation to
diminish the intra-class bias and feature shifting to diminish the crossclass bias. We also conduct theoretical analysis to derive its rationality
as well as the lower bound of the performance. EÔ¨Äectiveness is shown on
three few-shot benchmarks. Notably, our approach achieves state-of-theart performance on both miniImageNet (70.31% on 1-shot and 81.89%
on 5-shot) and tieredImageNet (78.74% on 1-shot and 86.92% on 5-shot).
Keywords: Few-Shot Learning ¬∑ Prototype RectiÔ¨Åcation ¬∑ Intra-Class
Bias ¬∑ Cross-Class Bias
Introduction
Many deep learning based methods have achieved signiÔ¨Åcant performance on
object recognition tasks with abundant labeled data provided . However,
these methods generally perform unsatisfactorily if the labeled data is scarce.
To reduce the dependency of data annotation, more researchers make eÔ¨Äorts to
develop powerful methods to learn new concepts from very few samples, which
is so-called Few-Shot Learning (FSL) . In FSL, we aim to learn prior
knowledge on base classes with large amounts of labeled data and utilize the
knowledge to recognize few-shot classes with scarce labeled data. It is usually
formed as N-way K-shot few-shot tasks where each task consists of N few-shot
classes with K labeled samples per class (the support set) and some unlabeled
samples (the query set) for test.
Classifying test samples by matching them to the nearest class prototype 
is a common practice in FSL. It is supposed that an expected prototype has the
minimal distance to all samples within the same class. However, the prototypes
they get are always biased due to the data scarcity in few-shot scenarios. The
internal factors that restrict the representation ability of the prototypes should
be identiÔ¨Åed for performance improvement. Hence, we Ô¨Ågure out the bias in
‚ãÜCorresponding author.
 
J. Liu et al.
prototype computation and accordingly propose the diminishing methods for
rectiÔ¨Åcation.
Basic Prototypes
Rectified Prototypes
Features of
Query Samples
Features of
Pseudo-Labeled
Query Samples
Features of
Support Samples
Cross-Class Bias Diminishing (ùë©ùë´ùíÑùíìùíêùíîùíî)
Intra-Class Bias Diminishing (ùë©ùë´ùíäùíèùíïùíìùíÇ)
Features of
Query Samples
(after ùêµùê∑-./00)
Fig. 1. Framework of our proposed method for prototype rectiÔ¨Åcation. The cross-class
bias diminishing module reduces the bias between the support set and the query set
while the intra-class bias diminishing module reduces the bias between the actually
computed prototypes and the expected prototypes.
In this paper, we target to Ô¨Ånd the expected prototypes which have the
maximum cosine similarity to all data points within the same class. The cosine
similarity based prototypical network (CSPN) is Ô¨Årstly proposed to extract discriminative features and compute basic prototypes from the limited samples. In
CSPN, we Ô¨Årstly train a feature extractor with a cosine classiÔ¨Åer on the base
classes. The cosine classiÔ¨Åer has a strong capability of driving the feature extractor to learn discriminative features. It learns an embedding space where features
belonging to the same class cluster more tightly. At the inference stage, we use
class means as the basic prototypes of few-shot classes. ClassiÔ¨Åcation can be
directly performed by nearest prototype matching based on cosine similarity.
Since the basic prototypes are biased due to data scarcity, we import a bias
diminishing module into the network for prototype rectiÔ¨Åcation, which is called
BD-CSPN in this paper. We Ô¨Ågure out two key factors: the intra-class bias and
the cross-class bias, which inÔ¨Çuence the representativeness of class prototypes.
The approach to reduce the bias is accordingly proposed as shown in Fig. 1. The
intra-class bias refers to the distance between the expectedly unbiased prototype and the prototype actually computed from the available data. To reduce
it, we adopt the pseudo-labeling strategy to add unlabeled samples with high
prediction conÔ¨Ådence into the support set in transductive setting. Considering
that some of the pseudo-labeled samples are possibly misclassiÔ¨Åed, we use the
weighted sum as the modiÔ¨Åed prototypes instead of simple averaging. It avoids
bringing larger bias into prototype computation. The cross-class bias refers to
the distance between the representative vectors of training and test datasets,
Prototype RectiÔ¨Åcation for Few-Shot Learning
which are commonly represented as the mean vectors. We reduce it by importing a shifting term Œæ to the query samples, driving them to distribute closely to
the support samples.
To verify the rationality of our bias diminishing method, we give the theoretical analysis in Section 4. The derivation of the expected performance of
cosine-similarity based prototypical network is Ô¨Årstly given. It shows that the
lower bound of the expected accuracy is positively correlated with the number of
samples. We demonstrate the eÔ¨Äectiveness and simplicity of our pseudo-labeling
strategy in raising the lower bound, which leads to signiÔ¨Åcant improvement as
shown in experiments. Then we give the derivation of shifting term Œæ in crossclass bias diminishing. In conclusion, we argue that our method is simpler yet
more eÔ¨Écient than many complicated few-shot learning methods. Also, it is
mathematically rigorous with the theoretical analysis.
Our contributions are summarized as:
1) We Ô¨Ågure out the internal factors: the intra-class bias and the cross-class
bias which restrict the representational ability of class prototypes in fewshot learning.
2) We propose the bias diminishing module for prototype rectiÔ¨Åcation, which is
mainly conducted by pseudo-labeling and feature shifting. It is conceptually
simple but practically eÔ¨Äective to improve the performance.
3) To verify the rationality of the intra-class bias diminishing method, we theoretically analyze the correlation between the number of sample and the lower
bound of the expected performance. Furthermore, we give the derivation of
the shifting term in cross-class bias diminishing.
4) We conduct extensive experiments on three popular few-shot benchmarks
and achieve the state-of-the-art performance. The experiment results demonstrate that our proposed bias diminishing module can bring in signiÔ¨Åcant
improvement by a large margin.
Related Works
Few-Shot Learning Few-shot learning methods can be divided into two groups:
gradient based methods and metric learning based methods. Gradient based methods focus on fast adapting model parameters to new tasks through gradient descent . Typical methods such as MAML and Reptile aim
to learn a good parameter initialization that enables the model easy to Ô¨Åne-tune.
In this section, we focus on metric learning based methods which are more closely
to our approach. Metric learning based methods learn an informative metric to
indicate the similarity relationship in the embedding space . Relation
network learns a distance metric to construct the relation of samples within
an episode. The unlabeled samples thus can be classiÔ¨Åed according to the computed relation scores. Prototypical Networks (PN) views the mean feature
as the class prototype and assigns the points to the nearest class prototype based
on Euclidean distance in the embedding space. It is indicated in that PN
shows limited performance in the high-dimensional embedding space. In some
J. Liu et al.
recent works, models trained with a cosine-similarity based classiÔ¨Åer are more
eÔ¨Äective in learning discriminative features . In this paper, we use cosine
classiÔ¨Åer to learn a discriminative embedding space and compute the cosine distance to the class prototype (mean) for classiÔ¨Åcation. The prototype computed
in the discriminative feature space is more robust to represent a class.
According to the test setting, FSL can be divided into two branches: inductive few-shot learning and transductive few-shot learning. The former predicts
the test samples one by one while the latter predicts the test samples as a whole.
Early proven in , transductive inference outperforms inductive inference
especially when training data is scarce. Some literatures recently attack fewshot learning problem in transductive setting. In , the shared information
between test samples via normalization is used to improve classiÔ¨Åcation accuracy. DiÔ¨Äerent from , TPN adopts transductive inference to alleviate
low-data problem in few-shot learning. It constructs a graph using the union of
the support set and the query set, where labels are propagated from support
to query. Under transductive inference, the edge-labeling graph neural network
(EGNN) proposed in learns more accurate edge-labels through exploring the
intra-cluster similarity and the inter-cluster dissimilarity. Our method takes the
advantage of transductive inference that samples with higher prediction conÔ¨Ådence can be obtained when the test samples are predicted as a whole.
Semi-Supervised Few-Shot Learning In semi-supervised few-shot learning, an extra unlabeled set not contained in current episode is used to improve
classiÔ¨Åcation accuracy . In , the extended versions of Prototypical
Networks are proposed to use unlabeled data to create class prototypes by
Soft k-Means. LST employs pseudo-labeling strategy to the unlabeled set,
then it re-trains and Ô¨Åne-tunes the base model based on the pseudo-labeled data.
For recognizing the novel classes, it utilizes dynamically sampled data which is
not contained in the current episode. DiÔ¨Äerent from these methods, the unlabeled data in our method comes from the query set and we requires no extra
datasets besides the support and query set.
Methodology
We Ô¨Årstly use cosine similarity based prototypical network (CSPN) to learn a
discriminative feature space and get the basic prototypes of few-shot classes.
Then we Ô¨Ågure out two inÔ¨Çuencing factors in prototype computation: the intraclass bias and the cross-class bias. Accordingly, we propose the bias diminishing
(BD) method for prototype rectiÔ¨Åcation in transductive setting.
Denotation
At the training stage, a labeled dataset D of base classes Cbase is given to train
the feature extractor FŒ∏(¬∑) and the cosine classiÔ¨Åer C(¬∑|W). At the inference
stage, we aim to recognize few-shot classes Cfew with K labeled images per
class. Episodic sampling is adopted to form such N-way K-shot tasks. Each
Prototype RectiÔ¨Åcation for Few-Shot Learning
episode consists of a support set S and a query set Q. In the support set, all
samples x are labeled and we use the extracted features X = FŒ∏(x) to compute
the prototypes P of few-shot classes. The samples in the query set are unlabeled
Cosine Similarity Based Prototypical Network
We propose a metric learning based method: cosine similarity based prototypical
network (CSPN) to compute the basic prototypes of few-shot classes. Training
a good feature extractor that can extract discriminative features is of great importance. Thus, we Ô¨Årstly train a feature extractor FŒ∏(¬∑) with a cosine similarity
based classiÔ¨Åer C(¬∑|W) on the base classes. The cosine classiÔ¨Åer C(¬∑|W) is:
C(FŒ∏(x) | W) = Softmax(œÑ ¬∑ Cos(FŒ∏(x), W))
where W is the learnable weight of the base classes and œÑ is a scalar parameter. We target to minimize the negative log-likelihood loss on the supervised
classiÔ¨Åcation task:
L(Œ∏, W | D) = E[‚àílogC(FŒ∏(x) | W)]
At the inference stage, retraining FŒ∏(¬∑) and classiÔ¨Åcation weights on the scarce
data of Cfew classes is likely to run into overÔ¨Åtting. To avoid it, we directly
compute the basic prototype Pn of class n as follows:
where X is the normalized feature of support samples. The query samples can
be classiÔ¨Åed by Ô¨Ånding the nearest prototype based on cosine similarity.
Bias Diminishing for Prototype RectiÔ¨Åcation
In CSPN, we can obtain the basic prototypes by simply averaging the features
of support samples. However, the prototypes computed in such low-data regimes
are biased against the expected prototypes we want to Ô¨Ånd. Therefore, we identify two inÔ¨Çuencing factors: the intra-class bias and the cross-class bias, and
accordingly propose the bias diminishing approach.
The intra-class bias within a class is deÔ¨Åned by Eq. (4):
Bintra = EX‚Ä≤‚àºpX‚Ä≤ [X
‚Ä≤] ‚àíEX‚àºpX[X]
where pX‚Ä≤ is the distribution of all data belonging to a certain class and pX is
the distribution of the available labeled data of this class. It is easy to observe
the diÔ¨Äerence between the expectations of the two distributions. The diÔ¨Äerence
becomes more signiÔ¨Åcant in low-data regimes. Since the prototype is computed
by feature averaging, the intra-class bias also can be understood as the diÔ¨Äerence between the expected prototype and the actually computed prototype. The
J. Liu et al.
expected prototype is supposed to be represented by the mean feature of all samples within a class. In practice, only a part of samples are available for training
which is to say that, it is almost impossible to get the expected prototype. In
few-shot scenario, we merely have K samples per few-shot class. The number of
available samples are far less than the expected amount. Computed from scarce
samples, the prototypes obviously tend to be biased.
To reduce the bias, we adopt the pseudo-labeling strategy to augment the
support set, which assigns temporary labels to the unlabeled data according
to their prediction conÔ¨Ådence . Pseudo-labeled samples can be augmented
into the support set such that we can compute new prototypes in a ‚Äòhigherdata‚Äô regime. We can simply select top Z conÔ¨Ådently predicted query samples
per class to augment the support set S with their pseudo labels. We use CSPN
as recognition model to get the prediction scores. Then we have an augmented
support set with conÔ¨Ådently predicted query samples: S‚Ä≤ = S ‚à™QZ
pseudo. Since
some pseudo-labeled samples are likely to be misclassiÔ¨Åed, simple averaging with
the same weights is possible to result in larger bias in prototype computation.
To compute the new prototypes in a more reasonable way, we use the weighted
‚Ä≤ as the rectiÔ¨Åed prototype. We note that X
‚Ä≤ refers to the feature of the
sample in S‚Ä≤ including both original support samples and pseudo-labeled query
samples. The rectiÔ¨Åed prototype of a class is thus computed from the normalized
features X
i=1 wi,n ¬∑ X
where wi,n is the weight indicating the relation of the augmented support samples
and the basic prototypes. The weight is computed by:
exp(Œµ ¬∑ Cos(X
j=1 exp(Œµ ¬∑ Cos(X
Œµ is a scalar parameter and Pn is the basic prototype obtained in Section 3.2.
Samples with larger cosine similarity to the basic prototypes hold larger proportions in prototype rectiÔ¨Åcation. Compared with the basic prototype Pn, the
rectiÔ¨Åed prototype P
n distributes closer to the expected prototype.
The cross-class bias refers to the distance between the mean vectors of
support and query datasets. It is derived from the domain adaptation problem
where the mean value is used as a type of the Ô¨Årst order statistic information to
represent a dataset . Minimizing the distance between diÔ¨Äerent domains is a
typical method of mitigating domain gaps. Since the support set and the query
set are assumed to distribute in the same domain, the distance between them is
the distribution bias rather than the domain gap. The cross-class bias Bcross is
formulated as:
Bcross = EXs‚àºpS[Xs] ‚àíEXq‚àºpQ[Xq]
where pS and pQ respectively represent the distributions of support and query
sets. Notably, the support set S and the query set Q include N few-shot classes
in Eq. (7). To diminish Bcross, we can shift the query set towards the support
Prototype RectiÔ¨Åcation for Few-Shot Learning
set. In practice, we add a shifting term Œæ to each normalized query feature Xq
and Œæ is deÔ¨Åned as:
i=1Xi,s ‚àí1
The detailed derivation of Œæ is given in the next section.
Theoretical Analysis
We give the theoretical analysis to show the rationality of our proposed bias
diminishing method.
Lower Bound of the Expected Performance
We derive the formulation of our expected performance in theory and point out
what factors inÔ¨Çuence the Ô¨Ånal result. We use X to represent the feature of a
class. For clear illustration, the formulation of class prototype we use in this
section is given:
where T = K + Z, X
‚Ä≤ is a subset sampled from X. X is the normalized feature and P is the normalized prototype. For cosine similarity based
prototypical network, an expected prototype should have the largest cosine similarity to all samples within its class. Our objective is to maximize the expected
cosine similarity which is positively correlated with the classiÔ¨Åcation accuracy.
It is formulated as:
max EP [EX[Cos(P, X)]]
And we derive it as:
EP [EX[Cos(P, X)]] = EP,X[P ¬∑ X]
= E[X] ¬∑ E[
From previous works , we know that:
B ] = E[A]
E[B] + O(n‚àí1)
(first order)
where A and B are random variables. In Eq. (12), E[A]
E[B] is the Ô¨Årst order estimator
B ]. Thus, Eq. (11) is approximate to:
EP [EX[Cos(P, X)]] ‚âàE[X] ¬∑ E[P]
J. Liu et al.
Based on Cauchy-Schwarz inequality, we have:
P and X are D-dimensional vectors which can be denoted as P = [p1, p2, ..., pD]
and X = [x1, x2, ..., xD] respectively. In our method, we assume that each dimension of a vector is independent from each other. Then, we can derive that:
i=1[V ar[pi] + E[pi]2]
i=1[V ar[pi] + E[xi]2]
T V ar[xi] + E[xi]2]
Thus, the lower bound of the expected cosine similarity is formulated as:
EP [EX[Cos(P, X)]] ‚â•E[X] ¬∑ E[P]
i=1V ar[xi] + PD
Maximizing the expected accuracy is approximate to maximize its lower
bound of the cosine similarity as shown in Eq. (16). It can be seen that the
number T of the sample is positively correlated with the lower bound of the
expected performance. Thus, we import more pseudo-labeled samples into prototype computation. The rationality of the pseudo-labeling strategy in improving
few-shot accuracy is that, it can eÔ¨Äectively raise the lower bound of the expected
performance.
Derivation of Shifting Term Œæ
We propose to reduce the cross-class bias by feature shifting and the derivation
of shifting term Œæ is provided as follows. In N-way K-shot Q-query tasks, the
accuracy can be formalized as:
1(yi,q == i)
1(Cos(Pi, Xi,q) > max
jÃ∏=i {Cos(Pj, Xi,q)})
where yi,q is the predicted label and i is the true class label. 1(b) is an indicator
function. 1(b) = 1 if b is true and 0 otherwise. Pi is the prototype of class i
Prototype RectiÔ¨Åcation for Few-Shot Learning
and Xi,q is the q-th query feature of class i. Based on Eq. (18), the accuracy
formulation can be further rewritten as:
1(Cos(Pi, Xi,q) > ti)
where ti denotes the cosine similarity threshold of the i-th class. Improving the
accuracy is equal to maximize the cosine similarity Cos(¬∑).
As mentioned above, there is a bias between the support and query set of a
class i. We assume that the bias can be diminished by adding a shifting term Œæi
to the query samples. Since the class labels are unknown, we approximately add
the same term Œæ to all query samples. The term Œæ should follow the objective:
Cos(Pi, Xi,q + Œæ)
We assume that each feature X can be represented as X = P + œµ. Eq. (20)
can be further formalized as:
Cos(Pi, Pi + œµi,q + Œæ)
To maximize the cosine similarity, we should minimize the following objective:
(œµi,q + Œæ)
The term Œæ is thus computed:
(Pi ‚àíXi,q)
We can see that Eq. (24) is in line with Eq. (8). For cosine similarity computation, the shifting term is calculated from the normalized features as displayed in
Section 3.3.
Experiments
miniImageNet consists of 100 randomly chosen classes from ILSVRC-2012
 . We adopt the split proposed in where the 100 classes are split into 64
training classes, 16 validation classes and 20 test classes. Each class contains 600
images of size 84 √ó 84. tieredImageNet is also a derivative of ILSVRC-2012
 containing 608 low-level categories, which are split into 351, 97, 160 categories for training, validation, test with image size of 84 √ó 84. Meta-Dataset
 is a new benchmark that is large-scale and consists of diverse datasets for
training and evaluating models.
J. Liu et al.
Implementation details
We train the base recognition model CSPN in the supervised way with SGD
optimizer and test the validation set on 5-way 5-shot tasks for model selection.
WRN-28-10 is used as the main backbone. ConvNets and ResNet-12
 are used for ablation. The results are averaged from 600 randomly sampled
episodes. Each episode contains 15 query samples per class. The initial value of œÑ
is 10 and Œµ is Ô¨Åxed at 10. More details are shown in the supplementary materials.
Table 1. Average accuracy (%) comparison on miniImageNet. ‚Ä° Training set and
validation set are used for training.
miniImageNet
Matching Network 
ConvNet-64
43.56¬±0.84
55.31¬±0.73
ConvNet-32
48.70¬±1.84
63.11¬±0.92
Prototypical Networks‚Ä° 
ConvNet-64
49.42¬±0.78
68.20¬±0.66
Relation Net 
ConvNet-256 50.44¬±0.82
65.32¬±0.70
SNAIL 
55.71¬±0.99
68.88¬±0.92
ConvNet-128 56.20¬±0.86
73.00¬±0.64
AdaResNet 
56.88¬±0.62
71.94¬±0.57
TADAM 
58.50¬±0.30
76.70¬±0.30
Activation to Parameter‚Ä° WRN-28-10
59.60¬±0.41
73.74¬±0.19
61.76¬±0.08
77.59¬±0.12
MetaOptNet-SVM 
62.64¬±0.61
78.63¬±0.46
62.93¬±0.45
79.87¬±0.33
Semi-Supervised
ConvNet-128 49.04¬±0.31
62.96¬±0.14
Transductive
ConvNet-64
55.51¬±0.86
69.86¬±0.65
ConvNet-256
Transductive Fine-Tuning WRN-28-10
65.73¬±0.68
78.40¬±0.52
BD-CSPN (ours)
WRN-28-10 70.31¬±0.93 81.89¬±0.60
Results on miniImageNet and tieredImageNet
The results on miniImageNet and tieredImageNet are shown in Table 1 and Table 2 respectively. It can be seen that we achieve state-of-the-art performance in
all cases. Compared with existing transductive methods , our proposed
BD-CSPN consistently achieves the best performance on both datasets. EGNN
 transductively learns edge-labels through exploring the intra-cluster similarity and the inter-cluster dissimilarity. Transductive Fine-Tuning is newly
published, providing a strong baseline by simple Ô¨Åne-tuning techniques. In comparison with TPN , we achieve better results with a simpler implementation of label propagation technique. Given the similar backbone ConvNet-128
Prototype RectiÔ¨Åcation for Few-Shot Learning
Table 2. Average accuracy (%) comparison on tieredImageNet. * Results by our implementation. ‚Ä° Training set and validation set are used for training.
tieredImageNet
ConvNet-32
51.67¬±1.81
70.30¬±1.75
Prototypical Networks‚Ä° 
ConvNet-64
53.31¬±0.89
72.69¬±0.74
Relation Net 
ConvNet-256 54.48¬±0.93
71.32¬±0.78
ConvNet-128 60.35¬±0.88* 77.24¬±0.72*
66.33¬±0.05
81.44¬±0.09
MetaOptNet-SVM 
65.99¬±0.72
81.56¬±0.53
Semi-Supervised
ConvNet-128 51.38¬±0.38
69.08¬±0.25
Transductive
ConvNet-64
59.91¬±0.94
73.30¬±0.75
ConvNet-256
Transductive Fine-Tuning WRN-28-10
73.34¬±0.71
85.50¬±0.50
BD-CSPN (ours)
WRN-28-10 78.74¬±0.95 86.92¬±0.63
on miniImageNet, BD-CSPN produces good results of 61.74% and 76.12% on
1-shot and 5-shot tasks respectively, surpassing TPN by large margins.
Our method also shows superiority compared with existing semi-supervised
methods . Note that LST uses extra unlabeled data as auxiliary information in evaluation, which is not contained in current episode. It re-trains and
Ô¨Åne-tunes the model on each novel task. We have a simpler technique without
re-training and Ô¨Åne-tuning which is more eÔ¨Écient in computation.
Results on Meta-Dataset
To further illustrate the eÔ¨Äectiveness of our method, we show 5-shot results on
the newly proposed Meta-Dataset in Table 3. The average rank of our 5-shot
model is 1.9. More details are provided in our supplementary materials.
Table 3. 5-shot results on Meta-Dataset: the model is trained on ILSVRC-2012 only
and test on the listed test sources.
Test 5-shot
Test 5-shot
Test 5-shot
Test 5-shot
Test 5-shot
ILSVRC 59.80 Omniglot 78.29
Aircraft 43.42
Birds 67.22
Textures 54.82
Quick Draw 58.80
Fungi 61.56 VGG Flower 83.88 TraÔ¨Éc Signs 68.68 MSCOCO 52.69
Ablation Study
The ablation results are shown in Table 4. We display the results of CSPN as
baselines which are obtained in inductive setting. The network is trained on
traditional supervised tasks (64-way), following the setting in . It achieves
J. Liu et al.
better performance than some complicated meta-trained methods with
the same backbone, as shown in Table 1. Based on CSPN, our BD module makes
an improvement by large margins up to 9% and 3% on 1-shot and 5-shot tasks
respectively. It leads to relatively minor improvements in 5-shot scenarios.
Table 4. Ablative results of bias diminishing module. CSPN: without bias diminishing modules; BDc-CSPN: with cross-class bias diminishing module; BDi-CSPN: with
intra-class bias diminishing module; BD-CSPN: with both modules.
1-shot 5-shot
1-shot 5-shot
miniImageNet
61.84 78.64
tieredImageNet
69.20 84.31
BDc-CSPN 62.54 79.32
BDc-CSPN 70.84 84.99
BDi-CSPN 69.81 81.58
BDi-CSPN 78.12 86.67
BD-CSPN 70.31 81.89
BD-CSPN 78.74 86.92
Ablation of Intra-Class Bias Diminishing It can be seen in Table 4 that
BDi-CSPN brings in signiÔ¨Åcant improvements on both datasets. The intra-class
bias diminishing module especially shows its merit in 1-shot scenarios. With
intra-class bias diminished, the accuracy on 1-shot miniImageNet increases from
61.84% to 69.81% and the accuracy on 1-shot tieredImageNet raises to 78.12%
from 69.20%.
Furthermore, to intuitively demonstrate the inÔ¨Çuence of our proposed intraclass bias diminishing module, we display the 5-way accuracy in Fig. 2(a)-2(b).
The results are reported without using cross-class bias diminishing module. It
shows a coincident tendency that with more pseudo-labeled samples, there is an
obvious growth of classiÔ¨Åcation accuracy. We use the validation set to determine
the value of Z and set it to 8 for accuracy comparison in Table 1 and Table 2.
Theoretical Value As we know, the expected accuracy Acc(P, X) has a
positive correlation with the expected cosine similarity. Then we derive the Ô¨Årstorder estimation of Acc(P, X) from Eq. (16) which is formulated as:
Acc(P, X) ‚âàŒ∑ ¬∑
where Œ∑ is a coeÔ¨Écient and K + Z = T. Œª and Œ± are values correlated with the
variance term and the expectation term in Eq. (16). The theoretical values of Œª
and Œ± can be approximately computed from the extracted features. Furthermore,
we can compute the value of Œ∑ by 1-shot and 5-shot accuracies of CSPN. Thus,
the number Z is the only variable in Eq. (25). The theoretical curves are displayed as the dashed lines in Fig. 2(c) to show the impact of Z on classiÔ¨Åcation
accuracy. The dashed lines, showing the theoretical lower bound of the expected
accuracy, have a consistent tendency with our experiment results in Fig. 2(a)-
2(b). Since the cosine similarity is continuous and the accuracy is discrete, the
accuracy stops increasing when the cosine similarity grows to a certain value.
Prototype RectiÔ¨Åcation for Few-Shot Learning
Fig. 2. EÔ¨Äectiveness of intra-bias diminishing. Z: the number of pseudo-labeled samples. (a) 5-way 1-shot results. (b) 5-way 5-shot results. (c) Theoretical value on mini-
ImageNet. The experiment results (solid lines) show a consistent tendency with the
theoretical results (dashed lines).
T-SNE Visualization We show t-SNE visualization of our intra-bias diminishing method in Fig. 3(a) for intuitive illustration. The basic prototype of
each class is computed from the support set while the rectiÔ¨Åed prototype is computed from the augmented support set. In this section, the expected prototype
refers to the Ô¨Årst term in Eq. (4) which is represented by the average vector of
all samples (both support and query samples) of a class in an episode. Due to
the scarcity of labeled samples, there is a large bias between the basic prototype
and the expected prototype. The bias can be reÔ¨Çected by the distance between
the stars and the triangles in Fig. 3(a).
Ablation of Cross-Class Bias Diminishing Table 4 shows the ablative results of the cross-class bias diminishing module. It illustrates an overall improvement as a result of diminishing the cross-class bias. Moving the whole query set
towards the support set center by importing the shifting term Œæ is an eÔ¨Äective
approach to reduce the bias between the two datasets. For example, the accuracy
increases by 1.64% on 1-shot tieredImageNet.
T-SNE Visualization
In few-shot learning, the support set includes far
less samples compared with the query set in an episode. There exists a large
distance between the two mean vectors of the datasets. We aim to decrease
the distance by shifting the query samples towards the center of the support
set as shown in Fig. 3(b). It depicts the spatial changing of the query samples,
before and after cross-class bias diminishing. The signiÔ¨Åcant part is zoomed in
for clear visualization, where the query samples with BDcross (marked in green)
distribute more closely to the center of support set.
Ablation of Backbone The results on miniImageNet are displayed in Table 5
and more ablation results are given in the supplementary materials. Our method
also shows good performance based on ConvNet-128 and ResNet-12, which is
J. Liu et al.
basic prototype
(a) T-SNE visualization of BDintra
(b) T-SNE visualization of BDcross
Fig. 3. We randomly sample a 5-way 1-shot episode on tieredImageNet. DiÔ¨Äerent
classes are marked in diÔ¨Äerent colors. Best viewed in color with zoom in.
Table 5. Ablation of backbones and result comparison with TFT (Transductive
Fine-Tuning ) on miniImageNet. * The backbone is ConvNet-64.
CSPN BD-CSPN TFT 5-shot
CSPN BD-CSPN TFT
ConvNet-128 55.62
50.46* ConvNet-128 72.57
62.35 ResNet-12
65.73 WRN-28-10
better than most approaches in Table 1. For example, with ResNet-12, we achieve
79.23% in 5-shot scenario, outperforming the strongest baselines: 78.7% and
78.63% .
Comparison with Transductive Fine-Tuning
We compare our method with TFT in Table 5, which is recently proposed as
a new baseline for few-shot image classiÔ¨Åcation. BD-CSPN outperforms it given
diÔ¨Äerent backbones. For example, we achieve better results which are higher
than TFT by 3% to 5% given ResNet-12. Since BD-CSPN and TFT conduct
experiments in the same transductive setting, the comparison between these two
methods is more persuasive to demonstrate the eÔ¨Äectiveness of the approach.
Conclusions
In this paper, we propose a powerful method of prototype rectiÔ¨Åcation in fewshot learning, which is to diminish the intra-class bias and the cross-class bias of
class prototypes. Our theoretical analysis veriÔ¨Åes that, the proposed bias diminishing method is eÔ¨Äective in raising the lower bound of the expected performance.
Extensive experiments on three few-shot benchmarks demonstrate the eÔ¨Äectiveness of our method. The proposed bias diminishing method achieves signiÔ¨Åcant
improvements in transductive setting by large margins (e.g. 8.47% on 1-shot
miniImageNet and 9.54% on 1-shot tieredImageNet).
Prototype RectiÔ¨Åcation for Few-Shot Learning
Implementation Details
WRN-28-10 , is used as the main backbone in the experiments. ConvNet-64
 , ConvNet-128 , ConvNet-256 and ResNet-12 are used in ablation
study. We remove the last ReLU layer of WRN-28-10 in experiments. The results
reported in our experiments are collected by sampling 600 episodes with 95%
conÔ¨Ådence intervals. We choose SGD as the optimizer with a momentum of 0.9
and a weight decay parameter of 0.0005. The maximum training epoch is set to
60. The initial learning rate is 0.1 and it is reduced after 10, 20, 40 epochs. At
the training stage, we use horizontal Ô¨Çip and random crop on the two ImageNet
derivatives as in .
Results on Omniglot and CUB
We conduct extra experiments on another two benchmarks: Omniglot and
Omniglot Omniglot has 1623 classes of handwritten characters with 20 samples
per class. All images are resized to 28 x 28. The data augmentation techniques
proposed by are used in higher-way test, which rotates each image by
90, 180, 270 degrees to form new classes. Therefore, the dataset has total 6492
classes and we use 4112 classes for training, 688 classes for validation and 1692
classes for test as in .
Table 6. Results on Omniglot.
Omniglot CSPN BD-CSPN CSPN BD-CSPN
ConvNet-64
ConvNet-128 97.33
ConvNet-256 97.85
CUB We use the Caltech-UCSD Birds (CUB) 200-2011 dataset of 200 Ô¨Ånegrained bird species. The dataset is split into 100 training classes, 50 validation
classes and 50 test classes as provided in .
J. Liu et al.
Table 7. Results on CUB.
CSPN BD-CSPN CSPN BD-CSPN
ConvNet-64
ConvNet-128 65.86
ConvNet-256 65.99
Additional Ablation on miniImageNet and tieredImageNet
We provide supplementary ablation study on miniImageNet and tieredImageNet
to show our performance on diÔ¨Äerent backbones.
Table 8. Backbone ablation on miniImageNet.
miniImageNet 1-shot 5-shot
ConvNet-64
ConvNet-256
Table 9. Backbone ablation on tieredImageNet.
tieredImageNet 1-shot 5-shot
ConvNet-64
ConvNet-128
ConvNet-256
Higher-way Results
Results on higher-way tasks are given in Table 10 to Table 12 to show the
eÔ¨Äectiveness of our method in harder tasks.
Prototype RectiÔ¨Åcation for Few-Shot Learning
Table 10. Higher-way test on miniImageNet.
miniImageNet 1-shot 5-shot
Table 11. Higher-way test on tieredImageNet.
tieredImageNet 1-shot 5-shot
Table 12. Higher-way test on Omniglot.
CSPN BD-CSPN CSPN BD-CSPN
ConvNet-128 92.83
ConvNet-256 93.82
ConvNet-64
ConvNet-64
J. Liu et al.
Robust Test
We conduct an experiment as follows to test the robustness of the proposed BD-
CSPN. In each 5-way K-shot 15-query episode, we randomly add extra 15√óN‚Äô
samples of N‚Äô classes that do not belong to the 5 classes. The extra samples
are treated as unlabeled data. Our model shows good robustness (aka little
performance drop) in 5-shot cases. The accuracy decreases to some extents when
the unlabeled data increases.
Table 13. Robust test on miniImageNet. Acc: the accuracy of the labeled 5√ó15 query
data. mAP: it is computed from top-15 conÔ¨Ådently predicted data of each class.
miniImageNet N‚Äô=1
1-shot Acc
66.88 (3.43‚Üì) 64.58 (5.73‚Üì)
5-shot Acc
80.31 (1.58‚Üì) 79.25 (2.64‚Üì)
1-shot mAP
5-shot mAP
Results on Meta-Dataset
Meta-Dataset is a new benchmark for few-shot learning. It is large-scale
and consists of diverse datasets for training and evaluating models. We show our
results in Table 14 and the ranks of our 5-shot model. For detailed comparison,
please refer to Table 1 (top) in .
Table 14. Results on Meta-Dataset. Avg. rank of our 5-shot model is 1.9.
Test Source 1-shot
45.57 59.80 (1)
66.77 78.29 (1)
32.85 43.42 (7)
49.41 67.22 (3)
40.64 54.82 (1)
Quick Draw
45.52 58.80 (1)
44.65 61.56 (1)
VGG Flower 69.97 83.88 (4)
TraÔ¨Éc Signs 53.93 68.68 (1)
40.06 52.69 (1)
Prototype RectiÔ¨Åcation for Few-Shot Learning