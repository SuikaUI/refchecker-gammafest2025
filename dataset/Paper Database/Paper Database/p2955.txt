Algebraic Methods for Deterministic
Blind Beamforming
ALLE-JAN VAN DER VEEN, MEMBER, IEEE
Invited Paper
Deterministic blind beamforming algorithms try to separate
superpositions of source signals impinging on a phased antenna
array by using deterministic properties of the signals or the
channels such as their constant modulus or directions-of-arrival.
Progress in this area has been abundant over the past ten years
and has resulted in several powerful algorithms. Unlike optimal or
adaptive methods, the algebraic methods discussed in this review
act on a ﬁxed block of data and give closed-form expressions
for beamformers by focusing on algebraic structures. This
typically leads to subspace estimation and generalized eigenvalue
problems. After introducing a simple and widely used multipath
channel model, the paper provides an anthology of properties that
are available, as well as generic algorithms that exploit them.
Keywords— Array signal processing, blind source separation,
constant modulus algorithm, delay estimation, direction of arrival
estimation, frequency estimation, multipath channels, sequence
estimation, singular value decomposition, space division multiplexing.
INTRODUCTION
In the context of array signal processing, beamforming
is concerned with the reconstruction of source signals from
the outputs of a sensor array. This can be done either by
coherently adding the contributions of the desired source
or by nulling out the interfering sources. The latter is an
instance of the more general problem of source separation.
Classically, beamforming requires knowledge of a look
direction, which is the direction of the desired source. Blind
beamforming tries to recover source signals without this
information, relying instead on various structural properties
of the problem.
The ﬁrst blind beamforming techniques proposed were
based on direction ﬁnding. The direction of each incoming
wavefront is estimated, at the same time producing a
beamformer to recover the signal from that direction. This
requires that at least that the antenna array is calibrated. If a
source comes in via several directions (coherent multipath),
then direction ﬁnding is more complicated. Depending on
Manuscript received May 13, 1997; revised February 15, 1998. This
work was supported by ENST, Paris, France.
The author is with the Delft University of Technology, Department of
Electrical Engineering/DIMES, 2628 CD Delft, The Netherlands.
Publisher Item Identiﬁer S 0018-9219(98)06971-0.
the situation, we also need to consider delay spread. Thus,
the applicability of these techniques is very much dependent
on the channel conditions and in general requires a small
number of well-deﬁned propagation paths per source.
More recently, new types of blind beamformers have
been proposed that are not based on speciﬁc channel
models, but instead exploit properties of the signals. A
striking example is the constant modulus algorithm (CMA),
which separates sources based on the fact that their baseband representation has a constant amplitude, such as is the
case for FM or phase modulated signals. A prime advantage
is that these beamformers are not dependent on channel
properties or array calibration. For man-made signals, such
as those encountered in wireless communications, signal
properties are often well known and accurate, leading to
robust algorithms. Several other properties are available,
for example, cyclostationarity caused by the bauded nature
of digital communication signals or introduced by small
differences in carrier frequencies. Ultimately, sources can
be separated based on their statistical independence, which
is a somewhat weaker, but generally valid property.
1) Deterministic Blind Beamforming: In
above, it is clear that blind beamforming is a wide ﬁeld,
even if we limit ourselves to source separation. To restrict
ourselves further, we will not consider stochastic techniques
here at all (cf. the paper by Cardoso in this issue),
and address cyclostationarity properties only marginally.
This leaves a ﬁeld that can be called “deterministic blind
beamforming,” which makes strong structural assumptions
on the scenario, but in exchange requires only a modest
number of samples. In particular, deterministic methods do
not exploit the source statistics, but the can can provide
exact results based on only a ﬁnite amount of data, at least
under noise-free conditions. They are usually derived by
ﬁrst looking at how a source separation problem could be
solved in the absence of noise, and then making sure that
the algorithm still behaves robustly when noise is added.
This often leads to elegant algorithms that have good
performance, albeit suboptimal from a statistical point of
0018–9219/98$10.00 1998 IEEE
PROCEEDINGS OF THE IEEE, VOL. 86, NO. 10, OCTOBER 1998
A second distinction is that we will only look at algebraic
techniques acting on a block of data, as opposed to adaptive
(updating) techniques useful for tracking. The latter are
often gradient descent techniques based on cost-function
minimization, where the cost derives from forcing one of
the structural properties or from a maximum-likelihood
(ML) criterion. Updating algorithms generally have a lower
computational complexity and can track a nonstationary
channel, but they place a larger demand on the number of
samples and need time to converge so that their relevance
depends on the requirements of the application. Issues
are unpredictable convergence speed, possible convergence
to suboptimal solutions, and initialization of the iteration.
A considerable problem in the context of source separation with adaptive techniques is that of recovering all
independent signals. In contrast, the algebraic techniques
considered here typically ﬁnd all separating beamformers
jointly as the collection of eigenvectors of an associated
eigenvalue problem. This makes them more reliable, but
at a computational cost. Also, a model order selection is
essential but often not trivial. The simplicity of the adaptive
techniques have made these the only algorithms that have
been implemented in actual current-day systems (cf. the
paper by Treichler, Larimore, and Harp, this issue). With
the advent of powerful DSP’s and more ﬁnite-data burst
oriented problems, this may change in the future.
Similar problems with local minima and initialization
hold for optimal ML techniques, which act on a block
of data and try to optimize an often highly nonlinear
cost function at great computational expenses. Algebraic
techniques can provide a good initial point in the search
for the optimal solution. For small sample sizes, the beneﬁt
of the optimization step is not necessarily worth the effort.
A related topic is that of blind identiﬁcation or equalization of convolutive channels, which is very similar except
that more structure is available and only one signal is to be
recovered (the others being echoes). Blind equalization is
discussed in depth in the paper by Tong and Perreau in this
issue (see also ). The main distinctive point in blind
beamforming considered here is the interest in recovering
all impinging signals.
The paper is thus centered around algebraic techniques
for deterministic blind beamforming. We consider two
classes of algorithms: those that are based on channel
properties and others based on signal properties. Despite
the fact that these properties are widely differing, the
resulting algorithms show a remarkable homogeneity. All
are subspace-based techniques and end with a generalized
eigenvalue problem: the beamformers are found as the
eigenvectors of a simultaneous diagonalization problem in
which several matrices can be diagonalized by the same
(eigenvector) matrix. The message of the paper is that
joint diagonalization is the fundamental problem for source
separation.
2) Application Example: By nature of this class of algorithms (i.e., they act on short data blocks with very
speciﬁc structures) we will be mostly interested in applications for wireless communications. An example of a blind
beamforming application in this area is the separation of
aircraft transponder signals. Civil air trafﬁc control uses
a “secondary surveillance radar” (SSR) to identify and
track aircraft , . After interrogation by a ground
radar station, the aircraft responds with a short data burst,
providing information on its call number, airspeed, and
altitude. In the newly developed SSR Mode-S, aircraft
are individually addressable, but implementation of this
standard has been slow. The system as it is currently
used has a single carrier frequency at 1090 MHz for all
return signals. It frequently occurs that several aircraft are
triggered by an interrogation beam, so that ground stations
receive a superposition of several data bursts, partially
overlapping in time and frequency. Data bursts are short
(56 or 112 bits) and do not contain training symbols. Thus,
it would be very interesting to separate two or three of such
messages using blind beamforming techniques. Besides
direction ﬁnding, there are several opportunities for this,
since signals are stochastically independent, carriers are
not exactly the same (there is a tolerance of 3 MHz), and
the data modulation is simple (pulse-amplitude modulation
with alphabet
0, 1 ) , .
3) Outline: The paper ﬁrst introduces a compact data
model by which multipath propagation channels can be
described (Sections II and III). We distinguish between
instantaneous and convolutive models. This is followed
by an overview of properties that are available in this
context (Section IV) which forms the center of the paper.
The second part is a more detailed anthology of example
algorithms (Sections VI and VII), which, starting at a
moderate level, requires an increasing proﬁciency in linear
algebra techniques on the part of the reader.
PHYSICAL CHANNEL MODEL
The propagation of signals through a radio channel is
fairly complicated to model. A correct treatment would
require a complete description of the physical environment,
which is not very suitable for the design of signal processing
algorithms. To arrive at a more useful parametric model we
have to make simplifying assumptions regarding the wave
propagation. Provided this model is reasonably valid, we
can, in a second stage, try to derive statistical models for
the parameters to obtain agreement with measurements. The
purpose of this section is to discuss a simple channel model
that can be used for array signal processing.
A. Delays of Narrow-Band Signals
Let us start with a well-known but important property
of narrow-band signals which says that a short time delay
translates to a phase shift. In signal processing, narrow-band
signals are usually represented by their lowpass equivalents
 . A real-valued bandpass signal with center frequency
such as received by an antenna, can be written as
where the baseband signal
is the complex envelope of
the received signal
. It is obtained from
PROCEEDINGS OF THE IEEE, VOL. 86, NO. 10, OCTOBER 1998
A linear array receiving a far ﬁeld point source.
ulation: multiplying the received signal with
followed by low-pass ﬁltering.
In array signal processing, we are interested in the effect
of small delays on the narrow-band baseband signal
results in
so that the complex envelope of the delayed signal is
. If the bandwidth
sufﬁciently small so that
, then standard
Fourier analysis yields
The well-known conclusion is that, for narrow-band signals,
time delays shorter than the inverse bandwidth amount to
phase shifts of the baseband signal. This is fundamental in
phased array signal processing.
B. Antenna Array Response
Let us consider a simple linear array consisting of
identical antenna elements, as in Fig. 1. A narrow-band
point source
is present in the far ﬁeld and is modulated
at carrier frequency
. If the distance between the array and
the source is large in comparison to the extent of the array,
the wave incident on the array is approximately planar. The
to the normal is the direction of arrival (DOA) of
the plane wave.
be the response of a single antenna element
to a signal from direction
. We usually assume that the
frequency response of the antenna is ﬂat over the band of
is the antenna gain
pattern. If the antennas are omnidirectional, then
a constant scalar.
The baseband signal at the location of the ﬁrst (reference)
antenna element is called
; it differs from
delay and a complex attenuation (the path loss). The signal
received by an antenna at a distance of
wavelengths from
the reference location experiences an additional delay
is small compared to the inverse bandwidth of
, where the phase shift can
be related to the angle of arrival
An antenna array with elements at locations
. Collecting the signals received by the individual elements into
, we obtain
where the array response vector
is the response of the
array to a planar wave with direction
. The array manifold
is the curve traced out by the vector
If the curve does not intersect itself, then knowledge of
the array manifold allows
to be determined from
direction ﬁnding. The common factor
does not play
a major role in this and is often omitted or lumped into
the complex attenuation factor of the channel between the
transmitter and receiver.
A uniform linear array (ULA) has elements equally
. All delays between two consecutive array
elements are the same, so that
Antenna responses are usually expressed in terms of
since this is what is actually measured by the array. If
wavelengths, there is a one-to-one relation between
. The speciﬁc structure of the array manifold of a
ULA admits convenient estimation of
and subsequently
using algebraic techniques.
C. Parametric Multipath Propagation Model
A commonly used parametric channel model for radio
propagation is a multiray scattering model, also known as
Jakes’ model (after , see also , , , and ). In
this model, the signal follows a number of distinct paths
on its way from the source to the receiver, referred to as
multipath rays. These arise from scattering, reﬂection, or
diffraction of the radiated energy due to objects that lie in
the environment. Apart from attenuation (fading), multipath
propagation can also cause spreading of the signal in time,
frequency and space, with signiﬁcant effects on the received
The scattering of the signal in the environment can be
specialized into three stages: scattering local to the source
at surrounding objects, reﬂections on distant objects of the
few dominant rays that emerge out of the local clutter, and
scattering local to the receiver (see Fig. 2). Let us ignore
the latter for the moment and assume that there are
bouncing off remote objects such as hills or tall buildings.
The received parametric signal model is then usually written
VAN DER VEEN: ALGEBRAIC METHODS FOR BLIND BEAMFORMING
Multipath propagation channel model.
as the convolution
is a vector consisting of the
antenna outputs,
is the array response vector, and the impulse response
collects all temporal aspects, such as pulse shaping,
and transmit and receive ﬁltering. The model parameters
of each ray are its (mean) angle-of-incidence
path delay
, and path loss
. The latter parameter lumps
the overall attenuation, all phase shifts, and possibly the
antenna response
Each of the rays is itself composed of a large number of
“mini-rays” due to scattering close to the source, all with
roughly equal angles and delays, but arbitrary phases. This
can be described by extending the model with additional
parameters such as the standard deviations from the mean
and mean delay
, which depend on the radius
(aspect ratio) of the scattering region and its distance to the
remote scattering object , . For macroscopic models,
the standard deviations are generally small (less than a
few degrees, and a fraction of
) and are usually, but not
always, ignored.
The local scattering, however, has a major effect on the
statistics and stationarity of
. For example, if all local rays
have equal amplitude, then
is the sum of a large number
of arbitrary complex numbers, each with equal modulus
but random phase, which gives
a complex Gaussian
distribution. Consequently, its amplitude has a Rayleigh
distribution (hence the name Rayleigh fading). A second
effect is that
is really (slowly) time varying:
if the source is in motion, then the Doppler shifts and
the varying location change the phase differences among
the rays so that the sum can be totally different from one
time instant to the next. The maximal Doppler shift
is given by the speed of the source (in m/s) divided by
the wavelength of the carrier. The coherence time of the
channel is inversely proportional to
, roughly by a factor
can be considered approximately constant for
time intervals smaller than this time , , . Angles
and delays are generally assumed to be stationary over
much longer periods.
Table 1 Typical Delay and Doppler Spreads in
Cellular Applications at 900 MHZ
Finally, scattering local to the receiver eventually results
in the reception of a number of rays with roughly equal
delays, but largely differing DOA’s. The corresponding
fading parameters have more or less equal amplitudes but
different phases. This type of scattering is not present if the
receiver is clear from local obstacles, e.g., on a mast, but
may prevail otherwise.
D. Typical Channel Parameters
Angle spread, delay spread, and Doppler spread are important characterizations of a radio channel, as it determines
not only the amount of equalization that is required, but also
the amount of diversity that can be obtained. In the context
of mobile cellular telephony, typical channel delays and
Doppler spreads that can occur at 900 MHz are provided
in Table 1 , (see also references in ).
The delay spread determines the maximal symbol rate
for which no equalization is required. The inverse of the
delay spread is proportional to the coherence bandwidth ,
 , . Narrow-band signals with a bandwidth sufﬁciently
smaller than the inverse of the delay spread experience a
ﬂat channel (in the frequency domain) that does not require
equalization;
is essentially a scalar and can be lumped
As noted before, the inverse of the Doppler frequency determines the coherence time, and thus the maximal temporal
window in block processing algorithms, or the required
speed of adaptation in adaptive algorithms.
The inverse of the angle spread (in radians) determines
the coherence distance in wavelengths, which gives an
indication of the minimal distance by which two antennas
have to be spaced to enable separation of two disparate
rays within this spread by (classical) spatial separation techniques. Rays without much angle spread have essentially
Angle spreads are strongly dependent on the geometry
of the environment and have not yet been studied as
thoroughly as delay spreads. Current research suggests that
most outdoor channels can be modeled adequately by a
small number of dominant rays and that in open or suburban
terrain most energy is often concentrated in a single ray in
the direction of the mobile , with relatively small angle
and delay spreads. Moreover, multiple rays usually have
widely separated angles.
The ﬁrst-generation American analog cellular AMPS
system (FDMA) and the more recent digital IS-54 system
(TDMA) have narrow-band signals at 25–30 kHz, with
carrier frequencies in the 900 MHz band . The symbol
period for IS-54 is 41.6
s. With delay spreads as in Table
1, it is seen that the symbol period is (much) larger in
PROCEEDINGS OF THE IEEE, VOL. 86, NO. 10, OCTOBER 1998
(a) Spatial beamformer with an I-MIMO channel and (b) space-time linear equalizer with
an FIR-MIMO channel.
all cases, so that the channel is usually instantaneous, not
convolutive (except perhaps in hilly terrains, where some
equalization may be needed). A data block in IS-54 spans
6.67 ms (162 bits). With a Doppler spread of 100 Hz, data
is stationary over a fraction of 10 ms so that beamforming
must be adaptive over the time slot.
The GSM system (TDMA) has signals with a bandwidth
of 200 kHz in blocks (time slots) of 577
s . The data
transmission rate is 270 kb/s, giving a symbol period of 3.7
s. Thus, in hilly terrains the delay spread spans maximally
ﬁve symbol periods, and equalization is necessary. The
delay spread is less than one symbol period in most urban
settings, and only minor equalization is required in this case.
In other cases, the reception is more like an instantaneous
mixture. The fading is stationary within the data block even
for high Doppler shifts. Data blocks belonging to the same
source are spaced at 5 ms, so fading is not stationary in
going from one block to the next, although delays and
angles might be the same.
In summary, knowledge of the delay spread and Doppler
spread allows us to decide, grosso modo, if an instantaneous
or a convolutive channel model is appropriate, and whether
it is time invariant or time varying over the data block.
DATA MODEL FOR SIGNAL PROCESSING
In Section II, we have looked at a channel model based
on physical properties of the radio channel. Though useful
for generating simulated data, a detailed model is not always suitable for identiﬁcation purposes, e.g., if the number
of parameters is large, if the angle spreads within a cluster
are large so that parameterization in terms of directions is
not possible, or if there is a large and fuzzy delay spread.
In these situations, it is more appropriate to work with an
unstructured model, where the channel impulse responses
are posed simply as arbitrary multichannel ﬁnite impulse
response (FIR) ﬁlters. It is a generalization of the physical
channel model considered earlier, in the sense that at a later
stage we can still specify the structure of the coefﬁcients.
A. I-MIMO Model
Assume that
source signals
are transmitted from
independent sources at different locations.
If the delay spread is small, then what we receive at the
antenna array will be a simple linear combination of these
where, as before,
is a stack of the output of the
antennas. We will usually write this in matrix form
Suppose we sample with a period
, normalized to
and collect a batch of
samples into a matrix
. The resulting
model is called an instantaneous multi-input multi-output model, or I-MIMO for short.
It is a generic linear model for source separation, valid when
the delay spread of the dominant rays is much smaller than
the inverse bandwidth of the signals, e.g., for narrow-band
signals, in line-of-sight situations or in scenarios where
there is only local scattering. Even though this appears to
limit its applicability, it is important to study it in its own
right, since more complicated convolutive models can often
be reduced by blind equalization techniques to
The objective of beamforming for source separation is
to construct a left-inverse
, such that
[see Fig. 3(a)]. This will recover the
source signals from the observed mixture. It immediately
follows that in this scenario it is necessary to have
to ensure interference-free reception, i.e., not more
sources than sensors. If we already know (part of)
because of training, then
denotes the Moore–Penrose pseudoinverse of
 – , here equal to its right inverse, and
complex conjugate transpose. Blind beamforming is to ﬁnd
with knowledge only of
If we adopt the multipath propagation model, then
endowed with a parametric structure: every column
sum of direction vectors
with different fadings
If the th source is received through
rays, then
VAN DER VEEN: ALGEBRAIC METHODS FOR BLIND BEAMFORMING
If each source has only a single ray to the receiver array
(a line-of-sight situation), then each
is a vector on the
array manifold, and identiﬁcation will be relatively straightforward. The more general case amounts to decomposing
-vector into a sum of vectors on the manifold,
which makes identiﬁcation much harder.
To summarize the parametric structure in a compact way,
we usually collect all
-vectors and path attenuation
coefﬁcients
of all rays of all sources in single matrices
To sum the rays belonging to each source into the single
-vector of that source, we deﬁne a selection matrix
denotes an
vector consisting
of 1’s. Together, this allows us to write the full (noise-free)
I-MIMO data model as
B. FIR-MIMO Model
Assume again that
source signals
transmitted from
independent sources, but moreover that
they are now received through a convolutive channel. To
limit ourselves to a practical and interesting case, let us
assume that the signals are digital with a common pulse
period, so that they can be described by a sequence of
dirac pulses
For convenience, we normalize the symbol period to
The signal emitted by a source is a convolution of
by the pulse shape function
, e.g., a raised cosine
(generalized sinc function), which gives
After propagation through the channel, the signal is
. The impulse response of the channel
from source
to the th sensor,
, is a convolution of
the pulse shaping ﬁlter
and the actual channel response
. We can include any propagation delays
and delays due to unsynchronized sources in
The data model is written compactly as the convolution
At this point, we make the assumption that the
associated to each source
are FIR ﬁlters of (integer)
length at most
maximal channel length among all sources is denoted by
. An immediate consequence of the FIR assumption is
that, at any given moment, at most
consecutive symbols
play a role in
Suppose that we sample each
at a rate of
the symbol rate, and collect samples during
periods. Then we can construct a data matrix
containing
all samples as
contains the
spatial and temporal samples taken during the
th interval.
Based on the FIR assumption, it follows that
factorization
and in this context
-dimensional vector.
The matrix
represents the unknown space-time channel,
contains the transmitted symbols.
block-Toeplitz structure: it is constant along the diagonals.
This structure is a consequence of the time-invariance of
the channel. Note that if the channels do not all have the
same length
, then certain columns of
are equal to zero.
A linear equalizer in this context can be written as a
which combines the rows of
to generate an
. In the model so far, we can only equalize among the antenna outputs (simple beamforming) and
PROCEEDINGS OF THE IEEE, VOL. 86, NO. 10, OCTOBER 1998
samples within one sample period (polyphase
combining). More generally, we would want to ﬁlter over
multiple sample periods, leading to a space-time equalizer.
For a linear equalizer with a length of
symbol periods,
we have to augment
horizontally shifted
copies of itself
Each column of
is a regression vector—the memory of
the ﬁlter. Using
, a general space-time linear equalizer
can be written as
, which combines
snapshots of
antennas [see Fig. 3(b)]. The augmented
data matrix
has a factorization
to the left are each over
positions.
has a block-Hankel structure, i.e., it is constant along
antidiagonals.
has the same structure as
necessary condition for space-time equalization (the output
is equal to a row of
is tall, which gives
minimal conditions on
in terms of
Unlike spatial beamforming, it will not be necessary to
; it sufﬁces to reconstruct a single block row of
, which can be done with
space-time equalizers
Nonlinear equalizer structures are possible, e.g., by using
feedback, but they are not discussed here.
C. Connection to the Parametric Multipath Model
For a single source, recall the multipath propagation
model (2), valid for specular multipath with small cluster
angle spread
is the pulse shape function by which the signals
are modulated,
is the array response vector function,
is the complex path attenuation.
Suppose as before that
has ﬁnite duration and is
zero outside an interval
. Consequently,
the same support for all
. At this point, we can deﬁne a
parametric “time manifold” vector function
, collecting
samples of
If we also construct a vector
with samples of
then it is straightforward to verify that (9) gives
denotes a Kronecker product, deﬁned for vectors
Thus, the multiray channel vector is a weighted sum of
vectors on the space-time manifold
of the Kronecker product, this is a vector in an
dimensional space, with more distinctive characteristics
-dimensional
-vector in a scenario without
delay spread. The connection of
as in (7) is that
is a stacking of all columns of
a single vector.
We can deﬁne, much as before, parametric matrix functions
denote a columnwise Kronecker product
(Khatri–Rao product). This gives
Extending now to
sources, we see that the
in (7) can be rearranged into an
is the selection matrix deﬁned in (3) that sums the
rays into channel vectors.
now plays the same
in the previous section. Each of its columns is
a vector on the space-time manifold.
VAN DER VEEN: ALGEBRAIC METHODS FOR BLIND BEAMFORMING
Table 2 Signal-Channel Structural Properties
PRINCIPLES OF BLIND BEAMFORMING
A summary of the noise-free data models developed so
The ﬁrst part of these model equations is generally valid
for linear time invariant channels, whereas the second part
is a consequence of the adopted multiray model.
Based on this model, the received data matrix
several structural properties. In several combinations, these
are often strong enough to allow to ﬁnd the factors
) from knowledge of
alone. Very often,
this will be in the form of a collection of beamformers (or
space-time equalizers)
such that each beamformed
is equal to one of the source signals, so
that it must have the properties of that signal. Properties
are listed in Table 2 and discussed below.
A. Matrix Structure
1) Toeplitz Structure: The ﬁxed baud rate of communication signals, along with time invariance, result in the fact
has a factorization in which
is block Hankel and
is block Toeplitz. This is a strong property and allows,
for example, the blind equalization of unknown channels
carrying unknown digital signals with equal baud rates. It
cannot be used for source separation, but it is very useful
for reducing the FIR-MIMO problem
instantaneous
problem , .
Several techniques are available nowadays: the original
methods, which are phrased in a stochastic context and use
the asymptotic diagonality of the source covariance matrix
 , closely related linear prediction (LP) methods ,
 , and “deterministic” subspace-based methods working
directly on
and exploiting either the Hankel structure
 , , or the Toeplitz structure of
 . Closely related to these are the cross-relation method
 and the mutually referenced equalizer method . It
is possible to incorporate partial knowledge of the channel
into some of the methods, in particular the fact that the
pulse shape function is usually known – . This
puts an additional linear constraint on the channel impulse
response vector
and may lead to important improvements
in accuracy.
The subspace-based methods exploit the linear nature of
the underlying problem and work well if the channel length
is known and well deﬁned but might fail otherwise. The LP
methods are robust against channel-length overestimation
but rely on longer data sequences and a sufﬁciently large
ﬁrst channel coefﬁcient. (The latter problem is overcome
by a “multistep approach” .) See and the paper
by Tong and Perreau in this issue for a more complete
2) Training Sequences: If training symbols are present in
the signal, then a number of columns of
are known.
This number should be such that this known submatrix
a wide matrix, in which case it generally has a right inverse
. This directly allows estimation of
is the corresponding window of the data matrix.
known, there are a large number of suitable
space-time equalizers (e.g., zero-forcing, minimum meansquare error, decision-feedback), differing in performance,
complexity, and symbols/noise assumptions. Techniques are
standard, and the literature is abundant.
A topic of increasing interest is that of semiblind techniques, where it is assumed that some training symbols are
available, but perhaps not sufﬁcient for channel estimation.
Also, it is felt that use of additional structures such as
the Toeplitz structure can signiﬁcantly improve the channel
estimates obtained from the use of training symbols only
 . Only a few algorithms are known at this point, e.g.,
 – .
3) Low Rank Factors: An important property used by
many algorithms is that
is a low rank factorization: if
are large enough, then
is a tall matrix
is a wide matrix. This has several implications, most
full column rank
full row rank
stand for the row span and column
span of the matrix argument, respectively. Almost any blind
separation/equalization method is (implicitly) based on this
low-rank property: knowing
and assuming full rank
factors, we have a basis for the row span of
column span of
, and it remains to ﬁnd the (hopefully
unique) matrix in this row or column span that has the
required structural properties, such as the Toeplitz structure,
or any of the structures to follow. Also, as mentioned
earlier, the low rank property is necessary in general even
is known, since any space-time equalizer is a row of
a left inverse of
. For this, it is required that
B. Signal Modulation Structure
The signal modulation structure includes the instantaneous amplitude and phase of the modulated signal, and
also the symbol constellation. Some typical modulation
structures are listed below.
PROCEEDINGS OF THE IEEE, VOL. 86, NO. 10, OCTOBER 1998
1) Constant Modulus: In many wireless applications, the
transmitted waveform has a constant modulus (CM). This
occurs, e.g., in FM modulation, or in phase modulation,
as in GSM. So-called CMA’s can separate arbitrary linear
superpositions of such signals by ﬁnding out which linear combinations of the antenna outputs
signals that have the CM property. Solutions are generally
unique up to an arbitrary phase offset. The CM property
is extremely robust and can be used for blind equalization,
as well as source separation – . Most algorithms
are based on iterative cost-function minimization, and a
lot of recent research effort has been on proving global
convergence and on initialization issues (see the paper by
Johnson et al. in this issue for an overview and references).
An algebraic technique is given in Section VII-A.
2) Finite Alphabet: Another important structure in digital communication signals is their ﬁnite alphabet (FA).
The modulated signal is a linear or nonlinear map of an
underlying ﬁnite alphabet, e.g.,
for signals with
a binary phase-shift keyed (BPSK) constellation. As with
the CM property, it is possible to separate arbitrary linear
combinations of FA signals in a more or less unique way,
given a minimal amount of samples – . For small
constellation sizes [BPSK or quadrature PSK (QPSK)],
this works very well. For high constellation sizes, only
iterative algorithms are known and their performance is
quite dependent on an initialization close to the solution.
Often, the CMA’s can be used to provide an initial point,
even if the constellation does not exactly have a CM
3) Distributional Properties and Independence: More generally, if the source distribution is known and not Gaussian,
separation is possible by restoring the distribution functions at the output of the beamformer, e.g., by using ML
techniques. Even if the distributions are not known, we
can restore distributional properties expressing the independence of sources. This is a vast area of research with
many directions (cf. and the paper by Cardoso in
this issue). Algebraic methods are possible by using higher
order stochastic moments and functions thereof, such as
cumulants (e.g., see – ). Source independence is
generally applicable and very useful for audio and seismic
applications, such as the separation of several speakers
using multiple microphones. Because it is a stochastic property, the number of samples that are required is typically
an order of magnitude larger than in the case where we can
use deterministic CM or FA properties to pose conditions
on every individual sample.
C. Temporal and Spectral Structure
The temporal structure relates to
as well, but now
with regard to its temporal properties. These can include
knowledge of its pulse shape function and, in the case of
CDMA signals, knowledge of the source codes, but also
certain statistical properties for sources that are temporally
1) CDMA Codes: In direct-sequence CDMA, the emitted
“chip symbols”
are in fact modulations of low-rate
source symbols
by known code vectors
(The code vectors are different for each source.) Because
the only unknowns are the
, this reduces the number
of unknowns in
by a factor
. The source symbols
can be recovered, e.g., by row span template matching
techniques – , which are essentially straightforward
least squares (LS) algorithms.
2) Temporally Nonwhite and Independence: If the sources
are independent and temporally nonwhite, separation is
possible by using the fact that the cross-covariance and
cross-cumulants of the signals at the output of the beamformer should be zero for all time lags. For example
This allows the separation of sources, but in this form it
cannot be used to equalize them. Often, the second-order
conditions are sufﬁcient to ﬁnd the beamformer; examples
of algebraic techniques for this are in – . Some
details are provided in Section VII-D.
3) Cyclostationarity: Many signals exhibit cyclostationary properties, i.e., their cyclic autocorrelation function
is wide-sense stationary
and has spectral lines at selective lags
and frequencies
 . This reﬂects that the signal is correlated with
frequency-shifted versions of itself and is typically caused
by periodicities such as the symbol rate in bauded communication signals, or residual carrier frequencies after
demodulation. If two sources have spectral peaks for different
, then they can be separated based on this
 – . It is usually required that these parameters are
known, although they can be estimated in speciﬁc cases.
Recent research focuses on the explicit introduction of
cyclostationarity at the transmitter, to facilitate separation
at the receiver. An elementary scheme for this is simply to
repeat the block or part of it , , or to deliberately
introduce small carrier offsets by additional modulations
with a periodic sequence .1 Channel identiﬁcation based
on cyclostationarity properties is possible as well (e.g., see
 ). As with high-order statistics methods, these methods
may in general require a considerable amount of data to
yield reliable results, as convergence may be slow.
For digital communication signals, a straightforward way
in which the cyclostationarity property can be expressed is
by oversampling the antenna outputs, at Nyquist rate rather
than the symbol rate. The multiple samples obtained during
one symbol period presumably give independent linear
combinations of the same transmitted bits, just as antennas
give independent linear combinations from sampling in
space. This fact was noted ﬁrst in and has generated
a lot of interest (e.g., see – ). It is the underlying
reason why we could factor
1An example algorithm that separates binary sources based on small
differences in carrier frequencies is given in Section VII-C.
VAN DER VEEN: ALGEBRAIC METHODS FOR BLIND BEAMFORMING
becomes a Toeplitz structure, and this structure then
induces the more general
in (8), where
similar block-Hankel structure. Although this was initially
called a second-order technique, the Toeplitz structure is a
deterministic rather than a stochastic property, i.e., valid
for any data size and independent of source correlation
properties.
D. Parametric Structures
Parametric structures are induced by the parametric multipath model (and extensions of it) that we have derived
in Section II. We use the fact that the columns of
do not take just any value, but have the speciﬁc forms
the parametric structure of
is known and the
parameters can be estimated. It makes sense to use such
models if the number of parameters is much smaller than,
e.g., the number of coefﬁcients in an unstructured FIR
1) The Spatial Manifold: In the I-MIMO model in (10),
each column of
is a linear combination of array response
, each of which is on the array manifold.
If the array manifold is known, e.g., by calibration or
from structural considerations, then we can try to ﬁt the
column span of
) to the appropriate linear
combinations. This will work if the number of rays is not
large and if the calibration data is reliable. For this purpose,
a large number of direction ﬁnding techniques have been
proposed (see the recent overview in ). Among the
high-resolution algorithms, the MUSIC algorithm is
still very popular, although it is now encompassed by the
more general WSF and MODE techniques – , which
provide asymptotically ML-optimal performance. These are
iterative optimization algorithms that need a starting point
of sufﬁcient accuracy. Attractive closed-form algebraic
techniques are possible if the geometry of the array has
a shift-invariance structure, as exhibited for example by a
uniform linear array (ULA), and this has led to the wellknown ESPRIT algorithm and variants thereof – .2
The ESPRIT algorithm is discussed in Section VI-A. It is
readily extended to two-dimensional direction ﬁnding of
both azimuth and elevation – . Most DOA models
assume point sources. However, the array manifold model
can be generalized to include the effects of small angle
spreads , .
2) The Temporal Manifold: Similarly, in (10), each column of
is a linear combination of vectors of the
is the temporal manifold function, the sampled response to an incoming pulse
. If the specular multipath model holds true and
the number of rays is not large, all received signals are
constructed from several delays of
, hence they can be
viewed as superpositions of a number of vectors
temporal manifold is usually known to a good accuracy
since it depends only on the pulse-shaping function and the
2For a ULA, the MODE algorithm can be made closed-form as well
receiver ﬁlters, both of which are under tight control. If
the spatial manifold is unknown or deemed unreliable, or if
the angular spread is complicated and diffuse, we can still
ﬁt to the temporal manifold and leave the spatial domain
unconstrained.
Otherwise, with knowledge of both the spatial and temporal manifold, we can attempt to do a joint estimation of
all angles and delays by ﬁtting to the space-time manifold
 – (see Section VI-C).
3) Residual Carrier Frequencies: Independent
narrowband sources modulated at high frequencies rarely have
exactly the same carrier frequency. Consequently, after
demodulation, the cochannel sources have unequal residual
carrier frequencies, with only partially overlapping spectra.
If the spectral properties of the sources are known or if
we sample sufﬁciently fast so that we can use stationarity
properties of the sources, the residual carrier frequencies
can be estimated and the sources can be separated, even
if the array manifold is unknown. This can be regarded as
a special case of cyclostationarity. An example is given
in Section VI-D.
PREPROCESSING
In the previous section, we have listed a number of
properties that are available for blind source separation
and equalization. The corresponding algorithms can be
broadly classiﬁed into row span and column span methods.
A row span method is a method that still works even if
we premultiply
with an arbitrary full rank matrix
on the left; this changes the mixing matrix but leaves the
row span invariant. Similarly, column span methods are
invariant to multiplication at the right. Algorithms that use
only properties of
are column span methods: all
information is contained in a basis of the column span of
. This reﬂects the fact that no constraints are placed on
Methods based on properties of the signals are usually row
span methods. In special cases, it is possible to translate
row span information into column span information by
stacking the data into block Hankel matrices. This occurs
for example for the residual carrier property.
In this second part of the paper, Sections VI and VII give
detailed examples of algebraic column span and row span
methods to illustrate a few of the deterministic properties
listed before. All algorithms can work with a basis of either
the row span or the column span of the data matrix. The
construction of this basis is a common and elementary preprocessing step, and is the topic of this section. In algebraic
methods, it is often the main computational bottleneck as
A. Subspace Estimation, SVD
Consider again the noise-free data model
rows but the rank of
is generically equal to
each antenna output (row of
) is a linear combination
source signals (rows of
). If we know
then with linear algebra techniques we can ﬁnd a basis
PROCEEDINGS OF THE IEEE, VOL. 86, NO. 10, OCTOBER 1998
for this row span, i.e., a matrix
rows such that
. At the same time,
independent columns, and not
, and we can ﬁnd
a basis for it, i.e., a matrix
columns such that
The numerically preferred way to obtain these bases
is to compute a singular value decomposition (SVD)
 – , which is a decomposition of
contain the orthogonal bases
diagonal matrix with
positive real numbers—the nonzero singular values. These
are usually sorted in nondecreasing order. The columns
and rows of
are called the singular vectors.
There is a well-known connection to eigenvalue problems:
, it is seen that
contains the
same eigenvectors as the empirical data covariance matrix,
are the corresponding eigenvalues. The singular
values give important information on the conditioning of
the problem: signals with low power or two signals with
-vectors (e.g., close directions-of-arrival) give rise
to small singular values.
can be interpreted as a whitened
data matrix, since
. It can be written as
: its columns are obtained from those of
a ﬁltering operation. This whitening operation is sometimes
called a Mahalanobis transformation.
With noise present, the data model becomes
is the additive noise term.
is no longer rank
deﬁcient but has full rank
. It is here that the SVD
becomes useful: the SVD of
can be written as
are square
is diagonal and partitioned into
“small” singular values. The same decomposition
holds in the noise-free case, but then with
Under mild conditions, one can show that the new basis
is a good approximation to the noise-free basis
asymptotically equal to it), provided that the noise singular
values, the entries of
, are substantially smaller than the
signal singular values, the entries of
. Alternatively, we
have to assume a sufﬁciently large number of samples and
spatially/temporally white noise so that the noise covariance
is a multiple of the identity matrix. The signal singular
values depend on the signal + noise power, the number
of samples, and the separation between the sources [cf.
Fig. 4(a) and (b)]. The noise singular values depend on the
noise power and the number of samples
[cf. Fig. 4(a)
and (c)]. The new
is equal to the old
, but augmented
with some noise power. The row space spanned by the new
can be viewed as an LS estimate of the subspace spanned
by the noise-free
. Thus, a rankapproximation of
, which is known as taking the truncated SVD.
Singular values for d = 2 sources, M = 5 antennas,
N = 10 samples. (a) Well-separated case: large gap between signal
and noise singular values. (b) Signals from close directions results
in a small signal singular value. (c) Increased noise level increases
noise singular values.
Conceptual beamformer structure.
We will use the SVD of
and subsequent truncation to
as a ﬁrst step in almost all our processing. This is
useful for several reasons: 1) if the rank of
without noise
is much smaller than
, then preﬁltering by
will remove an equal ratio of noise; 2) parameter estimation
is much easier from a minimal basis than from a full matrix;
and 3) after truncation, a stabilized inverse of
in certain (MMSE-type) receivers is
An untruncated full rank inverse can lead to severe noise
enhancement due to the inversion of small singular values.
Since we hardly ever use the diagonal property of
except perhaps to estimate the rank of
, simpler subspace
estimation methods have been proposed to estimate a basis
of the principal column span. These schemes are also
suitable for adaptive algorithms that update the estimate as
more data columns
are observed, and either start from
knowledge of the noise power, providing a level at which to
truncate the rank – , from knowledge of the rank
, e.g., if the number of sources is known , ,
or converge to the SVD under stationary conditions .
Automatic detection of the rank without knowledge of the
noise power or the number of sources/rays is a considerable
problem which deserves additional research.
B. Beamformer Structure
Let us assume that
has full column rank (independent
directions) and
has full row rank (independent signals).
Introduce the truncated SVD
VAN DER VEEN: ALGEBRAIC METHODS FOR BLIND BEAMFORMING
span the same subspace, so that there is a
invertible matrix
Substitution gives
is a beamformer which will recover
the main problem in blind beamforming is to construct the
based on properties of
(or both). Note that
it is sufﬁcient to construct any (orthogonal) basis of the
column span of
; we do not need the singular vectors,
only the subspace they span.
(where the
are the columns of
are the rows of
is clear that we cannot expect to recover the ordering of
signals. Usually, we also have to permit the exchange of a
phase factor between
, or even any scalar factor
if the power of the signals or the norm of vectors
EXAMPLES OF COLUMN SPAN METHODS
The next two sections will elaborate on the properties
listed in Section IV by demonstrating examples of how
these properties can be turned into algebraic algorithms
in (13). We ﬁrst look at column span methods,
which work on properties of
. Section VII will then
go into row span methods that exploit properties of
ease of description, we will always pretend a noiseless case
is rank deﬁcient. In the presence of noise, the
ﬁrst computational step is an SVD or subspace estimation,
followed by a rank truncation which reduces
to the quasi-noiseless case
, in the notation of
(11). The subsequent steps of the algorithms will remain
unchanged. Of course, a correct treatment of the noise
is very important—this makes the difference between a
good and a bad algorithm. But looking at the noiseless
case is sufﬁcient to understand the functioning of most
deterministic algorithms.
A. No Multipath
We start with a simple scenario, in which there is
no multipath and sources have only one ray toward the
receiving antenna array. Since no delays are involved, all
measurements are simply instantaneous linear combinations
of the source signals, i.e.,
. Each source has only
one ray, so that the data model is reﬁned to
are the array response
are the fading parameters,
and the rows of
contain the signals.
Computationally attractive ways to compute
are possible for certain regular antenna array
conﬁgurations for which
becomes a shift-invariant or
similar recursive structure. One well-studied example of
such a structure is that obtained from a ULA. For such an
array, with interelement spacing
wavelengths, we have
is the direction-of-arrival.
The ESPRIT algorithm is a well-known and elegant
technique to ﬁnd the factorization
shift-invariance properties of
Let us deﬁne
as a diagonal matrix of parameters, and selection matrices
which will select the ﬁrst and last
respectively. The Vandermonde structure of
ensures that
which is a direct expression of the shift-invariance of the
array. To use this property for estimating
, we ﬁrst compute an SVD
columns which together span the column
. Since the same space is spanned by the columns
, there must exist a
invertible matrix
Let us deﬁne
Then the shift-invariance of
implies that
consists of the top
are diagonal matrices and commute, we
is “tall” and has a left-inverse
is a diagonal matrix, this is an eigenvalue equation:
contains the eigenvectors of
(scaled arbitrarily
to unit norm), and the entries of
on the diagonal are
the eigenvalues. The blind beamformer is given by
. Thus, source separation in this case is essentially
PROCEEDINGS OF THE IEEE, VOL. 86, NO. 10, OCTOBER 1998
an eigenvalue problem. (This turns out to be the case for
many algebraic algorithms.) If the antennas are spaced by,
at most, half a wavelength, then the DOA’s are directly
recovered from
, otherwise they are ambiguous. Because
the rows of
are determined only up to a scaling, the
fading parameters
cannot be recovered unless we know
the average power of each signal. This is of course inherent
in the problem deﬁnition.
There are many important reﬁnements and extensions to
this algorithm. We can use the fact that all
are on the
unit circle along with the centro-symmetric structure of the
array to augment the data matrix to
is the reverse-identity matrix which ﬂips the rows
; this will not increase the rank but double the
number of observations . Using this structure, it is also
possible to transform
to a real-valued matrix by simple
linear operations on its rows and columns , . As
mentioned in Section IV-D, there are many other direction
ﬁnding algorithms that are applicable, in particular MODE
 . Although ESPRIT is statistically suboptimal, its performance is usually quite adequate. Its interest to us here
is its straightforward generalization to more complicated
estimation problems in which shift-invariance structure is
B. Coherent Multipath
In the above, we assumed that there was no multipath; each source had only one path to the antenna array.
However, the
model is also valid if sources
have multiple rays toward the array, as long as the delay
differences are small compared to the signal bandwidth so
that they can be represented by phase shifts. This is known
as coherent multipath. Let
be the number of sources,
the number of rays belonging to source , and
the total number of rays (assumed to be distinct). In that
case, a more detailed model is
is the Vandermonde matrix associated
with the DOA’s of the rays, as in (16), and
a selection matrix which adds groups of rays to source
signals, for example
in case of two sources, each with two rays.
is a diagonal scaling matrix representing the different amplitudes
(fadings) of each ray, including phase offsets. Because the
, the SVD of
can retrieve only a
-dimensional subspace
It is clear that blind beamforming is more challenging now;
we try to ﬁnd
such that each column of
is represented
by a sum of
Vandermonde vectors, rather than only
vectors, and
is not known.
To solve this problem algebraically using ESPRIT-type
techniques,3 we ﬁrst try to restore the rank to
possible if the number of antennas
is sufﬁciently large,
. In that case, we can form a
block-Hankel matrix out of
by taking vertical shifts of it
is a submatrix of
consisting of its
th row, and
is known as the spatial smoothing
factor , . With the above model, we have that
satisﬁes the factorization
consists of the top
, the factors in the above
factorization can be shown to have full rank
At this point, the structure of
in (19) shows that we
have reduced the problem to an
-type problem
without multipath, which can be solved using the ESPRIT
algorithm in Section VI-A. Thus we compute an SVD of
contains the dominant
singular vectors of
From (19) it follows that there is an invertible
We continue in the same way as before to compute
the data model satisﬁes the eigenvalue equation
which gives both
, up to scaling of its rows.
At this point, we have recovered
multiplication at the left by an arbitrary diagonal matrix.
The next objective is to estimate
from the structure of
in (19). This is now a much simpler task: we have available
matrices of size
, after correction by suitable powers
all equal to
. The structure of
ensures that
this matrix has only
distinct rows, which are the
. Hence, it sufﬁces to estimate these
unique rows,
which is a simple clustering problem if the rows of
sufﬁciently different. This determines both
, i.e., the
assignment of rays to sources. With
in hand, we have our
blind beamformer as before:
3Other techniques, such as MODE, are directly applicable to the
coherent case without modiﬁcations.
VAN DER VEEN: ALGEBRAIC METHODS FOR BLIND BEAMFORMING
C. Incoherent Multipath with Small Delay Spread
An extension of the previous would be to consider a true
multipath scenario, where each source is received via a
superposition of rays, each with its own angle
, and fading
. The question then becomes how to
estimate these parameters, and how to construct a spacetime beamformer to recover the sources. The problem is
known as joint angle-delay estimation – . In general,
this is a challenging task to perform blindly in column
space, without making further assumptions on the sources.
Let us here consider a scenario which allows a simple
extension of the previous and which has applications in
blind CDMA beamformers. Consider
sources as before.
Assume that these are digital sources, i.e., discrete-time
sources with a common pulse shape function
common pulse period
, normalized to
the following important restrictions leading to a simpliﬁed
version of the
is zero outside an interval
2) the delay spread is so small that
The implication is that every sample of the received signal
is a combination of
source symbols, and not more than
. These assumptions are approximately valid in a CDMA
receiver, after synchronization and matched ﬁltering with
the desired user code . (In this case,
in principle only one signal matches the code, but the
interference is strong.)
The received signal at the antennas can be written as
We sample at a rate
symbol periods and collect
all data samples in a matrix
Deﬁne matrices
is the parametric “time
manifold” vector function
the diagonal matrix containing the fading parameters, and
selection matrix which assigns each
ray to one of the sources, we ﬁnd that
satisﬁes the model
denotes the column-wise Kronecker product.
now plays the same role as
in the previous section.
Each of its columns is on the space-time manifold
. Because of the Kronecker product, this is a vector in
a high-dimensional space, which improves resolution and
allows to identify more rays than sensors.
To identify the rays and derive a beamformer using
similar techniques as before, we need
to satisfy
shift-invariance properties. With a uniform linear array,
already has such a property, and if the number of antennas
is larger than the number of rays we can proceed as before.
Otherwise, we can do a transformation such that
a Vandermonde structure. To this end, we use a wellknown property of the Fourier transformation: delays are
transformed into certain phase progressions. In particular,
collect the samples of the known waveform
denotes the
DFT matrix of size
is an integer multiple of
, then it is apparent that
the Fourier transform
is given by
is a Schur–Hadamard product: an entry-wise multiplication of two vectors or matrices). The same is to a very good
approximation true if
is bandlimited and sampled at or
above the Nyquist rate. Thus,
It follows that if we take the Fourier transform of each
oversampled antenna output over a single symbol period,
we can write the resulting data model
is known beforehand, we can divide it out of (23),
which amounts to a deconvolution. Obviously, this can be
done only on intervals where
is nonzero. The details of
this are in and omitted here. The result is that we can
obtain a matrix
which satisﬁes the model
where, because of the selection of nonzero frequency intervals, the number of rows of
is typically somewhat
smaller than in (22).
At this point, we have obtained a model with much the
same structure as in (17), but with
replaced by
where both
have a Vandermonde structure. The
construction of the beamformer can now follow the same
strategy as well. First note that the rank of
PROCEEDINGS OF THE IEEE, VOL. 86, NO. 10, OCTOBER 1998
since this is the number of rows of
. Thus we compute
the SVD of
As before, we have
and our objective is to compute the
construct a matrix
by composing shifted copies of
where now each shift is over blocks of
rows rather than
one. This matrix has model
is large enough and all rays belonging to the same
source have distinct delays, then the rank of
[Otherwise, we must also take shifts in the spatial domain
to restore the rank, i.e., “spatial smoothing,” as in (18).]
be the SVD of
, and suppose that
rows. It has the model
. To estimate
, and hence
now form two types of selection matrices: a pair to select
submatrices of
, and a pair to select from
To estimate
, we take submatrices consisting of the ﬁrst
and respectively last
whereas to estimate
we stack, for all
blocks, its ﬁrst
and respectively last
These data matrices have the structure
If dimensions are such that these are low-rank factorizations, then
Compare this equation to (20). Instead of a single eigenvalue equation, we now have two; the same matrix
can diagonalize both data matrices. As before, once we
have obtained
, we can immediately reconstruct
, which provides a beamformer to extract
each individual ray. After that, we need to assign the rays
to source signals (i.e., identify
Section VI-B) and combine them in any viable way to end
up with a beamformer that receives the individual source
signals, at the symbol rate. If we like, we can retrieve the
delays and angles of each ray from the eigenvalue matrices
, respectively. The correct pairing of angles to
delays follows simply from the fact that they share the
same eigenvectors.
Joint diagonalization problems such as the above are
overdetermined; one matrix already gives
, provided that
the eigenvalues are distinct. For example, we could work
only with the ﬁrst matrix (since we already assumed once
that the delays are distinct), and in this case we do not have
to make any assumptions on the structure of the antenna
array, i.e., we do not use its shift-invariance. We can also
form any linear combination of the two matrices and try
to ensure that the combination has distinct eigenvalues
(such an approach was taken in ). Several Jacobi-type
algorithms have been proposed as well, although some of
these assume that
is a unitary matrix , , ,
 , , , , , – .
Although these algorithms usually yield good performance, the problem of joint diagonalization with nonhermitian matrices has not yet been optimally solved. It is very
relevant to study such overdetermined eigenvalue problems.
Indeed, a third matrix arises if we use a two-dimensional
uniform antenna array, by which we can measure both
azimuth and elevation, or any other array with multiple
independent baselines. We will see several other examples
of joint eigenvalue problems later in this paper.
D. Space-Frequency Beamforming; Residual Carriers
A somewhat different scenario than what we considered
before, which, however, leads to the same type of data
models (and thus the same beamforming algorithms), is the
following. Suppose that we observe a frequency band of
interest and want to separate all sources that are present.
Assume that the sources are narrowband, typically with
different carrier frequencies, but that the spectra might
be partly overlapping. The objective is to construct a
beamformer to separate the sources based on differences
in angles or carrier frequencies. This is a problem of joint
angle-frequency estimation , . We will assume that
the sample rates in this application are much higher than
the data rates of each source and that there is only coherent
multipath, although generalizations are possible.
Suppose that the narrow-band signals have a bandwidth
of less than
, so that they can be sampled with a period
to satisfy the Nyquist rate. We normalize to
assume that the bandwidth of the band to be scanned is
times larger; after demodulation to IF we have to sample at
. Without multipath, the data model of the modulated
sources at the receiver is
is the residual modulation frequency of the th
). In matrix form this is
VAN DER VEEN: ALGEBRAIC METHODS FOR BLIND BEAMFORMING
written as
can be quite large (order 100, say), it would
be very expensive to construct a full data matrix of all
samples. In fact, it is sufﬁcient to subsample: collect
subsequent samples at rate
, then wait till the next period
before sampling again, resulting in a data matrix
With the model of
in (28), we ﬁnd that
factorization
Let us assume at this point that
. In that case,
is relatively bandlimited with respect to the observed band,
which allows to make the crucial assumption that
so that the model of
simpliﬁes to
is as in (22), only it has a different interpretation:
is now related to the carrier frequency.
is similar
except for a transpose and different powers, and
the pointwise multiplication represents the modulation on
the signals. Obviously, beamforming will not remove this
modulation, but after estimating
we can easily correct
If we do consider coherent multipath, the data model
The column span of this model has precisely the same
structure as
in (24) before, and hence we can use the
same algorithm to ﬁnd the beamformer.
If sources are assumed not to have equal carrier frequencies and
, we can separate them based on the
structure of
only. In this case we do not need the array
structure and an arbitrary array can be used, but we do not
recover the DOA’s. If frequencies can be close, however,
we will have to separate the signals based on differences in
angles as well. It is then also necessary to restore the rank
by spatial smoothing.
EXAMPLES OF ROW SPAN METHODS
Column span methods require rather sophisticated assumptions on the channel, and their accuracy largely depends on the validity of these assumptions. In contrast,
row span methods only pose
put all conditions on
. For communication signals with
signiﬁcant structures, this leads to powerful and robust blind
beamforming algorithms. We will be mainly concerned with
I-MIMO scenarios here, although extensions to general
FIR-MIMO models have been derived; e.g., in and 
the Toeplitz structure of
is exploited to reduce
. In fact, both problems are the same if we do
not use the Toeplitz structure of
As always, the ﬁrst step of row span methods is to reduce
dimensions to that of row
. Via an SVD, an orthogonal
basis for this is obtained as
A. Constant Modulus
For a signal (row vector)
property can be written as
The property holds for phase or frequency modulated signals, or any single-level digital constellation. Our objective
is, for a given
, to ﬁnd a factorization
all rows of
have this CM property. Let us assume that
we have computed an SVD
and have done the
subspace ﬁltering by
, so that at this point we have
. It remains to identify the
is a CM matrix.
looking for all beamforming vectors
is a CM signal. One can prove that, generically and for
, solutions are unique so that any CM signal that is
recovered this way is bound to be one of the original source
signals, up to a phase factor . Substituting
in (30), i.e.,
, shows that
satisﬁes the property
The CM problem is to ﬁnd all independent vectors
that satisfy this equation. An alternative way to write this
equation is by using the Kronecker product. By expanding
(31) into a sum of terms and rearranging, it follows that
PROCEEDINGS OF THE IEEE, VOL. 86, NO. 10, OCTOBER 1998
is the complex conjugate of
is a vector of
matrix whose rows are given
. Hence, we have turned the overdetermined
system of quadratic equations (31) into a linear system of
equations, subject to a quadratic constraint. Any solution of
the linear system in (32) can be written as
is a particular solution of the system (
are a basis of the null space of
the dimension of this space. An important result is that,
generically,
 . The remaining
problem is to ﬁnd out which linear combinations of the
lead to a vector
that can be written as
A convenient way to rephrase the latter problem is to
work with a matrix
. For any matrix, we can form
a vector by simply stacking its columns. Similarly, we can
“unvec” vectors into matrices. A notable property is that
. Thus, applying the unvec operation to every
in (33) leads to the equivalent
where each
. Hence, the problem is to
form linear combinations of known matrices
the result is rank-1 hermitian, so that it has a factorization
. In the present case, there are
matrices, and
we are looking for all
problem; we are in fact trying to rewrite the given arbitrary
as a rank-one basis
are the rows
of the beamforming matrix
Conversely, this means we can write each matrix
some linear combination of the rank-one basis
After collecting the coefﬁcients into diagonal matrices,
, it follows that the
the equations
’s are diagonal. This is a very fundamental set
of equations. The collection
are similar by congruence
to diagonal matrices, and can be jointly diagonalized.
In fact, this is again a generalized eigenvalue problem.
This is perhaps more clearly seen by looking at ratios,
(assuming invertibility) has a factorization as
can in principle be found as the
eigenvectors of
. Of course, given the full set of
equations and the presence of noise, we would rather try to
ﬁnd a single
that optimally satisﬁes all equations rather
than only one, which leads to the problem of simultaneous
diagonalization. Similar algorithms as mentioned for the
joint angle-delay estimation problem are available, e.g.,
based on Jacobi iterations , , , – .
Since we have a good starting point from the eigenvalue
problem of a pair of matrices, such iterations generally
converge extremely fast, i.e., in two or three iterations.
The CM problem is well studied as an adaptive blind
equalization technique. The difference with source separation is that, in equalization, we are interested in only
one signal since the others are shifted copies (echos) of it.
Applied to the problem of source separation, the adaptive
techniques have major problems in making sure that all
independent sources are recovered, and special attention
has to be paid to this . The algorithm described above
was called algebraic constant modulus algorithm (ACMA)
 and is very robust in this respect. Its complexity, on the
other hand, is reasonable only for a small number of sources
), which limits applications for equalization.
Experiment: We can illustrate the performance of ACMA
by an experiment with measured data.4 The sources are six
FM-modulated analog speech/music signals, occupying the
same bandwidth of 25 kHz in the 900 MHz band. Since
the signals are narrowband, this is an I-MIMO scenario
where no equalization is necessary, even though multipath
may be present. The uncalibrated antenna array consists of
omnidirectional antennas, arranged nonuniformly
roughly on a line, with a maximal baseline of 2.5 m. The
signal-to-noise (SNR) ratio is around 17 dB per antenna
per source, and the sources have roughly equal powers.
Their DOA’s are, respectively,
1.5, 7, 0, 42, 100, and 42
(nearﬁeld). With all sources present, the condition number
is around 20, which is medium conditioned.5
Fig. 6 shows the worst signal-to-interference ratio (SIR)
among the signals after beamforming, as a function of the
number of samples that have been used, and for a varying
number of sources. The reference “true”
-matrix has been
estimated from 500 samples. It is seen that only a small
number of samples are required (order
or so) to give a
good separation of all
sources, even though some of the
sources are only spaced by 1.5 .
B. Binary Symbol Constellation
Another property based on which digital sources can
be separated is their ﬁnite alphabet. Frequently, a BPSK
constellation is used, i.e., the transmitted signals are vectors
with all entries
. The signals are of
course modulated by some pulse shape function, but this
can be absorbed in the
-matrix, or perhaps the
which will result in the same problem since we do not use
its structure. Hence we arrive at the following problem:
, determine the factorization
. This can be viewed as a specialization
of the CM problem if we restrict the signals to be real as
4The experimental data was kindly provided by F. McCarthy, AR-
GOSystems, Sunnyvale, CA, June 1994, and is described in .
5The condition number of a matrix is the ratio of the largest to the
smallest singular value and can be interpreted as the maximal noise
ampliﬁcation of a zero-forcing beamformer W = Ay, here a factor 20, or
26 dB. With only two sources present, the ampliﬁcation is cond(A) = 1:2,
or only 1.5 dB.
VAN DER VEEN: ALGEBRAIC METHODS FOR BLIND BEAMFORMING
Residual SIR after blind beamforming of a mixture of d
signals using the constant-modulus property.
is real-valued, it is advantageous to write
with obvious deﬁnitions of
. If we work with
and take care to stay in the
real domain, then this forces our estimate of
to be real.
At the same time,
is usually much better conditioned
Our ﬁrst step is again an SVD of
, which will reduce
and the dimension from
. Thus, the
problem is equivalent to ﬁnding all independent vectors
The alphabet condition is written as
Denoting the
th column of
, substitution of (36)
into (37) leads to
Hence, we get the same type of problem as in the CM case,
and we arrive at the same joint diagonalization problem
(34) as before . Other discrete symbol alphabets can
in principle be treated by extensions of (37), but for higher
order constellations the complexity of the algorithm quickly
gets out of hand.
C. Binary Symbols with Residual Carrier Frequencies
In the case of digital signals from independent sources, it
is very reasonable to assume that the carrier frequencies are
slightly different. For example, if the sources are modulated
to 900 MHz then even if the carrier frequencies are the same
up to ﬁve to six orders of magnitude, after demodulation to
baseband using the nominal carrier frequency each of the
sources will have a residual carrier of up to roughly 5 kHz.
If the sources have a bandwidth of 20 kHz, then we can
expect phase shifts in the order of 90 per symbol. Hence,
the BPSK model
is too naive in
this case. We can either revert to the CM model to separate
the sources, or we can try to separate them based on these
small differences in residual carrier frequencies.
Modern-day communication systems use a common reference signal, so that the residual carrier is typically much
smaller, reportedly around 500 Hz or less. The residual
carrier method discussed below already works once the
phase shift between the ﬁrst and last symbol in the data
batch is more than
180 . For sources with a bandwidth
of 20 kHz and a difference in carriers of 500 Hz, this
amounts to a data batch of 20 samples. We can envision
systems where cochannel users are deliberately shifted
by such small amounts in order to facilitate separation.
This can be regarded as a special instance of separation
by “coding-induced cyclo-stationarity,” and such schemes
have been proposed, e.g., in , , and . The main
difference is that here the frequency offsets are regarded
as unknown parameters. One of the few algorithms that
considers this case can be found in ; it is a two-step
iterative approach.
A more accurate source model for BPSK sources is
is the unknown residual carrier frequency of the
source. If we now look at
Similarly as before, substitute
that we have to work with the complex data model). In
terms of Kronecker products, we can rewrite the equation
. If we collect the row vectors
in a matrix
as before, we obtain
The difference with the CM problem we had before is that
is unknown. However, it can readily be estimated using
the same shift-invariance ideas as before; with
denoting the shifted matrices, we obtain
is a generalized eigenvalue of the matrix pair
is its corresponding eigenvector. If the
residual frequencies are not the same, then this problem can
be solved using standard linear algebra techniques .
The resulting
are then distinct and the corresponding
eigenvectors
are unique up to scaling and can directly
be factored as
. This gives the collection of
beamforming vectors.
PROCEEDINGS OF THE IEEE, VOL. 86, NO. 10, OCTOBER 1998
Of course, we could also separate the sources based on
their CM properties. As can be guessed from the equations,
the difference in accuracy turns out to be only marginal.
The main beneﬁt in solving (40) is a somewhat reduced
computational complexity.
D. Source Independence
Algorithms similar to ACMA and residual carrier recovery have been derived in a more stochastic context and are
applicable to signals that are statistically independent. The
property that is used is that, for independent signals, the
rows of the
-matrix are asymptotically orthogonal to each
For example, as in , suppose we have source signals which are uncorrelated, but have a certain temporal
autocorrelation
is a diagonal matrix which should be nonzero
for the chosen value of the lag. If the noise is temporally
uncorrelated and spatially white, the correlation matrix for
the received data has the form
Thus, the blind beamformer
follows by solving
for the eigenvectors of
, or equivalently,
by jointly diagonalizing both
condition for this to work is that the eigenvalues are distinct,
which implies that the signals should have different spectral
signatures. Even for identically distributed sources this can
be assumed if the source signals have been received through
different channels, or, e.g., if they have different residual
carrier frequencies.
If we take multiple values for
, then we obtain a
joint diagonalization problem, much as in (34). In essence,
is computed such that the beamforming outputs look
“independent,” in this case with respect to their secondorder statistics at selected time lags.
Depending on the signals, there might not be much
distinctive information in the temporal correlations. More
general techniques lift this requirement by working on
higher order statistics, such as fourth-order cumulants.
problem, this has led to an algorithm
called JADE that is very similar in structure to ACMA,
except that it arrives at a collection of
fourth-order
cumulant matrices
, all of which can be simultaneously
diagonalized by
 . An extra processing step reduces
this to a more compact set of
matrices to be diagonalized.
The main limitation of stochastic techniques for source
separation is that they require data matrices to be fairly large
so that the experimental source covariance matrices are
sufﬁciently diagonal. This means that typically in an order
of magnitude more samples are required than in the ACMA
algorithms, which can make use of stronger assumptions on
the data to arrive at properties that are pointwise satisﬁed
in the absence of noise.
Experimental comparison between ESPRIT, ACMA, and
JADE . Shown are the empirical cumulative distributions of the
residual SIR, after blind beamforming based on N = 8 samples.
E. Experimental Comparison
Having seen many different approaches for computing
basically the same factorization, the question of choice
arises. This is still a dark area, and any preference is
clearly dependent on the availability and reliability of
the properties, among other considerations. Nonetheless, a
preliminary experimental performance comparison between
ESPRIT, ACMA, JADE, and a few other methods has been
reported in . In one of these experiments, data was
collected from a ULA with
elements, spaced at
slightly less than half wavelength in the 900 MHz band.
Two sources moving in residential trafﬁc in a suburban
setting were present at a distance of 2–3 km from the
array, transmitting analog FM-modulated 1 kHz tones at
slightly different carrier frequencies (15 kHz separation).
The average SNR was around 27
6 dB, and the sources
were at least 10
spaced in azimuth. Since the sources are
narrowband, the I-MIMO model
is appropriate.6
The results of this experiment are shown in Fig. 7, taken
from . In this case, separation based on the CM property
offers some 10 dB additional SIR improvement over the
direction-ﬁnding method (coherent ESPRIT). The JADE
algorithm is based on restoring statistical independence
properties, which requires many more samples to become
effective. Eventually, it surpasses both ESPRIT and ACMA
or so. Although one should be careful in
drawing general conclusions from a single experiment, it
seems fair to say that row span methods are quite promising
for blind source separation.
CONCLUSION
This paper has described algebraic methods for deterministic blind beamforming. Even within this limited
framework, many properties are available and can be used
to blindly separate sources and equalize channels. Column
span methods are mostly parametric and try to ﬁt a multiray
channel model to the observed data. These methods are
applicable if this model is valid to a reasonable accuracy,
with a small number of specular rays. The requirement of
6The results reported here were provided courtesy of A. L. Swindlehurst
and are based on measurement data shared by ArrayComm, Inc.
VAN DER VEEN: ALGEBRAIC METHODS FOR BLIND BEAMFORMING
a model order estimation and the sensitivity to model order
mismatch can be considered their Achilles heel. On the
other hand, potentially useful side information is obtained,
such as delays and angles of multipath rays, which enables
source localization. Uncalibrated antenna arrays can be
employed if there is sufﬁcient resolution in the delays or
residual carrier frequencies.
Row span methods use properties of the signals such as a
CM. If these properties are present, they are very powerful
and robust and not dependent on the validity of the channel
model or array calibration. The strength, and at the same
time the limitation, of deterministic row span methods is
that they almost always require the signals to be man made.
More generally applicable signal separation methods are
based on stochastic properties, and, e.g., force the independence of the outputs of the beamformer, or reconstruct
their distributions. Depending on the signal distributions
and the a priori knowledge, stochastic techniques can be
far superior but may require many more samples.
A major challenge in this area is to combine several
signal and channel properties at the same time, since this
would result in a superior and more robust beamformer. A
cue to this is the observation that all algebraic methods
considered in this paper lead to generalized eigenvalue
problems, where the beamforming coefﬁcients are given
by the eigenvectors—the same for each method! Hence,
joint diagonalization algorithms are envisioned to play an
increasingly important role.
ACKNOWLEDGMENT
The author wishes to gratefully acknowledge the several
years of pleasant and fruitful collaboration with Prof. A.
Paulraj and members of the Smart Antenna Research Group
at Stanford University, which yielded many of the visions
and ideas expressed in this paper. The author also thanks
Prof. J.-F. Cardoso and Prof. P. Duhamel for their feedback
and hospitality during the preparation of this work.