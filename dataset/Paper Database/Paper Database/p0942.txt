Active Learning of Linearly Parametrized Interatomic Potentials
Evgeny V. Podryabinkin1, Alexander V. Shapeev2
Skolkovo Institute of Science and Technology, Moscow, Russia
This paper introduces an active learning approach to the ﬁtting of machine learning interatomic potentials. Our approach is based
on the D-optimality criterion for selecting atomic conﬁgurations on which the potential is ﬁtted. It is shown that the proposed
active learning approach is highly eﬃcient in training potentials on the ﬂy, ensuring that no extrapolation is attempted and leading
to a completely reliable atomistic simulation without any signiﬁcant decrease in accuracy. We apply our approach to molecular
dynamics and structure relaxation, and we argue that it can be applied, in principle, to any other type of atomistic simulation. The
software, test cases, and examples of usage are published at 
Keywords: Interatomic potential, Active learning, Learning on the ﬂy, Machine learning, Atomistic simulation, Moment tensor
potentials
1. Introduction
Many research areas in materials science, molecular physics,
chemistry, and biology involve atomistic modeling. For example, in molecular dynamics (MD), as a rule, one of the following two classes of interatomic interaction models is used. The
ﬁrst class is the empirical interatomic potentials—they are very
computationally eﬃcient and allow for simulating large atomistic systems for microseconds of simulation time. However,
they typically yield only qualitative accuracy. The other class
is quantum-mechanical (QM) models, such as the density functional theory (DFT). They are very accurate, but computationally expensive. Their applicability is typically limited to hundreds of atoms and hundreds of picoseconds of simulation time.
Several directions of developing the models that would be
both accurate and computationally eﬃcient have been pursued.
They include the so-called linear scaling DFT that
ensures that the algorithmic complexity grows linearly when
the size of the atomistic system increases beyond hundreds of
atoms. Another direction is the development of semi-empirical
models, such as the tight-binding model , whose accuracy
and eﬃciency is between those of the empirical potentials and
DFT. In this paper we pursue a more recent approach based on
machine learning.
Machine learning interatomic potentials
Application of machine learning (ML) has recently been put
forward as a promising idea that would combine the accuracy of
the QM models and the eﬃciency of the interatomic potentials
 . Such machinelearning interatomic potentials (MLIPs) postulate a partitioning
1e-mail: 
2e-mail: 
of the interatomic interaction energy into individual contributions of the atoms (and sometimes bonds, bond angles, etc.) and
assume a very ﬂexible functional form for such a contribution,
making it a function of the positions of the neighboring atoms,
typically with hundreds or more parameters. These parameters
are found by requiring the energy, forces and/or stresses predicted by a MLIP to be close to those obtained by a QM model
on some atomic conﬁgurations. These conﬁgurations are called
the training set, and ﬁnding the parameters of a MLIP is known
as training or ﬁtting. One of the important features of MLIPs
are their ability to approximate potential energy surfaces with
arbitrary accuracy (at least theoretically) by increasing the number of parameters and the training set. It should be noted that
there are other, ML-based atomistic models of solids, including those predicting the energy directly without partitioning it
 , or constructing a density functional in a DFT with machine learning . A recent overview of ML-based models of
materials can be found in .
Each of the existing MLIPs has a nontrivial functional form
accounting for the physical symmetries of interatomic interaction. Namely, a MLIP should be invariant with respect to translation, rotation, and reﬂection of the space, and also permutation of chemically equivalent atoms. In addition, the potential should have a local support (i.e., depend on surrounding
atoms only within a ﬁnite cut-oﬀradius) and be smooth with
respect to atoms coming and leaving the support. In many instances, it is achieved by designing a ﬁxed number of descriptors —scalar functions that satisfy all the symmetries
and uniquely encode each atomic environment, and assuming
that a MLIP is an arbitrary function (which we call the regression model) of these descriptors. This idea was ﬁrst put forward
by Behler and Parrinello proposing an ML model which
they called a neural network potential (NNP), based on their
descriptors and neural networks as the regression model. Since
 
August 24, 2017
 
then, there has been many works on NNPs, see the review papers and references therein, and also more recent works
 . Another group of authors adopted
the Gaussian process regression framework . They used the
coeﬃcients of spherical harmonics expansion of the smeared
atomic positions as descriptors and used the kernel-based ML
model, where the kernel was based on the distance between
the vectors comprised of those coeﬃcients. In a follow-up paper, , the authors reﬁned this idea by proposing the smooth
overlap of atomic positions kernel, bypassing the step of designing the descriptors. For other examples of using Gaussian
process regression for constructing interatomic potentials refer
to . Three closely related works, , use Gaussian process regression to predict the forces on atoms directly,
without predicting the energy and taking its gradient. Finally,
 proposes a linear regression model with spherical harmonics coeﬃcients as the basis functions. In the present work, we
use the moment tensor potentials (MTPs) . These potentials
adopt a linear regression model with polynomial-like functions
of atomic coordinates as the basis functions. The MTPs can be
interpreted as having descriptors which are based on tensors of
inertia of atomic environments.
The MLIPs described above allow for improving their accuracy through increasing the number of the ﬁtting parameters.
However, the approximation properties of ML potentials depend not only on their algebraic form, but also on the training
set used to ﬁt them. Choosing a good training set for a potential
with many parameters (say, more than ten) proves to be a highly
nontrivial practical problem. Indeed, all the existing MLIPs are
interpolative, they fail to give reasonable answers outside their
training domain. Therefore, a good training set should make
a MLIP to be interpolative over all the relevant conﬁgurations.
Obviously, the more parameters a MLIP involves, the larger
and more diverse the training set is required in order to ﬁt such
The problem of choosing a proper training set for the ﬁtting
of a reliable MLIP is related to the problem of transferability—
the ability of interatomic potentials to extrapolate, i.e., give reasonable predictions outside the training domain (e.g., predict
the double vacancy formation energy if only single vacancies
are present in the training set). It is hardly expected that a MLIP
can extrapolate beyond the training domain, but even developing a reliable problem-speciﬁc MLIP that would accurately interpolate within the training domain is nontrivial, as pointed
out, for instance, by Behler [9, Section 4]. As an illustration of
this, the authors of sampled gamma surfaces (by shifting,
in diﬀerent ways, a part of a crystal along a glide plane) and included them in the training set, which allowed them to compute
the properties of dislocations accurately with the exception of
their Peierls barrier. To accurately reproduce the latter they devised a more complicated scheme of generating conﬁgurations
from the MD trajectories using one version of their potential in
order to ﬁt a better version of their potential.
An attractive idea is to attempt to sample the entire space
of atomic environments within, for example, a constraint on
the minimal interatomic distance. It is, however, not clear how
to do this with suﬃcient accuracy due to extremely high dimensionality of the space of atomic neighborhoods. Therefore,
in practice, the training set is usually generated by specially
designed sampling procedures such as, for example, random
perturbations of ideal crystalline conﬁgurations , sampling
from an ab-initio MD, or a classical MD with empirical potential or another (already ﬁtted) MLIP . These sampling
procedures, however, do not ensure that the training set covers fully, without “gaps”, the region in the conﬁguration space
required for training MLIPs reliably. In other words, a potential resulted from such a training procedure may later encounter
conﬁgurations on which this potential will have to extrapolate.
Active learning and learning on the ﬂy
The problem of extrapolation could be resolved if a MLIP
were able to detect extrapolative conﬁgurations, obtain the QM
data for those conﬁgurations, and be re-trained. In this scenario, the extrapolation problem (or the transferability problem)
would be solved by reliably predicting on the ﬂy whether a potential is extrapolating on a given conﬁguration. Alternatively,
in the case when learning on the ﬂy cannot be done, the selection of extrapolative conﬁgurations can be done oﬄine yielding
the training set that improves the transferability of the ﬁtted potential.
Both scenarios are related to a set of ML techniques called
active learning (AL). In contrast to passive learning in which a
potential learns every conﬁguration in the training set, in AL a
potential is trained only on a set of selected conﬁgurations. The
key component of any AL method is, thus, its query strategy—
an algorithmic criterion for deciding whether a given conﬁguration can be treated reliably by an ML model, or we need to
re-train our model by querying the QM data for this conﬁguration. If such decision can be made reliably then, as we show in
this paper, we do not have to ensure that the training set generated oﬄine has all the representative conﬁgurations.
A general overview of AL approaches can be found in .
In the context of interatomic potentials, the ﬁrst work that proposed AL was putting forward a Bayesian query-by-committee
strategy. AL was applied by Behler to the neural network potentials [9, Section 4], using the query by committee-type AL
strategy. Finally, the authors of train a machine learning model predicting the force errors based on the distance between a given atomic conﬁguration and the training set. A very
natural AL approach applicable to force ﬁelds based on Gaussian process regression , which has not yet
been implemented in practice, would be to use the Bayesian
predictive variance, shown to correlate with the actual error,
e.g., in .
In this paper we propose another AL approach for MLIPs
based on the D-optimality criterion [31, Section 3.5] allowing
for detecting the conﬁgurations on which a MLIP extrapolates.
This criterion was chosen because there exists an eﬃcient algorithm for checking for D-optimality . Also, as will be
discussed in this paper, D-optimality has appealing mathematical interpretations, such as decreasing the uncertainty in determining the parameters or maximizing the volume spanned by
the training set in the space of conﬁgurations, thus avoiding extrapolation. We apply our AL approach to the ﬁtting of MTPs,
however, it is easily generalizable to a any other linear potential,
i.e., a potential whose energy depends linearly on the parameters, such as SNAP or GAP. In principle, we can apply AL
to atomistic systems with any number of chemically diﬀerent
types of atoms, however, most linearly parametrized potentials
developed to date are only applicable to systems with a single
type of atoms. We demonstrate that our AL approach allows
one to train potentials on the ﬂy with a limited number of QM
calculations (occurring, typically, in the initial stage of MD or
another atomistic simulation) without loss in accuracy. In addition, we show that even without learning on the ﬂy, AL can
“optimize” the training set, in the sense of extracting a significantly smaller subset, training on which reduces the maximal
error and improves transferability.
It should be emphasized that the idea of ﬁtting interatomic
potentials on-the-ﬂy is not new. The motivation behind this
idea is the same as for the MLIPs—to eliminate expensive QM
calculations for those conﬁgurations (or atomic neighborhoods)
which are similar to the conﬁgurations already computed. Earlier works proposed a “learning-and-forgetting” scheme,
in which the interatomic potentials are ﬁtted to the current QM
data, and the old QM data are discarded. A signiﬁcant step forward was recently done by Li, Kermode and De Vita , who
proposed a “learning-and-remembering” scheme, in which the
database of QM calculations continuously grows with time. It
was demonstrated that this approach allows one to reduce the
number of QM calculations by a factor of 30 . In all cases,
the decision to compute the QM data for a given conﬁguration
was taken every n steps (e.g., n = 30 steps), where n is a ﬁxed
number depending on the system, the temperature at which it is
simulated, etc. This is the main diﬀerence from the approach
proposed in the present work: we formulate a query strategy
that is based on geometrical information (atomic positions and
supercell vectors) of a conﬁguration and does not use the QM
data, thus a well-trained potential will trigger the QM calculations very rarely.
2. Machine Learning Interatomic Potentials
Let x be a periodic atomistic conﬁguration with N atoms in
a supercell L. Suppose we can compute, for a given conﬁguration x, its QM energy Eqm(x), forces f qm
(x) (1 ≤i ≤N) and
stresses σqm(x). Such computation typically involves resolving
the electronic structure and is very expensive. For the purpose
of our paper, we treat such computation as a black box.
2.1. Linearly Parametrized Potentials
We next assume that each atom interacts with its neighborhood deﬁned by a cut-oﬀdistance Rcut > 0. The neighborhood
ri = (ri,1, . . . , ri,n) of atom i is deﬁned as a collection of vectors
pointing from atom i to all the atoms (and their periodic extensions), excluding the atom itself, that are not farther than Rcut.
The number of atoms in the neighborhood, n, may depend on i.
We assume that the total interaction energy of a conﬁguration is
where V is the interatomic potential—a scalar function of the
neighborhood ri. We deﬁne a linearly parametrized local potential as having linear dependence on the ﬁtting parameters θj:
θ jBj(ri),
where Bj are the ﬁxed basis functions. The concrete form of the
basis functions is not important for what follows, therefore we
give the details in the Appendix A on how Bj are constructed
for the moment tensor potentials (MTPs) used in this work.
We deﬁne the conﬁguration-dependent basis functions b j(x) :=
i=1 Bj(ri) and, using (1) and (2), write
The force f j(x) is a derivative of E(x) with respect to the position of the j-th atom, xj:
fj(x) = −∇xjE(x),
and the virial stresses are derivatives with respect to lattice vectors
 ∇LE(x)L⊤.
2.2. Fitting (training)
A linearly parametrized potential is uniquely determined
by the algebraic form, and the values of the ﬁtting parameters
θ j. The latter are found through the ﬁtting to the quantummechanical energy, forces, and stresses on a set of conﬁgurations XTS = {x(1), . . . , x(K)} which we call the training set.
The simplest form of ﬁtting is requiring E x(k) = Eqm x(k).
Expanding the left-hand side yields system of linear algebraic
equations on the coeﬃcients θj:
 x(k) = Eqm x(k).
In the matrix notation, we can write this system as Aθ = R,


This system is typically overdetermined (K ≥m), therefore we
deﬁne the solution through the pseudoinverse by θ := (A⊤A)−1A⊤R.
If the conﬁgurations in the training set XTS are also provided
with the forces f qm(x(k)) and stresses σqm(x(k)) one can add two
more families of equations in addition to ﬁtting to the energy:
 x(k) = Cf f qm
 x(k), i = 1, ..., N(k)
Csσ x(k) = Csσqm x(k).
These equations are combined into a single least-square minimization problem, therefore we need to introduce the coef-
ﬁcients Cf and Cs determining the relative importance of the
force- and stress-ﬁtting equations relative to the energy-ﬁtting
equation. Expanding the left-hand side of ((6)) yields the following equations:
 x(k) = −Cf f qm
 x(k)L(k)⊤
| det(L(k))|
= Csσqm x(k),
i = 1, . . . , N(k),
3. Active Learning
Active learning allows one to select the training set from
a given set of conﬁgurations or a stream of conﬁgurations. It
is done only based on the unlabeled data, i.e., no quantummechanical energy, forces or stresses are required for making
the decision about including a particular conﬁguration x∗into
the training set XTS. In the learning-on-the-ﬂy scenario this
means that the quantum-mechanical calculations are done only
when the conﬁguration is indeed suﬃciently “new”. The criterion on whether a given conﬁguration x∗should be added to
XTS is called the query strategy.
An overview of various query strategies is presented in .
In the present work we employ the variance reduction query
strategy based on the D-optimality criterion [31, Section 3.5]
and a fast algorithm, called the maxvol algorithm, developed in
 . A way to derive the D-optimality criterion is to assume
that the right-hand side of the equations (5), (7) has a Gaussian
random noise and we want to select m out of K equations such
that the noise in the solution is minimized. This is equivalent
to choosing a subset of equations (5), (7) such that its matrix
A ∈Rm×m has the maximal determinant by its absolute value.
Those conﬁgurations x(k) that correspond to the selected equations hence form XTS.
The active learning algorithm is determined by the following two choices: what equations are used for the ﬁtting and
what equations are used for the selection of the conﬁgurations.
It should be noted that the two sets of equations need not coincide: for instance, the ﬁtting can be done over all the equations
(5), (7), but the selection can be done only based on (5). In the
present work we use all the equations for the ﬁtting, and three
diﬀerent versions of the query strategy, as detailed below.
Query strategy QS1: Selection by the energy-ﬁtting equation
The ﬁrst query strategy, labeled as QS1, involves only the
energy-ﬁtting equation (5). Given some conﬁguration x∗, we
need to decide whether to insert it to XTS = x(1), . . . , x(m) . The
rows of the matrix A corresponding to x(i) ∈XTS are:


Following the maxvol algorithm , we form the row-vector
If we replace the k-th row of A by  b1(x∗) . . . bm(x∗) then |det A|
will change by a factor of |Ck| (the easiest way to see this is to
use the Cramer’s formula).
Our query strategy is thus as follows. If
γ(x∗) := max
1≤k≤m |Ck| > γth,
where we call γth ≥1 a threshold, then we add x∗to the training
set and remove x(k) with k = arg maxk|Ck|; otherwise, we keep
the XTS as is. This procedure guarantees that if x(k) is replaced
by x∗in XTS then |det A| is increased at least by a factor of γth.
If in the algorithm one stores A−1 instead of A then the complexity of computing γ(x∗) is only O(m2). When A changes, it
also takes O(m2) operations to update A−1 using the Sherman-
Morrison rank-one update.
It is worthwhile noting that the elements of C can be interpreted as the coeﬃcients of expressing E(x∗) through E x(k):
CkE x(k).
Hence we can say that if all |Ck| ≤1 then we are interpolating
the predicted value of the energy, E(x∗), through the energies
E x(k) = Eqm x(k). Hence, γ(x∗) deﬁned by (9) has a meaning
of a degree of extrapolation that we commit when evaluating
E(x∗). Hence we call γ(x∗) the extrapolation grade and the
parameter γth ≥1 deﬁnes the maximal allowed extrapolation
grade. It should be emphasized that γ(x∗) does not depend on
the QM data and is therefore a geometric feature of the conﬁguration x∗and conﬁgurations from XTS.
Query strategy QS2: Selection by all equations
The second query strategy, QS2, the matrix A is formed by
m equations chosen from (5), (7). Thus, each conﬁguration x∗
yields 1 + 3N + 6 rows in place of (8),

Cf∇x1b1(x∗)
Cf∇x1bm(x∗)

(here ∇x1b1(x∗) comes from expanding the force in basis functions) and it is selected for training if
k, j |Ck j| > γth.
We then use the maxvol algorithm to maximize |det A|; it
is a greedy algorithm replacing rows of A with rows of B until
maxk,j |Ck j| ≤γth. The algorithm is detailed in Appendix B.
Note that in this query strategy there may be more than one row
of A corresponding to one conﬁguration, and thus less than m
conﬁgurations may be selected into the training set. The algorithm complexity is O(Nm2).
Query strategy QS3: Selection by neighborhoods
To formulate the last approach we suppose, for the sake of
argument, that we could also ﬁt to the site energies,
1 ≤k ≤K, 1 ≤i ≤N(k).
Thus, in the third approach, QS3, A is formed by the equations
(11). We proceed similarly to QS2 and compose


Then if maxk,j |Ck j| > γth then we replace the rows in A with the
rows in B and update XTS accordingly. As in QS2, there may
be more than one row of B corresponding to one conﬁguration,
and thus the training set may contain less than m conﬁgurations.
The algorithm complexity is the same as that of QS2, O(Nm2).
It should be emphasized that no site energies are actually required from quantum mechanical data for the implementation
Learning on the ﬂy
The AL methodology naturally applies to learning on-the-
ﬂy scenario that combines the interatomic potential evaluation
and its learning into a single routine, see Fig. 1. At each iteration of an atomistic simulation, an unlabeled conﬁguration x∗
comes as an input to an AL procedure, that does the following.
1. Calculate extrapolation grade, γ(x∗). If γ(x∗) ≤γth then
go to step 5, else
2. Calculate Eqm(x∗), f qm(x∗), and σqm(x∗) with a
quantum-mechanical model.
3. Update XTS (and hence A) with x∗.
4. Re-ﬁt the MLIP and obtain new θ1, . . . , θm.
5. Return E(x∗), f(x∗), σ(x∗) according to the current values
of θ1, . . . , θm.
Note that in this scheme the parameter γth controls the ef-
ﬁciency of the learning-on-the-ﬂy scheme, eﬀectively ignoring
conﬁgurations which increase |det A| only slightly and perform
expensive QM calculations only for suﬃciently “new” conﬁgurations. In practice, there is an optimal range of γth for which
the QM calculations are not done too often, and on the other
hand, the extrapolation does not signiﬁcantly decrease the accuracy of the potential, see Section 4.4.
As another application, AL can be applied to reducing the
training set, for instance, when it contains many similar conﬁgurations. In Appendix C we show that such oﬄine application
of AL improves the transferability of a MLIP and reduces maximal errors as compared to learning from the full database.
Active LOTF
Quantum Mechanical Model
Atomistic Simulation
MLIP fitting:
query QM data, update training set,
retrain MLIP
Parameters
Active Learning:
need to learn?
calculate E, F, σ
Figure 1: Workﬂow in actively learning a potential on the ﬂy.
An activelearning scheme gets an atomistic conﬁguration and returns its energy, forces,
and stresses, by possibly retraining the interatomic potential.
4. Testing
In this section we test the proposed AL schemes. In Section 4.1 we give an illustratory example of how AL works for
a system with one degree of freedom. Then, in Section 4.2 we
test the accuracy of the ﬁtting of the MTP potentials on a
crystalline Li system, and in Section 4.3 we show that the extrapolation grade γ correlates with the error of ﬁtting. Finally,
in Section 4.4, we will test learning on the ﬂy.
All the tests are done using the open-source software that
we publish at 
The distribution package includes the examples of applications
described in this section.
4.1. A one-dimensional illustration
Figure 2: A one-dimensional example. The dotted line is the exact energy
Eqm(x), the red dashed line is the least-mean-square ﬁt, and the blue solid line
is the ﬁt with active learning. The least-mean-square has the lowest possible
energy (i.e., is closer to the exact energy in the energy well), but creates a spurious energy barrier around x = −3 that changes the correct long-term behavior
of the system.
We start by illustrating how the proposed method works in a
simple one-dimensional example. Suppose our system has only
one degree of freedom, x ∈[−4, 4], and is described by the
energy Eqm(x) = x2 + x3e−x2/2, shown in Figure 2, dotted line.
We approximate it by a potential E(x) = θ1x2 + θ2x3. Suppose
that we can sample the exact ﬁnite-temperature MD arbitrarily
long, and we minimize the mean-square error of the ﬁt on these
MD samples. This is equivalent to minimizing the free-energy
functional
(E(x) −Eqm(x))2e−Eqm(x)dx
resulting from a Boltzmann distribution with the dimensionless temperature kBT = 1.
We then obtain the ﬁt E(x) =
0.93x2 + 0.21x3, shown in Figure 2, red dashed line. The rootmean-square error of this ﬁt, deﬁned as the standard deviation
of E(x) −Eqm(x) with respect to the Boltzmann distribution, is
only 0.25. However, the major problem is that this ﬁt creates
a ﬁnite energy barrier around x = −3, which would cause the
system to occasionally escape the physical region and drive the
system to a spurious minimum x →−∞.
We next apply the AL approach to this problem by selecting two points (since there are two basis functions) from the
interval [−4, 4] for the ﬁtting of E(x). The most optimal points
are x1 = −4 and x2 = 4, as they maximize det
is then E(x) = x2 + 3 · 10−4x3, shown in Figure 2, blue solid
line. Its error is 0.46, but it correctly predicts the barriers at the
boundary of the region of interest, and hence the MD will not
escape the region of interest.
It thus can be concluded that, at least in this one-dimensional
example, AL oﬀers reliability at the cost of a trade-oﬀin accuracy as compared to passive learning. In the following subsections we will see that the diﬀerence between passive and active sampling is even more pronounced in a realistic MD—AL
oﬀers in practice a completely reliable model at the cost of a
marginal error increase.
4.2. Accuracy of learning molecular dynamics
In this and the following subsections we perform atomistic
simulations of Lithium. The tests are performed in a cubic supercell of 128 Lithium atoms arranged in a b.c.c. lattice. The
length of the supercell in each direction is greater than twice
the cut-oﬀradius, 2Rcut = 10Å. This ensures that each atomic
neighborhood does not contain multiple periodic images of a
single atom.
The energies, forces, and stresses were computed using DFT
with the VASP code , a projected augmented wave
(PAW) pseudopotential , and the Perdew-Burke-Ernzerhof
exchange-correlation functional . Lithium is an alkaline
metal with one valence electron and therefore its electronic structure can be computed faster than for the other elements, which
is helpful in collecting large statistics for the tests.
Before testing our AL approach, we perform a test of accuracy of the MTP potential for Li by ﬁtting to a ﬁxed quantummechanical database. The database was comprised of four abinitio MD trajectories sampling an NVT-ensemble at temperature T = 300 K, each trajectory ran for 6 000 time steps, each
time step was 1 fs. A sequence of MTPs with diﬀerent number of basis functions, m, was generated; the more basis functions are included, the better is the accuracy. The ﬁtting errors
are given in the Table 1. Here and in what follows we report
Table 1: RMS ﬁtting errors in energy, forces and stresses for MTPs with different number of basis functions, m. The root-mean-square (RMS) and the
maximum errors are quoted.
Energy error
Force error
Stress error
(meV/atom)
the root-mean-square (RMS) error and the maximum error. As
can be seen, the potentials systematically converge, however,
increasing the number of basis functions beyond 100, essentially, does not reduce the error. Therefore the results for the
subsequent tests will be quoted for the same set of 100 basis
functions.
4.3. Correlation of the error and the extrapolation grade
We next show that the force error correlates with the extrapolation grade γ(x∗). Note that the cost of evaluating γ(x∗) is
as cheap as a matrix-vector multiplication (or a matrix-matrix
multiplication for QS2 and QS3), as we do not need to consider
the cost of evaluating
in (8) (and B for
QS2 and QS3) since it is required for computing E(x) in any
case. The correlation between the error and γ(x∗) may be used
to assess the applicability of a MLIP to a given conﬁguration
x∗during an atomistic simulation. Even more important than
simply knowing γ for conﬁgurations appeared in MD, we can
store the conﬁgurations with high γ in order to perform the QM
calculations and reﬁt MLIP on them on-the-ﬂy or after the simulation.
We compute the force errors and the extrapolation grade
each time step of an MD at T = 300 K. The force errors versus
the extrapolation grade are plotted in Figure 3. A good correlation between the two can be observed—this indicates that in
practice an extrapolation grade can predict the correct order of
magnitude of the error a potential makes on a given conﬁguration without performing a QM calculation.
4.4. Learning on the Fly
We next test our AL strategy in a realistic setting of MD and
structure relaxation.
We run MD trajectories at T = 300 K for 100 ps, training
an MTP on the ﬂy. Graphs in Figure 4(a) show the amount
of QM calculations as a function of the simulation time. One
can see that all query strategies require many QM calculations
during an initial phase (1–5ps) and then gradually move to the
regime when QM calculations are required only rarely. QS1
requires about twice more QM calculations as compared to QS2
As one can see from the Figure 4(b) the amount of the QM
calculations drops signiﬁcantly as γth increases (with γth = 2
about four times less QM calculations are required as compared
to γth = 1). On the other hand, as seen from Table 2, the errors
extrapolation grade Γ
Force error @eVAD
Figure 3: Correlation between the extrapolation grade γ(x) and the force error
∆f(x) =   1
i=1 |fi(x) −f qm
(x)|21/2. Each point on the graph corresponds
to an MD time step. For 95% of conﬁgurations the RMS force error is within
[0.04 γ, 0.22 γ] eV/Å (dashed lines)—this indicates a good correlation between
the error and the extrapolation grade.
essentially do not increase up to γth = 2 and only at γth = 11
the maximum error exhibits a slight increase (for γth > 1 only
the errors of QS1 are tabulated, however, the behavior of QS2
and QS3 with increasing γth is essentially the same). This indicates that one can easily tune the eﬃciency-versus-accuracy
performance of an AL scheme by adjusting γth. Based on our
experience, we ﬁnd that a value for γth between 2 and 11 is a
good choice in practice—it does not signiﬁcantly reduce the accuracy, while the number of the QM calculations is just a few
times higher than the theoretical minimum (which is equal to
the number of undetermined parameters).
Table 2: Accuracy for diﬀerent query strategies and γth.
force error
Comparison with classical learning on the ﬂy
Next we test the reliability of our AL strategy in a scenario of learning-on-the-ﬂy MD for bulk Li, as in the previous test case. We compare it to a the classical learning-onthe-ﬂy algorithm inspired by . In the authors
propose to: (1) learn from an initial, one or few picosecondlong AIMD trajectory, and (2) perform an MD with the trained
potential, additionally adding conﬁgurations to the training set
once in every Nstep time steps. For the purpose of illustration,
we choose Nstep = 100 and run MD at the melting temperature,
although we note that the authors of report their results for
Nstep = 30 at a much lower temperature.
The results of this test are illustrated in Figure 5. If a potential is trained on a ﬁxed database, it is observed that once
in about 15ps the atomistic system escapes into an unphysical region characterized by very low (below 1Å) bond lengths.
Therefore, to assess the reliability of a potential, we terminate
the MD if after some simulation time the minimal distance between atoms becomes smaller than 1.5Å. We call the simulation time after which half the trajectories are terminated (i.e.,
the trajectory half-life), the failure time. From the transition
state theory, we estimate that in an AIMD, the failure time is
of the order of 1010s—which is much larger than is accessible
even with a classical MD.
Figure 5 illustrates the comparison of classical and active
learning. The classical learning-on-the-ﬂy scheme inspired by
 , increases the average failure time from about 15ps to 150ps
at a cost of 1500 additional QM calculations. In contrast, with
the proposed active learning-on-the-ﬂy scheme, we ran eﬀectively a 0.5µs-long simulation, which has not failed a single
time. We used parallel replica method to access such a
long timescale. During this 0.5µs-long trajectory the scheme
required only about 50 additional QM calculations (out of them
only 5 during the ﬁrst 150ps, as compared to 1500 for the classical learning). Thus, the AL approach oﬀers, in practice, a
completely reliable scheme as opposed to the classical learning
approach at a much smaller cost.
We note that we have observed many classical learning-onthe-ﬂy MD trajectories that fail within the ﬁrst 5ps of learning
of the ﬂy. This means that, in the logic of , the initial MD
trajectory should be extended beyond 1ps, at the cost of more
QM calculations. Instead, in this work we simply discarded
those trajectories when estimating the failure time (otherwise
the estimated failure time would be signiﬁcantly smaller than
150ps). It should also be remarked that decreasing Nstep from
100 to 30, as suggested in , should further improve the reliability of the classical learning on the ﬂy, but this would further
increase its cost and will make its failure time more expensive
to measure.
Automatic expansion of the training region
In the next test, we illustrate how the AL scheme allows for
an automatic expansion of the region spanned by the training
set. We start with the potential from the previous test, trained
on the ﬂy for 500ps at 450K. The training set contains 100
crystalline conﬁguration. We then start a new learning-on-the-
ﬂy MD at 900K which is well above the melting point.
The performance of learning on the ﬂy is shown in Figure 6.
The solid-to-liquid transition occurs after about 200fs of simulation time and most of learning takes place between 200fs and
300fs. We emphasize that the AL algorithm does not “know”
of the temperature change—it makes the decision only based
on incoming atomistic conﬁgurations.
After learning at 900K, the prediction errors at lower temperatures somewhat increase. To test this, we actively selected
three sets of conﬁgurations, sampled at 300K, 450K, and 900K,
and ﬁtted three potentials on these sets, denoted by MTP300,
(a) Comparison of the query strategies (γth = 1).
10000 15000 20000 25000 30000
(b) QS1 with diﬀerent thresholds γth
(ﬁrst 30 ps).
Figure 4: Amount of QM calculations in a learning-on-the-ﬂy MD as a function of the MD time step. (a): Comparison of the query strategies; (b): QS1 with
diﬀerent thresholds γth (ﬁrst 30 ps).
10ps 100ps
10ns 100ns
Classical LOTF
Active LOTF
Figure 5: Comparison of ab initio molecular dynamics (AIMD) with nolearning MD, classical learning on the ﬂy (LOTF) inspired by , and active
LOTF. The no-learning and classical LOTF MD are not completely reliable:
on average every 15ps the no-learning MD fails, i.e., escapes into an unphysical region in the phase space. The classical LOTF makes this ten times more
reliable (failure time of 150ps) at the expense of extra 1500 QM calculations.
In contrast, the active LOTF makes MD completely reliable (i.e., failures are
not observed) at the cost of only 50 QM calculations as measured over the ﬁrst
0.5µs of simulation time.
Figure 6: Learning after raising the temperature from 450K to 900K. The atomistic system takes about 200fs to liquify, and for the next 100fs the potential
does most of learning of liquid conﬁgurations. After this, the QM calculations
are done only occasionally.
Table 3: Errors of potentials trained at diﬀerent temperatures when tested on
conﬁgurations sampled at diﬀerent temperatures. The absolute errors are in
eV/Å. The relative errors are also given in parenthesis. The potential trained on
crystalline conﬁgurations (at 300K or 450K) fails on the liquid conﬁgurations
(900K). When additionally trained on liquid conﬁgurations, the potential shows
somewhat higher errors for crystalline conﬁgurations, but no longer fails on
liquid conﬁgurations.
Force error at:
0.016 (4.6%)
0.022 (5.7%)
0.017 (4.7%)
0.020 (5.2%)
0.030 (8.4%)
0.033 (8.5%)
0.062 (7.0%)
MTP450, and MTP900, respectively. The errors of these potentials on these sets are shown in Table 3. The potentials trained
on crystalline conﬁgurations (at 300K or 450K) fail to predict
forces for liquid conﬁgurations. Nevertheless, after additional
training on liquid conﬁgurations, the potential became applicable to both, liquid and crystalline conﬁgurations; however, the
errors on crystalline conﬁgurations became somewhat larger.
Active learning beyond molecular dynamics
Crystalline
Figure 7: An illustration of conﬁgurations selected into the training set by active
learning. The X-axis is the range of energies per atom of conﬁgurations after
relaxation. The Y-axis is the number of conﬁgurations within a certain energy
range. The training set features 24 crystalline conﬁgurations and 76 fully or
partly liquid.
To illustrate that our AL approach is applicable to other,
non-MD simulation, we use AL to relax (i.e., ﬁnd the nearest
local minimum of) the conﬁgurations selected in the training set
while learning a 900K MD from the previous test. Relaxation
will additionally give us information about the composition of
the training set: the conﬁgurations learned from MD at 450K
should preserve crystalline structure and relax to a perfect crystal, while the conﬁgurations learned from MD at 900K should
correspond to the liquid phase and relax to disordered (glasslike) conﬁgurations.
Thus, we take each conﬁguration from the training set, relax
while learning on the ﬂy, and compare its energy to the energy
of a relaxed ideal crystalline conﬁgurations. Only 1 of 100 con-
ﬁgurations required additional QM calculations while relaxing,
which indicates that there were practically no “new” conﬁgurations in the process. The result is shown in Figure 7. We
see that 24 of 100 conﬁgurations in the training set are perfect
crystals, some conﬁgurations correspond to the onset of melting
(solid-liquid coexistence), and some correspond to fully liquid
conﬁgurations.
It should be noted that extra care should be taken with regards to the fact that the interatomic potential may slightly change
while learning on the ﬂy during relaxation. Indeed, if a potential
increased after treating a certain conﬁguration, then this conﬁguration may be falsely considered as a local minimum (since
after the change in the potential energy, the nearby conﬁgurations have higher energies). This issue can be ﬁxed either by
re-running the relaxation or formulating the stopping criterion
in terms of forces only.
5. Discussion
Our results suggest that the proposed learning-on-the-ﬂy algorithms do not, essentially, reduce the accuracy of interatomic
potentials while always keeping the MD trajectory within the
physical region. It should also be emphasized that the AL algorithm introduces a computational overhead that, at least in our
test examples, was less expensive than calculating the energy,
forces and stresses. The overhead of retraining our potential
was also small compared to the time of calculating the energy,
forces and stresses.
Our AL algorithms is not speciﬁc to MD and can, in principle, be used with any other type of atomistic simulation, such as
structure relaxation, Monte-Carlo sampling, nudge elastic band
 , or the accelerated MD methods . Also, our algorithms
can learn conﬁgurations with varying number of atoms. This
may be important in many applications, including computational structure prediction where the sought conﬁgurations
may be of unknown size.
The choice of the D-optimality criterion, which our AL algorithms are based on, was motivated by reducing uncertainty
in the parameters of potential. However, there is also another interpretation. For example, the elements of the matrix A in QS1,
bj(x(k)), can be considered as descriptors of the conﬁguration
x(k), each conﬁguration is characterized by an m-dimensional
descriptor vector. In this sense the D-optimality criterion maximizes the volume of the simplex in Rm formed by m descriptor vectors. In the same way Bj
, which are the elements
of matrix A in QS3, can be considered as the descriptors of a
neighborhood of atom i of k-th conﬁguration. Therefore, QS3
“catches” conﬁgurations with the most diﬀerent atomic neighborhoods in the sense of the D-optimality criterion. This property of QS3 can be useful in designing algorithms of a learningon-the-ﬂy MD with million or more atoms where training has
to be done on local environments completed to small conﬁgurations.
6. Conclusion
Machine learning interatomic potentials oﬀer a promising
way of combining the accuracy of quantum mechanics and the
computational eﬃciency of the empirical interatomic potentials.
However, the weak point of the machine learning interatomic
potentials is reliability—the more general and accurate they are
required to be, the harder it is to generate oﬄine the training
dataset that ensures no extrapolation at the online evaluation
stage. In the present work we have shown that this problem
can be solved by applying active learning to the ﬁtting of the
machine learning interatomic potentials.
We have proposed a new active learning scheme based on
the D-optimality criterion and have shown empirically that it
yields an accurate, computationally eﬃcient, and reliable interatomic interaction model. In particular, using active learning in the learning-on-the-ﬂy scenario fully resolves the transferability problem—active learning detects when extrapolation
is attempted and retrains the potential on those conﬁgurations.
In the case when learning on the ﬂy cannot be performed, the
proposed active learning techniques allow one to control the
degree of extrapolation. The software, test cases, and examples of usage are published at 
ru/shapeev/mlip/.
Acknowledgments
The authors thank Prof. Ivan Oseledets for useful discussions of application of the D-optimality criterion in active learning, in particular for directing our attention to the maxvol algorithm . This work was supported by the Skoltech NGP Program No. 2016-7/NGP (a Skoltech-MIT joint project). A part
of the work was done by A.S. during the Fall 2016 long program at the Institute of Pure and Applied Mathematics, UCLA.
References