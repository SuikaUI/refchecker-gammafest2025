Multi-Range Attentive Bicomponent Graph
Convolutional Network for Traffic Forecasting
Weiqi Chen,1 Ling Chen,1, * Yu Xie,2 Wei Cao,2 Yusong Gao,2 Xiaojie Feng2
1 College of Computer Science and Technology, Zhejiang University, Hangzhou 310027, China
2 Alibaba Group, Hangzhou 311121, China
 , ,
{qianqing.xy, mingsong.cw, jianchuan.gys, xiaojie.fxj}@alibaba-inc.com
Traffic forecasting is of great importance to transportation
management and public safety, and very challenging due to
the complicated spatial-temporal dependency and essential
uncertainty brought about by the road network and traffic
conditions. Latest studies mainly focus on modeling the spatial dependency by utilizing graph convolutional networks
(GCNs) throughout a fixed weighted graph. However, edges, i.e., the correlations between pair-wise nodes, are much
more complicated and interact with each other. In this paper, we propose the Multi-Range Attentive Bicomponent
GCN (MRA-BGCN), a novel deep learning model for traffic forecasting. We first build the node-wise graph according to the road network distance and the edge-wise graph
according to various edge interaction patterns. Then, we implement the interactions of both nodes and edges using bicomponent graph convolution. The multi-range attention
mechanism is introduced to aggregate information in different neighborhood ranges and automatically learn the importance of different ranges. Extensive experiments on two
real-world road network traffic datasets, METR-LA and
PEMS-BAY, show that our MRA-BGCN achieves the stateof-the-art results.
Introduction
Traffic forecasting is one of the most challenging tasks in
Intelligent Transportation System (ITS) and of great importance to transportation management and public safety. The task of traffic forecasting is to
forecast the future traffic of a road network given the historical traffic data.
This task is very challenging mainly due to the complicated spatial-temporal dependency and essential uncertainty brought about by the road network and traffic conditions. On the one hand, the irregular underlying road network results in complicated correlations among traffic da-
* Corresponding author
Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
ta. On the other hand, due to various unpredictable traffic
conditions, traffic data is inherently uncertain.
Figure 1: The Interaction of Edges in a Node-Wise Graph
Early traffic forecasting approaches mainly employ
shallow machine learning for a single observation node or
few nodes, which are limited by the capability of capturing
the nonlinearity in traffic data and neglect or barely leverage the spatial dependency. Recent advances in deep learning make it possible to model the complicated spatialtemporal dependency in traffic forecasting. Some attempts
 applied Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) for traffic forecasting. However, CNNs restrict the model to process grid structures
(e.g., images and videos), and the non-Euclidean correlations dominated by irregular road networks are not considered. To tackle this problem, Graph Convolutional Networks (GCNs), which are efficient in handling non-
Euclidean correlations, are integrated with RNNs or CNNs to embed the prior
knowledge of the road network and capture the correlations
between pair-wise nodes. Despite promising results of in-
(a) Traffic network
(b) Fixed weighted graph
(c) The interaction of edges
The Thirty-Fourth AAAI Conference on Artiﬁcial Intelligence (AAAI-20)
troducing GCNs, we argue that there are still two important
aspects neglected in these approaches.
First, these approaches mainly focus on modeling the
spatial dependency by utilizing GCNs throughout a fixed
weighted graph. However, edges, i.e., the correlations between pair-wise nodes, are much more complicated and
interact with each other. Figure 1 illustrates an example.
As shown in Figure 1(a), sensors 1 and 3, as well as sensors 2 and 3, are correlated by road links. Obviously, these
correlations change with the current traffic condition and
interact with each other. As shown in Figure 1(b), existing
approaches build a weighted graph according to the road
network distance and use a GCN to implement the interaction of nodes, while the correlations between pair-wise
nodes are represented by fixed scalars in the adjacency
matrix, which neglects the complexity and interaction of
Second, these approaches usually use the information
aggregated in a given neighborhood range (i.e., neighbors
within 𝑘-hops), ignoring multiple range information. However, information in different ranges reveals distinct traffic
properties. A small neighborhood range indicates the local
dependency, and a large range tends to uncover an overall
traffic pattern in a relatively large region. Furthermore,
information in different ranges does not contribute equally
in all cases. For example, due to a traffic accident, a node
is predominantly influenced by its nearest neighbors, on
which a model should pay more attention rather than considering all neighbors within 𝑘-hops equally.
To address the aforementioned problems, we propose a
deep learning model called Multi-Range Attentive Bicomponent GCN (MRA-BGCN), which not only considers
node correlations, but also regards edges as entities that
interact with each other, as shown in Figure 1(c), and leverages multiple range information. The main contributions
of our work are as follows:
 We propose MRA-BGCN, which introduces the bicomponent graph convolution to explicitly model the correlations of both nodes and edges. The node-wise graph is
built according to the road network distance, and the
edge-wise graph is built by considering two types of
edge interaction patterns, stream connectivity and competitive relationship.
 We propose the multi-range attention mechanism for the
bicomponent graph convolution, which can aggregate information in different neighborhood ranges and learn the
importance of different ranges.
 We conduct extensive experiments on two real-world
traffic datasets, METR-LA and PEMS-BAY, and the
proposed model achieves the state-of-the-art results.
Related Works
Early traffic forecasting approaches, e.g., Linear Regression based approach , Kalman Filtering based approach , and Auto-
Regressive Integrated Moving Average (ARIMA) based
approach , mainly employ shallow machine learning for a single observation node or few nodes,
which are limited by the capability of capturing the nonlinearity in traffic data and neglect or barely leverage the spatial dependency.
Recent advances in deep learning make it possible to
model the complicated spatial-temporal dependency in
traffic forecasting. Some attempts applied Convolutional Neural
Networks (CNNs) and Recurrent Neural Networks (RNNs)
for traffic forecasting. In these studies, CNNs, which are
restricted to processing regular grid structures (e.g., images
and videos), are introduced to capture the spatial dependency, while the non-Euclidean correlations dominated by
irregular road networks are not considered.
To tackle this problem, researchers have applied graph
convolution to model the non-Euclidean correlations for
traffic forecasting. Li et al. proposed Diffusion
Convolutional Recurrent Neural Network (DCRNN),
which replaces the fully-connected layers in Gated Recurrent Units (GRU) by the diffusion
convolution operator. The diffusion convolution performs
graph convolution on the given graph and its inverse to
consider both inflow and outflow relationships. Yu et al.
 proposed Spatial-Temporal GCN (ST-GCN), which
combines a graph convolution with a 1D convolution. In
ST-GCN, the graph convolution captures the spatial dependency, and the 1D convolution is employed on time
axis to capture the temporal dependency, which is much
more computationally efficient than RNNs.
The above-mentioned GCN-based approaches encode
the road network distance into a fixed weighted graph representing the spatial dependency. To further modeling the
complicated correlations in traffic forecasting, Wu et al.
 proposed to capture the hidden spatial dependency
that is unseen in the given graph with a self-adaptive adjacency matrix. This self-adaptive adjacency matrix is
achieved by computing the similarity of node embeddings.
However, the hidden spatial dependency is learnt in a datadriven manner, which lacks the guidance of the domain
knowledge and may suffer from the overfitting problem. In
addition, existing traffic forecasting approaches are ineffective to model the interaction of edges and leverage multiple range information.
Figure2: The Architecture of MRA-BGCN
Preliminaries
Problem Definition
Given the historical traffic data from 𝑁 correlated traffic
sensors located on a road network, the task of traffic forecasting is to forecast the future traffic of the road network.
Following previous studies, we define the 𝑁 correlated
traffic sensors as a weighted directed graph 𝐺= (𝑉, 𝐸, 𝑨),
where 𝑉 is a set of |𝑉| = 𝑁 nodes, 𝐸 is a set of edges, and
𝑨∈ℝ𝑁×𝑁 is a weighted adjacency matrix representing the
nodes’ proximities, e.g., the road network distance between
any pair of nodes. The traffic data observed on 𝐺 at time 𝑡
are denoted as a graph signal 𝑿(𝑡) ∈ℝ𝑁×𝑃, where 𝑃 is the
feature dimension of each node. The traffic forecasting
problem aims to learn a function 𝑓 that is able to forecast 𝑇
future graph signals given 𝑇′ historical graph signals and
the graph 𝐺:
[𝑿(𝑡−𝑇′+1):𝑡, 𝐺]
𝑓→[𝑿(𝑡+1):(𝑡+𝑇)],
where 𝑿(𝑡−𝑇′+1):𝑡∈ℝ𝑁×𝑃×𝑇′ and 𝑿(𝑡+1):(𝑡+𝑇) ∈ℝ𝑁×𝑃×𝑇.
Graph Convolution
GCNs are building blocks for learning data with non-
Euclidean structures, i.e., graphs . They
are widely applied in node classification , graph classification , link
prediction , etc. GCN approaches
fall into two categories, spectral-based and spatial-based.
Spectral-based approaches conduct graph Fourier transformation and apply convolutional filters on the spectral
domain .
Spatial-based approaches aggregate the representations of a
node and its neighbors to get a new representation for the
node .
We briefly describe the graph convolution operator applied in our model. A graph convolution is defined over a
graph 𝐺= (𝑉, 𝐸, 𝑨):
𝜽⋆𝐺𝑿= 𝜌(𝑫̃−1𝑨̃𝑿𝜽),
where 𝑿∈ℝ𝑁×𝑃 is the input signal, 𝜽∈ℝ𝑃×𝐹 is the learnable parameter matrix, 𝑨̃ = 𝑨+ 𝑰𝑁 is the adjacency matrix
with self-connection, 𝑫̃ is the diagonal degree matrix of 𝑨̃,
𝑫̃−1𝑨̃ represents the normalized adjacency matrix, and 𝜌 is
a nonlinear activation function. A graph convolution can
aggregate information of 1-hop neighbors. By stacking
multiple graph convolution layers, we can expand the receptive neighborhood range.
Methodology
Model Overview
Figure 2 demonstrates the architecture of MRA-BGCN,
which consists of two parts: (1) the bicomponent graph
convolution module; and (2) the multi-range attention layer. The bicomponent graph convolution module contains
Graph Convolution
Graph Convolution
Multi-Range
Graph Convolution
Graph Convolution
Graph Convolution
Graph Convolution
Graph Convolution
several node-wise graph convolution layers and edge-wise
graph convolution layers, which can explicitly model the
interactions of both nodes and edges. The multi-range attention layer aggregates information in different neighborhood ranges and learns the importance of different ranges.
In addition, we combine MRA-BGCN with RNN to model
the temporal dependency for traffic forecasting. The detailed implementation is described in the following subsections.
Bicomponent Graph Convolution
Graph convolution is an efficient operation to model the
interaction of nodes given the graph structure. However, in
traffic forecasting, edges, i.e., the correlations between
pair-wise nodes, are much more complicated and interact
with each other. Thus, we propose the bicomponent graph
convolution, which can explicitly model the interactions of
both nodes and edges.
Figure 3: Edge Interaction Patterns
Chen et al. proposed to introduce line graph of
edge adjacencies to model edge correlations. Let 𝐺=
(𝑉, 𝐸, 𝑨) denotes the node-wise directed graph. 𝐺𝐿=
(𝑉𝐿, 𝐸𝐿, 𝑨𝐿) is the corresponding line graph, then the nodes
𝑉𝐿 of 𝐺𝐿 are the ordered edges in 𝐸, i.e., 𝑉𝐿=
{(𝑖→𝑗); (𝑖, 𝑗) ∈𝐸} and |𝑉𝐿| = |𝐸|. 𝑨𝐿 is an unweighted
adjacency matrix that encodes the edge adjacencies in the
node-wise graph, which is defined as: 𝑨𝐿,(𝑖→𝑗),(𝑗→ ) = 1
and 0 otherwise.
Despite the capability of considering edge adjacencies,
the line graph is an unweighted graph and only considers
two edges are correlated if one’s target node shares with
the other one’s source node. However, it is ineffective to
characterize various edge interaction patterns that are
common in traffic forecasting. As shown in Figure 3, we
define two types of edge interaction patterns to construct
the edge-wise graph 𝐺ℯ= (𝑉ℯ, 𝐸ℯ, 𝑨ℯ). Note that, each node
of 𝑉ℯ represents an edge of 𝐸.
Stream connectivity: In a traffic network, a road link is
possibly influenced by its upstream and downstream road
links. As shown in Figure 3(a), (𝑖→𝑗) is an upstream edge
of (𝑗→𝑘), and thus they are correlated. Intuitively, if the
joint node 𝑗 has a large number of neighbors (i.e., the degree of 𝑗 is large), the correlation between (𝑖→𝑗) and
(𝑗→𝑘) is weak, as it is susceptible to other neighbors. We
compute the edge weights for the stream connectivity in 𝑨ℯ
using Gaussian kernel:
𝑨ℯ,(𝑖→𝑗),(𝑗→ ) = 𝑨ℯ,(𝑗→ ),(𝑖→𝑗) =
(deg−(𝑗)+deg+(𝑗)− )2
where deg−(𝑗) and deg+(𝑗) denote the indegree and outdegree of node 𝑗 in the node-wise graph, respectively, and
𝜎 is the standard deviation of node degrees.
Competitive relationship: Road links sharing a same
source node probably contend for traffic resources and
incur competitive relationship. As shown in Figure 3(b),
two edges, (𝑖→𝑘) and (𝑗→𝑘), sharing the target node 𝑘
are correlated due to competitive relationship. Analogous
to stream connectivity, the intensity of competitive relationship is related to the outdegrees of the source nodes.
For example, if the source node of an edge has multiple
outcoming edges, this edge is robust for the competition of
traffic resources. Thus, we compute the edge weights for
the competitive relationship in 𝑨ℯ as:
𝑨𝑒,(𝑖→ ),(𝑗→ ) = 𝑨𝑒,(𝑗→ ),(𝑖→ ) =
(deg+(𝑖)+deg+(𝑗)− )2
With the constructed edge-wise graph 𝐺ℯ, as shown in
Figure 2, the bicomponent graph convolution can explicitly
model the interactions of both nodes and edges. The 𝑘-hop
bicomponent graph convolution is formulated as:
𝑿(𝑙+1) = 𝜽𝓃
⋆𝐺[𝑿(𝑙), 𝑴𝒁(𝑙)]⁡⁡⁡for⁡𝑙= 1, ⋯, 𝑘−1,
𝒁(𝑙+1) = 𝜽ℯ
⋆𝐺𝒁(𝑙)⁡⁡⁡for⁡𝑙= 0, ⋯, 𝑘−1,
𝒁(0) = 𝑴T𝑿(0)𝑾b,
where 𝜽⋆𝐺 is the graph convolution operation with parameter 𝜽, [⋅,⋅]is the concatenation operation, 𝑿(𝑙−1) is the input
to layer 𝑙 of the node-wise graph convolution, 𝒁(𝑙−1) is the
input to layer 𝑙 of the edge-wise graph convolution,
𝑴∈ℝ|𝑉|×|𝐸| is the incidence matrix that encodes the connections between nodes and edges, defined as: 𝑴𝑖,(𝑖→𝑗) =
𝑴𝑗,(𝑖→𝑗) = 1 and 0 otherwise. 𝑴𝒁(⋅) aggregates edge representations connected with each single node, and 𝑴T𝑿(⋅)
aggregates node representations connected with each single
edge. 𝑾b is a learnable projection matrix that transforms
the original node input 𝑿(0) to the original edge input 𝒁(0).
Multi-Range Attention
We propose the multi-range attention mechanism for the
bicomponent graph convolution to automatically learn the
importance of different neighborhood ranges, which is capable of aggregating information in different neighborhood
(a) Stream connectivity
(b) Competitive relationship
ranges rather than the given neighborhood range (i.e.,
neighbors within 𝑘-hops) only.
The bicomponent graph convolution module obtains
node representations in different neighborhood ranges,
𝓧= {𝑿(1), 𝑿( ), ⋯, 𝑿( )} , 𝑿(𝑙) ∈ℝ|𝑉|×𝐹, where 𝑘 is the
maximum hop (i.e., the number of layers in the bicomponent graph convolution module), and 𝐹 is the representation dimension of each node. 𝑿𝑖
(𝑙) ∈ℝ𝐹 denotes node 𝑖’s
representation in layer 𝑙. The multi-range attention layer
aims to capture an integrated representation from multiple
neighborhood ranges. To this end, first, a shared linear
transformation, parameterized by 𝑾a ∈ℝ𝐹×𝐹′, is applied
to every node in each layer. Then, the attention coefficients
of each layer are measured by calculating the similarity of
(𝑙) and 𝒖, where 𝒖∈ℝ𝐹′ is the neighborhood range
context embedding, which is initialized as a random vector
and jointly learnt during the training process. Finally, the
SoftMax function is applied to normalize the coefficients.
The multi-range attention mechanism is formulated as:
(𝑙) = (𝑾a𝑿𝑖
(𝑙) = SoftMax𝑙 and Li
et al. , we combine the proposed MRA-BGCN with
GRU by replacing the fully-connected
layers in GRU with MRA-BGCN. We refer this RNN
structure as Bicomponent Graph Convolutional GRU
(BGCGRU). To simplify notations, we denote ℊ(𝑿; 𝚯) as
applying MRA-BGCN to the input 𝑿, and 𝚯 is the total
trainable parameters. Then, BGCGRU is formulated as:
𝒛(𝑡) = 𝜎(ℊ([𝑿(𝑡), 𝑯(𝑡−1)]; 𝚯𝑧)),
𝒓(𝑡) = 𝜎(ℊ([𝑿(𝑡), 𝑯(𝑡−1)]; 𝚯𝑟)),
𝑪(𝑡) = tanh(ℊ([𝑿(𝑡), (𝒓(𝑡)⨀𝑯(𝑡−1))]; 𝚯𝑐)),
𝑯(𝑡) = 𝒛(𝑡)⨀𝑯(𝑡−1) + (1 −𝒛(𝑡))⨀𝑪(𝑡),
where 𝑿(𝑡) and 𝑯(𝑡) denote the input and output at time
step 𝑡, 𝒛(𝑡) and 𝒓(𝑡) denote the update gate and reset gate at
time step 𝑡, 𝜎 is the Sigmoid function, and ⨀ is the Hadamard product. As shown in Figure 4, we stack several
BGCGRU layers and employ the Sequence to Sequence
architecture for multiple step ahead
traffic forecasting.
Figure 4: The Sequence to Sequence Architecture
Table 1: The Statistics of METR-LA and PEMS-BAY
#Time Steps
Experiments
We evaluate MRA-BGCN on two public traffic network
datasets, METR-LA and PEMS-BAY .
METR-LA records four months of statistics on traffic
speed, ranging from Mar 1st 2012 to Jan 30th 2012, including 207 sensors on the highways of Los Angeles County.
PEMS-BAY contains six months of statistics on traffic
speed, ranging from Jan 1st 2017 to May 31th 2017, including 325 sensors in the Bay area. We adopt the same
data pre-processing procedures as Li et al. . The
observations of the sensors are aggregated into 5-minute
windows. The adjacency matrix of the node-wise graph is
constructed by road network distance with thresholded
Gaussian kernel . Z-score normalization is applied to the inputs. Both the datasets are split in
chronological order with 70% for training, 10% for validation, and 20% for testing. Detailed statistics of the datasets
are shown in Table 1.
We compare MRA-BGCN with the following models:
 HA: Historical Average, which models the traffic flow
as a seasonal process, and uses the average previous seasons as the prediction. The period is set to 1 week and
the prediction is based on the traffic data at the same
time in previous weeks.
Current Time
Table2: The Performance Comparison of Multiple Step Ahead Traffic Forecasting
Graph WaveNet
Graph WaveNet
 ARIMAkal: Auto-Regressive Integrated Moving Average
Model with Kalman filter, which is a classical time series prediction model .
 FC-LSTM: Recurrent neural network with fully connected LSTM hidden units .
 DCRNN: Diffusion Convolutional Recurrent Neural
Network , which combines recurrent
neural networks with diffusion convolution modeling
both inflow and outflow relationships.
 ST-GCN: Spatial-Temporal Graph Convolution Network , which combines 1D convolution
with graph convolution.
 Graph WaveNet: A convolution network architecture
 , which introduces a self-adaptive
graph to capture the hidden spatial dependency, and uses
dilated convolution to capture the temporal dependency.
For all neural network based approaches, the best hyperparameters are chosen using grid search based on the performance on the validation set.
Experimental Settings
Recalling that the task is to learn a function 𝑓:⁡ℝ𝑁×𝑃×𝑇′ →
ℝ𝑁×𝑃×𝑇. In experiments, we aim at forecasting the traffic
speed over one hour in the future given the traffic speed in
the last hour, i.e., 𝑇= 𝑇′ = 12.
In experiments, the number of the BGCGRU layers is
set to 2, with 64 hidden units. The maximum hop 𝑘 of the
bicomponent graph convolution is set to 3. We train our
model by using Adam optimizer to
minimize the mean absolute error (MAE) for 100 epochs
with the batch size as 64. The initial learning rate is 1e-2
with a decay rate of 0.6 per 10 epochs. In addition, the
scheduled sampling and L2 normalization with a weight decay of 2e-4 is applied for better
generalization.
Three common metrics of traffic forecasting are adopted
to measure the performance of different models, including
(1) Mean Absolute Error (MAE), (2) Mean Absolute Percentage Error (MAPE), and (3) Root Mean Squared Error
Performance Comparison
Table 2 presents the performances of MRA-BGCN and
baseline models for 15 minutes, 30 minutes, and 1 hour
ahead forecasting selected from the 12 forecasting horizons
on both datasets. We observe the following phenomena:
 MRA-BGCN achieves the best performance for all forecasting horizons. It outperforms traditional traffic forecasting methods (HA, ARIMAkal, and FC-LSTM) dramatically. MRA-BGCN also excels the vanilla GCNbased approaches (DCRNN and ST-GCN) distinctly,
which perform GCN on the fixed weighted graph built
according to the road network distance.
 With respect to the second-best model Graph WaveNet,
we can observe that MRA-BGCN achieves small improvement on PEMS-BAY dataset, while large improvement on METR-LA dataset. From another perspective, a similar circumstance can be observed that with
the growth of the forecasting horizon, the superiority of
MRA-BGCN increases. Note that, the data dependency
on METR-LA dataset (Los Angeles, which is known for
its complicated traffic conditions) is more complicated,
and long-term forecasting is inherently more uncertain
than short-term forecasting. Therefore, we consider that
MRA-BGCN is more capable to model complicated de-
pendencies. Graph WaveNet introduces a self-adaptive
graph to capture the hidden spatial dependency, which is
learnt in a data-driven manner and hard to detect in
complicated scenes. By contrast, we model the potential
spatial dependency under the guidance of the edge interaction patterns, which can provide a better comprehension of the data and are crucial for modeling complicated
dependencies.
In the following experiments, we choose to use the more
complicated dataset, METR-LA.
Effect of the Edge-Wise Graph
To verify the effectiveness of the proposed edge-wise
graph, we compare MRA-BGCN with two variants: (1)
MRA-BGCN-Identity, which ignores the edge correlations
and replaces the edge-wise adjacency matrix with an identity matrix. This essentially implies edges do not interact
with each other and are only determined by the connected
nodes; (2) MRA-BGCN-LineGraph, which replaces the
edge-wise graph with the line graph, which ignores various
edge interaction patterns. Table 3 shows the mean MAE,
RMSE, and MAPE of 12 predictions. We can observe that,
without considering the edge correlations, MRA-BGCN-
Identity yields the largest testing error. Moreover, MRA-
BGCN achieves the lowest testing error, which shows the
effectiveness of capturing various edge interaction patterns. The intuition is that the proposed edge-wise graph
considers stream connectivity and competitive relationship,
and gives the model the capability of capturing complicated dependencies.
Effect of the Multi-Range Attention Mechanism
To further verify the effectiveness of the multi-range attention mechanism, we evaluate MRA-BGCN with the following variants using different methods for leveraging the
multiple range information, including: (1) BGCN, biocomponent graph convolutional network, which ignores the
multiple range information and uses representations aggregated in the given neighborhood range (i.e., only the output
of layer 𝑘 is used); (2) MR-BGCN, multi-range bicomponent graph convolutional network, which leverages the
multiple range information by concatenating representations in each layer, and considers information from each
neighborhood range contributes equally. The difference
between MRA-BGCN and the variants is shown in Figure
5. Table 4 shows the mean MAE, RMSE, and MAPE of 12
predictions. We can observe that BGCN, which ignores the
multiple range information, achieves the worst performance, and MRA-BGCN works better than MR-BGCN.
The results verify the effectiveness of the multi-range attention mechanism, which is able to leverage multiple
range information and distinguish the importance of different neighborhood ranges.
Table 3: The Performance Comparison of MRA-BGCN and
MRA-BGCN without Edge-wise Graph
MRA-BGCN-Identity
MRA-BGCN-LineGraph
Table 4: The Performance Comparison of MRA-BGCN and
MRA-BGCN without the Multi-range Attention Mechanism
Figure 5: The Illustration of MRA-BGCN and the Variants
Conclusions and Future Work
We propose the Multi-Range Attentive Bicomponent Graph
Convolutional Network for traffic forecasting. Specifically,
the bicomponent graph convolution is proposed to explicitly model the correlations of both nodes and edges. An
edge-wise graph construction approach is proposed to encode stream connectivity and competitive relationship. The
multi-range attention mechanism is proposed to efficiently
leverage multiple range information and generate integrated representations. On two traffic datasets, our model
achieves the state-of-the-art performance. For future work,
we will investigate the following two aspects (1) applying
the proposed model to other spatial-temporal forecasting
tasks; (2) extending our approach to model more complex
spatial-temporal dependencies considering more factors,
e.g., traffic accidents and surrounding points of interest.
(b) MR-BGCN
(c) MRA-BGCN
Multi-Range
Acknowledgement
This work is supported by the National Key Research and
Development Program of China (No. 2018YFB0505000).