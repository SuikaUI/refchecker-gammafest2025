HAL Id: hal-00338658
 
Submitted on 13 Nov 2008
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of scientific research documents, whether they are published or not.
The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
Ultrasound image segmentation: a survey
Alison Noble, Djamal Boukerroui
To cite this version:
Alison Noble, Djamal Boukerroui. Ultrasound image segmentation: a survey. IEEE Transactions on
Medical Imaging, 2006, 25 (8), pp.987-1010. ￿10.1109/TMI.2006.877092￿. ￿hal-00338658￿
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 25, NO. 8, AUGUST 2006
Ultrasound Image Segmentation: A Survey
J. Alison Noble∗, Senior Member, IEEE, and Djamal Boukerroui
Abstract— This article reviews ultrasound segmentation methods, in a broad sense, focusing on techniques developed for
medical B-mode ultrasound images. First, we present a review
of articles by clinical application to highlight the approaches
that have been investigated and degree of validation that has
been done in different clinical domains. Then, we present a
classiﬁcation of methodology in terms of use of prior information.
We conclude by selecting 10 papers which have presented original
ideas that have demonstrated particular clinical usefulness or
potential speciﬁc to the ultrasound segmentation problem.
Index Terms— Segmentation, ultrasound, B-scan, review.
I. INTRODUCTION
Ultrasound image segmentation is strongly inﬂuenced by
the quality of data. There are characteristic artefacts which
make the segmentation task complicated such as attenuation,
speckle, shadows and signal dropout; due to the orientation
dependence of acquisition that can result in missing boundaries. Further complications arise as the contrast between areas
of interest is often low. However, there have been recent
advances in transducer design, spatial/temporal resolution,
digital systems, portability etc that mean that the quality of
information from an ultrasound (US) device has signiﬁcantly
improved . This has led to increased use of ultrasound
in not only its traditional area of application, diagnosis (and
computer-aided detection (CAD)), but also emerging areas
such as image-guided interventions, and therapy. Thus, there
is currently a re-emergence of interest in understanding how
to do one of the oldest image processing tasks, image segmentation, applied to ultrasound data. As this review attempts to
demonstrate, while in other areas of medical imaging (notably
X-ray Computed Tomography (CT) and Magnetic Resonance
Imaging (MRI)), application of general image processing
methods can sufﬁce, in the case of ultrasound data, customized
methods, which attempt to model the imaging physics in some
way have proven to be more successful. This article focuses
on techniques developed for native (conventional) B-mode
ultrasound images and not segmentation of radio-frequency
(RF) signal or Doppler images. Both 2D and 3D segmentation
are considered, although the literature on 2D methodology
is far more extensive, reﬂecting the still relatively low (but
increasing) use of 3D image acquisition technology in clinical
practice today.
In practice, one ﬁnds that most new segmentation methodology is reported by placing it in context of related literature
Manuscript received August 22, 2005; revised April 5, 2006. Asterisk
indicates corresponding author.
∗J. Alison Noble is with the Department of Engineering Science University
of Oxford, Oxford OX1 3PJ, UK.
D. Boukerroui is with HEUDIASYC, UMR CNRS 6599 Universit´e de
Technologie de Compi`egne, BP 20529 – 60205 Compi`egne Cedex, France
for a chosen clinical application and the few US segmentation reviews have been reported from this clinical domain
perspective e.g. – . To our knowledge this is the ﬁrst comprehensive review of ultrasound segmentation methodology
in a broad-sense. This points to some common methodology
issues across different clinical applications in terms of prior
modeling. There are a larger number of papers which describe
general segmentation methods which show application of a
method to one or two ultrasound images or sequences without
speciﬁc reference to ultrasound image formation or context.
We have not included these as they are much more difﬁcult
to identify. We have also not considered the segmentation of
ultrasound parametric images such as elasticity images, and
functional ultrasound contrast image sequences. Finally, we
recognize that in the future more work is likely to be done in
segmentation based on the RF signal but access is not widely
available so we have not considered this here. See , for
recent segmentation papers based on this.
The outline of the paper is as follows. In Section II we
review principal works on ultrasound image segmentation classiﬁed by clinical application as most researchers are interested
in a segmentation solution for a given clinical problem. This
section focuses on application areas in which the majority of
effort has been focussed, namely segmentation of echocardiography, breast ultrasound, transrectal ultrasound (TRUS),
intravascular ultrasound (IVUS) images, and ultrasound images acquired in obstetrics and gynaecology. Examples from
representative methods of the ﬁrst four are respectively shown
1−4. In Section III we summarize performance
assessment and clinical validation that has been done in these
areas to-date. Section IV will be of particular interest to
researchers working on new segmentation algorithm development. Here we focus on reviewing collectively ﬁrst papers
which have been motivated by and incorporate knowledge
of ultrasound physics (particularly speckle models) and then
articles that have developed segmentation solutions that used
other prior information (intensity, shape and temporal models)
We conclude in Section V by listing 10 papers which have
made contributions speciﬁc to ultrasound segmentation in
terms of novel ideas and/or validation and may be useful as
an introduction to those new to the ﬁeld.
II. CLASSIFICATION BY CLINICAL APPLICATION
In this section we have included papers which have undergone a reasonable clinical validation as well as papers
which may have been less-well validated but have particular
features which make them well-suited to the speciﬁc clinical
application domain.
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 25, NO. 8, AUGUST 2006
A. Cardiology
Echocardiography (ultrasound imaging of the heart) has
been one of the driving application areas of medical ultrasound
and the literature on methods for automatically segmenting and
tracking the left ventricle (the normal chamber assessed for
heart disease) is extensive. Most attention has been given to
tracking the motion of the endocardium (blood pool/tissue border) to allow for estimation of left ventricular areas/volumes
and derived measures such as the ejection fraction 1, and for
regional wall motion assessment. In particular, these measures
are used in diagnosis and assessment of ischaemic heart
disease. Most analysis is based on 2D acquisitions in which
it is implicitly assumed that the principal component of
motion is in the plane of the acquisition slice. The standard
2D diagnostic views used for this are called the parasternal
short-axis (SAX), and apical four-chamber (4C), two-chamber
(2C) and three-chamber (3C) views. The latter 3 are also
sometimes referred to as (apical) long-axis (LAX) views. The
quality of data, and hence challenges for segmentation, vary
depending on the view due to the anisotropy of ultrasound
image acquisition, artefacts such as shadowing from the lungs,
and attenuation which can be strong. Segmentation methods
should also have strategies for avoiding the papillary muscles.
Reliably ﬁnding the outer wall (often called epicardial border
detection) is much more challenging, particularly from apical views. There are many papers on left ventricle tracking
which deal with the tracking/deformation model independent
of feature extraction or the imaging modality. We have not
discussed these papers. See the review by Frangi et al. for
a discussion of this.
3D echocardiography is a relatively new imaging modality
and image analysis is not yet well-developed. Early work
used either freehand ultrasound (with 2D image acquisition
synchronized with recording the location of the slice with a
position sensor), rotational 3D probes which acquired a sparse
set of 2D image sequences, or real-time 3D echocardiography
based on the Volumetrics system , . However, a second
generation of real-time 3D echocardiography systems have
recently been produced by Philips Medical Systems. This
data is of higher quality than the rotational 3D probe and
Volumetrics systems . One therefore has to take particular
care in interpreting the results from early 3D work as being
representative of what can be achieved today.
This review focuses on endocardial border detection unless
otherwise stated. Much of the early work focused on still
(single) frame segmentation - simulating what a cardiologist
often does which is look at end-diastole (maximum expansion)
and end-systole (maximum contraction) frames to compute
measures such as the ejection fraction 1. However, to fully
assess heart function, analysis needs to be done over the
whole cardiac cycle. Cardiologists also use a movie of a
heart in decision-making as the speckle pattern associated
with deforming tissue can be observed in a movie whereas
in a still frame the speckle pattern is not always useful. As a
result, and in contrast to some other clinical application areas
(see later sections), in echocardiography it is perhaps more
logical to view segmentation as a spatio-temporal problem.
Examples of echocardiographic image segmentation: Short axis
images from Dias and Leit˜ao (a) Mikic et al. (b);
long axis images from Bosch et al. (c).
More recent successful approaches have taken this viewpoint.
An early review of endocardial border detection is presented
in . However, in the intervening 7 years or so there has
been extensive research and progress in this area. Examples
of segmentation results are illustrated in Fig. 1.
1) 2D endocardial border detection: The most popular
approach has been to treat echocardiographic endocardial
segmentation as a contour ﬁnding approach. This is not
straightforward as the contrast around the border of the left
ventricle chamber varies depending on the relative orientation
of the border to the transducer direction, and attenuation.
Thus conventional intensity gradient-based methods have had
limited success on typical clinical images.
Mishra et al. proposed an active contour solution where
the optimization was performed using a genetic algorithm. In
a ﬁrst image, low pass ﬁltering and morphological operations
were used to deﬁne an initial estimate of the contour. A
nonlinear mapping of the intensity gradient was used in the
energy functional which is minimized. The ﬁnal contour was
used to initialize contour ﬁnding in the next time frame.
The convergence of the method was compared to solving
the active contour using the conventional constrained quasi-
Newton method. Manual delineations were done on 20 frames
by 2 experts and the average compared to the automated algorithm to show that the inter-variability between experts was
similar to the difference between the manual and automated
methods. The area correlation was found to be 0.92. This was
a preliminary evaluation from which strong conclusions cannot
Mignotte and Meunier chose to use a statistical external
energy in a discrete active contour for the segmentation of
short axis parasternal images, arguing that this was well-suited
in ultrasound images with signiﬁcant noise and missing boundaries. To this end, a shifted Rayleigh distribution was used
to model gray levels statistics. The multiscale optimization
strategy of Heitz et al. was adapted to perform the energy
minimization. The same optimization strategy was used for
a maximum-likelihood (ML) region segmentation to extract
a crude endocardial initial contour for the snake algorithm.
Several segmentation results were shown and qualitatively
good results were obtained.
1ejection fraction = end-diastolic volume −end-systolic volume
end-diastolic volume
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 25, NO. 8, AUGUST 2006
Mignotte et al. proposed a boundary estimation algorithm, posed in a Bayesian framework where the prior
information was modeled using deformable templates. This
was a fully automatic unsupervised (i.e no learning) approach.
The estimation problem was formulated as a maximum a
posteriori (MAP) optimization solved by means of a Genetic
Algorithm. As in their previous work, , the likelihood
term relied on a shifted Rayleigh statistical model of the gray
levels distribution. The template was deﬁned by a circle along
with a set of admissible afﬁne global, non-afﬁne global and
local transformations. Illustrative results on simulated data and
on a series of short axis images (50 frames) were shown. A
comparison to manual delineations by two experts was also
presented. The region-based segmentation method of Boukerroui et al. follows a similar (Bayesian) methodological
Level sets are often considered as an alternative to active contours and this approach has also been considered
for echocardiographic image segmentation. Yan et al. 
considered applying the level set method to echocardiographic
images using an adaptation of the fast marching method. To
reduce errors attributed to using local feature (intensity gradient) measurements, they used an average intensity gradientbased measure in the speed term. The method was applied to a
parasternal short axis and an apical 4-chamber view sequence
but the results were only discussed qualitatively. The latter
example highlighted problems in using a purely edge-based
level set method. Lin et al. presented an interesting variant
of the level set segmentation idea which combines edge and
region information in a level set approach across spatial scales
(a pyramid). This method assumes that a boundary is a closed
curve. It was applied to rotational 3D echocardiography data
although the segmentation method was applied to individual
2D slices. On 24 apical images, 3 experts manually delineated
the borders of the left ventricle. Using the mean average
difference between contours as the metric they showed that
the automatic method was within the variability of the manual
delineations. Their method was said to work well when the
quality of data was reasonably good but the method depends
on being able to extract a contour at a high pyramid level.
Extending their previous work on using prior shapes in
a variational framework , Chen et al. , used
prior shape and intensity proﬁles to constrain the evolution
of a geometric active contour. The problem was formulated
as a coupled optimization problem where the prior intensity
proﬁles were used to assist the estimation of the balance
between the image information and the shape priors. The
intensity proﬁles were model free as they were based on the
maximization of a mutual information based criterion. Illustrative results were presented on long axis echocardiographic
Klinger et al. presented a fairly classic approach to segmenting short-axis echocardiographic images using techniques
based on mathematical morphology . Data was time averaged (N = 10) to give a time-averaged cycle with reduced
noise and then a series of morphological operators applied
to identify the left ventricle cavity from which the border
of the cavity could be found. This was tested on 7 canine
datasets where ischaemia had been induced in the animals to
change heart motion. The area and shape correlation between
the algorithm and an observer had r > 0.93. This is a relatively
early paper and highlights issues at this time in terms of
obtaining data (even on animals) of good enough quality to
perform automated analysis.
Segmentation of the left ventricle can also be considered a
region-based or pixel-classiﬁcation problem. In this case the
goal is to label pixels as either belonging to the blood pool or
myocardium.
Boukerroui et al. , working in a Bayesian framework,
presented a robust adaptive region segmentation. The adaptive
property considers local class mean with a slow spatial variation, to compensate for the non-uniformity of ultrasound echo
signals within the same tissue. The authors also used a multiple resolution implementation, as suggested by Ashton and
Parker , to justify the Gaussian probability density function
(pdf) approximation at the lower resolution. The method was
evaluated against manual delineation by an observer on a
long-axis sequence and compared with another region-based
segmentation method due to Xiao et al. . Qualitative results
were also shown on breast ultrasound data.
Artiﬁcial neural network (ANN) based methods have been
used for region-based segmentation , . For instance,
Binder et al. employed a 2-layer backpropagation network
that was trained by manually identifying 369 sample regions
(7 × 7 pixels) from 8 training images to segment the image
as tissue (n = 279) or blood pool (n = 90). Parameters (gray
level mean and variance, contrast, entropy and homogeneity
from the co-occurrence matrices) were used in the ANN.
Endocardial borders were found by ﬁrst performing a radial
search for candidate border points in single frames and then
using a spatio-temporal contour linking step. The method was
applied to end-diastolic and end-systolic parasternal short axis
(SAX) images from 38 patients with the data being of variable
quality (12 good, 13 moderate and 13 poor). This is one of
the few studies that has explicitly looked at data of varying
quality. Segmentation was successful in 34 of the 38 datasets.
The automated method was compared with manual tracing
by 2 experts. The ANN showed good correlation (r = 0.99)
but from Bland-Altman analysis tended to overestimate the
cavity areas. Technetium radionuclide ventriculography (Tc-
RNV) was performed on 12 patients to enable the ejection
fraction to be compared. The automated system showed a
correlation of r = 0.93 with Bland-Altman analysis showing
that the ANN overestimated the ejection fraction. Over all the
analyses, the best correlations were with the best data.
2) Spatio-temporal methods (2D + Time): It is natural
to view echocardiographic segmentation as a spatio-temporal
problem, since the object of interest moves (in a non-rigid
way) and speckle decorrelates over the sequence. Spatiotemporal analysis potentially leads to better localization of
a border, and gives a local estimate of image velocity as a
side product of the segmentation. For instance, Friedland et
al. modeled the temporal continuity by means of a Markov
Random Field (MRF). This is, to our knowledge, pioneering
work that deﬁned boundary detection as a minimization of an
energy function with a Markovian spatio-temporal regulariza-
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 25, NO. 8, AUGUST 2006
tion. Polar coordinates were used for the contour deﬁnition
and the Simulated Annealing (SA) algorithm was used for
the optimization. Herlin and Ayache used a spatiotemporal version of the Deriche edge detector in a method for
tracking cardiac boundaries but their approach was not fully
developed or validated in clinical practice. Mulet-Parada and
Noble proposed a local-phase-based approach to spatiotemporal endocardial border detection. They argue that local
phase is a better basis for ultrasound-based feature detection
and segmentation because local phase is theoretically invariant to intensity magnitude. They proposed using a derived
measure from phase, called feature asymmetry for detecting
the endocardium in a spatio-temporal space (2D+T). They
used the output of this feature detector (location, velocity
and conﬁdence in measurement) as the feature vector in a
motion tracking algorithm that was validated against manual
delineations by a cardiologist. Local-phase has since been used
in preference to intensity gradient for feature detection in a
number of echocardiography studies – .
A number of authors have used variations of the active
contour concept to segment and track left ventricle boundaries.
Chalana et al. developed a multiple active contour method
to detect both the endocardium and epicardium in shortaxis views . They deﬁned the left ventricle by an active
surface model, which they reparameterized to show that the
surface could be represented by two planar curves representing
the endocardial and epicardial borders. They used the image
intensity gradient as the attracting force and invoked temporal
continuity via an external energy term that constrained the
motion between consecutive frames. Their method was validated on 44 clinical datasets against manual delineations by 4
experts. The area correlation coefﬁcient between their method
and the average manual outline was 0.95 for the epicardium
and 0.91 for the endocardium. They reported that the computer
algorithm gives a lower boundary difference error for the
epicardium than the endocardium. This may be due to the fact
that their algorithm was initialized with a manual delineation
of the epicardium.
Kucera et al. presented an example of applying 3D active contours to 2D+T echocardiographic data using a regionbased external force. This is a relatively early work that used
region information in a contour based segmentation approach.
It can be compared to more recent level set based segmentation
methods such as , .
Mikic et al. proposed an active contour approach where
propagation of a ﬁtted contour from one frame to another
was guided by optical ﬂow estimates provided by the
method of Singh and Allen (See also ). This can be
viewed as providing knowledge to guide the initialization of
an active contour optimization. The image force in the active
contour was deﬁned in terms of a Gaussian smoothed intensity
gradient. Parameters in the active contour were determined
empirically. The method was evaluated on 8 image sequences
(3 short axis, 3 long-axis and two aortic root) and compared
with 3-5 manual delineations. For endocardial border segmentation, the area correlation coefﬁcient between their method
and the average area was 0.99, 0.95 and 0.99 for three short
axis sequences and the distance between the active contour
and manual outlines was 1.15, 1.29 and 2.07 mm respectively
(see Fig. 1(a) for an example result taken from their paper).
Setarehdan et al. developed a fuzzy multi-scale edge detection (FMED) method for endocardial and epicardial border
detection that uses a wavelet transform to deﬁne the
various levels of resolution of image content. In this work
an edge was deﬁned as a point with maximal membership
of the edge fuzzy set. Temporal information was included in
edge detection by deﬁning a moving edge fuzzy membership
function as well as an edge fuzzy membership function. The
combined edge and motion membership function was then
maximized to deﬁne edge points. This method was applied
to SAX images where a radial-search-based strategy was used
and the edge detection applied in 1D along rays from an automatically found center with some pre-processing restricting
the search for the endocardial and endocardial borders. The
method was evaluated on simulated data and 14 datasets from
healthy subjects compared to delineations by a single expert.
The correlation between the areas deﬁned by the algorithm
and the expert for the endocardial border was 0.96 and for the
epicardial border was 0.95. The rms radial (sampled) distance
between the algorithm and expert deﬁned boundaries was
found to be 1.84 mm (epicardium) and 3.5 mm (endocardium).
Dias and Leit˜ao , proposed an algorithm for the joint
endocardial and epicardial border estimation following the
earlier work of Friedland and Adam and Figueiredo and
Leit˜ao . As in , polar coordinates were used
for the contour representation. However to our knowledge,
this is the ﬁrst approach which takes into account speckle
statistics in boundary optimization. The estimation problem
was modeled in a Bayesian framework as a MAP estimation
problem with Rayleigh statistics for the data term and a spatiotemporal MRF for the regularization term. An iterative multigrid dynamic programming algorithm was used to solve the
optimization problem. Results are given on simulated data
and on one short axis sequence (half of a cardiac cycle).
See Fig. 1(a) for an example result taken from their paper.
Recently Figueiredo et al. , within the same framework,
presented an unsupervised parametric contour segmentation
based on B-spline representations. A Minimum Description
Length (MDL) criterion was used to estimate the number of
B-spline knots. In contrast to , where careful parameter
tuning of the prior terms was required, this leads to an
approach less dependent on parameter settings as the tradeoff between smoothness/robustness is optimal in the sense of
MDL. Illustrative segmentation examples on a number of medical applications, including cardiac short-axis and intravascular
ultrasound images were shown.
Jacob et al. – developed a Kalman-ﬁlter based endocardial and epicardial border tracking method based on the
dynamic contour tracking approach of Blake and Isard . In
this approach a spatio-temporal contour model is constructed
which has two parts; a shape-model constructed from manual
delineations of the LV borders of a training set; and a motion
model. An image measurement model is also deﬁned (for
instance in a 1D local-phase based feature detector is used
for endocardial border detection, and in a wavelet-based
method is used for epicardial border detection). A Kalman
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 25, NO. 8, AUGUST 2006
ﬁlter strategy is then used to combine the contour model with
the image measurements. The approach was evaluated in a
small case study on stress echocardiography data (4 datasets:
one 4C and three 2C) and the performance of the tracking and
interpretation compared with manual border delineations using
6 quantitative geometric measures . The area correlation
coefﬁcient was found to be 0.98 (n = 27). Bland-Altman
analysis on endocardial/epicardial areas showed that endocardial border estimation was more accurate than epicardial
border detection although the authors comment that strong
conclusions can not be drawn from this as manual delineation
is difﬁcult to do. In Jacob et al. attempt to perform
an evaluation against clinical scoring of border motion and
myocardial thickening by cardiologists (n = 4 stress datasets
(as used in , 2 clinical observers)). This is one of the few
papers that has considered stress-echocardiography data, but as
noted by the authors, only a limited number of datasets were
analyzed, and the data quality, though typical of that seen in
clinical practice was quite low.
Bosch et al. used an adaption of the Active Appearance
Model (AAM) approach that they called the active appearance
motion model (AAMM) to represent the shape and appearance
of the endocardium as well as its motion (see Fig. 1(c) for
an example result taken from their paper). An important step
in their method was nonlinear intensity normalization. Their
method was tested on 129 4-chamber datasets (n = 65 for
training, n = 64 for testing). An expert traced the borders
of the images. Manual delineations were compared with the
algorithm contours with an average distance error of 3.3 mm
comparable with inter/intra observer variability for 97% of the
Mitchell et al. developed a 3-D AAM for segmenting
2D+T 4-chamber echocardiography data (2D sequences with
the third dimension time). The approach is spatio-temporal
i.e. adjusts itself in space and time. The model was learned
from manually segmented examples in a training stage. The
method was evaluated on the same data as used in .
The method was deemed successful in 57 of the 64 datasets.
The endocardial average distance error was 3.9 mm which is
slightly worse than the method of Bosch et al. which they
explain as being due in part to the extra degree of freedom but
also to the fact that the 3-D method did not employ intensity
normalization.
3) 3D and 4D endocardial border detection: In relatively
early work on 3D endocardial border detection, Coppini et
al. considered segmentation and reconstruction of the
left ventricle from freehand ultrasound data where data was
acquired at 4 ﬁxed angles with respect to the 4-chamber view.
Boundaries were found in each 2D slice as the zero-crossings
of a Laplacian of a Gaussian edge operator. Edge points were
then linked to form contours. A neural network was then used
to classify edge segments as part of a boundary or not (training
was done on data from 4 subjects, with testing on 3 others).
An elastic surface model was then ﬁt to the edges. Preliminary
assessment of the different processing stages was given.
Song et al. treated the segmentation problem as a surface
ﬁtting problem posed in a Bayesian framework where the
goal was to ﬁnd a 3D surface which has the greatest posterior probability given the images . They argued that
by omitting an explicit feature detection step their method is
less sensitive to low-quality images. They tested their method
using 45 data sets from normal and diseased hearts; 20 of
the datasets were used to train the model (determine pixel
appearance and pixel class prediction models). The average
epicardial and endocardial surface projection distance errors
for end-diastolic frames were found to be 3.2 mm and 2.6 mm
respectively. This is interesting but preliminary work that to
our knowledge has not be pursued further.
Wolf et al. described a semi-automatic method of
segmentation called the restricted optimal path exploring
segmentation (ROPES) approach which was applied to 2D
slices of 3D transesophaegal echocardiography (TEE) data.
It is based on the idea of ﬁrst ﬁnding candidate edge points
which satisfy a multiscale criterion and minimizing a cost
function which forms line segments and then closed contours.
Comparison is made with manual delineations where a mean
distance in-plane error of 3.44 mm was reported (c.f. 2.92 mm
interobserver distance).
Angelini et al. considered segmentation of real-time 3D
echocardiography data from a Volumetrics system. First, the
3D+T data was pre-processed with a wavelet analysis (using
brushlets) to reduce speckle. Then a 2D balloon deformable
model, using an intensity gradient based force, was ﬁtted to
each slice and the volume derived from this. The method
was tested on 6 clinical datasets with comparison made with
MR manual segmentation on end-diastole and end-systole
frames. They referenced a paper by Takuma et al. which
claims an inter-observer variability of 8.3% and intra-observer
variability of 3.7% for volume estimation with disk summation
on real-time 3D (RT3D) echocardiography data. Their method
shows an 8.9% error compared to manual delineation on MR
data whereas manual delineation on RT3D versus manual
delineation on MR showed a much higher average value. This
paper, as with our own experience, shows that one has to
take care in using manual delineation on ultrasound data as a
reference.
Montagnat et al. developed a 3D+T model-based segmentation method for rotational 3D echocardiography. This
work is most interesting for its use of a cylindrical geometry for analysis, and using a combined edge and regionbased approach. 4D anisotropic diffusion ﬁltering was ﬁrst
applied to the data to reduce speckle (no distinction was
made between temporal and spatial dimensions). This method
assumes boundaries are located at high intensity gradients
and the parameter in the diffusion process is a function of
the intensity gradient magnitude. Thus this work does not
explicitly account for imaging physics. Then a deformable
model (discrete simplex mesh) is ﬁt to the ﬁltered data where
the external forces are provided by a 3D gradient operator
deﬁned in cylindrical co-ordinates (the 3D equivalent of the
work of Herlin and Ayache ). Speciﬁcally the intensity
gradient magnitude and orientation are used, together with
a region-based force based on a local analysis of intensity
values. Here it is perhaps surprising that the anisotropic
diffusion was also not done in the natural frame of reference
of acquisition. Qualitative results are presented.
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 25, NO. 8, AUGUST 2006
Although strictly speaking ﬁltering methods, the next 2
papers are theoretically elegant approaches which have shown
promising early results as ultrasound segmentation methods.
The solutions are posed in a variational framework and have
properties that make them well-suited to 3D echocardiography
segmentation. Sarti et al. developed a model for multiple scale analysis of space-time echocardiographic sequences
based on solving a nonlinear partial differential equation
combining ideas of the Perona-Malik anisotropic diffusion
model with the Galilean invariant movie multiscale analysis
of Guichard , . Coherent spatio-temporal structures
are preserved by the ﬁltering operation. Their method was
applied to a single example of rotational 3D echocardiographic
data. In an extension , the Perona-Malik spatial diffusion
was replaced with a curvature driven level-sets non-linear
anisotropic smoothing . That model was invariant under
gray value transformations and, unlike previous curvature evolution models, it well-preserved edges and corners on level-sets
while still allowing tangential smoothing along edges. In later
work, Mikula et al. presented a truly coupled spatio-temporal
anisotropic diffusion . In that work time smoothing was
curvature driven, and the authors argue, resulted in better
smoothing with velocity discontinuity preservation in contrast
to the previous acceleration based smoothing. Note that, in
contrast to the 4D diffusion model used in , the models
of , , treat the temporal dimension explicitly as time
rather than treating space and time as equivalent dimensions.
Corsi et al. presented a level set based segmentation
approach which was applied to real-time 3D echocardiography
from a Volumetrics system. The classical inﬂationary term in
the speed function was removed in order the avoid leakage.
Hence, close initialization of the level set function was required. Three parameters also had to be chosen. The level
set was initialized using manual delineation on a few (short
axis) frames. The method was tested in vitro (on balloons
of various volumes n = 18) with a correlation coefﬁcient
of r = 0.99 and an underestimation of the true volume. On
clinical data (n = 20) a correlation of r = 0.97 was found
when a comparison was made with MR volumes treated as
the reference. A −15.58 ml bias was observed in this case
(underestimation by level set method).
Sarti et al. presented a level set segmentation algorithm – the
subjective surfaces , – for images, such as ultrasound
images, which can have missing boundaries. Their approach
differs fundamentally from previous level-set segmentation
algorithms which concern only the zero level set. In this
work, all the level sets, hence the surface, evolve under a
suitably chosen speed function. The ﬂow sharpens the surface
around the edges and connects segmented boundaries across
the missing information. This work was further extended by
Mikula et al. and Corsaro et al. . An efﬁcient and
robust semi-implicit complementary volume numerical scheme
was proposed in order to solve the Riemannian mean curvature
ﬂow equation in 2D and 3D . Segmentation examples
of the classical Kanizsa triangle were shown to demonstrate
that the method can accommodate missing boundaries. Examples on 3D cardiac and fetal ultrasound images were
also shown.
Examples breast ultrasound from Madabhushi and Metaxas
 . From left to right: Original image, contrast-enhanced version,
detected boundary points and the output of deformable model.
4) Segmentation of the myocardium and epicardium:
Finally there is a very limited literature explicitly looking
at segmentation and analysis of the myocardium and
epicardial border detection , , . These are both
challenging to do from native B-mode images. There is also
very little literature speciﬁcally focussed on getting methods
to work on general clinical data rather than data from subjects
with a good acoustic window i.e. which give good images.
We have highlighted some of the few works that have done
so above , , . One further exception is the work
of Boukerroui et al. which considers how to enhance Bmode images to reduce the affect of attenuation and enhance
features. Although that method was shown quantitatively to
reduce attenuation, enhance features and not introduce artefacts after enhancement, that approach has not to-date been
fully tested in clinical practice.
B. Breast cancer
Ultrasound imaging of the breast is typically done as an
adjunct to physical examination and (X-ray) mammography
when breast cancer is suspected . Conventional B-mode
ultrasound does not detect microcalciﬁcations as well as Xray mammography (a key indicator of cancer) but is used
to help distinguish benign masses (cysts and ﬁboradenomas)
from malignant cancerous masses. There have been a number
of clinical studies that have looked at assessing how well
masses can be characterized from a single image by human
observers in terms of visually perceived texture and geometric
properties – . This has motivated researchers to look
at automating the detection and the characterization of imagederived diagnostic indicators of breast cancer (computer-aided
diagnosis or CAD) either from a static image frame or image
sequences. Thus the principal segmentation challenges pertain
to characterizing the textured appearance and geometry of a
cancer relative to normal tissue, and accommodating artefacts
such as the possibly strong attenuation across an image and
shadowing as well as the ‘fuzziness’ of cancerous mass boundaries which makes border delineation difﬁcult. Importantly, as
we see below, the studies of Stavos et al. – have greatly
inﬂuenced the design of algorithms for breast mass detection.
Interestingly, no signiﬁcant work has looked at the screening
case, i.e. most work has assumed the presence of a, typically
single, suspicious mass.
Horsch et al. presented a method involving thresholding
a pre-processed image that has enhanced mass structures.
Comparison is made of a partially automatic and fully au-
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 25, NO. 8, AUGUST 2006
tomatic version of the method with manual delineation on
400 cases/757 images (124 “complex” cysts, 182 benign
masses, 94 malignant masses). They compute four imagebased features (shape, echogeneity, margin and posterior
acoustic behavior) deﬁned respectively in terms of the depthto-width ratio, autocorrelation, “normalized radial gradient”,
and comparison of gray levels, to test their effectiveness at
distinguishing malignant and benign masses. This method was
further evaluated in , to assess the advantages of
different features using linear discriminant analysis where the
best 2 features were found to be the depth-to-width ratio
(shape) and normalized radial gradient (margin). In later work
aimed at further automating the method Drukker et al. 
extended this work to include mass detection by proposing
to ﬁrst ﬁlter the images with a radial gradient index ﬁltering
technique. The method was tested on the same database as
in , . They showed that 75% of lesions were correctly
identiﬁed. See also Drukker et al. for further validation on a
second database .
Neural Network (NN) based methods have proved to be
popular in this area. These aim to make a classiﬁcation
decision based on a set of input features. For instance, Chen
et al. presented a NN approach where input features
were variance contrast, autocorrelation contrast, and the distribution distortion in the (Daubechies) wavelet coefﬁcients
and an multilayered perceptron neural (MLP) network with
one hidden layer was trained by error backpropagation. The
method was applied to a database of 242 cases (161 benign,
81 carcinoma) giving a sensitivity of 98.77% and speciﬁcity
of 81.77%. They strongly argued that image texture was an
important component that made their method successful.
Huang and Chen proposed an approach that integrates the advantages of NN classiﬁcation and a watershedsegmentation methods to extract contours of a breast tumor
from US images. The main novelty of this work is in the
preprocessing step which helps effectively the watershed algorithm by means of a reasonably good selection of markers. The
authors proposed to use a self-organizing map (SOM) texturebased NN in order to select adaptively (ie locally) from a set
of nine predeﬁned ﬁlters the appropriate preprocessing ﬁler to
use. Their method was tested on a database of 60 images (21
benign, 39 carinomas), 40 used for training, 20 for testing.
Measures of contour difference and area difference between
the method and manual delineation were evaluated although
strong conclusions cannot be drawn from this evaluation.
The above methods treat the segmentation approach as
a general image processing problem i.e. do not take into
consideration that the image is an ultrasound image, and do
not explicitly consider speckle or imaging artefacts. There are
only a few examples of efforts that have attempted to use
domain knowledge in breast ultrasound image segmentation.
Xiao et al. presented an Expectation-Maximization
method that simultaneously estimates the attenuation ﬁeld
at the same time as classiﬁcation of regions into different
(intensity-based) regions. The number of regions (classes)
needs to be speciﬁed, which in the intended application is not
a strong limitation. That method was tested on experimental
data with different Time Gain Compensation (TGC) settings to
show that their approach gave consistent segmentations under
different TGC settings but has not undergone a large clinical
assessment. This method is compared to that of Boukerroui
Madabhushi and Metaxas combined intensity, texture
information and empirical domain knowledge used by radiologists with a deformable shape model in an attempt to limit
the effects of shadowing and false positives. (see Fig. 2 for an
example result taken from their paper). Their method requires
training but in the small database (N = 42). Using manual
delineation of the mass by a radiologist as a reference, and
the Hausdorff distance and average distance as boundary error
metrics, they showed that their method is independent of the
number of training samples, shows good reproducibility w.r.t.
parameters, and gives a True Positive area of 74.7%. They
also argued that it has automation advantages over the work
of Horsch et al. .
Although some of the previous methods can be applied
in 3D, the literature on 3D is less extensive. For instance,
Chen et al. , Chang et al. – and Sahiner et
al. take a deformable active contour approach. Chang et
al. applied a 3D version of the “sticks algorithm” to
reduce speckle noise, followed by 3D morphological ﬁltering
(opening and closing, but details not given) as pre-processing
steps. Then they applied an active contour which uses intensity
and intensity variance information. The method was tested
on 8 tumors (4 benign, 4 malignant) with volume estimates
compared with estimates by manual delineations. Using the
match rate as a performance metric, the average match rate
was about 95%.
Sahiner et al. compared 2D and 3D intensity-gradient
active contour segmentation based methods, the active contour
initialized by hand, and with algorithm parameters determined
empirically. Having found the segmentation solution, depthto-width ratio, a posterior shadowing feature measure, and
72 texture features based on co-occurrence matrix analysis
were computed around the boundary for each 2D slice and
linear discriminant analysis used to classify volumes. Four
radiologists graded the volumes in terms of perceived malignancy on a scale 1 −10. They showed that the radiologist
and computer-based methods were not statistically different
in classiﬁcation (Az = 0.92 versus Az = 0.87 average for
radiologists). However they did not look at the accuracy of
segmentation in depth and recognized that this was an area of
possible improvement.
B-mode ultrasound imaging can also be used to guide, in
real-time, a needle to a mass in biopsies and there has been
a few recent papers describing work aimed at automatically
tracking the needle during this procedure to localize the
position of the mass. The task here is one of contour detection.
Ding and Fenster, for instance, assume that the needle is
straight and develop an algorithm for needle detection based
on the Hough transform .
C. Prostate
Prostate cancer is the most commonly diagnosed cancer in
adult and ageing men. Early detection and early intervention
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 25, NO. 8, AUGUST 2006
Segmentation example of transverse US images of the prostate from
Gong et al. ; The solid contours are the ground truth established
by averaging ﬁve experts manual outlinings and the dotted contour are the
computer generated boundaries.
of progressive prostate cancer may help to reduce death rate.
Transrectal ultrasound (TRUS) imaging has long been an
essential tool for prostate cancer diagnosis. In fact, the combination of prostate speciﬁc antigen (PSA) testing with TRUS
and digital rectal examination (DRE) has been responsible
for diagnosing most prostate cancers in the United States
each year. Prostate volumes and boundaries play an important
role in diagnosis, treatment and follow-up of prostate cancer
(see, for example ). In general, prostate boundaries are
routinely outlined in transverse parallel 2D slices along the
length of the prostate. This has led to the development of a
number of methods for (semi-) automatic detection of prostate
boundaries 2. An example of prostate segmentation from Gong
et al. is shown in Fig. 3.
Classical techniques have been proposed for prostate segmentation; derivative edge detection was used in , and,
non-linear ﬁltering (minimum/maximum ﬁlter) was proposed
in – . Both supervised classiﬁcation methods such as
methods based on Neural Networks and unsupervised
pixel classiﬁers, for instance using Laws texture features
in a probabilistic framework have also been proposed.
These methods do not use shape modeling and knowledge of
ultrasound physics and have undergone limited validation.
Recent work has focused on incorporating prior information about shape and speckle models. For instance, Knoll et
al. proposed employing a parametrization of a snake
based on a 1D dyadic wavelet transform as a multiscale
boundary curve analysis tool. The initialization of the snake
used template matching between contour models of a training
set and signiﬁcant image edges. The authors used a 1D wavelet
based method in order to constrain the shape of the snake
to evolve towards predeﬁned models. The contour deformation method was integrated in a coarse-to-ﬁne segmentation
framework based on multiscale image edges represented by
the modulus maxima of the 2D dyadic wavelet transform.
The fully automatic method was tested on 77 images from 11
patients against two experts. The analysis showed that shape
information slightly improves results. However, no statistical
analysis (of signiﬁcance nor variance) was shown for the error
comparison against the inter-observer variability.
Ghanei et al. designed a 3D discrete deformable model
to semi-automatically outline the prostate boundaries. Good
segmentation results were obtained, in comparison to manual
2Shao et al. presented a review on prostate boundary detection for
articles before 2002. Our review overlaps with this on but also discusses
more recent contributions.
contours obtained slice-by-slice, subject to close initialization
of the surface to the true boundaries.
A 2D semi-automatic discrete dynamic contour (DDC)
model for prostate boundary segmentation was proposed
by Ladak et al. based on the Lobregt and Viergever
model . The same team extended their work to 3D images
in Hu et al. . The underlying model is similar to that in
Ghanei et al. . The former used 4 (for 2D, 6 for 3D)
manually selected points on speciﬁc locations of the prostate
boundary and then applied an appropriate interpolation to
complete the initial model. The latter used a few initial contours that were drawn on different slices. The speciﬁed points
were generally clamped during the deformation of the DDC
which uses some directional information (based on the fact
that prostate tissue appears darker than the non prostate tissues
in ultrasound). An editing tool was also provided to semiautomatically correct the segmentation results by specifying
more boundary points and then running the DDC algorithm
again. The accuracy of the 2D and 3D algorithm were assessed
using global and local measures, however against only one
expert radiologist. 117 images of 19 patients were used for
the 2D algorithm and 6 patients with an average of 24 slices,
acquired using a rotational probe to form a 3D data set, were
used for the 3D algorithm. The analysis showed that the semiautomatic segmentation was in agreement with the manual
one except where the prostate boundaries were missing. Some
other interesting conclusions can be drawn from this work.
For example 13% of cases were difﬁcult to assess and the 3D
algorithm performed better that the 2D one especially at the
lateral margins of the prostate. Recently, Chiu et al. ,
presented a variant of Ladak et al.’s algorithm where the
intensity gradient, used in the external energy force of the
DDC model, was estimated using the dyadic spline wavelet
transform.
Pathak et al. used the Sticks algorithm followed
by anisotropic edge-preserving smoothing based on the weakmembrane algorithm for semi-automatic boundary detection.
A Canny edge detector was then used to construct an edge map
rather than edges detected by the weak-membrane algorithm.
This enabled prior knowledge-based ﬁltering of the edge map
to be used to detect only the relevant edges. The method
was semi-automatic as user interaction was employed in the
edge-linking stage. The experiments on 125 images from 16
patients with the help of ﬁve expert observers showed an
increase of consistency in prostate delineation when automatically detected edges were used as a visual guide during the
manual outlining process. In order to restrict user interaction,
a deformable superellipse was employed as a parametric shape
model for the prostate in a later work . Superellipses are,
on the one hand, attractive as only 2 pose parameters and
4 shape parameters need to be estimated, and on the other,
as acknowledged by the authors, very restrictive as they can
only model symmetric shapes. Apparently this restriction was
not a draw back for prostate segmentation as the ﬁtting error
was less than the inter-observer variability. The authors chose
a Bayesian framework to solve the ﬁtting problem and used
their previous work to estimate the edge likelihood and a
training data set to estimate the prior distributions parameters
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 25, NO. 8, AUGUST 2006
of the superellipes shape parameters. The segmentation algorithm was semi-automatic as the user had to specify more than
two points to give an approximate scale of the prostate. The
algorithm was tested and analyzed under the same conditions
as in using the measures deﬁned in . The mean
distance between the computer-generated boundaries and the
average of the ﬁve manual outlines was signiﬁcantly smaller
than the average of the inter-observer variability. (see Fig.3
for an example result).
Shen et al. proposed a statistical shape model for automatic 2D prostate boundaries detection. Their model takes into
account the nature of TRUS images by considering the probe
position in the shape normalization step and by making the
image features descriptors invariant to probe rotation. Gabor
ﬁlters at different orientations and scales were used for the data
ﬁdelity term and afﬁne invariant features, which capture the
prostate shape in a hierarchical fashion, were employed for the
model term. The work presents several original contributions
mainly in modeling the prior geometry of the prostate in the
TRUS images. Modeling of the prostate boundaries by means
of Gabor ﬁlters might be improved by taking into account
the quadrature property of Gabor ﬁlters (see eg. and
references therein). Their method was evaluated on 8 images.
This is a preliminary evaluation from which strong conclusions
cannot be drawn3. The authors extended their work to segment
3D data in , and interestingly, they used a kernel support
vector machine (KSVM) to estimate a probability density
function of prostate tissue voxels based on the Gabor features.
Unfortunately, the modiﬁcation did not decrease the processing
time. Recently, the authors proposed an efﬁcient variant of
their previous work by using Zernike Moment based edge
detection at the coarse resolutions and kept the SVM modeling
only for the ﬁnest resolution. They also decreased the number
of support vectors without a loss of accuracy . The new
algorithm ran 10 times faster. Shen et al. also worked
on a 3D statistical atlas of the spatial distribution of cancer for
optimized prostate biopsy. One hundred prostate histological
samples were used in the atlas construction. A 99% biopsy
success rate was achieved using seven needles.
Abolmaesumi and Sirouspour developed a 2D boundary extraction method based on a probabilistic data association ﬁlter. They posed the 2D segmentation problem as an
estimation of a moving object along the cavity boundary,
where the motion is governed by a ﬁnite set of dynamical
models subject to uncertainty. Hence, the motion model along
the contour models the prior smoothness of the contour.
Angular discretisation of the contour from a manually selected
seed point inside the cavity was used to estimate the radial
distance of the boundary points to the seed point. In order
to increase robustness to noise and accuracy they combined
multiple trajectory models, with different data noise levels
and trajectory smoothness/dynamics. They used a probabilistic
3The prostate shape model was constructed using 10 manually segmented
images. To our knowledge, this small sample is unlikely to representatively
characterize the shape variability of the prostate. Indeed, an equivalent
approach was used by Wu et al. ; in which the modeling on 27 sample
boundaries produced 9 principal variations of the boundary (see for a
review of and for an alternative shape model).
data association ﬁlter (PDAF) for boundary extraction and
the interacting multiple model estimator (IMM) for model
combination 4. The boundary extraction was performed recursively using a modiﬁed Kalman ﬁlter with an approximately
constant angular velocity model and where the candidate edge
points were estimated using a 1D derivative operator along
each radial direction. A mathematical analysis of the PDAF
ﬁlter with respect to the process and noise parameters was
provided to help model selection based on the noise level in
the image and the shape of the object boundary. Segmentation
examples on several ultrasound applications (heart, breast,
prostate) demonstrated the potential of this approach. Some
limitations and open issues were highlighted mainly due
to the angular discretisation and implicitly, the performance
sensitivity to the choice of the seed point. The algorithm
was fast and could be implemented in real time. However,
the 3D extension of the approach is not obvious. The model
combination is particularly interesting. It can be viewed as an
adaptive regularization of the boundaries because the models
have different noise/smoothness tradeoffs. The IMM selects
the dominant model where there is a disagreement and takes
some kind of an average solution where the models agree.
However, the selection of the edge candidates is based on
intensity gradient and hence ignores the nature of the data.
This was improved in by using the Sticks algorithm 
for edge enhancement as a pre-processing step before applying
the PDAF/IMM algorithm.
Yu et al. presented a two-step semi-automatic activecontour based segmentation method. First, an initial elliptical approximation of the contour was obtained using two
manually selected points. A rough binary segmentation was
then obtained by optimizing an area-weighted mean-difference
criterion in a level sets framework. Finally, a ﬁner segmentation was accomplished via a parametric active contour model
in a polar coordinate system (see also for a polar
coordinate active contour). In the second stage, a Speckle
Reducing Anisotropic Diffusion, (SRAD ), was applied
to enhance the images and the instantaneous coefﬁcient of
variation (ICOV) was utilized as an edge cue in the derivation
of the external energy of the active contour model. Note
that log-compressed B-scan images have to be decompressed
before applying the SRAD algorithm. It is reported in ,
 that the ICOV allows for balanced and well-localized
edge strength measurements in bright as well as in dark regions
of speckle images. In summary, the ﬁrst stage of the segmentation algorithm uses global image statistics and the second
one uses local image features to reﬁne the segmentation. It
is unclear why the authors used 2 steps since both energy
functions could be minimized in the level sets framework
(see eg. ). A preliminary evaluation of the approach was
presented on 27 selected images acquired from 6 patients.
Manual delineations were performed by 3 sonographers. Only
images with a ‘reasonable’ interobserver variability were used.
The computer generated boundaries agreed with the average
manual contours within 2 mm. 76% of the results fell within
4As acknowledged by the authors, the combination is not original in itself
as it is used previously for radar management and tracking. It is the framework
in which it is used (segmentation) that is original.
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 25, NO. 8, AUGUST 2006
Segmentation example of IVUS images (vascular disease); (a)
example taken form Klingensmith et al. showing the initial
contour and the ﬁnal borders; (b) two segmentation examples of the automatic
algorithm by Brusseau et al. .
one standard deviation of the manual contours.
D. Other Cancer Types
The previous two subsections have considered the two main
areas of application of ultrasound in diagnosis of cancer. As
ultrasound is increasingly used in the planning and treatment
of interventions and therapy it is worth mentioning that there
are a growing number of publications related to (non-breast
and prostate) cancer diagnosis and therapy. Recent papers
include those looking at ultrasound segmentation of the kidney
and gallbladder , – and the liver – .
E. IVUS (vascular disease)
IntraVascular UltraSound (IVUS) is increasingly used as
a complementary tool to contrast X-ray angiography. It is
a real-time, high resolution and non-invasive imaging technique, which provides valuable anatomical information about
the coronary arterial wall and plaque. Recent developments,
include ECG-gated acquisition to overcome cyclic motion
artifacts and IVUS elastography which provides biomechanical
property estimates of vessel wall and artherosclerotic plaques,
that are helpful in diagnosis and in guiding interventional procedures , . Accurate segmentation of the lumen, the
plaque and the wall borders is a prerequisite for quantitative
analysis. Most, if not all, of the IVUS segmentation literature,
uses contour modeling and could be classiﬁed into one of 3
categories: edge driven , – , statistical –
 and high-level knowledge driven , . We review
some of the important papers in this section.
Sonka et al. presented a semi-automatic knowledgebased segmentation approach that identiﬁes the internal and
external lumina and the plaque-lumen boundaries. A novelty
of the approach was the attempt to incorporate knowledge to
mimic constraints used by an experienced ultrasonographer.
The method used dynamic programming to solve a cost
function based on edge strength and incorporated a priori
knowledge about cross-sectional arterial anatomy (such as object shape, edge direction, double echo pattern, wall thickness).
However, the method has several modeling limitations namely:
the edge strength did not include speckle statistics and some
prior information was included in a binary fashion with hard
thresholds. A similar model was used by Takagi et al. ,
and reported a similar performance. Their work differs from
the work of Sonka et al. mainly in the preprocessing step. An
adaptive spatio-temporal ﬁltering of speckle was performed
based on pre-segmentation of blood and tissue areas.
Subtraction of two consecutive IVUS images in time acquired at the same position can increase the signal-to-noise
ratio of the lumen area, i.e. obtain good contrast between
the lumen and other parts in the image. Bouma et al. 
compared several combinations of ﬁltering techniques (Gaussian, median, anisotropic diffusion) followed by lumen detection (thresholding, region-growing, discrete dynamic contour
(DDC) ). Experiments were carried out on 15 IVUS
images, obtained using an average of 20 subtracted images
all acquired at the same location. The evaluation against 4
experts showed that all the methods performed well on good
quality data and less well on difﬁcult cases. The automatic
DDC, preceded with a small scale median ﬁlter was found to
be the best alternative method to manual segmentation.
An extension of the DDC model has been proposed for 3D
semi-automatic segmentation of the lumen and adventitial borders in serial IVUS images . The same group presented
a faster method, the fast active surface (FAS) based on
Williams and Shah’s fast active contours (see Fig. 4(a) for an
example result). The former method is a force-acceleration
technique and the latter is a neighborhood-search method,
and both snakes used only intensity gradient information. An
editing tool was provided for user correction. In experiments,
both techniques performed well although the FAS was 60
times faster. The FAS method was further validated on 529
ECG-gated IVUS images against 4 observers using
the measures deﬁned in . Kovalski et al. used a
simpliﬁed 3D balloon model where the control points can
move only along the radial direction, and used polar coordinates to represent the contours which removes one degree
of freedom. The performance of the method was assessed on
88 images against two observers. The reported inter-observer
area variability was in the same range as in . However,
the computer to manual area variability was slightly higher
than the inter-observer one, for both the lumen and adventitial
borders. In contrast to the method in , the method of
Kovalski et al. was fully automatic.
The above methods use simple derivative operators to estimate intensity gradients. Recently Pardo et al. , proposed
a statistical deformable model that was applied to IVUS
images. They used a bank of Gaussian derivative ﬁlters, at
different orientations and scales, to locally describe edge/nonedge cues, in an adaptive fashion (i.e locally). The feature
space was reduced by linear discriminant analysis, and a
parametric classiﬁer was employed to guide the model deformation by minimizing the dissimilarity between measured
image features and the learned ones. The statistical learning
approach made the algorithm more robust in comparison to
using intensity gradient information, which supposes a prior
model of the edge 5.
A Bayesian level set approach was proposed for a semiautomatic segmentation of the lumen, intima and media borders using the shifted Rayleigh law as a model for the graylevel
statistics . This work is based on the previously published
Bayesian level set method of Sifakis et al. . Robustness
5The idea of statistical edge detection was originally proposed by Yuille;
See and the references therein, for a recent paper on this.
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 25, NO. 8, AUGUST 2006
to initialization was assessed, and a comparison made to an
intensity gradient level-set method, intensity gradient based
snakes and PDF-snakes using the same model as in .
Fifteen IVUS images were used, acquired at 20Mhz without
ECG-gating, and with 3 different initializations. The PDFsnakes were more stable on average. However the Fast-
Marching method had the smallest Hausdorff distance. As
expected the gradient-snake had the largest variability to
initialization as it does not model well the data. In a more
recent work , the same team proposed an automatic
variant of their previous work (automatic estimation of the
PDF region statistics parameters and the initial level set
contours). In the new algorithm, the speed function was based
on region statistics and gray level gradient information rather
than region statistics alone. The algorithm was tested on 600
IVUS frames acquired at 20MHz from a diseased superﬁcial
femoral artery and on a sequence of 86 simulated IVUS
images. The Hausdorff distances were below 0.066 mm for
the simulated data and below 0.344 mm for the in-vivo data
in comparison to one observer manual border delineation.
posteriori
probability
segmentation
Rayleigh distribution to model the data constraint and a 1D
Markov process to model the contour prior, was also used
in , . Both methods use polar coordinates, are
fully automatic and are related to previous work by Friedland
and Adam and Dias and Leit˜ao . Haas et al. 
considered multiple contours and modeled the sequence as
a ﬁrst-order Markov process to account for the temporal
continuity of the vessel walls. Brusseau et al. considered
only the segmentation of the luminal border (see Fig. 1(b)
for 2 results taken from their paper). However as the authors
showed, the luminal border does not always correspond to
the global maximum of the posterior pdf, nor to the ﬁrst
maximum, along radial direction. The algorithm ﬁrst detected
the ‘reliable’ points that are the ﬁrst or the global maximum
along the radial direction and then choose either the global
or the ﬁrst maximum depending on the contour prior energy.
Both methods were evaluated on several clinical cases against
two experts, and good correlation was obtained. Hansen et
al. presented a fully Bayesian analysis of space time
process of IVUS image based on deformable template models
and Markov Chain Monte Carlo (MCMC) simulation. Unfortunately they used a Gaussian model for both tissues and only
applied their method to one sequence. Gu´erault et al. 
presented a constrained maximum likelihood approach. The
originality of their work was not in the data term, which
uses a Rayleigh model, but in the modeling of the prior
information about the geometric deformations inherent in
IVUS images. Based on the hypothesis of a circular vessel,
they constrained the search space using a parametric model
of the contour which takes into account the catheter position
and its orientation. A stochastic minimization procedure was
utilized for the maximisation of the criterion.
Recently, two approaches have been published which aim
to incorporate high level knowledge in IVUS image segmentation. A machine learning approach mimicking the human
visual system was proposed for automatic detection of the
luminal and the medial-adventitial borders in . The
accuracy of the method was assessed on a reasonable data set.
Bovenkamp et al. , considered solving the segmentation
problem using a multi-agent knowledge approach. Its elaborate
high-level knowledge (450 rules) takes control over simple
low-level segmentation algorithm.
A major drawback of IVUS is its inability to consider the
vessel curvature and the orientation of the imaging catheter.
Hence, quantiﬁcations performed on these data are inevitably
distorted, since the vessel curvature remains unconsidered. Fusion between intravascular ultrasound and biplane angiography
provides a solution for correct 3D reconstruction of the IVUS
data (see eg. , ). This is out of the scope of this
review. Nevertheless, we comment that the research in this
ﬁeld uses angiography information only in the reconstruction
step of the 3D vessels. This is a valuable source of information
that could be used proﬁtably in the 3D segmentation step of
the IVUS images.
Finally, we note that some attention has also been given
to developing methods related to the diagnosis and treatment of vascular disease using a standard B-mode ultrasound transducer (ie. not IVUS), including work on segmentation of carotid vessels – and abdominal aortic
aneurysms .
F. Obstetrics and gynaecology
The non invasive nature of ultrasound is a strong argument
for its use in obstetrics and gynaecology. In obstetrics, segmentation provides valuable measurements in order to assess
the growth of the foetus and in diagnosis of fetal malformation.
Most analysis is based on 2D scans. Standard measurements
include the biparietal diameter, head circumference, length
of the fetal femur, the abdominal circumference and the
amniotic ﬂuid volume (see eg. , – ). There
is often a sharp contrast between the face of a foetus and
the surrounding amniotic ﬂuid, allowing automatic boundary
detection. Hence, obstetrics is a potential ﬁeld of application
for volume rendering and visualization (see eg. , ).
In gynaecology, most of reported segmentation algorithms
address ovarian follicle measurement and cyst detection and
measurement .
Muzzolini et al. used a split-and merge segmentation
approach to segment 2D US images of ovarian follicles. The
split and merge operations were controlled by means of a
simulated annealing algorithm (Metropolis). The authors used
a texture-based measure for block comparison in the splitting
and merging process which takes into account the block size.
In a later work, the same team proposed a robust texture
feature selection method based on outlier rejection to be used
in the segmentation algorithm .
A semi-automatic method for ovarian follicles segmentation was reported by Sarty et al. . The technique is a
knowledge based approach and is similar to earlier work of
the team . It simultaneously detects the inner and the
outer border of the follicle of interest, which was interactively
selected by deﬁning an angular region of interest. Both border
detections were based on the minimization of a cost function
using heuristic graph searching techniques. Polar coordinates
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 25, NO. 8, AUGUST 2006
were used and edges strength and direction were considered
in the cost function deﬁnition which incorporates some prior
knowledge. The outer wall was automatically detected after
the detection of the inner wall, for which frequent manual
correction were required. Measurements based upon the algorithm’s outer border correlated well with those based on a
human expert manual boundary tracing (31 US images were
used). A similar work was reported by Krivanek and Sonka
for follicle segmentation . An automatic approximation
of the inner follicles wall using watershed segmentation on
a smoothed image was ﬁrst performed. Then the knowledge
graph searching method was applied to detect both walls of
the follicle of interest.
Potoˇcnik and Zazula proposed a 3 step algorithm for automatic segmentation of follicles in 2D US images . The
ﬁrst step automatically detected seed points based on a combination of a watershed segmentation and several thresholding
operations on preﬁltered images. In the second step, accurate
boundary detection of the follicles was performed using a
region growing segmentation starting from the previously detected seed points. The pixel aggregation was controlled using
a criterion based on the mean gray level values and a weighted
gradient. The ﬁnal step was a recognition step which used
prior knowledge about the follicles in order to eliminate nonfollicle detected regions (shape, size, and localization within
an image). The authors extended this work to the segmentation
of a sequence of images . The new algorithm used the
detected objects in the previous frame in order to predict
the object in the next frame by means of a Kalman ﬁlter.
The algorithm was tested on 50 cases with a recognition rate
around 78% and a boundary accuracy around 1.1 mm (mean
error in comparison to manual boundary tracing). The results
are encouraging probably due mostly to the appropriate prior
knowledge used in the algorithm6.
Zimmer et al. made an interesting observation, showing that the local gray level entropy is a normal variable,
under the assumption that the local gray level pdf follows
a Gaussian, Rayleigh, Weibull or a Nakagami distribution.
This suggests that the local entropy may be successfully used
for region segmentation when its histogram shows multiple
distinct peaks. Indeed, the same team presented a bivariate
extension of an entropy-based thresholding method, the ‘minimum cross entropy thresholding’, in which the segmented
variable is replaced by a linear combination of the gray
level and the local entropy . The binary segmentation
algorithm was demonstrated on US images with ovarian cysts
in and was used in the segmentation step in a recent work
for quantitative analysis and malignancy detection of ovarian
masses . The demonstration of the normality of the local
entropy under more complete models, like the generalized Kdistribution, is still to be done (see Sec. IV-B).
All of the above methods operate in 2D which mimics
clinical practice. However, one is really looking at a threedimensional object, and the interest is to measure volume
rather than a linear dimension (Euclidean distance). Romeny
6However, the assumptions made by the authors to justify some parts are
in contradiction with each others (once they claimed a Gaussian model and
in other parts a Rayleigh model)!
et al. described a method for segmenting follicles from
3D ultrasound data which was fully automatic and consisted
of two steps (follicles centers detection followed by 1D
edge detection along radial rays generated from the follicle’s
center). The centers detection method was based on the socalled winding number of the intensity singularity 7. The edge
points along the 1D proﬁles were detected using a robust
multiscale zero-crossing of the second derivative. The lifetime of an edge pattern over scale was used as a measure of
its signiﬁcance.
Gooding et al. presented a level set based method for
segmenting sparse freehand ultrasound data of the ovary where
the speed function is a weighted sum of three terms; a surface
reconstruction term, a regularization term and an image term.
The image term was region-based and deﬁned in terms of
non-parametric probabilities of labeled regions. The method
required a good initialization. The method is more extensively
discussed in including a comparison of volume estimates
with aspirated volumes.
III. VALIDATION/QUANTITATIVE PERFORMANCE
ASSESSMENT
Tables I–IV summarize the validation done on the principal
methods discussed in Section II concerning the four largest
areas of application of ultrasound image segmentation, namely
cardiology, breast cancer, prostate cancer and IVUS (vascular
KEY TO TABLES
• Modality: 2D, 2D+T, freehand 3D, ROT3D=mechanical
scan 3D, RT3D(1)=ﬁrst generation real-time 3D (Volumetrics), SAX=Short Axis, LAX=Long Axis, XC=apical
X Chamber (X=2,3,4), TEE=transoesoephageal.
• Segmentation Criteria: C=Contour, S=Surface, R=Region
(2D) or Volume (3D,4D).
• Performance Measure: as stated, although papers differ
in their choice and naming so it has been difﬁcult to
reconcile names across papers/studies.
• Adhoc parameters: (−) none or sensitivity analysis done,
(+/−) yes and some attempt at sensitivity analysis, (+)
yes and no sensitivity done.
• Automation: (+) full, (−) interactive guidance/correction,
(=) substantial guidance.
• Evaluation: QL=qualitative, QN(m)=quantitative (manual
delineations),
QN(c)=quantitative
reference/standard).
• Validation number: Number of subjects (number of images).
• Validation Type (Standard or reference): OB(m)=human
observer (number of observers), CR=Clinical Reference
(e.g. angiography), CL=quantitative comparison with
method in literature
From this we can make a number of general comments on the
state-of-art in validation in this ﬁeld.
7The winding number is deﬁned as the number of times the image gradient
vector rotates over 2π when a closed curve is traversed about a ﬁxed point
i.e. the path integral of the angular increment of the direction of the gradient
vector over a closed neighborhood around a point.
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 25, NO. 8, AUGUST 2006
VALIDATION OF CARDIAC ULTRASOUND SEGMENTATION METHODS. THE METHODS ARE FIRST SORTED BY IMAGE DIMENSION (2D, 2D+T,3D,3D+T),
THEN BY DEGREE OF AUTOMATION (NON-AUTOMATIC, AUTOMATIC) AND FINALLY BY YEAR OF APPEARANCE (ASCENDING ORDER).
Interaction type
Evaluation
Performance
Validation/Illustration
parameters
Friedland 
Binder 
ROI, Manual training
Area correlation
OB(2), CR(NMR)
Bland-Altman Area (mm2)
−0.69 ± 1.7
Ejection Fraction (EF)
Bland-Altman EF (%)
−7.01 ± 6.11
SAX 2D, ROT3D
Seed point
Contour AD(end)
1.643 ± 0.503 pxl
Mishra 
Area correlation
Contour MAD
Plotted frame-by-frame
Seed point
Ellipse initial
Contour AD (end)
Manual Training
Mignotte 
Mignotte 
Rate correct. pxl classiﬁcation
Chalana 
ROI, Manual initial. of epi.
Contour AD (end)
3.61 ± 1.68 mm
Area correlation (end)
Contour AD (epi)
2.80 ± 1.28 mm
Area correlation (epi)
Kucera 
Manual Initial. (circle)
Contour MAD (end)
19(38), 1(9)
Correction
Mikic 
ROI, Manual initial
Contour AD
1.15 ± 0.2 mm
Area correlation
Contour AD
1.29 ± 0.35 mm
Area correlation
Contour AD
2.07 ± 0.40 mm
Area correlation
Setarehdan 
RMS radial based distance (end)
Area correlation (end)
RMS radial based distance (epi)
Area correlation (epi)
Ejection Fraction
Mulet-Parada 
Jacob 
Initialization
4 (rest and peak stress)
Bosch 
Manual Training (AAM)
corresp. point MAbD (end)
3.35 ± 1.22 mm
Area correlation coeff.
Mitchell 
Manual Training (AAM)
corresp. point MAbD (end)
3.90 ± 1.38 mm
OB(1), CL Bosch 
Area correlation coeff.
Boukerroui 
Area error (pxl2)
−7.59 ± 6.71 %
OB(1), CL Xiao 
Contour AD
5.96 ± 2.20 pxl
Coppini 
3D freehand
volume correlation coeff
(underestimate manual volume)
Corsi 
Initialization
Ejection fraction
y=0.90x+4.16 r=0.87
Bland-Altman volume
−15.58 ± 20.55 ml
3D freehand
Initialization
Surface projection dist. Err (epi)
3.2 ± 0.85 mm
Surface projection dist. Err (end)
2.6 ± 0.78 mm
Seed point
Contour MAvD (end)
3.44 ± 1.18 mm
Angelini 
Initialization
ESV % error
OB(1), CR(MRI)
EDV % error
EF % error
Montagnat 
Initialization
VALIDATION OF BREAST ULTRASOUND MASS DETECTION AND CLASSIFICATION METHODS: CR(B/A)=BIOPSY/ASPIRATION; THE METHODS ARE FIRST
SORTED BY IMAGE DIMENSION (2D,3D), THEN BY DEGREE OF AUTOMATION (NON-AUTOMATIC, AUTOMATIC) AND FINALLY BY YEAR OF APPEARANCE
(ASCENDING ORDER).
Interaction type
Evaluation
Performance
Validation/Illustration
parameters
ROI speciﬁed
Sensitivity
Speciﬁcity
Huang 
ROI speciﬁed
Match rate
Precision ratio
Horsch , 
2001, 2002
Lesion center
QN(m), QN(c)
Area overlap t = 0.4, detection correct
0.94 (auto)
OB(3), CR(B/A)
0.97 (partial auto)
0.87 (auto)
0.89 (partial auto)
Drukker 
QN(m), QN(c)
Area overlap t = 0.4, detection correct
OB(3), CR(B/A)
Madabhushi 
Mean boundary error
Normalized true positive overlap
Drukker 
ROC (Actual lesions and FP detection) Az
ROC Cancers from other detections Az
3D mechanical scan
ROI on 3 2D frames
Average volume match rate
Chang 
3D mechanical scan
ROI speciﬁed
Average volume match rate
Sahiner 
3D mechanical scan
3D ellipsoid initialization
• In general, to validate medical image segmentation methods quantitatively one can use simulation, phantom studies, animal model studies, and clinical studies using manual delineation, another modality as a “gold standard” or
reference, or some correlation with clinical outcome. The
literature on ultrasound segmentation indicates that some
simulation and phantom studies have been performed
but predominantly clinical data is used in validation.
This partly reﬂects the difﬁculty in deﬁning realistic
simulations and phantoms.
An effective ultrasound simulation package, ‘Field II’
is available , 8. The package provides an
excellent framework to simulate ultrasound transducer
ﬁelds and ultrasound imaging using linear acoustics. The
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 25, NO. 8, AUGUST 2006
VALIDATION OF PROSTATE ULTRASOUND SEGMENTATION METHODS. MAD=MEAN ABSOLUTE DIFFERENCE; MAXD = MAXIMUM DISTANCE.
AD=AVERAGE DISTANCE; HD = HAUSSDORFF DISTANCE (SEE ). SEE LADAK ET AL. FOR AREA SENSITIVITY AND ACCURACY. SEE TABLE II
FOR THE SORTING RULES.
Interaction type
Evaluation
Performance
Validation/Illustration
parameters
Knoll 
Contour MAD
04.70 pxl (2.61 mm)
Area difference
Area accuracy
Ladak 
Contour MAD
04.4 ± 1.8 pxl
Manual Initial. (4 points)
Manual correction
Contour MaxD
19.5 ± 7.8 pxl
Area accuracy
90.1 ± 3.2 %
Area sensitivity
94.5 ± 2.7 %
Area correlation
Pathak 
Manual Initial. (1 points)
Contour AD
0.7 ± 0.4 mm
Contour HD
1.8 ± 1.0 mm
Boxplots are also shown
Abolmaesumi , 
Seed point
Area overlap
Chiu 
Manual Initial. (4 points)
Manual correction
Contour MAD
02.89 ± 0.88 pxl
Contour MaxD
10.73 ± 4.56 pxl
Area difference
03.50 ± 2.40 %
Manual Initial. (4 points)
Manual Training
Contour AD
1.82 ± 1.44 mm
Contour HD
4.54 ± 2.93 mm
Boxplots are also shown
ROI, Manual initial
Contour RMS
01.16 ± 0.4 mm
Area accuracy
86.1 ± 5.6 %
Area sensitivity
92.3 ± 4.0 %
Shen 
Manual training (ASM)
Contour AD
3.20 ± 0.87 pxl
Area overlap error
3.98 ± 0.97 %
Area difference
1.66 ± 1.68 %
Manual Initial. (6 points)
Manual correction
Contour MAD
1.19 ± 0.14 mm
CL (Ladak )
Contour MaxD
7.01 ± 1.04 mm
Volume difference
7.16 ± 3.45 %
Zhan 
Manual Training
Contour AD
1.10 ± 0.16 vxl
Volume overlap error
4.13 ± 0.55 %
Volume difference
2.23 ± 1.19 %
program has been used in number of application to
provide ground truth data (see eg. , – ).
• Manual delineation on clinical data is by far the most
popular means of performance assessment although depending on the clinical area, there can be signiﬁcant interexpert and intra-expert variability (quite often, simply
because manual segmentation is not a task that they
would normally do) and delineation can be difﬁcult to do.
Therefore one needs to take care in interpreting results
when manual delineation is used as the reference.
• There is also a general lack of standardization of performance measures, which makes it difﬁcult to directly
compare methods. The one exception here is in cardiology, where the method of Chalana and Kim has
been used by a number of groups (however, see 
for a correction of the Percent Statistic test). This has
the advantage that multiple experts are used to deﬁne the
reference.
The method of Chalana and Kim assumes that segmentation boundaries can be well-deﬁned. This is not the
case, for example, for malignant breast masses where
a region-based metric is more applicable. Performance
metrics used in breast ultrasound segmentation performance assessment have employed quite simple area-based
measures with comparison with a single expert or multiple experts treated separately. This area might beneﬁt
from moving towards using performance methods that
use multiple expert segmentations such as the STAPLE
(simultaneous truth and performance level estimation)
8Free software for a number of operating systems is available at:
 
algorithm .
• From the Tables we note the low number of papers
reported with validation on databases with more than 50
• There are also no standard databases on which different
groups can compare methods, so comparisons have only
been made between methods developed by individual
groups. This is problematic for the ﬁeld as a whole, as
clinical ultrasound image quality varies a lot, more so
than in other areas of medical imaging such as CT and
IV. METHODOLOGY
A. What makes a good ultrasound segmentation method?
Due to the relatively low quality of clinical ultrasound
images, a good ultrasound image segmentation method needs
to make use of all task-speciﬁc constraints or priors. This is an
explicit or implicit assumption in all successful methods in the
literature. Methods can broadly be deﬁned in terms of those
that make use of imaging physics constraints, those that make
use of anatomical shape constraints, or temporal constraints
or a combination thereof (one could also include functional
constraints, such as a perfusion model, but segmentation of
contrast agent images is not considered in this review). In
the following subsection we consider ﬁrst speckle, the characteristic feature of ultrasound images, then intensity-based
priors and ﬁnally how geometric and temporal priors have
been employed.
B. Speckle - noise or a feature?
Speckle gives ultrasound images their characteristic granular
appearance. It inherently exists in coherent imaging, including
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 25, NO. 8, AUGUST 2006
VALIDATION OF IVUS ULTRASOUND SEGMENTATION METHODS. MAD = MEAN ABSOLUTE DIFFERENCE. WI= WILLIAM’S INDEX; CI= CONFIDENCE
INTERVAL. AD=AVERAGE DISTANCE; HD = HAUSSDORFF DISTANCE (SEE ). RMS= ROOTS MEAN SQUARED ERROR; MAXD= MAXIMUM
DISTANCE (PIXEL-TO-PIXEL). SEE TABLE II FOR THE SORTING RULES.
Interaction type
Evaluation
Performance
Validation/Illustration
parameters
Sonka 
Contour MaxD
0.33 ± 0.07 mm
Contour RMS
0.07 ± 0.02 mm
Contour MaxD
0.33 ± 0.09 mm
Contour RMS
0.08 ± 0.02 mm
Contour MaxD
0.33 ± 0.10 mm
Contour RMS
0.09 ± 0.03 mm
Takagi 
Area difference
−0.18 ± 1.36 mm2
Area correlation
Area difference
−0.15 ± 0.84 mm2
Area correlation
Contour MAD
0.099 ± 0.032 mm
8.2 ± 5.4 %
Shekhar 
Manual initial
Area correlation
Area WI (95% CI)
0.60 (0.53, 0.68)
Area WI (95% CI)
0.66 (0.47, 0.84)
(In vitro)
HD WI (95% CI)
0.63 (0.54, 0.73)
AD WI (95% CI)
0.58 (0.50, 0.67)
Area WI (95% CI)
0.46 (0.37, 0.54)
HD WI (95% CI)
0.59 (0.55, 0.63)
AD WI (95% CI)
0.64 (0.56, 0.71)
Klingensmith
Manual initial
Editing correction
Area WI (95% CI)
0.88 (0.78, 0.97)
HD WI (95% CI)
0.80 (0.74, 0.86)
AD WI (95% CI)
0.79 (0.75, 0.83)
Area WI (95% CI)
0.62 (0.37, 0.93)
HD WI (95% CI)
0.70 (0.65, 0.75)
AD WI (95% CI)
0.68 (0.57, 0.81)
Volume correlation
Initialization
Area absolute difference
06.5 ± 7.6 %
Area absolute difference
15.2 ± 17.4 %
Klingensmith
 ( )
Manual initial
Editing correction
Area WI (95% CI)
0.99 (0.95, 1.04)
Area difference
−0.07 ± 0.67 mm2
Area correlation
Area WI (95% CI)
0.98 (0.89, 1.06)
Area difference
−0.07 ± 0.67 mm2
Area correlation
Pardo 
Manual Initial.
Manual Training
Contour distance
2.30 ± 3.46 pxl
Haas 
Contour radial difference
−0.064 ± 0.156 mm
Contour radial difference
−0.025 ± 0.163 mm
Area correlation
Area difference
−0.470 ± 1.140 mm2
0.105 ± 0.094 mm
0.300 ± 0.104 mm
Area correlation
Area difference
−0.240 ± 1.070 mm2
0.083 ± 0.111 mm
0.344 ± 0.237 mm
ultrasound imaging. The analysis of this signal-dependent
effect has been a major subject of investigation in the medical
ultrasound imaging community as well as the optical (laser)
and radar imaging communities. The texture appearance of
the observed speckle does not correspond to underlying tissue
structure. However, the local brightness of the speckle pattern
does reﬂect the local echogeneity of the underlying scatterers.
Speckle can be undesirable and hence is seen as noise to be
reduced, or, as signal carrying some information about the
observed tissues. Thus from a segmentation perspective you
may chose to remove it or utilize it for the information it
The received echo signals are obtained by a coherent
summation of echo signals from many ultrasound scatterers.
Speckle has a random and deterministic nature as it is formed
from backscattered echoes of randomly or coherently distributed scatterers in the tissue , . It has been shown
that the statistical properties of the received signal, and thus
of the echo envelope, depend on the density and the spatial
distribution of the scatters . Several distribution families
have been proposed in the literature. For the special case of
a large number of randomly located scatterers, the statistics
of the envelope signal shows a Rayleigh distribution (see eg.
 , ). In this condition the speckle is called fully
developed. Deviations from such special scattering conditions
have been previously modeled via:
• The Rice distribution to account for a coherent component due to the presence of a regular structure of scatterers
within the tissue , .
• The K-distribution to account for low effective scatter density (partially developed speckle) (see eg. ,
Unfortunately, the Rician family fails to account for reduced
scatterer densities, and the K-distribution model does not take
into account the presence of a coherent component. General
models have been proposed in the literature namely the
generalized K-distribution and the homodyned K-distribution
(see eg. , ) and most recently the Rician Inverse of
Gaussian distribution . The three models are general and
can account for the different scattering conditions. However,
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 25, NO. 8, AUGUST 2006
the analytical complexity with these families is signiﬁcant.
Some effort has been put into efﬁciently estimating the parameters – and alternative simple models have also
been proposed such as the Nakagami family (see eg. ).
Note that all these models are for the envelope of the
received echo signal. In clinical ultrasound imaging systems, a
log-compression is performed to control the dynamic range of
the image. An approximate algorithm for the estimation of the
log-compression parameter from pixel values of a displayed
B-scan images was recently proposed . Statistics of the
log-compressed echo envelope have also been proposed ,
A number of tissue characterization algorithms , ,
 , , – , denoising algorithms , ,
local entropy statistics and an MRF model based
on the above models have been proposed in the literature.
There is also an extensive literature on speckle reduction which
has been proposed as a pre-segmentation step; recent works
include wavelets based methods – , anisotropic diffusion methods , , – and others , ,
 – .
1) Image features:
• Gray level distribution:
As noted in the previous section, the Rayleigh model of speckle has proved a popular choice. A Rayleigh distribution was used in the
anisotropic diffusion edge detection method of and
in statistical segmentation methods in , , ,
 , , . Most recently the Rayleigh distribution was incorporated into the level set method of Sarti et
al. and of Cardinal et al. . A shifted Rayleigh
distribution was used in the active contour approach
of , and in level set segmentation algorithm
in , . Other gray level distribution models have
also been used in the ultrasound segmentation literature: for instance, the Gaussian , , , ,
 , – , exponential , Gamma and
Beta distributions.
• Intensity gradient (and higher derivatives): The motivation for using intensity gradient as a feature comes from
the computer vision literature where based on a photometric model, high intensity gradients or equivalently
intensity step changes/discontinuities in intensity are frequently associated with edges of objects. In ultrasound
segmentation it is therefore appropriate to use intensity
gradient as a segmentation constraint if the goal is to ﬁnd
acoustic (impedance) discontinuities. Strictly speaking
one is also assuming that there is an approximately constant intensity on either side of the boundary (ie speckle
has low amplitude). It has proved a popular constraint
with or without prior speckle reduction, for example,
in , , , , , , , , –
 , , , , , , – ,
 , . Radial gradient estimation was also used
in , , , , . To reduce the effect of
speckle before gradient estimation, median ﬁltering ,
morphological smoothing , speckle reduction ,
 , , , coarse-to-ﬁne optimization , ,
 , , thresholding based adaptive smoothing ,
 and other preﬁltering techniques , , ,
 have been used.
Gradient based level set algorithms have also been the
most popular , , , , , , and
only few have used region information , , ,
 , or a combination of both , , ,
The limitations of the choice relate to the anisotropy
of image acquisition, as the strength of a boundary
response/edge is a function of the relative orientation of
the transducer to the boundary, signal attenuation with
depth reduces the strength of boundaries for deep objects,
and speckle gives a strong intensity gradient response.
Thus intensity gradient information has only really proved
a useful constraint for analyzing good quality clinical
images and used in conjunction with other features as
mentioned above as well as in , , , ,
 , .
• Phase: The local phase provides an alternative way to
characterize structure in an image which has been used
for example in – . Measuring local phase, or rather
phase congruency over spatial scales, provides a way to
characterize different intensity features in terms of shape
of the intensity proﬁle rather than the intensity derivative
magnitude; for example a step edge has a phase value of
0 or π, an intensity ridge has a phase of π/2. Thus, phase
has been suggested as a more robust feature for acoustic
boundary detection. Speckle also has a phase signature so
appropriate spatial scales have to be selected. Generally,
phase is estimated using quadrature ﬁlter banks. Thus
there is a link between phase-based methods and other
wavelet methods.
• Similarity measures: Within the current discussion of Bmode ultrasound segmentation, similarity measures have
been used to provide a displacement estimate as a constraint in spatio-temporal analysis rather than a standalone
segmentation feature (c.f. use in image registration). The
literature on ultrasound-ultrasound similarity measures
is very small. The sum-of-squares difference (SSD) is
used, for example in . Cohen and Dinstein developed
an ultrasound-speciﬁc similarity measure based on the
assumption that both image blocks contained speckle that
could be modeled as a Rayleigh distributed multiplicative
corruption . This method was shown to be better
than the SSD or normalized cross-correlation in .
A variant of Mutual information that uses neighborhood
information, the Mutual Information of Image Geometry
(MIIG) was proposed in . The MIIG similarity was
used for the estimation of an average intensity proﬁle
from a training set. This intensity prior was taken into
account in the segmentation by means of the same
similarity measure.
• Texture measures: Although, ultrasound texture patterns
are intrinsically dependent on the imaging system, they
characterize the microstructure of the tissues being im-
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 25, NO. 8, AUGUST 2006
aged. The distribution (coherent and/or random) of scatterers and their relative sizes to the wavelength of the
incident ultrasound pulse, produces different texture patterns. As noted in the section on Speckle, ultrasound
speckle statistics/measures have been successfully utilized to discriminate breast masses ( – , ,
 and references therein) and Bouhlel et al. 
have recently proposed a MRF for textured ultrasound images based on the K-distribution and on a multiplicative
degradation model. However, general statistical texture
analysis methods have been used with some success in
this ﬁeld. One potential advantage of texture analysis
is that most texture measures are based on statistical
patterns of the intensities and thus independent of the
physics of the imaging system (see for example ,
 ). Thus, in segmentation, where the aim is often
to characterize the imaged object rather than necessarily
characterize its true physical properties, texture analysis
methods have proved successful. Texture characterization
has been used. for instance, in classiﬁcation and discrimination studies of liver tissues – breast masses
 – , , , , – , carotid plaques
 , , coronary plaques , , myocardial
tissues , , the thyroid gland , , ovarian
masses and prostate tissues , . In general,
good classiﬁcation rates have been obtained when large
regions-of-interest are investigated (64 × 64 or 32 × 32
pixels). They are not as good with smaller sample sizes,
i.e., when the pathological area is very small. Texturebased segmentation algorithms have also been proposed
in the ultrasound literature and used in various clinical
application domains such as: ovaries , IVUS ,
prostate , , , breast , , , liver
 , , echocardiography and kidney ,
Literally hundreds of texture measures have been used in
the literature (statistical, structural, model based, transform based/spectral). Texture features derived from Haralick’s co-occurrence matrices, although computationally
expensive to compute, have performed well in a number
of applications and have been used in combination with
other measures or for comparison in a number of studies
 , , , , – , , – ,
 , , , , , , – .
Several authors have also emphasized the importance of a
multiple resolution characterization (see eg. , )
or the use of an intelligent parameters adjustment to the
ultrasound resolution .
2) Shape: Edge cues and region information are often not
sufﬁcient for a reliable and accurate segmentation. In this case
shape constraints are often found to effectively improve results. Because of attenuation, shadowing artefact and speckle,
shape constraints have proved popular and successful recently
in B-mode ultrasound image segmentation , , –
 , , , , , , , .
Shape information is embedded in segmentation methods
in several ways. Probably the most classical shape constraint
involves boundary regularization, say as in the choice of
the internal terms in an active contour. A second way to
impose a shape constraint is by using a parametric shape
and a preferred shape can be imposed, for example in a
probabilistic framework, using the learned distributions of the
shape parameter over a set of training examples. An example
of such a shape constraint used in ultrasound segmentation is
in the work of Gong et al. . A close variant is to impose a
shape constraint by restricting the space of possible shapes
to a predeﬁned model shape with a set of transformations
(global and/or local). This representation does not impose a
parametrization of the shape and does not require training.
In this case the constraint is imposed on the transformation
set, and global and local transformations may be penalized
differently. See for a good example of this. A widely and
acknowledged alternative way to employ a shape constraint
is via the use of a Point Distribution Model (PDM) . A
PDM describes the average shape and the most characteristic
shape variations of a set of training samples obtained using
Principal Component Analysis (PCA). The use of a PDM in
segmentation is known as an Active Shape Model (ASM).
As in the previous model, no parametrization of the shape
is needed. However, the set of possible shapes is deﬁned by
the principal modes of shape variation in the training set. In
general, prior shape knowledge is modeled in a probabilistic
framework. For instance, a Gaussian distribution or a
mixture model . Although ASMs are suitable to describe
free-form deformations, a point-to-point correspondence of the
shape is necessary for the estimation of the average shape
and its mode of variations. An extension to include intensity
prior information was proposed, called the Active Appearance
Model (AAM) in . Another extension is to include motion
information as in and the Active Appearance Motion
Model (AAMM) in . An extension of the AAM to 3D
was proposed by Bosch et al. . An advantage of the
AAM approach is that it attempts to learn both the geometric
shape and the boundary model of an object. A limitation is
that it assumes clinical images from different subjects have
similar appearance. This can be difﬁcult to achieve on routine
clinical images due to natural subject-to-subject tissue property
variations and operator-to-operator variation in acquisition.
This led Bosch et al. to propose a nonlinear normalization
step to reduce these effects.
To overcome the limitation of point-to-point correspondence
in the learning stage, Leventon et al. proposed to use a level
set representation of the shape . An example of the
use of such a shape model on US images is provided by
Xie et al. . In order to allow more ﬂexibility for the
shape variation, (i.e avoid the Gaussian assumption mentioned
above), a level set variant of the ASM, the Implicit ASM was
proposed in and applied to echocardiography in .
In this model, the evolving surface is not restricted within
the modeled space, but only attracted to it using a distance
function. To allow more ﬂexibility, Chen et al. proposed, again
in a level set framework, to constrain the solution using a
distance function to the learned average shape (i.e PCA is
not used to learn the principal mode of variation) . Prior
intensity information was also taken into account in a similar
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 25, NO. 8, AUGUST 2006
way as in their recent work , .
Finally, we would like to emphasise the fact that a shape
model is only as good as the training samples from which
it was built and the chosen shape-space model framework
(eg. linear, non linear). An important issue, still open to
our knowledge, concerns the aptitude of shape constraints to
handle disease cases.
3) Time: Ultrasound is often employed because it is realtime and thus the data available for segmentation is a temporal
image sequence rather than a static frame. Therefore it is
sometimes useful to employ temporal priors in segmentation
i.e. consider segmentation as a spatio-temporal process. The
most obvious example application is cardiac segmentation
where the object moves in a periodic pattern. Respiration can
also introduce (unwanted) motion. One way to handle motion
is to register the data prior to segmentation. The other approach
is to handle motion (correction or estimation) as part of the
segmentation process directly via a temporal prior.
Temporal priors or models can take a number of forms. The
choice depends on how well the motion can be parameterized
and whether computation speed is a determining factor in
designing the segmentation method. We illustrate this with
some example methods below.
First temporal priors may be “weak” in the sense of insisting
on global or local , , temporal coherence or
smoothness. Another simple way to invoke a weak notion of
temporal coherence is to propagate a segmentation result from
one frame to initialize the segmentation in the next frame ;
a variant of this is to adjust the position of the initializing
segmentation by using image velocity estimates .
A constant velocity model or other simple parametric model
might be assumed to allow propagation of a result from
one frame to initialize segmentation in another. A variant
of this is to use a Kalman ﬁlter to blend a spatio-temporal
model with feature measurements as in , . If the form
of the parametric model is not obvious or motion patientspeciﬁc then the temporal model may be estimated from data.
For example some authors have explicitly incorporated local
estimates of image velocity , , , . Malassiotis
et al use a temporal learning-ﬁltering procedure to reﬁne the
output of active contour tracking . In the work of Mitchell
et al the temporal model is learned from manually traced
segmentations.
Other authors have explicitly added time as an extra dimension to an N-dimensional segmentation problem , ,
 , , . Only a few authors have considered solving
the spatio-temporal segmentation problem where the space parameters are treated differently from the time parameter ,
V. CONCLUSION
To conclude this review we have selected 10 inﬂuential
papers in the ultrasound segmentation literature. These are
not claimed to be the ‘best’ but have been selected based on
criteria of the ultrasound-speciﬁc model they have employed
and/or whether evaluation has been performed on a reasonable
number of clinical datasets. In no particular order of importance:
• Binder et al. : although not a recent paper, this
is a good illustration of the application of neural networks
and learning to (cardiac) ultrasound image segmentation,
which is also one of the few ultrasound segmentation
methods that has been explicitly tested on a reasonable
number of clinical images of varying quality.
• Dutt and Greenleaf : statistics of logcompressed echo envelope using an underlying Kdistribution model before compression. Most ultrasound
data comes from machines where log-compression has
been done. Hence it is important that the model takes into
account this non-linear transformation (speckle prior).
• Mulet-Parada : proposes an intensity-invariant
image feature (local phase) for acoustic boundary and
displacement estimation as an alternative to intensity
derivatives (image prior).
• Friedland et al. : an early contribution viewing
ultrasound segmentation as a spatio-temporal problem;
(cardiac) boundary detection is solved as a minimization
of an energy function with a Markovian spatio-temporal
regularization.
• Mikula et al. : and references therein. Presents
a level set method for segmenting objects with missing
boundaries (as frequently observed in ultrasound images).
• Bosch et al. and Mitchell et al. , :
concerns the application and clinical validation of active
appearance and active appearance motion modelling (intensity, shape and motion priors).
• Xie et al. : presents an ultrasound segmentation method that combines texture and shape prior
information in a level set framework; : a good illustration of employing an imaging physics prior (a shifted Rayleigh distribution to model gray level statistics), and a shape prior (a
deformable template) to solve boundary estimation via
a multiscale minimization. (gray level distribution and
shape prior, probabilistic framework).
• Chalana and Kim : concerns the evaluation
of boundary segmentation methods w.r.t. multiple expert
delineations. In ultrasound segmentation this is particularly important as there can be uncertainty in manual
delineation. This is a quite widely employed method
in echocardiographic image segmentation and used elsewhere in the medical image segmentation evaluation
literature.
• Abolmaesumi and Sirouspour : presents a 2D
contour segmentation approach where two contour models are combined in order to achieve smooth results and
allow rapid changes in the boundary. This could be seen
as an adaptive regularization of the boundaries because
the models have different noise/smoothness tradeoff.
Some ﬁnal comments relating to open issues in this area.
In this review we have presented a snapshot view of the stateof-the-art in B-mode ultrasound image segmentation as seen
in the literature in the year 2005. First, (section III) we have
seen the need for more effort on segmentation validation to
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 25, NO. 8, AUGUST 2006
better understand the strengths and limitations of methods
both through comparison with other methods in the literature
and on larger (ideally standard) databases of data. This is
important to encourage the adoption of methods in clinical
practice. Even though ultrasound imaging is so widely used
in clinical diagnosis and image-guided interventions, the ﬁeld
is far behind other areas of clinical image analysis, such
as X-ray mammography or (rigid) image registration in this
respect. Second, in Section IV we have argued that successful
ultrasound segmentation methods should utilize geometric,
temporal, intensity and imaging physics priors. The choice
of which constraints to use is in part application speciﬁc, but
many constraints hold for generic ultrasound image segmentation. Encouragingly, evidence in the recent literature points
towards doing this in a more disciplined way, a trend which we
hope this review will encourage other researchers to follow.
ACKNOWLEDGMENTS
The authors would like to thank the anonymous reviewers
for their thoughtful suggestions on how best to present this
review, and the authors (too many to name in person) who
kindly provided copies of their papers which are discussed in
the review or permission to use ﬁgures from their papers.