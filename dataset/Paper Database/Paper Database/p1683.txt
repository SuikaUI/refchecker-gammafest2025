JOURNAL OF CONSUMER PSYCHOLOGY, 10(1&2), 83-100
Copyright 8 200 1, Lawrence Erlbaum Associates, Inc.
Structural Equations Modeling
V1.A. STRUCTURAL EQUATIONS
MODELING AND STATEMENTS
REGARDING CAUSALITY
My question deals with an issue related to causation. How
does one resolve issues of causal direction? For example, sup-
pose I develop the model depicted in Figure I, wherein mate-
rialism mediates the relation between "perceptions of
marketing" and "life satisfaction."
As proposed, perceptions of marketing influence, or
cause, materialistic values. A reviewer, however, suggests
that the relation could just as easily be reversed; that is, mate-
rialistic values may cause a person to have favorable percep-
tions of marketing. Although there is some theoretical
precedent for the proposed direction , the theory in this area is not well
developed. Outside of a compelling theory, how can I defend
the proposed direction? I have seen this problem arise in a
number of situations (e.g., doctoral defenses, presentations),
but I have not seen it satisfactorily resolved.
REFERENCES
Belk, Russell W. . Materialism: Trait aspects of living in the material
world. Journal of Consumer Research, 12, 265-280.
Belk, Russell W., Mayer, Robert, & Driscoll, Amy. . Children's recog-
nition of consumption symbolism in children's products. Journal of
Consumer Research, 10, 386397.
Professor Richard Netemeyer
Louisiana State University
This question addresses the issue of "mediation" as well as
causal direction. I offer an answer to the causal direction por-
Materialism
Structural equations attempting to capture causality.
tion of h s question assuming nonexperimental data and the
use of correlational data within a structural equation model-
ing (SEM) framework. As such, my answer is very narrowly
focused on one type ofmethodology relative to assessing cau-
sality. The interested reader is strongly urged to consult sev-
eral sources that discuss the process of mediation as well
 . (The issue of detecting mediation is
treated in detail in Question V1.E. in this special issue.)
In a correlational framework, particularly where the data
were collected cross sectionally andmodeled using SEM, it is
next to impossible to confidently infer that one construct
causes another. The requirement that a construct must be
shown to temporally precede its effect just does not exist. Fur-
thermore, in many models, switching the kection between
two constructs will not alter the fit ofthe model and may not al-
ter the parameter estimate of association between the two con-
structs . Models
such as these have been termed equivalent models because
they comprise the same constructs as a specified target model
that are no more or no less parsimonious than that target model.
As noted by MacCallum et al., equivalent models raise aprob-
lem similar to a confound in an experimental design in that a
confound offers an alternative explanation to the experimental
hdings. An equivalent model in SEM cannot be ruled out as a
statistically equivalent representation of the data.
Furthermore, the conditions for establishing causality us-
ing SEM are the same for other techmques-independent
variables (IVs) must be isolated, association must be demon-
strated, and directionality must be established. Bollen 
offeredadetailedreview, andHoyle and Smith (1 994,pp. 438-
439) offered a concise review of these conditions with respect
to SEM. With cross-sectional SEM data, one can safely argue
that a model is consistent with a set ofcausal relations, but the
exact directional association cannot be demonstrated. Still, the
determination of directionality is not solely a statistical judg-
ment. Directionality judgments can be enhanced by logical
reasoning and a thorough understanding of accumulated the-
ory and research such that a compelling directionality argu-
ment can be made. In this case, a cause and effect sequence
may be proposed but not hlly tested using SEM.
Though still not adequate for a confident causal inference,
longitudinal SEM procedures offer a better possibility of ini-
tial evidence for the direction of causation . There are many long-term studies that have
used such an approach that provide stronger evidence for a
temporal sequence of constructs in amodel. See Bullock et al.
(p. 256) and Hoyle and Smith for a briefreview
of some of these applications.
In sum, resolving the issue of causal directionality with
correlational data in a SEM framework is extremely difficult.
As stated by many modeling researchers, causal inferences
fiom such models (particularly those with cross-sectional
data) are rare and are likely ill advised . In many
cases, the conditions for inferring causality will not be met or
equivalent models that offer an alternative ordering to the
model constructs that fit the data equally well will exist.
Though putative logic, strong and learned theoretical argu-
ments, and longitudinally collected data can clearly
strengthen a directionality argument, most SEM applications
are best viewed as potential explanations that are consistent
with a set of causal relations. Ultimately, it is the design, not
the statistical method (i.e., SEM), that permits causal hypoth-
eses to be adequately tested .
REFERENCES
Baron, Reuben M., & Kenny, David A. . The moderator-mediator
variable distinction in social psychological research: Conceptual, stra-
tegic, and statistical considerations. Journal of Personality and Social
Psychology, 51, 1172-1 182.
Bollen, Kenneth A. . Structural equations with latent variables. New
York: Wiley.
Brown, Roger L. . Assessing specific mediational effects in complex
theoretical models. Structural Equation Modeling, 4, 142-1 56.
Bullock, Heather R, Harlow, Lisa L., & Mulaik, Stanley A. . Causa-
tion issues in shuctural equation modeling research. Structural Equa-
tion Modeling l, 253-267.
Campbell, Donald T.. & Stanley, Julian C. . Experimental and
quasi-erperimental designs for research. Chicago: Rand McNally.
Cohen, Jacob, & Cohen, Patricia. (1 983). Applied multiple regress/corela-
tion for the behavioral sciences (2nd ed.). Hillsdale, NJ: Lawrence
Erlbaum Associates, Inc.
Hayduk, Leslie. . LISREL issues, debates, andstrategies. Baltimore:
Johns Hopkins University Press.
Holmbeck, Grayson N. . Toward terminological, conceptual, and sta-
tistical clarity in the study of mediators and moderators: Examples
child-clinical and pedtatric psychology literatures. Journal of Con-
sulting and Clinical Psychology. 65, 599-61 0.
Hoyle, Rick H., & Panter, Abigail. . Writing about structural equation
models. In Rick H. Hoyle (Ed.), Structural equation modeling: Con-
cepts, hues, and applications (pp. 158-176). Thousand Oaks, CA:
Hoyle, Rick H., & Smith, Gregory T. . Formulating clinical research
hypotheses as strum1 equation models: A conceptual overview. Jour-
nal of Consulting and Clinical Psychology, 62, 429440.
MacCallum, Robert C., Wegener, Dwayne T., Uchino, Bert N., & Fabrigar,
Leandre R . The problem of equivalent models in applications of
covariance shucture analysis. Psychological Bulletin, 114, 185-199.
MueUer, Ralph 0.
 . Structural equation modeling: Back to basics.
Sinrctural Equation Modeling. 4, 353-369.
Sobel, Michael E. . Causal inferences in latent variable models. In
Kenneth Bollen & John Long (Eds.), Testingstructural equation models
@p. 3-35). Newbury Park, CA: Sage.
Professor Peter Bentler
University of California, Los Angeles
Your question is an excellent one, but the answer is d~fficult. The
ideal design wouldbe one in which causationacross time can help
e b t e one of the alternatives. In your example, ifperceptions
of marketing were measured at Time 1, materialism at Time 2,
and life satisfaction at Time 3, it wouldbe hard to argue that mate-
rialism at Time 2 affects perceptions at Time 1. Of course, in the
typical cross-sectional design, these alternatives cannot be teased
apart in this way. In such a design, the problem is that the two al-
ternative models are not nestedmodels, so that they cannot be di-
rectly compared statistically. Indeed, each of the two proposals is
a saturated model, and so both wdl exactly reproduce any data set.
This creates the quandary you suggested.
I do have a suggestion for a way to resolve this problem.
One way to resolve this issue is to nest both models inside a
larger model. Instead of a one-way arrow (in either direction)
between perceptions and materialism, replace this with two
one-way arrows in which perceptions affects materialism and
vice versa. Now this becomes a nonrecursive model, which is
not identified because it contains one more parameter than
data points. Therefore, by itself it cannot be tested. However,
if you add another variable or set of variables to the system
that affects either materialism or perceptions, but not any of
the other variables in the system, you will have an identified
model. An example might be socioeconomic status, which
one might propose to affect materialism but not any of the
other variables. Or, you could add a variable or set of variables
consequent to perceptions or marketing, but not both. If such
a model is identified, your alternative hypotheses have to do
with the relative size of the two paths between perceptions
and materialism. For example, you may 6nd that the path per-
ceptions + materialism is significantly larger than the reverse
path materialism + perceptions, whlch would support your
initial ideas. As far as I know, this proposed solution to your
problem has not appeared previously in the literature. A good
basic discussion of nonrecursive models is given by Kline
 . For example, you could embed your model into a dia-
gram as given by his Figure 6.5.
Kline, Rex B. . Principles andpractice of structural equation model-
ing. New York: Guilford.
Editor: As Bentler indicates, part of the problem with the
question posed is that the researcher is working with a sim-
STRUCTURAL EQUATIONS MODELING
plistic, impoverished, nomological network. Adding paths
representing influences from unique antecedents would in-
deed help tease apart the causal direction (as would adding
distinct consequential variables). The proposed model does
not have the usual conceptual limitation of a poor nomo-
logical net, whlch is the structural equivalence of two (or
more) pairs (or sets) of nodes or constructs (i.e., identical
precursors and effects). However, either scenario could be
salvaged somewhat with greater theoretical complexity, so
as to rule out alternative explanations, here, in trying to de-
termine which causal direction might be more sensible.
Cliff presented a readable, sobering reminder of
issues regarding making causal claims on the basis of mod-
eling covariance matrices. For example, he stated, "data do
not confinn a model, they only fail to disconfirm it" (p.
117). It is odd indeed that we (post modernists) claim to be
philosophically inclined toward the orientation of falsifica-
tion, yet articles are written more often from a perspective
as if we seek to confirm that our models fit (in structural
equations, or even hypotheses posed in an analysis of vari-
ance [ANOVA] framework). Cliff goes on to describe a
"corollary that when the data do not disconfixm a model,
there are many other models that are not disconfirmed ei-
ther" (p. 117). Presumably, scientific progress is impeded
with the existence of a single alternative competing model;
MacCallum et al. demonstrated on
models published in prestigious journals that there were as-
tronomical numbers of alternatives models that would have
provided equivalent fit.
There are all kmds of circumstances that might lead us to
investigate correlational data , but if
we seek to make causal statements, we would best operate ex-
perimentally. "The most satisfactory, almost the only satis-
factory, method for demonstrating causality is the active
control of variables" .
REFERENCES
Cliff, Norman. . Some cautions concerning the application of causal
modeling methods. Multivariate Behavioral Research, 18, 115-126.
Hulland, John, Chow, Yiu Ho, & Lam, Shunyin. . Use of causal models
in marketing research: A review. International Journal of Research in
Marketing, 13, 181-197.
V1.B. SEM USING CORRELATION OR
COVARIANCE MATRICES
Why, when doing a SEM, are we supposed to use co-
variance matrices, rather than correlation matrices, even
though a correlation matrix is a special kind of
covariance matrix?
Professor Peter Bentler
University of California, Los Angeles
The most basic answer is that in the standard model setup, you
should not use the correlation matrix primarily because of the
laziness ofthe program developers such as myself. The fact is
that the statistical theory for analyses based on the correlation
matrix was developed some decades ago, but developers have
not generally made it available in popular programs.
A more complicated answer is that, in a variety of con-
texts, it does not make sense to analyze correlations, because
variance differences may be critical to understanding a phe-
nomenon. For example, in repeated measures such as
growth curve modeling, one may expect the variances of the
variables (or factors) to increase systematically with time.
Or, in multiple group models, differences in means and vari-
ances may be fundamental to understanding the group dif-
ferences. Therefore, if a latent factor of vocabulary skills is
measured by some vocabulary tests at several ages, it may be
that in each case a one-factor model is appropriate, but only
if the means and variances of the factor are allowed to in-
crease with age. In such cases, analysis of correlation matri-
ces would yield parameters that distort the phenomenon.
Some phenomena also are simply best interpreted in the
covariance or raw score metric. Suppose that part of a model
involves the regression of annual income on years of school-
ing. Now, the unstandardized beta is important because it
represents the expected increase in (say, dollar) income per
year of added schooling, holding e v e w n g else constant.
However, standardization forced through the correlation
matrix makes it impossible to get this interpretation.
Of course, a covariance structure model also has a stan-
dardized solution. In this solution, all the parameters are in-
terpreted as if all variables, including the data, are in a
correlation metric. The advantage is that beta weights are now
interpretable as standardized betas, whlch will make more
sense than unstandardized betas when the variables have only
arbitrary scales. Therefore, you get the advantage of the cor-
relation metric even if you use a covariance matrix. Finally, in
a single group, you could input the correlation matrix but treat
it like any other covariance matrix (i.e., paying no special at-
tention to the fact that variances happen to be 1.0). In that
case, the statistics typically would be meaningful.
Professor Richard Bagoui
University of Michigan
This is a complicated question and might be best answered in
pieces. There are at least two cases in which a covariance ma-
trix should be used and not a correlation matrix. One is when
multiple sample analyses are done and constraints are placed
on parameters across samples to test (by use ofchi-square dif-
ference tests) for invariance of focal parameters. A second is
STRUCTURAL EQUATIONS MODELING
when, even when dealing with a single sample, equality con-
straints are imposed on two or more parameters (e.g., some-
times factor loadings are constrained to be equal or error
variances are constrained to be equal). In both of these cases,
the unique metric of measures for each sample are important
to retain and take into account, and use of a correlation matrix,
which imposes a lund of standardization, should be avoided.
More generally, however, the theory behind the maximum
likelihood method is based on the covariance matrix, and,
strictly speakmg, the chi-square test and standard errors (SEs)
of parameter estimates are not correct when the correlation
matrix is used. This applies in general, even when a single
sample is investigated and no equality constraints are im-
posed on parameters. A nice discussion of the issues can be
found in Cudeck .
Two further comments follow: Cudeck acknowl-
edged that for single sample confirmatory factor analyses in
which no equality constraints on parameters are imposed, the
correlationmatrix can be used for input. At least the parameter
estimates have desirable properties, even if the chi-square test
and SEs are not correct, strictly speakmg. In practice, the
chi-square test usually does not differ, if one uses the
covariance or correlationmatrix as input. As apractical analy-
sis strategy, at least in early stages of analysis, it is useful to
work first with a correlation matrix, as the parameters are
boundednicely and it is easier to make diagnoses ofpoorly fit-
ted models and other problems by examining output produced
by correlation matrices. With use of covariance matrices and
depending on the complexity of amodel the difference in vari-
ance of measures (e.g., some measures may have very small
variances, others very large variances, etc.), it is sometimes
difficult to check for the sources of problems, as factor load-
ings, error variances, and so on, are all over the map and it is
difficult to visually discover problems in convergent and
discriminant validity by inspection of a covariance matrix.
Some further comments follow: For weighted least
squares analysis of certain models in which, for example, in-
tercepts are estimated (e.g., in models with multiplicative in-
dicator variable~), it is useful to analyze the augmented
moment matrix in which means, a covariance matrix, and as-
ymptotic covariance matrices are computed in certain estima-
tion procedures.
Cudeck, Robert. . Analysis of correlation matrices using covariance
structure models. Psychological Bulletin, 105, 3 17-327.
Professor Robert Cudeck
University of Minnesota
The statistical theory underlying SEM has mostly been devel-
oped assuming the analysis applies to covariance matrices.
On the other hand, most analyses actually conducted are
performed with sample correlation matrices because correla-
tions are easier to work with, and easier to understand, than
covariances. Moving from variances and covariances to cor-
relations involves a rescaling of the variables that has to be ac-
commodated in the (statistical) theory or the results may be
adversely affected. Most topics dealing with correlations in
statistics are much more complicated than the related topics
that treat covariances. It is fortunate that estimates and tests
obtained in SEMs are scale free in the majority of cases. The
practical result of this property is that in most applications, an
analysis may be based on correlations. The results one obtains
will be directly related to the corresponding results computed
from variances and covariances. Cudeck gave an over-
view of the issues.
Cudeck, Robert. . Analysis of correlation matrices using covariance
structure models. Psychological Buiietin. 10.5. 3 17-327.
Editor: As these experts indicate, there are some conditions
under which a correlation matrix may be modeled and other
conditions under which the default choice, the covariance
matrix, is still preferred. Cudeck presented the issues
in terms of whether a model is scale invariant (i.e., the results
estimated on a correlation matrix would be simply a rescaled
version of what one would obtain had the covariance matrix
been modeled instead), and whether a parameter within a
model is scale free (defined similarly). Two common scenar-
ios of factor analysis are scale invariant with phi as a covariance
matrix. These invariant scalings mean that although the factor
loadings and other parameters will not necessarily be identi-
cal for the covariance and correlation solutions, one may be
rescaled to obtain and the other. In asense, then, the results are
"correlated in that relatively large (or small) loadings in the
covariance solution will correspond to the relatively large (or
small) loadings in the correlation solution.
Cudeck did warn, however, of the problems of
invariance, with the result that the factor patterns, the overall
fit statistics, and the SEs of the parameter estimates (and
therefore their significance tests) are likely to differ (across
the analyses of a covariance and correlation matrix on the
same data). He offers several tests, none of which are suffi-
cient to demonstrate that the correlation matrix may be pre-
ferred but are necessary in that the violations ofwhich would
suggest the covariance matrix would be preferred (e.g.,
STRUCTURAL EQUATIONS MODELING
check that the diagonal of the model-produced predicted
matrix for a correlation matrix is indeed comprised of uni-
ties, p. 320; fit the factor pattern model to both the correla-
tion and covariance matrices and verify that the fit statistics
are identical, p. 322). He also warned that most software has
been programmed to produce SEs as if the modeled matrix
were a covariance matrix, so it is his pessimistic and scary
hunch that most SEs (and therefore significance tests) re-
ported in the journal articles that model correlation matrices
are probably wrong.
Cudeck, Robert. . Analysis of correlation matrices using covariance
structure models. Psychological Bulletin, 105. 317-327.
V1.C. IMPROVING MODEL FIT BY
CORRELATING ERRORS
In SEMs, the fit of a model can often be significantly im-
proved by explicitly allowing for additional error covariances
between manifest vanables in the measurement model. What
does this imply for interpretation of the resulting coefficients?
Professor Joseph Cote
Washington State University
It is widely known that SEMs are sensitive to model mis-
specification. In other words, changing the specification of
the model will significantly affect the parameter estimates.
As such, researchers must provide strong theoretical justifica-
tion for any parameter specifications. Otherwise, the change
in model specification may simply be capitalizing on chance,
making the parameter estimates meaningless.
The need for strong theoretical justification applies to all
structural and measurement parameters, not just correlated
errors. Although reviewers commonly do not question
changes in structural parameters (e.g., allowing correlation
among exogenous variables, freeing paths between endoge-
nous and exogenous variables, etc.), this does not relieve the
researcher fiom the burden of providing strong theoretical
justification. Conversely, reviewers often raise concerns
about k i n g correlated error parameters. As noted earlier,
their concerns are perfectly justified.
It is also true that strong theoretical justification can be
provided for specifying a correlated error (e.g., method
effects can be modeled as a latent construct or correlated er-
rors). As long as all model specifications (including corre-
lated errors) can be theoretically justified, then
interpretation of the parameter estimates is appropriate. If
any model specification (including structural relations) can-
not be theoretically justified, the interpretation of parameter
estimates is inappropriate.
This question raises a second concern that is not explicitly
stated. What constitutes a significant fit? The use of the
ch-square test for model fit has well-know limitations. Re-
searchers will commonly use one of several fit indexes apply-
ing a rule of thumb as a guide (e.g., normed fit index greater
than 0.90). There exists another severe, but less well-known,
problem with fit indexes. When there are a large number of
measures or constructs, it is not uncommon for fit to be de-
graded. It may well be that no amount of model modification
will yield an acceptable fit using standard approaches. In
cases in whlch models are very complicated (i.e., large num-
ber of measures and constructs), Carmines and McIver (1 98 1)
suggested the following:
Wheaton et al. suggest that the researcher also com-
pute a relative chi-squared (czldf). As they indicate, this sta-
tistic takes sample size into consideration in assessing good-
ness of fit. They suggest a ratio of approximately five or less,
"as beginning to be reasonable." In our experience, however,
chi-square to degrees of freedom ratios in the range of 2 to 1 or
3 to 1 are indicative of an acceptable fit between the hypothe-
sized model and the sample data. @. 80)
My experience indicates that complex models with fit in-
dexes in the 0.8 range would still meet the acceptability re-
quirements suggested by Carmines and McIver . I
would rather see an author make this argument rather than use
post hoc model modifications to get anormed fit index greater
than 0.9. However, if a reviewer or editor insisted on a nomed
fit index greater than 0.9, then I would consider apost hoc cor-
related error if the author could demonstrate that all other pa-
rameter estimates were unaffected by the change. The
stahility of the estimates would provide an inhcation that the
model was not purely capitalizing on chance.
Carmines, Edward G., & McIver, John P. . Unobserved variables. In
George W. Bohrnstedt & Edgar F. Borgatta (Eds.), Socialmemrement:
Current issues (pp. 1 1 1-130). Beverly Hills, CA: Sage.
Professor Richard Netemeyer
Louisiana State University
I restrict my answer to this question to cases involving
within-factor correlated measurement error. First, most ap-
plications of allowing for within-factor correlated measure-
ment errors (i.e., additional error covariances between
manifest variables) to improve model fit represent post hoc
adjustments . Thus,
the likelihood is high that this correlated error is sample id-
iosyncratic and may not replicate to other samples. Second,
although allowing for a correlated measurement error will
almost always improve fit, the researcher still may know
very little as to why such an error is present in the first
placethe reasoning for such error is likely speculative.
Third, measurement models that contain within-factor cor-
related measurement errors do not represent unidimensional
constructs. Some unwanted or unexplained sources of vari-
ance exist that were not specified a priori in the model. That
is, the covariation between a pair of indicators (items) has
not been adequately accounted for by the factors in the orig-
inal measurement model. This unwanted or unexplained
covariation could be due to many things (i.e., a methods
factor, respondent yea-saying, the presence of an unwanted
theoretical trait, etc.), but it still threatens unidirnensional
measurement. Thus, by allowing for within-factor corre-
lated measurement errors, the correspondence between the
construct of interest and its empirically determined factor
becomes unclear .
In sum, the use of within-factor correlated measurement
error to improve model fit should be viewed critically. There
will be few occasions where such error terms will be justi-
fied a priori and theoretically. In fact, several researchers ad-
vocate that a within-factor correlated measurement error
should not be employed unless (a) it is warranted on theoret-
ical or methodological grounds (e.g., correlating measure-
ment errors for the same indicator for the same constructs
for longitudinally collected data), (b) it does not signifi-
cantly alter the structural parameter estimates of a model,
and (c) it does not significantly alter the measurement pa-
rameter estimates of a model .
Gerbing and Anderson firher suggested that the strongest
emphasis be placed on the first condition.
Professor Peter Bentler
University of California, Los Angeles
Implied in your question is the simple answer-namely,
that there are additional sources of correlation in the vari-
ables beyond only the common factors that are part of the
measurement model. Stated differently, the model has
omitted some common factors, where each correlated er-
ror represents an omitted factor. (It will be difficult to
identify such factors with only two indicators per factor,
so the correlated error representation is a lot more reli-
able, as well as simpler to obtain, based on the Lagrange
Multiplier test, as I call it in my program EQS, or on
modification indexes.)
It seems reasonable to be suspicious of such correlated er-
rors primarily because of their post hoc status, which might
imply that they would not cross validate well, especially when
initially obtained fiom a small sample. (I do not worry much if
they are obtained in very large samples.) Aside fiom this rea-
sonable criticism, worry about correlated errors seems to me
to be overblown. It is very likely that in any domain, theory
will always be inadequate to exactly predict all sources of cor-
relation in data. For example, when building an instrument
with 20 items to measure a single factor, it may well be that a
very large general factor could largely explain the correla-
tions among the items. However, it probably would be fool-
hardy to expect that there are not minor sources of covariation
due to such things as common item wordings, item se-
quences, unanticipated minor factors, and perhaps violation
of continuity assumptions through the use of Likert scales.
Correlated errors will summarize such covariation. Do not
forget, however, that current methods are not good enough to
construct, post hoc, any omitted common factors that might
exist in such error correlations. If there are many correlated
errors, it may be best to go back to exploratory factor analysis
to check on the main latent sources of variance to cleanup the
measurement model.
REFERENCES
V1.D. SEM VERSUS ANOVA
Anderson, James C., & Gerbing, David W. . Structural equation mod-
eling in practice: A review and recommended two-step approach. Psy-
chological Bulletin. 103. 41 1-423.
Bagozzi, Richard P. (1 983). Issues in the application of covariance structure
analysis: A further comment. Journal of Consumer Research, 9, 44%
Fomell, Claes. . Issues in the application of covariance smcture anal-
ysis: A comment. Journal of Consumer Resemh, 9,443448.
Gerbing, David W., & Anderson, James C. . On the meaning of
within-factor correlated measurement errors. Journal of Consumer Re-
search, 11, 572-580.
Hoyle, Rick H., & Smith, Gregory T. . Formulating clinical research
hypotheses as structural equation models: A conceptual overview. Jour-
nal of Consulting and Clinical Psychology, 62, 429-440.
MacCallurn, Robert C., Roznowski, Mary, &Necowitz, Lawrence B. (1 992).
Model modifications in covariance structure analysis: The problem of
capitalization on chance. Psychological Bulletin. 11, 490-504.
A researcher proposes a conceptual model representing hy-
pothesized causal relations among a set of antecedent and
outcome constructs. An experimental study is undertaken in
which certain antecedents are both manipulated and mea-
sured. Outcomes are also measured. ANOVA on the manip
ulation checks reveals that the manipulations have the
expected effect on participants' responses to the antecedent
measures, thereby supporting the success of the manipula-
tions. In contrast, ANOVAs on the outcome measures reveal
that participants' responses to these are unaffected by the
manipulations. However, when the researcher uses causal
modeling analyses based on participants' responses to the
antecedent and outcome measures, there are significant path
estimates between the antecedents and outcomes. What
conclusions should the researcher draw about the hypothe-
sized causal relations? Is it appropriate to interpret the
correlational findings as supporting hypothesized causal re-
lations, despite the null effects observed for the outcome
measures in the experimental study?
Professor Joseph Cote
Washington State University
Oooh, h s is a good one! First, you must have faith that the
structural model is accurate. This is not something that should
be quickly assumed. It is well known that SEM is very sensi-
tive to model misspecification. As such, I would instantly
have some doubts about the LISREL estimates. At the same
time, it is possible that a true effect is not picked up by
ANOVA. By default, ANOVA reduces the available informa-
tion (converting interval data to categorical data). It is possi-
ble that ANOVA would miss a relation that would be
uncovered by LISREL. To be honest, a researcher would need
to look closely at the data to decide which approach was most
appropriate. I would also expect this situation to arise only
when the relations (explained variances) were relatively
small (even if statistical significance is very strong). If you
had a strong relation, the information reduction caused by
ANOVA would not affect the results. I should also note that
most researchers fail to report the variance explained when
fitting LISREL models. They simply assume that because sta-
tistical significance exists, relations are strong. This is simply
Professor Richard Bagoui
University of Michigan
Actually, in addition to the ANOVA and causal modeling
analysis, an analysis of the experimental data can be made as
well by use of SEM in an ANOVA design framework, but
where measurement error is taken into account. Doing so is
especially useful for multivariate analysis of variance
(MANOVA) contexts in which causal orderings are proposed
also among the dependent variables (DVs) and a type of
step-down analysis is to be conducted. A limitation of this ap-
proach in practice, however, is the need to have large samples.
The problem with a traditional causal model, as with path
analysis, is that the findings of the significant paths between
measured manipulations (e.g., manipulation checks taken on
interval scales) and outcome measures indicate only a linear
association between the variables. I am not sure, however, how
often the proposed discrepancy occurs in practice between
null effects under ANOVA and significant paths under causal
models. It is important to get at the bottom of the discrepancy.
One possibility is that so much error exists in the manipulation
as to inflate the denominator in the F test, but with multiple
measures of manipulation checks, it is possible to correct for
measurement error when doing the causal analysis.
Editor: Bagozzi's perspective on this issue is based on recent
work done by him and other researchers who have considered
a closer integration of the analysis of variance and SEMs . It
is important in translating an ANOVA problem into a SEM
framework, that the basics are not lost .
Bagozzi and Yi claimed the relative advantages
of SEMs over MANOVA include no restrictive equality of
covariance matrices across conditions, an opportunity to
correct for measurement error, and a more complete model-
ing of the theoretical relations among all the variables (p.
282). The relative disadvantages include less robustness to
possible violations of the assumption of multivariate nor-
mality, requirements of larger sample sizes, and more com-
plex models with larger numbers of parameters to estimate
increase in the likelihood of improper solutions and non-
convergence (p. 283).
There is another issue in the question that was posed-
the question implies that the researcher has conceptualized a
sort of process by which the manipulated variables are
thought to impact most immediately the manipulation
checks and then more distally the outcome measures, almost
as if the manipulation check variables are mediators. Per-
haps the experimental procedure lends itself to effects that
are that short lived; possibly the manipulation needs to be
stronger. (Its weakness may be indicated by effect size in-
dexes or relevant path coefficients.)
REFERENCES
Bagozzi, Richard P., & Yi, Youjae. (1 989). On the use of structural equation
models in experimental designs. Journal of Marketing Research, 26,
Cole, David A,, Maxwell, Scott E., h e y , Richard, & Salas, Eduardo.
 . Multivariate group comparisons of variable systems:
MANOVA and structural equation modeling. Psychological Bulletin,
114, 174-184.
Jaccard, James, Turrisi, Robert, &Wan, Choi K. (1 990). Interaction effects in
multiple regression. Newbury Park, CA: Sage.
V1.E. MEDIATORS AND MODERATORS
I have been looking into articles on mediating and moderat-
ing. The main citations appear to be Baron and Kenny 
and Sharma, Durand, and Gur-Arie . They say that to
STRUCTURAL EQUATIONS MODELING
show that C mehates the relation between A and B (A + C +
B), you have to model
1. B = bo + blA, and show that A (the IV) has a significant
main effect on B (the ultimate DV).
2. C= b2 + b d , and show thatA has a significant main ef-
fect on C (the mediator).
3. B = 64 + bsA + bsC, and show not only that C has a
main effect on B, but also that bs (the b coefficient for
A in Equation 3) is less than bl (the coefficient for A in
Equation 1).
One thing that they do not make clear is whether, in a mul-
tiple regression framework, these tests should be done indi-
vidually or as part of the whole multiple regression model. I
think that the tests should be done in the context of the whole
model, but because both articles deal with simple regression,
it is not clear, and in fact gives the impression that the tests
should be done separately and individually. For instance, sup-
pose I am predicting E using A, B, and C, and that I think D
mediates between B and E (i.e., A 4 E, B + D 4 E, and C +
E). It seems to me that I would model
4. E = 67 + b d + b9B + bloc, and show that, in the con-
text of (i.e., while statistically controlling for) the
other variables, B has a significant main effect on E.
5. D = bl I + blzB, and show that, like in Equation 2, the
focal IV has a significant effect on the mediator (or
should thls be, E = l$ + bi'A + 6
6. E = b13 + b14A + blSB + b16C + bl;lD, and show that,
even in the context of the other variables, D has a sig-
nificant main effect on E, and that 615 (for B here) is
less than b9 (B in Equation 4).
Anyway, if this is the right way to do it, I cannot find any-
one who says clearly that it is. Which means it would be
good to have it written down somewhere. And if it is the
wrong way to do it, then it is even more important to set peo-
ple like me straight.
Moderation issues appear just as tricky. Sharma et al.
(1 98 1) seem to be arguing for the following: To prove a mod-
erating influence of Con A's relation with B, you must model
7. B = big + b19A, to show a main effect for A.
8. B = b20 + b2 IA + b22C, and show no main effect for C
because if there was a main effect it would be an IV or
a "quasi moderator" but not a moderator.
9. B = b23 + bz4A + bZ5C+ b26A *C, and show an effect for
the A *C interaction, and a lower beta coefficient for A
in this equation (b24) than (b19) in Equation 7.
Therefore, they argued for inclusion of the main effect, which
I think a lot of people do not do. Second, what they actually ar-
gued in their article is not described in the way I have put it-
this is my interpretation of their notation, so here again I thmk
it is worth having a more definitive word.
While investigating these issues, I have come across two
Web sites on mediation and moderation that readers may
find useful: (a) David Kenny's site, 
-dakenny/causalm.htm; and (b) David MacKinnon's site,
 
REFERENCES
Baron, Reuben M., & Kenny, David A. . The moderator-mediator
variable distinction in social psychological research: Conceptual, stra-
tegic, and statistical considerations. Journal of Personality and Social
Psychology, 51, 1 173-1 182.
Sharma, Subash, D m d , Richard M., & Gur-Arie, Oded. (198 1). Identifica-
tion and analysis of moderator variables. Journal of Marketing Re-
search, 28, 291-300.
Professor Donald Lehmann
Columbia University
Tests for mediation and moderation are widely employed,
usually in a formulaic manner. However, these tests are only a
means to the goal of developing a causal understanding of a
phenomenon. Thus, before discussing such tests, three points
seem relevant: (a) Both issues deal with proper specification
of a simultaneous equation (structural) model. Correct speci-
fication involves a blend of theoretical and empirical issues.
Whether one concludes that a particular relation exists de-
pends on the strength of the priors, not just statistical signifi-
cance in the sample. (b) Mediation and moderation are
logically continuous constructs. Thus, the real question is
about degree, not whether or not. (c) Although the term mod-
erate implies a lessening of an effect, hlgher levels of one
variable can lead to greater (or lower) effects of another. Thus,
a better term would be alter
The simplest way to consider mediation and moderation is
in the context of simple graphical models (Figure 2). In Case
A, themodel posits thatxaffects 2. Model B adds asecondpre-
dictor, I: Model C assumesxaffects Zonly indirectly through
its effect on Y (i.e., X s effect on Z is fully mediated by Y).
Model D assumes the effect of YonZis affectedor altered (i.e.,
moderated) by the level of W Model E assumes both mediation
(of Y on X) and moderation (of Won Y). Finally, Model F as-
sumes the effect of X on Z is partially mehated by Y:
If the assumed model is simple until proven otherwise (the
common scientific practice of parsimony even though the op-
posite may be true), then llnks are added only when they ex-
plain significant additional variation. That means we begin
with the simple models and add terns. For example, to Model
B, Z= bo + bl Y+ bzX+ e, we add b3 (corresponding to the inter-
action term Win Model D) to see if Wmoderates the effect of
Yon Z. The test then becomes whether b3 is significantly differ-
STRUCTURAL EQUATIONS MODELING
D. Modmtcd (htauted) Model:
Z=b,+b,Y+bgr+b,o+c
FIGURE 2 DepictingMerent modelstorepmmtcaudstructms.
ent from zero, or equivalently, if adding the variable signifi-
cantly increases the variance explained (i.e., R2); that is, if
Model D significantly outperforms Model B . Notice this says nothing
about how the size of the direct (main) effect of Yon Zchanges;
it can stay the same, increase, or decrease, which is largely de-
termined by the coding scheme used.
Similarly, mediation requires two conditions. First, Xmust
impact Y (i.e., cl # 0 in Model C). Second, the direct effect of
XonZdecreases when we add Yto themodel (i.e., b2 in Model
B is less than a1 in Model A).' Thus, mediation requires that
both direct and indirect (through Y) paths exist from X to Z
and that the direct path in this model be weaker than the sim-
ple direct effect of Xon Z (i.e., in Model A).
If there are a number ofpossible moderators (interactions),
then two approaches are possible. First, one could add inter-
actions one at a time and separately test for their significance.
This makes sense if each has some theoretical support (i.e., a
priori expectations of nonzero interactions). On the other
hand, if we return to the simple until proven otherwise posi-
tion, then some of the interactions may appear to be signifi-
cant due to chance (e.g., 1 out of 20 at the .05 level).
Therefore, amore conservative procedure is to test for the im-
'For readers familiar with Baron and K a y . it may be easier to
think of the b2 in Model F as that which becomes insignificant, or at least less
provement due to the inclusion of the set of interactions as a
group (i.e., in a nested model F test). Then, only if the set of
interactions is significant does one examine individual terms.
It is important to notice that tests of both mediation and
moderation are influenced by collinearity among predictor
variables. In mediation tests, the original and mediator vari-
ables are correlated (inourexample,Xand Y), whichmakes es-
timation of the separate effects ofX and Y less reliable (and
hence, tests to prove they are nonzero more difficult). The
problem is even worse for moderation tests. Whereas in medi-
ation analyses we expect thatXand Y should be correlated, the
correlation between Y and W i s basically an inevitable incon-
venience. (The problem gets worse ifmultiple interactions are
tested simultaneously because Y, W I , W2, etc., all share a
common element.) Therefore, various coding schemes (i.e.,
effect codmg) are often employed to reduce the problem.
In running tests for mediation and moderation, also keep in
1. Moderator analysis focuses on whether a particular
known and measured variable influences the effect of one
variable on another. When the moderator represents differ-
ences in participants, the issue is whether the effect is constant
across all observations (e.g., participants). In many situations,
heterogeneity in response is not well explained by the readily
available variables (e.g., demographics). Thus, other means
of exploring participant heterogeneity in response (e.g., clus-
ter or latent class analysis) may be hitfbl.
2. Treating moderation or mediation as a yes-no question
leaves out a lot of information. Not only is statistical signifi-
cance ofp = .05 1 not very different from p = .049, but the p
value itself is easily manipulated (i.e., by increasing sample
size). Therefore, a more continuous measure that concen-
trates on the size ofthe effects seems preferable. For example,
J simple index of mediation comparing a1 in Model A to bz in
Model F is (a, - b2)lal. Assuming a1 and b2 are positive and b2
is less than al, this index ranges fiom 0 (complete mediation)
to 1 (no mediation).
3. Mediation tests derive directly from the principles of
path analysis . Specifically, we
can compare a simple model of X to Z (Model A) to a
two-equation model in which, in the first equation,Xaffects X
and in the second, Y affects Z(Mode1 C). If the effect ofXto Z
can be explained by the product of the effect ofXon Y and Y
on Z(i.e., a1 = a h ) , then there is no need for (nor evidence of)
a direct link from X to Z. (In this simple case, that result is
equivalent to having r, = (r, )(r,).)
REFERENCES
Asher, Herbert B. . Causal modeling. Beverley Hills, CA: Sage.
Baron, Reuben M., & K a y , David A. . 'Ibe moderator-mediator
variable distinction in social psychological research: Conceptual, sba-
tegic, and statistical considemtiom. Journal ofPersonaii~ and Social
Psychology, 51,1173-1 182.
Blalock, Hubert M., Jr. . Causal inferences in non-experimental re-
search. Chapel Hill: University of North Carolina Press.
Lehmann, Donald R., Gupta, Sunil, & Steckel, Joel H. . Marketingre-
search. Reading, MA: Addison-Wesley-Longman.
Professor Roderick McDonald
University of Illinois
I think the best way to discuss the question of detecting or
showing moderation or mediation in a regression is to set
aside the entire literature on these topics and start from
scratch. First, consider moderation and the regression equa-
tion for the interaction model:
where Y is a (random) response variable, X and Z are explana-
tory variables-fixed
or random, quantitative or categorical-
and e is a residual. Standard texts such as Neter, Wasserman,
andKutner told us how to fit the regression, get SEs for
the coefficients bo, 61, bz, and b3, and use these to get confi-
dence bounds and test the parameters for significance-for
those who, unllke me, still believe in significance tests . Not all texts on the linear
model tell us this, but it is not necessary to distinguish cases in
which the explanatory variables are random or fixed (when ob-
served, they are no longer random), or, as Baron and Kenny
 do: to hstinguish quantitative (continuous) and cate-
gorical IVs. IfXand Yare highly correlated, this makes aprob-
lem for the naive computation ofthe SEs of bl and b2, but ifwe
fit the interaction model with X and Z measured fiom their
means, thenXZis uncorrelated (by construction) with Xand 2,
so the SE of b3 is trustworthy and there is no problem, except
the unavoidable judgment, deciding whether it is significant
andnon-negligible-that is, whether we have a departure from
additivity of the effects of X and Z.
If we chose to rewrite the regression as
we might be tempted to say that the moderator variable Z al-
ters the regression coefficient [bl + b34 of Yon the explana-
tory and IV X. If we chose to rewrite it as
we might be tempted to say that the moderator variable X al-
ters the regression coefficient [b2 + b f l on the IV Z. As I see
it, both temptations should be avoided, thus avoiding the
whole collection of reifications and misconceptions that ap-
pear to constitute the literature on moderator variables. An in-
teraction is a departure from additivity of effects that is
symmetric in the explanatory variables.
There also seems to be some confusion in the literature you
cite about moderating a regression and moderating a correla-
tion. Using graduate school algebra of expectations, we easily
find that the squared correlation betweenxand Yis given by
and, symmetrically, the squaredcorrelation betweenzand Yis
so, we can say that if the effects are not additive, then each
IV moderates the correlation of the DV with the other.
However, why complicate the obvious? An interaction is
an interaction is an interaction, as Gertrude Stein would
have put it.
However, there is a complication deserving remark.
Finding that one explanatory variable alters the correla-
tion of the response with another does not necessarily
imply the interaction model. It could be that in the sim-
the error variance of Y is a function of some variable Z. (This
is only one of many models invoking control of heterosce-
dasticity or types of nonlinearity giving rise to a dependence
of correlations on other measures.)
My recommendation is that, hst, fit the model in Equation
1 to check for nonadditivity, measuring each variable from its
mean. Do not call the nonadditivity moderation of either by
the other. Second, do residual plots if you suspect hetero-
scedasticity caused by a variable included in your data and try
to find a suitable model for it, but do not expect it as an every-
day occurrence in research.
Now we turn to mediation. Again, I do not follow the con-
ventional wisdom offered in the references you cite, although
I do not reject the term. First, we recognize the following
rather grim reality: It is a truism ofpath analysis, dating back
to Sewell Wright 
that if the partial correlation of X with Y when Z is partialled
out is zero, then possibly (a) Xdirectly causes Zand Zdirectly
causes Y, butXhas no direct effect on Y; (b) Ydirectly causes Z
and Zdirectly causes X, but Y has no direct effect onX; and (c)
Zdirectly causes bothXand Y, andXand Yhaveno othercom-
mon cause. We may feel we can rule out (c) on good theoreti-
cal grounds. I have seen few good examples of this, even
when we have a clear time order, because the measures may
reflect a developmental process or a state stable over time, so
that "post" has nothing to do with "propter." Ifwe can rule out
STRUCTURAL EQUATIONS MODELING
(c), we may say that Z mediates between X and Y in one direc-
tion or the other.
It is well known, though commonly not mentioned in the
texts on SEM, that for model (a), separately fitting the two re-
gressions (a) Z on X and (b) Yon Z, is equivalent to fitting the
full model with SEM software by maximum likelihood (but
not by least squares, curiously enough), and that testing the
partial correlation pxyz is equivalent to testing fit of the full
model. In fact, the simple regression and partial correlation
procedure has small sample properties that the clever SEM
approach lacks. Therefore, you can get the effect sizes by re-
gression and test mediation-the
channeling of causality
through Z-by
partial correlation, a s h g if the partial corre-
lation is significant or, better, if it is approximately zero, just
using Fisher's transformation as in the elementary accounts
of testing correlations. Nothing fancy is needed.
However, the idea of looking for a mediation over and
above a nonnegligible direct effect, as in the question, seems
to me very dangerous-with
or without theoretical elimina-
tion of model (c). It is a truism of path analysis that the model in whlch Xboth directly causes
Y and indirectly causes it through Z is just identified and
unrestrictive, fitting every data set perfectly. It is not distin-
guishable by data from the very large number of other nonre-
strictive models for three variables. If we know so very much
that we can rule out all the other models, we can fit the model:
either by a SEM program or by the two regressions. The di-
rect effect ofXon Y is b9. This is the conjectured change in Y
if we could control Xand increase it by one unit while hold-
ing Z constant. The total effect ofX on Y through the causal
chain X + Z + Y (the conjectured change in Y if we could
make Xincrease one unit and allow both Zand Y to change as
a consequence) is (b9 + b7b10). Some writers then define an
indirect-mediated effect as the difference between the total
effect and the direct effect ofXon Y. I prefer not to, because
this does not correspond to a reasonable thought experi-
ment. A
super-confident investigator may not only do this, but com-
pare the indirect effect (67610) with the direct effect b9 and
claim that the indirect effect-which
can be negative, tend-
ing to cancel the direct effect-is
in some sense non-negligi-
bly greater than or less than the direct effect. This supposes
more substantive knowledge than I find available in the path
analyses that come to me as a consultant.
Note that there is no need to follow the advice you quote
that we should also fit
because by SEM theory we know that the total effect,
b; = b9 +b7b10, is already given by just Equations 7 and 8.
 Note also that whether b9 is less than or greater
than bi depends on the sign pattern of b9, b7, and blo, so I be-
lieve the advice you cite is simply incorrect. Perhaps the con-
clusion is that mediation in regression models should not be
cut loose &om the more general concepts of SEM. And note
that the only thing tested in a path model is the vanishing of a
handful of partial correlations and is almost always consistent
with many plausible alternative models . Failure to recognize this fact is allowing the prolifera-
tion of a confident but weakly supported collection of empiri-
cal SEM studies.
REFERENCES
Bollen, Kenneth A. (1 989). Structural equations with latent variables. New
York: Wiley.
Duncan, Otis D. (1 975). Infroduction to structural equation modeling. New
York: Academic.
Harlow, Lisa, Mulaik, Stanley A., & Steiger, James. (Eds.). . What if
there were no significance rests? Mahwah, NJ: Lawrence Erlbaum As-
sociates, Inc.
MacCallum, Robert C., Wegener, Dwayne T., Uchino, Bert N., & Fabrigar,
Leandre R. . The problem of equivalent models in applications of
covariance sbucture analysis. Psychological Bulletin. 114. 185-199.
McDonald, Roderick P. . Test theory: A unified treatment. Mahwah,
NJ: Lawrence Erlbaum Associates, Inc.
Neter, John, Wasserman, William, & Kuhler, Michael H. . Appliedlin-
ear statistical models. Chicago: Irwin.
Professor Joseph Cote
Washington State University
The steps outlined for mediating effects are essentially cor-
rect. However, the outline suggests looking at the coeffi-
cients. This is improper. You must look at the change in R2.
The reason for h s is that mediators may cause collinearity
problems. The collinearity will affect the regression coeffi-
cients in unpredictable ways, making them inappropriate in-
hcators of significance. Compare the change in R2 in
sequence. Fit the following three models (assume D moder-
ates relations between E and B):
To test for mediating effects, the size ofR2 values should be as
follows 3 2 2 > 1. Note that the R2 for Equation 3 can be equal
to the R2 for Equation 2 because D may completely moderate
the effects ofB. Of course, the empirical test is only relevant if
a strong theoretical case can also be made.
The procedure outlined for testing moderating effects is es-
sentially correct. However, as with mediators, you cannot use
the beta coefficients to test them. With interaction effects you
STRUCTURAL EQUATIONS MODELING
dehitely have collinearity problems. As such, the beta values
are unstable in unpredictable ways. I would test for moderat-
ing effects in the following manner. First, fit the following two
models (assumes D moderates the relation between E and B):
To test for moderating effects, the R* for Equation 5 is
greater that Equation 4. It is perfectly acceptable to then fit a
thud equation.
D can still have a direct effect on E in addition to the moderat-
ing effect. In this case, R2 for Equation 6 is greater that Equa-
tion 5. Note that because of collinearity problems, any of the
coefficients fiom Equation 5 may now be lower or insignifi-
cant (including interaction effects). However, this does not
mean that an interaction does not exist. Again, because of
collinearity problems, the beta estimates are unstable and un-
predictable. Only the R2 remains unaffected by collinearity. It
is also important that strong theory accompany tests for mod-
erating effects. Because of collinearity, the interaction term
may sufficiently model a direct effect of D.
Professor Timothy Heath
University of Pittsburgh
It is an additional challenge to test mediation and moderation
in the context of other model terms. The inclusion of one pre-
dictor or set thereof affects tests of other predictors, so the
choice of which predictors and terms to include in regression
models is one of the more fundamental decisions a researcher
can face. When making such decisions, sensitivity to at least
three types of relations within predictors is required: The first
is mediation, where one predictor causes another predictor,
which then causes the DV. The second is confounding, where
predictors covary for reasons other than predictor-to-predic-
tor causation. And the third is moderation, where the effect of
one predictor on the DV depends on (and varies across) levels
of another predictor. I discuss mediation and confounding in
response to a question on the former because both involve pat-
terns of collinearity. I then address the moderation question
that asks whether it is necessary to test a given interaction
(product) term in the context of its constituent main effects.
These questions appear to be related because each involves
the effect of some model terms on tests of some target effects,
but despite a surface similarity, mediation and moderation in-
volve different statistical tests and vastly different underlying
causal models .
In this response, I limit myself to major issues involved in
simple ordinary least squares (OLS) applications. For
in-depth treatments of path analyses and moderation tests in
multiple regression, readers are encouraged to consult the fol-
lowing sources: applied regression and research texts devoted
to causal assessments such as Cohen and Cohen ,
Pedhazur (1 982), Cook and Campbell (1 979), and Judd and
McClelland ; econometrics texts such as Johnston
 , Judge, Griffiths, Hill, and Lee , and Maddala
 ; causal modeling books such as Blalock ,
Bagozzi (1 980), and Davis (1 985); and books addressing tests
of moderation in multiple regression such as Aiken and West
 and Jaccard, Turisi, and Whan .
As per the question, Baron and K e ~ y
 stated that to
show that Wmediates the relation betweenxand Y(X+ W+
Y), you have to demonstrate the following:
and show that Xhas a significant main
effect on Y,
and show that Xhas a significant main
effect on K
and show not only that W has a main ef-
fect on Y, but also that Xs coefficient
drops significantly relative to Step 1
(preferably to nonsignificance).
If we are predicting Y using Xand Z and we think Wmedi-
ates between Xand Y, should we include additional predic-
tors (here, Z) in all of the submodel tests, or should we
eliminate them?
In this example, Xis our primary predictor, whose effect is
proposed to go through W, our hypothesized (causal) media-
tor. Z is a confound or error control. We might include Z to (a)
make sure that X does not receive undue credit for causing Z
(i.e., an X + Y relation arising only because X is correlated
with the actual cause, Z) or (b) to reduce error variance and
thereby increase sensitivity to X's effects. As we will show,
there is no statistical distinction between Z and W, which, by
OLS, are treated essentially as covariates, but the interpreta-
tions of their effects diverge in important ways.
There are two general responses to this initial question.
First, models that add a potential medator (W)
to assess its
impact on the X 4 Y coefficient should retain all predictors
from the original model testing the X+ Y coefficient (e.g., Z)
lest changes in X s coefficient arising fiom the omission of
those variables be mistakenly attributed to the inclusion ofthe
mediator. Second, the models used to test mediation depend
on the researcher's a priori beliefs and goals. If there is reason
to believe that the true effect ofXon Y is that which exists after
removing any potential effect of 2, then Z should be included
in all models.
If, on the other hand, the researcher is not sure what pattern
of variances best reflects X's effect on Y, the safest tack is to
include Z in all models because inclusion would be consistent
with conventional wisdom and popular path analytic ap-
proaches. The rationale is that the best specification is the one
that includes all potentially relevant variables to (a) maximize
statistical power by reducing error and (b) account as thor-
oughly as possible for potential collinear or confounding rela-
tions. In practice, therefore, researchers commonly test
STRUCTURAL EQUATIONS MODELING
mediation with packages such as LISREL and EQS in which
numerous facets of the underlying measurement and smc-
tural models are estimated simultaneously. Hence, there is
ample reason for adapting Steps 1 through 3 to broader-based
models in the following manner, where Z can be thought of as
either a single predictor or set thereof
to show that when extracting the
variance in X and Y that is shared
with other variables (Z),
remain associated significantly,
to show that when extracting the
variance in X and W that is shared
with other variables (Z), Xand W
remain associated significantly,
Y=h(X, KZ)
to show that when extracting the
variance in X, Y, and W that is
shared with other variables (Z),
not only that W is significantly as-
sociated with Y, but that the X+Y
association becomes significantly
weaker relative to Step 1' (prefexa-
bly becoming nonsignificant).
However, in in
these in which mm~~hers
are not certain
which patterns of shared miawe with Y best reflect the causal idu-
ences ofX, K and Z, meamhers may wish to report more thorough
medmtion tests. The reason is & despite themcation for includ-
ing Zin all models, inclusion risks dating the ambiguity already in-
herent in the stalktical controls & anchor most tests of m&m
Consider the following patterns and &eqn&hons when we control
for Z (as a potential c o n f i ) either experimentally or statistically.
Naiure of Means of Control for Z
Evidence of X+Y
Experimentally Con-
Statistically Con-
relationship
trolling Z (Manipu-
trolling for Zs Ef-
late X and Z
fects (Measure Z
Orthogonally)
and Extract the
Variance It Shares
With X and Y Be-
fore Estimating the
X+Y Association)
If evidence of X s effect
A. Xprobably has an
B. Xprobably has an
(e.g., a significant
X+Y association)
persists when con-
trolling for Z
If evidence of X s effect
C. Xprobably has no
D. Xmay or may not
(e.g., a significant
have an effect; the
X-tY association)
X+Z confound is
disappears when
not disentangled
controlling for Z
"The word effect here refers to a true causal influence rather than some em-
pirical estimate of that influence. The phrase "Xprobably has an effect" is ap-
plied to both statistical and experimental controls, although the probability
that statistical significance reflects an actual causal effect is greater in the
context of e x m e n t a l controls, assuming that random selection and ran-
dom assignment mitigate confounds that might arise when Xis measured
rather than manipulated.
Two forms of ambiguity arise in Case D where, given the
confounding, there is no way of knowing whether, or to what
degree, the X-Ycovariance shared with Z is due to X+ Y cau-
sation. This problem is illustrated in the Venn diagram in Fig-
ure 3, where each circle represents the unit variance of a
hypothetical variable (variance scaled to 1 .O) and where over-
lapping regions represent shared variance (e.g., r2). In a stan-
dard OLS run, X s effect is tested by taking the region of
shared variance between Xand Y that is not shared with other
predictors and comparing it with error (variance in Y shared
with no predictors). This tests whetherxs contribution to the
overall model R2 has a unique component that itself is statisti-
cally significant. To be conservative, if this unique compo-
nent is not significant even though the bivariate X-Y
correlation is, the rule of thumb is to conclude thatXhas no ef-
fect on I: In reality, however, this data pattern is ambiguous
with respect to X's causal role because we do not know what,
if any, proportion of the nonunique X-Y covariation arose
from X + Y causation.
The second source of ambiguity takes the form of inter-
pretive license granted to Case D. If we assume that the other
criteria for mediation in Steps 1 ' through 3' are met (e.g., r,
given W is statistically significant), we would conclude the
following when adding either Z or W to the model:
1. E: If evidence of an X-Y association &sappears when
X has no real effect.
2. F: If evidence of an X-Y association disappears when
adding fl X has an effect, but it is mediated by K As is widely
known, but sometimes overlooked, the data cannot distin-
guish one model fiom the other, where researchers are al-
lowed to draw diametrically opposed conclusions depending
on their preferred theory. (The previous patterns are consis-
tent with various other models as well such as that in which Z
causes both X and I:)
These two sources of ambiguity are amplified when they
exist together in a single model in which one set of statistical
controls is included for potential confounds (or error reduc-
tion) and another set is included for potential mediators. In
Figure 2, for example, consider how our estimates of Ws po-
FIGURE 3 Venn diagram of unit variances among four hypotheti-
cal variables. Vis the DV, Xis the predictor, W is the predictor and po-
tential mediator ofX+ Y, andZis the"other" predictor orpredictors.
STRUCTURAL EQUATIONS MODELING
tential mediation change when we include Z to control for po-
tential confounding effects:
Without Z in the Models
With Z in the Models
1. Xaffects Y
1. Xaffects Y
2. Xaffects W
2. X does not affect W
3. W affects Y
3. W does not affect Y
4. Most (roughly 70%) of X s effect can be
4. None of X s effect can
accounted for by
roughly the area
be accounted for by W
An WnY divided by the area XnY
Both models support X as an important predictor of Y
However, the first suggests that most of this effect is mediated
whereas the second suggests none of it is. The incon-
gruity arises fiom the fact that including Z adjusts for poten-
tial confounding between Z and X, Z and
and therefore Z
and the covariation between X and K In the case depicted in
Figure 2, Zcan account for virtually all of the shared variance
between X and Wand thereby eliminates the evidence of W
mediating role. Conventional wisdom would suggest that we
include Z and conclude that there is no evidence of a X + W
+ Y path. Our intuition, however, suggests caution here be-
cause limiting our tests to mediation ofXs unique component
(unique fiom Z) ignores roughly half ofXs potential effect on
Y, the halfthat might be mediated by K Although it is unllkely
(though possible) that collinearity arising fiom a single addi-
tional predictor would produce such a result, the probability is
much higher when we include numerous additional predic-
tors, as has become common in marketing in whlch large sur-
veys and increasingly detailed databases inflate the chances
of multicollinearity .
Finally, X may not have an effect until Z is added to the
model, where Z is referred to as asuppressor variable (an X-Z
correlation suppresses the bivariate X-Y correlation). Sup-
pression can exist for any variable in the theorized causal
path, so the validity of standard path analytic tests is threat-
ened at every level of the path by both the inclusion and exclu-
sion of relevant predictors (potential confounds and
suppressors, respectively).
The number of possible patterns and the degree of poten-
tial ambiguity grows exponentially as we add predictors.
However, researchers can simplify their assessments by not
testing the effects of each additional predictor separately, but
by testing them simultaneously. Given the multiple sources
and general pervasiveness of ambiguity in tests of mediation,
researchers are encouraged to provide a thorough report of
mediation-relevant data patterns. Specifically, there are four
suggestions:
1. Exercise extreme care in justifling a priori the theory
and the constructs needed to test it. Given the correlational na-
ture of the data, rarely will the data themselves discriminate
between competing models, especially without experimental
controls that could anchor causal direction . The logic of the underlying theory will then determine
the study's contribution as much as will the associated data.
Researchers might justify each measure, construct, and
path included in the model, indicating the role of each to (a)
test a potential cause, (b) control for a potential confound, (c)
uncover an effect masked by suppression, (d) reduce error
variance, (e) test for mediation, and ( f ) test for moderation. It
would also be usefkl to discuss things omitted fiom the
model: (a) potentially relevant constructs and what their roles
might be (confound, suppressor, error reducer, etc.) and (b)
causal paths among constructs included in the model and why
we should believe they do not exist. Addressing both the in-
clusion and exclusion of constructs and effects might require
an appendix to mitigate length, but researchers might do so
because this rationale will discriminate one competing model
from another as much, and perhaps more so, than will any
given pattern of data.
2. Publish the correlation matrix for all endogenous and
exogenous indicators and constructs, preferably with
covariances above the diagonal. Doing so allows readers to
evaluate the raw bivariate associations uncontaminated by
other variables. Researchers may also want to print path coef-
ficients as well as bivariate correlations in their path diagrams
 .
3. Report two sets of mediation tests, one based on com-
plete models and one based on single-path-only models
(those that address only the variables involved of the focal
causal path). For example, a single-path-only model that con-
sists ofX, K and Y can be thought of as a raw trivariate associ-
ation uncontaminated by other variables. The results of
single-path-only and complete models will concur when nei-
ther collinearity nor multicollinearity are substantial.
4. State supporting results in an unbiased fashion. Al-
though popular phrases such as "the data are consistent with
our model" are accurate at a literal level, they risk misleading
readers by implying (through omission) more empirical sup-
port than that found. The question arises as to whether the data
are equally consistent with other models that may also be de-
fendable theoretically. The bias toward confirmatory evi-
dence is ubiquitous and difficult to irradiate even among ex-
perts . To combat this bias,
researchers might use phrases that are not only linguistically
accurate but that inform as well (e.g., the data are consistent
with this model as well as the following models, the data are
not inconsistent with our model or with others, etc.).
REFERENCES
Aiken, Leona S., & West, Stephen G. . Multiple regression: Testing
and inteipreting interactions. Newbury Park, CA: Sage.
Bagozzi, RichardP. . Causalmodelingin marketing. New York: Wiley.
Baron, Reuben M., & Kenny, David A. . The moderator-mediator
variable distinction in social psychological research: Conceptual, stra-
tegic, and statistical considerations. Journal of Personalip and Social
Psychologv, 51, 1173-1 182.
STRUCTURAL EQUATIONS MODELING
Bateman, Thomas S., &Zeitharnl, Carl P. . The psychological context
of strategic decisions: A model and convergent experimental findings.
Strategic Management Journal, 10, 59-74.
Blalock, Hubert M. . Causal models in the social sciences. Chicago:
Cohen, Jacob, & Cohen, Patricia. (1 983). Applied multiple regression/corre-
lation analysis for the behavioral sciences. Hillsdale, NJ: Lawrence
Erlbaum Associates, Inc.
Cook, Thomas D., & Campbell, Donald T. . Quasi-experimentation:
Design and analysis issues forfield settings. Chicago: Rand McNally.
Davis, James A. (1 985). The logic ofcausal order. Newbury Park, CA: Sage.
Heath, Timothy B. . The logic of mere exposure: A reinterpretation of
Anand, Holbrook, and Stephens . Journal of Consumer Re-
search, 17.237-241.
Jaccard, James, Tunisi, Robert, & Wan, Choi K. . Interaction effects in
multiple regression. Newbury Park, CA: Sage.
Johnston, John. . Econometric method. New York: McGraw-Hill.
Judd, Charles M., & McClelland, Gary H. . Data analysis: A model
comparison approach. San Diego: Harcourt Brace Jovanovich.
Judge, George G., Griffiths, W. E., Hill, R. Carter, & Lee, Tsoung-Chao C.
 . The theory andpractice of econometrics. New York: Wiley.
Law, Sharmistha, Hawkins, Scott A,, & Craik, Fergus I. M. . Repeti-
tion-induced belief in the elderly: Rehabilitating age-related memory
deficits. Journal of Consumer Research, 25, 91-103.
MacCallum, Robert. . Specification searches in covariance structure
modeling. Psychological Bullerin, 100, 107- 120.
Maddala, G. S. . Econometrics. New York: McGraw-Hill.
Mason, Charlotte H., & Perreault, William D. . Collinearity, power,
and interpretation of multiple regression analysis. Journal ofMarketing
Research, 28, 268-280.
Pedhazur, Edward J. . Multiple regression in behavioral research.
New York: Holt, Rinehart, & Winston.
Julie Irwin
University of Pennsylvania
The second part of the question raises issues regarding testing
moderation (interactions). Some excellent books have been
published on the subject, and we do not attempt to duplicate
their thoroughness here . However, it
may be useful to present a short tutorial on the interpretation
of regression coefficients when interactions are and are not
included. All of these arguments hold equally well for other
nonlinear equations .
The terms moderator effect and interaction are used some-
what interchangeably. The term moderator typically is in-
voked when the researcher wishes to focus on one component
of an interaction. The research question of interest is whether
this variable's effect on the DV is changed (exacerbated or
moderated) by the level of the other component of the interac-
tion. Statistically, though, this focus is irrelevant; interactions
are symmetrical in the sense that they affect both components
of the product term and may be interpreted from either per-
spective; if Zmoderates X's effect, then so too does Xmoder-
Regarding the interpretation of regression coefficients,
suppose one is interested in the relation between DV Y and
predictor variables X and Z. The following models are of
potential interest:' Model A, Y = bo + blX. The coefficient
bl tests if there is a relation, overall, between X and Y.
Model B, Y = bo + blX + b2Z. The terms b, and h are partial
regression coefficients that test the effect of one variable when
controlling statistically for the other. The bl slope will remain
unchanged fiom Model A if there is no redundancy (colline-
arity)2 between X and Z, although its statistical significance
may change due to reduced error variance. Neither bl nor h
tests whether there is an interactive relation between X and Z,
so it is not necessary to show that b2 is not statistically signifi-
cant or that bl is, to establish moderation.
Model C, Y = bo + blX + bzZ + b$
x Z. This model in-
cludes an interaction term, and the interpretation of all of
the coefficients is affected, in ways that may seem
counterintuitive. In fact, researchers appear to apply
heuristics learned from additive regression to regression
with an interactive term, often with misleading results
 . The coefficient bl tests the ef-
fect ofXon YwhenZequals 0, and b2 tests the effect ofZon
YwhenXequals 0. An algebraic reformulation ofthe previ-
ous equation makes clear why this is so:
The b1 test is not equivalent to the main effect test of the effect
ofX on Y, and to avoid confusion with the main effect test, re-
searchers sometimes use the termsimple effect instead ofmain
effect . Note
that the bl effect is the test when Z is zero, even if zero is not a
meaningful value for Z to take (e.g., if Z was measured on a
Likert scale ranging from 1 through 7). On the other hand, the
variables may be linearly transformed so that zero is a useful
value and the bl test is meaninghl . For instance, if the vari-
ables are mean centered (i.e., the mean is subtracted from each
value), bl tests the effect of X on Y when Z is average. If Z is
symmetrically distributed, this test will be essentially equiva-
lent to the main effect ofXon Z. By extension, contrast coded
variables with a mean of zero will induce tests essentially
equivalent to main effects tests in ANOVA. The main point is
that in additive multiple regression lacking interaction tenns,
any linear recoding of variables does not change the coeffi-
cients' values or interpretations. With interaction terms, how-
ever, coding becomes important. Regardless of 2's effect
'By convention, the same coefficient is used for a given predictor across
models, with the understanding that the interpretation of the coefficient can
vary across models.
2It has recently been shown that collinearity among predictors in
fact increases the power to detect interactions (McClelland & Judd,
STRUCTURAL EQUATIONS MODELING
(simple or moderating), adding an interaction term can change
b depending on how Zis coded and the meaning of zero on that
scale. A change in b~ (or b2) from the simple additive model
(Model B) to the model with an interaction term (Model C) has
no bearing on whether there is a moderating effect of Z.
The partial regression coefficient on the interaction term is
the only indication of whether there is amoderator effect. If b3
is significant, then the effect ofXon Y is different at different
levels ofZ. Likewise, the relation between Zand Y is different
at different levels ofX. These conclusions hold regardless of
whether b1 or b2 is statistically significant.
Occasionally, researchers attempt to test for interaction ef-
fects without including the components of the interaction in
the model (the main effects). For instance, they may test the
following reduced model instead of the full Model C:
This product-only model is problematic because the coeffi-
cient (64) on the product term is not invariant over linear trans-
formations ofXand Z. Except for very special circumstances,
b4 will not be equal to the fill model's b3.
The importance of including component terms (i.e., Xand
Z) when testing interactions (X*Z) has been addressed in
depth elsewhere . In brief,
multiplying X by Z introduces scaling artifacts that are re-
solved by including in the model separate effects for each of
the interaction's components. For example, suppose that X
and Ywere coded in larger units than Z (e.g., Xand Y in dollars
andZin decades). The simple relations (i.e., nonpartialed cor-
relations) between the product term X*Z and the variables I:
X, and Z would be affected by these scaling differences. Most
important for our purposes, there would be a scale-driven re-
lation between Yand X*Z. Including the components of an in-
teraction in the model removes scaling artifacts and leaves us
with the test we desire: a product term that tests whether the
slope of Yon X depends on the level of Z regardless of scale.
Note that the b3 test (the moderation test in the full model) is
invariant over linear rescalings ofXand Z, as it should be. The
bottom line is that the reduced (product-only) model is not ac-
ceptable because it fails to provide a scale-independent test
for changes in the X-Y and Z-Y slopes across levels of the
other predictor. More generally, therefore, to ensure valid
tests of higher order effects, lower order effects should be in-
cluded in the model. Readers may also find interesting
Henderson and Velleman (1 98 I), LeClerc and Little (1 997),
Lynch , and Sharma, Durand, and Oded .
REFERENCES
Aiken, Leona S., & West, Stephen G. . Multiple regression: Testing
and interpreting interactions. Newbury Park, CA: Sage.
Burks, Barbara S. . On the inadequacy of the partial and multiple cor-
relation technique. Journal of Educational Psychology, 17,532-540.
Burks, Barbara S. . Statistical hazards in nature-nurture investiga-
tions. In M. Whipple (Ed.), National society for the study of education:
27 yearbook (Part 1, pp. 1 S35). Blwmington, IL: Public School Pub-
lishing Company.
Cohen, Jacob. (1 978). Partialed products are interactions; partialed powers
are curve components. Psychological Bulletin, 85, 858-866.
Cohen, Jacob, & Cohen, Patricia. (1 983). Applied multiple regression/corre-
lotion analysis for the behavioral sciences. Hillsdale, NJ: Lawrence
Erlbaum Associates, Inc.
Cronbach, Lee J. . Statistical tests for moderator variables: Flaws in
analyses recently proposed. Psychological Bulletin, 102.41 8420.
Henderson, James, & Velleman, Paul F. (1 98 1). Building multiple regression
models interactively. Biometrics, 37, 39141 1 .
Irwin, Julie R., & McClelland, Gary H. . Heuristics for moderatedre-
gression modek(WorkingPaper). Wharton: University of Pennsylvania
Jaccard, James, Turrisi, Robert, & Wan, Choi K. . Interaction efecrs in
multiple regression. Newbury Park, CA: Sage.
Judd, Charles M., & McClelland, Gary H. . Data analysis: A model
comparison approach. San Diego, CA: Harcourt Brace Jovanovich.
LeClerc, France, & Little, John D. C. . Can advertisingcopy makeFSI
coupons more effective? JoumalofMarketingReseorch, 34,473484.
Lynch, John G., Jr. . Uniqueness issues in the decompositional model-
ing of multiattribute overall evaluations: An information integration
perspective. Journal of Marketing Research, 22, 1-19.
McClelland, Gary H.. & Judd, Charles M. . Statistical difficulties of
detecting interactions and moderator effects. Psychological Bulletin.
114.376390.
Shanna, Subash, Durand, Richard M., & Gur-Arie, Oded. . Identifica-
tion and analysis of moderator variables. Journal of Marketing Re-
search, 28, 291-300.
Professor Tim Ambler
London Business School
A variable is a mediator "to the extent that it accounts for
the relation between the predictor and criterion" . The introduction of intervening
variables has proved valuable . For example, traditional multivariate methods
showed that the size of the firm was a driver of export per-
formance ,
though subsequent analysis gave mixed results . With hindsight, it seems unlikely that the
firm's size can predict performance. If firms have to be big
to be successful, small ones would not grow and, con-
versely, if they had to be small, large firms would fail. Firm
size is much more likely to be a moderator.
As Baron and Kenny pointed out, intervening vari-
ables may be introduced when the relation between the IV and
the DV do not accord with theoretical expectations. If the re-
lation is unexpectedly weak, a moderator may be sought, and
if it is surprisingly strong, a mediator may provide the expla-
nation. The importance of theory in determining causality
cannot be overemphasized. Virtually all the analysis that fol-
lows deals with correlation, and yet much of the literature
usually states, or implies, causality. It should be determined
from the context in addition to the associative tests that fol-
STRUCTURAL EQUATIONS MODELING
Path c (2) yo
XP- Path c (z') yo
FIGURE 4 Models to distinguish mediators and moderators.
low. Where time series data are available, so called "Granger
causality" infers causality where the IV occurs systematically be-
fore the DV.
A simple metaphor for the distinction between mediation
and moderation uses plumbing. The original pipe allows water
to flow from the IV, Xp, to the DV, Yo, Path c in Figure 4, Model
1. If the introduction of the new variablex~
causes the water to
flow along Paths a and b instead of c, as in Model 2, then X ~ i s
mdator. The new Paths a and b replace c. 1 f X ~
operates, how-
ever, as a valve regulating the flow ffom the N to the DV, as in
Model 3, then XM is a moderator .
Following MacKinnon, Warsi, and Dwyer , let us
fist consider mediation. Path c in Model 1 is represented by
where Yo is the outcome variable (DV) adjusted to remove
the intercept,' Xp is the predictor, or IV, and e is the unex-
plained variability.
The Baron and Kenny conditions require two re-
gressions to test mediation:
'This issue will become important if Mis a moderator because the correla-
tion between the independent variable (IV) and IV*M causes multicolline-
arity when they are used together in regression. This problem can be greatly
reduced by centeringthe variables .
If the coefficients a , P, and 2 are significant, and z' equals 0,
then XM is a mediator. XM is a partial mediator when z is
greater than z', but z' is still significant.
MacKinnon et al. showed that, for Equations 1
which means that we need Equations 1 or 2, but not both, be-
cause either a or p being insignificant (statistically zero)
would cause z' equals t equals 0.
The mediated effect is (z - z'), or ap . The percentage of the effect that is mediated is given
by { 100 x ap/[ap + z']} . Alter-
natively, the proportion of indirect to nonzero direct effect is
given by {ap/z).
Care will be needed where a , P, and z do not all have the
same sign. Suppose first that all coefficients are positive but
then any one is replaced by its inverse (e.g., rainfall is re-
placed by drought or trust by lack of trust). Two paths
change &om positive to negative correlations. Each time a
single variable reverses polarity, two relations reverse polar-
is, apz remains positive. As z' is likely to become
insignificant, its sign is irrelevant. Conversely, suppose that
one path was negative (e.g., the original Path c before the in-
tervention of the mediator, i.e., z). Then, a negative relation
is being mediated (replaced) by two positive ones, which is
impossible. Accordingly, apz is greater than 0 is a condition
for mediation that has not previously appeared in the litera-
ture, as far as I know.
Sobel derived the usual approximate significance
test for the mediated effect (ap) giving the SE as
= ~ $ 2 + oia2 , omitting the o&o$ term as being
ample sizes need to be above 50 for reasonable and
around 200 for accurate mediated effect SE estimates
 .
Let us turn to the issue of moderation. "A moderator is a
qualitative (e.g., sex, race, class) or quantitative (e.g., level of
reward) variable that affects the hrection andlor strength of
the relation between an independent or predictor variable and
a dependent or criterion variable" . To test for moderation, we maintain Equations 1 and 2
(presented earlier) and replace Equation 3 with
If a equals P equals 0 (neither are significant) but y is sig-
nificant, then& is a pure moderator noted confusion in the literature over
whether moderators can be related to IVs or the DV and
sought to deal with the problem by allowing two weaker
STRUCTURAL EQUATIONS MODELING
forms of moderation: quasi moderation and homologizers.
Quasi moderation relaxes the requirement that XM is related to
neither the DV nor IV. Thus, in Equations 2 and 5, a, P, or
both may be significant. If P is significant, Equation 5 would
become symmetric between the moderator and the IV. The re-
sulting ambiguity over which was the IV and which was the
moderator led Sharma et al. to conclude (p. 294) that even a
quasi moderator must not be related to the DV (i.e., P = 0). A
homologizer variable is not related to the IV or DV either, but
unlike apure moderator, has no interaction with the IV (i.e., y
in Equation 5 is not significant).
In conclusion, the tests for mediation and moderation are
set out in Table 1. These indicate that the well-known Baron
and Kenny (1 986) tests for mediation are overspecified in one
respect (a does not need to be tested) and underspecified ( a p ~
> 0) in another. Their nonuse of equations also leads to some
ambiguity which this article set out to resolve.
Statistical Tests for Intervening Variables
Condition 1 :
Condition 2:
Condition 3:
Condition 4:
p but not y
7 > r', per-
fect medi-
ation if 7'
not signif-
not an issue