www.brookes.ac.uk/go/radar
Oxford Brookes University – Research Archive and
Digital Asset Repository (RADAR)
Directorate of Learning Resources
Kohli, P, Ladicky, L and Torr, P H
Robust higher order potentials for enforcing label consistency.
Kohli, P, Ladicky, L and Torr, P H   Robust higher order potentials for enforcing label
consistency. International Journal of Computer Vision, 82 (3). pp. 302 ‐ 324.
Doi: 10.1007/s11263‐008‐0202‐0
This version is available:  
Available in the RADAR: May 2010
Copyright © and Moral Rights are retained by the author(s) and/ or other copyright owners. A copy can be
downloaded for personal non‐commercial research or study, without prior permission or charge. This item cannot
be reproduced or quoted extensively from without first obtaining permission in writing from the copyright
holder(s). The content must not be changed in any way or sold commercially in any format or medium without the
formal permission of the copyright holders.
This document is the postprint of the journal article. Some differences between the published version and this
version may remain and you are advised to consult the published version if you wish to cite from it.
Robust Higher Order Potentials for Enforcing Label
Consistency
Pushmeet Kohli
Microsoft Research, Cambridge, UK
L’ubor Ladický
Philip H. S. Torr
Oxford Brookes University, Oxford, UK
This paper proposes a novel framework for labelling problems which is able to combine multiple
segmentations in a principled manner. Our method is based on higher order conditional random ﬁelds and
uses potentials deﬁned on sets of pixels (image segments) generated using unsupervised segmentation
algorithms. These potentials enforce label consistency in image regions and can be seen as a generalization of the commonly used pairwise contrast sensitive smoothness potentials. The higher order potential
functions used in our framework take the form of the Robust P n model and are more general than the
P n Potts model proposed recently in . We prove that the optimal swap and expansion moves for
energy functions composed of these potentials can be computed by solving a st-mincut problem. This
enables the use of powerful graph cut based move making algorithms for performing inference in the
framework. We test our method on the problem of multi-class object segmentation by augmenting the
conventional CRF used for object segmentation with higher order potentials deﬁned on image regions.
Experiments on challenging data sets show that integration of higher order potentials quantitatively and
qualitatively improves results leading to much better deﬁnition of object boundaries. We believe that
this method can be used to yield similar improvements for many other labelling problems.
Index Terms
Discrete Energy Minimization, Markov and Conditional Random Fields, Object Recognition and
Segmentation.
*Manuscript
Click here to download Manuscript: soft_pami.tex
Click here to view linked References
I. INTRODUCTION
In recent years an increasingly popular way to solve various image labelling problems like
object segmentation, stereo and single view reconstruction is to formulate them using image
segments (so called superpixels) obtained from unsupervised1 segmentation algorithms – .
These methods are inspired from the observation that pixels constituting a particular segment
often have the same label; for instance, they may belong to the same object or may have the
same surface orientation. This approach has the beneﬁt that higher order features based on all the
pixels constituting the segment can be computed and used for classiﬁcation2. Further, it is also
much faster as inference now only needs to be performed over a small number of superpixels
rather than all the pixels in the image.
Methods based on grouping segments make the assumption that segments are consistent with
object boundaries in the image , i.e. segments do not contain multiple objects. As observed by
 and this is not always the case and segments obtained using unsupervised segmentation
methods are often wrong. To overcome these problems and use multiple segmentations
of the image (instead of only one) in the hope that although most segmentations are bad, some
are correct and thus would prove useful for their task. They merge these multiple superpixels
using heuristic algorithms which lack any optimality guarantees and thus may produce bad
results. In this paper we propose an algorithm that can compute the solution of the labelling
problem (using features based on image segments) in a principled manner. Our approach couples
potential functions deﬁned on sets of pixels with conventional unary and pairwise cues using
higher order CRFs. We test the performance of this method on the problem of object segmentation
and recognition. Our experiments show that the results of our approach are signiﬁcantly better
than the ones obtained using pairwise CRF models (see ﬁgure 1).
A. Object segmentation and recognition
Combined object segmentation and recognition is one of the most challenging and fundamental
problems in computer vision. The last few years have seen the emergence of object segmentation
1By unsupervised, we mean that the segmentation algorithm does not use information from object recognition.
2In some sense this causes the problem of scene understanding to be decoupled from the image resolution given by the
hardware; it is conducted using more natural primitives that are independent of resolution.
Incorporating higher order potentials for object segmentation. (a) An image from the MSRC-21 dataset. (b),(c) and
(d) Unsupervised image segmentation results generated by using different parameters values in the mean-shift segmentation
algorithm . (e) The object segmentation obtained using the unary likelihood potentials from Textonboost. (f) The result of
performing inference in the pairwise CRF deﬁned in section II. (g) Our segmentation result obtained by augmenting the pairwise
CRF with higher order potentials deﬁned on the segments shown in (b),(c) and (d). (h) The rough hand labelled segmentations
provided in the MSRC data set. It can be clearly seen that the use of higher order potentials results in a signiﬁcant improvement
in the segmentation result. For instance, the branches of the tree are much better segmented.
algorithms which integrate object speciﬁc top-down information with image based low-level
features – . These methods have produced excellent results on challenging data sets.
However, they typically only deal with one object at a time in the image independently and
do not provide a framework for understanding the whole image. Further, their models become
prohibitively large as the number of classes increases. This prevents their application to scenarios
where segmentation and recognition of many object classes is desired.
Shotton et al. recently proposed a method (Textonboost) to overcome this problem. In
contrast to using explicit models to encode object shape they used a boosted combination of
texton features which jointly modeled shape and texture. They combine the result of textons
with colour and location based likelihood terms in a condition random ﬁeld (CRF). Although
their method produced good segmentation and recognition results, the rough shape and texture
model caused it to fail at object boundaries. The problem of extracting accurate boundaries of
objects is considerably more challenging. In what follows we show that incorporation of higher
order potentials deﬁned on superpixels dramatically improves the object segmentation result. In
particular, it leads to segmentations with much better deﬁnition of object boundaries as shown
in ﬁgure 1.
B. Higher Order CRFs
Higher order random ﬁelds are not new to computer vision. They have been long used to
model image textures – . The initial work in this regard has been quite promising and
higher order CRFs have been shown to improve results for problems such as image denoising
and restoration , and texture segmentation . However their use has been quite limited due
to lack of efﬁcient algorithms for performing inference in these models.
Traditional inference algorithms such as BP are quite computationally expensive for higher
order cliques although recent work has improved their performance for certain classes of potential
functions. Lan et al. proposed approximation methods for BP to make efﬁcient inference
possible in higher order MRFs. This was followed by the recent work of Potetz in which
he showed how belief propagation can be efﬁciently performed in graphical models containing
moderately large cliques. However, as these methods were based on BP, they were quite slow
and took minutes or hours to converge.
Kohli et al. recently showed how certain higher order clique potentials can be minimized
using move making algorithms for approximate energy minimization such as α-expansion and
αβ-swap . They introduced a class of higher order potentials called the P n Potts model
and showed how the optimal expansion and swap moves for energy functions containing these
potentials can be computed in polynomial time by solving a st-mincut problem. The complexity
of their algorithm increased linearly with the size of the clique and thus it was able to handle
cliques composed of thousands of latent variables.
The higher order energy functions characterizing the higher order CRFs arising from our work
are more general in form than the P n Potts model and thus cannot be minimized efﬁciently
using the algorithm of . We introduce a new family of higher order potentials which is
a generalization of the P n Potts class. The potential functions belonging to this family are
parameterized with a truncation parameter Q which controls their robustness. We will show how
energy functions composed of these robust potentials can be minimized using move making
algorithms such as α-expansion and αβ-swap. Speciﬁcally, we show how the optimal swap and
expansion moves for such potentials can be found using algorithms for computing the st-mincut.
C. Organization of the Paper
This paper proposes a general framework for solving labelling problems which has the ability
to utilize higher order potentials deﬁned on segments3. We test this framework on the problem
of object segmentation and recognition by integrating label consistency and shape based terms
deﬁned on segments with conventional unary and pairwise potentials. We show how inference in
this framework can be efﬁciently performed by extending the recent work on minimizing energy
function with higher order cliques . To summarize, the novelties of our approach include:
1) The method for efﬁciently solving a new family of higher order potentials which we call
the robust P n model, and is a generalization of the P n Potts model.
2) A novel higher order region consistency potential which is a strict generalization of the
commonly used pairwise contrast sensitive smoothness potential.
3) The application of higher order CRFs for object segmentation and recognition which
integrate the above mentioned higher order potentials with conventional unary and pairwise
potentials based on colour, location, texture, and smoothness.
An outline of the paper follows. In section II we discuss the basic theory of conditional random
ﬁelds. We then show how pairwise CRFs can be used to model labelling problems like object
segmentation. In section III we augment the pairwise CRF model by incorporating novel higher
order potentials based on super-pixel segmentations. In section IV we review the work on move
making algorithms for solving higher order energy functions. The potential functions which can
be solved using our method are described in section V. Finally, in section VI we show how the
optimal expansion and swap moves for energy functions composed of such potentials can be
computed by solving a st-mincut problem. The experimental results of our method are given in
section VII. These include qualitative and quantitative results on well known and challenging
data sets for object segmentation and recognition. The conclusions and directions for future
work are listed in section VIII. The proofs of the theorems stated in the paper are given in the
3An earlier version of this paper appeared as .
II. PRELIMINARIES
We start by providing the basic notation used in the paper. Consider a discrete random ﬁeld
X deﬁned over a lattice V = {1, 2, . . ., N} with a neighbourhood system E. Each random
variable Xi ∈X is associated with a lattice point i ∈V and takes a value from the label set
L = {l1, l2, . . . , lk}. The neighborhood system E is the set of edges connecting variables in the
random ﬁeld. A clique c is a set of random variables Xc which are conditionally dependent on
each other. Any possible assignment of labels to the random variables will be called a labelling
(denoted by x) which takes values from the set L = LN.
The probability Pr(X = x) of any labelling x of the random variables will be referred to
as Pr(x). From the Hammersley Clifford theorem, the posterior distribution Pr(x|D) over the
labellings of a Markov Random Field (MRF) is a Gibbs distribution and can be written as
Pr(x|D) = 1
where ψc(xc) are potential functions deﬁned over the variables (xc = {xi, i ∈c}) constituting
the clique c, Z is a normalizing constant known as the partition function, and C is the set of all
cliques . The corresponding Gibbs energy is deﬁned as
E(x) = −log Pr(x|D) −log Z =
The maximum a posteriori (MAP) labelling x∗of the random ﬁeld is deﬁned as
x∗= arg max
x∈L Pr(x|D) = arg min
A conditional random ﬁeld (CRF) may be viewed as an MRF globally conditioned on the data .
In this case, the potential functions are conditioned by the data and are thus should be written as
ψc(xc|D). To be concise, we will drop D, and just use ψc(xc) to denote the potential functions
A. Pairwise CRFs for Object Segmentation
The CRF models commonly used for object segmentation are characterized by energy functions
deﬁned on unary and pairwise cliques as:
ψij(xi, xj).
Here V corresponds to the set of all image pixels, while E is the set of all edges connecting
the pixels i, j ∈V. The edge set is commonly chosen to deﬁne a 4 or 8 neighbourhood. The
labels constituting the label set L represent the different objects. The random variable xi denotes
the labelling of pixel i of the image. Every possible assignment of the random variables x (or
conﬁguration of the CRF) deﬁnes a segmentation.
The unary potential ψi of the CRF is deﬁned as the negative log of the likelihood of a label
being assigned to pixel i. It can be computed from the colour of the pixel and the appearance
model for each object. However, colour alone is not a very discriminative feature and fails to
produce accurate segmentations. This problem can be overcome by using sophisticated potential
functions based on colour, texture, location, and shape priors as shown by , , – .
The unary potential used by us can be written as:
ψi(xi) = θTψT(xi) + θcolψcol(xi) + θlψl(xi)
where θT, θcol, and θl are parameters weighting the potentials obtained from TextonBoost(ψT)
 , colour(ψcol) and location(ψl) respectively.
The pairwise terms ψij of the CRF take the form of a contrast sensitive Potts model:
ψ(xi, xj) =
if xi = xj,
otherwise,
where the function g(i, j) is an edge feature based on the difference in colors of neighboring
pixels . It is typically deﬁned as:
g(i, j) = θp + θv exp(−θβ||Ii −Ij||2),
where Ii and Ij are the colour vectors of pixel i and j respectively. θp, θv, and θβ are model
parameters whose values are learned using training data. We refer the reader to , , 
for more details.
1) Inferring the most probable segmentation: The object segmentation problem can be solved
by ﬁnding the least energy conﬁguration of the CRF deﬁned above. As the pairwise potentials
of the energy function (4) are of the form of a Potts model it can be minimized approximately
using the well known α-expansion algorithm . The resulting segmentation can be seen in
ﬁgure 1. We also tried other energy minimization algorithms such as sequential tree-reweighted
message passing (TRW-S) , . The α-expansion algorithm was preferred because it was
faster and gave a solution with lower energy compared to TRW-S.
2) Need for Higher Order CRFs: The use of Potts model potentials in the CRF model
makes it favour smooth object boundaries. Although this improves results in most cases it
also introduces an undesirable side effect. Smoothness potentials make the model incapable
of extracting the ﬁne contours of certain object classes such as trees and bushes. As seen in
the results, segmentations obtained using pairwise CRFs tend to be oversmooth and quite often
do not match the actual object contour. In the next section we show how these results can
be signiﬁcantly improved by using higher order potentials derived from multiple segmentations
obtained from an unsupervised image segmentation method.
III. INCORPORATING HIGHER ORDER POTENTIALS
Methods based on grouping regions for segmentation generally make the assumption that all
pixels constituting a particular segment (or region) belong to the same object . This is not
always the case, and image segments quite often contain pixels belonging to multiple object
classes. For instance, in the segmentations shown in ﬁgure 2 the bottom image segment contains
some ‘building’ pixels in addition to all the grass pixels.
Unlike other object segmentation algorithms which use the label consistency in segments
as a hard constraint, our method uses it as a soft constraint. This is done by using higher
order potentials deﬁned on the image segments generated using unsupervised segmentation
algorithms. Speciﬁcally, we augment the pairwise CRF model explained in the previous section
by incorporating higher order potentials deﬁned on sets or regions of pixels. The Gibbs energy
of this higher order CRF can now be written as:
ψij(xi, xj) +
where S refers to a set of image segments (or super-pixels), and ψc are higher order potentials
deﬁned on them. In our experiments, the set S consisted of all segments of multiple segmentations
of an image obtained using an unsupervised image segmentation algorithm such as meanshift (see section III-D for more details). We will now describe in detail how these higher
order potentials are deﬁned.
A. Region based consistency potential
The region consistency potential is similar to the smoothness prior present in pairwise CRFs .
It favours all pixels belonging to a segment taking the same label, and as will be shown later is
Quality sensitive region consistency prior. (a) An image from the MSRC data set. (b) and (c) Two different segmentations
of the image obtained using different parameter values for the mean-shift algorithm. (d) A hand labelled object segmentation of
the image. (e) and (f) The value of the variance based quality function G(c) (see equation 11) computed over the segments of
the two segmentations. Segments with high quality values are darker. It can be clearly seen that segments which contain multiple
object classes have been assigned low quality. For instance, the top segment of the left tree in segmentation (c) includes a part
of the building and thus is brighter in the image (f) indicating low quality. Potentials deﬁned on such segments will have a
lower labelling inconsistency cost and will have less inﬂuence in the CRF.
particularly useful in obtaining object segmentations with ﬁne boundaries. It takes the form of
a Pn Potts model (see equation 16) :
xi = lk, ∀i ∈c,
otherwise.
where |c| denotes the cardinality of the pixel set c which in our case is the number of pixels
constituting superpixel c, while θh
p and θα are parameters of the potential. The expression θh
gives the label inconsistency cost, i.e. the cost added to the energy of a labelling in which
different labels have been assigned to the pixels constituting the segment. The parameters θh
and θα are learned from the training data by cross validation as described in section VII. The
reader should note that this potential takes multiple variables as argument and thus cannot be
expressed in the conventional pairwise CRF model.
B. Quality sensitive consistency potential
Not all segments obtained using unsupervised segmentation are equally good, for instance,
some segments may contain multiple object classes. A region consistency potential deﬁned over
such a segment will encourage an incorrect labelling of the image. This is because the potential
(9) does not take the quality or goodness of the segment into account. It assigns the same penalty
for breaking ‘good’ segment as it assigns to ‘bad’ ones. This problem of the consistency potential
can be overcome by deﬁning a quality sensitive higher order potential (see ﬁgure 2). This new
potential works by modulating the label inconsistency cost with a function of the quality of the
segment (which is denoted by G(c)). Any method for estimating the segment quality can be
used in our framework. A good example would be the method of which uses inter and
intra region similarity to measure the quality or goodness of a segment. Formally, the potential
function is written as:
if xi = lk, ∀i ∈c,
otherwise.
For our experiments, we use the variance of the response of a unary feature evaluated on all
constituent pixels of a segment to measure the quality of a segment, i.e.
G(c) = exp
i∈c(f(i) −µ)2∥
and f() is a function evaluated on all constituent pixels of the superpixel c.
If we restrict our attention to only pairwise cliques i.e. |c| = 2, the variance sensitive potential
c(xi, xj) =
if xi = xj,
∥f(i)−f(j)∥2
otherwise.
This is the same as the pairwise potential (6) commonly used in pairwise CRFs for different
image labelling problems , . Thus, the variance sensitive potential can be seen as a
higher order generalization of the contrast preserving potential. The variance function response
over two segmentations of an image is shown in ﬁgure 2.
C. Making the potentials robust
The P n Potts model enforces label consistency rigidly. For instance, if all but one of the pixels
in a super-pixel take the same label then the same penalty is incurred as if they were all to take
Behaviour of the rigid P n Potts potential and the Robust P n model potential. The ﬁgure shows how the cost enforced
by the two higher order potentials changes with the number of variables in the clique not taking the dominant label i.e.
Ni(xc) = mink(|c| −nk(xc)).
different labels. Due to this strict penalty, the potential might not be able to deal with inaccurate
super-pixels or resolve conﬂicts between overlapping regions of pixels. This phenomenon is
illustrated in ﬁgure 4 wherein a part of the bird is merged with the ‘sky’ super-pixel and results
in an inaccurate segmentation. Intuitively, this problem can be resolved using the Robust higher
order potentials deﬁned as:
if Ni(xc) ≤Q
otherwise.
where Ni(xc) denotes the number of variables in the clique c not taking the dominant label i.e.
Ni(xc) = mink(|c|−nk(xc)), γmax = |c|θα(θh
vG(c)), and Q is the truncation parameter which
controls the the rigidity of the higher order clique potential. We will show in section IV how
energy functions composed of such potentials can be minimized using move making algorithms
such as α-expansion and αβ-swap.
Unlike the standard P n Potts model, this potential function gives rise to a cost that is a linear
truncated function of the number of inconsistent variables (see ﬁgure 3). This enables the robust
potential to allow some variables in the clique to take different labels. In the image shown in
ﬁgure 4, the robust P n potentials allows some pixels of the ‘sky’ segment to take the label ‘bird’
thus producing a much better segmentation. Experiment results are shown for multiple values
of the truncation parameter Q. More qualitative results can be seen in ﬁgure 13.
Object segmentation and recognition using the Robust P n higher order potentials (13). (a) Original Image. (b)
Labelling from unary likelihood potentials from Textonboost . (c) and (d) Segmentations obtained by varying the parameters
of the Mean shift algorithm for unsupervised image segmentation . (e) Result obtained using pairwise potential functions as
described in . (f) Result obtained using P n Potts model potentials deﬁned on the segments (or superpixels) shown in (c)
and (d). These higher order potentials encourage all pixels in a superpixel to take the same label. The P n Potts model rigidly
enforces label consistency in regions thus causing certain pixels belonging to the ‘bird’ to erroneously take the label ‘sky’ as
they were included in the ‘sky’ superpixel. This problem can be overcome by using the Robust P n model potentials deﬁned in
(13) which are robust and allow some variables in the clique to take different labels. (g) and (h) show results obtained by using
the robust potentials with truncation parameter Q equal to 0.1|c| and 0.2|c| respectively. Here |c| is equal to the size of the
superpixel over which the Robust P n model potential is deﬁned. (i) Hand labelled segmentation from the MSRC dataset.
D.. Generating multiple segmentations
We now explain how the set S of segments used for deﬁning the higher order energy function
(8) was generated. Our framework is quite ﬂexible and can handle multiple overlapping or
Generating multiple segmentations. The ﬁgure shows the segmentations obtained by using different parameters in the
mean-shift algorithm. The parameters used for generating the segmentation are written below it in the format (hs, hr), where
hs and hr are the bandwidth parameters for the spatial and range (colour) domains.
non-overlapping segments. The computer vision literature contains algorithms for sampling the
likely segmentations of an image or for generating multi-scale segmentations . However,
following in the footsteps of we choose to generate multiple segmentations by varying the
parameters of the mean shift segmentation algorithm . This method belongs to the class of
unsupervised segmentation algorithms which work by clustering pixels on the basis of low level
image features , , . They have been shown to give decent results which have proved
to be useful for many applications , , .
The kernel used in the mean shift algorithm is deﬁned as the product of spatial and range
kernels. The spatial domain contains the (x, y) coordinates, while the range domain contains
pixel colour information in LUV space. An assumption of Euclidian metric in both of them
allows the use of a single bandwidth parameter for each domain, hs for spatial and hr for
range. The segmentation results obtained using 2 different spatial {7, 18} and 3 different range
parameter values {6.5, 9.5, 15} are shown in ﬁgure 5. It can be seen that the results do not change
dramatically on small images by modifying hs. The only difference occurs on very noisy parts
of the image like trees and bushes. By increasing the range parameter hr we can get a range
of segmentations which vary from over-segmented to under-segmented. We decided to use three
segmentations with parameters (hs, hr) = {(7, 6.5), (7, 9.5), (7, 15)}.
IV. INFERENCE IN HIGHER ORDER CRFS
The problem of inferring the most probable solution of a higher order CRF is equivalent to
minimizing an energy function. In general, the energy minimization problem is NP-hard .
However, there exist classes of functions which can be solved exactly in polynomial time. Two
well known classes of tractable functions are: submodular functions, and functions deﬁned over
graphs with bounded tree width. However, most energies encountered in practical problems do not
belong to these families. They are instead solved using algorithms for approximate energy minimization. These algorithms can be divided into two broad categories: message passing algorithms
such as belief propagation and its variants , , , and move making algorithms such
as the graph cut based α-expansion and αβ-swap . Message passing algorithms have been
shown to produce excellent results for many energy functions. However, their runtime complexity
increases exponentially with the size of the largest clique in the random ﬁeld, making them
inapplicable to functions deﬁned over large cliques. Efﬁcient graph cut based α-expansion and
αβ-swap move algorithms have been successfully used to minimize energy functions composed
of pairwise potential functions. In this paper, we show how they can be applied to a large and
useful class of higher order energy functions.
A.. Expansion and Swap Move Algorithms
Move making algorithms start from an initial solution and proceed by making a series of
changes which lead to solutions having lower energy. At each step, the algorithms search a
move space and choose the move which leads to the solution having the lowest energy. This
move is referred to as the optimal move. The algorithm is said to converge when no lower energy
solution can be found.
The size of the move space is a key characteristic of these algorithm. A large move space
means that bigger changes to the current solution can be made. This makes the algorithm less
prone to getting stuck in local minima and also results in a faster rate of convergence. This paper
deals with two particular large move making algorithms, namely α-expansion and αβ-swap 
whose move space size increases exponentially with the number of variables involved in the
energy function. We will use the notation of to describe how these algorithms work. The
moves of the expansion and swap algorithms can be encoded as a vector of binary variables
t ={ti, ∀i ∈V}. The transformation function T(xp, t) of a move algorithm takes the current
labelling xp and a move t and returns the new labelling xn which has been induced by the
An α-expansion move allows any random variable to either retain its current label or take
label ‘α’. One iteration of the algorithm involves making moves for all α in L in some order
successively. The transformation function Tα() for an α-expansion move transforms the label of
a random variable Xi as
Tα(xi, ti) =
An αβ-swap move allows a variable whose current label is α or β to either take label α or β.
One iteration of the algorithm involves performing swap moves for all α and β in L in some
order successively. The transformation function Tαβ() for an αβ-swap transforms the label of a
random variable xi as
Tαβ(xi, ti) =
xi = α or β and ti = 0,
xi = α or β and ti = 1.
The energy of a move t is the energy of the labelling x the move t induces i.e. Em(t) =
E(T(x, t)). The move energy is a pseudo-boolean function (Em : {0, 1}n →R) and will be
denoted by Em(t). At each step of the expansion and swap move algorithms, the optimal move
t∗, i.e. the move decreasing the energy of the labelling by the most amount is computed. This
is done by minimizing the move energy i.e. t∗= arg mint E(T(x, t)). The optimal move t∗can
be computed in polynomial time if the move function Em(t) is submodular.
B. Recent Developments
The last few years have seen a lot of interest in graph cut based move algorithms for energy
minimization. Komodakis et al. , recently gave an alternative interpretation of the
α-expansion algorithm. They showed that α-expansion works by solving the dual of a linear
programming relaxation of the energy minimization problem. Using this theory, they developed
a new algorithm (FAST-PD) which was faster than vanilla α-expansions and produced the exact
same solution. Alahari et al. have recently proposed a similar but simpler method which
achieves the same performance.
Researchers have also proposed a number of novel move encoding strategies for solving
particular forms of energy functions. Veksler proposed a move algorithm in which variables
can choose any label from a range of labels. They showed that this move space allowed them
to obtain better minima of energy functions with truncated convex pairwise terms. Kumar and
Torr have since shown that the range move algorithm achieves the same guarantees as the
ones obtained by methods based on the standard linear programming relaxation. More recently,
Lempitsky, Rother and Blake proposed an algorithm which encoded labels by a binary
string. During each move, the variables were allowed to change a particular bit of the binary
string. They showed that this particular move encoding strategy results in a substantial speedup
when minimizing energy functions with large label sets.
C. Computing Moves using Graph Cuts
We had discussed in section IV-A that the optimal expansion and swap moves can be computed
by minimizing a (move) function of binary variables. Functions of binary variables (F : {0, 1} →R)
are usually referred to as Pseudo-boolean functions. It is known that a move function can
be minimized in polynomial time if it is submodular (See Appendix A). Submodular set
functions are encountered in many areas of research and are particularly useful in combinatorial
optimization, probability and geometry , . Many optimization problems relating to submodular functions can be solved efﬁciently. In this respect they are similar to convex/concave
functions encountered in continuous optimization.
Algorithms for submodular function minimization have high runtime complexity. Although
recent work has been successful in reducing the runtime complexity of these algorithms, they
are still quite computationally expensive and cannot be used to minimize large functions. For
instance, the complexity of the current best algorithm for general submodular function minimization is O(n5T +n6) where T is the time taken to evaluate the function . This algorithm
improved upon the previous best algorithm by a factor of n log n.
Some submodular functions can be minimized much more efﬁciently by solving an st-mincut
problem . Speciﬁcally, all submodular functions of binary variables of order at most 3 can be
minimized in this manner , . Researchers have shown that certain higher order functions
can be transformed into submodular functions of order 2, and thus can also be minimized ,
 . The same transformation technique can be used to minimize some functions of multi-valued
variables – .
Solving pairwise CRFs using move making algorithms involves computing optimal moves
by minimizing quadratic pseudo-boolean move functions. Boykov et al. showed that all
expansion move functions encountered while minimizing an energy function composed of metric
potential functions are submodular. As these functions are quadratic, they can be efﬁciently
minimized by solving an equivalent st-mincut problem. They also showed that all αβ-swap
move functions can be exactly minimized if the pairwise potentials of the CRF are semi-metric.
V. ROBUST HIGHER ORDER POTENTIALS
Kohli et al. recently characterized a class of higher order clique potentials for which
the optimal expansion and swap moves can be computed by minimizing a submodular function.
However, as discussed earlier, minimizing a general submodular function is quite computationally
expensive and it is infeasible to apply this procedure to minimize energy functions encountered
in computer vision problems, which generally involve millions of random variables. In the same
work, they also introduced a class of higher order clique potentials called the P n Potts model
and showed that the optimal expansion and swap moves for energy functions containing these
potentials can be computed in polynomial time by solving a st-mincut problem. The P n Potts
model was deﬁned as:
xi = lk, ∀i ∈c,
otherwise.
where γmax ≥γk, ∀lk ∈L. This potential is a higher order generalization of the widely used
Potts model potential which is deﬁned over cliques of size two as ψij(a, b) = γk if a = b = lk
and γmax otherwise.
In this paper we introduce a novel family of higher order potentials which we call the Robust
P n model. This family contains the P n Potts model as well as its robust variants, and can
be used for modelling many computer vision problems. We show that the optimal swap and
expansion move energy functions for any Robust P n model potential can be transformed into a
second order submodular function by the addition of at most two binary auxiliary variables. This
transformation enables us to ﬁnd the optimal swap and expansion moves in polynomial time4.
4All second order submodular functions of binary variables can be minimized exactly in polynomial time by solving an
st-mincut problem , .
The Robust P n model potentials take the form:
ψc(xc) = min{min
k∈L((|c| −nk(xc))θk + γk), γmax}
where |c| is the number of variables in clique c, nk(xc) denotes the number of variables in clique
c which take the label k in labelling xc, and γk, θk, γmax are potential function parameters which
satisfy the constraints:
θk = γmax −γk
γk ≤γmax, ∀k ∈L.
Q is called the truncation parameter of the potential and satisﬁes the constraint 2Q < |c|. It can
be seen that the Robust P n model (17) becomes a P n Potts model (16) when the truncation
parameter is set to 1.
Example 1: Consider the set of clique variables X = {X1, X2, . . . , X7} where each Xi, i ∈
{1, 2, . . ., 7} takes a value from the label set L = {a, b, c}. If the clique potential takes the
form a P n Potts model, it assigns a cost γmax to all labellings of the random variables except
those where all variables Xi take the same label. Thus, the conﬁguration x = (a, a, b, a, c, a, a)
will be assigned cost γmax even though there are only 2 variables (speciﬁcally, X3 and X5)
which are assigned labels (b and c) different from the dominant label a. In contrast, if the clique
potential takes the form of the Robust P n model with truncation 3 i.e., Q = 3, it assigns the
cost: γa + (γmax−γa)
× 2 to the same conﬁguration.
The region based consistency potentials (13) used in our higher order CRF takes the form of
a Robust P n model where the constants γk have the same value for all labels k ∈L. In this
case, the higher order potential can be seen as encouraging all the variables in the clique c to
take the same label. In other words, the potential tries to reduce the number of variables in the
clique not taking the dominant label i.e., Ni(xc) = mink(|c| −nk(xc)). In what follows we will
refer to these variables as inconsistent.
Unlike the P n Potts model that rigidly enforces label consistency, the Robust P n Potts model
gives rise to a cost that is a linear truncated function of the number of inconsistent variables
(see ﬁgure 3). This enables the robust potential to allow some variables in the clique to take
different labels.
Approximating Concave Consistency Potentials. The ﬁgure shows the result of combining two robust higher order
potentials (a) and (b). The resulting potential function is shown in (c).
A. Approximating Concave Consistency Potentials
Multiple Robust P n model potentials can be combined to approximate any non-decreasing
concave consistency potential up to an arbitrary accuracy. This potential takes the form:
ψc(xc) = min{min
k∈L Fc((|c| −nk(xc))), γmax}
where Fc is a non-decreasing concave function5. This is illustrated in ﬁgure 6.
B. Generalized form of Robust Higher Order Potentials
We now provide a characterization of a larger class of functions for which at most two auxiliary
variables are sufﬁcient to transform the higher order swap and expansion move energy functions
5A function f(x) is concave if for any two points (a, b) and λ where 0 ≤λ ≤1: λf(a) + (1 −λ)f(b) ≤f(λa + (1 −λ)b).
to second order functions. The potentials belonging to this new family have the form:
ψc(xc) = min{min
k∈L((P −fk(xc))θk + γk), γmax}
where the parameter P and functions fk(xc) are deﬁned as:
otherwise.
and weights wk
i ≥0, i ∈c, k ∈L encode the relative importance of different variables in
preserving consistency of the labelling of the clique. The parameters γk, θk, γmax of the potential
function satisfy the constraints:
θk = γmax −γk
γk ≤γmax, ∀k ∈L.
Qk, k ∈L are the truncation parameters of the potential functions and satisfy the constraints
Qa + Qb < P, ∀a ̸= b ∈L.
If we assume that wk
i = wi ≥0 and Qk = Q for all k ∈L, the potential family (20) can
be seen as weighted version of the Robust P n model. The weights can be used to specify the
relative importance of different variables. For instance, this can be used to change the robust
region consistency potential (13) to reduce the inconsistency cost for pixels on the segment
boundary by reducing their weights. We will show that for the case of symmetric weights i.e.
i = wi, the higher order swap and expansion and move energy functions for the potentials
(20) can be transformed to a submodular second order binary energy6.
VI. MINIMIZING HIGHER ORDER MOVE FUNCTIONS USING GRAPH CUTS
We will now explain how the optimal swap and expansion moves for energy functions containing potential functions of the form (20) can be computed using graph cuts. The computation
of the optimal moves requires the minimization of higher order move functions. This is done by
ﬁrst transforming the higher order move functions to quadratic submodular functions by adding
auxiliary binary variables, and then minizing them using graph cuts.
6Higher order potentials with asymmetric weights can also be transformed to quadratic functions in a similar manner. We
restrict our attention to potentials with symmetric weights for a cleaner exposition.
(a) Graph construction for minimizing higher order quadratic functions of the form (25) using the transformation given
in theorem 1. For every binary variable ti in the energy function there is a corresponding graph node vi. The minimum cost
source sink cut (st-mincut) divides the graph into two sets: the source set (S) and the sink set (T ). vi ∈(S) implies ti = 1 while
vi ∈(T ) implies ti = 0. (b) Graph illustrating how two higher order potentials of the form (25) can be summed together to attain
any function of the generalized concave form (29). Function f and g are deﬁned over 10 binary variables (c = {1,2, ..., 10}).
They are deﬁned as: f(t) = min(1 + P
i∈c 2(1 −ti), 2 + P
i∈c ti, 5) and g(t) = min(2 + P
i∈c(1 −ti), 1 + P
i∈c ti, 6).
A. Transforming Higher Order Move Energies
The problem of transforming a general submodular higher order function to a second order
one has been well studied . It is known that in the worst case this may require the addition
of exponential number of auxiliary binary variables. Due to the special form of the Robust P n
model (10), the method described in the paper only needs to add two binary variables per higher
order potential to transform the move energy to a submodular quadratic function. This allows
for the efﬁcient computation of the optimal swap and expansion moves. The complexity of our
algorithm for computing the optimal move increases linearly with the size of the clique. This
enables us to handle potential functions deﬁned over very large cliques.
The important observation that inspired our method is the fact that higher order pseudo-boolean
functions of the form:
f(tc) = min
i (1 −ti), θ1 +
i ti, θmax
can be transformed to submodular quadratic pseudo-boolean functions, and hence can be minimized using graph cuts. Here, tc = {ti ∈{0, 1}, i ∈c} is the set of binary random variables
included in the clique c, and w0
i ≥0, θ0, θ1, θmax are parameters of the potential
satisfying the constraints θmax ≥θ0, θmax ≥θ1, and
i (1 −ti) ≥θmax
i ti ≥θmax
∀tc ∈{0, 1}|c|
where ∨is a boolean OR operator. The transformation to a quadratic pseudo-boolean function
requires the addition of only two binary auxiliary variables making it computationally efﬁcient.
Theorem 1: The higher order pseudo-boolean function:
f(tc) = min
i (1 −ti), θ1 +
i ti, θmax
can be transformed to the submodular quadratic pseudo-boolean function:
f(tc) = min
r0(1 −m0) + m0
i (1 −ti) + r1m1 + (1 −m1)
by the addition of binary auxiliary variables m0 and m1. Here, r0 = θmax −θ0, r1 = θmax −θ1
and K = θmax −θ0 −θ1. Proof in appendix.
The graph construction for minimizing the quadratic pseudo-boolean function (28) is shown in
ﬁgure 7 (a).
Multiple higher order potentials of the form (25) can be summed together to obtain higher
order potentials of the more general form
f(tc) = Fc(
where Fc : R →R is any concave function. See ﬁgure 7 (b) for an illustration.
In what follows we show that any swap or expansion move energy for higher order potentials
of the form (20) can be converted to a submodular pairwise function if wk
i = wi for all k ∈L.
Our transformation requires the addition of only two binary auxiliary variables. To proceed
further, we will need to deﬁne the function W(s), s ⊆c:
It can be seen from constraint (21) that W(c) = P.
B. Swap Moves
Recall from the deﬁnition of the swap move transformation function that only variables which
are currently assigned labels α or β can take part in a αβ-swap move. We call these variables
active and denote the vector of their indices by ca. tca will be used to denote the corresponding
vector of move variables. Similarly, variables in the clique which do not take part in the swap
move are called passive, and the set of their indices is denoted by cp. Let functions f m
k (tca), k ∈
{0, 1} be deﬁned as:
The move energy of a αβ-swap move from the current labelling xp
c is equal to the energy of
the new labelling xn
c induced by the move and is given as
c (tca) = ψc(xn
The new labelling xn
c is obtained by combining the old labelling of the passive variables Xcp
with the new labelling of the active variables Xca as:
cp ∪Tαβ(xp
On substituting the value of xn
c from (33) in (32), and using the deﬁnition of the higher order
potential functions (20) we get:
cp ∪Tαβ(xp
k∈L(zkθk + γk), γmax}
where zk = P −fk(xp
cp ∪Tαβ(xp
ca, tca)).
It can be easily observed that if conditions:
W(ca) < P −Qα
W(ca) < P −Qβ,
are satisﬁed, then the expression:
cp ∪Tαβ(xp
ca, tca)))θk + γk
is greater than γmax for both k = α and k = β. Thus, in this case the move energy ψm
c (tca) is
independent of tca and is equal to the constant:
k∈L\{α,β}((P −fk(xp
c))θk + γk), γmax}
which can be ignored while computing the swap moves. However, if constraints (36) are not
satisﬁed, the move energy becomes: ψm
ca, tca) =
min{(W(ca) −f m
0 (tca))θα + λα, (W(ca) −f m
1 (tca))θβ + λβ, λmax}
where λα = γα + Rαβθα, λβ = γβ + Rαβθβ, λmax = γmax and Rαβ = W(c −ca).
The higher order move energy (39) has the same form as the function deﬁned in equation
(27), and can be transformed to a pairwise function by introducing binary auxiliary variables
m0 and m1 as:
r0(1 −m0) + θβm0
r1m1 + θα(1 −m1)
where r0 = λα + δ, r1 = λβ + δ, and δ = λmax −λα −λβ.
The properties γmax ≥γk, ∀k ∈L and wi ≥0 of the clique potential (20) imply that all
coefﬁcients of the energy function (40) are non-negative. The function is thus submodular and
can be minimized by solving a st-mincut problem . The graph construction for minimizing
the energy function (40) is shown in ﬁgure (8a). The constant δ in (40) does not affect the
minimization problem i.e. it does not change the move having the least energy and thus is
C.. Expansion Moves
We now describe how the optimal expansion moves can be computed for the higher order potentials (20). Let ck denote the set of indices of variables in clique c that have been assigned label
k in the current solution xp
c. We ﬁnd the dominant label d ∈L in xp
c such that W(cd) > P −Qd
where d ̸= α. The constraints Qa + Qb < P, ∀a ̸= b ∈L of the higher order potentials (20) make
sure that there is at most one such label. If we ﬁnd such a label in the current labelling, then
the expansion move energy can be written as: ψm
c (tc) = ψc(Tα(xp
c, tc)) or, ψm
min{λα + θα
witi, λd + θd
wi(1 −ti), λmax}
(a) Swap Move
(b) Expansion Move
(a) Graph construction for minimizing the swap energy function (40). (b) Graph construction for minimizing the
expansion move energy function (43). For every binary move variable ti in the energy function there is a corresponding graph
node vi. The minimum cost source sink cut (st-mincut) divides the graph into two sets: the source set (S) and the sink set (T ).
vi ∈(S) implies ti = 1 while vi ∈(T ) implies ti = 0.
where λα = γα, λd = γd + Rdθd, λmax = γmax and Rd = W(c −cd). Without the minimization
operator the function (41) becomes:
c (tc, tcd) =
0 (tc) > P −Qα
0 (tcd) ≤Qd −Rd
where Kα = λα +(P −f m
0 (tc))θα, and Kd = λd +f m
0 (tcd)θd. Next we will show that this higher
order move energy can be written as a second order submodular function with the addition of
the auxiliary binary variables m0 and m1.
Theorem 2: The expansion move energy (42) can be transformed into the pairwise function:
r0(1 −m0) + θdm0
r1m1 + θα(1 −m1)
where r0 = λα + δ, r1 = λd + δ, and δ = λmax −λα −λd. Proof in appendix.
The energy function (43) is submodular and can be minimized by ﬁnding the st-mincut in the
graph shown in ﬁgure (8b).
If a dominant label cannot be found then the move energy can be written as:
c (tc) = min{λα + θα
witi, λmax}
where λα = γα, and λmax = γmax. This can be transformed to the binary pairwise energy:
c (tc) = r1m1 + θα(1 −m1)
witi + λα,
where r1 = λmax −λα. The proof for this transformation is similar to the one shown for
Theorem 2.
VII. EXPERIMENTS
In this section we provide the details of our experiments which are divided in two parts. The
ﬁrst set of experiments analyze the performance of our algorithm for minimizing higher order
energy functions, while those in the second set deal with evaluating the performance of using
our higher order potentials for the problem of object segmentation.
A. Computational Performance
We have tested our methods on randomly generated higher order energy functions. We compare
the performance of our methods with the Iterated Conditional Modes (ICM) algorithm. Comparison with the conventional factor graph formulation of message passing algorithms like BP
and TRW-S was infeasible due to the large size of cliques deﬁning the energy functions used in
our tests7. Our experiments show that the graph cut based expansion and swap move algorithms
for the Robust P n model potentials produce solutions with lower energy compared to the ICM
algorithm. Further, they required much less time to converge to the ﬁnal solution compared
to ICM. The graph in ﬁg. 10 show how the energy of the solutions obtained from different
minimization algorithms changes with time. The graphs in ﬁg. 9 show how the convergence
time for the different algorithm is inﬂuenced by parameters of the energy function.
7It should be noted that the Robust P n model potentials can be transformed into pairwise potentials by the addition of multilabel auxiliary variables. This enables the use of message passing algorithms for minimizing energy functions composed of them.
However, the analysis of these transformations, and the subsequent study of the performance of message passing algorithms on
the transformed functions lies outside the scope of this paper.
(a) No. of Potentials
(b) Inconsistency Cost
(c) Truncation
(d) No. of Labels
Convergence times of the swap and expansion move algorithms. The graphs show how the convergence times of the move
algorithms is affected by changes in the higher order energy function. The experiments were performed on grids corresponding
to 10 randomly selected images from the Sowerby dataset for Object Segmentation. The size of the grid was 96× 64. The unary
and pairwise potentials were generated using the method proposed in . Higher order potentials of the form of the Robust
P n were generated randomly and incorporated in the conditional random ﬁeld. A detailed description of the graphs can be
found in the text. The average convergence time (in seconds) of the expansion, swap and ICM algorithms (in this order) for the
different experiments were: (a) 3.3, 6.4, 312.3, (b) 3.5, 5.6, 384.6, (c) 3.3, 5.8, 318.4 (d) 9.6, 35.9, 298.1.
The graph in ﬁgure 9(a) shows how the convergence time is affected by the number of
higher order potentials. In the energy functions used for this experiment, each random variable
is included in the same number of higher order cliques. The x-axes of the graph shows the
Comparison of solution energy with respect to runtime. For the experiment, we used a CRF deﬁned over a rectangular
grid of 6000 random variables with a label set of size 7. The pairwise terms of the random ﬁeld enforced 8 connectivity. The
energy function used in the experiment had higher order potentials deﬁned over a random number of cliques. These cliques
were generated so that each variable of the random ﬁeld is included in exactly one higher order clique. The graph shows how
the energy of the solution obtained from different minimization algorithms changes with time when we use a Robust P n model
with the truncation parameter Q equal to one tenth of the clique size i.e. Q = 0.1|c|. It can be seen that expansion and swap
algorithms are much faster and produce better solutions than ICM.
number of higher order potentials each variable is involved in. As expected the convergence
time increases with the number of higher order potentials in the energy function. The graph
in ﬁgure 9(b) shows the effect of parameter γmax of the Robust P n model potentials on the
convergence time. The graph in ﬁgure 9(c) shows the effect of the truncation parameter Q of
the Robust P n model. Q is speciﬁed as the percentage of the size of the higher order clique.
The change in convergence time of the move making algorithms with the increase in size of the
label set of the random variables can be seen in graph 9(d).
B. Object Segmentation Results
For comparative evaluation of our method we implemented the state of the art TextonBoost 
algorithm which uses a pairwise CRF. We then augmented the CRF model by adding higher order
Qualitative object segmentation and recognition results. The ﬁrst column shows the original image from the Sowerby-7
dataset. Column 2 shows the result of performing inference in the pairwise CRF model described in section II. The result obtained
using the P n Potts potential (10) is shown in column 3. The results of using the Robust P n potential (13) is shown in column
4. The hand labelled segmentation used as ground truth is shown in column 5.
potentials deﬁned on segments obtained from mean-shift .
Datasets: We tested both the pairwise CRF and higher order CRF models on the MSRC-
21 and Sowerby-7 datasets. The MSRC dataset contains 23 object classes and comprises
of 591 colour images of 320×213 resolution. The Sowerby dataset contains 7 object classes and
comprises of 104 colour images of 96×64 resolution. In our experiments, 50% of the images
in the dataset were used for training and the remaining were used for testing.
C.. Setting CRF parameters
The optimal values for different parameters of the higher order CRF were found in a manner
similar to the one used for the pairwise CRF in . The model parameters were learned by
minimizing the overall pixelwise classiﬁcation error rate on a set of validation images - a subset
of training images which were not used for training unary potentials.
A simple method for selecting parameter values is to perform cross-validation for every
combination of unary, pairwise and higher order parameters within a certain discretized range.
Unfortunately, the space of possible parameter values is high dimensional and doing an exhaustive
search is infeasible even with very few discretization levels for each parameter. We used a
heuristic to overcome this problem. First we learned the weighting between unary potentials
from colour, location and Textonboost. Then we kept these weights constant and learned the
optimal parameters for pairwise potentials. Pairwise and higher order potentials have similar
functionality in the framework, thus learning of higher order parameters from the model with
optimal unary and pairwise parameters would lead to very low weights of higher order potentials.
Instead we learned optimal higher order parameters in CRF with only unary and higher order
potentials and in the last step the ratio between pairwise and higher order potentials. The ﬁnal
trained coefﬁcients for the MSRC dataset were θT = 0.52, θcol = 0.21, θl = 0.27, θp = 1.0,
θv = 4.5, θβ = 16.0, θα = 0.8, θh
p = 0.2, θh
v = 0.5, θh
β = 12.08. Parameter learning for higher
order CRFs is an ongoing topic of research.
D.. Quantitative Segmentation Results
The results of our experiments show that integration of higher order P n Potts model potentials
quantitatively and qualitatively improves segmentation results. The use of the robust potentials
lead to further improvements (see ﬁgure 4,11, 13 and 15). Inference on both the pairwise and
higher order CRF model was performed using the graph cut based expansion move algorithm.
The optimal expansion moves for the energy functions containing the Robust P n potential (13)
were computed using the method described in the previous section .
Effect of Multiple Segmentations: The use of multiple segmentations allows us to obtain
accurate segmentations of objects with thin structures. For instance, consider the image shown in
ﬁgure 12 (a). Our method produces an accurate segmentation (ﬁgure 12 (g)) of the bird which,
unlike the solution of the pairwise CRF (ﬁgure 12 (f)), also contains the bird’s leg. This result
does not require that many super-pixels contain both: a part of the bird’s leg, and a part of the
bird’s body. In fact, as shown in ﬁgures 12 (b) and (c), many super-pixels contain only the leg
and many other super-pixels contain only (a part of) the bird without the leg. As we explain
below, our method can work even if only one super-pixel contains both the bird body and leg
The reader should observe that solution of the higher order CRF (ﬁgure 12 (g)) is roughly
consistent9 with all super-pixels present in the multiple segmentations (ﬁgures 12 (b), (c) and
8The magnitude of the learned parameter values does not correctly reﬂect the relative strength (importance) of higher order
potentials vis a vis pairwise potentials. Higher order potential costs (see equations 9 and 10) are multiplied by a term dependent
on the size of the clique (segment). This is typically a large number and makes the cost of higher order potentials high compared
to that of the pairwise potentials.
9The solution does not assign different labels to many pixels belonging to the the same super-pixel.
Segmenting objects with thin structures using multiple segmentations. (a) An images from the MSRC-21 dataset.
(b), (c) and (d) Multiple segmentations of the image obtained by varying the parameters of the mean shift algorithm . (e)
Labelling from TextonBoost unary potentials (see section II). (f) Result of the pairwise CRF (see section II). (g) Results obtained
by incorporating the Robust P n higher order potential (13) deﬁned on the segments. (h) Hand labelled result used as ground
(d)). The solution is thus assigned a low cost by the higher order label consistency potentials.
Now consider the solution of the pairwise CRF (ﬁgure 12 (f)). This labelling is consistent with
super-pixels in two segmentations (ﬁgure 12 (b) and (c)), but is inconsistent with regards to the
segmentation shown in ﬁgure 12 (d). It assigns ‘bird’ and ‘water’ labels to pixels constituting
the super-pixel which contained the bird, and is thus assigned a high cost by the higher order
label consistency potential deﬁned on that super-pixel.
Use of Image Speciﬁc Appearance Models: Shotton et al. used the segmentation
result obtained from the pairwise CRF to build an image speciﬁc colour appearance model for the
different object classes. They added unary potentials derived from these models in their pairwise
CRF model. The appearance models were also iteratively reﬁned (as proposed by Rother et al.
 ) to obtain the ﬁnal segmentation result. In our experiments, we observed that although
the use of image speciﬁc models leads to better segmentations for some of the images, it led
to worse solutions for some others. Therefore, while comparing results of pairwise and higher
order random ﬁeld models, we decided against using this technique to avoid obfuscation of the
Some qualitative results. Please view in colour. First Row: Original Image. Second Row: Unary likelihood labelling
from Textonboost . Third Row: Result obtained using a pairwise contrast preserving smoothness potential as described in
 . Fourth Row: Result obtained using the P n Potts model potential . Fifth Row: Results using the Robust P n model
potential (13) with truncation parameter Q = 0.1|c|, where |c| is equal to the size of the superpixel over which the Robust P n
higher order potential is deﬁned. Sixth Row: Hand labelled segmentations. Observe that the results obtained using the Robust
P n model are signiﬁcantly better than those obtained using other methods. For instance, the leg of the sheep and bird have
been accurately labelled which was missing in other results. Same can be said about the tail and leg of the dog, and the wings
of the aeroplane.
Accurate hand labelled segmentations which were used as ground truth. The ﬁgure shows some images from the MSRC
data set (column 1), the hand labelled segmentations that came with the data set (column 2), and the new segmentations hand
labelled by us which were used as ground truth (column 3).
Ground Truth: The hand labelled ‘ground truth’ images that come with the MSRC-23 data
set are quite rough. In fact qualitatively they always looked worse than the results obtained from
our method. The hand labelled images suffer from another drawback. A signiﬁcant numbers of
pixels in these images have not been assigned any label. These unlabelled pixels generally occur
at object boundaries and are critical in evaluating the accuracy of a segmentation algorithm. It
should be noted that obtaining an accurate and ﬁne segmentation of the object is important for
many tasks in computer vision.
In order to get a good estimate of our algorithm’s accuracy, we generated accurate segmentations which preserved the ﬁne object boundaries present in the image. Generating these
segmentations is quite time consuming. It takes between 15-60 minutes to hand label one image.
We hand labelled 27 images from the MSRC data set. Figure 14 shows the original hand labelled
images of the MSRC data set and the new segmentations manually labelled by us which were
used as ground truth.
Evaluating Accuracy: Typically the performance of a segmentation algorithm is measured
by counting the total number of mislabelled pixels in the image. We believe this measure is
Qualitative results of our method. (a) Original Images. (b) Segmentation result obtained using the pairwise CRF
(explained in section II). (c) Results obtained by incorporating the Robust P n higher order potential (13) deﬁned on segments.
(d) Hand labelled result used as ground truth.
not appropriate for measuring the segmentation accuracy if the user is interested in obtaining
accurate segmentations as alpha mattes with ﬁne object boundaries. As only a small fraction of
image pixels lie on the boundary of an object, a large qualitative improvement in the quality of
the segmentation will result in only a small increase in the percentage pixel-wise accuracy. This
phenomenon is illustrated in ﬁgure 16.
With this fact in mind, we evaluate the quality of a segmentation by counting the number
of pixels misclassiﬁed in the region surrounding the actual object boundary and not over the
entire image. The error was computed for different widths of the evaluation region. The evaluation
regions for some images from the MSRC dataset are shown in ﬁgure 17. The accuracy of different
segmentation methods is plotted in the graph shown in ﬁgure 18.
The relationship between qualitative and quantitative results. (a) Original Image. (b) Segmentation result obtained
using the pairwise CRF (explained in section II). Overall pixelwise accuracy for the result is 95.8%. (c) Results obtained by
incorporating the Robust P n higher order potential (13) deﬁned on segments. Overall pixelwise accuracy for this result is
98.7%. (d) Hand labelled result used as ground truth. It can be seen that even a small difference in the pixelwise accuracy can
produce a massive difference in the quality of the segmentation.
Boundary accuracy evaluation using trimap segmentations. The ﬁrst column shows some images from the MSRC
dataset . The ground truth segmentations of these image are shown in column 2. Column 3 shows the trimaps used for
measuring the pixel labelling accuracy. The evaluation region is coloured gray and was generated by taking an 8 pixel band
surrounding the boundaries of the objects. The corresponding trimaps for an evaluation band width of 16 pixels is shown in
VIII. CONCLUSIONS AND FUTURE WORK
In this paper we proposed a novel framework for labelling problems which is capable of
utilizing features based on sets of pixels in a principled manner. We also introduced a novel
family of higher order potentials which we call the robust P n model. We showed that energy
functions composed of such potentials can be minimized using the graph cut based expansion
Pixelwise classiﬁcation error in our results. The graph shows how the overall pixelwise classiﬁcation error varies as
we increase the width of the evaluation region.
and swap move algorithms. Our methods for computing the optimal expansion and swap moves
are extremely efﬁcient. They can handle potentials deﬁned over cliques of thousands of random
variables.
We tested this approach on the problem of multi-class object segmentation and recognition.
Our experiments showed that incorporation of P n Potts and robust P n model type potential
functions (deﬁned on segments) in the conditional random ﬁeld model for object segmentation
improved results. We believe this method is generic and can be used to solve many other labelling
problems. In the future we would like to investigate the use of more sophisticated higher order
potentials based on the shape and appearance of image segments. We believe that such potentials
would be more discriminative and will result in even better performance.
Up until now, the work on solving higher order potentials using move making algorithms has
targeted particular classes of potential functions. Developing efﬁcient large move making for
exact and approximate minimization of general higher order energy functions is an interesting
and challenging problem for future research. Another interesting direction would be study and
use of primal-dual schema (such as Fast-PD ) for efﬁciently minimizing the class of higher
order potentials proposed in this paper.
IX. ACKNOWLEDGEMENTS
This work was supported by the EPSRC research grant GR/T21790/01(P), HMGCC and
the IST Programme of European Community, under the PASCAL Network of Excellence. We
also would like to thank Sarah Mercer and Howard Cummings for support and encouragement.
Professor Torr is in receipt of a Royal Society Wolfson Research Merit Award, and would like
to acknowledge support from the Royal Society and Wolfson foundation.