IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 9, NO. 6, NOVEMBER 1998
Comparative Study of Stock Trend Prediction
Using Time Delay, Recurrent and
Probabilistic Neural Networks
Emad W. Saad, Student Member, IEEE, Danil V. Prokhorov, Member, IEEE,
and Donald C. Wunsch, II, Senior Member, IEEE
Abstract—Three networks are compared for low false alarm
stock trend predictions. Short-term trends, particularly attractive
for neural network analysis, can be used proﬁtably in scenarios
such as option trading, but only with signiﬁcant risk. Therefore,
we focus on limiting false alarms, which improves the risk/reward
ratio by preventing losses. To predict stock trends, we exploit
time delay, recurrent, and probabilistic neural networks (TDNN,
RNN, and PNN, respectively), utilizing conjugate gradient and
multistream extended Kalman ﬁlter training for TDNN and RNN.
We also discuss different predictability analysis techniques and
perform an analysis of predictability based on a history of daily
closing price. Our results indicate that all the networks are
feasible, the primary preference being one of convenience.
Index Terms—Conjugate gradient, extended Kalman ﬁlter, ﬁnancial engineering, ﬁnancial forecasting, predictability analysis,
probablistic neural network, recurrent neural network, stock
market forecasting, time delay neural network, time series analysis, time series prediction, trend prediction.
I. INTRODUCTION
UR approach to market forecasting capitalizes on two
observations: that predictions over a relatively short time
are easier to do reliably, and that attempts to proﬁt on shortterm moves need this reliability to compensate for risks, taxes,
and transaction costs. We arbitrarily select a 2% upwards
move in stock price within 22 working days as presenting a
reasonable opportunity to proﬁt utilizing a suitable leveraged
strategy such as call options or margin trading. The risks
inherent in such a strategy require a strong emphasis on
reliability of signals. Therefore we focus on limiting false
alarms, i.e., inaccurate prediction of 2% or greater increases,
adopting a strategy of waiting for the best opportunities to
take a position. Incidentally, focusing only on upwards moves
is chosen because of the general upward trend of the market
over time.
Earlier we demonstrated that short-term predictions are
achievable using probabilistic, time-delay, and recurrent net-
Manuscript received July 16, 1996; revised June 3, 1997 and June 30, 1998.
This work was supported by the National Science Foundation, Ford Scientiﬁc
Research Laboratory, Texas Advanced Technology Program, and the Texas
Tech Center for Applied Research.
E. W. Saad and D. C. Wunsch, II, are with the Applied Computational
Intelligence Laboratory, Department of Electrical Engineering, Texas Tech
University, Lubbock, TX 79409-3102 USA.
D. V. Prokhorov is with the Scientiﬁc Research Laboratory, Ford Motor
Co., Dearborn, MI 48121-2053 USA.
Publisher Item Identiﬁer S 1045-9227(98)07353-6.
works – . This paper compares the three networks and
evaluates them against a conventional method of prediction.
Also, a predictability analysis of the stock data is presented
and related to the neural-network results. In Sections II–IV,
we describe the architecture as well as the training procedure
of the time-delay, probabilistic, and recurrent neural networks
(TDNN, PNN, and RNN), respectively. Section V describes a
linear classiﬁer, for the purpose of comparatively evaluating
the neural networks performance. In Section VI, we present
several techniques which can be used to analyze the predictability of the different stocks. In Section VII, the different
experimental tests as well as their results are described, starting
with the predictability tests, followed by the actual forecasting
using different neural networks and conventional classiﬁer.
Section VIII contains a comparison of the three networks from
the point of view of architecture, implementation complexity,
training time, and forecasting capability, and Section IX is the
conclusion.
II. TIME-DELAY NEURAL NETWORKS
The TDNN used in this study are feedforward multilayer
perceptrons, where the internal weights are replaced by ﬁnite
impulse response (FIR) ﬁlters (Fig. 1). This builds an internal
memory for time series prediction – . Our goal is not
price prediction but rather trend prediction, which can be
formulated as a problem of pattern classiﬁcation. An output
of “1” corresponds to an upward trend of 2% or more, while
an output of “ 1” corresponds to a downward trend or upward
trend less than 2%. TDNN is appropriate for this because trend
prediction requires memory.
By using FIR ﬁlters as synaptic connections, each weight is
replaced by a weight vector
is the vector carrying signals from neuron
The output state of neuron
dimensional vector
, storing the history of the state of neuron
previous time steps
The input signal to every neuron at the application of the input
includes the output signals from the previous layer
1045–9227/98$10.00 1998 IEEE
SAAD et al.: COMPARATIVE STUDY OF STOCK TREND PREDICTION
(a) Three-neuron TDNN with FIR ﬁlters (wji) as synaptic connections. (b) Expanded view of FIR synaptic connections of TDNN. FIR ﬁlters
build internal memory into the network.
at time steps ,
is the delay
associated with the corresponding weight vector.
Taking the inner product of
, we get the output
of the weight ﬁlter
Summing the FIR weights outputs, we get the activation
of the neuron
is the number of neurons in the previous layer of
the network and
represents a threshold. The nonlinear
activation function of the neuron then produces an output
For all neurons, we used the hyperbolic tangent activation
which usually accelerates training .
A. Cost Function
Conventional training of TDNN consists of minimizing a
cost function, the mean square error of the network. Since
we are willing to forego some proﬁt opportunities in order
to limit false alarms, we introduce a penalizing factor which
punishes the network for false alarms more than for missed
proﬁt opportunities
is the desired output.
The quadratic error of the network is multiplied by the
penalizing factor
The penalizing factor is equal to one if classiﬁcation is correct,
to the constant
for missed predictions, and to
alarms. To limit the false alarm ratio,
is greater than
IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 9, NO. 6, NOVEMBER 1998
PNN architecture. This network is the fastest in training, at the cost of
requiring one hidden unit (pattern unit) for each pattern in the entire training
B. Training TDNN
One way to train TDNN is to transform the network into a
static one by unfolding it in time . However, this method
has the drawback of creating redundant weights, and therefore
needs bookkeeping, in addition to that it does not have
symmetry between forward propagation and backpropagation.
Another method is temporal backpropagation . While minimizing the total cost, this method incorporates dependence
of the future step costs on the current step state. Detailed
description of the training method can be found in . We
further enhance our system by utilizing conjugate gradient
training , – . Results of TDNN forecasting using the
above techniques appear in Section VII.
III. PROBABILISTIC NEURAL NETWORK
The probabilistic neural network (PNN) is an algorithm
for approximating the Bayesian decision rule . We use a
PNN with four layers of dedicated nodes (Fig. 2). Twenty-nine
input nodes are fully connected with the next layer of pattern
nodes. Input nodes distribute components of the input
PNN requires one pattern node for every pattern in the training
set. The th pattern node output function is
is the th training pattern, and
is the smoothing
parameter of the Gaussian kernel. Other alternatives to
available , including
with adaptable
 , and full
covariance matrices .
The third layer is formed by summation nodes which sum
the outputs
of those pattern units that correspond to two
categories of predictions, A and B. In our case, category A is
an acceptable proﬁt in the next 22 working days, and category
B is the opposite.
The output node adds signals from these two summation
nodes, with only the summation node B weighted by the
is the ratio of losses associated with false
alarms to those associated with missed proﬁt opportunities.
We have used
, emphasizing the importance of avoiding
false alarms. At the output, we have a hard-limiting threshold:
whenever an input pattern
belongs to category (A) and
if it is from category (B).
PNN memorizes all training patterns. Each time a new
is presented to the network, it computes (9) for
all pattern units, sums up the resulting
’s in the summation
units, and outputs the result. PNN’s generalization certainly
depends on the value of the smoothing parameter
how well the training data represents the problem domain.
Our approach to forecasting with PNN is based on the
following preprocessing technique , . For each pattern,
29 inputs are used: 14 Level-0 features and 15 Level-1
features. The deﬁnition for our features are
exponential moving average of
is the stock’s closing price on day , and
The idea behind (11)–(13) is that the stock price series is
assumed to be formed of cycles of different frequencies. If we
sample the data at different frequencies, the samples would
carry all the information in the series. In order to do this,
we use sample blocks of data. The farther in the past is the
block, the further it is spaced from the next block, and the
larger is the block size. The index
determines how far back
in time the center of the block is situated.
is chosen such
that it covers the period between the consecutive blocks. The
are provided as shown in (13a) at the bottom
of the page. After several tests, we selected
almost six months (about 113 working days) of historical data
SAAD et al.: COMPARATIVE STUDY OF STOCK TREND PREDICTION
Recurrent network architecture. Z 1 represents a one time step delay
unit. This network has a compact memory structure. The EKF described is
well-suited for this architecture.
are used to predict the trend of the stock closing price in the
next month.
Results of PNN forecasting appear in Section VII.
IV. RECURRENT NEURAL NETWORK AND ITS TRAINING
The recurrent neural network (RNN) considered in this
paper (Fig. 3) is a type of discrete-time recurrent multilayer
perceptrons . Temporal representation capabilities of this
RNN can be better than those of purely feedforward networks,
even with tapped-delay lines. Unlike other networks, RNN is
capable of representing and encoding deeply hidden states, in
which a network’s output depends on an arbitrary number of
previous inputs.
Among many methods proposed for training RNN’s, extended Kalman ﬁlter1 (EKF) training stands out . EKF
training is a parameter identiﬁcation technique for a nonlinear
dynamic system (RNN). This method adapts weights of the
network pattern-by-pattern accumulating training information
in approximate error covariance matrices and providing individually adjusted updates for the network’s weights.
We assume that all weights of the RNN are assembled in
. This can be split into
as a vector of the
th group of weights, we
assume that
It is required by the EKF method that we compute derivatives of the RNN’s
outputs, rather than output errors, with
respect to the weights . These derivatives are obtained
through backpropagation through time or its truncated version
 , . We store them in a set of matrices
has dimension: size
. This set is obtained
by truncated backpropagation through time, with depth 20,
meaning that we do not use more than 20 copies of the network
to accumulate appropriate derivatives.
1We note that the full name of the EKF method described here is parameterbased node-decoupled EKF.
The following equations form the basis of the EKF training
procedure:
is a scalar learning rate,
is the Kalman gain
matrix for the th group of weights,
error vector,
is a vector of the desired outputs,
is the actual output vector of the RNN;
forms the squared error to be minimized, where
user-speciﬁed matrix introduced to incorporate weighting of
individual components in the error vector
(this matrix is
often equal to the unity matrix, but it incorporates the penalty
of (7) and (8) in our case),
is the size
approximate error covariance matrix which models
correlation between each pair of weights within the th group
of weights, and
is a positive diagonal matrix that helps
to avoid numerical divergence of the procedure and prevents
getting stuck in a local minimum .
Grouping of weights can be done in a variety of ways.
We employ grouping by node, i.e., weights belonging to the
same neuron are grouped together. Thus, we ignore correlation
between weights belonging to different neurons. This results
in a signiﬁcant reduction of computational complexity and
storage requirements since the size of each error covariance
can then be made much smaller than
, the size
in the case when
The matrices
are initialized as diagonal matrices with
large diagonal elements (values between 100 and 10 000).
User-speciﬁed values of
are usually increased from 0.01
to 10 whereas diagonal components of
are decreased
from 0.01 to 10
as training progresses.
When there is a large data base including a variety of operational conditions (different market trends), batch updating
of weights is superior to pattern-by-pattern updating since the
network learns to simultaneously minimize error on a batch
of patterns taken from different regions of the data base. To
combine efﬁciency of EKF training with a batch-like update,
without violating consistency between the weights and the
approximate error covariance matrices
, the multistream
training approach was ﬁrst proposed and tested in .
data streams. It is then useful to consider
copies of the same RNN (weights are identical for all the
copies). Each copy is assigned a separate stream. We apply
each copy of the RNN to a training vector drawn from its
stream. We obtain
stream error vectors and
sets of matrices
. We concatenate all
to form one
of dimension:
denotes the total number
of columns. Concatenating all the stream error vectors results
in a single error vector
of dimension:
is the total number of rows. The number of columns
of each of the Kalman gain matrices
is increased
IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 9, NO. 6, NOVEMBER 1998
The global scaling matrix
also grows
times for each of
its dimensions.
Among all these increases of dimensionality, only the matrix
’s “swelling” is critical because it must be inverted. This may
be a potential bottleneck of the training procedure, particularly
are large. While applying the multistream
EKF procedure to a variety of real-world tasks, we have,
however, experienced no problems , , . We have
found singular-value decomposition best for inverting
100 elements .
Allocation of data streams can be done in various ways. It is
impractical to use too short streams since the total number of
may otherwise be too large, prohibiting inversion
. On the other hand, having too few streams may not
cause a signiﬁcant improvement over the one-stream (basic)
EKF training. We usually see an order of magnitude faster and
superior generalization with the multistream EKF. For large
data sets, this advantage increases. One-stream training fails
for sets of several thousand vectors , . We have used
multistream EKF training of RNN for predicting trends of
several stocks. A typical stock history amounts to less than
2500 days. Any of 40 training streams starts from an entry
point chosen randomly in the whole set. One weight update is
then based on 40 training pairs. After the ﬁrst 40 pairs have
been processed, we proceed to the next 40 pairs. We repeat
updating until acceptable performance is attained.
Our ﬁnal network’s architecture is the one-hidden-layer
RNN with one input of a normalized daily closing price,
eight fully recurrent hidden neurons and one output neuron.
Recurrent and output nodes have the common bipolar sigmoid
nonlinearity deﬁned by (6).
Training usually lasts for around one hundred passes, where
one pass corresponds to a complete processing of the whole
training set. As in Section II-A, we also incorporated penalizing factors in the error measure for RNN training. We
have experimentally determined that the optimal range for the
penalizing factor is between 3 and 5. Missed opportunities
receive no extra penalty.
V. CONVENTIONAL CLASSIFIER
It is useful to check the performance of a linear classiﬁer
applied to our problem. This establishes the lower limit
of performance when comparing results of various neural
networks (see Section VII).
The linear classiﬁer we used is the Fisher linear classiﬁer
 , which has the form
is the vector to be classiﬁed. It consists of a delay
line of length 50:
carries the stock price on the day of purchase as well as on
the previous 49 days.
is a linear mapping function, and
is a threshold. If
is positive, the pattern is classiﬁed as
a proﬁt opportunity.
We deﬁne the within-class scatter matrix and the betweenclass scatter matrix, respectively, as
means the sample belongs to class
expected vector,
is the covariance matrix,
is the a priori
probability of class , and
is the expected vector of the
mixture distribution which is expressed by
Our criterion is to ﬁnd the mapping function
maximizes the between-class scatter and minimizes the withinclass scatter. There are several ways to formulate this criterion.
The map is then found to be
The optimum threshold is calculated as follows :
as criteria is valid only when the class means
are distinct. Calculation of the two-class mean vectors showed
them to be relatively distinct. We compare performance of the
linear classiﬁer (18)–(24) with that of neural networks of the
preceding sections in Section VII.
VI. PREDICTABILITY ANALYSIS
The stock market is governed by a mixture of both deterministic and random factors. It is partially random, partially
chaotic . Though chaotic series are hard to distinguish from
random ones, they are driven by deterministic equations. While
random series are unpredictable, chaotic ones are in many
cases predictable by neural networks which can learn to model
the underlying function from samples. Predictability analysis
is intended to determine the degree to which a stock is chaotic.
This can be achieved by several tools, either graphical or
quantitative. As we will see, the graphical methods described
here are easier to use but carry little information. Therefore,
they are typically used as a preliminary test. Quantitative
methods require more computations, but they are usually more
powerful. However, the state of the art at this writing is still
A. Phase Space Diagrams
A phase space diagram (phase diagram) is the easiest test
of chaotic behavior. It is a scatter plot where the independent
variable is the value of a time series (i.e., closing price)
at time , and the dependent variable is
SAAD et al.: COMPARATIVE STUDY OF STOCK TREND PREDICTION
(a) Three-dimensional phase diagram of AAPL stock with
shows some regularity. (b) Two-dimensional phase diagram of a random
series. The path covers all the data range.
The phase diagram of a deterministic system is identiﬁed
by its regularity. The trajectory is contained in a limited area
of the range of the series called an attractor. Furthermore, if
the series is chaotic, the attractor has a complicated shape and
is called a strange attractor. This is in contrast to a random
series where the trajectory covers all the range of the diagram
Phase diagrams can be plotted only in two or three dimensions, which is the main shortcoming of this technique. Each
dimension is called the embedding dimension. The process
of representing a system by one variable and its lagged
versions is called embedding . A system, with an
dimensional attractor, can be embedded in an
dimensional
space provided that
This is according to Takens embedding theorem . The
attractor dimension can be estimated by different ways, including the method explained in the following section. While
Takens theorem gives no indication of how to choose
, Abarbanel et al. proposes the following method to calculate a
suitable value for
. We ﬁrst compute the correlation factor
as a function of
. The denominator is simply the variance
and it serves for normalization. We then ﬁnd the value of
which gives the ﬁrst zero correlation, as the lag for the phase
space. An alternative method is to choose
which gives the
ﬁrst minimum of the mutual information
This is supported by the argument that the different coordinates
should be an uncorrelated delay (see also Section VI-D1).
Unfortunately, according to (25), the method of plotting the
phase diagram in two or three dimensions is valid only for
attractors of dimension less than unity and hence unusable for
most economic systems due to their high dimensionality.
B. Correlation Dimension
This is one of the most popular measures of chaos. It has
been introduced by Grassberger and Procaccia , and it is
a measure of the fractal dimension of a strange attractor. The
name fractal comes from the fact that the dimension is not an
integer . For example, the attractor of a stable system is a
point which has zero dimension. The attractor of an oscillating
system is a circle which has two dimensions. These attractors
have integer dimensions. A chaotic attractor is characterized
by a noninteger dimension. The correlation dimension
be viewed as measure of the deviation of a time series from
randomness and is calculated as follows.
1) We choose a suitable time lag
. From the scalar time
series, we form
embedding dimensions
2) For every point, we count the number
within a hypersphere of radius
centered at that point.
Assuming random distribution, the probability that a
point lies within
of the chosen point will be
points, we get the average probability
otherwise.
3) We vary , calculate
, and plot log
for a given value of
IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 9, NO. 6, NOVEMBER 1998
4) The slope of the linear part of this curve is the correlation
, based on the relation
5) We calculate then
and plot it against the embedding dimension over a sufﬁciently large range of
increases inﬁnitely with
, this indicates that the
process is random. If it stabilizes after some value of
this indicates that we have a chaotic series.
1) Effect of Finite Number of Data Points: If we use a series of ﬁnite length
, it establishes an upper limit on the
calculated correlation dimension . Consider the slope of
orders of magnitude, extending from
which correspond to
, respectively. We then
The lower limit of
, and the upper limit is
one. For large
, the calculated fractal dimension will have an
upper limit of
. If we calculate the slope over just
one order of magnitude, the upper limit becomes
For ﬁnancial data series of length of the order of 1000
(corresponding to about four-year history), the upper limit
becomes six. Hence this method fails for a large class of ﬁnancial series, because of their high dimensionality. In addition,
nonstationarity of the stock price will hinder its use even if
data covering a long history is available.
C. Lyapunov Exponent
Chaos is characterized by sensitivity to initial conditions.
The Lyapunov Exponent measures divergence of two orbits
starting with slightly different initial conditions . If one
orbit starts at
and the other at
steps, the
divergence between orbits becomes
. For chaotic orbits,
exponentially for large
is the Lyapunov Exponent
A positive exponent indicates chaotic behavior. From our
ﬁnancial data the Lyapunov Exponent is calculated as follows.
1) We test the series by plotting
relation is close to linear, then the divergence is exponential and we can proceed to calculate the Lyapunov
2) Starting from two points
close in value but
not in time, we have
3) We repeat the last step for an arbitrary
times and calculate the Lyapunov exponent at each time
using (36) and take the average value.
The Lyapunov exponent method can be used for high dimensionality series since it does not involve calculating the
system dimension. The lower limit on the series length is
the number of points
on which the exponent is averaged.
Usually several hundred points are enough.
D. Relation of the Predictability Analysis to Choices of
Neural Network Techniques
1) Network Architecture: The neural-network architecture
and the phase space characteristics of a time series are strongly
related. Calculating the fractal dimension of a series by the
method of Grassberger gives us an estimate of the number
of degrees of freedom in the system. If we then calculate a
suitable delay using (26), we can reconstruct the phase space
of the system. Since highly correlated inputs to the network are
redundant , using the reconstructed phase space variables
as inputs to
the time delay network, might be an improvement.
If the conventional methods fail to calculate the system
dimension, we can minimize output error of a neural network
as a function of the number of hidden neurons , . This
number can estimate the system dimension.
2) Multistep Prediction: Chaotic systems are characterized
by the exponential divergence between two closely starting
paths. This makes the multistep prediction of a chaotic system
an impossible task . Even if the network is very well
trained to make one step predictions, a very small error at
the ﬁrst step prediction will increase exponentially with time
and may be unacceptable after the
-step prediction according
to the relation
are the ﬁrst and
th step prediction errors,
respectively.
We have previously compared neural and conventional
(ARMA) techniques for price prediction , as opposed to
trend classiﬁcation considered in this paper. While performance of both TDNN and ARMA is similar for single step
predictions, TDNN outperforms ARMA in accuracy of multistep predictions.
Comparing neural network prediction to a threshold autoregressive (TAR) model predictions of the sunspot series,
Weigend found that both were comparable in single step
predictions, but the neural network outperformed the TAR
model in multistep predictions. He also suggests in that
instead of using the Lyapunov exponent to calculate the
prediction error, we can estimate Lyapunov exponent in (39)
SAAD et al.: COMPARATIVE STUDY OF STOCK TREND PREDICTION
Phase diagram for Apple stock using a delay of 22 days, shows some
regularity in contrast with the random series phase diagram in Fig. 4.
through the calculation of the multistep prediction error. This is
particularly convenient when conventional methods fail due to
insufﬁciency of data points or due to other practical problems.
Among neural networks used in this study, only RNN utilizes a concept of multistep predictions when its hidden nodes
feed themselves with their outputs from the previous time
step. Though distinct Lyapunov exponents of some stocks may
suggest using different truncation depths of backpropagation
through time for RNN training (see Section IV), we found
depth 20 to be a reasonable choice for all the stocks.
VII. RESULTS
Predictability and forecasting tests have been run on a
variety of stocks and on different data sets, where some
are more recent than the others. Generally the later tests
conﬁrm the earlier ones. The tests run in or before April 1996
include only Apple, IBM, Motorola, and Microsoft stocks. The
most recent tests run in 1997 include the following stocks
which cover a larger variety of categories: Apple (AAPL),
IBM (IBM), Motorola (MOT), Microsoft (MSFT) represent
the technology group which generally has high volatility.
American Express (AXP), Wells Fargo (WFC) represent the
banks. Walt Disney Co. (DIS), McDonald (MCD) represent the
consumer stocks. Public Svc New Mexico (PNM), Energas
(V.EEG) are cyclical stocks.
A. Predictability Analysis
1): Phase Diagrams: Phase diagrams of Apple, IBM, Motorola, and Microsoft stock prices have been plotted in two
dimensions, with a delay of 22 days, following the procedure
described in Section VI-A. They showed some regularity,
which indicate the presence of determinism in the stocks.
Fig. 5 shows the phase diagram of Apple stock. The other
stocks have similar diagrams.
2) Correlation Dimension: Calculated correlation dimension for the stocks under test was found to increase as
the embedding dimension is increased (up to an embedding
dimension of six for Apple stock). We interpret the failure of
this method as a consequence of the high dimensionality of
the ﬁnancial system as explained in Section VI-B-1.
3) Lyapunov Exponent: This is the most successful predictability analysis technique. Averaging over 50 points, we
found Lyapunov exponents of 0.44, 0.55, 0.31, and 0.3 for
Apple, IBM, Motorola, and Microsoft stocks, respectively, for
the data ending in April 1996. They are all positive, suggesting
that all the stocks under test are chaotic, hence predictable.
The Lyapunov exponents have been recalculated after updating
the data in April 1997 and adding more stocks. These newer
results are summarized in Table I. Most of the stocks have
a Lyapunov exponents in the same range, except the cyclical
stocks which have relatively lower Lyapunov exponents. A
zero Lyapunov exponent means either the series is random or
the series is periodic. The low Lyapunov exponent in this case
can be attributed to the periodicity present in the cyclic stocks.
4) Summary of Results: Though the Apple phase diagram
showed some regularity, it doesn’t carry much information
for the reasons explained in Section VI-A. The correlation
dimension failed as was expected due to the reasons explained
in Section VI-B. The Lyapunov exponent was the most successful test, and it is in agreement with the practical neural
networks results, since all stocks gave positive exponents
which indicates their deviation from randomness, and hence
the possibility of prediction. The periodicity in the PNM and
VEEG stocks was conﬁrmed by the small Lyapunov exponent.
B. Neural-Network Forecasting
In the following four tests, proﬁt opportunities are deﬁned as
days which are followed by a 2% up move of the stock closing
price, within the following 22 working days. Test number 5
also include predictions of 5 and 10% up moves.
1) Results of PNN: The probabilistic network was tested
, 2, 4, and 8, and for a smoothing parameter ranging
with a step of 0.025. These tests
were repeated using 500, 1000, 1500, and 1800 training points
ending on April 31, 1995. The test set had 200 points starting
from the end of the training set and ending on February 15,
1996. The best results of these tests are listed in Table II.
2) Results of TDNN: We have trained the time-delay network for iterative price prediction from which the proﬁt
opportunities were extracted. The stopping criteria, as explained in Section II-C, was stabilization of the error. The
network had 50 input delays and no delays in the hidden layer.
The test data extended from March 1, 1995 to August 23, 1995
(126 days). The best number of training days varied. Table III
shows the results.
3) Results of RNN: We trained RNN on data dating back
to January 2, 1987. The training was stopped as soon as the
network was trained long enough. Long enough was typically
below 100 passes, with a false alarm rate of less than 10%, and
missed about 80% of opportunities. We used a penalty factor
[see equations of Section II-A and matrix
in (14)] between
1 and 3, gradually increasing it. We usually started training
with values of the learning rate
as low as 0.01, increasing it
by an order of magnitude once in ten or 20 passes. A similar
strategy was applied to vary the diagonal components of the
except that we kept decreasing them to
(see Section IV). All diagonal components were ﬁxed to
be the same and to be varied in synchrony with adjustments
of the learning rate. Our results are given in Table IV.
IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 9, NO. 6, NOVEMBER 1998
LYAPUNOV EXPONENT’S FOR THE STOCK DATA, CALCULATED USING THE METHOD IN SECTION VI-C
BEST RESULTS OF PNN TESTED ON DATA ENDING ON FEBRUARY 15, 1996
RESULTS OF TDNN TESTED ON DATA ENDING ON AUGUST 23, 1995
RESULTS OF RNN TESTED ON DATA ENDING ON AUGUST 23, 1995
4) Comparative Test: Increasing the number of participating stocks, we added Microsoft for all three networks, and we
updated our data to the end of April 1996. The three networks
were tested on a 100 days set ending on March 20, 1996 (the
last month data was needed to calculate the proﬁt opportunity
of the last day in test). The results indicated that retraining the
networks was necessary. We retrained the three networks by
augmenting our old training sets with new data up to October
18, 1995. The results of the three networks are summarized in
Table V and shown in Fig. 6.
For the PNN, we tried combinations of
range around those values which gave the best results in
the former test. The new results were as good as the old
The TDNN was trained to do direct trend prediction, which
is easier than the price prediction. We used the technique
described in Section VI-D1 to determine the delays between
the network inputs. In training the networks, different combinations of the network parameters have been examined. These
variable parameters were the number of layers, number of
neurons in each layer, number of delays in each layer, delay
between inputs, penalty factor, length of training set and
range of initial random weights. In all cases a one-hiddenlayer network performed better than a two-hidden-layer one.
We used the correlation coefﬁcient described in Section VI-A
to estimate the delay between inputs. We used seven inputs
with delay
between one another for all stocks except
Microsoft for which we used ten inputs with delay
hidden layer had from three to seven neurons, and the input
and hidden layer delays were of equal values between seven
and ten. Thus, the input layer had both a coarse and a ﬁne
resolution delay lines. For Motorola, the false alarm rate was
always lower when training on the maximum available history
data, while for other stocks shorter training sets (300 to 500
days) were necessary to achieve best results. A small penalty
factor resulted in a high false alarm rate while a large one
resulted in zero proﬁt prediction. For all stocks, the optimum
penalty factor was
[See (8)].
For the RNN, the training strategy was similar to the one
described above. We however found that an increase in the
penalty factor was necessary in order to avoid making an
unacceptable number of false predictions (above 10–15%).
We typically started with the penalty factor of two gradually
increasing it to ﬁve, and trained for less than 150 passes.
SAAD et al.: COMPARATIVE STUDY OF STOCK TREND PREDICTION
Actual and predicted proﬁt opportunities for (a) Apple, (b) IBM, (c)
Motorola, and (d) Microsoft. The predictions are generally spread over the
period, with a low false alarm rate.
The new results in Table V show that the RNN made a
small number of predictions comparing with its performance
illustrated in the Table IV. It is a manifestation of a higher
penalty imposed for false alarms during training.
5) Predicting Higher Trends: In order to test the ability of
the neural networks to predict higher percentages of increase,
more tests have been performed on data last updated in
April 1997. In addition, a wider variety of stocks have been
tested. The same approach have been used as in the previous
comparative test (see Section VII-B4). The simulation results
are summarized in Table VI.
In Table VI, the tests giving zero predictions would give
some predictions if the penalizing factor was decreased, but
with unacceptably high false alarm rate (50% or more).
Generally, the prediction of 5% upward trend is possible with
acceptable false alarm rate. Predicting 10% upward usually
leads to either a signiﬁcantly higher false alarm rate, or to
zero predictions.
Comparing the different stock categories, we think that
technology stocks are generally harder to predict due to their
higher volatility.
C. Conventional Classiﬁer
The linear classiﬁer was tested on the same 100-day test
set used for the neural networks (see Table IV). We found
that the shorter training set of 500 points, rather than all the
available history data since January 1987, gave the best results
summarized in Table VII.
We then performed a linear classiﬁer test with data updated
until April 1997 to predict 2, 5, and 10% trend. The best
results are shown in Table VIII.
Comparing Tables VI and VIII, we can see that the linear
classiﬁer produced higher false alarm rates than the neural net
methods, as expected.
VIII. COMPARISON
A. Network Architecture
The PNN is a four-layer network. The number of neurons
in the ﬁrst hidden layer is equal to the number of training
patterns. This means that using 1000 training patterns with 29
inputs each requires 29 000 weights between the input and
ﬁrst hidden layer. While training TDNN or RNN with so
many weights would be difﬁcult, training PNN is essentially
an allocation of memory. However, testing PNN on every new
pattern requires carrying out operations prescribed by (9) with
each stored pattern, which may take signiﬁcantly more time
than testing TDNN or RNN.
The TDNN is a moderate-size network, generally of three or
four layers. In most of our tests we used a three-layer network
with ﬁve to ten input nodes, three to seven hidden nodes, and
one output node. We used seven to ten delays in the input and
hidden layers. The largest network required 841 weights.
The RNN has a compact structure. In all tests we used
a three-layer network of one input, one output, and eight
fully recurrent hidden neurons. The resulting network had 89
B. Implementation Complexity and Training Time
Among the three networks, the PNN is the simplest to
implement. All connections are in the forward direction. No
derivatives are calculated. Therefore it is the fastest network
in training. Other architectures exist which similarly have the
advantage of fast training – . The weights between the
input and pattern units are directly determined by training
patterns. The weights of the output neuron are set according to
(10). Training time is determined by duration of the leave-oneout test to estimate the best
, and it is typically much
less than training time for either TDNN or RNN.
IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 9, NO. 6, NOVEMBER 1998
COMPARISON OF TDNN, PNN, AND RNN BEST RESULTS FOR DATA ENDING MARCH 23, 1996. THE FALSE ALARM RATE IS RELATIVELY LOW FOR ALL OF THEM
PREDICTING 2, 5, AND 10% COMPARISON FOR DATA ENDING IN APRIL 1997. A LOW FALSE ALARM RATE COULD STILL BE ACHIEVED
RESULTS OF THE LINEAR CLASSIFIER TEST ON DATA ENDING ON AUGUST 23, 1995
SAAD et al.: COMPARATIVE STUDY OF STOCK TREND PREDICTION
TABLE VIII
RESULTS OF THE LINEAR CLASSIFIER TEST ON DATA ENDING IN APRIL 1997. MOST OF THE RESULTS ARE WORSE THAN THE NEURAL NETWORKS ONES
TDNN training is an iterative process where each cycle
consists of one or more forward propagations through the
network, and one backpropagation to obtain derivatives of the
cost function with respect to the network weights. The weights
form a three-dimensional matrix of size equal to the square of
the total number of neurons multiplied by the total delay in
all layers plus one. The implementation of both forward and
backward passes requires careful bookkeeping of indexing.
In order to accelerate the training, it is necessary to use
an efﬁcient training method like the conjugate gradient presented above. This requires extra subroutines to calculate the
direction of descent and to perform the line minimization.
Training is an iterative process. The number of iterations
varies from tens to several thousands. Every iteration includes
one backpropagation and one or more forward propagations
for the line minimization required by the conjugate gradient
algorithm. When training in batch mode, we need to repeat
the above iterations for all the training patterns in every cycle.
The training speed is proportional to the number of training
patterns and depends on the network’s size. Training time
of our experimentations varied between a few minutes and
several hours on a Pentium Pro 200 PC.
Implementation complexity of the multistream EKF training
of the RNN consists of three main components: truncated
backpropagation through time, EKF computations, and the
’s inversion [see (14)]. Compared with complexity
of the TDNN training, only the last two components matter
since backpropagation computes derivatives in both training
Computational complexity of the EKF algorithm scales
linearly with the number of data streams used. Also, the
’s inversion imposes an additional computational
burden proportional to the cube of the number of streams.
Nonetheless, we did not ﬁnd increasing computational complexity a problem while using up to 50 streams. Furthermore,
the multistream EKF algorithm spends the same computer
processing time as does the conjugate gradient technique for a
similar neural network and identical training set on the same
workstation.
While TDNN training with the conjugate gradient method
invokes the line minimization routine, RNN training utilizes the EKF and matrix inversion routines. Adding to it
a nontrivial bookkeeping for recurrent connections, we thus
conclude that the overall implementation complexity of the
IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 9, NO. 6, NOVEMBER 1998
RNN training is the highest among the training methods
discussed in this paper.
C. Summary and Extension
The three networks showed comparable results. It was
possible to control the false alarm rate and even reduce it
to zero, in the case of PNN through the loss factor, and in the
case of TDNN and RNN through the penalty factor. Although
this generally reduces the number of the network predictions
to about 10% of the total number of proﬁt opportunities, this
can be acceptable while seeking conservative predictions.
One obvious application of our strategy is in options
trading. Considering a typical example like IBM stock, we
made the TDNN predict proﬁt opportunities for a period of
100 days ending April 21, 1997, and we picked up a typical
day when the network predicted a 2% increase like April
7, 1997, when the stock price was $129.125. Following a
two-month holding period strategy, a January 1998, $110
option (in the money) could be bought at the network “buy”
signal for $26.75 and sold on May 21, 1997 for $69. In the
case of trading on 1000 shares and assuming $50 commission
each way, the proﬁt would be $42.15/share, which is
equivalent to 157.57%. Or a January 1998 $130 option (at
the money) could be bought for $15.375 and sold on May 21,
1997 for $51. In this case the proﬁt would be $35.525/share,
which is equivalent to 231.06%. If we consider an out of
the money option like January 1998 $140, it could be bought
for $11 and sold on May 21, 1997 for $43, making a proﬁt
of $31.9/share, equivalent to 290%. On any selling day, not
being the day of peak price, these proﬁts would be typical
ones. Of course, any false alarms could incur losses of up
100%. Therefore, the aggressive trading strategy outlined
above really does need our emphasis on eliminating them.
IX. CONCLUSION
Predicting short term stock trends based on history of daily
closing prices is possible using any of the three different networks discussed here. Preliminary predictability analysis and
careful neuroengineering are important premises for successful
performance. The correlation coefﬁcient calculated using (26)
is useful in estimating the delay between the TDNN inputs. A
small Lyapunov exponent indicates either a random or cyclic
behavior of the stock. In the later case, it was noticed that a
relatively short training set should be used.
TDNN is moderate with respect to implementation complexity and memory requirement.
PNN has advantages of extreme implementation simplicity
and low false alarm rate even for stocks with low predictability. Its minor disadvantages are the storage requirement of
every training pattern and the increased testing time. PNN
is more suitable for stocks which do not need training on
long history, like Apple stock. This can be determined using
a validation set.
RNN has the capability to dynamically incorporate past
experience due to internal recurrence, and it is the most
powerful network among the three in this respect. Like TDNN,
RNN does not need large memory storage, but its minor disadvantage is the implementation complexity—a one-time task.
ACKNOWLEDGMENT
The authors gratefully acknowledge the help of the undergraduate students: E. Stevens, R. Montgomery, J. Casall,
J. Escabi, C. Hoffman, A. Davis, and J. Haggard in data
collection and running simulations. They would also like to
thank the reviewers for their valuable comments.