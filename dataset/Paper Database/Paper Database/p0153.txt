IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING, VOL. 2, NO. 1, PART 11, JANUARY 1994
Connectionist Probability Estimators
in HMM Speech Recognition
Steve Renals, Member, IEEE, Nelson Morgan, Senior Member, IEEE,
HervC Bourlard, Member, IEEE, Michael Cohen, and Horacio Franco
Abstract- We are concerned with integrating connectionist
networks into a hidden Markov model (HMM) speech recognition
system. This is achieved through a statistical interpretation of
connectionist networks as probability estimators. We review the
basis of HMM speech recognition and point out the possible
benefits of incorporating connectionist networks. Issues necessary
to the construction of a connectionist HMM recognition system
are discussed, including choice of connectionist probability es-
timator. We describe the performance of such a system using
a multilayer perceptron probability estimator evaluated on the
speaker-independent DARPA Resource Management database. In
conclusion, we show that a connectionist component improves a
state-of-the-art HMM system.
I. INTRODUCTION
VER THE PAST few years, connectionist models have
been widely proposed as a potentially powerful approach
to speech recognition [ 11- . However, although connec-
tionist methods have performed well in discrete utterance
recognition addressed as a static pattern recognition problem
 , architectures and associated training algorithms have not
yet been developed that can adequately model the temporal
structure of speech.
State-of-the-art continuous speech recognition systems are
statistical in nature, based on hidden Markov models (HMM’s)
 - . Within this statistical framework, connectionist meth-
ods have been used to improve continuous speech recognition
systems -[lo]. Such improvements have resulted from an
integration of the connectionist and statistical components,
based on a statistical interpretation of the computations being
performed by connectionist networks.
This paper discusses such a connectionist-statistical speech
recognition system that was developed at the International
Computer Science Institute (ICSI) in collaboration with SRI
Intemational. We shall review the HMM approach to speech
recognition and, through a discussion of possible training
criteria and probability estimators, describe how a probabilistic
Manuscript received February 1, 1993; revised September 15, 1993. This
work was supported by the Intemational Computer Science Institute, DARPA
contract MDA904-90-C-5253 awarded to SRI Intemational, ESPRIT Basic
Research Action 6487, Wemicke, a SERC postdoctoral fellowship, and a
fellowship from CONICET, Argentina.
S. Renals was with the Intemational Computer Science Institute, Berkeley
CA 94704. He is now with Cambridge University Engineering Department,
Cambridge, UK.
N. Morgan is with the Intemational Computer Science Institute, Berkeley
H. Bourlard is with Lemout & Hauspie Speechproducts, Ieper, Belgium.
M. Cohen and H. Franco are with SRI Intemational, Menlo Park, CA 94025.
IEEE Log Number 9214814.
Fig. 1. Schematic of a two-state, left-to-right HMM. A HMM is a stochastic
automaton consisting of a set of states and corresponding transitions between
states. HMh4’s are “hidden” because the state of the model q is not observed,
rather, the output x of a stochastic process attached to that state is observed.
This is described by a probability distribution p(x1q). The other set of
pertinent probabilities are the state transition probabilities P(qz 1qj).
understanding of connectionist networks enables the construc-
tion of a hybrid connectionist-HMM system. We shall discuss
the performance of this system evaluated on the DARPA
Resource Management database, which is a 991-word speaker-
independent continuous speech recognition task [ 1 11.
11. STATISTICAL
RECOGNITION
A. Hidden Markov Models
Hidden Markov modeling of speech assumes that speech is
a piecewise stationary process, that is, an utterance is modeled
as a succession of discrete stationary states, with instantaneous
transitions between these states. A simple HMM is illustrated
in Fig. 1. Essentially, a HMM is a stochastic automaton, with
a stochastic output process attached to each state.’ Thus, we
have two concurrent stochastic processes: a Markov process
modeling the temporal structure of speech and a set of state
output processes modeling the stationary character of the
speech signal. Note that a wider class of models (hidden semi-
Markov models) includes a third stochastic process modeling
state duration . We shall not deal with models of this class,
concerning ourselves only with time-synchronous HMM’s.
’ More generally, the stochastic process could be regarded as being attached
to each transition. If the processes attached to each transition exiting a
particular state are tied (i.e., constrained to be equal), then this is equivalent
to that process being attached to the state. In practice, state processes, rather
than transition processes, are used in most speech recognition systems.
10634676/94$04.00 0 1994 IEEE
IEEE TRANSACIIONS ON SPEECH AND AUDIO PROCESSING, VOL. 2, NO. 1, PART 11, JANUARY 1994
Ideally, there would be a unique HMM for each allowable
sentence in the language being modeled; this is clearly unfea-
sible for any but the most trivial of languages. A hierarchical
modeling scheme is usually adopted. Each sentence is modeled
as a sequence of words. The number of total models required
is now much smaller-rather
than one model per possible
sentence, there is now one model per vocabulary word. How-
ever, for large vocabularies, a very large training set would be
required to learn models for each word; some words occur very
infrequently. Thus, a further decomposition is required into
subword units. Although there are good linguistic arguments
for choosing units such as syllables or demisyllables, the unit
most commonly used is the phone? and this is the unit used
here. There are around 60 basic phone HMM's (for English)
from which word and sentence models may be constructed.
For any given sentence, we may write down the corresponding
HMM; each state in that HMM is contributed by a constituent
phone HMM.
B. HMM Speech Recognition
The basic problem of speech recognition is to be able to
transcribe the sequence of words corresponding to a spoken
utterance. A general approach to this problem is to output
the most probable sentence given the acoustic data. Thus,
we choose sentence S (and, consequently, the associated
sequence of HMM's) for which the probability3 P(SIX) is a
maximum, where X is a sequence of N acoustic data vectors
{x(l),x(2),
. . . , x(t), . . . , x(N)}! If we use hidden Markov
models, then a sentence is represented by a particular sequence
of models M, and the probability we require is P(M1X).
It is not obvious how to estimate P(M1X) directly (but see
Section V-B); however, we may re-express this probability
using Bayes' rule:
This separates the probability estimation process into two
parts: acoustic modeling, in which the data-dependent prob-
ability p(XIM)/p(X) is estimated, and language modeling,
in which the prior probabilities of sentence models P(M) are
estimated. Thus, we are able to treat acoustic modeling and
language modeling independently by using the data-dependent
and prior probability estimates.
If we use the criterion referred to as the maximum likelihood
criterion, then estimation of the acoustic model reduces to
estimating p(X1M) as p(X) is assumed to be equal across
models. Calculation of this probability involves the sum of
the probabilities of all possible paths of length N through M.
'A phone is an acoustic category, whereas a phoneme is a linguistic
category. For example, an utterance of the word "citizenship" may be
phonemically transcribed as /s ih t ih z en sh i p/, although the /z/ may
be voiced or unvoiced. A phone transcription would represent an unvoiced /z/
as [SI. The distinction between phones and phonemes is often confused in the
speech recognition literature.
3We use P to represent a probability and p to represent a probability
probability should actually be written as P ( S I X , 0 ) , where 0
represents the model parameters. For now, we shall ignore this conditioning
on the model.
In this case, training may be performed by the Baum-Welch
(or forward-backward) algorithm [ 131-[ 151. Another criterion,
which is usually referred to as the Viterbi criterion, only
considers the best path through M, leading to simplifications
of the algorithms involved. This criterion also generates,
as a by-product of training or recognition, the word (or
possibly subword unit) segmentation. In this case, a sentence
is then represented by a particular state sequence QF =
{q(l), . . . , q(t), . . . , q ( N ) } , where q(t) represents the partic-
ular state (out of the set of possible HMM states) visited
at time t, and we estimate p(X(QF). Training using the
Viterbi criterion is sometimes known as the segmental k-means
algorithm [ 161.
Using the maximum likelihood criterion, recognition can
be carried out using a best-first search strategy via the stack
decoding algorithm or, equivalently, by an A* search
[ 181. Recognition may be performed using the Viterbi criterion
by computing the state sequence Q r that maximizes the
posterior P(QF IX). The Viterbi algorithm essentially traces
the minimum cost (or maximum probability) path tl rough a
time-state lattice [ 191 subject to the constraints imposed by the
acoustic and language models.
C. Acoustic Data Modeling
Density Estimation: The usual HMM training approach is
to construct a density estimator that maximizes the likelihood
P(X1M) (or P(XIQF) if the Viterbi criterion is used).
In the course of training an acoustic model, various assump-
tions are usually made:
Piecewise stationarity-We
can model speech using a
Markov chain.
The prior probability of a model can be separately esti-
language model including syntactic constraints
about word sequences and phonological rules about sub-
word unit sequences P(M) may be derived without
reference to the acoustic data (although some attempts
have been made to relax this assumption ).
Observation independence-The
current data vector x( t)
is conditionally independent of previously emitted data
vectors xi-' = {x(l), . . . , x(t - I)}.
First order Markov process-The
current state of the
process q(t) depends only on the previous state q(t - 1).
State emission-The
current data vector x(t) is dependent
only on the current state of the process q(t).
p(XIM) can be computed in terms of local joint densities
p(x(t), q(t)lX",',
Q",-', M) of a model M emitting a data
vector x(t) while in state q(t), given the previous state
sequence Qi- ' and acoustic vector sequence Xi-' :
P(XIM) = Cdq.S(t),XIM)
P(qs(t),XIM) =
P ( q 4 t - I), X;-'IM)P(x(tL qs(t)lXi-'7 QT(t - 1)>M).
(This is the forward recurrence of the Baum-Welch algorithm.)
The above assumptions allow us to simplify the local density:
p(x(t), q(t) Pi-', Q",' , M) =
P(x(t)lq(t), M) P(q(t)Iq(t -
RJ3NAI-S ef al.: CONNECTIONIST PROBABILlTY ESTIMATORS
The likelihood of a particular state emitting a particular
data vector p(x(t)lq(t),M) is drawn from the state output
or emission probability density function (pdf). The other
probability P(q(t)Iq(t - 1),M) is referred to as the state
transition probability.
Training an acoustic model by density estimation involves
estimating the state transition probabilities and the pdf from
which the state output likelihoods are drawn. A key design
decision in acoustic modeling (given a training criterion such
as maximum likelihood density estimation) is the choice of
functional form for the state output pdfs.
Most HMh4 speech recognition systems use a parametric
form of output pdf. In this case, a particular functional
form is chosen for the set of pdfs to be estimated. Typical
choices include Laplacians, Gaussians, or mixtures (linear
combinations) of these. The parameters of the pdf are then
estimated to optimally model the training data. If we are
dealing with a family of models within which the correct
model falls, this is an optimal strategy. However, in the case of
modeling speech using HMM’s, both the HMM assumptions
and the output pdf‘s used for the HMM’s are not good models
of speech. In this case, producing the best possible model
of each unit of speech (within the HMM constraints) will
not necessarily lead to the best speech recognition perfor-
An altemative approach is nonparametric density estima-
tion. Although this does not address the problem of the HMM
being an incorrect model, it does attempt to use the data to
choose the family of output pdf‘s. In nonparametric density
estimation, the family of pdf‘s under consideration changes as
more data is seen. An example is Parzen window estimation
 , which is a kemel-based method. In this technique, as
new data points occur, new kernels corresponding to those
data points are added to the estimator. This has been used in
HMM speech recognition by Soudoplatoff .
Discriminative Training: Ultimately, in speech recognition,
we are not concerned with estimating the joint density of
the speech data and word sequence but are interested in the
posterior probability of a word sequence given the acoustic
data. More informally, we are not finally concemed with
modeling the speech signal but with correctly choosing the
sequence of words that was uttered.
We may translate this concern to a local level if we assume
the Viterbi criterion. Rather than constructing the set of pdf‘s
that best describe the data (within the constrained family of
functions being optimized), we are interested in ensuring that
the correct HMM state is the most probable (according to the
model) for each frame.
This leads us to a discriminative training criterion. Discrim-
inative training attempts to model the class boundaries-learn
the distinctions between classes-rather
than construct as
accurate a model as possible for each class. In practice,
this results in an algorithm that minimizes the likelihood of
incorrect, competing models and maximizes the likelihood
of the correct model. This differs from maximum likelihood
density estimation in which each data point is used to update
the density model of the class to which it has been assigned?
Thus, in discriminative training, the parameters of a class pdf
will be forced toward training examples from that class (as in
maximum likelihood training) but will also be pushed away
from training examples from competing classes.
There are many discriminative pattern recognition methods
in the literature, including the method of potential functions
 , learning vector quantization (LVQ) , and the mul-
tilayer perceptron (MLP) (see e.g., ). Unlike the other
methods, the MLP may be used directly to compute class-
conditional posterior probabilities (see Section 111-B).
D. Prior Probabilities
The combination of phone models to form word models
is constrained by a phone-structured lexicon that details the
allowed pronunciations for each word or, more generally,
by the phonotactics of the language. Likewise, the construc-
tion of sentences from words is constrained by a language
model, such as a stochastic grammar or (more simply) a
wordpair grammar that lists all allowable pairs of words. In
a statistical speech recognition system, the language model
assigns a prior probability to each allowable sentence in
the language. Using the allowable pronunciations for each
word (which may be probabilistic), prior probabilities are also
specified for each phone (and for each state of each phone
model). Therefore, the specification of the language model,
phone-structured lexicon, and basic phone HMM’s sets the
prior probabilities for sentences, words, phones, and HMM
These prior probabilities are encoded in the topology and
associated transition probabilities of the hidden Markov word
and sentence models. It will be important later to distinguish
these prior probability estimates from the prior probability
estimates of the phone relative frequencies observed in the
training data. We generally do not wish to use the latter since a
typical speech training database is much smaller than a typical
textual corpus from which the language model is derived; in
any event, we are forced to use the former since it is implicit
to the models used in the recognition process.
111. MLP PROBABILITY ESTIMATION
A. Multilayer Perceptrons
MLP’s are probably the best studied class of neural net-
works. They have a layered feedforward architecture with an
input layer, zero or more hidden layers, and an output layer.
Each layer is connected to the previous via a weight matrix
and operates according to the relation
51n the case of “soft” density estimation, each data point is shared out
amongst classes (depending on the likelihood of generation by each class)
so that several class densities are updated. However, there is no sense of
discrimination.
IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING, VOL. 2, NO. 1, PART 11, JANUARY 1994
output of unit i in layer L
element of the weight matrix between layers L - 1
transfer function of a unit, typically a sigmoid:
Equation (5) can incorporate a bias for yf by assuming a unit
in layer L - 1 with a fixed output of 1. The equation may also
be modified to allow layer L to receive input from multiple
lower layers via additional weight matrices.
MLP’s are trained to associate an input vector with a
desired output vector. Both classification and regression may
be performed in the same framework. In the case of N-class
classification, a network with N outputs would be used: one
for each class. A “1-from-”’ training scheme would thus be
used, where the desired output vector would contain a one for
the correct class and zero for all other classes.
Training is accomplished via the back-propagation algo-
rithm (e.g., ), which is a steepest descent procedure.
For large problems, a stochastic approximation procedure is
usually adopted (per sample update rather than batch update).
B. Posterior Probability Estimation
MLP’s may be used to estimate probabilities. Several au-
thors have discussed the behavior of feedforward networks in
terms of learning probability distributions (e.g., Hopfield ).
Bourlard and Wellekens , proved that a MLP trained
to perform classification is a class-conditional posterior prob-
ability estimator: that is, after a “1-from-”’ training, a MLP
output value, which is given an input x, will be an estimate of
the posterior probability P(ci Ix) of the corresponding class ci
given the input. This result holds for training with various error
functions (including relative entropy and mean square error).
The output units should be constrained to be nonnegative and
less than one (e.g., using a sigmoid transfer function).
Note that a sigmoid transfer function does not constrain the
sum (over all classes) of class-conditional posterior probabil-
ities to equal one. However, computational experiments have
shown that the sum of estimated posteriors is usually extremely
close to one for test vectors drawn from a region of space that
is well sampled by the training data , . However, in
estimation. Assuming equal class priors, for simplicity, we
have the relation
A posterior probability estimate tells us how probable it is that
a particular vector belongs to a particular class but gives us no
information on how likely it is to observe that vector in the first
place. The full joint density estimate, on the other hand, tells
us both how likely we are to observe a particular vector, as
well as its class membership probabilities. Therefore, although
a MLP does not provide a full probability model, if we are
interested in discriminating between classes, it may provide a
“better” use of parameters.
The theorem that shows that a MLP may be used as a
posterior probability estimator is valid only when a global
minimum of the error function is attained. In practice, this
is not attainable; indeed, using a cross-validation training
schedule, a local minimum is not reached as training is stopped
early to avoid overfitting (see Section VI). Cross validation is a
sensible approach, however, since we do not wish to compute
the density for the training set but estimate this density for an
unseen test set. Empirical results indicate that good posterior
probability estimates are achieved with this method .
C. Obtaining Likelihood Estimates
Applying a trained MLP to test data gives us estimates
of the conditional posterior probabilities of each class. These
probabilities depend on the relative class frequencies, which
may be regarded as estimates of p(ci). However, as discussed
earlier, we want to use the language model priors at recognition
time. Thus, the relative class frequencies are factored out at
recognition time to give (scaled) likelihood estimates rather
than posterior probability estimate^.^
It is easy to convert posteriors to scaled likelihoods using
(8) but with nonequal priors:
Dividing each MLP output by its relevant frequency results
in a scaled likelihood estimate that is suitable for use at
recognition time.
some applications (e.g., when combining Or comparing the
estimates from different networks), it is desirable to enforce
a “sum-to-1” constraint. One way of achieving this is by
adopting a normalizing output transfer function such as the
normalized exponential or “softmax” 
HMM Probability Estimation
Using the above framework, we may use a MLP to estimate
HMM output probabilities. As an example, consider a system
with P single-state phone models. If a MLP is trained to
classify its inputs into one of P phone classes, then the ith
output~of the MLP is as an estimate of P(c;Ix). This may be
used to estimate the output probability of the single state of
phone HMM ci. This posterior probability estimate implicitly
uses the relative frequencies in the training set as phone
priors; therefore, we use (9) to convert the posterior probability
estimates to scaled likelihood estimates. In general, the output
’This substitution is not forced upon us; there is no theoretical reason why
a Viterbi search cannot he carried out using posterior probabilities (see
Section E D , however).
f(x’) = xjEL
where zf is the activation (PretranSfer function Output) Of Unit
i in layer L.
In estimating Posteriors using a MLP, we are using a
discriminative training criterion and not performing density
6This result was expanded by Gish , Hampshire and Pearlmutter ,
and Richard and Lippmann , among others.
FENALS et U/.: CONNECTIONIST PROBABILITY ESTIMATORS
probabilities of multiple-state HMM’s may be estimated using
a MLP with an output corresponding to each independent state.
Estimating probabilities in this way enables us to make
weaker assumptions than standard HMM systems.
Although a MLP is a parametric model, a large network
defines an extremely flexible set of functions. In this
manner, we do not make strong assumptions about the
input statistics. Hence, multiple sources of evidence may
be combined as the input to a MLP. For example, a single
MLP may be trained using input data that mixes samples
drawn from several discrete or continuous distributions.
By training discriminatively and not constructing a com-
plete model of the joint density, we are making weaker
assumptions about the functional form of the output
Maximum likelihood estimation of HMM parameters
requires the assumption of conditional independence of
observations. MLP’s can model correlations across an
input window of adjacent frames.
A further benefit of using MLP’s comes from the regularity
of the resulting recognition computations, enabling an efficient
implementation using parallel hardware.
E. Priors and Biases
We would like to have a statistical understanding of the
parameters of a connectionist network. If we use a softmax
transfer function at the output layer, then
w;j hidj + bias;) ,
P(c;Ix) 0: exp [log(P(Xlcz)) + log(p(ci))l
hidj output of hidden unit j
weight from hidden unit j to output unit i
biasi bias value for output unit i.
It is tempting to identify the weighted sum of hidden unit out-
puts as the data part (as well as the log likelihood log(p(x1c;)))
and the bias as the prior part (the log prior log(p(ci))) of
each output unit. Our observations of the output biases of a
trained network do indeed show a correlation with the log
priors (relative frequencies).
Note that a similar relationship holds in the case of sigmoid
output units. If the output of a sigmoid is a posterior proba-
bility, then, following the above reasoning, we may identify
the bias with the log odds of the prior log[p(c;)/(l - p(c;)],
remembering that the inverse of the sigmoid function f(z) is
However, this relationship is too facile. Let us consider the
case of a Gaussian classifier. As is well known, we can write
down the corresponding linear discriminant function (see e.g.,
 ) for a Gaussian classifier with equal covariances:
l%[f/(l - fll.
gi(x) = W T X + wio
where gi(x) is the discriminant function for class i and w is
a weight matrix expressible in terms of the mean (pi) of class
i and the covariance (E). wio is the bias for class i. In this
case, we have
w; = E-lp;
Here, the bias is influenced by the class mean and covariance
(a data term) as well as the log prior term.
We may expect the output biases of a trained MLP to be
influenced by the acoustic data, as well as prior information.
One way we attempted to minimize the influence of the
acoustic data on the output biases was to replace the usual
sigmoid hidden unit transfer function (1/1 + exp(-z)) with
a tanh(z) function. This has a (-l,+l) range (rather than
(0,l)); therefore, in the case of random input, the expected
output would be 0. Hence, it might be hoped that the biases
would learn to encode the class relative frequencies, rather
than the acoustic data. Of course, hidden unit outputs resulting
from speech input are not random and, as reported in ,
the network biases were not good replacements for the priors
at recognition time. However, this postulated relationship
was used to speed training time and improve generalization
(Section VII-A).
Iv. ALTERNATIVE
CONNECTIONIST ESTIMATORS
MLP’s are not the only connectionist probability estimators
we could use for this task. In this section, we consider radial
basis function (RBF) networks and the recurrent generalization
of the MLP. Both these classes of network are posterior
probability estimators when trained appropriately. We also
consider MLP’s used as predictors, which may be shown to
estimate conditional likelihoods.
A. Radial Basis Function Networks
RBF networks are also feedforward networks. Their primary
difference from MLP’s is that the hidden layer consists of
units with local or semi-local transfer functions. They are often
referred to as radial basis functions since they may be radial
in nature and are assumed to form a high-dimensional basis
for the input data set.
The RBF network was originally introduced as a
method of function approximation , . A set of K
approximating functions f k ( X , 0) is constructed from a set
of J basis functions q5j(x, 8)
This defines a network with J RBF’s (hidden units) and
K linear output units, with weights Ukj. The form of
the RBF’s is typically Gaussian, with the “weights”
between the input and hidden layer specifying the means
and covariances of the RBF’s.
IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING, VOL. 2, NO. 1, PART 11, JANUARY 1994
When using RBF networks, the RBF layer is usually trained
in an unsupervised manner (e.g., k-means clustering). The
hidden units in such a network may be regarded as modeling
the input distribution with no discriminative component. There
are several attractive reasons for using RBF networks:
Training the RBF layer in an unsupervised manner is
computationally efficient.
If linear output units are used, then the discriminative
training of the output layer may be accomplished nonit-
eratively using a matrix inversion , .
Since RBF’s are local, they are suitable for time-varying
input distributions. RBF’s that describe input data that no
longer occurs will not affect the final classification. This
is not the case for MLP’s where hidden units have global
effects within the input space.
RBF networks have a structural isomorphism to tied
mixture density models although the training criterion
is often different . In both cases, the outputs are
weighted sums of Gaussians; however, in the tied mixture
case, the network is trained as a density estimator using
the maximum likelihood criteria; in the RBF case, it is
trained as a discriminative posterior probability estimator.
There is no reason why the means and variances of the
RBF’s cannot be trained discriminatively using the back-
propagation algorithm. However, this sacrifices computational
efficiency at training time. Furthermore, it seems that a full
discriminative training of nonlocal (sigmoid) hidden units is
likely to be more effective than training local hidden units
since the global hidden units are in a position to compute
global “facts” about the input.
In the case of RBF networks with sigmoid or softmax
outputs, we can show that the outputs are posterior probability
estimates since the essential conditions are the same as for
a MLP. In the case of linear output units, the outputs are not
guaranteed to be formally probabilities-they
may be negative
or greater than one, although it may be proved that the outputs
of a trained 1-from-N RBF network will sum to one .
In practice, e.g., , , outputs less than zero or greater
than one are not common. Such outputs are usually reset by a
post-network hard limiter between zero and one.
Linear output RBF networks are an attractive probability
estimator for computational reasons , [U]; large RBF
networks may be trained on a substantial speech database using
standard workstations. This is not the case with MLP’s. RBF
networks with a prior-weighted softmax (or prior-weighted
linear normalizing) output transfer function are also potentially
attractive since, in this case, there is a relationship between the
RBF network weights and the coefficients of a tied mixture
density system [411.
RBF networks have been used successfully as probability
estimators in HMM continuous speech recognition systems
 and isolated word recognition systems [U]. However,
there has been no evidence that RBF networks outperform
MLP’s, provided there is adequate computational support to
train the desired MLP. In a series of experiments at ICSI
using the DARPA speaker-dependent Resource Management
continuous speech database, the RBF systems offered a con-
siderably inferior performance compared with our standard
MLP systems (these MLP experiments are discussed in 
and and are similar to the speaker-independent experi-
ments in Section VII). Using single frame perceptual linear
prediction (PLP) coefficient inputs , a 5 12 hidden-unit
MLP produced a phone classification rate of 59% at the
frame level. Extensive experiments with RBF networks (using
the various training schemes and output transfer functions
outlined above) produced a best classification score of 52%.
This network had lo00 RBF’s and prior-weighted, normalized
exponential output units. The RBF’s were determined by a k-
means clustering process, and training of the output weights
was performed using backpropagation.
Experiments have also been performed in which the co-
efficients of a tied mixture density HMM (SRI’S DECIPHER
system ) were used to initialize a RBF network, which was
then discriminatively trained using the scheme described in
 . However, this additional training did not result in an
improved performance. We hypothesize that the initial state of
the network, as specified by the maximum likelihood trained
tied mixture system, also corresponded (or nearly so) to a local
minimum of the error surface of the discriminative objective
function of the RBF network.
B. Recurrent Networks
We may also use recurrent networks to estimate poste-
rior probabilities of HMM states. Robinson , [lo] has
used such networks to great effect in phone recognition and
continuous speech recognition systems.
These recurrent networks are essentially multilayer percep-
trons with added recurrent connections between the hidden
units. These feedback connections are advantageous since they
provide the network with a time-dependent state. A MLP may
be interpreted as a FIR filter with a fixed window back in
time. A recurrent network, however, is an IIR system with a
potentially infinite window back in time. This is due to the
network’s internal feedback.
A recurrent network may be unfolded in time to give a
multilayer network with a separate layer for the hidden units
at each time. This unfolding enables training using a variant
of the back-propagation algorithm, which is referred to as
backpropagation through time , , . Since the output
layer at any time may be regarded as the output of a deep
feedforward network, the probability estimation proofs for the
MLP also hold (given similar training conditions). Thus, we
may use such networks to estimate probabilities.
C. Predictive MLP’s
MLP’s may be used for regression. Given the previous p
samples or frames of speech, we may train a MLP to predict
the next sample or frame. Although it is unlikely that a single
predictive MLP could be used practically as a general model
of speech, it is a powerful way to model stationary dynamics.
Thus, we could embed predictive MLP’s in a Markov process
to give a piecewise stationary model of speech dynamics
[5 11- .
RENALS er al.: CONNFCTIONIST PROBABILITY ESTIMATORS
The resultant model is a (nonlinear) autoregressive (AR)
HMM, in which state output pdf‘s depend on the predic-
tion error of the MLP. Linear ARHMM’s using Gaussian
autoregressive densities on each state are well studied [ S I ,
 . An advantage of using this type of model is that it
explicitly addresses observation independence by modeling
the observations as an AR process. If the AR process is
constructed at the sample level, then we have an elegant fusion
of linear predictive analysis and hidden Markov modeling with
no distinction between analysis and recognition.
Using MLP’s as nonlinear predictors in an ARHMM results
in a more powerful, but more computationally expensive,
model than a linear ARHMM. The predictive MLP’s are
trained by the usual gradient descent process embedded in
a Viterbi - or forward-backward HMM training
algorithm. These nonlinear ARHMM’s have generally mod-
eled at the feature vector level, rather than at the sample level.
Levin used a single predictive MLP, rather than a MLP
for each HMM state; however, this MLP had an extra set of
“control” inputs, representing the HMM state.
Predictive MLP’s do not have the discriminative character
of direct MLP probability estimators. Rather than estimat-
ing posterior probabilities of the form P(qilx(t)), they
estimate a conditional likelihood p(x(t) Iq;, X:::),
may be used to estimate the global conditional likelihood
P(X,NI, Q,”,I lxy7 QY> [571-[581-
V. DISCRIMINATIVE
As discussed earlier, traditional HMM’s incorporate a com-
plete probabilistic model of the joint density p(X,M). This
is generally estimated using a prior language model P(M)
and an acoustic model p(X1M) optimized by a maximum
likelihood process. This joint density is assumed proportional
to the posterior P(MIX), and the normalizing denominator
p(X) is ignored.
All these probabilities should be conditioned on the model
parameters 0, and the probability of the data should be
expressed as p(XI0). At recognition time, this is constant
across all models. At training time, the parameters of the
models are being adapted by the training algorithm; therefore,
p(XI0) is not constant across models. We may rewrite this
probability as
P(XI0) = CP(XIMi7 @)P(Ma)
= P(xIc, @)P(c) CP(XIIj7 @)P(I,)
where C represents the correct model, and I, represents an
incorrect model.
p(XIM, O>/p(XlO) rather than p(XJM, e), we must
maximize this ratio. This may be carried out by discriminative
training, which maximizes the likelihood of the correct model
while simultaneously reducing the likelihood of competing,
incorrect models. We refer to an HMM trained in this fashion
as a discriminative HMM.
A. Frame-Level Discrimination
In this paper, we deal mainly with discriminative training
of HMM’s at the frame level, rather than the model level.
In practice, this means we are concemed with the estimation
of the state output probabilities p(xlqi). As discussed earlier,
we may obtain posterior probability estimates P(cj Ix) using
a MLP trained for framewise phone classification. If we
consider single-output distribution phone HMM’s (i.e., single-
state or multiple-state HMM’s that have a shared output
distribution common to all states in the model), then the
probability P(cj Ix) output by the MLP may be identified with
the posterior probability p(qilx) of a state qi in the phone
HMM modeling c j . After dividing by the relative frequencies
(estimates of P(cj) and hence P(qi)) and invoking Bayes’
rule, we have a discriminative acoustic model at the frame
level, i.e., an estimate of p(xlqi)/p(x).
In practice, rather than using a single frame of acoustic
input, we use 2n + 1 frames, which give n frames of left and
right context. The MLP estimates the not-so-local probability
In this approach, the transition probabilities are not es-
timated discriminatively. The maximum likelihood estimate
may be used, or some duration constraint may be encoded
using model states and constant transition probabilities. An
alternative approach was the discriminative HMM, which was
originally defined by Bourlard and Wellekens . Here, the
network estimates the local posterior probabilities P(q(t) Iq(t -
l), x(t)). This posterior combines the modeling of the output
probabilities (which is now transition specific, rather than state
specific) and the transition probabilities.
It is clear that this approach leads to discriminative acoustic
models at the frame level only, which does not guarantee
discrimination at the word or sentence level. However, it is
worth noting that if the local probabilities sum to one over all
possible states (which is, of course, the case for actual posterior
probabilities or if a softmax function is used at the output of
the MLP and always approximately true in other cases-see
Section 111-B), then the global posteriors P(S(X) are also
discriminant, summing to one over all possible sentences.
(For a proof of this, see .) The local probabilities may
be estimated by a MLP, with the addition of binary input
units, representing the previous state (one for each possible
previous state). At recognition time, posterior probabilities
p(q(t)lq(t - l),x(t)) must be computed for all possible
transitions. Thus, several forward passes through the network
are required for each frame, corresponding to each possible
q(t - 1). We have not yet performed significant experiments
using this scheme.
P(qiIx(t - n), . . . ,x(t),
. . . ,x(t + n)).
B. Global Discrimination
There have been two basic approaches suggested for the
optimization of a discriminative HMM at a model (or global)
level. One involves a direct computation of the posterior
probability of a model given the acoustic data; the second
is the Viterbi approximation to this.
Bahl et al. presented a training scheme for continuous
HMM’s in which the mutual information between the acous-
IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING, VOL. 2, NO. I . PART 11. JANUARY 1994
tic evidence and the word sequence was maximized. This
approach used a discriminative objective function that was
locally maximized by gradient ascent. More recently, Bridle
introduced the “alphanet” representation of HMM’s, in
which the computation of the HMM “forward” probabilities
ajt = P(Xi,
q(t) = j ) is performed by the forward dynamics
of a recurrent network. Alphanets may be discriminatively
trained by minimizing a relative entropy objective function.
This function incorporates the negative log of the posterior
probability of the correct model, given the acoustic evidence
P(MIX, O), rather than the local posterior of a state given one
frame of acoustic evidence. This posterior is the ratio of the
likelihood of the correct model to the sum of the likelihoods
of all models. The numerator of this ratio is the quantity
computed by the forward-backward algorithm in training mode
(when the word sequence is constrained to be the correct word
sequence, only time-warping variations are considered). The
denominator involves a sum over all possible models. This
is equivalent to the sum computed if the forward-backward
algorithm were to be run at recognition time (with the only
constraints over the word sequence provided by the language
model). Direct computation of this quantity for continuous
speech would be prohibitive for both training and recognition.
A simpler quantity to compute is the sum over all possible
phoneme sequences (unconstrained by language model). This
is not desirable as it assumes uniform priors, rather than those
specified by the language model.
Initial work in using global optimization methods for con-
tinuous speech recognition has been performed by Bridle ,
Niles , and Bengio . Bridle and Bengio used this
approach to optimize the input parameters via some (linear
or nonlinear) transform, training the parameters of the HMM
by a maximum likelihood process.
The Viterbi approximation to this is analogous to segmental
lc-means training and has been referred to as embedded train-
ing [@] or connectionist Viterbi training . In this method,
a frame-level optimization is interleaved with a Viterbi re-
alignment. It should be noted that the transition probabilities
are still optimized by a maximum likelihood criterion (or the
Viterbi approximation to it). It may be proved that performing
a Viterbi segmentation using posterior local probabilities will
also result in a global optimization . There is, however, a
mismatch between model and acoustic data priors, as discussed
VI. A CONNECTIONIST-HMM CONTINUOUS
SPEECH RECOGNITION SYSTEM
The previously described components may be put together
to form a hybrid connectionist-HMM continuous speech
recognition system (Fig. 2).
The front end consists of sampling the time-amplitude
waveform, followed by an analysis process designed to give a
concise representation of the speech signal. This is usually a
frame-based analysis in which a window of speech (typically
20 ms wide) is analyzed by some kind of spectral analysis, and
the window is advanced at discrete intervals (typically 10 ms).
The resulting speech signal is then characterized by a series
Targets i-
RECOGNITION
Probabilities
Fig. 2. Schematic of the training and recognition processes. At both training
and recognition times, the speech is processed by a front end (e.g., a me1
cepstral or a PLP transform) that extracts a concise description of the
speech every frame (typically every 10 ms). Using alignments produced
by a previously trained recognizer (or bootstrapping on time-aligned labeled
data, such as the TIMIT database), a MLP is trained to phonetically classify
frames of data. The alignment/trainiig process may be iterated to provide
an “embedded training” process. For recognition, a trained MLP is used to
estimate phone probabilities in a Viterbi dynamic programming search. This
search uses the constraints of allowed word pronunciations and the language
model to produce the most probable string of words (according to the model).
of feature vectors at 10-ms intervals. This method of analysis
embeds piecewise stationarity since it assumes that the speech
signal may be represented by a sequence of discrete spectral
“snapshots.”
In this paper, we are concerned with building statistical
models of the speech signal in the feature vector domain. We
use a set of basic HMM’s, corresponding to phones. These
are concatenated or built into networks, to form words and
sentences, according to the lexicon and language model.
When training a traditional HMM system, the topologies and
output pdf‘s of the HMM’s are chosen and initialized and their
parameters estimated. In our connectionist HMM system, we
follow the same basic approach. We choose the topologies of
the HMM’s, and we choose a MLP (with a given architecture)
to be the output pdf estimator. In the case where we have a
single pdf per phone (Le., p(xlqi) = p(x1cj) for all states q;
of phone cj), the MLP may be viewed as being trained to
perform phonetic discrimination. We initialize the models and
perform a Viterbi alignment (using a bootstrap recognizer),
producing a time-aligned state segmentation that is subject
to the language model. From the state segmentation, we can,
of course, obtain phone and word segmentations. The state
segmentation is used to produce the training targets for the
MLP. The MLP targets implicitly contain information about
the model. The MLP is then trained using the backpropagation
algorithm. In this Viterbi training scheme, the temporal and
static parts of the training problem are separated, in contrast to
the forward-backward algorithm. The process may be iterated,
altemating between training the MLP and re-estimating the
transition probabilities, which is an embedded training process.
RENALS et al.: CONNECTIONIST PROBABILITY ESTIMATORS
The usual time-synchronous Viterbi decoding algorithm is
used for recognition. For each frame of speech, a vector of
HMM state conditional posterior probabilities (p(qi1x) for all
states qi) is produced by the MLP. These are converted to
scaled likelihoods by dividing by the relative state frequencies
of the training data. In combination with the transition prob-
abilities, we may use the Viterbi algorithm to compute the
HMM state sequence most likely to have produced the speech
signal, given the lexical and language model constraints. An
additional parameter used in the recognition is the word transi-
tion probability, which is usually set by hand using a validation
set. This parameter penalizes (lowers the probability) of word
transitions, thus reducing the tendency to favor short words
over longer ones.*
Modeling Context: Thus far, we have only considered
context-independent9 phone modeling using MLP’s. However,
traditional HMM systems have experienced a much improved
performance by modeling phones in context , , .
Consider a set of N phone classes C = (c1 , .. . , CAT} and
D context classes V = { d l , . . . , d ~ } .
A naive approach
to estimating context-dependent probabilities using a MLP
would require a network containing D x N outputs. This
approach scales badly because it would result in extremely
large networks for anything other than a trivial set of context
classes. The traditional context-dependent HMM approach also
suffers from the need to estimate an excessive number of
parameters.
However, without any simplifying assumptions, we may
estimate context-dependent posterior probabilities using net-
works that are not substantially larger than our context-
independent MLP’s. The method uses a network decompo-
sition based on the definition of conditional probability:
P(Ci,djlX) = P(CiIX)P(djlCi,X).
of data, the second network must be run multiple times for all
possible phone classes. Fortunately, with a possible constraint
on representability, we may increase computational efficiency
by having a direct connection from the binary units to the
output units, bypassing the hidden units.
We may compute a table of the binary units’ effect on the
output, with these vectors being added on directly before the
output transfer function. Thus, the bulk of computation is only
performed once per frame.
A variant of the second approach , uses an equiv-
alent decomposition:
The second network maps acoustic data to the phone class
in a particular context. In this case, we have one network
for each possible context. The number of parameters is re-
duced by constraining the set of networks to share a hidden
layer. Furthermore, the hidden-to-output transformation of
the context-dependent networks may be initialized with the
context-independent weights. Cross-validation training may
then be used to ensure that context-dependent training does
not decrease performance. This leads to a smoothing of the
context-independent and context-dependent parameters.
VII. EXPERIMENTS
A. Methods
Most of our experiments have been performed using the
DARPA Resource Management (RM) speaker-independent
continuous speech database [ 111. This is a very well-studied
database with a vocabulary of 991 words. The standard training
set contains 3990 sentences from 109 speakers. Evaluation
is performed over various test sets typically containing 300
sentences from 10-12 new speakers.
of a speech recognition task is strongly
affected by the branching factor, or perp,exiry, which is the
geometric mean of the number of words that can follow any
word. When no grammar is used, the RM task has a
simple word-pair grammar listing allowable pairs of words,
of the deterministic source grammar used to generate sentences
for the RM task was abut
The front-end used in these experiments was a me1 cepstral”
analysis, producing 12 Coefficients, plus energy for each 10-
ms frame of speech. In addition to these 13 coefficients, we
estimate their temporal derivatives , giving 26 coefficients
per frame.
We chose the basic subword unit to be the phone. Each
phone was represented as a two- or three-state left-to-right
HMM. However, the two- or three-state output pdf‘s in each
model were tied. Thus, each phone model contained a single
‘OThe me1 cepstrum is the Fourier transform of the logarithm of a
me1 spectrum. This spectrum, which is usually computed using DFT’s, is
equivalent to an unequally spaced filter bank that approximates the “critical
bands” of human hearing. The cepstrum is usually truncated (higher order
terms set to zero) to smooth the representation, essentially removing closely
spaced variations from the log spectrum.
The first term on the right-hand side is estimated by our usual
context-independent MLP. The second term is the estimate of
the posterior probability of the context class, given the input
and the phone class. This second term may also be estimated
on the phone class.
two basic ways:
with the usual speech input, Plus a dependence
perplexity of 991--any
word can follow any other. With a
This dependence On the phone ‘lass may be represented in
the perplexity is reduced to about 60. Note that the perplexity
1) By an extra set of 1-from-N binary inputs (one for each
2) by having a replicated network
from input data
The first approach has been investigated in 1461 and 1691.
This method of network decomposition may be viewed as
trading space for time during recognition. At recognition time,
probabilities must be computed for all phones in all contexts
(assuming there is no pruning). This means that for each frame
possible phone class)
to context class) for each possible phone class.
*This is a result of the observation independence assumption, causing an
underestimate of the joint Observation density .
9A context-independent phone model is one that models a phone in
whatever context it may occur. Context-dependent phone models, however,
model phones in specific phonetic contexts to take account of the acoustic
effect of context. Thus, there may be several different models for a single
phone, depending on the surrounding context.
IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING, VOL. 2, NO. 1, PART 11, JANUARY 1994
output distribution, with the multiple states acting as a duration
model. The output pdf's were estimated using a MLP with N
outputs corresponding to N phones. This MLP, when trained
as a phonetic classifier, output class conditional posterior
probabilities.
These probability estimates were integrated into SRI'S sys-
tem known as Decipher . It includes multiple probabilistic
word pronunciations, cross-word phonological models, multi-
ple densities per phone, and context-dependent phone models.
The basic Decipher system uses tied Gaussian mixture state
output pdf's.
Initial work used a context-independent form of Decipher.
This was the complete Decipher system, except that there
were 69 context-independent phone models, rather than over
3000 context-dependent models. In this work, we replaced the
tied mixture pdf's by a MLP. Additionally, we also worked
with the context-dependent Decipher system. In this case, the
context-dependent tied mixture pdf's were augmented by the
context-independent MLP pdf's.
The context-dependent Decipher system was used to boot-
strap our models. Our initial training targets were obtained by
using the tied mixture Decipher segmentation, and we retained
the estimated transition probabilities.
B. Architectures and Training
The networks trained to perform these estimations were
large. In addition to the current frame (26 inputs), four
frames of left and right context were appended, giving a
total of 234 inputs. We usually used networks with about
1000 hidden units and 69 output classes, giving a total of
over 300 000 weights. Training a network with this many
weights is not trivial.' ' We used a cross-validation training
procedure combined with stochastic gradient descent (per-
pattem update). Cross-validation training is essential for good
generalization and preventing overtraining, especially when
using large networks. In our training schedule, we cross
validate by testing phonetic classification on an independent
test set after each epoch.'* When the classification performance
on the validation set first fails to improve by a certain amount
(typically OS%), the gradient descent step-size is reduced,
typically by a factor of 2. After each succeeding epoch, the
step size is further reduced until, once again, there is no
improvement on the validation set. Training is then halted.
Following the discussion in Section 111, we have found
empirically that the output biases of a trained network may
approximate the log odds of the priors (for a sigmoid transfer
function) or the log of the priors (for a softmax transfer
function). We have found that training is speeded (by over
25%) and generalization improved by initializing the output
"Computation was done using the RAP , which is a ring array
processor that was configured with from four to 20 TMS320C30 DSP's.
This provided matrix-vector operations that were two orders of magnitude
faster than the Sparc 2 workstations ordinarily used for program development.
Training still took 1-2 days using a 16-processor system.
I2An epoch corresponds to a training iteration over the entire training set.
Note that when using random pattem selection, training does not involve a
series of complete passes through the complete training set. We regard an
epoch as training on P randomly chosen pattems when there are P patterns
in the training set.
biases to the log odds (or log) of the relative frequencies of
the corresponding classes. Another training improvement was
to use random (with replacement) pattem presentation. These
two methods together improved the speed of training by a
factor of 2 (training time of ten epochs through the training
set reduced to five) and improved generalization.
C. Results
Our experiments were performed using a MLP with sigmoid
outputs trained on the RM training set. Training the 300 OOO
weight network required around five passes through the train-
ing database of 1.5 million training pattems. Around 225 000
pattems were used for cross validation , which was the same
as the network cross-validation set, was used to tune the HMM
recognition parameters, such as the word transition probability.
Final word recognition results were obtained using unseen
test sets of 300 sentences. Three such sets were used here:
the February 1991 and the two September 1992 RM speaker-
independent test sets. No tuning of parameters was performed
using these sets.
A context-independent form of the Decipher system was
used as a baseline. It was trained using the maximum likeli-
hood forward-backward procedure and gave a word error of
11.0% on the February 1991 test set, using the RM word-
pair grammar (perplexity 60). When the usual HMM output
probability estimators were replaced with a MLP trained to
classify its input acoustic vectors into one of 69 classes
(and outputting posterior probability estimates), the word
recognition error improved to 5.8%. This network was trained
from context-dependent alignments, which may give a slight
advantage to the MLP. A similar experiment using context-
independent alignments resulted in a slight degradation in
performance (to 6.1%) but still showed a large improvement
over the baseline. In a later experiment, we further reduced
the error to about 5% by realigning the data using the MLP
for probability estimation and then retraining the MLP with
the new alignment.
In a related experiment, the MLP probability estimates were
smoothed together with probabilities from the full context-
dependent Decipher tied-mixture system. Two heuristics were
tried for combining the MLP and tied mixture estimates of
the state output probabilities. In the first, weighted logs of the
MLP and tied mixture likelihood estimations were used:
where P,l,
denotes the MLP estimate of a probability and
Pt, the tied mixture estimate. A single set of As was used over
all the states; they were optimized for minimum recognition
error over the 300-sentence development set.
In the second heuristic, the log of a weighted average of the
state output probabilities estimated by the MLP and the tied
RENALS et d.: CONNECTIONIST PROBABILITY ESTIMATORS
PERPLEXITY 60 WORDPAIR GRAMMAR. (CI-MLP is the
context-independent MLP-HMM hybrid system, CD-HMM is the
full contextdependent Decipher system, and the MM system is
a simple interpolation between the CD-HMM and the CI-MLP.)
RESULTS USING THE THREE TEST SETS WITH THE
RESULTS USING THE THREE TEST SETS
USING NO GRAMMAR (PERLPEXITY 991)
Gaussian mixtures was used
In this approximation, the probability of the data P(x) was
required to ensure that the two likelihood estimates are scaled
similarly. This cannot be obtained from the MLP and was
approximated by summing over the state conditional tied
Gaussian likelihoods:
Ptm(xlqi)P(qi)*
The best results on the development set were obtained using
the first method, which was adopted when evaluating over the
three test sets. This reduced the error significantly in both
cases. These results are summarized in Tables I and I1 and
graphed in Fig. 3 for the February 1991 test set using the
wordpair grammar. The relationship between the number of
parameters and recognition performance is graphed in Fig. 4.
VIII. CONCLUSION
In this paper, we have reviewed the basis of statistical
(HMM) speech recognition methods, paying attention to the
assumptions embedded in standard techniques. In particular,
we have considered density estimation methods compared
with discriminative methods. Using the result that feedforward
networks may discriminatively estimate probabilities, we have
constructed a connectionist HMM speech recognition system.
Experiments on the DARF'A speaker-independent Resource
Management task have demonstrated that these connectionist
methods improved a state-of-the-art HMM speech recognition
Fig. 3. Results using the February 1991 test set, using the perplexity
60 wordpair grammar. This also includes the performance of the con-
text-independent tied mixture HMM (CI-HMM) system.
Error ("A)
Million Parameters
Recognition error versus number of parameters, for the February
1991 test set, using the wordpair grammar. A MLP with the same number
of parameters as the CI-HMM (500 hidden units) achieves about 8.0%
recognition error (not shown on this graph).
context-dependent HMM.
However, the latter system has
50 times the number of models and 35 times the number
of parameters compared with the MLP system.
Interpolating MLP context-independent probabilities with
tied mixture context-dependent probabilities produced an
increase in word accuracy.
These results arise from weakening two underlying HMM
Comparing like with like, a discriminatively trained con-
nectionist context-independent system performed consid-
Model COrrectness-BY
estimating Only the class-
erably better than the corresponding maximum likelihood
conditional posterior probability, we have not attempted
tied mixture system.
to optimize an inappropriate model of the joint density.
The context-independent MLP-HMM hybrid system had
This discriminative approach seems to be a better use of
a word accuracy of from 0.8 to 2.5% lower than the
parameters for a recognition task.
assumptions:
IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING, VOL. 2, NO. 1, PART 11, JANUARY 1994
Observation independence-The
acoustic Context was in-
creased by presenting a multiframe input to the network.
Thus, the probabilities estimated were conditioned on a
sequence of data vectors, rather than a single data vector,
[I91 H. Ney, “The use of a one-stage dynamic programming algorithm
for connected word recognition,” IEEE Trans. Acoustics Speech Signal
Processing, vol. 32, pp. 263-271, 1984.
[201 L. R. Bahl et al., “Automatic phonetic baseform determination,” in
Proc. IEEE Inr. Conf. Acoustics Speech Signal Processing (Toronto),
1991, pp. 173-176.
weakening the observation
assumption*
1211 E. parzen. “On
of a orobabiliw densiw function and mode.”
Furthermore, we are finding the connectionist HMM frame-
work a good one in which to explore issues such as robust front
ends, speaker adaptation, consistency modeling, and context-
dependent phone modeling.
ACKNOWLEDGMENT
This work benefited from the input of P. Kohn, Y. Konig,
and C. Wooters. The authors wish to thank M. Hochberg, A.
Robinson, and an anonymous referee for a critical reading of
the manuscript.