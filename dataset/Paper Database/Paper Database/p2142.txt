NBER WORKING PAPER SERIES
A SIMPLE PLANNING PROBLEM FOR COVID-19 LOCKDOWN
Fernando E. Alvarez
David Argente
Francesco Lippi
Working Paper 26981
 
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
April 2020
First draft, March 23, 2020. We benefited from the comments of Andrew Atkeson, Gadi Barlevy,
Mike Golosov, Fausto Gozzi, Francois Gourio, Lars Hansen, Kiminori Matsuyama, Magne
Mogstad, Casey Mulligan, Tom Phelan, Filip Rozsypal, Fabiano Schivardi, Rob Shimer, Daniele
Terlizzese, Fabrice Tourre, Marcelo Veracierto, Ivan Werning, and panelists and participants on
the HELP! (Health and Pandemics Economics Group) seminar on March 27th, the World Bank's
Development Policy and Covid-19 e-seminar on April 1st, and the Federal Reserve Bank of
Chicago Virtual Macro Seminar on April 3rd, and the Chicago Economics Department lunch on
April 8th. The authors declare to have no conflict of interest to disclose regarding the research on
this paper. The views expressed herein are those of the author and do not necessarily reflect the
views of the National Bureau of Economic Research.
At least one co-author has disclosed a financial relationship of potential relevance for this
research. Further information is available online at 
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2020 by Fernando E. Alvarez, David Argente, and Francesco Lippi. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.
A Simple Planning Problem for COVID-19 Lockdown
Fernando E. Alvarez, David Argente, and Francesco Lippi
NBER Working Paper No. 26981
April 2020
JEL No. E6
We study the optimal lockdown policy for a planner who wants to control the fatalities of a
pandemic while minimizing the output costs of the lockdown. We use the SIR epidemiology
model and a linear economy to formalize the planner's dynamic control problem. The optimal
policy depends on the fraction of infected and susceptible in the population. We parametrize the
model using data on the COVID19 pandemic and the economic breadth of the lockdown. The
quantitative analysis identifies the features that shape the intensity and duration of the optimal
lockdown policy. Our baseline parametrization is conditional on a 1% of infected agents at the
outbreak, no cure for the disease, and the possibility of testing. The optimal policy prescribes a
severe lockdown beginning two weeks after the outbreak, covers 60% of the population after a
month, and is gradually withdrawn covering 20% of the population after 3 months. The intensity
of the lockdown depends on the gradient of the fatality rate as a function of the infected, and on
the assumed value of a statistical life. The absence of testing increases the economic costs of the
lockdown, and shortens the duration of the optimal lockdown which ends more abruptly. Welfare
under the optimal policy with testing is higher, equivalent to a one-time payment of 2% of GDP.
Fernando E. Alvarez
University of Chicago
Department of Economics
1126 East 59th Street
Chicago, IL 60637
 
David Argente
Pennsylvania State University
Department of Economics
403 Kern Building
University Park
State College, PA 16801
 
Francesco Lippi
Einaudi Institute for Economics and Finance
Via Sallustiana 62
00187 Rome
 
Introduction and Overview
We present a simple optimal control model for the COVID19 epidemic. We adopt a variation
in the SIR epidemiology model reviewed and proposed by Atkeson and Neumeyer
 to analyze the optimal lockdown policy. Our aim is to contribute to the ongoing
discussion on the optimal policy response to the COVID shock, see Barro, Ursua, and Weng
 ; Eichenbaum, Rebelo, and Trabandtz ; Hall, Jones, and Klenow ; Dewatripont et al. ; Piguillem and Shi ; Jones, Philippon, and Venkateswaran 
and the contributions in the volume by Baldwin and Weder .
The typical approach in the epidemiology literature is to study the dynamics of the
pandemic, for infected, deaths, recovered, as functions of some exogenously chosen diﬀusion
parameters, which are in turn related to various policies, such as the partial lockdown of
schools, universities, businesses, and other measures of diﬀusion mitigation, and where the
diﬀusion parameters are stratiﬁed by age and individual covariates. This is the approach
followed for instance by Ferguson and Et.al . We use a simpliﬁed version of these
models proposed by Atkeson to analyze how to optimally balance the fatality induced
by the epidemic with the output costs of the lockdown policy.
The novel aspect of our
analysis is to explicitly formulate and solve a control problem, where the diﬀusion parameter
is chosen to maximize a given social objective and taking into account the dynamic nature of
the problem.1 By computing the optimal policy, and the associated trajectories, we aim to
gauge the intensity and duration of the optimal COVID lockdown, and to understand what
are the key elements that determine it. A reason to write a planning problem directly is that
with social interactions there is an externality to be corrected, as understood in much of the
search literature and as carefully analyzed in Eichenbaum, Rebelo, and Trabandtz 
and Toxvaerd .
The planner’s objective is to minimize the present discounted value of fatalities while
1An optimal control problem based on a very similar epidemiological model can be found in Hansen and
Troy , but the objective function and the feasible policies are diﬀerent.
also trying to minimize the output costs of the lockdown policy, since agents in lockdown
are assumed not to produce. Underlying our setup is a SIR epidemiology model, describing
how the virus propagates from the Infected agents to those Susceptible of falling ill, as well
as the rates at which, once infected, agents either recover or die. We formulate and solve
the problem of a planner who has access to a single instrument to deal with the epidemic:
the lockdown of the citizens.2 The planner’s problem features a tradeoﬀbetween the output
cost of lockdown, which are increasing in the number of susceptible and infected agents, and
the fatality cost of the epidemic. The state of the problem is two dimensional and, in spite
of its simplicity, it does not have an analytic solution. We study how the optimal intensity
and duration of the lockdown depend on the cost of fatalities, as measured by the value of a
statistical life, on the eﬀectiveness of the lockdown (the reduction in the number of contacts
once the citizens are asked to stay home), and on the possibility of testing, i.e. to identify
those who acquired immunity to the disease. We show that if the fatality rate (probability
of dying conditional on being infected) is increasing in the number of infected people, as is
likely the case once the hospital capacity is reached, the policy maker motive for lockdown is
strengthened. But, an optimal gradual lockdown may also arise in the absence of non-linear
costs, since the costs and beneﬁts of the policy depend on the state of the system.
We parametrize the model using a range of estimates about the COVID19 epidemic which
are obviously uncertain. We explore several variations of our benchmark scenario, including
the severity of the congestion eﬀects on the fatality rate, a range of valuations for the value of
lost lives, and the possibility of testing and releasing the recovered agents from lockdown. We
illustrate these points using a quantitative analysis, accompanied by simulations, summary
tables of the main results, and phase diagrams that allow us to study the problem under any
initial condition.
The quantitative results are useful to gauge what parameters of the problem are important
2While the lockdown is not the only margin of action (other actions might involve reinforcing health
treatment capacity and incentivizing the development of vaccines), in the short run this seems to be an
important policy tool available and used by several countries.
in shaping the intensity and duration of the optimal lockdown policy. Several comparative
statics analysis are developed. In our baseline parameterization, conditional on a 1% fraction
of infected agents at the outbreak, the possibility of testing and no cure for the disease, the
optimal policy prescribes a lockdown starting two weeks after the outbreak, covering 60%
of the population after 1 month. The lockdown is kept tight for about a full month, and is
subsequently gradually withdrawn, covering 20% of the population 3 months after the initial
outbreak. The output cost of the lockdown is high, equivalent to losing 8% of one year’s
GDP (or, equivalently, a permanent reduction of 0.4% of output). The total welfare costs is
almost three times bigger due to the cost of deaths (see Figure 1 and Table 2).
These results are based on a relatively pessimistic parameterization of the fatality rate,
and on the fraction of the population that would have been infected if there was no lockdown.
In the less pessimistic, yet in our view still realistic cases, which assume a lower fatality rate
and/or a lower speed of spread of the virus, the optimal lockdown is shorten by more than
one month. The intensity of the optimal lockdown depends critically on the gradient of the
fatality rate as a function of the infected. If we assume that the fatality rate is constant,
the intensity and duration of the lockdown are signiﬁcantly reduced and, in some cases,
completely eliminated, even though the welfare cost of the pandemic remain high. On the
other hand, the value of the statistical life we use in our benchmark case (20 times annual
GDP per capita) is on the low range of the estimates in the literature. Following Hall, Jones,
and Klenow , our benchmark value takes into account that the majority of the victims
of the virus have a below average life expectancy. A higher value of statistical life (say 30
times annual GDP per capita), makes the abandonment of the lockdown more gradual, taking
a bit more than six months to be totally abandoned. Considering a much larger value, in
the order of 80 to 140 times the annual GDP per capita, implies a very strict lockdown that
lasts for about 9 months, and a year after still has about 15% of the population in lockdown.
Finally, our benchmark scenario assumes that there is a test that allows those that recover
to go back to work, so that they are not subject to the lockdown. In the absence of such a
test the optimal lockdown is shorter, but it involves roughly the same total number of hours
lost due to the lockdown (see Figure 8 and Table 2). The most salient feature of the case
where a test is not available is that the lockdown ends up sooner, more abruptly. This is due
to the dynamics of the epidemiological model: as time goes by the fraction of those recovered
increases, and thus the lockdown becomes progressively less eﬃcient to stop the transmission
of the virus by locking down a progressively larger fraction of those that do not transmit it.
The availability of such test has large welfare gains, on the order of 2% of one years GDP.
A byproduct of the calculations is the beneﬁt of the lockdown policy, measured as a
percentage permanent GDP ﬂow of following the optimal policy vs the case of no lockdown
(see Table 2). For instance, for the range of our preferred values, the total welfare cost of the
virus is equivalent to a loss of 30% to 40% of one year GDP. From this loss, the part due to
lockdown of workers is between 8% and 12% of one year GDP. We also use these measures to
analyze the importance of diﬀerent features. This conﬁrms that the elasticity of the fatality
rate to the number of infected is a key determinant of the optimal policy –we found that when
the fatality rate is ﬂat the optimal policy is to have no lockdown. As mentioned above, we
also analyze the sensitivity of the optimal policy to a large range of values of the a statistical
life, and to the unavailability to have a test to avoid locking out immune workers.
Needless to say the analysis has limitations: the underlying model has no heterogeneity in
fatality rates nor in diﬀusion rates, the lockdown policy cannot be diﬀerentiated across agent’s
type (e.g. young versus old, workers vs retirees). We also ignore direct health interventions
that might be put in place to mitigate the consequences of the disease (building emergency
hospitals, incentivizing the research and cure for the disease). Finally, we ignore the longterm economic consequences of a temporary lockdown, a potentially important eﬀect, whose
analysis requires adding one state to the problem.
Our objective is similar to that pursued by Eichenbaum, Rebelo, and Trabandtz .
While they focus on a competitive equilibrium where a consumption tax is used to slowdown economic activity as well as the epidemic diﬀusion, we focus on a simpler planner
problem that at each time directly mandates the level of lockdown to its citizen. In our
setup, the interaction of the law of motion coming from the SIR model and the control of
lockdown makes the problem non-convex, which requires the use global methods. Another
recent contribution addressing the optimal control problem in the presence of contagion
externalities can be found in Jones, Philippon, and Venkateswaran .
The paper is organized as follows: the next section describes the planner’s problem and
the epidemic model. Section 3 uses some micro data to calibrate the key model parameters
drawing from Atkeson ; Ferguson and Et.al . Section 4 discusses the preliminary
results of the optimal control problem under diﬀerent scenarios.
A planner model of lockdown control
We start with a modiﬁed version of the, by now well known, SIR model as described in
Atkeson . Agents can be divided between those susceptible to be infected S(t), those
infected I(t), and those recovered R(t), i.e.
N(t) = S(t) + I(t) + R(t) for all t ≥0
Typically, in the SIR model those “recovered” include those that have been infected and are
now assumed to be immune and those have died. In our case, we will only include those
that are alive, so N(t) will be changing through time, by substracting those that die. We
normalize the initial population to N(0) = 1. The planner can decide to lockdown a fraction
L(t) ∈[0, ¯L] of those susceptible and those infected, where ¯L ≤1 allows us to realistically
consider that even in a disaster scenario some economic activity such as energy and basic
food production have to continue. Recovered agents are not in lockdown. A fraction of those
that are in lockdown cannot be infected, nor can infect some other susceptible agents. We
assume that the lockdown is only partially eﬀective in eliminating the transmission of the
virus. When L agents are in lockdown, then (1 −θL) agents can transmit the virus, where
θ ∈(0, 1] is a measure of the lockdown eﬀectiveness. If θ = 1, the policy is fully eﬀective in
curbing the diﬀusion, but since some contacts will still happen in the population even under
a full economic lockdown, we allow θ < 1.
The law of motion of the susceptible agents is:
˙S(t) = −β S(t)(1 −θL(t)) I(t)(1 −θL(t))
where β is the number of susceptible agents per unit of time to whom an infected agent can
transmit the virus, among those not in lockdown. All susceptible agents that get the virus
become infected. For the infected, a fraction γ recovers, thus:
˙I(t) = β S(t)(1 −θL(t)) I(t)(1 −θL(t)) −γI(t)
A rate 0 < φ(I) ≤γ per unit of time of those infected die. Thus, population decreases due
to death among those infected as:
−˙N(t) = D(t) = φ(I(t)) I(t)
While we assume that the rate γ at which infected recover is exogenous, the fraction of
those recovering that die is assumed to depend on the number of infected I, given by the
function φ. Note that in this epidemiological model, locking down a part of the population,
while economically costly, can be very powerful to reduce the rate at which susceptible agents
become infected. This is because in the standard model, it is the product of the infected
and susceptible that determine the new infections per unit of time. Hence, decreasing the
number of contacts of each, decreases the new infections by its square. This completes the
description of the epidemiological block of the model.
We assume that each agent alive produces w units of output, when she is not in lockdown.
Agents are assumed to live forever, unless they die from the infection.3 The planner discounts
all values at the rate r > 0. We assume that with probability ν per unit of time both a vaccine
and a cure simultaneously appear, so that all infected are cured and all susceptible become
immune, ie. all infected and susceptible become recovered. The planner seeks to maximize:
e−(r+ν)t 
(N(t) −[S(t) + I(t)] L(t)) w + ˙N(t)χ + ν
by choice of the control L(t) at all times, i.e. choosing the fraction of agents to lockdown
L(t). In the baseline case we assume that those that have recovered from the virus can be
identiﬁed, say with an antibody test, and don’t need to be locked down; we also explore the
case where such a test in not available. The objective function includes the present value
of the output of those alive, as well as an extra cost χ, in units of output, for each agent
that dies as a consequence of the virus above and beyond the loss output. The term ν
is the product of the probability that a cure takes place ν times the discounted value of
output from there on, wN(t)/r. The planner’s problem is subject to the law of motion of the
susceptible individuals equation (2), the infected equation (3), the population, equation (4),
and an initial condition (N(0), I(0), S(0)) with I(0) > 0 and S(0) + I(0) ≥N(0). Below we
give an equivalent, perhaps easier to interpret, formulation of the planner’s objective function
in terms of the output cost of lock down and the cost of fatalities evaluated using the value
of a statistical life.
Discussion of modeling assumptions
We now brieﬂy review the key assumptions of the
1. We restrict the extent of the lockdown to ¯L ≤1. This is to take into account, in a
very rough manner, that some sectors cannot shut down even with the most severe
lockdown, such as health, basic services, food production and distribution, etc.
2. If θ = 1 the lockdown is able to completely stop the infections process, i.e. to achieve
3We introduce a parameter to correct for this in the calculation of the value of a statistical life.
˙S = 0 (at L = 1). If θ < 1 the eﬀectiveness of the lockdown policy is partial (people
keep transmitting the virus) but at a lower rate. We will choose as a baseline θ = 0.5,
which we deem as reasonable, but we acknowledge we have no hard evidence to lean
3. Those recovered are assumed to be immune and, in our benchmark analysis with a test
(τ = 1), we assume the recovered are not locked down. It seems like a property of any
optimal policy, provided that previously infected agents cannot contract the infection
again for a related policy). The case with no test (τ = 0),
when everybody must be in lock down, is also discussed.
4. In the law of motion for S and I given by equation (2) and equation (3), we do not
scale by the population N(t) to compute the number of infected at time t. Instead we
simply write, βI(t)S(t)(1 −θL(t))2, instead of βI(t)S(t)(1 −θL(t))2/N(t). This seems
to be the standard in the SIR literature, although it will be preferable to scale them
by N(t). Since some agents die, this cannot be done by simple setting N(0) = 1. We
follow the literature, since this also saves one state variable.
5. Note that the assumption in the SIR model that new infections are proportional to
the product of S and I, means that when one assume that it can lockdown those that
have contacts, the term (1 −θL), i.e the fraction not lockdown, enters in a quadratic
form. Hence, if (1 −θL) is one half, it has the eﬀect to reduce to one-fourth the rate of
transmission of infections in that period. This is similar to the feature in search theory
aptly named “quadratic search”.
6. We assume that agents who are infected, but not in lockdown, can still produce as
much as those susceptible or recovered not in lockdown. This can be easily changed,
4This choice of θ has the interesting feature of making the marginal eﬀect of the quadratic search eﬀect of
lockdown on the transmission of the virus the same as in the linear case. By this we mean that for θ = 0.5
the term (1 −θL)2, which gives the reduction in transmission of the virus in equation (2) and equation (3),
has the same derivative with respect to L as the linear case of (1 −L) at no lockdown (L = 0).
but a better model will have two types of infected, one with symptoms and one without.
Those with symptoms should be lockdown ﬁrst, and only after them, one should isolate
the rest.5
7. We assume that agents in lockdown do not produce. A more realistic model will have at
least some agent who can produce, even in lockdown (working remotely). This variation
is easy to explore by adding a relative productivity loss parameter in front of the S + I
term in the objective function.
8. The assumption that φ(I) is increasing in I, postulated in equation (8), captures that as
I increases, the capacity to treat patients diminishes and the rate at which an infected
agent dies increases.
9. We assume that all agent are inﬁnitely lived, except for the risk of dying after contracting the virus. This simpliﬁcation is acceptable given the short time horizon of the
problem. On the other hand, not having an explicit age structure yields unrealistic
eﬀects on the impact of mortality risk.
10. The planning problem incorporates two types of cost. One is the economic activity lost
during a lockdown among those susceptible and infected, and also due to the death of
infected agents. Note that since we model an inﬁnitely lived agent, the death of an
infected person implies a cost equal to the present value of this person’s income, which
overestimates the economic cost of death, measured as the value of a statistical life. In
the model parameterization discussed below, we use the extra term for the cost of each
death (χ) to adjust the valuation of the years lost in term of typical consumption to
the ﬁnite remaining years of life span, as done in the literature that uses the value of a
statistical life (v.s.l) and the adaptations to this particular application.
5We do not include an intermediate state E(t), as it is done in some of the SIR models –see Atkeson’s
note–, where agents have no symptoms but can transmit the virus. This may be interesting to include.
An equivalent planner minimization problem.
We can rewrite the problem in equation (5) into an equivalent one that conserves on the state space and has a perhaps simpler
interpretation. So far we described the case where those that recover can be identiﬁed and
hence not subject to lockdown. Below, we also consider the case that such a test is not
available so that the lockdown must apply to the entire population. The parameter τ = 1
will indicate that the test is available which is our baseline case; we will also discuss the case
where τ = 0, i.e. the test it is not available.
The problem of the planner consists in minimizing the present value, discounted at rate
r + ν, of the following ﬂow cost:
τ(S + I) + 1 −τ
so the cost of having a state (S, I) and a current control L is that an amount wL(S + I)
of output by the susceptible and infected is lost if the test is available (τ = 1), or that an
amount wL is lost in the case in which the test is not available (τ = 0).
The cost of fatalities due to the infection is given by the present value of output that
they would have produced, w/r, as well as by the extra cost of death, χ. Of course, what
matters for the problem is the magnitude
, which has the same units as the value of
a statistical life.
Thus, we can write the objective function as:
e−(r+ν)t 
τ(S(t) + I(t)) + 1 −τ
+ I (t) φ (I (t))
This problem has a two-dimensional state, (S, I).6 Recall that by adjusting χ one controls
the weight of fatalities relative to a unit of output. Indeed our benchmark case is very close
6The problem formulation assumes testing is available or not, through the parameter τ. It would be
interesting to modify the setup so that τ would also be a control, incorporating its associated cost. Notice
that in equation (6) when τ = 0 the output cost is wL(t), while the actual cost would be slightly smaller and
equal to wN(t)L(t), where N(t) < N(0) since a small part of the population has died by time t. We use this
simpliﬁcation to maintain a parsimonious state space, as common practice in SIR models.
to trade oﬀa unit of output loss with the statistical value of a life, as commonly measured.
The per day rate at which infected people die, which we refer to as the fatality rate, is
assumed to have the following functional form
φ(I) = ϕ + κI
which reﬂects that the capacity to treat patients diminishes and, as a result, the rate at
which infected agents die increases.
The planner solves the following Bellman-Hamilton-Jacobi equation:
(r + ν)V (S, I) = min
τ(S + I) + 1 −τ
−[β S(t)(1 −θL(t)) I(t)(1 −θL(t))] ∂SV (S, I)
+ [β S(t)(1 −θL(t)) I(t)(1 −θL(t)) −γI(t)] ∂IV (S, I)
The domain of V is (S, I) ∈R2 such that S + I ≤1. Note that V (S, I) can be interpreted as
the minimum expected discounted cost of following the optimal policy in units of output loss.
Recall that if φ(I) = 0, then the value of the objective of the planner at time t = 0 will give
N(0)w. Thus, the quantity rV (S, I)/w converts the stock-value of the value function into a
ratio of the ﬂow cost relative to output at time t = 0, when there is no virus. We solve this
problem by discretizing the model to weekly intervals, using value function iteration over a
large non-linear grid for (S, I). Finally, we notice that the value function has simple analytic
expressions on the boundary of its domain, where the lockdown policy is not exercised. In
particular, on the I = 0 axis we have V (S, 0) = 0, for all S ∈(0, 1), so that the cost is zero
if nobody is infected. On the S = 0 axis we have V (0, I) = (w+χ)I
I ∈(0, 1).
Parametrization of the model
We parameterize the model using data from the World Health Organization (WHO) compiled by the Johns Hopkins University Center for Systems Science and Engineering (JHU
CCSE) while acknowledging, like the rest of the recent literature, that at this point there is
considerable uncertainty about infection, recovery, and mortality rates. The data includes
the total cases, including separately those that have recovered and those that have died. We
deﬁne active cases as the total number of cases minus those that either recovered or died.
We use daily observations of all the countries that have registered at least 100 active cases
and include observations of the ﬁrst 25 days after they ﬁrst cross this threshold.
To calibrate β, the rate at which individuals who are infected bump into other people and
shed virus onto those people, we use the daily increase in active cases and assume a value
of 20 percent. The parameter γ governing the rate (per day) at which infected people either
recover or die is considered a ﬁxed parameter of the disease and is set to γ=1/18 reﬂecting
an estimated duration of illness of 18 days as in Atkeson but also consistent with the
fraction of infected agents that recovered or died according to the WHO as compiled in JHU
We set the fatality rate ϕ=0.01 × γ, which is consistent with the age-adjusted fatality rate
estimated form the Diamond Princess cruise ship and with the lower bound mortality rate in
the city of Vo’ Euganeo – two cases where there has been extensive testing. We set κ=0.05
× γ so the fatality rate is 3 percent when 40 percent of the population is infected. There is
considerable uncertainty on the fatality rate, mostly because the true rate of infected is not
really know. For instance, Eran, Jay, and Sood argue that the number of infected is
probably at least an order of magnitude larger, and thus the mortality rate much smaller.
We set the planner’s discount factor to be consistent with a 5 percent annual interest rate
and the per unit of time probability ν that a vaccine and a cure will appear so that it implies
that it takes on average a year and a half for these medical discoveries to become available.
We normalize output w=1 and set the extra cost of dying χ to zero. Note that in this case
a unit of output produced by each agent, w can be interpreted as GDP per capita, let say
65,000 USD. On the other hand, using r = 0.05 (5% per year) and χ = 0, then the shadow
cost of each life lost used by the planner is [w/r + χ], which is 20 times annual GDP per
capita, or about $1.3 Million.
Our choice of the benchmark value for χ = 0, and hence of the penalty deaths, is in line
with Hall, Jones, and Klenow . These authors use an utilitarian criterium to value the
extra years of life lost among those likely to die due to the infection, obtaining a cost of about
30 times per capita annual consumption, which is very close to our benchmark value of 20
times annual GDP per capita.7 The value of 20 annual per capita GDP is much lower than
the typical ﬁgures for statistical value of life, which are closer to $ 10 million, see Kniesner
and Viscusi , or about 150 GDP per capita. We will report result for half this value,
i.e. with a penalty of 10, and 30 annual GPD per capita, as well as for values closer to the
typical value of statistical life, of 80 and 140 times annual GDP per capita.
Lastly, we assume that even in a disaster scenario, economic sectors such as health,
government, retail, utilities, and food manufacturing will continue. These sectors combined
account for 25-30% of GDP . Thus, we set ¯L = 0.7.
7Following Hall, Jones, and Klenow and the literature they refer to, one can use that a year of life
lost is valued as three times annual consumption. Then, following their ideas, one can compute the expected
number of years of lives lost to those that die as a consequence of the virus, conditional on being infected.
They obtain a number between 10 and 15 years, with 10 being their headline ﬁgure. Thus, 3 × 10 years×
annual consumption per capita = 3 × 10 years × 2/3× annual GDP per capita = 20 × annual GDP per
Parameter Values for Benchmark Case
Deﬁnition/Reason
Daily increase of active cases if unchecked
Daily rate of infected recovery (includes those that die).
IFR: fatality per active case (per day).
Implies a 3 percent fatality rate with 40 percent infected.
Annual interest rate 5 percent.
Prob rate vaccine + cure (exp. duration 1.5 years)
1 - GPD share health, retail, government, utilities, and food mfg.
Eﬀectiveness of lockdown
Value of Statistical Life 20 × w (i.e. v.s.l ≈$1.3M)
In this section, we present the result for our numerical calculations. We display the time
path of the optimal policy starting at I(0) = 0.01, i.e. one percent of population infected
at t = 0 for our benchmark parameter values.8
In particular, we display the time path
of the optimal lockdown policy L(t) as function of time, the fraction of the population for
which lockdown applies L(t)[τ(S(t) + I(t)) + 1 −τ], the path of infected I(t), and the total
accumulated fraction of dead up to time t. Recall that N(0) = 1, so both infected and the
stock of dead can be all interpreted as fraction of the initial population. In this graphs,
the horizontal axis is time, conditional on the cure-vaccine not occurring before that period.
For comparison, we also plot the path if there is no lockdown policy, i.e. for L(t) = 0 for
all t ≥0. We complement these time paths with other type of ﬁgures: heat maps of the
8We assume that the initial fraction of the population susceptible is 98%, or S(0) = 0.98.
policy as a function of the state, including phase diagrams, and a 3-D representation of the
value function, as well as with a table with the value of following the policy across diﬀerent
scenarios.
Benchmark case.
We present the result for our benchmark case ﬁrst, and then we do some
sensitivity analysis. On one hand, our benchmark case favors a policy of lockdown due to the
following features: (i) the chosen values for the parameters β and γ of the SIR model imply
that a large fraction will be exposed to the virus if unchecked, lim S(t) ≈0.97 as t →∞, (ii)
we assume that the fatality rate can increase from 1% to up to 3% of those infected when
fraction of infected goes from 5% to 40%, and (iii) we assume that those recovered can be
identiﬁed and hence they are not locked down. On the other hand, our benchmark case uses
a value of statistical life of 20 times annual per capita GDP, which is in line with utilitarian
values of life for those likely to be aﬀected by COVID-19, see Hall, Jones, and Klenow ,
but an order of magnitude smaller than the average value of a statistical life used in other
public policy evaluations. We conduct sensitivity analysis for each of the these assumption
In what follows, we ﬁrst present the result for our benchmark parameter case, in Figure 1
and Figure 3, as well as its associated value function and optimal policy Figure 2. A phase
diagram for the benchmark case is shown in Figure 9. For the benchmark parameter values,
the top panel of Figure 1 shows that the lockdown starts only after two weeks. For these
parameters, the fraction of the population in lockdown peaks at 60%, about 10 days after the
lockdown starts, and decreases to be below 10% of the population by the sixteenth week after
the lockdown started. The lockdown ends in about 4 months. This implies a considerable
ﬂattening of the curve of infected, as can be seen in the middle panel of the ﬁgure, by
comparing the red (without no lockdown) vs blue lines (with optimal policy). In the long
run, the total number of deaths is about 0.80% smaller with the optimal policy, as can be
seen in the bottom panel of the ﬁgure.
Lower eﬀectiveness of lockdown.
We explore the sensitivity to parameter values by
changing the eﬀectiveness of the lockdown, i.e. by reducing it from θ = 0.5 to θ = 0.3. In the
case of less eﬀective lockdown, displayed in Figure 3 i.e. lower θ, the duration and severity
are lower. The fraction of population peaks in approximately 20 days, but it decreases at a
faster rate, reaching zero lockdown two months after the lockdown started. Instead, if the
lockdown where to be more eﬀective, say θ = 0.7, the duration will be even longer –case not
displayed in ﬁgures.
Constant fatality rate function (no congestion of health care system).
Importantly, the results change dramatically, in the sense that it is essentially optimal to have zero
lockdown, if κ = 0. This is the case where the case fatality rate is constant at 1%, so there
is no congestion on the health care system.
Lower fatality rate.
In this case we keep the increase in the fatality rate as the congestion
on the health care system increases –so we keep the value of κ, but we decrease the case
fatality rate when there are very few infected, i.e. we reduce ϕ to half of its benchmark
value. In comparison to the benchmark case, the lockdown is shorter, ﬁnishing about one
month earlier as can be seen in Figure 4.
Diﬀerent values of statistical life.
In Figure 5 we explore the consequence of a smaller
implied statistical value of life, half the value of the benchmark case. Unsurprisingly, the
lower value of v.s.l considerably diminishes the optimal lockdown level and duration, peaking
at a lower value than benchmark case, and with duration since start to ﬁnish of about 50 days.
In Figure 6, we explore the eﬀect of increasing the value of statistical life to 30 times
annual GDP per capita –which is in the upper end of the values consider by Hall, Jones,
and Klenow .9 In this case, the lockdown starts in two weeks –a bit faster than the
9For instance, this is consistent with a value of each year of extra life of 3 times annual consumption per
capita, times 15 years of lost expected life expectancy conditional on dying after being infected.
benchmark–, peaks in a month with about 60% of the population in lockdown, and decreases
linearly and slowly, until is abandoned slightly more than six month after it stared. The
fraction of population in lockdown reaches 10% only in slightly more than about 4 month
after the lockdown started. In this case, the more aggressive, and specially longer, lockdown
policy implies that the fraction of death after the epidemic is over is reduced by 1%, about
0.20% more than in the benchmark.
For reference, we have also computed the cases where the value of statistical life is 80
and 140 times annual per capita GDP, even though we view these values as too high for
this particular application. As expected the optimal lockdown rate is very high, for a very
long time. In the case of v.s.l. = 80 ann. per capita GDP, the lockdown rate starts in two
weeks, and L(t) = ¯L for about 8 months. The fraction of population in lockdown reaches
50% slightly about 3 months after the lockdown started, and it is approximately 15% a year
into the lockdown, when L(t) is below its allowed maximum. The case of v.s.l. = 140 ann.
per capita GDP is similar, since it is L(t) = ¯L for about 10 month. Another small diﬀerence
is that the lockdown starts almost right away in the case of the largest v.s.l..
Lower transmission rate.
In this case, since virus spread slowly (i.e. β = 0.10), the
lockdown starts much later. It also lasts considerably less, about two and half months. With
this rate, absence of changing behavior, the fraction of population that in the long run will
be infected, i.e 1−S(t) for large t is about 0.75, roughly in line with the CDC estimates, and
much smaller than in our benchmark case which is approximately 0.97. Figure 7 shows that
the infection curve is ﬂattened by the policy, but much less than in the benchmark case.
No testing of the recovered.
Figure 8 shows the results of the case with no test, so τ = 0
in the model. In this case the lockdown applies to anybody in the population, including
those that have recovered from the virus.
Recall that in this case, it is less eﬃcient to
lockdown agents, because the recovered are also lockdown, which it has the cost of reducing
output, without the beneﬁt of reducing the transmission of the virus.
In the case of no
test, the lockdown declines much more sharply than in the benchmark case with testing.
Interestingly, in both cases the lockdown involves similar costs in terms of forgone output,
since in the absence of testing the lockdown duration is shorter but it applies to a larger
fraction of people (recovered agents are also in lockdown). The most salient feature of the
case where a test is not available is that the lockdown ends up sooner, more abruptly. This
is due to the dynamics of the epidemiological model: as time goes by the fraction of those
recovered increases, and thus the lockdown becomes progressively less eﬃcient to stop the
transmission of the virus by locking down a progressively larger fraction of those that do not
transmit it. In spite of the similarity in term of total hour lost, we show below that welfare
under the optimal policy with testing is higher, in the order of a permanent 0.1% GDP ﬂow,
or equivalently to a one-time payment of 2% of a year’s GDP.
Figure 1: Benchmark Case (medium eﬀectiveness θ = 0.5)
Time (days)
Population (%)
Lockdown policy
Lockdown rate
% of population
Time (days)
Population (%)
Infected (%)
Infected (no control)
Infected (control)
Population (%)
Dead (no control)
Dead (control)
Note: The top panel shows the time paths for the lockdown rate (dashed blue line) and the share of the
population under lockdown (solid blue line). The panel in the center shows the share of the population that is
infected with control (blue) and without control (red). The bottom panel shows the share of the population
that die under control (blue) and under no control (red). The paths shown are under medium eﬀectiveness
(i.e. θ=0.5). The initial condition is I(0) = 0.01 and S(0) = 0.98.
Details on the benchmark case.
Figure 2 displays the value function and the optimal policy for the benchmark parameter values. The value function is plotted in the right
panel, for the relevant state space (S, I), and normalized as explained above, so we display
rV (S, I)/w in the vertical axis. The units are permanent ﬂow cost as a fraction of the total
output previous to the virus. Thus, a value of 0.02, means a cost equivalent to a permanent
reduction of 2% percent in the value of output, relative to the ﬂow of output before the
virus. Note that the V in the boundary of the state space with either S = 0 or I = 0, has
the properties described in Section 2.
The left panel panel of Figure 2 has a heat map of the optimal policy L∗(S, I). Yellow
indicates higher value of the lockdown rate L, and blue indicates lower values of L. Note that
close to both boundaries, i.e. either S = 0 for I = 0, ie. it is optimal to have zero lockdown
Figure 2: Value Function and Optimal Policy, benchmark case
Note: The ﬁgure on the left shows the optimal policy for the benchmark parameter values. The blue area
indicates lower values of lockdown and the yellow color higher values. The ﬁgure on the left depicts the value
function. The units for the value function are permanent ﬂow cost as a fraction of the total output before
the epidemic.
Figure 9 shows the heat map from the optimal policy, as in the previous ﬁgure, and a two
phase diagrams, i.e. two paths, in the state space (S, I) that the system will take starting
from an initial conditions. One path corresponds to the case of no policy, which moves to
large values of the fraction of infected –given by the red line. The other path has the evolution
of the state under the optimal policy –the dash light blue line–, where it can be seen that
the fraction infected is much smaller, as a consequence of the lockdown policy. Also you can
see how the two path coincide for a while, since the position of the seed of the virus is in the
region of the state space where lockdown is not optimal. Then the optimal path is controlled
by the lockdown, and shows a much lower fraction of infected in the vertical axis. Eventually,
the path moves to the region with no lockdown, which occurs after the system has acquired
herd immunity –note that at the end the trajectory is decreasing in I even if there is no
lockdown. This phase diagram can be used to follow other alternative paths, such as what
would happen if the optimal policy were to start after the virus has been unchecked for a
longer period of time. Note that unless the susceptible have reached a very small number,
starting the optimal policy later will involved immediate lockdown, i.e. the path will start
in the yellow area.
Size of the welfare cost under optimal policy.
Table 2 summarizes the value of following the optimal policy vs. the value where there is no lockdown (No Policy), for diﬀerent
parameter values.10
As explained above, our favorite all summary measure is to report
rV (S(0), I(0))/w. This number is the total expected discounted sum of future losses, both
due to the lost GDP caused by the lockdown in future periods, as well as the values of the lost
lives, where every life is evaluated at [w/r +χ]. The multiplication by r in rV (S(0), I(0))/w,
converts the expected discounted sum of future values into a permanent annual ﬂow, and the
division by w compares it with the level output before the virus was seeded. We also present
the part of rV (S(0), I(0))/w that is due to the output cost of the shutdown. This is just
0 e−(r+ν)t [1 −τ + τL(t)(S(t) + I(t))] dt. Capitalizing the cost due to the lockdown, i.e.
dividing it by r, we can obtain also a simple statistic measuring the severity of the lockdown.
For instance if this capitalized measure is 10%, then the lockdown is equivalent to stop 10%
of the population to work for an entire year. Finally, the last column displays the present
discounted value of leaving the virus unchecked, which we label as No Policy in column of
10The no policy case should not be interpreted as what will occur in the absence of policy, since an
equilibrium, even if constraint eﬃcient, will feature individuals self-isolating.
Table 2. In the three cases we express the losses in percentage. Importantly, if one wants
to convert any of this ﬁgures to the equivalent into one time payment, we should just divide
the them by r, i.e. multiplied them by 20 given our 5% annual interest rate.
For instance, for the benchmark case, the second row in top panel of Table 2, following the
optimal policy implies a permanent loss of approximately 1.5% of output. In other words,
as a consequence of the outbreak of the virus, even following the optimal policy, welfare
is comparable to an equivalent measure of being 1.5% permanently poorer. We can also
recapitalize this loss and express it as fraction of one year GDP, obtaining, 28%. From the
1.5% total permanent loss, 0.4% is due to output losses due to lockdown, or an equivalent to
8% of one year GDP., While for the same parameters, if there is no lockdown (No Policy),
the loss is equivalent to a permanent decrease in output of 1.9%. Thus, the optimal policy
reduces the losses of an equivalent of permanent increase of 0.40% of GDP per year. The
ﬁrst three rows explore the diﬀerent values of eﬀectiveness of the lockdown.
The second panel, with four rows, corresponds to the case of diﬀerent values of a statistical
life. Recall that the benchmark case, χ = 0 implies a value of a statistical of life (v.s.l) of
about 20 annual GDP per capita. We consider a case with lower value, i.e. with a multiple
of 10, and case with a higher value, 30 annual GDP per capita, and two cases with a much
higher value, typical from uses of a statistical value of life in other contents, i.e. 80 and 140
annual GDP per capita. For a (v.s.l) of 30 annual GDP per capita, the part due to output
loss is a permanent ﬂow of 0.6% or equivalently a 12% fraction of one year GDP.
The next panel, with three rows corresponds to the case where the fatality rate φ(I) is
constant at ϕ = 0.01γ, or equivalently κ = 0. In this case, as explained above, the optimal
policy has no lockdown, so the loses of the optimal policy and the case of no policy are the
same, and also much smaller, since the death rate does not spike up. This highlights the
importance of the assumption implied in our benchmark case that φ is increasing, which
captures the extra fatalities due to the congestion in the heath care system caused by a large
number of infected.
The last panel, with four rows, corresponds to the case of no test, or τ = 0 in the notation
used above. For this case, we present ﬁve diﬀerent values of χ, corresponding to ﬁve diﬀerent
values of a statistical life. Each row has v.s.l is a multiple of the annual GDP per capita,
with multiples of 10, 20, 30, 80, and 140, and otherwise the parameters are the same as in the
benchmark case. Comparing the benchmark case –i.e. the second row of the top panel– with
the same case without test –i.e. the second row of the last panel– we ﬁnd small diﬀerences. In
particular the expected discounted cost under the optimal policy is, expressed as a permanent
ﬂow is 0.1% (10 basis point) higher without test than with test, i.e. 1.6% vs 1.5%, or in terms
of a one time value approximately 2% of a year GDP. This diﬀerence gets larger for larger
values of a statistical life. For a smaller value of v.s.l., we ﬁnd that the diﬀerence is smaller
than 0.1%, and . Instead, as v.s.l increases to multiplies of annual GDP per capita of 30, 80
and 140 the values are higher. For our preferred parameter values, say v.s.l. between 20 and
30 times ann. per capita GDP, the value of the test is equivalent to between 2% and 4% of
one year GDP.
Table 2: Welfare Losses
with Optimal Policy vs. without Intervention
Parameters
Welfare Loss
Output Loss
Welfare Loss
Benchmark Case
Low eﬀectiveness
Medium eﬀectiveness
High eﬀectiveness
Alternative Values of Statistical Life, diﬀerent χ
v.s.l = 10× GDP per capita
v.s.l = 30× GDP per capita
v.s.l = 80× GDP per capita
v.s.l = 140× GDP per capita
Constant fatality rate
Low eﬀectiveness
Medium eﬀectiveness
High eﬀectiveness
No testing of the recovered τ = 0
v.s.l = 10× GDP per capita
v.s.l = 20× GDP per capita
v.s.l = 30× GDP per capita
v.s.l = 80× GDP per capita
v.s.l = 140× GDP per capita
Note: Welfare losses are measured by the permanent percent reduction in per capita GDP induced by the
policy (or its absence) under various parametrizations. Output losses is the welfare cost component due to
the reduced level of economic activity (i.e. excluding fatalities). The benchmark parameter values are from
Table 1. Multiplying any of the numbers in the last three columns by 1/r = 20, converts the losses from
permanent ﬂow to a one time payment as a fraction of a year GDP. The initial condition for all scenarios is
I(0) = 0.01 and S(0) = 0.98.
Other ﬁgures
Figure 3: Low Lockdown Eﬀectiveness (θ = 0.3)
Time (days)
Population (%)
Lockdown policy
Lockdown rate
% of population
Time (days)
Population (%)
Infected (%)
Infected (no control)
Infected (control)
Population (%)
Dead (no control)
Dead (control)
Note: The top panel shows the time paths for the lockdown rate (dashed blue line) and the share of the
population under lockdown (solid blue line). The panel in the center shows the share of the population that is
infected with control (blue) and without control (red). The bottom panel shows the share of the population
that die under control (blue) and under no control (red). The paths shown are under medium eﬀectiveness
(i.e. θ=0.3). The initial condition is I(0) = 0.01 and S(0) = 0.98.
Figure 4: Lower Fatality Per Active Case (ϕ = 0.005 × γ)
Lockdown policy
Time (days)
Population (%)
Lockdown rate
% of population
Infected (%)
Time (days)
Population (%)
Infected (no control)
Infected (control)
Population (%)
Dead (no control)
Dead (control)
Note: The top panel shows the time paths for the lockdown rate (dashed blue line) and the share of the
population under lockdown (solid blue line). The panel in the center shows the share of the population that is
infected with control (blue) and without control (red). The bottom panel shows the share of the population
that die under control (blue) and under no control (red). The paths shown are under a lower fatality rate
(i.e. ϕ = 0.005 × γ). The initial condition is I(0) = 0.01 and S(0) = 0.98.
Figure 5: Lower Value of Statistical Life, v.s.l. = 10 ann. GDP p/capita)
Time (days)
Population (%)
Lockdown policy
Lockdown rate
% of population
Time (days)
Population (%)
Infected (%)
Infected (no control)
Infected (control)
Population (%)
Dead (no control)
Dead (control)
Note: The top panel shows the time paths for the lockdown rate (dashed blue line) and the share of the
population under lockdown (solid blue line). The panel in the center shows the share of the population
that is infected with control (blue) and without control (red). The bottom panel shows the share of the
population that die under control (blue) and under no control (red). The paths shown are under a lower
value of statistical life (i.e. χ = −1
r , v.s.l approximately $0.65 Million). The initial condition is I(0) = 0.01
and S(0) = 0.98.
Figure 6: Higher Value of Statistical Life, ( v.s.l. = 30 ann. GDP p/capita)
Time (days)
Population (%)
Lockdown policy
Lockdown rate
% of population
Time (days)
Population (%)
Infected (%)
Infected (no control)
Infected (control)
Population (%)
Dead (no control)
Dead (control)
Note: The top panel shows the time paths for the lockdown rate (dashed blue line) and the share of the
population under lockdown (solid blue line). The panel in the center shows the share of the population
that is infected with control (blue) and without control (red). The bottom panel shows the share of the
population that die under control (blue) and under no control (red). The paths shown are under a higher
value of statistical life (i.e. χ = 1
r , v.s.l approximately $1.9 Million). The initial condition is I(0) = 0.01
and S(0) = 0.98.
Figure 7: Lower Transmission Rate (β = 0.10)
Lockdown policy
Time (days)
Population (%)
Lockdown rate
% of population
Infected (%)
Time (days)
Population (%)
Infected (no control)
Infected (control)
Population (%)
Dead (no control)
Dead (control)
Note: The top panel shows the time paths for the lockdown rate (dashed blue line) and the share of the
population under lockdown (solid blue line). The panel in the center shows the share of the population that is
infected with control (blue) and without control (red). The bottom panel shows the share of the population
that die under control (blue) and under no control (red). The paths shown are under a lower number of
susceptible agents per unit of time to whom an infected agent can transmit the virus (i.e. β = 0.10). The
initial condition is I(0) = 0.01 and S(0) = 0.98.
Figure 8: No testing of those recovered (τ = 0)
Time (days)
Population (%)
Lockdown policy
Lockdown rate = % of population
Time (days)
Population (%)
Infected (%)
Infected (no control)
Infected (control)
Population (%)
Dead (no control)
Dead (control)
Note: Except for the testing, which is set to τ = 0, this ﬁgure uses the benchmark parameter values. The
top panel shows the time paths for the lockdown rate and the share of the population under lockdown, which
coincide in this case, since there is no testing. The panel in the center shows the share of the population
that is infected with control (blue) and without control (red). The bottom panel shows the share of the
population that die under control (blue) and under no control (red). The case shown is with no testing for
those recovered. The initial condition is I(0) = 0.01 and S(0) = 0.98.
Figure 9: Phase Diagram, benchmark case with I(0) = 0.01
Note: The ﬁgure shows the optimal policy for the benchmark parameter values. The blue area indicates
lower values of lockdown and the yellow color higher values. The ﬁgure also shows two phase diagrams in
the state space (S, I). The red dot indicates the initial condition I(0) = 0.01 and S(0) = 0.98. The red line
corresponds to the case of no policy. The light blue line shows the dynamics of the state under the optimal