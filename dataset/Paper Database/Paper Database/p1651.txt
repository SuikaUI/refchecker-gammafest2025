SOME ASPECTS OF THE SEQUENTIAL DESIGN
OF EXPERIMENTS
HERBERT ROBBINS
1. Introduction. Until recently, statistical theory has been restricted to the design and analysis of sampling experiments in which
the size and composition of the samples are completely determined
before the experimentation begins. The reasons for this are partly
historical, dating back to the time when the statistician was consulted, if at all, only after the experiment was over, and partly intrinsic in the mathematical difficulty of working with anything but
a fixed number of independent random variables. A major advance
now appears to be in the making with the creation of a theory of the
sequential design of experiments, in which the size and composition
of the samples are not fixed in advance but are functions of the observations themselves.
The first important departure from fixed sample size came in
the field of industrial quality control, with the double sampling inspection method of Dodge and Romig [l]. Here there is only one
population to be sampled, and the question at issue is whether the
proportion of defectives in a lot exceeds a given level. A preliminary
sample of n\ objects is drawn from the lot and the number x of defectives noted. If x is less than a fixed value a the lot is accepted without further sampling, if x is greater than a fixed value b (a<b) the
lot is rejected without further sampling, but if aSxSb
then a second
sample, of size w2, is drawn, and the decision to accept or reject the
lot is made on the basis of the number of defectives in the total sample
of Wi+n2 objects. The total sample size n is thus a random variable
with two values, n\ and ni+n2, and the value of n is stochastically
dependent on the observations. A logical extension of the idea of
double sampling came during World War II with the development,
chiefly by Wald, of sequential analysis , in which the observations
are made one by one and the decision to terminate sampling and to accept or reject the lot (or, more generally, to accept or reject whatever
statistical "null hypothesis" is being tested) can come at any stage.
The total sample size n now becomes a random variable capable in
principle of assuming infinitely many values, although in practice a
finite upper limit on n is usually set. The advantage of sequential
An address delivered before the Auburn, Alabama, meeting of the Society,
November 23, 1951, by invitation of the Committee to Select Hour Speakers for
Southeastern Sectional Meetings; received by the editors December 10, 1951.
HERBERT ROBBINS
[September
over fixed-size sampling lies in the fact that in some circumstances
the judicious choice of a sequential plan can bring about a considerable reduction in the average sample size necessary to reduce the
probability of erroneous decision to a desired low level. The theory of
sequential analysis is still very incomplete, and much work remains
to be done before optimum sequential methods become available for
treating the standard problems of statistics.
The introduction of sequential methods of sampling freed statistics from the restriction to samples of fixed size. However, it is
not only the sample size that is involved in the efficient design of an
experiment. Most statistical problems met with in practice involve
more than one population, and in dealing with such problems we
must specify which population is to be sampled at each stage. An
example will serve to clarify this point. Suppose we are dealing
with two normally distributed populations with unknown means
Mi» M2 and variances of, of, and that we wish to estimate the value of
the difference Mi~"M2- In order to concentrate on the point at issue
we shall suppose that the total sample size, w, is fixed. There remains
the question of how the n observations are to be divided between the
two populations. If #1, #2 denote the means of samples of sizes #1, n2
from the two populations, then #1 — x2 is an unbiased estimator of
Mi~M2, with variance a-2 = (o^/wi) +(02/^2). For fixed n=ni+ti2,
minimum when ni/fi2 = Ö I / 0 * If the latter ratio is known in advance,
all is well. If this ratio is not known, but if the sampling can be done
in two stages, then it would be reasonable to draw preliminary
samples of some size m from each of the two populations and to use
the values so obtained to estimate 0-1/0-2; the remainder of the n—2m
observations could then be allocated to the two populations in accordance with the sample estimate of o*i/(r2. The question then becomes, what is the best choice for m? If m is small, no accurate estimate of <ri/(T2 can be made. If m is large, then the remaining n — 2m
observations may be too few to permit full utilization of the approximate knowledge of cri/o^. (This kind of dilemma is characteristic of
all sequential design problems.) More generally, we could consider
schemes in which the observations are made one by one, with the decision as to which population each observation should come from
being allowed to depend on all the previous observations; the total
sample size n could be fixed or could be a random variable dependent
on the observations.
Despite the total absence of theory, a notable pioneering venture in
the spirit of sequential design was carried out in 1938 by Mahalanobis
 to determine the acreage under jute in Bengal. Preliminary sur-
SEQUENTIAL DESIGN OF EXPERIMENTS
veys were made on a small scale to estimate the values of certain
parameters, a knowledge of which was essential to the efficient design of a subsequent large scale census. In a subsequent publication
 Mahalanobis called attention to the desirability of revising the
design of any experiment as data accumulates. The question, of
course, is how best to do this.
We are indebted to Wald for the first significant contribution to the
theory of sequential design. His book states the problem in full
generality and gives the outline of a general inductive method of
solution. The probability problems involved are formidable, since
dependent probabilities occur in all their complexity, and explicit
recipes are not yet available for handling problems of practical interest. Nevertheless, enough is visible to justify a prediction that future
results in the theory of sequential design will be of the greatest importance to mathematical statistics and to science as a whole.
In what follows we shall discuss a few simple problems in sequential
design which are now under investigation and which are different
from those usually met with in statistical literature. Optimum solutions to these problems are not known. Still, it is often better to have
reasonably good solutions of the proper problems than optimum solutions of the wrong problems. In the present state of statistical theory
this principle applies with particular force to problems in sequential
2. A problem of two populations. Let A and B denote two statistical populations (coins, urns, manufacturing processes, varieties
of seed, treatments, etc.) specified respectively by univariate cumulative distribution functions F(x) and G(x) which are known only to
belong to some class D. We shall suppose that the expectations
exist. How should we draw a sample x\, #2, • • • , #n from the two
populations if our object is to achieve the greatest possible expected value
of the sum S „ = x i + • • • +xn?
For example, let A and B denote two coins of unknown bias, and
suppose that we are allowed to make n tosses, with the promise of
getting $1 for each head but nothing for tails. If #,- = 1 or 0 according
as heads or tails occurs on the ith. toss, then Sn denotes the total sum
which we are to receive, and a and /? (0 :ga, /? ^ 1) are the respective
probabilities of obtaining heads on a single toss of coins A and B.
As a general intuitive principle, whenever we feel pretty sure from
HERBERT ROBBINS
[September
the results of previous observations that one of the two numbers a,
j8 is the greater, we shall want to devote more of our future observations to that population. Note that there is no terminal decision to
make; that is, we are not interested in estimating a—fi or in testing
the hypothesis that a=/3, etc., after the sample is drawn. The whole
problem lies in deciding how to draw the sample. There certainly exist
practical situations in which the present problem represents more
nearly what one wants to solve than would any formulation in terms
of testing hypotheses, estimating parameters, or making terminal
decisions. In fact, the problem represents in a simplified way the
general question of how we learn—or should learn—from past experience. A reasonably good solution of the problem must therefore be
found if mathematical statistics is to provide a guide to what has
been called by Neyman [ô] inductive behavior.
To begin with we shall consider the special case already mentioned
in which A and B are coins and the unknowns a and /3 are the respective probabilities of obtaining heads (x t=l) on a single trial. Let us
take as an example of a possible sampling rule the following.
Rule R\. For the first toss choose A or B at random. Then, for
/ = 1, 2, • • •, if the ith toss results in heads, stick to the same coin for
the (i+l)th
toss, while if the ith toss results in tails, switch to the
other coin for the (i+l)th
What are the operating characteristics of the rule Ri? The successive tosses represent the evolution of a simple Markov chain with
four states, (A, H), (A, T), (B, H), (B, T), and with transition probabilities which are easily written down; for example, the probability
of a transition from (A, H) on the ith toss to {A, T) on the (i+l)th
toss is 1 — a. Let pi denote the probability of obtaining heads on the
ith toss. To avoid trivialities we shall suppose that a and /3 are not
both 0 or both 1; then |a+/3 — l| < 1 . It is easy to show that
pi+1 « (« + 0 - l)p{ +(a + p~
from which it follows that
p{ = ( a + 0 - l)«-i px
2 - (a + fi) J T 2 - (a + fi)
and hence that
2 - ( « + /3)
where we have set
SEQUENTIAL DESIGN OF EXPERIMENTS
It follows that in using the rule Ri,
Hm E ( — ) = lim (
— ) = y + —
Now, if we knew which of the two numbers ce, /3 is the greater, then
by using the corresponding coin exclusively we could achieve the
E ^ = m a x ( < * , / 3 ) = 7 + 5.
Hence it is natural to take the difference
L(A, B% Ri) - (7 + 8) - ( T + YZr) = 5[* ~ 73"] ~ °
as a measure of the asymptotic loss per toss, by a person who uses Ri,
due to ignorance of the true state of affairs. It is easy to show that
L(A, B, Ri) has its maximum value, Mi = 3-2 3 / 2£U72, when a = 0
and /3 = 2 — 21/2^.586 or vice versa. Thus a person using Ri will, for
large n, lose on the average at most 17.2 cents per toss due to ignorance of which is the better coin. On the other hand, consider the
rule Ro which consists in choosing one of the two coins A, B at random
and then sticking to it, come what may (or in tossing the two coins
alternately). The corresponding quantity L(A,
Bf Ro) is easily
seen to have the value (7 + 8)— 7=sS, which has its maximum, M0
= 1/2, when a = 0 and /3 = 1 or vice versa. Clearly, Ri is considerably
better than R0.
The rule Ro makes the choice of the coin for the ith. toss independent of the results of previous tosses, while Ri makes this choice
depend on the result of the (i — l)th toss only. For the most general
rule R the choice of the coin for the ith toss will depend on the results
# ! , • • • , Xi-i of all the previous tosses. For any such rule R let
Ln(A, B, R) == max (a, 0) - E ®
where E denotes expectation computed on the basis of a1 fi> and R,
Mn(R) = max [Ln(A, B, R)],
HERBERT ROBBINS
[September
<t>M = min [Mn(R)].
It would be interesting to know the value of <j>{n) and the explicit
description of any "minimax" rule R for which the value <j>(n) is
A much simpler problem is : do there exist rules R such that
lim Ln(A, B, R) = 0
for every A, B?
We shall see in the next paragraph that the answer is yes, not only
in the case of the coins but for any two populations.
Returning to the general case in which A and B are arbitrary
statistical populations for which the values (1) exist, consider the
sampling rule R defined as follows: let
1 = ai < a2 < • • • < an < • • • ,
2 = 6i < b2 < • • • < bn < • • •
be two fixed, disjoint, increasing sequences of positive integers of
density 0; that is, such that the proportion of the integers 1, 2, • • • , n
which are either a's or Vs tends to 0 as n—» <*>. We define inductively:
if the integer i is one of the a's> take the ith observation, xiy from
population A, if i is one of the ô's, take %i from B, and if i is neither
one of the a's nor one of the b's> take Xi from A or B according as the
arithmetic mean of all previous observations from A exceeds or does
not exceed the arithmetic mean of all previous observations from B.
It can be shown to follow from the strong law of large numbers that
with probability 1,
lim — = max (a, j3).
This in turn can be shown to imply the relation
lim E ( — ) = max (a, 0),
lim Ln(A, B, R) = max (a, 0) - lim E ( — ) = 0
for any A, B such that a> /3 exist.
3. Some other problems of sequential design. The problem of
SEQUENTIAL DESIGN OF EXPERIMENTS
§2 can be generalized in various ways. For one thing, we can let the
total sample size n be a random variable, either independent of the
observations or dependent on them. As an example of the latter case,
suppose in the problem of the two coins that we have to pay a fixed
amount c for the privilege of making each toss. We may then decide
to stop tossing whenever it seems pretty certain that max (a, &)<c;
this amounts to a special case of a problem of three populations. We
can even consider the case of a continuum of populations. Suppose
we can apply a certain treatment to some plant or animal at any
intensity 0 in some interval, and let F(x, 0) be the cumulative distribution function of the response x to the treatment of intensity 0.
The expected value
xdF(x, 0),
the "regression" of x on 0, is assumed to be unknown. Let {0t} denote any sequence of 0 values, chosen sequentially by the experimenter, and let {xi} denote the corresponding sequence of responses,
so that each Xi has the distribution Pr [x t^x] = F(x, 0t). (I) Suppose
a(0) has a unique maximum at some unknown point 0O. How should
the experimenter choose the sequence {di} in order to maximize the
expected value of the sum Sn=xi+
• • • +xn or, alternatively, in
order to estimate the value of 0O? (II) Suppose a(6) is an increasing
function of 0 which takes on a given value a0 at some unknown point
0O. How should the experimenter choose the sequence {di} in order to
estimate the value of 0o? Problem I is the problem of the experimental determination of the maximum of a function when the observations are subject to a random error; Problem II is fundamental
in sensitivity testing and bioassay.
It is clear that in both of these problems the choice of each 0tshould be made to depend on the responses xi, • • • , #i_i at the previous levels 0i, • • • , 0;_i of the treatment, so that we are dealing with
problems of sequential design. The non-sequential study of Problem
I was initiated by Hotelling (see also ), but no sequential
theory has yet been published. Problem II has been considered by
Robbins and Monro ; their method is as follows. Let {an} be a
sequence of positive constants such that
Z ) « n < 0 0 ,
let 0i be arbitrary, and set
HERBERT ROBBINS
[September
0w+i - On + an(aQ - xn)
(» » 1, 2, • • • )•
Then under certain mild restrictions on F(x, 0) it can be shown that
lim 0n = So
in probability.
In this and other problems, any sequential design with reasonably
good properties is likely to find an appreciative audience. This will
encourage the use of random sampling methods to find empirical
approximations to the operating characteristics of sequential designs
when a full mathematical solution is difficult. An empirical study of
the rapidity of convergence in (20) has been made by Teichroew .
4. The problem of optional stopping. To fix the ideas, let x be
normally distributed with unknown mean 0 and unit variance. Suppose we wish to test the null hypothesis, Ho, that 0 = 0 against the
alternative, Hi, that 0>O. The standard statistical test based on a
sample of fixed size n is the following. Let Sn~xi+
• • • +xn and
reject H0 in favor of Hi if and only if
Sn > an1'2,
where a is some constant. The probability of rejecting H0 when it is
true will then be
c(a) « 1 - *(«),
where we have set
and by choosing a large we can make e(a) as small as we please. For
example, if a = 3.09 then €(a)S.001.
Suppose now that Ho is true but that an unscrupulous experimenter
wishes to get an unwary statistician to reject it. If the sample size n
has not been agreed upon in advance the experimenter could adopt
the technique of stopping the sampling as soon as the inequality (21)
is verified. The law of the iterated logarithm of probability theory
implies that with probability 1 the inequality (21) will hold for infinitely many values of n if the sampling continues indefinitely, no
matter how large the value of a. Hence the experimenter is "sure" to
come eventually to a value of n for which (21) holds, and by stopping
the experiment at this point he will cause the statistician to reject Ho
even though it is true. This fact immediately vitiates the use of (21)
as a test of H0 if there is any possibility that optional stopping may be
The simplest way for the statistician to guard against the effect
SEQUENTIAL DESIGN OF EXPERIMENTS
of optional stopping is to insist that the size of the sample be fixed in
advance of the experimentation. Such a restriction would often be
too rigid for practical use. The statistician might therefore content
himself with setting limits ni rg n ^ n^ on the sample size which will be
flexible enough to meet the contingencies of experimentation but
narrow enough to eliminate the worst effects of optional stopping. To
this end the statistician would like to know the value of the function
g{n\y ni, a) = Pr [Sn > an112 for some »i, 5* n ^ w2],
where the %i are independent and normal (0, 1). It is quite easy to
establish the inequality
g(ni, fi2, a) <
; where X = — >
X1'2 - 1 \
V (x - i)W
which is useful when X is not too large, and sharper inequalities can
no doubt be devised.
The problem of optional stopping has received little attention in
statistical theory. (See, however, [ll], especially pp. 286-292.) One
need not assume that the experimenter is consciously trying to deceive the statistician—the two are often the same person—to recognize the desirability of devising methods of statistical analysis which
would be relatively insensitive to the effects of optional stopping.