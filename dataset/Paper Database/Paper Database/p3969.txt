IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 55, NO. 7, JULY 2017
Deep Recurrent Neural Networks for
Hyperspectral Image Classiﬁcation
Lichao Mou, Student Member, IEEE, Pedram Ghamisi, Member, IEEE,
and Xiao Xiang Zhu, Senior Member, IEEE
Abstract—In recent years, vector-based machine learning
algorithms, such as random forests, support vector machines,
and 1-D convolutional neural networks, have shown promising
results in hyperspectral image classiﬁcation. Such methodologies, nevertheless, can lead to information loss in representing
hyperspectral pixels, which intrinsically have a sequence-based
data structure. A recurrent neural network (RNN), an important
branch of the deep learning family, is mainly designed to handle
sequential data. Can sequence-based RNN be an effective method
of hyperspectral image classiﬁcation? In this paper, we propose a
novel RNN model that can effectively analyze hyperspectral pixels
as sequential data and then determine information categories
via network reasoning. As far as we know, this is the ﬁrst time
that an RNN framework has been proposed for hyperspectral
image classiﬁcation. Speciﬁcally, our RNN makes use of a
newly proposed activation function, parametric rectiﬁed tanh
(PRetanh), for hyperspectral sequential data analysis instead of
the popular tanh or rectiﬁed linear unit. The proposed activation
function makes it possible to use fairly high learning rates
without the risk of divergence during the training procedure.
Moreover, a modiﬁed gated recurrent unit, which uses PRetanh
for hidden representation, is adopted to construct the recurrent
layer in our network to efﬁciently process hyperspectral data and
reduce the total number of parameters. Experimental results
on three airborne hyperspectral images suggest competitive
performance in the proposed mode. In addition, the proposed
network architecture opens a new window for future research,
showcasing the huge potential of deep recurrent networks for
hyperspectral data analysis.
Index Terms—Convolutional neural network (CNN), deep
learning, gated recurrent unit (GRU), hyperspectral image classiﬁcation, long short-term memory (LSTM), recurrent neural
network (RNN).
I. INTRODUCTION
N THE past few decades, the analysis of hyperspectral
imagery acquired by remote sensors has attracted considerable attention in the remote sensing community, as such data
are characterized in hundreds of continuous observation bands
throughout the electromagnetic spectrum with high spectral
Manuscript received August 26, 2016; revised October 29, 2016; accepted
November 15, 2016. Date of publication April 28, 2017; date of current
version June 22, 2017. This work was supported in part by the China
Scholarship Council, in part by the Alexander von Humboldt Foundation,
in part by the Helmholtz Association through the framework of the Young
Investigators Group SiPEO under Grant VH-NG-1018, and in part by the
European Research Council (ERC) under the European Unions Horizon 2020
Research and Innovation Programme under Grant ERC-2016-StG-714087
(Acronym: So2Sat). (Corresponding author: Xiao Xiang Zhu.)
The authors are with the Remote Sensing Technology Institute, German
Aerospace Center, 82234 Wessling, Germany, and also with Signal Processing
in Earth Observation, Technical University of Munich, 80333 Munich, Germany (e-mail: ; ; ).
Color versions of one or more of the ﬁgures in this paper are available
online at 
Digital Object Identiﬁer 10.1109/TGRS.2016.2636241
resolution . With this rich spectral information, different
land cover categories can potentially be precisely differentiated. To beneﬁt from this type of data, supervised hyperspectral image classiﬁcation plays a signiﬁcant role and has been
investigated in many applications, including urban development – , the monitoring of land changes – , scene
interpretation – , and resource management , .
Numerous types of supervised classiﬁcation models have
been discussed in the literature, including decision trees ,
random forests , , and support vector machines
(SVMs) , . Among them, the random forest 
develops multiple trees from randomly sampled subspaces
of input hyperspectral pixel vectors and then combines the
outputs via voting or a maximum a posteriori rule. In contrast,
SVM, a supervised machine learning technique, has achieved
great success in various applications and is considered a stable
and efﬁcient algorithm for hyperspectral image classiﬁcation
tasks. An SVM seeks to separate two-class data by learning an
optimal decision hyperplane that can best separate the training
samples in a kernel-included high dimensional feature space.
Some strategies, such as one-against-all and one-against-one,
enable the use of original binary SVM for multiclass classiﬁcation. In addition, some extensions of the SVM model
in hyperspectral image classiﬁcation have been presented to
improve the classiﬁcation performance , .
When the ratio of the number of available training samples
and the number of spectral bands is unbalanced, theoretical and practical problems may arise and the hyperspectral
image classiﬁcation becomes an ill-posed problem. For example, while keeping the number of available training samples
constant, the classiﬁcation accuracy will decrease when the
dimension of input feature vectors becomes large , .
In recent years, deep learning has made promising achievements in the machine learning ﬁeld – . It attempts to
learn hierarchical representations from raw data and is capable
of learning simple concepts ﬁrst and then successfully building
up more complex concepts by merging the simpler ones.
In remote sensing, convolutional neural networks (CNNs)
have been shown to be successful for hyperspectral data
classiﬁcation – . Hu et al. presented a CNN
that contains an input layer, a convolutional layer, a maxpooling layer, a fully connected layer, and an output layer
for hyperspectral image classiﬁcation. The CNN has been
employed to classify hyperspectral data directly in the spectral
domain. Makantasis et al. presented a deep learningbased classiﬁcation method that hierarchically constructs highlevel features automatically. In particular, their model exploits
0196-2892 © 2017 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted,
but republication/redistribution requires IEEE permission. See for more information.
IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 55, NO. 7, JULY 2017
a CNN to encode the spectral and spatial information of
pixels and a multilayer perceptron to conduct the classiﬁcation
task. Chen et al. proposed a regularized 3-D CNN-based
feature extraction model to extract efﬁcient spectral-spatial
features for hyperspectral image classiﬁcation. In addition,
Chen et al. proposed a hybrid framework based on stacked
autoencoders for the classiﬁcation of the hyperspectral data.
All of the supervised models for hyperspectral images
described earlier are vector-based methodologies.1 It should
be noted that these vector-based approaches can lead to information loss when representing hyperspectral pixels, which
intrinsically have a sequence-based data structure. To the best
of our knowledge, almost all advanced spectral classiﬁers, such
as SVM, random forest, and CNN-based classiﬁcation, are
vector-based approaches, which consider hyperspectral data to
be a collection of pixel vectors and perform the classiﬁcation
procedure in feature space: each pixel is considered a point in
an orderless d-dimensional feature space in which d represents
the number of dimensions (bands) . However, hyperspectral
data can be seen as a set of orderly and continuing spectra sequences in the spectral space. Analyzing hyperspectral
imagery from a sequential perspective has not been addressed
so far. Our motivation in this paper is to explore the representation of hyperspectral pixels via the sequential perspective
instead of classifying hyperspectral data in the feature space.
In this paper, we make use of a recurrent neural network (RNN) to characterize the sequential property of
a hyperspectral pixel vector for the classiﬁcation task.
An RNN – is a network that uses recurrent connections between neural activations at consecutive time steps;
such a network uses hidden layers or memory cells to
learn the states that model the underlying dynamics of the
input sequence for sequential data over time. RNNs have
gained signiﬁcant attention for solving many challenging
problems involving sequential data analysis, such as language modeling , machine translation , and speech
recognition , . Since the temporal variability of a
sequential signal, such as a language sentence, is similar to the
spectral variability of a hyperspectral pixel, the same idea can
be applied to hyperspectral pixel vectors. The RNN exploits
a recurrent procedure to characterize spectral correlation and
band-to-band variability, where the network parameters are
determined by training with available samples. In this context,
we propose a novel RNN with a specially designed activation
function and modiﬁed gated recurrent unit (GRU) to solve the
multiclass classiﬁcation for hyperspectral imagery. This paper
contributes to the literature in three major respects.
1) We represent and process the pixels of hyperspectral
images via a sequential perspective instead of taking
them as feature vectors to capture the intrinsic sequencebased data structure of hyperspectral pixels. This enables
us to take full advantage of the sequential property of
hyperspectral data, e.g., spectral correlation and bandto-band variability.
1Here, vector-based approaches refer to those that consider the input to be
vectors. Although CNN-based models consider the inherent relationship of the
inputs during the process, such models are still categorized as vector-based
models in this paper.
2) An RNN with GRUs is proposed for a hyperspectral
image classiﬁcation task. To the best of our knowledge,
this is the ﬁrst use of the recurrent network model for
the problem of hyperspectral image classiﬁcation.
3) We introduce a new activation function, parametric
rectiﬁed tanh (PRetanh), which generalizes the rectiﬁed
unit for the deep RNN and then modiﬁes the proposed
activations of GRUs. With this new activation function,
fairly high learning rates can be used to train the network
without the risk of divergence.
The remainder of this paper is organized as follows.
An introduction to RNNs is brieﬂy given in Section II. The
details of the proposed RNN architecture for hyperspectral
image classiﬁcation, including a novel activation function and
modiﬁed GRU, are described in Section III. The network
setup, experimental results, and a comparison with stateof-the-art approaches are provided in Section IV. Finally,
Section V concludes this paper.
II. BACKGROUND ON RECURRENT NEURAL NETWORKS
An RNN , is a class of artiﬁcial neural network
that extends the conventional feedforward neural network with
loops in connections. Unlike a feedforward neural network,
an RNN is able to process the sequential inputs by having a
recurrent hidden state whose activation at each step depends
on that of the previous step. In this manner, the network can
exhibit dynamic temporal behavior.
Given a sequence data x = (x1, x2, . . . , xT ), where xi is
the data at ith time step, an RNN updates its recurrent hidden
state ht by
ϕ(ht−1, xt), otherwise
where ϕ is a nonlinear function, such as a logistic sigmoid
function or hyperbolic tangent function. Optionally, the RNN
may have an output y = (y1, y2, . . . , yT ). For some tasks,
such as hyperspectral image classiﬁcation, we need only one
output, i.e., yT .
In the traditional RNN model, the update rule of the
recurrent hidden state in (1) is usually implemented as follows:
ht = ϕ(Wxt + Uht−1)
where W and U are the coefﬁcient matrices for the input at
the present step and for the activation of recurrent hidden units
at the previous step, respectively.
In fact, an RNN can model a probability distribution over
the next element of the sequence data, given its present
state ht, by capturing a distribution over sequence data of variable length. Let p(x1, x2, . . . , xT ) be the sequence probability,
which can be decomposed into
p(x1, x2, . . . , xT ) = p(x1) · · · p(xT |x1, . . . , xT −1).
Then, each conditional probability distribution can be modeled with a recurrent network
p(xt|x1, . . . , xt−1) = ϕ(ht)
MOU et al.: DEEP RNNs FOR HYPERSPECTRAL IMAGE CLASSIFICATION
where ht is obtained from (1) and (4). Our motivation in this
paper is apparent here: a hyperspectral pixel acts as sequential
data instead of a feature vector, and so a recurrent network
can be adopted to model the spectral sequence.
As an important branch of the deep learning family, RNNs
have recently shown promising results in many machine learning and computer vision tasks. However, it has been observed
that it is difﬁcult to train the RNNs to deal with long-term
sequential data, as the gradients tend to vanish. To address this
issue, one common approach is to design a more sophisticated
recurrent unit.
Long short-term memory (LSTM) , is a special
type of recurrent hidden unit, capable of learning long-term
dependences. LSTM was initially introduced in . Since
then, a number of minor modiﬁcations to the original version
have been made , . A recurrent layer with traditional
recurrent hidden units is shown in (2), which simply calculates
a weighted linear sum of inputs and then applies a nonlinear
function. In contrast, an LSTM-based recurrent layer creates
a memory cell ct at step t. The activation of the LSTM units
can be computed by
ht = ot tanh(ct)
where tanh(·) is the hyperbolic tangent function and ot is the
output gate that determines the part of the memory content
that will be exposed. The output gate is updated by
ot = σ(Woixt + Wohht−1 + Wocct)
where σ(·) is a logistic sigmoid function and W terms denote
weight matrices; e.g., Woi is the input–output weight matrix
and Woc represents the memory-output weight matrix.
The memory cell ct is updated by adding new content of
memory cell ˜ct and discarding part of the present memory
ct = it ⊙˜ct + ft ⊙ct−1
where ⊙is an elementwise multiplication, and the new content
of memory cell ˜ct is obtained by
˜ct = tanh(Wcixt + Wchht−1).
Input gate it modulates the extent to which the new memory
information is added to the memory cell. The degree to which
content of the existing memory cell is forgotten is decided by
the forget gate ft. The equations that calculate these two gates
are as follows:
it = σ(Wiixt + Wihht−1 + Wicct−1)
ft = σ(W f ixt + W f hht−1 + W f cct−1).
Fig. 1 shows the graph model of LSTM.
III. PROPOSED RECURRENT NETWORK FOR
HYPERSPECTRAL IMAGE CLASSIFICATION
In the main procedure of the proposed recurrent network,
as shown in Fig. 2, the input of the network is a hyperspectral
pixel x, where the kth spectral band is denoted as xk. The
output is a label that indicates the category the pixel belongs
to. The entire classiﬁcation map can be obtained by applying
Fig. 1. Graphic model of LSTM. i, f , o, and c are the input gate, forget gate,
output gate, and memory cell, respectively. The new memory cell content is
denoted by ˜c.
the network to all pixels in the image. The ﬂowchart of our
RNN can be summarized as follows.
1) First, the value of the existing spectral band xk is fed
into the input layer.
2) Then, the recurrent layer receives xk and calculates the
hidden state information for the current band; it also
restores that information in the meantime.
3) Subsequently, the value of the next band xk+1 is input
to the recurrent layer simultaneously with the state
information of xk, and the activation at spectral band
k + 1 is computed by a linear interpolation between
proposal activation and the activation of the previous
4) Finally, the RNN predicts the label of the input hyperspectral pixel by looping through the entire hyperspectral
pixel sequence.
Two important factors affect the performance of RNN:
the activation function and the structure of the recurrent
unit. In Section III-A and Section III-B, we will discuss our
innovative contributions on these two factors in detail.
A. Parametric Rectiﬁed tanh
Recently, rectiﬁed linear activation functions, such as the
rectiﬁed linear unit (ReLU) , have become a common
approach to training deep convolutional networks. They have
been proposed to alleviate the vanishing gradient problem and
speed up the learning process by identifying positive values;
however, this leads to a nonbounded output. We have utilized
the proposed activation function instead of the existing ones
for several reasons.
1) To train an RNN in our task, the vanishing gradient
problem is not a concern, as modern recurrent network
models, such as LSTM and GRU, have already been
designed to tackle this issue. By using gates, LSTMs
and the GRUs help preserve the errors that can be backpropagated through sequence and layers. By maintaining
a more constant error, they allow recurrent networks
to continue to learn over many bands of hyperspectral
pixels without the risk of the vanishing gradient.
2) In our experiments, the recurrent network often runs into
numerical problems when a rectiﬁed linear function like
IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 55, NO. 7, JULY 2017
Overview of our pipeline. First, the value of existing spectral band xk is fed into the input layer. Then, the recurrent layer receives xk and calculates
the hidden state information for the current band; it also restores that information in the meantime. Next, the value of the next band xk+1 is input to the
recurrent layer simultaneously with the state information of xk, and the activation at spectral band k + 1 is computed by a linear interpolation between
proposal activation and the activation of previous band k. Finally, the RNN can predict the label of the input hyperspectral pixel by looping through the entire
hyperspectral pixel sequence.
ReLU is used as an activation functions for the network
output, given that gradients often need to be truncated
often (and ReLU cannot dampen them like the bounded
activation functions, such as tanh).
3) Traditional bounded activation functions, such as sigmoid and tanh, are always likely to generate some
nonzero values, resulting in dense representations, while
sparse representations seem to be better than dense
representations in terms of representation learning.
Thus, to train a valid recurrent network for the hyperspectral
image classiﬁcation, we designed the new activation function
PRetanh, which has two major advantages: 1) producing a
bounded output and 2) promoting sparsity adaptively.
Deﬁnition: In this section, we introduce a newly deﬁned
activation function—PRetanh. It is deﬁned as
λi tanh(hi), if hi ≤0
where hi is the input of the nonlinear activation f on the ith
channel and 0 ≤λi ≤1 is a coefﬁcient that can control the
range of the negative part. The subscript i means that PRetanh
can be varied in different channels. When λi = 0, it turns to
f (hi) = max(0, f (hi)) = max(0, tanh(hi)).
When λi is a learnable parameter, we refer to (11) as a
parametric rectiﬁed hyperbolic tangent function. Fig. 3 shows
the shapes of tanh and PRetanh. Equation (11) is equivalent to
f (hi) = max(0, tanh(hi)) + λi min(0, tanh(hi)).
In our method, the PRetanh parameter λi is adaptively
learned jointly with the whole neural network model. We
expect that end-to-end training can lead to more specialized
activations. Note that extra parameters are introduced in PRetanh. The total number of extra parameters for each layer is
equal to the number of channels, which is negligible when
taking into account the number of weights of the whole network. Therefore, we anticipate no extra risk of overﬁtting with
the same number of training samples. In addition, a channelshared variant version of PRetanh can be considered
f (hi) = max(0, tanh(hi)) + λ min(0, tanh(hi))
where all channels of one layer share the same coefﬁcient λ.
In this case, only a single extra parameter is introduced for
each layer.
Optimization: With respect to the training of PRetanh,
we use the backpropagation algorithm and simultaneously
optimize the parameters of PRetanh with the neural networks.
Suppose we have an objective function L that we wish to
minimize, and the update rule of parameter λi is derived by
the chain rule
The term (∂L)/(∂f (hi)) is the gradient backpropagated
from the deeper layer of PRetanh. The summation 
applied in all positions of the feature maps. Speciﬁcally, the
gradient of activation is given by
tanh(hi), if hi ≤0.
Equation (16) can be rewritten as follows:
= min(0, tanh(hi)).
Moreover, for the channel-shared variant version, the
gradient of λ is as follows:
i sums over all channels of the layer.
MOU et al.: DEEP RNNs FOR HYPERSPECTRAL IMAGE CLASSIFICATION
(From left to right) tanh, ReLU, and PRetanh. For PRetanh, the coefﬁcient λ of the negative part is not constant and is adaptively learned.
The momentum method is commonly used to help accelerate stochastic gradient descent in the relevant direction and
dampens oscillations by adding a fraction γ of the update
parameter. Here, we adopt the momentum method when
updating parameter λi. The updating rule is
λi := γ λi + η ∂L
where η is the learning rate and γ is the momentum. Note
that we do not use weight decay, i.e., ℓ2 regularization, for
updating λi, since a weight decay term tends to push the
rectiﬁed parameters λi to zero.
Analysis: The two major advantages lie in obtaining adaptively sparse and bounded output. Sparsity arises when λi = 0
and hi ≤0. The more such units exist in a layer, the more
sparse the resulting representations will be. The traditional
tanh, in contrast, is always likely to generate some nonzero
values, resulting in dense representations, while sparse representations seem to be better than dense representations.
In addition, unlike the popular ReLU , which restricts the
form of the negative part, we do not apply any constraints or
regularization to it. As a result, the parameter λi that controls
sparsity can be learned freely as the network trains. The other
merit of PRetanh, the bounded output, is important from a
practical perspective, because it means that the activations of
the recurrent network will not blow up. The bounded output
can reduce the probability of change in the distribution of
internal nodes of deep networks to some extent, which allows
fairly high learning rates to be used without the risk of divergence. In Section IV, it will be demonstrated that, compared
with ReLU, using PRetanh as the activation function can
effectively overcome the divergence of the recurrent network
for hyperspectral image classiﬁcation in the course of training.
Nevertheless, since PRetanh is affected by tanh, it likely
moves many inputs into the saturated regime of the nonlinearity, and slows down the convergence. This effect is
ampliﬁed as the recurrent network depth increases. In practice,
the saturation problem and the resulting vanishing gradients
are usually addressed by a carefully chosen initialization and
the use of small learning rates. If, however, the distribution
of inputs could be ensured to remain more stable as the
training goes on, the optimizer would be less likely to fall
into the saturation regime. In this paper, we combine a batch
normalization technique with PRetanh to avoid the vanishing
gradient problem.
dimensional
h = (h1, h2, . . . , h D), we normalize the ith channel as
ˆhi = hi −E[hi]
expectation,
H = {h(1)...(N)
} represents the set of values of hi over
a mini training batch, and Var[hi] is the variance. We also
need to scale and shift the normalized values; otherwise,
just normalizing a layer would limit the layer in terms of
what it can represent. Therefore, the normalized input hi is
transformed into
g(hi) = αi ˆhi + βi
where α and β are parameters learned along with the original
network parameters. Finally, batch normalization makes it possible to use PRetanh nonlinearities by preventing the network
from getting stuck in the saturated modes.
B. Recurrent Unit
Recently, more and more empirical results have demonstrated that RNNs are not just powerful in theory ,
 , but can also be reliably learned in practice for
processing long-term sequential data , , . One
interesting observation is that a few of these successes were
obtained with the traditional RNN model. Rather, they used
an RNN with sophisticated recurrent hidden units like LSTM,
because such structures are capable of alleviating the vanishing
gradient problem. However, available training samples for
remote sensing image classiﬁcation are often limited, forcing
researchers to control the total number of trainable parameters
of the network as much as possible. We, therefore, design a
novel GRU with PReLU, which is able to deal with longterm sequential data like hyperspectral sequences and is more
suitable for a small number of training samples, since it has
fewer parameters than LSTM.
1) LSTM for Hyperspectral Image Classiﬁcation: For a
hyperspectral image classiﬁcation task, given a hyperspectral
pixel sequence x = (x1, x2, . . . , x K), a traditional RNN
framework calculates the hidden vector sequence h =
(h1, h2, . . . , hK ) by iterating the following equation from
k = 1 to K:
hk = ϕ(wihxk + Whhhk−1 + bh)
IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 55, NO. 7, JULY 2017
where wih denotes the input-hidden weight vector, Whh represents the context weight matrix of the hidden layer, bh is
the hidden bias vector, and ϕ(·) is the hidden layer activation
function. Finally, the predicted label y can be computed as
y = WohhK + bo
where Woh is the output-hidden weight matrix and bo is the
bias vector of output layer.
In this paper, we want to use an RNN to characterize
the spectral correlation and band-to-band variability when
mapping between input pixel sequences and output labels.
Unfortunately, for standard recurrent network architecture, the
range of spectral contexts that can be accessed in practice
is quite limited. The problem is that the inﬂuence of a given
input on the hidden layer and, therefore, on the network output
either decays or blows up exponentially as it cycles around the
recurrent connections of the network. This effect is a common
challenge in designing and training deep RNNs and is known
as the vanishing gradient problem .
To process long-term sequences, which is crucial to the
task, as hyperspectral imagery usually includes hundreds of
spectral bands, LSTMs were proposed to address the vanishing
gradient problem. LSTMs introduce the gate concept
and memory cell to help preserve the error that can be
backpropagated through steps and layers. By maintaining a
more constant error, they allow recurrent networks to continue
to learn over many steps (over 1000) and thereby enable us to
utilize a large range of spectral contexts, e.g., to link the ﬁrst
and last spectral bands remotely.
2) Gated Recurrent Unit With PReLU: However, LSTMs
lead to more parameters, which need to be learned. And,
as discussed earlier, the limited number of training samples
drives a need to restrict the number of parameters, to avoid
overﬁtting.
Therefore, a deep RNN with modiﬁed GRUs tailored for
hyperspectral sequence analysis is proposed for hyperspectral
image classiﬁcation. GRUs , have fewer parameters
than LSTMs, and can also effectively process a long-term
spectral sequence. Moreover, PReLU is introduced to our
modiﬁed GRUs, allowing us to use fairly high learning rates
without the risk of divergence.
A GRU can cause a recurrent unit to adaptively capture
the dependences of different spectral bands. Similar to the
LSTM unit, the GRU has gate units that control the ﬂow of
information inside the unit without including separate memory
The activation hk
i of the ith GRU at spectral band k is
computed by a linear interpolation between the proposal activation pk
i and the activation of the previous spectral band hk−1
i is an update gate that determines how much the unit
updates its activation or content. The update gate uk
calculated as follows:
i = σ(wui xk + Wuhhk−1)i
where wui is the input-update weight vector and Wuh represents the update-hidden weight matrix.
Similarly to LSTM, the GRU takes a linear sum between the
newly computed state and the present state. However, it lacks
a mechanism to control what part of the state information
will be exposed, rather exposing the whole state value at each
spectral band.
The proposal activation pk
i is computed using the value of
the existing spectral band and the activation of the previous
band, which reﬂects the updated information of the recurrent
hidden state. It is calculated with PRetanh and batch normalization as follows:
i = f (g(wpixk + Wrh(rk ⊙hk−1)))i
where rk is a set of reset gates, wpi denotes the proposal-input
weight vector, and Wrh represents the reset-hidden weight
matrix. Moreover, f (·) and g(·) represent PRetanh and batch
normalization, respectively. When the reset gate rk
i is fully
OFF, i.e., rk
i is 0, it will completely discard the activation of
the hidden layer at previous spectral bands hk−1
use the value of the existing spectral band xk. When open
i close to 1), in contrast, the reset gate will partially keep
the information of the previous step.
i = wpi xk + Wrh(rk ⊙hk−1). Equation (26) can then
be transformed as
The reset gate rk
i is computed similar to the update gate
i = σ(wri xk + Wrhhk−1)i
where wri and Wrh are the reset-input weight vector and the
reset-hidden weight matrix, respectively.
Fig. 4 shows the graphic model of the GRU through time.
IV. EXPERIMENTAL RESULTS AND DISCUSSION
A. Data Description
1) Pavia University: This data set is acquired by reﬂective
optics system imaging spectrometer (ROSIS). The image is
of 610 × 340 pixels covering the Engineering School at the
University of Pavia, which was collected under the HySens
project managed by the German Aerospace Agency (DLR).
The ROSIS-03 sensor comprises 115 spectral channels ranging
from 430 to 860 nm. In this data set, 12 noisy channels have
been removed and the remaining 103 spectral channels are
investigated in this paper. The spatial resolution is 1.3 m per
pixel. The available training samples of this data set cover
nine classes of interests. Table I provides information about
different classes and their corresponding training and test
MOU et al.: DEEP RNNs FOR HYPERSPECTRAL IMAGE CLASSIFICATION
Graphic model of a GRU through time. The reset and update gates are denoted by r and u, respectively, and p and h are the proposal activation and
the ﬁnal activation.
NUMBER OF TRAINING AND TEST SAMPLES USED
IN THE PAVIA UNIVERSITY DATA SET
NUMBER OF TRAINING AND TEST SAMPLES
USED IN THE HOUSTON DATA SET
2) Houston Data: The second data set was acquired over
the University of Houston campus and its neighboring urban
area. It was collected with an ITRES-CASI 1500 sensor on
June 23, 2012 between 17:37:10 and 17:39:50 UTC. The average altitude of the sensor was about 1676 m, which results in
2.5-m spatial resolution data consisting of 349 by 1905 pixels.
The hyperspectral imagery consists of 144 spectral bands
ranging from 380 to 1050 nm and was processed (radiometric
correction, attitude processing, GPS processing, geocorrection, and so on) to yield the ﬁnal geocorrected image cube
representing the sensor spectral radiance. Table II provides
NUMBER OF TRAINING AND TEST SAMPLES USED
IN THE INDIAN PINES DATA SET
information about all 15 classes of this data set with their
corresponding training and test samples.
3) Indian Pines Data: The third data set was gathered by
an airborne visible/infrared imaging spectrometer sensor over
the Indian Pines agricultural site in Northwestern Indiana in
June 1992, and presents 16 classes, mostly related to land
covers. The data set consists of 145 by 145 pixels with
a spatial resolution of 20 m per pixel and 10-nm spectral
resolution over the range of 400–2500 nm. In this paper, we
made use of 200 bands, after removing 20 bands affected
by atmosphere absorption. The number of training and test
samples is displayed in Table III.
B. General Information
To evaluate the performance of different models for hyperspectral image classiﬁcation, we use the following evaluation
1) Overall Accuracy (OA): This index shows the number of
hyperspectral pixels that are classiﬁed correctly, divided
by the number of test samples.
2) Average Accuracy (AA): This measure is the average
value of the classiﬁcation accuracies of all classes.
IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 55, NO. 7, JULY 2017
Learning curves for a recurrent network with ReLU, one with tanh and one with the proposed PRetanh on the training samples of (a) Pavia University
data set and (b) Houston data set. As shown in these ﬁgures, with PRetanh, we can make use of a fairly high learning rate, e.g., 1.0 instead of a relatively low
default 0.002, to train the recurrent network for hyperspectral image classiﬁcation without the risk of divergence. Meanwhile, it can be seen that the ReLU
can cause the recurrent network to diverge when a fairly high learning rate is used. Here, we use the Adadelta optimization algorithm.
CLASSIFICATION ACCURACIES OF DIFFERENT TECHNIQUES IN PERCENTAGES FOR PAVIA UNIVERSITY.
THE BEST ACCURACY IN EACH ROW IS SHOWN IN BOLD
3) Kappa Coefﬁcient: This metric is a statistical measurement of agreement between the ﬁnal classiﬁcation
map and the ground-truth map. It is the percentage
agreement corrected by the level of agreement that could
be expected due to chance alone. It is generally thought
to be a more robust measure than a simple percent
agreement calculation, since k takes into account the
agreement occurring by chance .
If the number of samples for each category is identical,
OA and AA are equal. However, the category distribution
suffers from an imbalanced phenomenon in practice. Adopting
OA alone is not precise, since rare categories are commonly
ignored. Therefore, AA is also utilized to evaluate the performance of different classiﬁcation models. Strong differences
between the OA and AA may indicate that a speciﬁc class is
incorrectly classiﬁed with a high proportion.
To validate the effectiveness of the proposed RNN-based
classiﬁcation framework, it is compared with the most widely
used vector-based classiﬁcation models, SVM and random
forest. The SVM with an RBF kernel was implemented using
the libsvm package.2 Fivefold cross-validation is taken into
2 
account to tune the hyperplane parameters. Furthermore, in
this paper, experiments using other popular activation functions (i.e., tanh and ReLU) and recurrent units (i.e., LSTM)
are also carried out to verify the validity of the proposed
network. To conduct a fair comparison, PRetanh/tanh/ReLU
models are trained using the same total number of epochs, and
the same network architecture is adopted. The learning rates
are also switched after running the same number of epochs.
The methods included in the comparison are summarized as
1) RF-200: Random forest with 200 trees.
2) SVM-RBF: RBF kernel SVM with cross validation.
3) CNN: The architecture of the CNN is set as in ,
and contains an input layer, a convolution layer, a maxpooling layer, a fully connected layer, and an output
layer. The number of convolutional kernels is 20 for all
three data sets. The length of each convolution kernel
and pooling size is 11 and 3, respectively. Furthermore,
100 hidden units are included in the fully connected
4) RNN-LSTM:
We follow the implementation of LSTM as used
MOU et al.: DEEP RNNs FOR HYPERSPECTRAL IMAGE CLASSIFICATION
CLASSIFICATION ACCURACIES OF TEST SAMPLES ON THE HOUSTON DATA SET. THE BEST ACCURACY IN EACH ROW IS SHOWN IN BOLD
ACCURACY COMPARISON FOR THE INDIAN PINES DATA SET. THE BEST ACCURACY IN EACH ROW IS SHOWN IN BOLD
5) RNN-GRU-tanh: RNN with GRUs that use tanh as the
activation function.
6) RNN-GRU-ReLU: ReLU is adopted to activate the
output of recurrent units.
7) RNN-GRU-PRetanh:
proposed PRetanh activation function for the hidden
representation of GRUs.
To make the proposed approach fully comparable with
other supervised classiﬁers, we used the standard sets of
training and test samples for the data sets. For instance,
we used the training and test sets of the 2013 GRSS
classiﬁcation
The RNN was trained with the Adadelta algorithm, and all
the suggested default parameters except the learning rate were
used for all of the following experiments. We made use of a
fairly high learning rate of 1.0 instead of the relatively low
default of 0.002 to train the network. The proposed network
model uses a single recurrent layer that adopts our modiﬁed
GRUs of size 64 with sigmoid gate activation and PRetanh
activation functions for hidden representations. The output
layer uses softmax activation and then outputs a one-hot vector
for hyperspectral image classiﬁcation. All weight matrices
in our RNN and bias vectors are initialized with a uniform
distribution, and the values of these weight matrices and bias
vectors are initialized in the range [−0.1,0.1]. Then, all the
weights can be updated during the training procedure. In both
hyperspectral data sets, we randomly chose 10% of the training
samples as the validation set. That is, during the training, we
used 90% of the training samples to learn the parameters,
including the weight matrices W, bias vectors b, the parameters α and β of batch normalization, and the coefﬁcients λ of
PRetanh, and used the remaining 10% of the training samples
as validation to tune the superparameters, such as the number
of recurrent units in the recurrent layer. All test samples were
used to evaluate the ﬁnal performance of the trained recurrent
IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 55, NO. 7, JULY 2017
Classiﬁcation results obtained by different methods for the Pavia University scene. (a) Composite image of hyperspectral data. (b) Training data.
(c) Ground-truth reference. (d) RF-200. (e) SVM-RBF. (f) CNN. (g) RNN-LSTM. (h) RNN-GRU-tanh. (i) RNN-GRU-PRetanh.
network. It is noteworthy that the Indian Pines data are a small
and unbalanced data set, which is challenging for training a
valid supervised recurrent network. To address this concern,
we not only use a dropout with a probability of 0.5 on the
output of recurrent layer but also utilize a dropout of 0.2
on the weight matrices of the network, which indicates the
MOU et al.: DEEP RNNs FOR HYPERSPECTRAL IMAGE CLASSIFICATION
Classiﬁcation results obtained by different methods for the Houston scene. (From top to bottom) True-color composite of the hyperspectral data
(wavelength R: 640.7 nm, G: 550.2 nm, and B: 459.6 nm), training data, ground-truth reference, RF-200, SVM-RBF, CNN, RNN-LSTM, RNN-GRU-tanh,
and RNN-GRU-PRetanh.
fraction of the input units to drop for input gates and recurrent
connections.
The experiments are organized into three parts. The ﬁrst
one aims primarily at analyzing the behavior of different
activation functions, which involves tanh, ReLU, and the
proposed PRetanh. The comparison of the LSTM unit and
GRU is also discussed in this part. In the second experiment,
the effectiveness of an RNN that is based on the sequential
IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 55, NO. 7, JULY 2017
Confusion matrix of different methods for the Pavia University data set. (a) RF-200. (b) SVM-RBF. (c) CNN. (d) RNN-LSTM. (e) RNN-GRU-tanh.
(f) RNN-GRU-PRetanh.
perspective of a hyperspectral pixel is compared with the
traditional vector-based models, such as random forest, SVM,
and 1-D CNN. In the last part, we discuss processing time.
C. Analysis of the Network
1) Comparisons Between ReLU, tanh, and PRetanh: The
activation function is a basic building block of a neural
network, because it enables the network to detect nonlinear
features in the data. Here, we investigate and compare the
behaviors of three activation functions, ReLU, tanh, and
PRetanh. Fig. 5 compares the convergence performance of
RNN-GRU-ReLU, RNN-GRU-tanh, and RNN-GRU-PRetanh
on both the Pavia University and Houston data. All activation
functions can make the recurrent network converge except
ReLU. Moreover, compared with tanh, the proposed PRetanh
activation function starts reducing error earlier and ﬁnally
reduces the loss to a lower value, which means that the network can converge to a better solution. In particular, PRetanh
can obtain the error value of 0.272 on the Pavia University
data set after 100 epochs, while the traditional tanh activation
function can only achieve 0.334. As Fig. 5(a) shows, the RNN
with ReLU as the activation function falls into divergence,
which means that we cannot obtain a valid network. For the
Houston data set, the recurrent network with the proposed
PRetanh can quickly converge to the error of 0.401 after
100 iterations. In the same conditions, tanh can only yield
0.603. ReLU, however, cannot cause the recurrent network
to converge. We also compare the classiﬁcation accuracies
of RNN-GRU-tanh and RNN-GRU-PRetanh. As shown in
Tables IV–VI, compared with tanh, the network with the
proposed PRetanh activation function increases the accuracy
signiﬁcantly by 8.15% of OA, 2.74% of AA, and 0.0847 of the
Kappa coefﬁcient, respectively, on the Pavia University data
set. For the Houston data set, the accuracy increments on OA,
AA, and Kappa coefﬁcient are 4.12%, 6.38%, and 0.0821,
respectively. On the Indian Pines data set, our network is
able to achieve the accuracy increments of 2.92%, 5.37%, and
0.0733 for OA, AA, and the Kappa coefﬁcient, respectively.
2) Comparison of Recurrent Unit Architecture: The most
prominent trait shared between LSTM and GRU is that there
is an additive loop of their update from k −1 to k, which is
lacking in the conventional feedforward neural networks, such
as CNNs. In contrast, compared with the traditional recurrent
unit like (2), both LSTM and GRU keep the existing content
and add the new content on top of it [see (7) and (24)]. These
two units, however, have a number of differences as well.
LSTM uses three gates and a cell, an input gate, an output
MOU et al.: DEEP RNNs FOR HYPERSPECTRAL IMAGE CLASSIFICATION
Zoomed-in view confusion matrix of different methods for the Houston data set. (a) RF-200. (b) SVM-RBF. (c) CNN. (d) RNN-LSTM.
(e) RNN-GRU-tanh. (f) RNN-GRU-PRetanh. To show the result more clearly, we show only class #6 to class #13, which are easily misclassiﬁed in the
Houston data set.
NUMBER OF TOTAL TRAINABLE PARAMETERS
IN DIFFERENT RECURRENT LAYERS
gate, a forget gate, and a memory cell, to control the exposure
of memory content, while the GRU only employs two gates
to control the information ﬂow. In this way, the total number
of parameters in the GRU is reduced by about 25%, which
makes it the recurrent unit of choice in the recurrent layer for
the hyperspectral image classiﬁcation task. Table VII shows
the number of total trainable parameters in different recurrent
Tables IV–VI list the results obtained by our experiments. For all three data sets, the RNN-GRU-PRetanh outperforms the LSTM-based network (RNN-LSTM) on all indexes.
Speciﬁcally, the RNN-GRU-PRetanh increases the accuracy
signiﬁcantly by 10.86% of OA, 0.45% of AA, and 0.1020
of Kappa, respectively, on the Pavia University data set;
by 4.44% of OA, 5.84% of AA, and 0.0717 of the Kappa
coefﬁcient, respectively, on the Houston data set; and by 8.11%
of OA, 6.61% of AA, and 0.0994 of the Kappa coefﬁcient,
respectively, on the Indian Pines data set.
D. Vector-Based Methods Versus Our Recurrent Network
The classiﬁcation maps of the Pavia University data set
obtained by the conventional vector-based models and our
network are shown in Fig. 6, and the corresponding accuracy indexes are presented in Table IV. An analysis of the
classiﬁcation accuracies indicates that the SVM with RBF
kernel (SVM-RBF) outperforms the random forest model,
mainly because the kernel SVM generally handles nonlinear
inputs more efﬁciently than the random forest model. It can be
seen that the proposed recurrent network RNN-GRU-PRetanh
outperforms the SVM-RBF and CNN in terms of OA and the
Kappa coefﬁcient. Compared with SVM-RBF and CNN, the
proposed RNN-GRU-PRetanh increases the OA by 10.03%
and 8.34%, respectively. Moreover, the proposed network
achieves the best accuracies on some speciﬁc classes of the
Pavia University data, such as asphalt, meadows, metal sheets,
and shadows. For instance, the accuracy of the meadows
category obtained by RNN-GRU-PRetanh reaches 85.24%,
IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 55, NO. 7, JULY 2017
Classiﬁcation results obtained by different methods for the Indian Pines scene. (a) True-color composite (bands R: 26, G: 14,
Ground-truth
reference.
RNN-GRU-tanh.
(i) RNN-GRU-PRetanh.
and the proposed network can achieve almost 100% on the
shadows class.
Fig. 7 shows the classiﬁcation maps on the Houston data
set; the comparison of accuracies between the random forest,
SVM-RBF, and RNN-GRU-PRetanh can be found in Table V.
The proposed RNN-GRU-PRetanh achieves signiﬁcantly better scores for OA, AA, and the Kappa coefﬁcient compared
with all other methods. Misclassiﬁcation in this data set
lies in similar objects, such as Road-Highway-Railway and
Grass Healthy-Grass Stressed-Grass Synthetic. The proposed
RNN-GRU-PRetanh achieves the best AA of 70.89% on
Road-Highway-Railway, as well as the best AA of 88.63%
on Grass Healthy-Grass Stressed-Grass Synthetic. Confusion
matrices for the Pavia University data set and the Houston
data set can be found in Figs. 8 and 9, respectively. Note
that, for the Houston data set, because of the relatively large
number of classes, only selected materials that have high
misclassiﬁcation rates are illustrated. In general, the proposed
RNN-GRU-PRetanh also tends to show superior performance
in distinguishing similar materials.
The classiﬁcation maps and accuracy assessment for the
Indian Pines data set are shown in Fig. 10 and Table VI.
It can be seen that the proposed RNN-GRU-PRetanh yields
substantially more accurate results than the other methods. Speciﬁcally, compared with SVM-RBF and CNN, the
improvements in OA achieved by the proposed recurrent
network are 15.85% and 4.45%, respectively, and the increments of AA obtained by RNN-GRU-PRetanh are 2.87% and
5.18%, respectively. Fig. 11 also shows that SVM-RBF and
CNN are not very effective for discrimination between similar classes such as Grass-Pasture and Grass-Pasture-Mowed
because of their similar spectral reﬂectance. The classiﬁcation
MOU et al.: DEEP RNNs FOR HYPERSPECTRAL IMAGE CLASSIFICATION
Confusion matrix of different methods for the Indian Pines data set. (a) RF-200. (b) SVM-RBF. (c) CNN. (d) RNN-LSTM. (e) RNN-GRU-tanh.
(f) RNN-GRU-PRetanh.
TABLE VIII
STATISTICS OF TRAINING TIME (min)
STATISTICS OF TESTING EFFICIENCY (pixels/s)
of these similar land covers is improved with the proposed
recurrent network.
E. Processing Time
Processing time of different methods is compared in this
section. All the experiments are conducted on a personal
computer equipped with an Intel Core I5 with 2.20 GHz. The
training times of different approaches are shown in Table VIII.
It is not surprising that deep neural network-based methods,
including CNN and RNN, require a longer training time compared with other traditional vector-based classiﬁcation models,
such as random forest and SVM. Fortunately, such differences
remain within one to two orders of magnitude. Between CNN
and RNN, RNN requires more yet a tolerable training time, as
it involves additional channel-by-channel updates. However,
one advantage of deep neural networks is that they are fast
in testing (see Table IX), which is very important in practice.
Also, thanks to the rapid development of hardware technology,
especially of GPU, deep neural networks’ drawback of a long
training time is becoming less and less decisive.
V. CONCLUSION
In this paper, we propose a novel RNN model for hyperspectral image classiﬁcation, inspired by our observation
that hyperspectral pixels can be regarded as sequential data.
Speciﬁcally, we proposed a newly designed activation function
PRetanh for hyperspectral data processing in RNN, providing
an opportunity to use fairly high learning rates without the risk
of getting stuck in the divergence. Furthermore, a modiﬁed
GRU with PRetanh was developed to effectively analyze
hyperspectral data. For hyperspectral image classiﬁcation, our
proposed recurrent network was shown to provide statistically
higher accuracy than SVM-RBF and CNN. The proposed
model considers the intrinsic sequential data structure of a
hyperspectral pixel for the ﬁrst time, representing a novel
methodology for better understanding, modeling, and processing of hyperspectral data.
In the future, further experiments will be conducted to
fully substantiate the features of deep RNN for hyperspectral
image processing, providing more accurate analysis for remote
sensing applications, such as transfer learning for remote
sensing big data analysis and change detection. In addition,
this paper only concentrates on modeling hyperspectral pixels
in the spectral domain. An end-to-end convolutional-RNN
will be considered for spatial-spectral hyperspectral image
classiﬁcation in the future. We believe that such a spatialspectral network architecture can further improve classiﬁcation
IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 55, NO. 7, JULY 2017
ACKNOWLEDGMENT
The authors would like to thank the National Center for
Airborne Laser Mapping for providing the Houston data set.
The authors would also thank Prof. P. Gamba from the
University of Pavia, Pavia, Italy, for providing the reﬂective
optics system imaging spectrometer data and corresponding
reference information.